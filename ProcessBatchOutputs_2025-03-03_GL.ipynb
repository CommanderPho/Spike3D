{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0056bc66-7629-4ef7-8c87-f28f8fcd9dc8",
   "metadata": {
    "autorun": true,
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "imports",
     "REQUIRED",
     "ACTIVE",
     "run-main"
    ]
   },
   "outputs": [],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import os\n",
    "import sys\n",
    "import platform\n",
    "from copy import deepcopy\n",
    "from typing import List, Dict, Optional, Union, Callable\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tables as tb\n",
    "from copy import deepcopy\n",
    "from datetime import datetime, timedelta\n",
    "from attrs import define, field, Factory\n",
    "\n",
    "# # required to enable non-blocking interaction:\n",
    "# %gui qt5 ## TODO 2024-01-18 - this causes kernel to crash when running notebook remotely via VSCode's ssh remote\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "from pyphocorehelpers.function_helpers import function_attributes\n",
    "from pyphocorehelpers.exception_helpers import CapturedException\n",
    "\n",
    "# Jupyter interactivity:\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from pyphocorehelpers.gui.Jupyter.JupyterButtonRowWidget import JupyterButtonRowWidget\n",
    "from pyphocorehelpers.gui.Jupyter.simple_widgets import code_block_widget\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.BapunDataSessionFormat import BapunDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.RachelDataSessionFormat import RachelDataSessionFormat\n",
    "from neuropy.core.session.Formats.Specific.HiroDataSessionFormat import HiroDataSessionFormatRegisteredClass\n",
    "from neuropy.utils.matplotlib_helpers import matplotlib_configuration_update\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "from neuropy.core import Epoch\n",
    "\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData, loadData\n",
    "import pyphoplacecellanalysis.General.Batch.runBatch\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchRun, BatchResultDataframeAccessor, run_diba_batch, BatchComputationProcessOptions, BatchSessionCompletionHandler, SavingOptions\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import SessionBatchProgress\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsResults, AcrossSessionTables, AcrossSessionsVisualizations\n",
    "\n",
    "from pyphocorehelpers.Filesystem.path_helpers import set_posix_windows\n",
    "from pyphoplacecellanalysis.General.Batch.pythonScriptTemplating import build_vscode_workspace, build_windows_powershell_run_script\n",
    "\n",
    "from pyphocorehelpers.exception_helpers import CapturedException\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import InstantaneousFiringRatesDataframeAccessor\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import PipelineCompletionResult, BatchSessionCompletionHandler\n",
    "\n",
    "from pyphocorehelpers.Filesystem.metadata_helpers import FilesystemMetadata, get_file_metadata\n",
    "from pyphocorehelpers.Filesystem.path_helpers import discover_data_files, generate_copydict, copy_movedict, copy_file, save_copydict_to_text_file, read_copydict_from_text_file, invert_filedict\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import get_file_str_if_file_exists\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import check_output_h5_files, copy_files_in_filelist_to_dest\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import ConcreteSessionFolder, BackupMethods\n",
    "\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots, BatchPhoJonathanFiguresHelper\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PAPER_FIGURE_figure_1_add_replay_epoch_rasters, PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_3, main_complete_figure_generations\n",
    "\n",
    "from neuropy.core.neuron_identities import NeuronIdentityDataframeAccessor\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import build_merged_neuron_firing_rate_indicies\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalComputationFunctions, DirectionalLapsHelpers\n",
    "from pyphocorehelpers.gui.Jupyter.simple_widgets import fullwidth_path_widget, filesystem_path_folder_contents_widget\n",
    "\n",
    "import inspect\n",
    "from jinja2 import Template\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import MAIN_get_template_string, write_test_script\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import export_session_h5_file_completion_function, curr_runtime_context_header_template, export_rank_order_results_completion_function, figures_rank_order_results_completion_function, determine_session_t_delta_completion_function, perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function, compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function, compute_and_export_session_wcorr_shuffles_completion_function, compute_and_export_session_instantaneous_spike_rates_completion_function, compute_and_export_session_extended_placefield_peak_information_completion_function, compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function, backup_previous_session_files_completion_function, compute_and_export_session_trial_by_trial_performance_completion_function, save_custom_session_files_completion_function, compute_and_export_cell_first_spikes_characteristics_completion_function, figures_plot_cell_first_spikes_characteristics_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import kdiba_session_post_fixup_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.pythonScriptTemplating import ProcessingScriptPhases\n",
    "\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _add_cell_remapping_category\n",
    "from pyphoplacecellanalysis.General.Batch.pythonScriptTemplating import BatchScriptsCollection, generate_batch_single_session_scripts, display_generated_scripts_ipywidget\n",
    "\n",
    "\n",
    "BATCH_DAY_DATE: str = '2025-03-03'\n",
    "# BATCH_DATE_TO_USE = f'{BATCH_DAY_DATE}_Apogee' # used for filenames throught the notebook\n",
    "# BATCH_DATE_TO_USE = f'{BATCH_DAY_DATE}' # used for filenames throught the notebook\n",
    "BATCH_DATE_TO_USE = f'{BATCH_DAY_DATE}_GL' # used for filenames throught the notebook\n",
    "# BATCH_DATE_TO_USE = f'{BATCH_DAY_DATE}_Lab' # used for filenames throught the notebook\n",
    "# BATCH_DATE_TO_USE = f'{BATCH_DAY_DATE}_rMBP' # used for filenames throught the notebook\n",
    "\n",
    "known_scripts_output_paths = [Path(v).resolve() for v in ['/Users/pho/repo/Pho Secondary Workspace/Spike3DEnv/cloud/turbo/Data/Output/gen_scripts', '/home/halechr/cloud/turbo/Data/Output/gen_scripts/', '/Users/pho/University of Michigan Dropbox/MED-DibaLabDropbox/Data/Pho/Outputs/output/collected_outputs', '/home/halechr/FastData/gen_scripts/', 'output/gen_scripts/', \"K:/scratch/gen_scripts\"]]\n",
    "scripts_output_path = find_first_extant_path(known_scripts_output_paths)\n",
    "assert scripts_output_path.exists(), f\"scripts_output_path: {scripts_output_path} does not exist! Is the right computer's config commented out above?\"\n",
    "# fullwidth_path_widget(scripts_output_path, file_name_label='Scripts Output Path:')\n",
    "print(f'scripts_output_path: {scripts_output_path}')\n",
    "\n",
    "collected_outputs_path = scripts_output_path.joinpath('../collected_outputs').resolve()\n",
    "collected_outputs_path.mkdir(exist_ok=True)\n",
    "assert collected_outputs_path.exists()\n",
    "print(f'collected_outputs_path: {collected_outputs_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d958aaf",
   "metadata": {},
   "source": [
    "## Build Processing Scripts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cb673d3",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-main"
    ]
   },
   "outputs": [],
   "source": [
    "# Get the generated code for user-contributed functions:\n",
    "# phase_any_run_custom_user_completion_functions_dict = None\n",
    "# phase_any_run_custom_user_completion_functions_dict = {} # do no post-user functions\n",
    "\n",
    "phase_any_run_custom_user_completion_functions_dict = {\n",
    "\t# 'backup_previous_session_files_completion_function': backup_previous_session_files_completion_function,\n",
    "    # \"export_rank_order_results_completion_function\": export_rank_order_results_completion_function, # ran 2024-09-26 3pm\n",
    "# # # #     # \"figures_rank_order_results_completion_function\": figures_rank_order_results_completion_function,\n",
    "    # \"determine_session_t_delta_completion_function\": determine_session_t_delta_completion_function,  # ran 2024-05-28 6am\n",
    "\t# 'perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function': perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function, # ran 2024-09-26 3pm\n",
    "    # 'compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function': compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function, # ran 2024-09-26 3pm\n",
    "    # 'kdiba_session_post_fixup_completion_function': kdiba_session_post_fixup_completion_function,\n",
    "\t# 'compute_and_export_session_wcorr_shuffles_completion_function': compute_and_export_session_wcorr_shuffles_completion_function,\n",
    "\t# 'compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function': compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function,\n",
    "    # 'compute_and_export_session_instantaneous_spike_rates_completion_function': compute_and_export_session_instantaneous_spike_rates_completion_function,\n",
    "    # 'compute_and_export_session_extended_placefield_peak_information_completion_function': compute_and_export_session_extended_placefield_peak_information_completion_function,\n",
    "\t# 'compute_and_export_session_trial_by_trial_performance_completion_function': compute_and_export_session_trial_by_trial_performance_completion_function, \n",
    "\t# 'export_session_h5_file_completion_function': export_session_h5_file_completion_function, # ran 2024-09-26 3pm\n",
    "\t'save_custom_session_files_completion_function': save_custom_session_files_completion_function,\n",
    "\t# 'compute_and_export_cell_first_spikes_characteristics_completion_function': compute_and_export_cell_first_spikes_characteristics_completion_function,\n",
    "\t# 'figures_plot_cell_first_spikes_characteristics_completion_function': figures_plot_cell_first_spikes_characteristics_completion_function,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa767589",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-main"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# Hardcoded included_session_contexts:\n",
    "included_session_contexts: List[IdentifyingContext] = UserAnnotationsManager.get_hardcoded_good_sessions()\n",
    "# included_session_contexts\n",
    "# excluded_session_keys = ['kdiba_gor01_one_2006-6-08_14-26-15', 'kdiba_gor01_two_2006-6-07_16-40-19', 'kdiba_pin01_one_fet11-01_12-58-54']\n",
    "# excluded_session_keys = ['2006-6-08_14-26-15', '2006-6-09_1-22-43']\n",
    "excluded_session_keys = []\n",
    "excluded_session_contexts = [IdentifyingContext.try_init_from_session_key(session_str=v) for v in excluded_session_keys]\n",
    "# excluded_session_contexts\n",
    "\n",
    "included_session_context = [v for v in included_session_contexts if v not in excluded_session_contexts]\n",
    "included_session_context\n",
    "\n",
    "## Setup Functions:\n",
    "# force_recompute_override_computations_includelist = ['rank_order_shuffle_analysis', '_add_extended_pf_peak_information',\n",
    "#     '_build_trial_by_trial_activity_metrics',\n",
    "#     '_decode_and_evaluate_epochs_using_directional_decoders',\n",
    "#     '_decode_continuous_using_directional_decoders',\n",
    "#     '_decoded_epochs_heuristic_scoring',\n",
    "#     '_split_train_test_laps_data',\n",
    "#     'perform_wcorr_shuffle_analysis'\n",
    "# ]\n",
    "\n",
    "force_recompute_override_computations_includelist = None\n",
    "# force_recompute_override_computations_includelist = ['directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring']\n",
    "# force_recompute_override_computations_includelist = ['split_to_directional_laps','merged_directional_placefields','directional_decoders_evaluate_epochs','directional_decoders_epoch_heuristic_scoring']\n",
    "# force_recompute_override_computations_includelist = ['directional_decoders_evaluate_epochs','directional_decoders_epoch_heuristic_scoring']\n",
    "# force_recompute_override_computations_includelist = ['lap_direction_determination', 'split_to_directional_laps', 'pf_computation', 'pfdt_computation','firing_rate_trends','merged_directional_placefields','rank_order_shuffle_analysis',]\n",
    "# force_recompute_override_computations_includelist = ['firing_rate_trends', 'extended_stats', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', ]\n",
    "# force_recompute_override_computations_includelist = ['rank_order_shuffle_analysis','wcorr_shuffle_analysis','trial_by_trial_metrics']\n",
    "\n",
    "# force_recompute_override_computation_kwargs_dict = None\n",
    "# force_recompute_override_computation_kwargs_dict = {'rank_order_shuffle_analysis':({'num_shuffles': 500, 'skip_laps': False} | dict(minimum_inclusion_fr_Hz=2.0, included_qclu_values=[1,2,4,5,6,7]))}\n",
    "# computation_kwargs_dict={'rank_order_shuffle_analysis':({'num_shuffles': 500, 'skip_laps': False} | dict(minimum_inclusion_fr_Hz=2.0, included_qclu_values=[1,2,4,5,6,7]))}\n",
    "\n",
    "\n",
    "extra_extended_computations_include_includelist = [\n",
    "\t# 'wcorr_shuffle_analysis'\n",
    "]\n",
    "\n",
    "custom_phase_extended_computations_include_includelist = None\n",
    "# custom_phase_extended_computations_include_includelist=['lap_direction_determination', 'pf_computation', 'pfdt_computation', 'firing_rate_trends',\n",
    "# \t'pf_dt_sequential_surprise',\n",
    "# \t'extended_stats',\n",
    "# \t'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', \n",
    "# \t'ratemap_peaks_prominence2d',\n",
    "# \t'long_short_inst_spike_rate_groups',\n",
    "# \t'long_short_endcap_analysis',\n",
    "# \t# 'spike_burst_detection',\n",
    "# \t'split_to_directional_laps',\n",
    "# \t'merged_directional_placefields',\n",
    "# \t'rank_order_shuffle_analysis',\n",
    "# \t# 'directional_train_test_split',\n",
    "# \t'directional_decoders_decode_continuous',\n",
    "# \t'directional_decoders_evaluate_epochs',\n",
    "# \t'directional_decoders_epoch_heuristic_scoring',\n",
    "#     'wcorr_shuffle_analysis',\n",
    "#     'trial_by_trial_metrics',\n",
    "#     'extended_pf_peak_information',\n",
    "# ]\n",
    "\n",
    "\n",
    "# debug_print = True\n",
    "debug_print = False\n",
    "known_global_data_root_parent_paths = [Path('/Users/pho/data'), Path(r'/nfs/turbo/umms-kdiba/Data'), Path(r'/media/halechr/MAX/Data'), Path(r'W:/Data'), Path(r'/home/halechr/FastData'), Path(r'/Volumes/MoverNew/data')] # Path(r'/home/halechr/cloud/turbo/Data'), , Path(r'/nfs/turbo/umms-kdiba/Data'), Path(r'/home/halechr/turbo/Data'), \n",
    "global_data_root_parent_path = find_first_extant_path(known_global_data_root_parent_paths)\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "good_session_concrete_folders = ConcreteSessionFolder.build_concrete_session_folders(global_data_root_parent_path, included_session_contexts)\n",
    "\n",
    "## Different run configurations:\n",
    "# ==================================================================================================================== #\n",
    "# ACTIVE PHASE                                                                                                         #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "# active_phase = ProcessingScriptPhases.clean_run\n",
    "# active_phase = ProcessingScriptPhases.continued_run\n",
    "active_phase = ProcessingScriptPhases.final_run\n",
    "# active_phase = ProcessingScriptPhases.figure_run\n",
    "\n",
    "\n",
    "# END ________________________________________________________________________________________________________________ #\n",
    "# custom_user_completion_functions_dict = active_phase.get_custom_user_completion_functions_dict(extra_run_functions=phase_any_run_custom_user_completion_functions_dict)\n",
    "custom_user_completion_functions_dict = phase_any_run_custom_user_completion_functions_dict ## directly override the outputs:\n",
    "\n",
    "# print(f'custom_user_completion_functions_dict: {custom_user_completion_functions_dict}')\n",
    "custom_user_completion_function_template_code, custom_user_completion_functions_dict = MAIN_get_template_string(BATCH_DATE_TO_USE=BATCH_DATE_TO_USE, collected_outputs_path=collected_outputs_path, override_custom_user_completion_functions_dict=custom_user_completion_functions_dict)\n",
    "# print(f'custom_user_completion_function_template_code: {custom_user_completion_function_template_code}')\n",
    "active_phase_dict = active_phase.get_run_configuration(custom_user_completion_function_template_code=custom_user_completion_function_template_code, extra_extended_computations_include_includelist=extra_extended_computations_include_includelist)\n",
    "\n",
    "## Completely replace with custom functions:\n",
    "if custom_phase_extended_computations_include_includelist is not None:\n",
    "\tprint(f'WARNING: custom_phase_extended_computations_include_includelist: {custom_phase_extended_computations_include_includelist} is provided so only these extended_computation_fns will be used (overwritting the phase defaults!).')\n",
    "\tactive_phase_dict['extended_computations_include_includelist'] = custom_phase_extended_computations_include_includelist\n",
    "\n",
    "# active_phase_dict['extended_computations_include_includelist'].remove('wcorr_shuffle_analysis')\n",
    "active_phase_dict['should_freeze_pipeline_updates'] = False \n",
    "# active_phase_dict['should_freeze_pipeline_updates'] = True # `should_freeze_pipeline_updates`\n",
    "# active_phase_dict['should_create_vscode_workspace'] = True\n",
    "\n",
    "# ## Default non-overriden for custom suffix:\n",
    "# active_phase_dict['override_custom_pickle_suffix'] = '' # default, None\n",
    "# active_phase_dict['force_recompute_override_computation_kwargs_dict'] = {}\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Custom Suffix and overrides                                                                                          #\n",
    "# ==================================================================================================================== #\n",
    "# '_withNormalComputedReplays-frateThresh_5.0-qclu_[1, 2]' ___________________________________________________________ #\n",
    "active_phase_dict['override_custom_pickle_suffix'] = '_withNormalComputedReplays-qclu_[1, 2]-frateThresh_5.0'\n",
    "included_qclu_values = [1,2]\n",
    "minimum_inclusion_fr_Hz = 5.0\n",
    "job_suffix = f\"_withNormalComputedReplays-qclu_12-frateThresh_5.0\" ## ends up being something like # job_suffix = f\"_withNormalComputedReplays-qclu_12-frateThresh_5.0_tbin_25ms\"\n",
    "\n",
    "\n",
    "# # # \"_withNormalComputedReplays-frateThresh_5.0-qclu_[1, 2, 4, 6, 7, 9]\" _______________________________________________ #\n",
    "# active_phase_dict['override_custom_pickle_suffix'] = \"_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0\" ##\n",
    "# included_qclu_values = [1, 2, 4, 6, 7, 9]\n",
    "# minimum_inclusion_fr_Hz = 5.0\n",
    "# job_suffix = f\"_withNormalComputedReplays-qclu_124679-frateThresh_5.0\"\n",
    "\n",
    "\n",
    "# # \"_withNormalComputedReplays-frateThresh_5.0-qclu_[1, 2]\" _______________________________________________ #\n",
    "# active_phase_dict['override_custom_pickle_suffix'] = \"_withNormalComputedReplays-qclu_[1, 2]-frateThresh_5.0\" \n",
    "# included_qclu_values = [1, 2]\n",
    "# minimum_inclusion_fr_Hz = 5.0\n",
    "# job_suffix = f\"_withNormalComputedReplays-qclu_12-frateThresh_5.0\"\n",
    "\n",
    "# # # \"_withNormalComputedReplays-frateThresh_5.0-qclu_[1, 2, 4, 6, 7, 8, 9]\" _______________________________________________ #\n",
    "# active_phase_dict['override_custom_pickle_suffix'] = \"_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 8, 9]-frateThresh_5.0\"\n",
    "# included_qclu_values = [1, 2, 4, 6, 7, 8, 9]\n",
    "# minimum_inclusion_fr_Hz = 5.0\n",
    "# job_suffix = f\"_withNormalComputedReplays-qclu_1246789-frateThresh_5.0\"\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Common:                                                                                                              #\n",
    "# ==================================================================================================================== #\n",
    "num_shuffles = 1024\n",
    "drop_previous_result_and_compute_fresh = True\n",
    "\n",
    "# laps_decoding_time_bin_size = None\n",
    "laps_decoding_time_bin_size = 0.025\n",
    "# laps_decoding_time_bin_size = 0.025\n",
    "\n",
    "# ripple_decoding_time_bin_size = 0.058\n",
    "# job_suffix='tbin_58ms'\n",
    "ripple_decoding_time_bin_size = 0.025\n",
    "# job_suffix='tbin_50ms'\n",
    "# ripple_decoding_time_bin_size = 0.025\n",
    "# job_suffix='tbin_25ms'\n",
    "\n",
    "\n",
    "# job_suffix = f\"{active_phase_dict['override_custom_pickle_suffix']}_tbin_25ms\"\n",
    "job_suffix = f\"{job_suffix}_tbin_25ms\"\n",
    "# job_suffix = f\"{job_suffix}_tbin_50ms\"\n",
    "\n",
    "\n",
    "\n",
    "# END ________________________________________________________________________________________________________________ #\n",
    "print(f'job_suffix: {job_suffix}')\n",
    "active_phase_dict['force_recompute_override_computation_kwargs_dict'] = {\n",
    "\t'merged_directional_placefields': {'laps_decoding_time_bin_size': laps_decoding_time_bin_size, 'ripple_decoding_time_bin_size': ripple_decoding_time_bin_size},\n",
    "\t'directional_decoders_evaluate_epochs': {'should_skip_radon_transform': False},\n",
    "\t'rank_order_shuffle_analysis': {'num_shuffles': num_shuffles, 'skip_laps': False, 'minimum_inclusion_fr_Hz':minimum_inclusion_fr_Hz, 'included_qclu_values':included_qclu_values},\n",
    "    'perform_wcorr_shuffle_analysis': dict(num_shuffles=num_shuffles, drop_previous_result_and_compute_fresh=True),\n",
    "}\n",
    "# active_phase_dict['force_recompute_override_computations_includelist'] = list(active_phase_dict.get('force_recompute_override_computation_kwargs_dict', {}).keys())\n",
    "\n",
    "# active_phase_dict['force_recompute_override_computations_includelist'] = [] # empty list so that everything isn't forced to recompute each time. NEEDS TO BE CHANGED WHEN qclus/fr_Hz change\n",
    "# active_phase_dict['force_recompute_override_computations_includelist'] = ['directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring']\n",
    "active_phase_dict['force_recompute_override_computations_includelist'] = list(active_phase_dict.get('force_recompute_override_computation_kwargs_dict', {}).keys())\n",
    "\n",
    "active_phase_dict['override_parameters_flat_keypaths_dict'] = {'rank_order_shuffle_analysis.included_qclu_values': included_qclu_values, 'rank_order_shuffle_analysis.minimum_inclusion_fr_Hz': minimum_inclusion_fr_Hz,\n",
    "} # need to provide `override_parameters_flat_keypaths_dict`\n",
    "\n",
    "active_phase_dict['custom_user_completion_function_override_kwargs_dict'] = {\n",
    "\t'compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function': dict(included_qclu_values=included_qclu_values, minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, ripple_decoding_time_bin_size=ripple_decoding_time_bin_size, num_wcorr_shuffles=num_shuffles, drop_previous_result_and_compute_fresh=drop_previous_result_and_compute_fresh),\n",
    "\t# 'backup_previous_session_files_completion_function': dict(desired_suffix='Pre2024-11-21'),\n",
    "\t# 'compute_and_export_session_instantaneous_spike_rates_completion_function': dict(instantaneous_time_bin_size_seconds_list=[1000.0], epoch_handling_mode='UseAllEpochsMode', save_hdf=True, save_pickle=True, save_across_session_hdf=False),\n",
    "\t# 'compute_and_export_session_wcorr_shuffles_completion_function': dict(should_skip_previous_saved_shuffles=False, with_data_name=None),\n",
    "\t# 'perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function': dict(save_hdf=True, desired_shared_decoding_time_bin_sizes=None, custom_all_param_sweep_options=None, additional_session_context=None),\n",
    "\t# 'compute_and_export_session_trial_by_trial_performance_completion_function': dict(active_laps_decoding_time_bin_size=0.25),\n",
    "    'compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function': dict(ripple_decoding_time_bin_size_override=ripple_decoding_time_bin_size, laps_decoding_time_bin_size_override=laps_decoding_time_bin_size,\n",
    "        needs_recompute_heuristics=True, force_recompute_all_decoding=True,\n",
    "        save_hdf=True, allow_append_to_session_h5_file=False,\n",
    "\t\tmax_ignore_bins=2, same_thresh_cm=10.7, max_jump_distance_cm=60.0, # Heuristic settings\n",
    "\t\t),\n",
    "}\n",
    "\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Last-Chance Overrides                                                                                                #\n",
    "# ==================================================================================================================== #\n",
    "# # Interactive Debugging in Notebooks:\n",
    "# active_phase_dict.update(dict(should_use_neptune_logging=False, should_create_vscode_workspace=True, should_use_file_redirected_output_logging=False, \n",
    "# \tshould_freeze_pipeline_updates=True,\n",
    "# ))\n",
    "\n",
    "# ## No custom suffix!\n",
    "# active_phase_dict.update(dict(job_suffix=job_suffix, should_freeze_pipeline_updates=False, should_use_neptune_logging=False, should_generate_run_notebooks=True, should_create_vscode_workspace=True, should_use_file_redirected_output_logging=False, create_slurm_scripts=True,\n",
    "# ))\n",
    "\n",
    "\n",
    "# Custom Job Suffix that will not interfere with running jobs ________________________________________________________ #\n",
    "active_phase_dict.update(dict(job_suffix=job_suffix, should_freeze_pipeline_updates=True, should_use_neptune_logging=False, create_slurm_scripts=True, should_generate_run_scripts=True, should_generate_run_notebooks=True, should_create_vscode_workspace=True, should_use_file_redirected_output_logging=True,\n",
    "))\n",
    "\n",
    "\n",
    "# #TODO 2024-11-20 07:12: - [ ] Run with this, I hardcoded the parameter change for now\n",
    "# {'ripple_decoding_time_bin_size': 0.058}\n",
    "\n",
    "## Non-interactive batch computation in scripts\n",
    "# active_phase_dict.update(dict(should_use_neptune_logging=True, should_generate_run_notebooks=False, should_use_file_redirected_output_logging=True))\n",
    "\n",
    "# END ________________________________________________________________________________________________________________ #\n",
    "\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# BEGIN MAIN SCRIPT BODY                                                                                               #\n",
    "# ==================================================================================================================== #\n",
    "## Build Slurm Scripts:\n",
    "session_basedirs_dict: Dict[IdentifyingContext, Path] = {a_session_folder.context:a_session_folder.path for a_session_folder in good_session_concrete_folders}\n",
    "batch_scripts_collection: BatchScriptsCollection = generate_batch_single_session_scripts(global_data_root_parent_path, session_batch_basedirs=session_basedirs_dict, included_session_contexts=included_session_contexts,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\toutput_directory=scripts_output_path, use_separate_run_directories=True,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# should_use_neptune_logging=False,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# should_use_neptune_logging=True,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# should_freeze_pipeline_updates=False, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# create_slurm_scripts=True, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# should_create_vscode_workspace=True,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# should_generate_run_notebooks=False,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# extended_computations_include_includelist=extended_computations_include_includelist,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, # ['split_to_directional_laps', 'rank_order_shuffle_analysis'],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# force_recompute_override_computation_kwargs_dict=force_recompute_override_computation_kwargs_dict,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# should_use_file_redirected_output_logging=False,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# should_use_file_redirected_output_logging=True,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# should_perform_figure_generation_to_file=False,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# batch_session_completion_handler_kwargs=dict(enable_hdf5_output=False),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# custom_user_completion_functions=custom_user_completion_functions,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# custom_user_completion_function_template_code=custom_user_completion_function_template_code,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# should_force_reload_all=True,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# should_force_reload_all=False,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t**active_phase_dict\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t)\n",
    "\n",
    "\n",
    "# batch_scripts_collection.included_session_contexts, output_python_scripts, output_slurm_scripts\n",
    "\n",
    "output_python_scripts = batch_scripts_collection.output_python_scripts\n",
    "output_jupyter_notebooks = batch_scripts_collection.output_jupyter_notebooks\n",
    "output_slurm_scripts = batch_scripts_collection.output_slurm_scripts\n",
    "vscode_workspace_path = batch_scripts_collection.vscode_workspace_path\n",
    "\n",
    "if vscode_workspace_path is not None:\n",
    "\tdisplay(fullwidth_path_widget(vscode_workspace_path, file_name_label='vscode_workspace_path:'))\n",
    "\n",
    "print(f\"extended_computations_include_includelist: {active_phase_dict['extended_computations_include_includelist']}\")\n",
    "computation_script_paths = [x[0] for x in output_python_scripts]\n",
    "generate_figures_script_paths = [x[1] for x in output_python_scripts]\n",
    "print(f'generate_figures_script_paths: {generate_figures_script_paths}')\n",
    "_out_widget = display_generated_scripts_ipywidget(batch_scripts_collection.included_session_contexts, output_python_scripts)\n",
    "display(_out_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-main"
    ]
   },
   "outputs": [],
   "source": [
    "## INPUTS: active_phase, output_slurm_scripts, computation_script_paths, generate_figures_script_paths\n",
    "also_show_figure_script_outputs: bool = False\n",
    "\n",
    "# Maximum number of parallel script executions\n",
    "max_parallel_executions = 1\n",
    "# List of your script paths\n",
    "# if active_phase.value == ProcessingScriptPhases.figure_run:\n",
    "if active_phase.is_figure_phase:\n",
    "\tprint(f'fig mode!')\n",
    "\tscript_paths = generate_figures_script_paths\n",
    "else:\n",
    "\tscript_paths = computation_script_paths\n",
    "\n",
    "\n",
    "if (platform.system() == 'Windows'):\n",
    "\tpowershell_script_path = build_windows_powershell_run_script(script_paths, max_concurrent_jobs=max_parallel_executions, script_name='run_scripts')\n",
    "\t# print(f'powershell_script_path: {powershell_script_path}')\n",
    "\tdisplay(fullwidth_path_widget(powershell_script_path, file_name_label='powershell_script_path:'))\n",
    "\n",
    "\tif also_show_figure_script_outputs or active_phase_dict['should_perform_figure_generation_to_file']:\n",
    "\t\tpowershell_figures_script_path = build_windows_powershell_run_script(generate_figures_script_paths, max_concurrent_jobs=1, script_name='run_figure_scripts')\n",
    "\t\tdisplay(fullwidth_path_widget(powershell_figures_script_path, file_name_label='powershell_figures_script_path:'))\n",
    "\n",
    "\n",
    "if (platform.system() != 'Windows'):\n",
    "\t## Linux Only: Slurm Scripts\n",
    "\t# sbatch_start_slurm_scripts: str = \"\\n\".join([f\"sbatch '{slurm_script}'\" for slurm_script in output_slurm_scripts])\n",
    "\tsbatch_run_start_slurm_scripts: str = \"\\n\".join([f\"sbatch '{slurm_script}'\" for slurm_script in output_slurm_scripts['run']])\n",
    "\tsbatch_figs_start_slurm_scripts: str = \"\\n\".join([f\"sbatch '{slurm_script}'\" for slurm_script in output_slurm_scripts['figs']])\n",
    "\n",
    "\tif not active_phase.is_figure_phase:\n",
    "\t\t# Create and display the code block widget\n",
    "\t\trun_slurm_code_block = code_block_widget(sbatch_run_start_slurm_scripts, label=\"RunMain:\")\n",
    "\n",
    "\tif (active_phase.is_figure_phase or also_show_figure_script_outputs and (len(sbatch_figs_start_slurm_scripts)>0)):\n",
    "\t\t# Create and display the code block widget\n",
    "\t\tfigs_slurm_code_block = code_block_widget(sbatch_figs_start_slurm_scripts, label=\"Figures:\")\n",
    "\n",
    "# Batch 1\n",
    "# sbatch '/nfs/turbo/umms-kdiba/Data/Output/gen_scripts/run_kdiba_pin01_one_11-02_17-46-44/run_kdiba_pin01_one_11-02_17-46-44.sh'\n",
    "# sbatch '/nfs/turbo/umms-kdiba/Data/Output/gen_scripts/run_kdiba_pin01_one_11-02_19-28-0/run_kdiba_pin01_one_11-02_19-28-0.sh'\n",
    "# sbatch '/nfs/turbo/umms-kdiba/Data/Output/gen_scripts/run_kdiba_pin01_one_11-03_12-3-25/run_kdiba_pin01_one_11-03_12-3-25.sh'\n",
    "# sbatch '/nfs/turbo/umms-kdiba/Data/Output/gen_scripts/run_kdiba_pin01_one_fet11-01_12-58-54/run_kdiba_pin01_one_fet11-01_12-58-54.sh'\n",
    "\n",
    "# Batch 2:\n",
    "# sbatch '/nfs/turbo/umms-kdiba/Data/Output/gen_scripts/run_kdiba_vvp01_one_2006-4-09_17-29-30/run_kdiba_vvp01_one_2006-4-09_17-29-30.sh'\n",
    "# sbatch '/nfs/turbo/umms-kdiba/Data/Output/gen_scripts/run_kdiba_vvp01_one_2006-4-10_12-25-50/run_kdiba_vvp01_one_2006-4-10_12-25-50.sh'\n",
    "# sbatch '/nfs/turbo/umms-kdiba/Data/Output/gen_scripts/run_kdiba_vvp01_two_2006-4-09_16-40-54/run_kdiba_vvp01_two_2006-4-09_16-40-54.sh'\n",
    "# sbatch '/nfs/turbo/umms-kdiba/Data/Output/gen_scripts/run_kdiba_vvp01_two_2006-4-10_12-58-3/run_kdiba_vvp01_two_2006-4-10_12-58-3.sh'\n",
    "\n",
    "# Batch 3\n",
    "# sbatch '/nfs/turbo/umms-kdiba/Data/Output/gen_scripts/run_kdiba_gor01_one_2006-6-08_14-26-15/run_kdiba_gor01_one_2006-6-08_14-26-15.sh'\n",
    "# sbatch '/nfs/turbo/umms-kdiba/Data/Output/gen_scripts/run_kdiba_gor01_one_2006-6-09_1-22-43/run_kdiba_gor01_one_2006-6-09_1-22-43.sh'\n",
    "# sbatch '/nfs/turbo/umms-kdiba/Data/Output/gen_scripts/run_kdiba_gor01_two_2006-6-07_16-40-19/run_kdiba_gor01_two_2006-6-07_16-40-19.sh'\n",
    "# sbatch '/nfs/turbo/umms-kdiba/Data/Output/gen_scripts/run_kdiba_gor01_two_2006-6-08_21-16-25/run_kdiba_gor01_two_2006-6-08_21-16-25.sh'\n",
    "# sbatch '/nfs/turbo/umms-kdiba/Data/Output/gen_scripts/run_kdiba_gor01_two_2006-6-09_22-24-40/run_kdiba_gor01_two_2006-6-09_22-24-40.sh'\n",
    "# sbatch '/nfs/turbo/umms-kdiba/Data/Output/gen_scripts/run_kdiba_gor01_two_2006-6-12_16-53-46/run_kdiba_gor01_two_2006-6-12_16-53-46.sh'\n",
    "\n",
    "# KDIBA/gor01/one/2006-6-09_1-22-43\n",
    "# sbatch '/nfs/turbo/umms-kdiba/Pho/Output/gen_scripts/run_kdiba_gor01_one_2006-6-09_1-22-43/run_kdiba_gor01_one_2006-6-09_1-22-43.sh'\n",
    "\n",
    "# sbatch '/nfs/turbo/umms-kdiba/Pho/Output/gen_scripts/run_kdiba_gor01_one_2006-6-09_1-22-43/run_kdiba_gor01_one_2006-6-09_1-22-43.sh'\n",
    "# \n",
    "# sbatch '/nfs/turbo/umms-kdiba/Pho/Output/gen_scripts/run_kdiba_gor01_one_2006-6-08_14-26-15/run_kdiba_gor01_one_2006-6-08_14-26-15.sh'\n",
    "# sbatch '/nfs/turbo/umms-kdiba/Pho/Output/gen_scripts/run_kdiba_gor01_one_2006-6-12_15-55-31/run_kdiba_gor01_one_2006-6-12_15-55-31.sh'\n",
    "# sbatch '/nfs/turbo/umms-kdiba/Pho/Output/gen_scripts/run_kdiba_gor01_two_2006-6-07_16-40-19/run_kdiba_gor01_two_2006-6-07_16-40-19.sh'\n",
    "# sbatch '/nfs/turbo/umms-kdiba/Pho/Output/gen_scripts/run_kdiba_gor01_two_2006-6-12_16-53-46/run_kdiba_gor01_two_2006-6-12_16-53-46.sh'\n",
    "# sbatch '/nfs/turbo/umms-kdiba/Pho/Output/gen_scripts/run_kdiba_vvp01_one_2006-4-09_17-29-30/run_kdiba_vvp01_one_2006-4-09_17-29-30.sh'\n",
    "# sbatch '/nfs/turbo/umms-kdiba/Pho/Output/gen_scripts/run_kdiba_vvp01_one_2006-4-10_12-25-50/run_kdiba_vvp01_one_2006-4-10_12-25-50.sh'\n",
    "# sbatch '/nfs/turbo/umms-kdiba/Pho/Output/gen_scripts/run_kdiba_vvp01_two_2006-4-09_16-40-54/run_kdiba_vvp01_two_2006-4-09_16-40-54.sh'\n",
    "# sbatch '/nfs/turbo/umms-kdiba/Pho/Output/gen_scripts/run_kdiba_vvp01_two_2006-4-10_12-58-3/run_kdiba_vvp01_two_2006-4-10_12-58-3.sh'\n",
    "# sbatch '/nfs/turbo/umms-kdiba/Pho/Output/gen_scripts/run_kdiba_pin01_one_11-03_12-3-25/run_kdiba_pin01_one_11-03_12-3-25.sh'\n",
    "# sbatch '/nfs/turbo/umms-kdiba/Pho/Output/gen_scripts/run_kdiba_pin01_one_fet11-01_12-58-54/run_kdiba_pin01_one_fet11-01_12-58-54.sh'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jinja2\n",
    "print(jinja2.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f98344",
   "metadata": {},
   "source": [
    "## Execute the generated scripts in parallel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2fb7d6",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "## recieves: max_parallel_executions, script_paths\n",
    "\"\"\"\n",
    "# Maximum number of parallel script executions\n",
    "max_parallel_executions = 5\n",
    "# List of your script paths\n",
    "script_paths = output_python_scripts\n",
    "\"\"\"\n",
    "\n",
    "# Function to execute a script\n",
    "def run_script(script_path):\n",
    "\tpython_executable = 'python'\n",
    "\t# python_executable = '/home/halechr/Library/VSCode/green/.venv_green/bin/python'\n",
    "\t\n",
    "\ttry:\n",
    "\t\tresult = subprocess.run([python_executable, script_path], capture_output=True, text=True)\n",
    "\t\treturn script_path, result.stdout, result.stderr\n",
    "\texcept BaseException as e:\n",
    "\t\treturn script_path, None, str(e)\n",
    "\n",
    "# Create a progress bar\n",
    "progress_bar = widgets.IntProgress(value=0, min=0, max=len(script_paths), description='Running:', bar_style='info')\n",
    "display(progress_bar)\n",
    "\n",
    "# Run scripts in parallel with a limit on the number of parallel instances\n",
    "with ProcessPoolExecutor(max_workers=max_parallel_executions) as executor:\n",
    "\tfutures = {executor.submit(run_script, path): path for path in script_paths}\n",
    "\tfor future in as_completed(futures):\n",
    "\t\tscript, stdout, stderr = future.result()\n",
    "\t\tprogress_bar.value += 1  # Update the progress bar\n",
    "\t\tif stderr:\n",
    "\t\t\tprint(f\"Error in {script}: {stderr}\")\n",
    "\t\telse:\n",
    "\t\t\tprint(f\"Completed {script}\")\n",
    "\n",
    "# Progress bar will automatically update as scripts complete\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”· Maintenence and File Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from copy import deepcopy\n",
    "from typing import Dict, List, Tuple, Optional, Callable, Union, Any\n",
    "from typing_extensions import TypeAlias\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from nptyping import NDArray\n",
    "import neuropy.utils.type_aliases as types\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import find_csv_files, find_HDF5_files, find_most_recent_files, OldFileArchiver\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import ConcreteSessionFolder, BackupMethods\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionHelpers\n",
    "\n",
    "all_known_session_contexts: List[IdentifyingContext] = UserAnnotationsManager.get_all_known_sessions()\n",
    "known_global_data_root_parent_paths = [Path('/Users/pho/data'), Path(r'/nfs/turbo/umms-kdiba/Data'), Path(r'/media/halechr/MAX/Data'), Path(r'W:/Data'), Path(r'/home/halechr/FastData'), Path(r'/Volumes/MoverNew/data')] # Path(r'/home/halechr/cloud/turbo/Data'), , Path(r'/nfs/turbo/umms-kdiba/Data'), Path(r'/home/halechr/turbo/Data'), \n",
    "global_data_root_parent_path = find_first_extant_path(known_global_data_root_parent_paths)\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "print(f'global_data_root_parent_path: {global_data_root_parent_path}')\n",
    "all_known_session_concrete_folders = ConcreteSessionFolder.build_concrete_session_folders(global_data_root_parent_path, all_known_session_contexts)\n",
    "known_collected_outputs_paths = [Path(v).resolve() for v in ['/Users/pho/data/collected_outputs',\n",
    "                                                            '/Volumes/SwapSSD/Data/collected_outputs', r\"K:/scratch/collected_outputs\", '/Users/pho/Dropbox (University of Michigan)/MED-DibaLabDropbox/Data/Pho/Outputs/output/collected_outputs', r'C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs',\n",
    "                                                            '/home/halechr/FastData/collected_outputs/', '/home/halechr/cloud/turbo/Data/Output/collected_outputs']]\n",
    "collected_outputs_directory = find_first_extant_path(known_collected_outputs_paths)\n",
    "assert collected_outputs_directory.exists(), f\"collected_outputs_directory: {collected_outputs_directory} does not exist! Is the right computer's config commented out above?\"\n",
    "# fullwidth_path_widget(scripts_output_path, file_name_label='Scripts Output Path:')\n",
    "print(f'collected_outputs_directory: {collected_outputs_directory}')\n",
    "\n",
    "\n",
    "known_scripts_output_paths = [Path(v).resolve() for v in ['/Users/pho/repo/Pho Secondary Workspace/Spike3DEnv/cloud/turbo/Data/Output/gen_scripts', '/home/halechr/cloud/turbo/Data/Output/gen_scripts/', '/Users/pho/University of Michigan Dropbox/MED-DibaLabDropbox/Data/Pho/Outputs/output/collected_outputs', '/home/halechr/FastData/gen_scripts/', 'output/gen_scripts/', \"K:/scratch/gen_scripts\"]]\n",
    "scripts_output_path = find_first_extant_path(known_scripts_output_paths)\n",
    "assert scripts_output_path.exists(), f\"scripts_output_path: {scripts_output_path} does not exist! Is the right computer's config commented out above?\"\n",
    "# fullwidth_path_widget(scripts_output_path, file_name_label='Scripts Output Path:')\n",
    "print(f'scripts_output_path: {scripts_output_path}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move misplaced files to session folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import try_move_pickle_files_on_GL\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionHelpers\n",
    "\n",
    "## INPUTS: good_session_concrete_folders, session_basedirs_dict, computation_script_paths\n",
    "\n",
    "# session_basedirs_dict: Dict[IdentifyingContext, Path] = {a_session_folder.context:a_session_folder.path for a_session_folder in good_session_concrete_folders}\n",
    "is_dryrun: bool = True\n",
    "# is_dryrun: bool = False\n",
    "debug_print: bool = False\n",
    "\n",
    "# copy_dict, moved_dict, (all_found_pipeline_pkl_files_dict, all_found_global_pkl_files_dict, all_found_pipeline_h5_files_dict) = try_move_pickle_files_on_GL(good_session_concrete_folders, session_basedirs_dict, computation_script_paths,\n",
    "# \t\t\tis_dryrun=is_dryrun, debug_print=debug_print)\n",
    "\n",
    "## Specify which files to match:    \n",
    "copy_dict, moved_files_dict_files = AcrossSessionHelpers._copy_exported_files_from_session_folder_to_collected_outputs(BATCH_DATE_TO_USE='2025-03-04', cuttoff_date=datetime(2025, 2, 20), target_dir=collected_outputs_directory, custom_file_globs_dict={\n",
    "    'pkl': '*standalone_wcorr_ripple_shuffle_data_only*.pkl',\n",
    "    'csv': '*ripple_WCorrShuffle_df*.csv',\n",
    "    # 'h5': '*.h5',\n",
    "}, is_dry_run=is_dryrun)\n",
    "\n",
    "copy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionHelpers\n",
    "\n",
    "is_dryrun: bool = False\n",
    "\n",
    "assert collected_outputs_directory.exists()\n",
    "copy_dict, moved_files_dict_files = AcrossSessionHelpers._copy_exported_files_from_session_folder_to_collected_outputs(BATCH_DATE_TO_USE='2025-03-04', cuttoff_date=datetime(2024, 11, 25), target_dir=collected_outputs_directory, is_dry_run=is_dryrun)\n",
    "copy_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "script_output_folders = [Path(v).parent for v in computation_script_paths]\n",
    "\n",
    "excluded_session_keys = ['kdiba_pin01_one_fet11-01_12-58-54', 'kdiba_gor01_one_2006-6-08_14-26-15', 'kdiba_gor01_two_2006-6-07_16-40-19']\n",
    "excluded_session_contexts = [IdentifyingContext(**dict(zip(IdentifyingContext._get_session_context_keys(), v.split('_', maxsplit=3)))) for v in excluded_session_keys]\n",
    "# excluded_session_contexts\n",
    "\n",
    "all_found_pkl_files_dict = {}\n",
    "all_found_pipeline_pkl_files_dict = {}\n",
    "all_found_global_pkl_files_dict = {}\n",
    "all_found_pipeline_h5_files_dict = {}\n",
    "\n",
    "copy_dict = {}\n",
    "moved_dict = {}\n",
    "\n",
    "# scripts_output_path\n",
    "for a_good_session_concrete_folder, a_session_basedir, a_script_folder in zip(good_session_concrete_folders, session_basedirs_dict, script_output_folders):\n",
    "\tif debug_print:\n",
    "\t\tprint(f'a_good_session_concrete_folder: {a_good_session_concrete_folder}, a_session_basedir: {a_session_basedir}. a_script_folder: {a_script_folder}')\n",
    "\tif a_good_session_concrete_folder.context in excluded_session_contexts:\n",
    "\t\tif debug_print:\n",
    "\t\t\tprint(f'skipping excluded session: {a_good_session_concrete_folder.context}')\n",
    "\telse:\n",
    "\t\tall_found_global_pkl_files_dict[a_session_basedir] = list(a_script_folder.glob('global_computation_results*.pkl'))\n",
    "\t\t\n",
    "\t\tfor a_global_file in all_found_global_pkl_files_dict[a_session_basedir]:\n",
    "\t\t\t## iterate through the found global files:\n",
    "\t\t\ttarget_file = a_good_session_concrete_folder.global_computation_result_pickle.with_name(a_global_file.name)\n",
    "\t\t\tcopy_dict[a_global_file] = target_file\n",
    "\t\t\t# if not is_dryrun:\n",
    "\t\t\t## perform the move/copy\n",
    "\t\t\twas_success = try_perform_move(src_file=a_global_file, target_file=target_file, is_dryrun=is_dryrun)\n",
    "\t\t\tif was_success:\n",
    "\t\t\t\tmoved_dict[a_file] = target_file\n",
    "\t\tall_found_pipeline_pkl_files_dict[a_session_basedir] = list(a_script_folder.glob('loadedSessPickle*.pkl'))\n",
    "\t\tfor a_file in all_found_pipeline_pkl_files_dict[a_session_basedir]:\n",
    "\t\t\t## iterate through the found global files:\n",
    "\t\t\ttarget_file = a_good_session_concrete_folder.session_pickle.with_name(a_file.name)\n",
    "\t\t\tcopy_dict[a_file] = target_file\n",
    "\t\t\t# if not is_dryrun:\n",
    "\t\t\t## perform the move/copy\n",
    "\t\t\twas_success = try_perform_move(src_file=a_file, target_file=target_file, is_dryrun=is_dryrun)\n",
    "\t\t\tif was_success:\n",
    "\t\t\t\tmoved_dict[a_file] = target_file\n",
    "\t\tall_found_pipeline_h5_files_dict[a_session_basedir] = list(a_script_folder.glob('loadedSessPickle*.h5'))\n",
    "\t\tfor a_file in all_found_pipeline_h5_files_dict[a_session_basedir]:\n",
    "\t\t\t## iterate through the found global files:\n",
    "\t\t\ttarget_file = a_good_session_concrete_folder.pipeline_results_h5.with_name(a_file.name)\n",
    "\t\t\tcopy_dict[a_file] = target_file\n",
    "\t\t\t# if not is_dryrun:\n",
    "\t\t\t## perform the move/copy\n",
    "\t\t\twas_success = try_perform_move(src_file=a_file, target_file=target_file, is_dryrun=is_dryrun)\n",
    "\t\t\tif was_success:\n",
    "\t\t\t\tmoved_dict[a_file] = target_file\n",
    "\t\t# all_found_pkl_files_dict[a_session_basedir] = find_pkl_files(a_script_folder)\n",
    "\n",
    "## discover .pkl files in the root of each folder:\n",
    "# all_found_pipeline_pkl_files_dict\n",
    "# all_found_global_pkl_files_dict\n",
    "## OUTPUTS: copy_dict\n",
    "# copy_dict\n",
    "moved_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f583772",
   "metadata": {},
   "source": [
    "## â›“ï¸ðŸŸ¢ Post-Processing of batch outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef5938c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyphocorehelpers.Filesystem.path_helpers import save_filelist_to_text_file\n",
    "\n",
    "\n",
    "debug_print = True\n",
    "known_global_data_root_parent_paths = [Path(r'/nfs/turbo/umms-kdiba/Data'), Path(r'W:\\Data'), Path(r'/home/halechr/cloud/turbo/Data'), Path(r'/media/halechr/MAX/Data'), Path(r'/Volumes/MoverNew/data')] # , Path(r'/home/halechr/FastData'), Path(r'/home/halechr/turbo/Data'), Path(r'W:\\Data'), Path(r'/home/halechr/cloud/turbo/Data')\n",
    "global_data_root_parent_path = find_first_extant_path(known_global_data_root_parent_paths)\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "# Hardcoded included_session_contexts:\n",
    "included_session_contexts = UserAnnotationsManager.get_hardcoded_good_sessions()\n",
    "good_session_concrete_folders = ConcreteSessionFolder.build_concrete_session_folders(global_data_root_parent_path, included_session_contexts)\n",
    "\n",
    "# Output Paths:\n",
    "## OUTPUTS: included_h5_paths, included_session_contexts, good_session_concrete_folders\n",
    "\n",
    "## INPUTS: good_session_concrete_folders, target_dir, BATCH_DATE_TO_USE\n",
    "\n",
    "# target_dir: Path = Path(global_data_root_parent_path)\n",
    "target_dir: Path = collected_outputs_path\n",
    "\n",
    "included_h5_paths = [Path(get_file_str_if_file_exists(v.pipeline_results_h5)).resolve() for v in good_session_concrete_folders]\n",
    "check_output_h5_files(included_h5_paths)\n",
    "included_h5_paths\n",
    "\n",
    "def _across_session_h5_output_basename_fn(session_context: Optional[IdentifyingContext], session_descr: Optional[str], basename: str, *args, separator_char: str = \"_\"):\n",
    "\t\"\"\" Captures `BATCH_DATE_TO_USE` \"\"\"\n",
    "\t# a_session_folder.context\n",
    "\tif session_context is not None:\n",
    "\t\tsession_descr = session_context.session_name # '2006-6-07_16-40-19'\n",
    "\t_filename_list = [BATCH_DATE_TO_USE, session_descr, basename]\n",
    "\tif len(args) > 0:\n",
    "\t\t_filename_list.extend([str(a_part) for a_part in args if a_part is not None])\n",
    "\treturn separator_char.join(_filename_list)\n",
    "\n",
    "copy_h5_dict = ConcreteSessionFolder.build_backup_copydict(good_session_concrete_folders, target_dir=collected_outputs_path, backup_mode=BackupMethods.CommonTargetDirectory, rename_backup_basename_fn=_across_session_h5_output_basename_fn, only_include_file_types=['h5']) # , rename_backup_suffix=BATCH_DATE_TO_USE\n",
    "copy_h5_dict\n",
    "\n",
    "\n",
    "## INPUTS: target_dir, BATCH_DATE_TO_USE\n",
    "h5_filelist_output_filename=f'{BATCH_DATE_TO_USE}_all_sessions_h5_filelist.txt'\n",
    "h5_filelist_output_file_path = Path(target_dir).joinpath(h5_filelist_output_filename).resolve() # Use Default\n",
    "print(f'h5_filelist_output_file_path: {h5_filelist_output_file_path}')\n",
    "_out_string, filelist_path = save_filelist_to_text_file(included_h5_paths, filelist_path=h5_filelist_output_file_path, debug_print=True) # r\"W:\\Data\\all_sessions_h5_filelist_2024-03-28_Apogee.txt\"\n",
    "filelist_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690f140f",
   "metadata": {},
   "source": [
    "# Output File Processing Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy exported `pipeline_results.h5` files into the `collected_outputs` folder, adding the current date\n",
    "```\n",
    "copying \"W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\output\\pipeline_results.h5\"\n",
    "\t\t -> \"K:\\scratch\\collected_outputs\\2024-06-12_Apogee_2006-6-08_14-26-15_pipeline_results.h5\"...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135cb2d8-65b3-405b-a41b-22b2fa7cb28e",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "a_copy_dict = copy_h5_dict\n",
    "\n",
    "# Copies each file sequentially to the collected_outputs directory, and then builds an output file list\n",
    "## INPUT a_copy_dict\n",
    "moved_files_dict_h5_files = copy_movedict(a_copy_dict)\n",
    "moved_files_dict_h5_files\n",
    "# INPUTS: active_filelist_prefix, target_dir\n",
    "# active_filelist_prefix: str = 'backed_up_files'\n",
    "active_filelist_prefix: str = 'session_h5_files'\n",
    "\n",
    "# target_dir: Path = Path(global_data_root_parent_path)\n",
    "target_dir: Path = collected_outputs_path\n",
    "\n",
    "moved_files_copydict_output_filename=f'{active_filelist_prefix}_copydict_{BATCH_DATE_TO_USE}.csv'\n",
    "moved_files_copydict_file_path = target_dir.joinpath(moved_files_copydict_output_filename).resolve() # Use Default\n",
    "print(f'moved_files_copydict_file_path: \"{moved_files_copydict_file_path}\"')\n",
    "\n",
    "_out_string, filedict_out_path = save_copydict_to_text_file(moved_files_dict_h5_files, moved_files_copydict_file_path, debug_print=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2024-09-04 - Batch Output Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import copy_session_inst_fr_data_to_across_session_pkl\n",
    "\n",
    "## Complete Concise Run:\n",
    "# RESULT_DATE_TO_USE = '2024-09-26'\n",
    "\n",
    "RESULT_DATE_TO_USE: str = BATCH_DAY_DATE\n",
    "print(f'RESULT_DATE_TO_USE: {RESULT_DATE_TO_USE}')\n",
    "\n",
    "# instantaneous_time_bin_size_seconds_list = [0.002, 0.005, 0.025, 1000.0]\n",
    "instantaneous_time_bin_size_seconds_list = [1000.0]\n",
    "\n",
    "across_sessions_recomputed_instantaneous_fr_dict, moved_files_dict_files, (filelist_path, filedict_out_path) = copy_session_inst_fr_data_to_across_session_pkl(RESULT_DATE_TO_USE=RESULT_DATE_TO_USE, collected_outputs_path=collected_outputs_path, instantaneous_time_bin_size_seconds_list=instantaneous_time_bin_size_seconds_list)\n",
    "\n",
    "\n",
    "# '/nfs/turbo/umms-kdiba/Data/across_session_result_long_short_recomputed_inst_firing_rate_2024-06-10_GL.pkl'\n",
    "# Path('/nfs/turbo/umms-kdiba/Data/Output/collected_outputs/across_session_result_long_short_recomputed_inst_firing_rate_2024-06-11_GL.pkl').resolve()\n",
    "# ## Save pickle:\n",
    "# inst_fr_output_filename=f'across_session_result_long_short_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl'\n",
    "# global_batch_result_inst_fr_file_path = Path(global_data_root_parent_path).joinpath(inst_fr_output_filename).resolve() # Use Default\n",
    "# print(f'global_batch_result_inst_fr_file_path: {global_batch_result_inst_fr_file_path}')\n",
    "# # Save the all sessions instantaneous firing rate dict to the path:\n",
    "# saveData(global_batch_result_inst_fr_file_path, across_sessions_instantaneous_fr_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ! After Sessions are processed and their `.h5` files are exported, build the combined tables\n",
    "The combined (across session) tables are saved out into .csv and .pkl formats: `W:\\Data\\2024-06-12_Apogee\\neuron_identities_table.csv` -- ideally this would be in the combined outputs folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c123baf6",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionTables\n",
    "\n",
    "## FILE_OUTPUTS: '/nfs/turbo/umms-kdiba/Pho/Output/collected_outputs/2024-10-22_GL'\n",
    "\n",
    "## INPUTS: included_session_contexts, included_h5_paths, global_data_root_parent_path, BATCH_DATE_TO_USE\n",
    "# neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table = AcrossSessionTables.build_all_known_tables(included_session_contexts, included_h5_paths, should_restore_native_column_types=True, )\n",
    "\n",
    "# target_dir: Path = Path(global_data_root_parent_path)\n",
    "target_dir: Path = collected_outputs_path\n",
    "assert target_dir.exists(), f'target_dir: \"{target_dir}\" does not exist!'\n",
    "(neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table), output_path_dicts = AcrossSessionTables.build_and_save_all_combined_tables(included_session_contexts, included_h5_paths, override_output_parent_path=target_dir, output_path_suffix=f'{BATCH_DATE_TO_USE}')\n",
    "curr_collected_outputs_folder = Path(output_path_dicts['neuron_replay_stats_table']['.csv']).resolve().parent\n",
    "filesystem_path_folder_contents_widget(curr_collected_outputs_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_replay_stats_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "source": [
    "# 2024-06-12 11:18: - [ ] HACK: reads back in the exported `neuron_replay_stats_table` CSV to fix an issue with pd.NA and np.nan not reading a NaNs and the dtypes of the columns being messed up on load:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_curr_read_path = output_path_dicts['neuron_replay_stats_table']['.csv']\n",
    "# _curr_read_path = Path('/Users/pho/University of Michigan Dropbox/MED-DibaLabDropbox/Data/Pho/Outputs/output/collected_outputs/2024-06-12_Apogee/neuron_replay_stats_table.csv').resolve()\n",
    "neuron_replay_stats_table: pd.DataFrame = pd.read_csv(_curr_read_path, na_values=['', 'nan', 'np.nan','<NA>'],\n",
    "\t\t\t\t\t\t\t\t\t\tdtype={\n",
    "\t\t\t\t\t\t\t\t\t\t\t'long_pf_peak_x': 'float64', \n",
    "\t\t\t\t\t\t\t\t\t\t\t'short_pf_peak_x': 'float64',\n",
    "\t\t\t\t\t\t\t\t\t\t\t'long_LR_pf2D_peak_x': 'float64',\n",
    "\t\t\t\t\t\t\t\t\t\t\t'long_LR_pf2D_peak_y': 'float64',\n",
    "\t\t\t\t\t\t\t\t\t\t\t'long_RL_pf2D_peak_x': 'float64',\n",
    "\t\t\t\t\t\t\t\t\t\t\t'long_RL_pf2D_peak_y': 'float64',\n",
    "\t\t\t\t\t\t\t\t\t\t\t'short_LR_pf2D_peak_x': 'float64',\n",
    "\t\t\t\t\t\t\t\t\t\t\t'short_LR_pf2D_peak_y': 'float64',\n",
    "\t\t\t\t\t\t\t\t\t\t\t'short_RL_pf2D_peak_x': 'float64',\n",
    "\t\t\t\t\t\t\t\t\t\t\t'short_RL_pf2D_peak_y': 'float64',\n",
    "\t\t\t\t\t\t\t\t\t\t\t'long_LR_pf1D_peak': 'float64',\n",
    "\t\t\t\t\t\t\t\t\t\t\t'long_RL_pf1D_peak': 'float64',\n",
    "\t\t\t\t\t\t\t\t\t\t\t'short_LR_pf1D_peak': 'float64',\n",
    "\t\t\t\t\t\t\t\t\t\t\t'short_RL_pf1D_peak': 'float64',\n",
    "\t\t\t\t\t\t\t\t\t\t\t'peak_diff_RL_pf1D_peak': 'float64',\n",
    "\t\t\t\t\t\t\t\t\t\t\t'peak_diff_LR_pf1D_peak': 'float64'\n",
    "\t\t\t\t\t\t\t\t\t\t}, index_col='neuron_uid')\n",
    "neuron_replay_stats_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import TruncationCheckingResults\n",
    "\n",
    "# truncation_checking_aclus_dict, jonathan_firing_rate_analysis_result.neuron_replay_stats_df = truncation_checking_result.build_truncation_checking_aclus_dict(neuron_replay_stats_df=jonathan_firing_rate_analysis_result.neuron_replay_stats_df)\n",
    "\n",
    "# 'is_rate_extrema', 'is_refined_exclusive', 'is_refined_LxC', 'is_refined_SxC'\n",
    "# 'is_long_peak_left_cap', 'is_long_peak_right_cap', 'is_long_peak_either_cap'\n",
    "\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _add_cell_remapping_category\n",
    "\n",
    "neuron_replay_stats_df = deepcopy(neuron_replay_stats_table)\n",
    "\n",
    "neuron_replay_stats_df, (non_disappearing_endcap_cells_df, disappearing_endcap_cells_df, minorly_changed_endcap_cells_df, significant_distant_remapping_endcap_cells_df) = _add_cell_remapping_category(neuron_replay_stats_df=neuron_replay_stats_df,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t   loaded_track_limits = {'long_xlim': np.array([59.0774, 228.69]), 'short_xlim': np.array([94.0156, 193.757]), 'long_ylim': np.array([138.164, 146.12]), 'short_ylim': np.array([138.021, 146.263])},\n",
    ")\n",
    "# neuron_replay_stats_df\n",
    "significant_distant_remapping_endcap_cells_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non_disappearing_endcap_cells_df\n",
    "significant_distant_remapping_endcap_cells_df\n",
    "# 'track_membership'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required for Interactive Plotting and figure displace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_replay_stats_table.index.unique() #['neuron_uid'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f99ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsVisualizations\n",
    "\n",
    "matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "num_sessions: int = 13\n",
    "graphics_output_dict = AcrossSessionsVisualizations.across_sessions_firing_rate_index_figure(long_short_fr_indicies_analysis_results=long_short_fr_indicies_analysis_table, num_sessions=num_sessions, save_figure=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadc1ac7-5771-4cd5-94c6-7a6244eb8217",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": []
   },
   "source": [
    "## Extract output files from all completed sessions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be651cc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2023-10-04 - Load Saved across-sessions-data, process, and produce figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ad5bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsResults, AcrossSessionsVisualizations\n",
    "\n",
    "# 'collected_outputs/across_session_result_long_short_recomputed_inst_firing_rate_2024-06-11_GL.pkl'\n",
    "across_session_result_long_short_recomputed_inst_firing_rate_file = collected_outputs_path.joinpath('across_session_result_long_short_recomputed_inst_firing_rate_2024-06-11_GL.pkl').resolve()\n",
    "across_session_result_long_short_recomputed_inst_firing_rate_file.exists()\n",
    "\n",
    "'across_session_result_long_short_inst_firing_rate_2024-06-11_GL.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When done, `result_handler.across_sessions_instantaneous_fr_dict` is now equivalent to what it would have been before. It can be saved using the normal `.save_across_sessions_data(...)`\n",
    "\n",
    "## INPUTS: BATCH_DATE_TO_USE, BATCH_DATE_TO_USE\n",
    "print(f\"BATCH_DATE_TO_USE: {BATCH_DATE_TO_USE}\")\n",
    "## Save the instantaneous firing rate results dict: (# Dict[IdentifyingContext] = InstantaneousSpikeRateGroupsComputation)\n",
    "# AcrossSessionsResults.save_across_sessions_data(across_sessions_instantaneous_fr_dict=across_sessions_instantaneous_fr_dict, global_data_root_parent_path=global_data_root_parent_path,\n",
    "#                                                  inst_fr_output_filename=f'across_session_result_long_short_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl')\n",
    "\n",
    "across_session_result_long_short_recomputed_inst_firing_rate_filename: str = f'across_session_result_long_short_recomputed_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl'\n",
    "# \"/nfs/turbo/umms-kdiba/Pho/Output/collected_outputs/across_session_result_long_short_recomputed_inst_firing_rate_2024-10-22_GL.pkl\"\n",
    "\n",
    "# AcrossSessionsResults.save_across_sessions_data(across_sessions_instantaneous_fr_dict=across_sessions_recomputed_instantaneous_fr_dict, global_data_root_parent_path=global_data_root_parent_path,\n",
    "#                                                  inst_fr_output_filename=across_session_result_long_short_recomputed_inst_firing_rate_filename)\n",
    "\n",
    "AcrossSessionsResults.save_across_sessions_data(across_sessions_instantaneous_fr_dict=across_sessions_recomputed_instantaneous_fr_dict, global_data_root_parent_path=collected_outputs_path.resolve(),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t inst_fr_output_filename=across_session_result_long_short_recomputed_inst_firing_rate_filename)\n",
    "\n",
    "\n",
    "# \"/nfs/turbo/umms-kdiba/Data/Output/collected_outputs/across_session_result_long_short_recomputed_inst_firing_rate_2024-09-26_GL.pkl\"\n",
    "\n",
    "# '/nfs/turbo/umms-kdiba/Data/across_session_result_long_short_recomputed_inst_firing_rate_2024-06-10_GL.pkl'\n",
    "# Path('/nfs/turbo/umms-kdiba/Data/Output/collected_outputs/across_session_result_long_short_recomputed_inst_firing_rate_2024-06-11_GL.pkl').resolve()\n",
    "# ## Save pickle:\n",
    "# inst_fr_output_filename=f'across_session_result_long_short_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl'\n",
    "# global_batch_result_inst_fr_file_path = Path(global_data_root_parent_path).joinpath(inst_fr_output_filename).resolve() # Use Default\n",
    "# print(f'global_batch_result_inst_fr_file_path: {global_batch_result_inst_fr_file_path}')\n",
    "# # Save the all sessions instantaneous firing rate dict to the path:\n",
    "# saveData(global_batch_result_inst_fr_file_path, across_sessions_instantaneous_fr_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_path_suffix: str = '2024-09-11_GL'\n",
    "# output_path_suffix: str = '2024-09-26_GL'\n",
    "output_path_suffix: str = BATCH_DATE_TO_USE\n",
    "# graphics_output_dict = AcrossSessionsResults.post_compute_all_sessions_processing(global_data_root_parent_path=global_data_root_parent_path, BATCH_DATE_TO_USE=BATCH_DATE_TO_USE, plotting_enabled=True)\n",
    "graphics_output_dict = AcrossSessionsResults.post_compute_all_sessions_processing(global_data_root_parent_path=collected_outputs_path, output_path_suffix=output_path_suffix, plotting_enabled=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PendingNotebookCode import build_and_merge_all_sessions_joined_neruon_fri_df\n",
    "\n",
    "all_sessions_joined_neruon_fri_df, out_path = build_and_merge_all_sessions_joined_neruon_fri_df(global_data_root_parent_path, BATCH_DATE_TO_USE, included_session_contexts=included_session_contexts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.user_annotations import UserAnnotationsManager, SessionCellExclusivityRecord\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "\n",
    "annotation_man = UserAnnotationsManager()\n",
    "\n",
    "LxC_uids = []\n",
    "SxC_uids = []\n",
    "\n",
    "for a_ctxt in included_session_contexts:\n",
    "\tsession_uid = a_ctxt.get_description(separator=\"|\", include_property_names=False)\n",
    "\tsession_uid\n",
    "\tsession_cell_exclusivity: SessionCellExclusivityRecord = annotation_man.annotations[a_ctxt].get('session_cell_exclusivity', None)\n",
    "\tLxC_uids.extend([f\"{session_uid}|{aclu}\" for aclu in session_cell_exclusivity.LxC])\n",
    "\tSxC_uids.extend([f\"{session_uid}|{aclu}\" for aclu in session_cell_exclusivity.SxC])\n",
    "\t\n",
    "# [a_ctxt.get_description(separator=\"|\", include_property_names=False) for a_ctxt in included_session_contexts]\n",
    "\n",
    "long_short_fr_indicies_analysis_table['XxC_status'] = 'Shared'\n",
    "long_short_fr_indicies_analysis_table.loc[np.isin(long_short_fr_indicies_analysis_table.neuron_uid, LxC_uids), 'XxC_status'] = 'LxC'\n",
    "long_short_fr_indicies_analysis_table.loc[np.isin(long_short_fr_indicies_analysis_table.neuron_uid, SxC_uids), 'XxC_status'] = 'SxC'\n",
    "\n",
    "long_short_fr_indicies_analysis_table\n",
    "## 2023-10-11 - Get the long peak location\n",
    "\n",
    "long_short_fr_indicies_analysis_table['long_pf_peak_x'] = neuron_replay_stats_table['long_pf_peak_x']\n",
    "long_short_fr_indicies_analysis_table\n",
    "\n",
    "## SAVE:\n",
    "# long_short_fr_indicies_analysis_table_filename = 'output/2023-10-07_long_short_fr_indicies_analysis_table.csv'\n",
    "long_short_fr_indicies_analysis_table_filename: str = f'output/{BATCH_DATE_TO_USE}_long_short_fr_indicies_analysis_table.csv'\n",
    "long_short_fr_indicies_analysis_table.to_csv(long_short_fr_indicies_analysis_table_filename)\n",
    "print(f'saved: {long_short_fr_indicies_analysis_table_filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the saved across-session results:\n",
    "# inst_fr_output_filename = 'long_short_inst_firing_rate_result_handlers_2023-07-12.pkl'\n",
    "# inst_fr_output_filename = 'across_session_result_long_short_inst_firing_rate.pkl'\n",
    "# inst_fr_output_filename='across_session_result_long_short_inst_firing_rate_2023-07-21.pkl'\n",
    "# inst_fr_output_filename=f'across_session_result_handler_{BATCH_DATE_TO_USE}.pkl'\n",
    "# inst_fr_output_filename='across_session_result_long_short_inst_firing_rate_2023-08-09_Test.pkl'\n",
    "# inst_fr_output_filename='across_session_result_long_short_inst_firing_rate_2023-10-04-GL.pkl'\n",
    "# inst_fr_output_filename='across_session_result_long_short_recomputed_inst_firing_rate_2023-10-04-GL-Recomp.pkl'\n",
    "# inst_fr_output_filename='across_session_result_long_short_recomputed_inst_firing_rate_2023-10-07.pkl'\n",
    "# inst_fr_output_filename: str = f'across_session_result_long_short_recomputed_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl'\n",
    "# inst_fr_output_load_filepath: Path = Path('/nfs/turbo/umms-kdiba/Data/Output/collected_outputs/across_session_result_long_short_recomputed_inst_firing_rate_2024-06-11_GL.pkl').resolve()\n",
    "# inst_fr_output_load_filepath: Path = collected_outputs_path.joinpath('across_session_result_long_short_recomputed_inst_firing_rate_2024-06-11_GL.pkl').resolve()\n",
    "inst_fr_output_load_filepath: Path = collected_outputs_path.joinpath('across_session_result_long_short_recomputed_inst_firing_rate_2024-09-26_GL.pkl').resolve()\n",
    "\n",
    "# \"/nfs/turbo/umms-kdiba/Data/Output/collected_outputs/across_session_result_long_short_recomputed_inst_firing_rate_2024-09-26_GL.pkl\"\n",
    "assert inst_fr_output_load_filepath.exists()\n",
    "inst_fr_output_filename: str = inst_fr_output_load_filepath.name\n",
    "# across_session_inst_fr_computation, across_sessions_instantaneous_fr_dict, across_sessions_instantaneous_frs_list = AcrossSessionsResults.load_across_sessions_data(global_data_root_parent_path=global_data_root_parent_path, inst_fr_output_filename=inst_fr_output_filename)\n",
    "across_session_inst_fr_computation, across_sessions_instantaneous_fr_dict, across_sessions_instantaneous_frs_list = AcrossSessionsResults.load_across_sessions_data(global_data_root_parent_path=inst_fr_output_load_filepath.parent, inst_fr_output_filename=inst_fr_output_filename)\n",
    "# across_sessions_instantaneous_fr_dict = loadData(global_batch_result_inst_fr_file_path)\n",
    "num_sessions = len(across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionTables\n",
    " \n",
    "## Load all across-session tables from the pickles:\n",
    "# output_path_suffix: str = f'2023-10-07'\n",
    "# output_path_suffix: str = f'{BATCH_DATE_TO_USE}'\n",
    "# output_path_suffix: str = '2024-06-12_GL'\n",
    "# output_path_suffix: str = '2024-09-03_GL'\n",
    "output_path_suffix: str = '2024-09-26_GL'\n",
    "# neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table = AcrossSessionTables.load_all_combined_tables(override_output_parent_path=global_data_root_parent_path, output_path_suffix=output_path_suffix) # output_path_suffix=f'2023-10-04-GL-Recomp'\n",
    "neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table = AcrossSessionTables.load_all_combined_tables(override_output_parent_path=collected_outputs_path, output_path_suffix=output_path_suffix)\n",
    "num_sessions = len(neuron_replay_stats_table.session_uid.unique().to_numpy())\n",
    "print(f'num_sessions: {num_sessions}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d829b90",
   "metadata": {},
   "source": [
    "### 2023-11-15 - For manual testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf78cacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Load the saved across-session results:\n",
    "# Outputs: across_session_inst_fr_computation, across_sessions_instantaneous_fr_dict, across_sessions_instantaneous_frs_list, neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table\n",
    "\n",
    "inst_fr_output_filename: str = f'across_session_result_long_short_recomputed_inst_firing_rate_{BATCH_DATE_TO_USE}.pkl'\n",
    "across_session_inst_fr_computation, across_sessions_instantaneous_fr_dict, across_sessions_instantaneous_frs_list = AcrossSessionsResults.load_across_sessions_data(global_data_root_parent_path=global_data_root_parent_path, inst_fr_output_filename=inst_fr_output_filename)\n",
    "# across_sessions_instantaneous_fr_dict = loadData(global_batch_result_inst_fr_file_path)\n",
    "num_sessions = len(across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionTables\n",
    "\n",
    "## Load all across-session tables from the pickles:\n",
    "output_path_suffix: str = f'{BATCH_DATE_TO_USE}'\n",
    "neuron_identities_table, long_short_fr_indicies_analysis_table, neuron_replay_stats_table = AcrossSessionTables.load_all_combined_tables(override_output_parent_path=global_data_root_parent_path, output_path_suffix=output_path_suffix) # output_path_suffix=f'2023-10-04-GL-Recomp'\n",
    "num_sessions = len(neuron_replay_stats_table.session_uid.unique().to_numpy())\n",
    "print(f'num_sessions: {num_sessions}')\n",
    "# neuron_replay_stats_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "across_sessions_instantaneous_frs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2024-06-11 - Across Session Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "long_short_fr_indicies_analysis_table.plot.scatter(x='long_pf_peak_x', y='x_frs_index', title='Pf Peak position vs. LapsFRI', ylabel='Lap FRI')\n",
    "long_short_fr_indicies_analysis_table.plot.scatter(x='long_pf_peak_x', y='y_frs_index', title='Pf Peak position vs. ReplayFRI', ylabel='Replay FRI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2023-10-10 - Statistics for `across_sessions_bar_graphs`, analysing `across_session_inst_fr_computation` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import pho_stats_perform_diagonal_line_binomial_test, pho_stats_bar_graph_t_tests\n",
    "\n",
    "binom_test_chance_result = pho_stats_perform_diagonal_line_binomial_test(long_short_fr_indicies_analysis_table)\n",
    "print(f'binom_test_chance_result: {binom_test_chance_result}')\n",
    "\n",
    "LxC_Laps_T_result, SxC_Laps_T_result, LxC_Replay_T_result, SxC_Replay_T_result = pho_stats_bar_graph_t_tests(across_session_inst_fr_computation)\n",
    "\n",
    "# n_total: 823, n_above_diagonal: 457, n_exact_on_diagonal: 0, n_below_diagonal: 366\n",
    "# binom_test_chance_result: BinomTestResult(k=457, n=823, alternative='two-sided', statistic=0.5552855407047388, pvalue=0.0016893424059938723)\n",
    "# LxC_Laps_T_result: TtestResult(statistic=12.249237714915296, pvalue=3.8446809431691085e-08, df=12)\n",
    "# SxC_Laps_T_result: TtestResult(statistic=-12.413163641851535, pvalue=5.768107640498047e-07, df=9)\n",
    "# LxC_Replay_T_result: TtestResult(statistic=-0.7636543941504783, pvalue=0.4598247399068105, df=12)\n",
    "# SxC_Replay_T_result: TtestResult(statistic=-3.069767144140489, pvalue=0.01335902191105584, df=9)\n",
    "\n",
    "# n_total: 823, n_above_diagonal: 457, n_exact_on_diagonal: 0, n_below_diagonal: 366\n",
    "# binom_test_chance_result: BinomTestResult(k=457, n=823, alternative='two-sided', statistic=0.5552855407047388, pvalue=0.0016893424059938723)\n",
    "# LxC_Laps_T_result: TtestResult(statistic=12.249237714915296, pvalue=3.8446809431691085e-08, df=12)\n",
    "# SxC_Laps_T_result: TtestResult(statistic=-12.413163641851535, pvalue=5.768107640498047e-07, df=9)\n",
    "# LxC_Replay_T_result: TtestResult(statistic=-0.7636543941504783, pvalue=0.4598247399068105, df=12)\n",
    "# SxC_Replay_T_result: TtestResult(statistic=-3.069767144140489, pvalue=0.01335902191105584, df=9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_print: bool = False\n",
    "enable_neptune: bool = True\n",
    "\n",
    "if enable_neptune:\n",
    "\timport neptune # for logging progress and results\n",
    "\tfrom neptune.types import File\n",
    "\tfrom pyphoplacecellanalysis.General.Batch.NeptuneAiHelpers import Neptuner, AutoValueConvertingNeptuneRun, set_environment_variables \n",
    "\n",
    "\t## Gets the notebook filepath for Neptune:\n",
    "\timport IPython\n",
    "\tfrom pyphocorehelpers.programming_helpers import IPythonHelpers\n",
    "\tnotebook_filepath: str = IPythonHelpers.try_find_notebook_filepath(IPython.extract_module_locals())\n",
    "\tassert Path(notebook_filepath).resolve().exists(), f\"found notebook filepath: '{notebook_filepath}' does not exist\"\n",
    "\n",
    "\t\n",
    "\t# notebook_filepath\n",
    "\n",
    "\t# '/home/halechr/repos/Spike3D/BatchInteractiveProcessing_2024-06-11_GL.ipynb'\n",
    "\n",
    "\tneptune_kwargs = {'project':\"commander.pho/PhoDibaLongShortAcrossSessions\",\n",
    "\t'api_token':\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIxOGIxODU2My1lZTNhLTQ2ZWMtOTkzNS02ZTRmNzM5YmNjNjIifQ==\"}\n",
    "\t\t\t\n",
    "\tneptuner = Neptuner(project_name=neptune_kwargs['project'], api_token=neptune_kwargs['api_token'])\n",
    "\n",
    "\n",
    "\tif neptuner.run is None:\n",
    "\t\t# neptuner.run = neptune.init_run(project=neptuner.project_name, api_token=neptuner.api_token, dependencies=\"infer\", source_files=[notebook_filepath]) # see git_ref=GitRef(repository_path=\"/path/to/repo\")\n",
    "\t\t# Add the session_context properties to the run: {'format_name': 'kdiba', 'animal': 'vvp01', 'exper_name': 'two', 'session_name': '2006-4-09_16-40-54'}\n",
    "\n",
    "\t\tneptuner.run = AutoValueConvertingNeptuneRun(project=neptuner.project_name, api_token=neptuner.api_token, dependencies=\"infer\", source_files=[notebook_filepath])\n",
    "\n",
    "\t\t# Create an AutoValueConvertingNeptuneRun and copy the attributes\n",
    "\t\t# neptuner.run = AutoValueConvertingNeptuneRun(base_run._client, base_run._uuid, base_run._url)\n",
    "\t\n",
    "\t\tparams = {'BATCH_DATE_TO_USE': BATCH_DATE_TO_USE, \"run_workstation\": \"GL\"}\n",
    "\t\tneptuner.run[\"parameters\"] = params\n",
    "\n",
    "\t\tneptuner.outputs = neptuner.run['outputs']\n",
    "\t\tneptuner.figures = neptuner.outputs['figures']\n",
    "\n",
    "\tneptuner_run = neptuner.run\n",
    "\t\n",
    "\t# run = neptune.init_run(source_files=[\"**/*.dvc\"])\n",
    "\n",
    "\t# # Pre-execution dataframe view:\n",
    "\t# run[\"dataset/global_batch_run_progress_df\"].upload(File.as_html(global_batch_run.to_dataframe(expand_context=True, good_only=False))) # \"path/to/test_preds.csv\"\n",
    "\n",
    "else:\n",
    "\t# no neptune:\n",
    "\tneptuner = None    \n",
    "\tneptuner_run = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_save_path, a_save_dict in registered_output_files.items():\n",
    "\ta_save_dict['fig']\n",
    "\ta_save_dict['context']\n",
    "\tneptuner.figures.upload(File(a_save_path.resolve().as_posix()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "neptuner_run[f'output_files/across_sessions_fig_2'] = _out_fig_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (neptuner is not None) and (neptuner_run is not None):\n",
    "\tneptuner.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KDiba Session Discovery - Determines contexts to process - 2024-09-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "# from neuropy.utils.result_context import print_identifying_context_array_code\n",
    "\n",
    "# known_global_data_root_parent_paths = [Path(r'/nfs/turbo/umms-kdiba/Data'), Path(r'W:\\Data'), Path(r'/home/halechr/cloud/turbo/Data'), Path(r'/media/halechr/MAX/Data'), Path(r'/Volumes/MoverNew/data')] # , Path(r'/home/halechr/FastData'), Path(r'/home/halechr/turbo/Data'), Path(r'W:\\Data'), Path(r'/home/halechr/cloud/turbo/Data')\n",
    "# global_data_root_parent_path = find_first_extant_path(known_global_data_root_parent_paths)\n",
    "# assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "sessions_df, export_folder_path = KDibaOldDataSessionFormatRegisteredClass.find_build_and_save_sessions_experiment_datetime_df_csv(\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# global_data_root_parent_path=global_data_root_parent_path,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\texport_csv_path=Path('EXTERNAL/PhoDibaPaper2024Book/data/sessions_experiment_datetime_df.csv').resolve(),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tbad_sessions_csv_path=Path('EXTERNAL/PhoDibaPaper2024Book/data/2024-09-23_bad_sessions_table.csv').resolve(),\n",
    ")\n",
    "sessions_df = sessions_df.reset_index(drop=True, inplace=False)\n",
    "sessions_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old_included_session_contexts = [\n",
    "#     IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15'), \n",
    "#     IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43'), \n",
    "#     IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31'), # \n",
    "#     IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19'), \n",
    "#     IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44'), #\n",
    "#     IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25'),\n",
    "#     # IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54'), #\n",
    "# ]\n",
    "\t\n",
    "# new_included_session_contexts = [\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_19-11-57'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_21-2-40'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-11_12-48-38'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-11_15-16-59'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-11_16-2-46'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-12_14-39-31'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-12_14-59-23'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-12_15-25-59'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-12_17-53-55'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-16_14-49-24'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-16_15-12-23'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-16_18-47-52'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-17_12-33-47'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-17_12-52-15'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-18_13-6-1'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-18_13-28-57'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-18_15-23-32'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-18_15-38-2'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-19_13-34-40'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-19_13-50-7'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-19_16-37-40'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-19_16-48-9'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-21_10-24-35'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-21_11-19-2'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-25_13-20-55'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-25_14-28-51'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-25_17-17-6'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-25_17-33-28'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-26_13-22-13'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-26_13-51-50'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-27_14-43-12'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-27_18-21-57'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-28_12-17-27'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-28_12-38-13'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-28_16-48-29'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-28_17-6-14'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-07_11-26-53'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_15-46-47'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_3-23-37'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-13_14-42-6'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-13_15-22-3'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-03_11-0-53'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-03_20-28-3'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_21-26-8'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-04_21-20-3'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-05_19-26-43'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_11-43-50'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_12-15-3'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_21-17-16'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_22-4-5'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-19_12-35-59'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-19_13-2-0'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-19_13-55-7'),\n",
    "# ]\n",
    "\n",
    "# completely_new_included_session_contexts = [\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-25_14-28-51'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-28_16-48-29'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-18_13-28-57'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_19-11-57'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-26_13-22-13'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_3-23-37'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-25_17-33-28'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-28_17-6-14'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-03_11-0-53'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-18_13-6-1'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_11-43-50'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-27_18-21-57'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_21-17-16'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-19_13-34-40'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-27_14-43-12'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-19_13-50-7'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-25_13-20-55'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-21_10-24-35'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-12_17-53-55'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_22-4-5'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-17_12-52-15'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-19_16-37-40'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-11_15-16-59'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-19_16-48-9'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-19_13-2-0'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-16_18-47-52'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-19_13-55-7'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-28_12-38-13'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-12_14-59-23'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-21_11-19-2'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_12-15-3'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_21-2-40'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-12_14-39-31'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-25_17-17-6'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_15-46-47'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-11_16-2-46'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-18_15-38-2'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-13_15-22-3'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-05_19-26-43'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-17_12-33-47'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-12_15-25-59'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_21-26-8'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-16_14-49-24'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-11_12-48-38'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-28_12-17-27'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-13_14-42-6'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-16_15-12-23'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-07_11-26-53'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-26_13-51-50'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-04_21-20-3'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-19_12-35-59'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-18_15-23-32'),\n",
    "#     IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-03_20-28-3'),\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completely_new_included_session_contexts = set(new_included_session_contexts) - set(old_included_session_contexts)\n",
    "print_identifying_context_array_code(completely_new_included_session_contexts, array_name='completely_new_included_session_contexts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing programmatic .py to .ipynb conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.notebook_helpers import convert_script_to_notebook\n",
    "\n",
    "# Usage:\n",
    "script_path = Path(r\"K:\\scratch\\gen_scripts\\run_kdiba_gor01_one_2006-6-12_15-55-31\\run_kdiba_gor01_one_2006-6-12_15-55-31.py\").resolve()\n",
    "script_dir = script_path.parent.resolve()\n",
    "notebook_path = script_path.with_suffix('.ipynb')\n",
    "convert_script_to_notebook(script_path, notebook_path)\n",
    "# convert_script_to_notebook(script_path, notebook_path, custom_delimiter=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old File Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import OldFileArchiver\n",
    "\n",
    "\n",
    "# deleted_file_list = OldFileArchiver.remove_backup_files_from_session_data_folders(good_session_concrete_folders=all_known_session_concrete_folders, is_dryrun=True)\n",
    "always_delete_patterns = {\n",
    "\t'.pkltmp': '*.pkltmp',\n",
    "\t'.pkl.bak': '*.pkl.bak',\n",
    "}\n",
    "# always_delete_patterns = {} # disable non-conditional deletes while the pipeline is running in batch\n",
    "\n",
    "# Define patterns to conditionally delete\n",
    "conditional_delete_patterns = {\n",
    "\t# '.pkl': '*.pkl',\n",
    "\t'pipeline.pkl': '*loadedSessPickle*.pkl',\n",
    "\t'global.pkl': '*global_computation_results*.pkl',\n",
    "}\n",
    "\n",
    "# Define the cutoff date\n",
    "# cutoff = datetime(2023, 9, 1)  # Example cutoff date\n",
    "# cutoff = datetime(2024, 9, 1)\n",
    "cutoff = datetime(2025, 2, 20)\n",
    "# deleted_file_list = OldFileArchiver.remove_backup_files_from_session_data_folders(good_session_concrete_folders=all_known_session_concrete_folders, cutoff_date=cutoff, is_dryrun=True)\n",
    "deleted_file_list = OldFileArchiver.remove_backup_files_from_session_data_folders(good_session_concrete_folders=all_known_session_concrete_folders,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  always_delete_patterns=always_delete_patterns,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  conditional_delete_patterns=conditional_delete_patterns,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   cutoff_date=cutoff, is_dryrun=False)\n",
    "deleted_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import OldFileArchiver\n",
    "\n",
    "## INPUTS: collected_outputs_directory, excluded_or_outdated_files_list\n",
    "archive_folder = OldFileArchiver.archive_old_files(collected_outputs_directory=collected_outputs_directory, excluded_or_outdated_files_list=excluded_or_outdated_files_list, is_dry_run=True)\n",
    "\n",
    "archive_folder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
