{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0056bc66-7629-4ef7-8c87-f28f8fcd9dc8",
   "metadata": {
    "autorun": true,
    "tags": [
     "imports",
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "build_module_logger(module_name=\"Spike3D.pipeline\"):\n",
      "\t Module logger com.PhoHale.Spike3D.pipeline has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.Spike3D.pipeline.log\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "# %load_ext viztracer\n",
    "# from viztracer import VizTracer\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import neptune # for logging progress and results\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveWrapper import neptune_output_figures\n",
    "neptune_kwargs = {'project':\"commander.pho/PhoDibaLongShort2023\",\n",
    "'api_token':\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIxOGIxODU2My1lZTNhLTQ2ZWMtOTkzNS02ZTRmNzM5YmNjNjIifQ==\"}\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "from copy import deepcopy\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pho's Formatting Preferences\n",
    "# from pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\n",
    "# set_pho_preferences_concise()\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.general_helpers import CodeConversion\n",
    "from pyphocorehelpers.function_helpers import function_attributes\n",
    "from pyphocorehelpers.print_helpers import print_keys_if_possible, print_value_overview_only, document_active_variables, objsize, print_object_memory_usage, debug_dump_object_member_shapes, TypePrintMode\n",
    "from pyphocorehelpers.print_helpers import get_now_day_str, get_now_time_str, get_now_time_precise_str\n",
    "from pyphocorehelpers.programming_helpers import IPythonHelpers\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "# from neuropy import core\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.core.epoch import NamedTimerange, Epoch\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.BapunDataSessionFormat import BapunDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.RachelDataSessionFormat import RachelDataSessionFormat\n",
    "from neuropy.core.session.Formats.Specific.HiroDataSessionFormat import HiroDataSessionFormatRegisteredClass\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "from neuropy.core.neurons import NeuronType\n",
    "\n",
    "\n",
    "from pyphocorehelpers.print_helpers import generate_html_string\n",
    "\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot, create_daily_programmatic_display_function_testing_folder_if_needed, session_context_to_relative_path\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveWrapper import batch_load_session, batch_extended_computations, SessionBatchProgress, batch_programmatic_figures, batch_extended_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.Extensions.pyqtgraph_helpers import build_pyqtgraph_epoch_indicator_regions # Add session indicators to pyqtgraph plot\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import _helper_add_long_short_session_indicator_regions\n",
    "\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "# 'time_bin_indices': valid_time_bin_indicies, 'posterior_to_pf_mean_surprise': one_left_out_posterior_to_pf_surprises_mean, 'posterior_to_scrambled_pf_mean_surprise': one_left_out_posterior_to_scrambled_pf_surprises_mean}\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import plot_long_short_expected_vs_observed_firing_rates\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import plot_long_short_surprise_difference_plot\n",
    "\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveWrapper import _update_pipeline_missing_preprocessing_parameters\n",
    "\n",
    "\n",
    "session_batch_status = {}\n",
    "session_batch_errors = {}\n",
    "enable_saving_to_disk = False\n",
    "\n",
    "global_data_root_parent_path = find_first_extant_path([Path(r'W:\\Data'), Path(r'/media/MAX/Data'), Path(r'/Volumes/MoverNew/data'), Path(r'/home/halechr/turbo/Data')])\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1538e2a-4e39-4d11-90b5-a9fef9258058",
   "metadata": {
    "tags": [
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "source": [
    "# Load Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f917bad9-8fe7-4882-b83b-71cf878fffd2",
   "metadata": {
    "tags": [
     "load",
     "REQUIRED"
    ]
   },
   "outputs": [],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Load Data                                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "active_data_mode_name = 'kdiba'\n",
    "\n",
    "## Data must be pre-processed using the MATLAB script located here: \n",
    "#     neuropy/data_session_pre_processing_scripts/KDIBA/IIDataMat_Export_ToPython_2022_08_01.m\n",
    "# From pre-computed .mat files:\n",
    "\n",
    "local_session_root_parent_context = IdentifyingContext(format_name=active_data_mode_name) # , animal_name='', configuration_name='one', session_name=self.session_name\n",
    "local_session_root_parent_path = global_data_root_parent_path.joinpath('KDIBA')\n",
    "\n",
    "good_contexts_list = [IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-13_15-22-3'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-17_12-33-47'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-18_13-6-1'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-18_15-23-32'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-19_13-34-40'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-27_14-43-12'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-11_12-48-38'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-11_16-2-46'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-12_15-25-59'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-16_14-49-24'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-16_18-47-52'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-17_12-52-15'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-19_13-50-7'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-25_13-20-55'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-26_13-51-50'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_21-26-8'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-05_19-26-43'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_21-17-16'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_22-4-5'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54'),\n",
    "    IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-04_21-20-3')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d13e68b4-03e0-4388-a35c-87a352a6e6b3",
   "metadata": {
    "scrolled": true,
    "tags": [
     "load",
     "single_session",
     "REQUIRED"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "basedir: /media/MAX/Data/KDIBA/gor01/two/2006-6-08_21-16-25\n",
      "Loading loaded session pickle file results : /media/MAX/Data/KDIBA/gor01/two/2006-6-08_21-16-25/loadedSessPickle.pkl... done.\n",
      "Loading pickled pipeline success: /media/MAX/Data/KDIBA/gor01/two/2006-6-08_21-16-25/loadedSessPickle.pkl.\n",
      "property already present in pickled version. No need to save.\n",
      "using provided computation_functions_name_whitelist: ['_perform_baseline_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_two_step_position_decoding_computation']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the blacklist/whitelist or computation function definitions change. Rework so that this is smarter.\n",
      "updating computation_results...\n",
      "done.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the blacklist/whitelist or computation function definitions change. Rework so that this is smarter.\n",
      "updating computation_results...\n",
      "done.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the blacklist/whitelist or computation function definitions change. Rework so that this is smarter.\n",
      "updating computation_results...\n",
      "done.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "Loading loaded session pickle file results : /media/MAX/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/global_computation_results.pkl... done.\n",
      "cannot load global results: [Errno 2] No such file or directory: '/media/MAX/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/global_computation_results.pkl'\n"
     ]
    }
   ],
   "source": [
    "%pdb off\n",
    "# %%viztracer\n",
    "# [*] - indicates bad or session with a problem\n",
    "# 0, 1, 2, 3, 4, 5, 6, 7, [8], [9], 10, 11, [12], 13\n",
    "curr_context = good_contexts_list[3] # select the session from all of the good sessions here.\n",
    "local_session_parent_path = local_session_root_parent_path.joinpath(curr_context.animal, curr_context.exper_name) # 'gor01', 'one' - probably not needed anymore\n",
    "basedir = local_session_parent_path.joinpath(curr_context.session_name).resolve()\n",
    "print(f'basedir: {str(basedir)}')\n",
    "\n",
    "# # Read if possible:\n",
    "saving_mode = PipelineSavingScheme.SKIP_SAVING\n",
    "force_reload = False\n",
    "\n",
    "# #Force write:\n",
    "# saving_mode = PipelineSavingScheme.TEMP_THEN_OVERWRITE\n",
    "# saving_mode = PipelineSavingScheme.OVERWRITE_IN_PLACE \n",
    "# force_reload = True\n",
    "\n",
    "    # ==================================================================================================================== #\n",
    "    # Load Pipeline                                                                                                        #\n",
    "    # ==================================================================================================================== #\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-full_session_LOO_decoding_analysis.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "# epoch_name_whitelist = ['maze']\n",
    "epoch_name_whitelist = None\n",
    "active_computation_functions_name_whitelist=[#'_perform_estimated_epochs_computation', \n",
    "                                            '_perform_baseline_placefield_computation',\n",
    "                                        # '_perform_time_dependent_placefield_computation',\n",
    "                                        '_perform_extended_statistics_computation',\n",
    "                                        '_perform_position_decoding_computation', \n",
    "                                        '_perform_firing_rate_trends_computation',\n",
    "                                        '_perform_pf_find_ratemap_peaks_computation',\n",
    "                                        # '_perform_time_dependent_pf_sequential_surprise_computation'\n",
    "                                        '_perform_two_step_position_decoding_computation',\n",
    "                                        # '_perform_recursive_latent_placefield_decoding'\n",
    "                                    ]\n",
    "# active_computation_functions_name_whitelist=['_perform_baseline_placefield_computation']\n",
    "\n",
    "curr_active_pipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_whitelist=epoch_name_whitelist,\n",
    "                                        computation_functions_name_whitelist=active_computation_functions_name_whitelist,\n",
    "                                        saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                        skip_extended_batch_computations=True, debug_print=False, fail_on_exception=True) # , active_pickle_filename = 'loadedSessPickle_withParameters.pkl'\n",
    "\n",
    "if not force_reload: # not just force_reload, needs to recompute whenever the computation fails.\n",
    "    try:\n",
    "        curr_active_pipeline.load_pickled_global_computation_results()\n",
    "    except Exception as e:\n",
    "        print(f'cannot load global results: {e}')\n",
    "\n",
    "# 6m 1.1s\n",
    "# 12m 15.6s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a29b890",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "were pipeline preprocessing parameters missing and updated?: False\n"
     ]
    }
   ],
   "source": [
    "## Post Compute Validate 2023-05-16:\n",
    "from scripts.run_BatchAnalysis import post_compute_validate\n",
    "\n",
    "post_compute_validate(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7f4bc79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included whitelist is specified: ['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n",
      "\t done.\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "\t done.\n",
      "long_short_decoding_analyses missing.\n",
      "\t Recomputing long_short_decoding_analyses...\n",
      "sane_midpoint_x: 120.5290979122065, hardcoded_track_midpoint_x: None, track_min_max_x: (15.182688599114876, 256.24088442352786)\n",
      "hardcoded_track_midpoint_x is None, falling back to sane_midpoint_x... 120.5290979122065\n",
      "desc_crossings_x: (20,), asc_crossings_x: (20,)\n",
      "setting new computation epochs because laps changed.\n",
      "using self.config.grid_bin_bounds_1D: (15.182688599114876, 256.24088442352786)\n",
      "using self.config.grid_bin_bounds: ((15.182688599114876, 256.24088442352786), (88.93029378232772, 160.71688030454493))\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11293,) should be less than time_window_edges: (13209,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11293,) should be less than time_window_edges: (13209,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11293,) should be less than time_window_edges: (13209,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11293,) should be less than time_window_edges: (13209,)!\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11293,) should be less than time_window_edges: (13209,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11293,) should be less than time_window_edges: (13209,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11293,) should be less than time_window_edges: (13209,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (11293,) should be less than time_window_edges: (13209,)!\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 35, n_all_epoch_timebins = 165)\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n",
      "(n_neurons = 35, n_all_epoch_timebins = 165)\n",
      "\t done.\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: ['jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'long_short_decoding_analyses']. Saving global results...\n",
      "global_computation_results_pickle_path: /media/MAX/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/global_computation_results.pkl\n",
      "Saving (file mode 'w+b') saved session pickle file results : /media/MAX/Data/KDIBA/gor01/two/2006-6-08_21-16-25/output/global_computation_results.pkl... done.\n"
     ]
    }
   ],
   "source": [
    "# 2023-01-* - Call extended computations to build `_display_short_long_firing_rate_index_comparison` figures:\n",
    "extended_computations_include_whitelist=['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses'] # do only specifiedl\n",
    "# extended_computations_include_whitelist=['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis'] # do only specifiedl\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_whitelist=extended_computations_include_whitelist, include_global_functions=True, fail_on_exception=True, progress_print=True, force_recompute=True, debug_print=False)\n",
    "if len(newly_computed_values) > 0:\n",
    "\tprint(f'newly_computed_values: {newly_computed_values}. Saving global results...')\n",
    "\ttry:\n",
    "\t\t# Try to write out the global computation function results:\n",
    "\t\tcurr_active_pipeline.save_global_computation_results()\n",
    "\texcept Exception as e:\n",
    "\t\tprint(f'!!WARNING!!: saving the global results threw the exception: {e}')\n",
    "\t\tprint(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!')\n",
    "else:\n",
    "\tprint(f'no changes in global results.')\n",
    "# 10m 29.5s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6e13d31",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Pipeline Loading/Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba28d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea: versioning pickles with date?\n",
    "from datetime import datetime\n",
    "\n",
    "# datetime object containing current date and time\n",
    "save_time = datetime.now()\n",
    " \n",
    "print(\"save_time =\", save_time)\n",
    "\n",
    "# dd/mm/YY H:M:S\n",
    "dt_string = save_time.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "print(\"date and time =\", dt_string)\n",
    "\n",
    "# save_time = date"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c17a70f",
   "metadata": {},
   "source": [
    "#### 2023-05-26 - On only updating/appending the pickle file instead of having to re-write the whole 30GB+ thing\n",
    "The pickle file format is a sequential format. Thus, if you change one item, at least everything behind that position in the file has to be rewritten.\n",
    "\n",
    "Also see: https://docs.python.org/3.6/library/shelve.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98d64a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "\n",
    "from pyphocorehelpers.print_helpers import DocumentationFilePrinter, print_filesystem_file_size, print_object_memory_usage, print_keys_if_possible, debug_dump_object_member_shapes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735a9f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_object_memory_usage(curr_active_pipeline)\n",
    "# print_keys_if_possible(\"curr_active_pipeline._stage\", curr_active_pipeline._stage, max_depth=1, non_expanded_item_keys=['display_output'], additional_excluded_item_classes=['DynamicParameters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944d3fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_printer = DocumentationFilePrinter(doc_output_parent_folder=Path('/home/halechr/repo/Spike3D/EXTERNAL/DEVELOPER_NOTES/DataStructureDocumentation'), doc_name='NeuropyPipeline')\n",
    "doc_printer.save_documentation('NeuropyPipeline', curr_active_pipeline, non_expanded_item_keys=['stage','_reverse_cellID_index_map', 'pf_listed_colormap', 'computation_results', 'active_configs', 'logger', 'plot', '_plot_object', 'display_output'],\n",
    "                               additional_excluded_item_classes=[\"<class 'pyphoplacecellanalysis.General.Pipeline.Stages.Display.Plot'>\"], max_depth=16) # 'Logger'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ec5043",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE) # AttributeError: 'PfND_TimeDependent' object has no attribute '_included_thresh_neurons_indx'\n",
    "# TypeError: cannot pickle 'MplMultiTab' object\n",
    "# PicklingError: Can't pickle .set_closure_cell at 0x000002BF248F50D0>: it's not found as attr._compat.make_set_closure_cell..set_closure_cell\n",
    "# TypeError: cannot pickle 'PyQt5.QtCore.pyqtSignal' object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2bd0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_global_computation_results() # PicklingError: Can't pickle .set_closure_cell at 0x000002BF248F50D0>: it's not found as attr._compat.make_set_closure_cell..set_closure_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e894282",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.load_pickled_global_computation_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6274bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "curr_active_pipeline.display_output_history_list\n",
    "curr_active_pipeline.display_output.clear()\n",
    "# curr_active_pipeline.display_output = DynamicParameters()\n",
    "# curr_active_pipeline.display_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ae79e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.clear_display_outputs()\n",
    "curr_active_pipeline.clear_registered_output_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae39cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.OVERWRITE_IN_PLACE)\n",
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326d35c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "long_pf2D, short_pf2D, global_pf2D = long_results.pf2D, short_results.pf2D, global_results.pf2D\n",
    "\n",
    "# Get existing laps from session:\n",
    "long_laps, short_laps, global_laps = [curr_active_pipeline.filtered_sessions[an_epoch_name].laps.as_epoch_obj() for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_replays, short_replays, global_replays = [Epoch(curr_active_pipeline.filtered_sessions[an_epoch_name].replay.epochs.get_valid_df()) for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "# short_laps.n_epochs: 40, long_laps.n_epochs: 40\n",
    "# short_replays.n_epochs: 6, long_replays.n_epochs: 8\n",
    "\n",
    "print(f'short_laps.n_epochs: {short_laps.n_epochs}, long_laps.n_epochs: {long_laps.n_epochs}')\n",
    "print(f'short_replays.n_epochs: {short_replays.n_epochs}, long_replays.n_epochs: {long_replays.n_epochs}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c850782f",
   "metadata": {},
   "source": [
    "# End Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dda48261",
   "metadata": {
    "tags": [
     "load",
     "ACTIVE"
    ]
   },
   "outputs": [],
   "source": [
    "## long_short_decoding_analyses:\n",
    "curr_long_short_decoding_analyses = curr_active_pipeline.global_computation_results.computed_data['long_short_leave_one_out_decoding_analysis']\n",
    "## Extract variables from results object:\n",
    "long_one_step_decoder_1D, short_one_step_decoder_1D, long_replays, short_replays, global_replays, long_shared_aclus_only_decoder, short_shared_aclus_only_decoder, shared_aclus, long_short_pf_neurons_diff, n_neurons, long_results_obj, short_results_obj, is_global = curr_long_short_decoding_analyses.long_decoder, curr_long_short_decoding_analyses.short_decoder, curr_long_short_decoding_analyses.long_replays, curr_long_short_decoding_analyses.short_replays, curr_long_short_decoding_analyses.global_replays, curr_long_short_decoding_analyses.long_shared_aclus_only_decoder, curr_long_short_decoding_analyses.short_shared_aclus_only_decoder, curr_long_short_decoding_analyses.shared_aclus, curr_long_short_decoding_analyses.long_short_pf_neurons_diff, curr_long_short_decoding_analyses.n_neurons, curr_long_short_decoding_analyses.long_results_obj, curr_long_short_decoding_analyses.short_results_obj, curr_long_short_decoding_analyses.is_global\n",
    "\n",
    "# (long_one_step_decoder_1D, short_one_step_decoder_1D), (long_one_step_decoder_2D, short_one_step_decoder_2D) = compute_short_long_constrained_decoders(curr_active_pipeline, recalculate_anyway=True)\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_epoch_context, short_epoch_context, global_epoch_context = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_epoch_name, short_epoch_name, global_epoch_name)]\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "long_pf2D, short_pf2D, global_pf2D = long_results.pf2D, short_results.pf2D, global_results.pf2D\n",
    "decoding_time_bin_size = long_one_step_decoder_1D.time_bin_size # 1.0/30.0 # 0.03333333333333333"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35dbb4d2-0e85-45b8-8794-34d1bea96c0d",
   "metadata": {},
   "source": [
    "# Display Functions Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e308ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "batch_extended_programmatic_figures(curr_active_pipeline=curr_active_pipeline)\n",
    "# \n",
    "\n",
    "\n",
    "_out = curr_active_pipeline.display('_display_long_short_laps', curr_active_pipeline.sess.get_context())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee06cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "neptune_output_figures(curr_active_pipeline=curr_active_pipeline)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1245ff74-29c9-4410-9b31-99203502bdf6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# `attrs` object shape specifications, updating `LeaveOneOutDecodingAnalysisResult`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047dd77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attrs import fields, fields_dict, asdict\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import LeaveOneOutDecodingAnalysisResult, TimebinnedNeuronActivity, LeaveOneOutDecodingResult\n",
    "\n",
    "LeaveOneOutDecodingAnalysisResult.__annotations__\n",
    "\n",
    "\n",
    "type(long_results_obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba31db6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# fields(C).x.metadata\n",
    "\n",
    "# fields(C).x.metadata\n",
    "\n",
    "def _filter_obj_attribute(an_attr, attr_value):\n",
    "\t\"\"\" return attributes only if they have n_neurons in their shape metadata \"\"\"\n",
    "\treturn ('n_neurons' in an_attr.metadata.get('shape', ()))\n",
    "\n",
    "# Find all fields that contain a 'n_neurons':\n",
    "neuron_indexed_attributes = [a_field for a_field in fields(type(long_results_obj)) if ('n_neurons' in a_field.metadata.get('shape', ()))]\n",
    "# neuron_shape_index_for_attributes = [a_field.metadata['shape'].index('n_neurons') for a_field in neuron_indexed_attributes]\n",
    "neuron_shape_index_for_attribute_name_dict = {a_field.name:a_field.metadata['shape'].index('n_neurons') for a_field in neuron_indexed_attributes} # need the actual attributes so that we can get the .metadata['shape'] from them and find the n_neurons index location\n",
    "neuron_shape_index_for_attribute_name_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d674f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_specifying_fields = {a_field.name:a_field.metadata.get('shape', None) for a_field in fields(type(long_results_obj)) if a_field.metadata.get('shape', None) is not None}\n",
    "shape_specifying_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8784f28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_temp_obj_dict = asdict(long_results_obj, filter=_filter_obj_attribute)\n",
    "_temp_obj_dict = {k:v.take(indices=aclu_is_included, axis=neuron_shape_index_for_attribute_name_dict[k]) for k, v in _temp_obj_dict.items()} # filter the n_neurons axis containing items to get a reduced dictionary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def sliced_by_aclus(self, aclus):\n",
    "# \t\"\"\" returns a copy of itself sliced by the aclus provided. \"\"\"\n",
    "# \tfrom attrs import asdict, fields, evolve\n",
    "# \taclu_is_included = np.isin(self.original_1D_decoder.neuron_IDs, aclus)  #.shape # (104, 63)\n",
    "# \tdef _filter_obj_attribute(an_attr, attr_value):\n",
    "# \t\t\"\"\" return attributes only if they have n_neurons in their shape metadata \"\"\"\n",
    "# \t\treturn ('n_neurons' in an_attr.metadata.get('shape', ()))            \n",
    "# \t_temp_obj_dict = asdict(self, filter=_filter_obj_attribute)\n",
    "# \t# Find all fields that contain a 'n_neurons':\n",
    "# \tneuron_indexed_attributes = [a_field for a_field in fields(type(self)) if ('n_neurons' in a_field.metadata.get('shape', ()))]\n",
    "# \t# neuron_shape_index_for_attributes = [a_field.metadata['shape'].index('n_neurons') for a_field in neuron_indexed_attributes]\n",
    "# \tneuron_shape_index_for_attribute_name_dict = {a_field.name:a_field.metadata['shape'].index('n_neurons') for a_field in neuron_indexed_attributes} # need the actual attributes so that we can get the .metadata['shape'] from them and find the n_neurons index location\n",
    "# \t_temp_obj_dict = {k:v.take(indices=aclu_is_included, axis=neuron_shape_index_for_attribute_name_dict[k]) for k, v in _temp_obj_dict.items()} # filter the n_neurons axis containing items to get a reduced dictionary\n",
    "# \treturn evolve(self, **_temp_obj_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8c488a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_decoder_result.most_likely_position_indicies_list: list<np.ndarray<(1, epoch_num_time_bins[epoch_idx])>>[num_epochs]\n",
    "a_decoder_1D.num_neurons\n",
    "a_decoder_1D.flat_position_size\n",
    "# a_decoder_1D.original_position_data_shape\n",
    "\n",
    "# a_decoder_1D.F: (flat_position_size, num_neurons)\n",
    "\n",
    "\n",
    "## Decoder Result (DecodedFilterEpochsResult):\n",
    "a_decoder_result.num_filter_epochs\n",
    "\n",
    "\n",
    "# [a_decoder_1D.F[:,np.squeeze(curr_most_likely_position_indicies)] for curr_most_likely_position_indicies in a_decoder_result.most_likely_position_indicies_list] # [decoded_epoch_idx]\n",
    "[a_decoder_1D.F[np.squeeze(curr_most_likely_position_indicies),:] for curr_most_likely_position_indicies in a_decoder_result.most_likely_position_indicies_list] # [decoded_epoch_idx]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "844354b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2023-05-26 - Get Expected firing rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83a1c8d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Any\n",
    "from scipy.special import factorial, logsumexp\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from nptyping import NDArray, DataFrame, Shape, assert_isinstance, Int, Structure as S\n",
    "\n",
    "def compute_measured_vs_expected_firing_rates(active_pos_df, active_filter_epochs, a_decoder_1D: \"BasePositionDecoder\", a_decoder_result: \"DecodedFilterEpochsResult\"):\n",
    "\t\"\"\" 2023-05-26 - Goal is to compute the expected and measured firing rates for each cell for each epoch. \n",
    "\n",
    "\tWant to be able to get a vector of firing rates (one for each cell) for an epoch i.\n",
    "\n",
    "\t\"\"\"\n",
    "\tall_cells_decoded_epoch_time_bins = {}\n",
    "\tall_cells_decoded_expected_firing_rates = {}\n",
    "\t\n",
    "\t# all_cells_decoded_expected_firing_rates_arr: List[np.ndarray] = [a_decoder_1D.F[np.squeeze(curr_most_likely_position_indicies),:] for curr_most_likely_position_indicies in a_decoder_result.most_likely_position_indicies_list]\n",
    "\t# assert len(all_cells_decoded_expected_firing_rates_arr) == a_decoder_result.num_filter_epochs # one for each epoch\n",
    "\n",
    "\t# num_timebins_in_epoch: NDArray[Shape[\"num_epochs\"], Int] = np.array([np.shape(epoch_values)[0] for epoch_values in all_cells_decoded_expected_firing_rates_arr])\n",
    "\t# num_total_flat_timebins: int = np.sum(num_timebins_in_epoch) # number of timebins across all epochs\n",
    "\t# flat_epoch_idxs: NDArray[Shape[\"Num_total_flat_timebins\"], Int] = np.concatenate([np.repeat(i, np.shape(epoch_values)[0]) for i, epoch_values in enumerate(all_cells_decoded_expected_firing_rates_arr)]) # for each time bin repeat the epoch_id so we can recover it if needed\n",
    "\t\n",
    "\t# flat_expected_firing_rates: NDArray[Shape[\"Num_total_flat_timebins, num_neurons\"], Any] = np.vstack(all_cells_decoded_expected_firing_rates_arr)\n",
    "\t# flat_expected_num_spikes: NDArray[Shape[\"num_total_flat_timebins, num_neurons\"], Any] = flat_expected_firing_rates * a_decoder_result.decoding_time_bin_size\n",
    "\t# flat_observed_num_spikes: NDArray[Shape[\"num_total_flat_timebins, num_neurons\"], Any] = np.hstack(a_decoder_result.spkcount).T\n",
    "\t# flat_observed_from_expected_difference: NDArray[Shape[\"num_total_flat_timebins, num_neurons\"], Any] = flat_expected_num_spikes - flat_observed_num_spikes\n",
    "\t\n",
    "\t## for each cell:\n",
    "\tfor i, left_out_aclu in enumerate(a_decoder_1D.neuron_IDs):\n",
    "\t\t# aclu = decoder_1D.neuron_IDs[i]\n",
    "\t\tleft_out_neuron_IDX = a_decoder_1D.neuron_IDXs[i] # should just be i, but just to be safe\n",
    "\t\t## TODO: only look at bins where the cell fires (is_cell_firing_time_bin[i])\n",
    "\n",
    "\t\t## single cell outputs:\n",
    "\t\tcurr_cell_decoded_epoch_time_bins = [] # will be a list of the time bins in each epoch that correspond to each surprise in the corresponding list in curr_cell_computed_epoch_surprises \n",
    "\t\t\n",
    "\t\tcurr_cell_pf_curve = a_decoder_1D.pf.ratemap.tuning_curves[left_out_neuron_IDX]\n",
    "\t\t# curr_cell_spike_curve = decoder_1D.pf.ratemap.spikes_maps[unit_IDX] ## not occupancy weighted... is this the right one to use for computing the expected spike rate? NO... doesn't seem like it\n",
    "\n",
    "\t\t## Must pre-allocate each with an empty list:\n",
    "\t\tall_cells_decoded_expected_firing_rates[left_out_aclu] = [] \n",
    "\t\t\n",
    "\t\tfor decoded_epoch_idx in np.arange(a_decoder_result.num_filter_epochs):\n",
    "\t\t\tcurr_epoch_time_bin_container = a_decoder_result.time_bin_containers[decoded_epoch_idx]\n",
    "\t\t\tcurr_cell_decoded_epoch_time_bins.append(curr_epoch_time_bin_container)\n",
    "\t\t\tcurr_time_bins = curr_epoch_time_bin_container.centers\n",
    "\t\t\tcurr_epoch_p_x_given_n = a_decoder_result.p_x_given_n_list[decoded_epoch_idx] # .shape: (239, 5) - (n_x_bins, n_epoch_time_bins)\n",
    "\t\t\tassert curr_epoch_p_x_given_n.shape[0] == curr_cell_pf_curve.shape[0]\n",
    "\t\t\t\n",
    "\t\t\t## Need to exclude estimates from bins that didn't have any spikes in them (in general these glitch around):\n",
    "\t\t\tcurr_total_spike_counts_per_window = np.sum(a_decoder_result.spkcount[decoded_epoch_idx], axis=0) # left_out_decoder_result.spkcount[i].shape # (69, 222) - (nCells, nTimeWindowCenters)\n",
    "\t\t\tcurr_is_time_bin_non_firing = (curr_total_spike_counts_per_window == 0) # this would mean that no cells fired in this time bin\n",
    "\t\t\t# curr_non_firing_time_bin_indicies = np.where(curr_is_time_bin_non_firing)[0] # TODO: could also filter on a minimum number of spikes larger than zero (e.g. at least 2 spikes are required).\n",
    "\t\t\t# curr_posterior_container = decoder_result.marginal_x_list[decoded_epoch_idx]\n",
    "\t\t\t# curr_posterior = curr_posterior_container.p_x_given_n # TODO: check the posteriors too!\n",
    "\t\t\t# curr_most_likely_positions = curr_posterior_container.most_likely_positions_1D # (n_epoch_time_bins, ) one position for each time bin in the replay\n",
    "\t\t\tcurr_most_likely_position_indicies = a_decoder_result.most_likely_position_indicies_list[decoded_epoch_idx] # (n_epoch_time_bins, ) one position for each time bin in the replay\n",
    "\t\t\t\n",
    "\t\t\t# curr_epoch_observed_num_spikes = decoder_result.spkcount[decoded_epoch_idx] # (nCells, n_epoch_time_bins)\n",
    "\t\t\t\n",
    "\t\t\t# From the firing map of the placefields for this neuron (`decoder_1D.F.T[left_out_neuron_IDX]`) get the value for each position bin index in the epoch\n",
    "\t\t\tcurr_epoch_expected_fr = np.squeeze(a_decoder_1D.F.T[left_out_neuron_IDX][curr_most_likely_position_indicies])\n",
    "\t\t\t# expected_num_spikes = curr_epoch_expected_fr * decoder_result.decoding_time_bin_size\n",
    "\n",
    "\t\t\t# Eqn 1:\n",
    "\t\t\t# p_n_given_x = lambda n: (1.0/factorial(n)) * pow(expected_num_spikes, n) * np.exp(-expected_num_spikes) # likelihood function\n",
    "\t\t\t\n",
    "\t\t\t# Compute the expected firing rate for this cell during each bin by taking the computed position posterior and taking the sum of the element-wise product with the cell's placefield.\n",
    "\t\t\t# curr_epoch_expected_fr = decoder_1D.pf.ratemap.tuning_curve_unsmoothed_peak_firing_rates[left_out_neuron_IDX] * np.array([np.sum(curr_cell_pf_curve * curr_p_x_given_n) for curr_p_x_given_n in curr_epoch_p_x_given_n.T]) # * decoder_1D.pf.ratemap.\n",
    "\t\t\t\n",
    "\t\t\tall_cells_decoded_expected_firing_rates[left_out_aclu].append(curr_epoch_expected_fr)\n",
    "\n",
    "\n",
    "\t\t## End loop over decoded epochs\n",
    "\t\t# assert len(curr_cell_decoded_epoch_time_bins) == len(curr_cell_computed_epoch_surprises)\n",
    "\t\tall_cells_decoded_epoch_time_bins[left_out_aclu] = curr_cell_decoded_epoch_time_bins\n",
    "\n",
    "\t# ## End loop over cells\n",
    "\n",
    "\t## Reshape to -for-each-epoch instead of -for-each-cell\n",
    "\tall_epochs_decoded_epoch_time_bins = []\n",
    "\tall_epochs_computed_expected_cell_firing_rates = []\n",
    "\tfor decoded_epoch_idx in np.arange(active_filter_epochs.n_epochs):\n",
    "\t\tall_epochs_decoded_epoch_time_bins.append(np.array([all_cells_decoded_epoch_time_bins[aclu][decoded_epoch_idx].centers for aclu in a_decoder_1D.neuron_IDs])) # these are duplicated (and the same) for each cell\n",
    "\t\tall_epochs_computed_expected_cell_firing_rates.append(np.array([all_cells_decoded_expected_firing_rates[aclu][decoded_epoch_idx] for aclu in a_decoder_1D.neuron_IDs]))\n",
    "\n",
    "\t## These are already in the -for-each-epoch form and just need conversion:\n",
    "\tdecoder_time_bin_centers = [a_decoder_result.time_bin_containers[decoded_epoch_idx].centers for decoded_epoch_idx in np.arange(a_decoder_result.num_filter_epochs)]\n",
    "\tall_epochs_computed_expected_cell_num_spikes = [(all_epochs_computed_expected_cell_firing_rates[decoded_epoch_idx] * a_decoder_result.decoding_time_bin_size) for decoded_epoch_idx in np.arange(a_decoder_result.num_filter_epochs)]\n",
    "\tall_epochs_computed_observed_from_expected_difference = [(all_epochs_computed_expected_cell_num_spikes[decoded_epoch_idx] - a_decoder_result.spkcount[decoded_epoch_idx]) for decoded_epoch_idx in np.arange(a_decoder_result.num_filter_epochs)]\n",
    "\t# Interpolate the measured positions to the window center times:\n",
    "\tmeasured_pos_window_centers = [np.interp(curr_time_bins, active_pos_df.t, active_pos_df.lin_pos) for curr_time_bins in decoder_time_bin_centers] # TODO 2023-05-26: do I want .x or .lin_pos?\n",
    "\t\n",
    "\t## These aggregate over all time bins in each epoch:\n",
    "\t\t# Note that some of these correspond to values that are still separate by cell\n",
    "\tall_epochs_decoded_epoch_time_bins_mean = np.vstack([np.mean(curr_epoch_time_bins, axis=1) for curr_epoch_time_bins in all_epochs_decoded_epoch_time_bins]) # mean over all time bins in each epoch  # .shape (614, 65) - (n_epochs, n_neurons)\n",
    "\tall_epochs_computed_expected_cell_firing_rates_mean = np.vstack([np.mean(curr_epoch_values, axis=1) for curr_epoch_values in all_epochs_computed_expected_cell_firing_rates]) # mean over all time bins in each epoch  # .shape (614, 65) - (n_epochs, n_neurons)\n",
    "\tall_epochs_computed_expected_cell_firing_rates_stddev = np.vstack([np.std(curr_epoch_values, axis=1) for curr_epoch_values in all_epochs_computed_expected_cell_firing_rates]) # mean over all time bins in each epoch  # .shape (614, 65) - (n_epochs, n_neurons)\n",
    "\n",
    "\t# the maximum magnitude difference is found for all timebins within each epoch. This gives 1 value for each epoch\n",
    "\tall_epochs_computed_observed_from_expected_difference_max_index = [np.argmax(np.abs(all_epochs_computed_observed_from_expected_difference[decoded_epoch_idx]), axis=1, keepdims=False) for decoded_epoch_idx in np.arange(a_decoder_result.num_filter_epochs)]\n",
    "\tall_epochs_computed_observed_from_expected_difference_maximum = [np.array([all_epochs_computed_observed_from_expected_difference[decoded_epoch_idx][neuron_IDX, all_epochs_computed_observed_from_expected_difference_max_index[decoded_epoch_idx][neuron_IDX]] for neuron_IDX in np.arange(len(a_decoder_1D.neuron_IDs))]) for decoded_epoch_idx in np.arange(a_decoder_result.num_filter_epochs)]\n",
    "\t\n",
    "\treturn decoder_time_bin_centers, all_epochs_computed_expected_cell_num_spikes, all_epochs_computed_observed_from_expected_difference, measured_pos_window_centers, (all_epochs_decoded_epoch_time_bins_mean, all_epochs_computed_expected_cell_firing_rates_mean, all_epochs_computed_expected_cell_firing_rates_stddev, all_epochs_computed_observed_from_expected_difference_maximum)\n",
    "\n",
    "import awkward as ak # new Awkward array for ragged arrays\n",
    "\n",
    "def simpler_compute_measured_vs_expected_firing_rates(active_pos_df, active_filter_epochs, a_decoder_1D: \"BasePositionDecoder\", a_decoder_result: \"DecodedFilterEpochsResult\"):\n",
    "\t\"\"\" 2023-05-30 - Goal is to compute the expected and measured firing rates for each cell for each epoch. \n",
    "\t\t\tAttempting a smarter and more refined implementation.\n",
    "\tWant to be able to get a vector of firing rates (one for each cell) for an epoch i.\n",
    "\n",
    "\t\"\"\"\n",
    "\tnum_neurons = a_decoder_1D.num_neurons\n",
    "\tnum_epochs = a_decoder_result.num_filter_epochs\n",
    "\t\n",
    "\tall_cells_decoded_expected_firing_rates_list: List[np.ndarray] = [a_decoder_1D.F[np.squeeze(curr_most_likely_position_indicies),:] for curr_most_likely_position_indicies in a_decoder_result.most_likely_position_indicies_list]\n",
    "\tassert len(all_cells_decoded_expected_firing_rates_list) == a_decoder_result.num_filter_epochs # one for each epoch\n",
    "\n",
    "\tnum_timebins_in_epoch: NDArray[Shape[\"Num_epochs\"], Int] = np.array([np.shape(epoch_values)[0] for epoch_values in all_cells_decoded_expected_firing_rates_list])\n",
    "\tnum_total_flat_timebins: int = np.sum(num_timebins_in_epoch) # number of timebins across all epochs\n",
    "\tflat_epoch_idxs: NDArray[Shape[\"N_total_flat_timebins\"], Int] = np.concatenate([np.repeat(i, np.shape(epoch_values)[0]) for i, epoch_values in enumerate(all_cells_decoded_expected_firing_rates_list)]) # for each time bin repeat the epoch_id so we can recover it if needed\n",
    "\t\n",
    "\tflat_expected_firing_rates: NDArray[Shape[\"N_total_flat_timebins, N_neurons\"], Any] = np.vstack(all_cells_decoded_expected_firing_rates_list)\n",
    "\tflat_expected_num_spikes: NDArray[Shape[\"N_total_flat_timebins, N_neurons\"], Any] = flat_expected_firing_rates * a_decoder_result.decoding_time_bin_size\n",
    "\tflat_observed_num_spikes: NDArray[Shape[\"N_total_flat_timebins, N_neurons\"], Any] = np.hstack(a_decoder_result.spkcount).T\n",
    "\tflat_observed_from_expected_difference: NDArray[Shape[\"N_total_flat_timebins, N_neurons\"], Any] = flat_expected_num_spikes - flat_observed_num_spikes\n",
    "\n",
    "\t## Awkward Array (Ragged-array) version:\n",
    "\tragged_expected_firing_rates_arr = ak.Array(all_cells_decoded_expected_firing_rates_list) # awkward array\n",
    "\tnum_timebins_in_epoch = ak.num(ragged_expected_firing_rates_arr, axis=1)\n",
    "\tnum_total_flat_timebins: int = np.sum(num_timebins_in_epoch)\n",
    "\tprint(f'num_neurons: {num_neurons}, num_epochs: {num_epochs}, num_total_flat_timebins: {num_total_flat_timebins}')\n",
    "\n",
    "\tragged_expected_num_spikes_arr = ragged_expected_firing_rates_arr * a_decoder_result.decoding_time_bin_size\n",
    "\tragged_observed_from_expected_diff = ragged_expected_num_spikes_arr - ak.Array([v.T for v in a_decoder_result.spkcount])\n",
    "\t# ragged_observed_from_expected_diff_MAXIMUMS = ragged_observed_from_expected_diff[ak.argmax(np.abs(ragged_observed_from_expected_diff), axis=1, keepdims=False)]\n",
    "\t# flat_observed_from_expected_diff_MAXIMUMS = ak.flatten(ragged_observed_from_expected_diff_MAXIMUMS, axis=1)\n",
    "\n",
    "\t## By epoch quantities, this is correct:\n",
    "\tobserved_from_expected_diff_ptp = ak.to_regular(ak.ptp(ragged_observed_from_expected_diff, axis=1)).to_numpy().T # type: 120 * 30 * float64\n",
    "\tobserved_from_expected_diff_mean = ak.to_regular(ak.mean(ragged_observed_from_expected_diff, axis=1)).to_numpy().T # type: 120 * 30 * float64\n",
    "\tobserved_from_expected_diff_std = ak.to_regular(ak.std(ragged_observed_from_expected_diff, axis=1)).to_numpy().T # type: 120 * 30 * float64\n",
    "\n",
    "\t# df = pd.DataFrame(dict(zip(('epoch_idx', 'expected_fr', 'expected_spikes', 'observed_spikes', 'observed_from_expected_diff'), (flat_epoch_idxs, flat_expected_firing_rates, flat_expected_num_spikes, flat_observed_num_spikes, flat_observed_from_expected_difference))))\n",
    "\t# return df, num_total_flat_timebins, num_timebins_in_epoch\n",
    "\treturn (num_neurons, num_timebins_in_epoch, num_total_flat_timebins), (observed_from_expected_diff_ptp, observed_from_expected_diff_mean, observed_from_expected_diff_std)\n",
    "\n",
    "# returned_shape_tuple, (observed_from_expected_diff_ptp, observed_from_expected_diff_mean, observed_from_expected_diff_std) = simpler_compute_measured_vs_expected_firing_rates(active_pos_df, active_filter_epochs, a_decoder_1D=decoder_1D_LONG, a_decoder_result=decoder_result_LONG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31600914",
   "metadata": {
    "tags": [
     "prototyping",
     "testing_ONLY"
    ]
   },
   "outputs": [],
   "source": [
    "# # Testing breakout for `simpler_compute_measured_vs_expected_firing_rates`:\n",
    "# active_pos_df = active_pos_df\n",
    "# active_filter_epochs = active_filter_epochs\n",
    "# a_decoder_1D: \"BasePositionDecoder\" = decoder_1D_LONG\n",
    "# a_decoder_result: \"DecodedFilterEpochsResult\" = decoder_result_LONG\n",
    "\n",
    "# num_epochs = a_decoder_result.num_filter_epochs\n",
    "\n",
    "# all_cells_decoded_expected_firing_rates_list: List[np.ndarray] = [a_decoder_1D.F[np.squeeze(curr_most_likely_position_indicies),:] for curr_most_likely_position_indicies in a_decoder_result.most_likely_position_indicies_list]\n",
    "\n",
    "# assert len(all_cells_decoded_expected_firing_rates_list) == a_decoder_result.num_filter_epochs # one for each epoch\n",
    "\n",
    "# num_timebins_in_epoch: NDArray[Shape[\"Num_epochs\"], Int] = np.array([np.shape(epoch_values)[0] for epoch_values in all_cells_decoded_expected_firing_rates_list])\n",
    "# num_total_flat_timebins: int = np.sum(num_timebins_in_epoch) # number of timebins across all epochs\n",
    "# flat_epoch_idxs: NDArray[Shape[\"N_total_flat_timebins\"], Int] = np.concatenate([np.repeat(i, np.shape(epoch_values)[0]) for i, epoch_values in enumerate(all_cells_decoded_expected_firing_rates_list)]) # for each time bin repeat the epoch_id so we can recover it if needed\n",
    "\n",
    "# flat_expected_firing_rates: NDArray[Shape[\"N_total_flat_timebins, N_neurons\"], Any] = np.vstack(all_cells_decoded_expected_firing_rates_list)\n",
    "# flat_expected_num_spikes: NDArray[Shape[\"N_total_flat_timebins, N_neurons\"], Any] = flat_expected_firing_rates * a_decoder_result.decoding_time_bin_size\n",
    "# flat_observed_num_spikes: NDArray[Shape[\"N_total_flat_timebins, N_neurons\"], Any] = np.hstack(a_decoder_result.spkcount).T\n",
    "# flat_observed_from_expected_difference: NDArray[Shape[\"N_total_flat_timebins, N_neurons\"], Any] = flat_expected_num_spikes - flat_observed_num_spikes\n",
    "\n",
    "\n",
    "# # df = pd.DataFrame(dict(zip(('epoch_idx', 'expected_fr', 'expected_spikes', 'observed_spikes', 'observed_from_expected_diff'), (flat_epoch_idxs, flat_expected_firing_rates, flat_expected_num_spikes, flat_observed_num_spikes, flat_observed_from_expected_difference))))\n",
    "# # all_cells_decoded_expected_firing_rates_arr\n",
    "\n",
    "# ## Awkward Array (Ragged-array) version:\n",
    "# ragged_expected_firing_rates_arr = ak.Array(all_cells_decoded_expected_firing_rates_list) # awkward array\n",
    "# num_timebins_in_epoch = ak.num(ragged_expected_firing_rates_arr, axis=1)\n",
    "# num_total_flat_timebins: int = np.sum(num_timebins_in_epoch)\n",
    "# print(f'num_neurons: {a_decoder_1D.num_neurons}, num_epochs: {num_epochs}, num_total_flat_timebins: {num_total_flat_timebins}')\n",
    "\n",
    "# ragged_expected_num_spikes_arr = ragged_expected_firing_rates_arr * a_decoder_result.decoding_time_bin_size\n",
    "# ragged_observed_from_expected_diff = ragged_expected_num_spikes_arr - ak.Array([v.T for v in a_decoder_result.spkcount])\n",
    "# # ragged_observed_from_expected_diff\n",
    "# # ragged_observed_from_expected_diff_MAXIMUMS = ragged_observed_from_expected_diff[ak.argmax(np.abs(ragged_observed_from_expected_diff), axis=1, keepdims=False)]\n",
    "# # ragged_observed_from_expected_diff_MAXIMUMS\n",
    "# # ragged_expected_num_spikes_arr\n",
    "# # flat_observed_from_expected_diff_MAXIMUMS = ak.flatten(ragged_observed_from_expected_diff_MAXIMUMS, axis=2)\n",
    "\n",
    "# ## By epoch quantities, this is correct:\n",
    "# observed_from_expected_diff_ptp = ak.to_regular(ak.ptp(ragged_observed_from_expected_diff, axis=1)).to_numpy().T # type: 120 * 30 * float64\n",
    "# observed_from_expected_diff_mean = ak.to_regular(ak.mean(ragged_observed_from_expected_diff, axis=1)).to_numpy().T # type: 120 * 30 * float64\n",
    "# observed_from_expected_diff_std = ak.to_regular(ak.std(ragged_observed_from_expected_diff, axis=1)).to_numpy().T # type: 120 * 30 * float64\n",
    "\n",
    "# # ragged_observed_from_expected_diff_MAXIMUMS[0][0][0]\n",
    "# # ragged_observed_from_expected_diff\n",
    "# # ragged_expected_firing_rates_arr[0, 0, :]\n",
    "# # ragged_expected_firing_rates_arr\n",
    "# # flat_observed_from_expected_diff_MAXIMUMS[0,:,0]\n",
    "# # ragged_observed_from_expected_diff_MAXIMUMS.to_list()\n",
    "\n",
    "# # ragged_observed_from_expected_diff_MAXIMUMS.show()\n",
    "\n",
    "# # observed_from_expected_diff_mean\n",
    "# # num_total_flat_timebins\n",
    "\n",
    "# # observed_from_expected_diff_mean.to_list()\n",
    "\n",
    "# # [observed_from_expected_diff_mean[:,i].to_numpy() for i in np.arange(a_decoder_1D.num_neurons)]\n",
    "# observed_from_expected_diff_ptp.shape\n",
    "\n",
    "# # ak.flatten(observed_from_expected_diff_mean[:,i,:], axis=0)\n",
    "# # ak.to_regular(ragged_observed_from_expected_diff_MAXIMUMS, axis=0)\n",
    "# # ak.concatenate(observed_from_expected_diff_mean, axis=1)\n",
    "\n",
    "# # ragged_observed_from_expected_diff_MAXIMUMS[:, 0, :]\n",
    "# # latitude = ragged_observed_from_expected_diff_MAXIMUMS[..., 1]\n",
    "# # longitude, latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4ba9abd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_neurons: 35, num_epochs: 28, num_total_flat_timebins: 165\n",
      "num_neurons: 35, num_epochs: 28, num_total_flat_timebins: 165\n"
     ]
    }
   ],
   "source": [
    "## Common to both Long and Short:\n",
    "active_pos_df = global_session.position.to_dataframe()\n",
    "assert (long_results_obj.active_filter_epochs.as_array() == short_results_obj.active_filter_epochs.as_array()).all() # ensure that the active_filter_epochs for both are the same.\n",
    "active_filter_epochs = long_results_obj.active_filter_epochs\n",
    "\n",
    "## Long Specific:\n",
    "decoder_1D_LONG = long_results_obj.original_1D_decoder\n",
    "decoder_result_LONG = long_results_obj.all_included_filter_epochs_decoder_result\n",
    "# call `compute_measured_vs_expected_firing_rates`\n",
    "decoder_time_bin_centers_LONG, all_epochs_computed_expected_cell_num_spikes_LONG, all_epochs_computed_observed_from_expected_difference_LONG, measured_pos_window_centers_LONG, (all_epochs_decoded_epoch_time_bins_mean_LONG, all_epochs_computed_expected_cell_firing_rates_mean_LONG, all_epochs_computed_expected_cell_firing_rates_stddev_LONG, all_epochs_computed_observed_from_expected_difference_maximum_LONG) = compute_measured_vs_expected_firing_rates(active_pos_df, active_filter_epochs, decoder_1D_LONG, decoder_result_LONG)\n",
    "# The Flat_* versions exist because it's difficult to plot while all of the metrics are separated in lists.\n",
    "Flat_decoder_time_bin_centers_LONG = np.concatenate(decoder_time_bin_centers_LONG) # .shape: (412,)\n",
    "Flat_all_epochs_computed_expected_cell_num_spikes_LONG = np.vstack([np.concatenate([all_epochs_computed_observed_from_expected_difference_LONG[decoded_epoch_idx][target_neuron_IDX, :] for decoded_epoch_idx in np.arange(decoder_result_LONG.num_filter_epochs)]) for target_neuron_IDX in decoder_1D_LONG.neuron_IDXs]) #.shape (20, 22)\n",
    "\n",
    "# call `simpler_compute_measured_vs_expected_firing_rates`\n",
    "returned_shape_tuple_LONG, (observed_from_expected_diff_ptp_LONG, observed_from_expected_diff_mean_LONG, observed_from_expected_diff_std_LONG) = simpler_compute_measured_vs_expected_firing_rates(active_pos_df, active_filter_epochs, a_decoder_1D=decoder_1D_LONG, a_decoder_result=decoder_result_LONG)\n",
    "## Short Specific:\n",
    "decoder_1D_SHORT = short_results_obj.original_1D_decoder\n",
    "decoder_result_SHORT = short_results_obj.all_included_filter_epochs_decoder_result\n",
    "\n",
    "# call `compute_measured_vs_expected_firing_rates`\n",
    "decoder_time_bin_centers_SHORT, all_epochs_computed_expected_cell_num_spikes_SHORT, all_epochs_computed_observed_from_expected_difference_SHORT, measured_pos_window_centers_SHORT, (all_epochs_decoded_epoch_time_bins_mean_SHORT, all_epochs_computed_expected_cell_firing_rates_mean_SHORT, all_epochs_computed_expected_cell_firing_rates_stddev_SHORT, all_epochs_computed_observed_from_expected_difference_maximum_SHORT) = compute_measured_vs_expected_firing_rates(active_pos_df, active_filter_epochs, decoder_1D_SHORT, decoder_result_SHORT)\n",
    "# The Flat_* versions exist because it's difficult to plot while all of the metrics are separated in lists.\n",
    "Flat_decoder_time_bin_centers_SHORT = np.concatenate(decoder_time_bin_centers_SHORT) # .shape: (412,)\n",
    "Flat_all_epochs_computed_expected_cell_num_spikes_SHORT = np.vstack([np.concatenate([all_epochs_computed_observed_from_expected_difference_SHORT[decoded_epoch_idx][target_neuron_IDX, :] for decoded_epoch_idx in np.arange(decoder_result_SHORT.num_filter_epochs)]) for target_neuron_IDX in decoder_1D_SHORT.neuron_IDXs]) #.shape (20, 22)\n",
    "Flat_epoch_time_bins_mean = all_epochs_decoded_epoch_time_bins_mean_SHORT[:,0]\n",
    "\n",
    "# call `simpler_compute_measured_vs_expected_firing_rates`\n",
    "returned_shape_tuple_SHORT, (observed_from_expected_diff_ptp_SHORT, observed_from_expected_diff_mean_SHORT, observed_from_expected_diff_std_SHORT) = simpler_compute_measured_vs_expected_firing_rates(active_pos_df, active_filter_epochs, a_decoder_1D=decoder_1D_SHORT, a_decoder_result=decoder_result_SHORT)\n",
    "\n",
    "## Sanity Checks that the LONG and SHORT decoders and their decoded results aren't identical:\n",
    "assert (Flat_decoder_time_bin_centers_SHORT == Flat_decoder_time_bin_centers_LONG).all()\n",
    "Flat_decoder_time_bin_centers = Flat_decoder_time_bin_centers_LONG # equivalent\n",
    "assert (decoder_1D_LONG.neuron_IDs == decoder_1D_SHORT.neuron_IDs).all()\n",
    "assert not (decoder_1D_LONG.P_x == decoder_1D_SHORT.P_x).all() # the occupancies shouldn't be identical between the two encoders, this might indicate an error\n",
    "assert not (decoder_1D_LONG.F == decoder_1D_SHORT.F).all() # the placefields shouldn't be identical between the two encoders, this might indicate an error\n",
    "# assert not np.array([(Flat_all_epochs_computed_expected_cell_num_spikes_LONG[i] == Flat_all_epochs_computed_expected_cell_num_spikes_SHORT[i]).all() for i in np.arange(active_filter_epochs.n_epochs)]).all(), \"all expected number spikes for all cells should not be the same for two different decoders! This likely indicates an error!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7851560b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "767fe16d",
   "metadata": {},
   "source": [
    "### 2023-05-26 - MONDAY TODO - Plot the `all_epochs_computed_observed_from_expected_difference_maximum` which should show the change from expectation for each neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07e626f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(all_epochs_computed_observed_from_expected_difference_maximum_LONG) # len(...): 20 (n_epochs)\n",
    "all_epochs_computed_observed_from_expected_difference_maximum_LONG[0].shape # [0].shape: (22, ) (n_cells, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d599509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_SHARED = Flat_decoder_time_bin_centers.copy()\n",
    "y_LONG = Flat_all_epochs_computed_expected_cell_num_spikes_LONG.copy()\n",
    "y_SHORT = Flat_all_epochs_computed_expected_cell_num_spikes_SHORT.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfaf1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_SHARED = Flat_epoch_time_bins_mean.copy()\n",
    "y_LONG = all_epochs_computed_observed_from_expected_difference_maximum_LONG.copy()\n",
    "y_SHORT = all_epochs_computed_observed_from_expected_difference_maximum_SHORT.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d8db7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_SHARED = Flat_epoch_time_bins_mean.copy()\n",
    "# y_LONG = observed_from_expected_diff_ptp_LONG.copy()\n",
    "# y_SHORT = observed_from_expected_diff_ptp_SHORT.copy()\n",
    "y_LONG = observed_from_expected_diff_mean_LONG.copy()\n",
    "y_SHORT = observed_from_expected_diff_mean_SHORT.copy()\n",
    "# assert y_LONG.shape[0] == t_SHARED.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39eb2906",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Array shapes are incompatible for broadcasting.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 21\u001b[0m\n\u001b[1;32m     16\u001b[0m long_long_diff \u001b[39m=\u001b[39m (observed_from_expected_diff_mean_LONG[:, is_long_track_epoch] \u001b[39m-\u001b[39m observed_from_expected_diff_mean_SHORT[:, is_long_track_epoch])\n\u001b[1;32m     18\u001b[0m \u001b[39m# np.mean(long_long_diff)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39m# np.mean(short_short_diff)\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m ttest_results \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39;49mstats\u001b[39m.\u001b[39;49mttest_rel(long_long_diff, short_short_diff)\n\u001b[1;32m     23\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlong_test: \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mmean(long_long_diff)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mshort_test: \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mmean(short_short_diff)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/repo/Spike3D/.venv/lib/python3.9/site-packages/scipy/stats/_axis_nan_policy.py:455\u001b[0m, in \u001b[0;36m_axis_nan_policy_factory.<locals>.axis_nan_policy_decorator.<locals>.axis_nan_policy_wrapper\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    453\u001b[0m     samples \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39masarray(sample\u001b[39m.\u001b[39mravel()) \u001b[39mfor\u001b[39;00m sample \u001b[39min\u001b[39;00m samples]\n\u001b[1;32m    454\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 455\u001b[0m     samples \u001b[39m=\u001b[39m _broadcast_arrays(samples, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m    456\u001b[0m     axis \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39matleast_1d(axis)\n\u001b[1;32m    457\u001b[0m     n_axes \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(axis)\n",
      "File \u001b[0;32m~/repo/Spike3D/.venv/lib/python3.9/site-packages/scipy/stats/_axis_nan_policy.py:18\u001b[0m, in \u001b[0;36m_broadcast_arrays\u001b[0;34m(arrays, axis)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_broadcast_arrays\u001b[39m(arrays, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     15\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m    Broadcast shapes of arrays, ignoring incompatibility of specified axes\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     new_shapes \u001b[39m=\u001b[39m _broadcast_array_shapes(arrays, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m     19\u001b[0m     \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     20\u001b[0m         new_shapes \u001b[39m=\u001b[39m [new_shapes]\u001b[39m*\u001b[39m\u001b[39mlen\u001b[39m(arrays)\n",
      "File \u001b[0;32m~/repo/Spike3D/.venv/lib/python3.9/site-packages/scipy/stats/_axis_nan_policy.py:30\u001b[0m, in \u001b[0;36m_broadcast_array_shapes\u001b[0;34m(arrays, axis)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39mBroadcast shapes of arrays, ignoring incompatibility of specified axes\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     29\u001b[0m shapes \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39masarray(arr)\u001b[39m.\u001b[39mshape \u001b[39mfor\u001b[39;00m arr \u001b[39min\u001b[39;00m arrays]\n\u001b[0;32m---> 30\u001b[0m \u001b[39mreturn\u001b[39;00m _broadcast_shapes(shapes, axis)\n",
      "File \u001b[0;32m~/repo/Spike3D/.venv/lib/python3.9/site-packages/scipy/stats/_axis_nan_policy.py:81\u001b[0m, in \u001b[0;36m_broadcast_shapes\u001b[0;34m(shapes, axis)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39m# Among all arrays, there can only be one unique non-1 shape element.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[39m# Therefore, if any non-1 shape element does not match what we found\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[39m# above, the arrays must not be broadcastable after all.\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39many(\u001b[39m~\u001b[39m((new_shapes \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m|\u001b[39m (new_shapes \u001b[39m==\u001b[39m new_shape))):\n\u001b[0;32m---> 81\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mArray shapes are incompatible for broadcasting.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     83\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m     \u001b[39m# Add back the shape elements that were ignored\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     new_axis \u001b[39m=\u001b[39m axis \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39mlen\u001b[39m(axis))\n",
      "\u001b[0;31mValueError\u001b[0m: Array shapes are incompatible for broadcasting."
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "\n",
    "\n",
    "# 2023-05-30 9:30pm - just compute the aggregate stats for the short v long expected firing rates:\n",
    "\n",
    "## Get the epochs that occur on the short and the long tracks:\n",
    "is_short_track_epoch = (Flat_epoch_time_bins_mean >= short_session.t_start)\n",
    "is_long_track_epoch = np.logical_not(is_short_track_epoch)\n",
    "\n",
    "# All comparisons should be (native - alternative), so a positive value (> 0) is expected\n",
    "# analyze the decodings of the events on the short track:\n",
    "short_short_diff = (observed_from_expected_diff_mean_SHORT[:, is_short_track_epoch] - observed_from_expected_diff_mean_LONG[:, is_short_track_epoch])\n",
    "# expect that the short_short decoding is better than the long_short decoding, so short_short_diff should be significantly < 0.0\n",
    "\n",
    "# analyze the decodings of the events on the long track:\n",
    "long_long_diff = (observed_from_expected_diff_mean_LONG[:, is_long_track_epoch] - observed_from_expected_diff_mean_SHORT[:, is_long_track_epoch])\n",
    "\n",
    "# np.mean(long_long_diff)\n",
    "# np.mean(short_short_diff)\n",
    "\n",
    "ttest_results = scipy.stats.ttest_rel(long_long_diff, short_short_diff)\n",
    "\n",
    "print(f'long_test: {np.mean(long_long_diff)}')\n",
    "print(f'short_test: {np.mean(short_short_diff)}')\n",
    "\n",
    "\n",
    "# long_long_diff\n",
    "# active_filter_epochs.epochs\n",
    "\n",
    "# long_replays\n",
    "\n",
    "# short_replays\n",
    "\n",
    "# short_session.t_start\n",
    "# short_session.t_stop\n",
    "# long_session.t_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fe25ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from neuropy.utils.matplotlib_helpers import draw_epoch_regions\n",
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\"\"\" plots one subplot for each neuron. \n",
    "\n",
    "t_SHARED, y_LONG, y_SHORT\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# the y-min and max across all cells and time bins:\n",
    "global_y_max_SHORT = np.max([np.max(v) for v in y_SHORT]) # 0.9280231494040394\n",
    "global_y_min_SHORT = np.min([np.min(v) for v in y_SHORT]) # -4.850176354048617\n",
    "print(f'global_y_min_SHORT: {global_y_min_SHORT}, global_y_max_SHORT: {global_y_max_SHORT}')\n",
    "\n",
    "global_y_max_LONG = np.max([np.max(v) for v in y_LONG]) # 0.9280231494040394\n",
    "global_y_min_LONG = np.min([np.min(v) for v in y_LONG]) # -4.850176354048617\n",
    "print(f'global_y_min_LONG: {global_y_min_LONG}, global_y_max_LONG: {global_y_max_LONG}')\n",
    "\n",
    "# the y-min and max across all cells and time bins:\n",
    "global_y_max = np.max([global_y_max_LONG, global_y_max_SHORT]) # 0.9280231494040394\n",
    "global_y_min = np.min([global_y_min_LONG, global_y_min_SHORT]) # -4.850176354048617\n",
    "print(f'global_y_min: {global_y_min}, global_y_max: {global_y_max}')\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(ncols=1, nrows=20, sharex=True, sharey=False) # , sharey=True\n",
    "\n",
    "shift_offset = 10\n",
    "for i, ax in enumerate(axes):\n",
    "\tshifted_i = shift_offset + i\n",
    "\tneuron_IDX = decoder_1D_LONG.neuron_IDXs[shifted_i]\n",
    "\tneuron_id = decoder_1D_LONG.neuron_IDs[shifted_i]\n",
    "\t\n",
    "\t# ax.scatter(Flat_decoder_time_bin_centers, np.concatenate([all_epochs_computed_observed_from_expected_difference[decoded_epoch_idx][neuron_IDX, :] for decoded_epoch_idx in np.arange(decoder_result.num_filter_epochs)]), marker=\"o\",  s=2)\n",
    "\t# ax.scatter(Flat_decoder_time_bin_centers, Flat_all_epochs_computed_expected_cell_num_spikes[neuron_IDX], marker=\"o\",  s=2, label=f'long[{neuron_id}]')\n",
    "\tax.axhline(y=0.0, linewidth=1, color='k') # the y=0.0 line\n",
    "\t# Per-epoch result:\n",
    "\t# ax.scatter(Flat_decoder_time_bin_centers_LONG, Flat_all_epochs_computed_expected_cell_num_spikes_LONG[neuron_IDX], marker=\"o\",  s=2, label=f'Long[{neuron_id}]')\n",
    "\t# ax.scatter(Flat_decoder_time_bin_centers_SHORT, Flat_all_epochs_computed_expected_cell_num_spikes_SHORT[neuron_IDX], marker=\"o\",  s=2, label=f'Short[{neuron_id}]')\n",
    "\n",
    "\t## Add in the mean epoch difference:\n",
    "\tax.scatter(t_SHARED, y_LONG[neuron_IDX, :], marker=\"s\",  s=5, label=f'E<Long[{neuron_id}]>')\n",
    "\tax.scatter(t_SHARED, y_SHORT[neuron_IDX, :], marker=\"s\",  s=5, label=f'E<Short[{neuron_id}]>')\n",
    "\n",
    "\tax.set_ylabel(f'{neuron_id}')\n",
    "\t\n",
    "\tepochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, defer_render=False, debug_print=False)\n",
    "\t\n",
    "# Set the x-axis and y-axis limits of the first subplot, which because sharex=True and sharey=True will set the rest of the plots too\n",
    "axes[0].set_xlim([Flat_decoder_time_bin_centers_LONG[0], Flat_decoder_time_bin_centers_LONG[-1]])\n",
    "axes[0].set_ylim([global_y_min, global_y_max])\n",
    "axes[-1].set_xlabel('time')\n",
    "axes[-1].legend() # show the legend\n",
    "\n",
    "plt.suptitle('Expected vs. Observed Firing Rate Differences (by Replay Epoch)')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3348cb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_sess_context = curr_active_pipeline.sess.get_context()\n",
    "## Finally, add the display function to the active context\n",
    "active_identifying_ctx = curr_sess_context.adding_context('display_fn', display_fn_name='long_short_expected_vs_observed_firing')\n",
    "active_identifying_ctx_string = active_identifying_ctx.get_description(separator='|') # Get final discription string:\n",
    "\n",
    "print(f'active_identifying_ctx_string: {active_identifying_ctx_string}')\n",
    "\n",
    "\t\n",
    "# curr_sess_context.\n",
    "# fig.savefig("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993412e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_epochs_computed_observed_from_expected_difference_LONG[0] #.shape (42, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0319692c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_epochs_computed_observed_from_expected_difference_maximum_LONG[0] # .shape (42, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fee52d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_epochs_computed_expected_cell_firing_rates_mean_LONG[0] # .shape (42,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21dbc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_epochs_computed_observed_from_expected_difference_LONG[0].shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c232970",
   "metadata": {},
   "source": [
    "# Rate Remapping Investigations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af84b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.neurons import NeuronType\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import compute_rate_remapping_stats\n",
    "rate_remapping_df = compute_rate_remapping_stats(curr_active_pipeline.global_computation_results.computed_data.long_short_fr_indicies_analysis, global_session.neurons.aclu_to_neuron_type_map, considerable_remapping_threshold=0.7)\n",
    "# rate_remapping_df\n",
    "high_remapping_cells_only = rate_remapping_df[rate_remapping_df['has_considerable_remapping']] \n",
    "high_remapping_cells_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9003439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract rr_* variables from rate_remapping_df\n",
    "rr_aclus = rate_remapping_df.index.values\n",
    "rr_laps, rr_replays, rr_skew, rr_neuron_type = [rate_remapping_df[n].values for n in ['laps', 'replays', 'skew', 'neuron_type']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79483e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot using Paginator:\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import RateRemappingPaginatedFigureController\n",
    "\n",
    "## Paginated multi-plot\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context()\n",
    "_out_rr_pagination_controller = RateRemappingPaginatedFigureController.init_from_rr_data(rr_aclus, rr_laps, rr_replays, rr_neuron_type, max_subplots_per_page=20, a_name='TestRateRemappingPaginatedFigureController', active_context=active_identifying_session_ctx)\n",
    "a_paginator = _out_rr_pagination_controller.plots_data.paginator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a16a3469",
   "metadata": {},
   "source": [
    "# Weird Plotting Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6688edf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_identifying_filtered_session_ctx = global_epoch_context\n",
    "display_output = curr_active_pipeline.display('_display_spike_rasters_window', active_identifying_filtered_session_ctx, type_of_3d_plotter=None) # , type_of_3d_plotter=None\n",
    "spike_raster_window = display_output['spike_raster_window']\n",
    "# Extras:\n",
    "active_2d_plot = spike_raster_window.spike_raster_plt_2d # <pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster.Spike2DRaster at 0x196c7244280>\n",
    "active_3d_plot = spike_raster_window.spike_raster_plt_3d # <pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster.Spike2DRaster at 0x196c7244280>\n",
    "main_graphics_layout_widget = active_2d_plot.ui.main_graphics_layout_widget # GraphicsLayoutWidget\n",
    "main_plot_widget = active_2d_plot.plots.main_plot_widget # PlotItem\n",
    "background_static_scroll_plot_widget = active_2d_plot.plots.background_static_scroll_window_plot # PlotItem\n",
    "\n",
    "# _plot_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5cdbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.programming_helpers import IPythonHelpers\n",
    "\n",
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "x_frs_dict, y_frs_dict = long_short_fr_indicies_analysis_results['x_frs_index'], long_short_fr_indicies_analysis_results['y_frs_index'] # use the all_results_dict as the computed data value\n",
    "active_context = long_short_fr_indicies_analysis_results['active_context']\n",
    "# IPythonHelpers.cell_vars(lambda: globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f99839",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_short_fr_indicies_df = pd.DataFrame({'aclu': list(x_frs_dict.keys()), 'replay_fr_idx': list(x_frs_dict.values()), 'laps_fr_idx': list(y_frs_dict.values())}) # , columns=['aclu','replay_frs']\n",
    "long_short_fr_indicies_df.set_index('aclu', inplace=True)\n",
    "# long_short_fr_indicies_df\n",
    "# long_short_fr_indicies_df.to_clipboard()\n",
    "long_short_fr_indicies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58696b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_short_fr_indicies_analysis_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7742482",
   "metadata": {},
   "source": [
    "## 2023-05-01 - Test my interneuron hypothesis by looking at interneurons across the long/short divide\n",
    "\n",
    " 1. Interneuron identity should be best determinant of active environment.\n",
    "\n",
    " 2. Do people know anything about interneurons that activate in a given environment? For example, to interneurons activate alongside pyramidal cells when replaying a given environment?\n",
    "\n",
    " 3. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b7df38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1. Interneuron identity should be best determinant of active environment.\n",
    "\n",
    "# 2. Do people know anything about interneurons that activate in a given environment? For example, to interneurons activate alongside pyramidal cells when replaying a given environment?\n",
    "\n",
    "# 3. \n",
    "# global_results.pf1D_dt.reset()\n",
    "# global_results.pf2D_dt.reset()\n",
    "# global_results.all_attributes\n",
    "\n",
    "list(curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.keys())\n",
    "\n",
    "curr_active_pipeline.global_computation_results.computed_data.long_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2d06a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "\n",
    "jonathan_firing_rate_analysis_result = JonathanFiringRateAnalysisResult(**curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ac6c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.rdf.rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc9c2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.time_binned_instantaneous_unit_specific_spike_rate.time_bins #.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785ca961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "instantaneous_fr_df = deepcopy(jonathan_firing_rate_analysis_result.time_binned_instantaneous_unit_specific_spike_rate.instantaneous_unit_specific_spike_rate_values)\n",
    "instantaneous_fr_df['t'] = jonathan_firing_rate_analysis_result.time_binned_instantaneous_unit_specific_spike_rate.time_bins\n",
    "instantaneous_fr_df #.plot()\n",
    "\n",
    "smoothed_instantaneous_fr_df = instantaneous_fr_df.ewm(span=60).mean()\n",
    "\n",
    "smoothed_instantaneous_fr_df.plot(x='t')\n",
    "plt.title(\"Instantaneous Firing Rates\")\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('Firing Rate (Hz)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8b7bbd",
   "metadata": {
    "tags": [
     "output",
     "figure",
     "display",
     "ACTIVE"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import build_figure_basename_from_display_context\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import _plot_session_long_short_track_firing_rate_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "\n",
    "jonathan_firing_rate_analysis_result = JonathanFiringRateAnalysisResult(**curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.to_dict())\n",
    "long_plots, short_plots = _plot_session_long_short_track_firing_rate_figures(curr_active_pipeline, jonathan_firing_rate_analysis_result, figures_parent_out_path=curr_active_pipeline.get_output_path())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345b3cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "instantaneous_fr_df.set_index('t').to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ff9bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Require placefield presence on either the long or the short\n",
    "jonathan_firing_rate_analysis_result.neuron_replay_stats_df = jonathan_firing_rate_analysis_result.neuron_replay_stats_df[np.logical_or(jonathan_firing_rate_analysis_result.neuron_replay_stats_df['has_long_pf'], jonathan_firing_rate_analysis_result.neuron_replay_stats_df['has_short_pf'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87851fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.neuron_replay_stats_df[np.logical_or(jonathan_firing_rate_analysis_result.neuron_replay_stats_df['has_long_pf'], jonathan_firing_rate_analysis_result.neuron_replay_stats_df['has_short_pf'])].index.to_numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8de2e3da",
   "metadata": {},
   "source": [
    "# 2023-05-19 - Testing S-only emergence, L-only replays in S, peak position remappings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d082385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "\n",
    "jonathan_firing_rate_analysis_result = JonathanFiringRateAnalysisResult(**curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.to_dict())\n",
    "neuron_replay_stats_df = jonathan_firing_rate_analysis_result.neuron_replay_stats_df.copy()\n",
    "neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23e5131",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import SplitPartitionMembership, SetPartition\n",
    "## 2023-05-19 - Get S-only pfs\n",
    "is_S_pf_only = np.logical_and(np.logical_not(neuron_replay_stats_df['has_long_pf']), neuron_replay_stats_df['has_short_pf'])\n",
    "is_S_only = neuron_replay_stats_df.track_membership == SplitPartitionMembership.RIGHT_ONLY\n",
    "assert (is_S_pf_only == is_S_only).all()\n",
    "S_only_aclus = neuron_replay_stats_df.index[is_S_only].to_numpy()\n",
    "neuron_replay_stats_df[is_S_pf_only]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc5b2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Show L-only pfs stop replaying on S\n",
    "is_L_pf_only = np.logical_and(np.logical_not(neuron_replay_stats_df['has_short_pf']), neuron_replay_stats_df['has_long_pf'])\n",
    "is_L_only = neuron_replay_stats_df.track_membership == SplitPartitionMembership.LEFT_ONLY\n",
    "assert (is_L_pf_only == is_L_only).all()\n",
    "L_only_aclus = neuron_replay_stats_df.index[is_L_only].to_numpy()\n",
    "neuron_replay_stats_df[is_L_only]\n",
    "\n",
    "\n",
    "## For ('kdiba', 'gor01', 'one', '2006-6-09_1-22-43') - Have L-only cells [24, 98] that have ['short_num_replays'] = [8, 7]. We were hoping that there would be few to no replays on the S-track that involved L-only cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3bdd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2023-05-23 - Get Common (SHARED) placefields\n",
    "## Goal 1: From the cells with the placefields on both tracks, compute the degree to which they remap in position and sort them according to their distance.\n",
    "is_BOTH_pf_only = np.logical_and(neuron_replay_stats_df['has_short_pf'], neuron_replay_stats_df['has_long_pf']) # (63,)\n",
    "BOTH_pf_only_aclus = neuron_replay_stats_df.index[is_BOTH_pf_only].to_numpy()\n",
    "\n",
    "## NOTE: is_BOTH_pf_only is a much more stringent requirement (and a strict subset) than `is_BOTH_only`\n",
    "is_BOTH_only = neuron_replay_stats_df.track_membership == SplitPartitionMembership.SHARED # (99,)\n",
    "BOTH_only_aclus = neuron_replay_stats_df.index[is_BOTH_only].to_numpy()\n",
    "assert BOTH_only_aclus.shape[0] >= BOTH_pf_only_aclus.shape[0]\n",
    "\n",
    "BOTH_pf_only_df = neuron_replay_stats_df[is_BOTH_pf_only].copy()\n",
    "BOTH_pf_only_df['long_short_pf_peak_x_displacement'] = BOTH_pf_only_df['long_pf_peak_x'].values - BOTH_pf_only_df['short_pf_peak_x'].values\n",
    "BOTH_pf_only_df['long_short_pf_peak_x_distance'] = BOTH_pf_only_df['long_short_pf_peak_x_displacement'].abs()\n",
    "BOTH_pf_only_df.sort_values(by=['long_short_pf_peak_x_distance'], inplace=True, ascending=False)\n",
    "BOTH_pf_only_df\n",
    "\n",
    "#TODO 2023-05-23 - Can do more detailed peaks analysis with: long_results.RatemapPeaksAnalysis and short_results.RatemapPeaksAnalysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f51c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 24 cells, 133 Epochs, 789 Total Timebins\n",
    "# Other\n",
    "\t\n",
    "\t- is_non_firing_time_bin: numpy.ndarray - (24, 789)\n",
    "\t- all_epochs_num_epoch_time_bins: numpy.ndarray - (133,)\n",
    "\t\n",
    "    ## Indexing Helpers:\n",
    "\t\t- all_epochs_reverse_flat_epoch_indicies_array: numpy.ndarray - (789,)\n",
    "\t\t- split_by_epoch_reverse_flattened_time_bin_indicies: list - (133,)\n",
    "    \n",
    "\t- original_1D_decoder: pyphoplacecellanalysis.Analysis.Decoder.reconstruction.BasePositionDecoder\n",
    "\t\t- pf: neuropy.analyses.placefields.PfND\n",
    "\t\t- neuron_IDXs: numpy.ndarray - (24,)\n",
    "\t\t- neuron_IDs: numpy.ndarray - (24,)\n",
    "\t\t- F: numpy.ndarray - (119, 24)\n",
    "\t\t- P_x: numpy.ndarray - (119, 1)\n",
    "        \n",
    "\t- flat_all_epochs_decoded_epoch_time_bins: numpy.ndarray - (24, 789)\n",
    "\n",
    "# Measured\n",
    "\t- flat_all_epochs_measured_cell_spike_counts: numpy.ndarray - (24, 789)\n",
    "\t- flat_all_epochs_measured_cell_firing_rates: numpy.ndarray - (24, 789)\n",
    "\n",
    "\n",
    "# Expected\n",
    "\t- flat_all_epochs_computed_expected_cell_firing_rates: numpy.ndarray - (24, 789)\n",
    "\t- flat_all_epochs_difference_from_expected_cell_spike_counts: numpy.ndarray - (24, 789)\n",
    "\t- flat_all_epochs_difference_from_expected_cell_firing_rates: numpy.ndarray - (24, 789)\n",
    "    \n",
    "    \n",
    "    \n",
    "## Epoch-based\n",
    "\t- all_epochs_decoded_epoch_time_bins_mean: numpy.ndarray - (133, 24)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "- flat_all_epochs_measured_cell_firing_rates: numpy.ndarray - .shape: (24, 789) \n",
    "- flat_all_epochs_computed_expected_cell_firing_rates: numpy.ndarray - .shape: (24, 789)\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b3a9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_results_obj.flat_all_epochs_computed_expected_cell_firing_rates\n",
    "long_results_obj.flat_all_epochs_measured_cell_firing_rates\n",
    "\n",
    "# long_results_obj.result_df_grouped\n",
    "\n",
    "\n",
    "measured_dfs = pd.DataFrame(long_results_obj.flat_all_epochs_measured_cell_firing_rates.T, columns=long_results_obj.original_1D_decoder.neuron_IDs)\n",
    "expected_dfs = pd.DataFrame(long_results_obj.flat_all_epochs_computed_expected_cell_firing_rates.T, columns=long_results_obj.original_1D_decoder.neuron_IDs)\n",
    "# pd.DataFrame(np.stack((long_results_obj.flat_all_epochs_measured_cell_firing_rates, long_results_obj.flat_all_epochs_computed_expected_cell_firing_rates)), columns=['measured_fr', 'expected_fr'])\n",
    "measured_dfs.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8566f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.neuron_replay_stats_df.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cdb9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import compute_evening_morning_parition\n",
    "\n",
    "difference_sorted_aclus, evening_sorted_aclus, morning_sorted_aclus = compute_evening_morning_parition(neuron_replay_stats_df, debug_print=True)\n",
    "sorted_neuron_replay_stats_df = neuron_replay_stats_df.reindex(difference_sorted_aclus).copy() # This seems to work to re-sort the dataframe by the sort indicies\n",
    "sorted_neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7524856f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.neurons import NeuronType\n",
    "\n",
    "%matplotlib qt\n",
    "# Look at replays during ripples vs. those not during ripples. Also potentially PBEs vs. not PBEs.\n",
    "\n",
    "# NeuronType.from_any_string_series(['pyr','intr'])\n",
    "'pyr','cont','intr'\n",
    "\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "curr_active_pipeline.display('_display_jonathan_interactive_replay_firing_rate_comparison', active_identifying_session_ctx, included_neuron_types=NeuronType.from_any_string_series(['pyr'])) # only the pyramidal neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7ebf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f61971",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display('_display_jonathan_interactive_replay_firing_rate_comparison', active_identifying_session_ctx, included_neuron_types=NeuronType.from_any_string_series(['intr']), require_placefield=False) # only the pyramidal neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0859e13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import build_replays_custom_scatter_markers, CustomScatterMarkerMode\n",
    "\n",
    "_curr_included_aclus = jonathan_firing_rate_analysis_result.neuron_replay_stats_df[np.logical_or(jonathan_firing_rate_analysis_result.neuron_replay_stats_df['has_long_pf'], jonathan_firing_rate_analysis_result.neuron_replay_stats_df['has_short_pf'])].index.to_numpy()\n",
    "_curr_output = curr_active_pipeline.display('_display_batch_pho_jonathan_replay_firing_rate_comparison', active_identifying_session_ctx, included_unit_neuron_IDs=_curr_included_aclus, marker_split_mode=CustomScatterMarkerMode.NoSplit)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d69eed8a",
   "metadata": {},
   "source": [
    "## 2023-04-13 - Shuffled Surprise\n",
    "\"\"\" \n",
    "Relevant Functions:\n",
    "`perform_full_session_leave_one_out_decoding_analysis`:\n",
    "\t`perform_leave_one_aclu_out_decoding_analysis`:\tfrom pyphoplacecellanalysis.Analysis.Decoder.decoder_result import perform_leave_one_aclu_out_decoding_analysis\n",
    "\t`_analyze_leave_one_out_decoding_results`: from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.DefaultComputationFunctions import _analyze_leave_one_out_decoding_results\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aac42d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023-04-18 - Refactored into decoder_result\n",
    "result, result_df, result_df_grouped = long_results_obj.result, long_results_obj.result_df, long_results_obj.result_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c107570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import DiagnosticDistanceMetricFigure\n",
    "\n",
    "## Render the internactive slider that allows selecting the timebin index to debug\n",
    "n_timebins = np.sum(long_results_obj.all_epochs_num_epoch_time_bins)\n",
    "timebinned_neuron_info = long_results_obj.timebinned_neuron_info\n",
    "result = long_results_obj.new_result\n",
    "active_fig_obj, update_function = DiagnosticDistanceMetricFigure.build_interactive_diagnostic_distance_metric_figure(long_results_obj, timebinned_neuron_info, result)\n",
    "active_fig_obj.integer_slider(n_timebins=n_timebins, update_func=update_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7670bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Get set of cells active in a given time bin, for each compute the surprise of its placefield with the leave-one-out decoded posterior.\n",
    "\n",
    "# 2. From the remainder of cells (those not active), randomly choose one to grab the placefield of and compute the surprise with that and the same posterior.\n",
    "\n",
    "# Expectation: The cells that are included in the time bin are expected to have a lower surprise (be less correlated with) the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1692fd1",
   "metadata": {
    "tags": [
     "active"
    ]
   },
   "outputs": [],
   "source": [
    "win, plots = plot_long_short_surprise_difference_plot(curr_active_pipeline, long_results_obj, short_results_obj, long_epoch_name, short_epoch_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118c3089",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_results_obj.timebinned_neuron_info.n_timebins # 736\n",
    "short_results_obj.timebinned_neuron_info.n_timebins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893964b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_results_obj.flat_all_epochs_measured_cell_firing_rates.shape # (30, 736)\n",
    "# short_results_obj.flat_all_epochs_measured_cell_firing_rates.shape # (30, 736)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae2e695",
   "metadata": {
    "tags": [
     "active",
     "NOW_05-25",
     "expected_vs_observed"
    ]
   },
   "outputs": [],
   "source": [
    "win, plots_tuple, legend = plot_long_short_expected_vs_observed_firing_rates(long_results_obj, short_results_obj, limit_aclus=list(BOTH_pf_only_df.index[:2].values))\n",
    "long_epoch_indicator_region_items, short_epoch_indicator_region_items = _helper_add_long_short_session_indicator_regions(win, long_epoch=curr_active_pipeline.filtered_epochs[long_epoch_name], short_epoch=curr_active_pipeline.filtered_epochs[short_epoch_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f55bb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot # works pretty well seemingly\n",
    "\n",
    "export_pyqtgraph_plot(win)\n",
    "# pg.setConfigOption('leftTitle', 'MathText')\n",
    "# win.setTitle(r'JSD(p_x_given_n, pf[<font size=\"4\"><b><span style=\"color:red;\">i</span></b></font>]) - JSD(p_x_given_n, pf[<font size=\"4\"><b>j</b></font>]) where <font size=\"4\"><b>j</b></font> non-firing')\n",
    "\n",
    "# win.setTitle(generate_html_string(f'JSD(p_x_given_n, pf[{i_str}]) - JSD(p_x_given_n, pf[{j_str}]) where {j_str} non-firing', font_size=8))\n",
    "\n",
    "# r'$\\fn{JSD}{\\matr{pf}_{i}, \\Pr{\\vec{x}_{t}|\\vec{n}_{t}}} - \\fn{JSD}{\\matr{pf}_{j}, \\Pr{\\vec{x}_{t}|\\vec{n}_{t}}}$'\n",
    "# title_str"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f996fd9",
   "metadata": {},
   "source": [
    "## Pre 2023-04-13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b6ac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import plot_kourosh_activity_style_figure\n",
    "\n",
    "from neuropy.core.neurons import NeuronType\n",
    "# # Include only pyramidal aclus:\n",
    "# print(f'all shared_aclus: {len(shared_aclus)}\\nshared_aclus: {shared_aclus}')\n",
    "# shared_aclu_neuron_type = long_session.neurons.neuron_type[np.isin(long_session.neurons.neuron_ids, shared_aclus)]\n",
    "# assert len(shared_aclu_neuron_type) == len(shared_aclus)\n",
    "# # Find only the aclus that are pyramidal:\n",
    "# is_shared_aclu_pyramidal = (shared_aclu_neuron_type == NeuronType.PYRAMIDAL)\n",
    "# pyramidal_only_shared_aclus = shared_aclus[is_shared_aclu_pyramidal]\n",
    "# print(f'num pyramidal_only_shared_aclus: {len(pyramidal_only_shared_aclus)}\\npyramidal_only_shared_aclus: {pyramidal_only_shared_aclus}')\n",
    "\n",
    "\n",
    "## Drop Pyramidal but don't use only shared aclus:\n",
    "all_aclus = deepcopy(long_session.neurons.neuron_ids)\n",
    "neuron_type = long_session.neurons.neuron_type\n",
    "assert len(neuron_type) == len(all_aclus)\n",
    "# Find only the aclus that are pyramidal:\n",
    "is_aclu_pyramidal = (neuron_type == NeuronType.PYRAMIDAL)\n",
    "pyramidal_only_all_aclus = all_aclus[is_aclu_pyramidal]\n",
    "print(f'num pyramidal_only_all_aclus: {len(pyramidal_only_all_aclus)}\\npyramidal_only_all_aclus: {pyramidal_only_all_aclus}')\n",
    "\n",
    "is_aclu_interneuron = (neuron_type == NeuronType.INTERNEURONS)\n",
    "interneuron_only_all_aclus = all_aclus[is_aclu_interneuron]\n",
    "print(f'num interneuron_only_all_aclus: {len(interneuron_only_all_aclus)}\\ninterneurons: {interneuron_only_all_aclus}')\n",
    "\n",
    "# app, win, plots, plots_data = plot_kourosh_activity_style_figure(long_results_obj, long_session, shared_aclus, epoch_idx=5, callout_epoch_IDXs=[0,1,2,3], skip_rendering_callouts=True)\n",
    "# app, win, plots, plots_data = plot_kourosh_activity_style_figure(long_results_obj, long_session, pyramidal_only_shared_aclus, epoch_idx=2, callout_epoch_IDXs=[0,4], skip_rendering_callouts=False)\n",
    "app, win, plots, plots_data = plot_kourosh_activity_style_figure(long_results_obj, long_session, pyramidal_only_all_aclus, epoch_idx=6, callout_epoch_IDXs=[2,4,6], skip_rendering_callouts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985977d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use the Jupyter Index Thing\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import DiagnosticDistanceMetricFigure\n",
    "\n",
    "## Render the internactive slider that allows selecting the timebin index to debug\n",
    "n_timebins = np.sum(long_results_obj.all_epochs_num_epoch_time_bins)\n",
    "timebinned_neuron_info = long_results_obj.timebinned_neuron_info\n",
    "result = long_results_obj.new_result\n",
    "active_fig_obj, update_function = DiagnosticDistanceMetricFigure.build_interactive_diagnostic_distance_metric_figure(long_results_obj, timebinned_neuron_info, result)\n",
    "active_fig_obj.integer_slider(n_timebins=n_timebins, update_func=update_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1aa692",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_fig_obj.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea983fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "app, win, self.plots, self.plots_data = plot_kourosh_activity_style_figure(long_results_obj, long_session, pyramidal_only_all_aclus, epoch_idx=11, callout_epoch_IDXs=[0,1,2, 3, 4, 5], skip_rendering_callouts=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f519e392",
   "metadata": {},
   "source": [
    "# 2023-04-13 Show Surprise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b417bb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.MultiContextComparingDisplayFunctions import plot_long_short, plot_long_short_any_values, plot_long_short_expected_vs_observed_firing_rates, _helper_add_long_short_session_indicator_regions\n",
    "# plot_long_short(long_results_obj, short_results_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feefc5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_long_short_any_values(long_results_obj=long_results_obj, short_results_obj=short_results_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b8a7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_long_short_expected_vs_observed_firing_rates(long_results_obj=long_results_obj, short_results_obj=short_results_obj, limit_aclus=[89]) # 4, 89, 28, 97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdf68bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fn = lambda a_results_obj: a_results_obj.all_epochs_decoded_epoch_time_bins_mean[:,0]\n",
    "# y_fn = lambda a_results_obj: a_results_obj.all_epochs_all_cells_one_left_out_posterior_to_scrambled_pf_surprises_mean\n",
    "y_fn = lambda a_results_obj: a_results_obj.all_epochs_all_cells_one_left_out_posterior_to_pf_surprises_mean\n",
    "# y_fn = lambda a_results_obj: a_results_obj.all_epochs_computed_one_left_out_posterior_to_pf_surprises\n",
    "\n",
    "# (time_bins, neurons), (epochs, neurons), (epochs)\n",
    "# all_epochs_computed_one_left_out_posterior_to_pf_surprises, all_epochs_computed_cell_one_left_out_posterior_to_pf_surprises_mean, all_epochs_all_cells_one_left_out_posterior_to_pf_surprises_mean\n",
    "win, plots_tuple, legend = plot_long_short_any_values(long_results_obj, short_results_obj, x=x_fn, y=y_fn, limit_aclus=[20])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2fe80559",
   "metadata": {},
   "source": [
    "# 2023-04-13 - Find Good looking epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa9a519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "from pyphocorehelpers.plotting.figure_management import PhoActiveFigureManager2D\n",
    "from pyphoplacecellanalysis.GUI.Qt.Mixins.PaginationMixins import PaginatedFigureController\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import DecodedEpochSlicesPaginatedFigureController\n",
    "\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context()\n",
    "_out_pagination_controller = DecodedEpochSlicesPaginatedFigureController.init_from_decoder_data(long_results_obj.active_filter_epochs, long_results_obj.all_included_filter_epochs_decoder_result, \n",
    "\txbin=long_results_obj.original_1D_decoder.xbin, global_pos_df=global_session.position.df, a_name='TestDecodedEpochSlicesPaginationController', active_context=active_identifying_session_ctx,  max_subplots_per_page=10)\n",
    "# _out_pagination_controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa14005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out_pagination_controller.params.debug_print = True\n",
    "_pagination_widget = _out_pagination_controller.ui.mw.ui.paginator_controller_widget\n",
    "_pagination_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2443fed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test rendering multiple figures sequentially:\n",
    "list(_out_pagination_controller.plots_data.keys())\n",
    "\n",
    "# _out_pagination_controller.on_paginator_control_widget_jump_to_page()\n",
    "\n",
    "_out_pagination_controller.params.active_identifying_figure_ctx\n",
    "# _out_pagination_controller.params.variable_name\n",
    "_out_pagination_controller.plots_data.paginator.num_pages\n",
    "\n",
    "# `included_combined_indicies_pages` is what was used in the other `BatchPhoJonathanFiguresHelper._build_batch_plot_kwargs(...)` call\n",
    "included_combined_indicies_pages = _out_pagination_controller.plots_data.paginator.included_combined_indicies_pages\n",
    "_out_pagination_controller.plots_data.paginator.subplot_no_pagination_configuration\n",
    "\n",
    "fig = _out_pagination_controller.plots.fig\n",
    "# _out_pagination_controller.plots.figure_id\n",
    "# _out_pagination_controller.plots.name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a9a5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_linear_fit_df.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f0018ec",
   "metadata": {},
   "source": [
    "### 2023-05-30 - Add the radon-transformed linear fits to each epoch to the stacked epoch plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d24f3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert long_results_obj.all_included_filter_epochs_decoder_result.num_filter_epochs == np.shape(epochs_linear_fit_df)[0]\n",
    "\n",
    "radon_transform_plots = []\n",
    "_out_pagination_controller.plots_data.radon_transform_line_data = []\n",
    "\n",
    "for epoch_idx, epoch_vel, epoch_intercept in zip(np.arange(long_results_obj.all_included_filter_epochs_decoder_result.num_filter_epochs), epochs_linear_fit_df['velocity'].values, epochs_linear_fit_df['intercept'].values):\n",
    "    # build the discrete line over the centered time bins:\n",
    "    epoch_time_bins = long_results_obj.all_included_filter_epochs_decoder_result.time_bin_containers[epoch_idx].centers\n",
    "    epoch_time_bins = epoch_time_bins - epoch_time_bins[0] # all values should be relative to the start of the epoch:\n",
    "    epoch_line_eqn = (epoch_vel * epoch_time_bins) + epoch_intercept\n",
    "    _out_pagination_controller.plots_data.radon_transform_line_data.append(epoch_line_eqn)\n",
    "\n",
    "def _callback_update_decoded_single_epoch_slice_plot(curr_ax, params: \"VisualizationParameters\", plots_data: \"RenderPlotsData\", plots: \"RenderPlots\", ui: \"PhoUIContainer\", i:int, curr_time_bins, *args, **kwargs): # curr_posterior, curr_most_likely_positions, debug_print:bool=False\n",
    "    \"\"\" 2023-05-30 - Based off of `_helper_update_decoded_single_epoch_slice_plot` to enable plotting radon transform lines on paged decoded epochs\n",
    "\n",
    "    Needs only: curr_time_bins, plots_data, i\n",
    "    Accesses: plots_data.epoch_slices[i,:], plots_data.global_pos_df, params.variable_name, params.xbin, params.enable_flat_line_drawing\n",
    "    \"\"\"\n",
    "    debug_print = kwargs.pop('debug_print', False)\n",
    "    if debug_print:\n",
    "        print(f'_callback_update_decoded_single_epoch_slice_plot(..., i: {i}, curr_time_bins: {curr_time_bins})')\n",
    "    # plot the radon transform line on the epoch:\n",
    "    radon_transform_plot = curr_ax.plot(curr_time_bins, plots_data.radon_transform_line_data[i], label=f'computed radon transform', linestyle='dashed', linewidth=3, color='#e5ff00', alpha=0.8, marker='+', markersize=10) # Opaque RED # , linestyle='dashed', linewidth=2, color='#ff0000ff'\n",
    "    if debug_print:\n",
    "        print(f'\\t success!')\n",
    "    return params, plots_data, plots, ui\n",
    "\n",
    "\n",
    "# .params.on_render_page_callbacks: a dict of callbacks to be called when the page changes and needs to be re-rendered\n",
    "on_render_page_callbacks = _out_pagination_controller.params.get('on_render_page_callbacks', None)\n",
    "if on_render_page_callbacks is None:\n",
    "    _out_pagination_controller.params.on_render_page_callbacks = {} # allocate a new list\n",
    "## add or update this callback:\n",
    "_out_pagination_controller.params.on_render_page_callbacks['plot_radon_transform_line_data'] = _callback_update_decoded_single_epoch_slice_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a26325",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_pagination_controller.plots.fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d1db39",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_pagination_controller.ui.mw.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d526f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .\n",
    "\n",
    "current_page_idx = _out_pagination_controller.ui.mw.ui.paginator_controller_widget.current_page_idx\n",
    "curr_page_data_indicies, curr_page_data_items =  _out_pagination_controller.plots_data.paginator.get_page_data(page_idx=current_page_idx)\n",
    "print(f'current_page_idx: {current_page_idx}, curr_page_data_indicies: {curr_page_data_indicies}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c30bfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_pagination_controller.on_paginator_control_widget_jump_to_page(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1ace00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.indexing_helpers import safe_find_index_in_list\n",
    "\n",
    "def _get_current_page_data_indicies():\n",
    "\t\"\"\" captures `ui.mw.ui.paginator_controller_widget.current_page_idx`, `plots_data.paginator` \"\"\"\n",
    "\tcurrent_page_idx = _out_pagination_controller.ui.mw.ui.paginator_controller_widget.current_page_idx\n",
    "\tcurr_page_data_indicies, curr_page_data_items =  _out_pagination_controller.plots_data.paginator.get_page_data(page_idx=current_page_idx)\n",
    "\treturn current_page_idx, curr_page_data_indicies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e6526e9",
   "metadata": {},
   "source": [
    "# 2023-03-28 - Playing around with older computations/visualizations from the `_display_short_long_firing_rate_index_comparison` era:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a13cccd",
   "metadata": {},
   "source": [
    "# Plot long|short firing rate index using 'long_short_fr_indicies_analyses':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caab469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_save_parent_path = Path(r'E:\\Dropbox (Personal)\\Active\\Kamran Diba Lab\\Results from 2023-01-20 - LongShort Firing Rate Indicies')\n",
    "## Get the output path (active_session_figures_out_path) for this session (and all of its filtered_contexts as well):\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "figures_parent_out_path = create_daily_programmatic_display_function_testing_folder_if_needed()\n",
    "active_session_figures_out_path = session_context_to_relative_path(figures_parent_out_path, active_identifying_session_ctx)\n",
    "print(f'curr_session_parent_out_path: {active_session_figures_out_path}')\n",
    "active_session_figures_out_path.mkdir(parents=True, exist_ok=True) # make folder if needed\n",
    "curr_active_pipeline.display('_display_short_long_firing_rate_index_comparison', curr_active_pipeline.sess.get_context(), fig_save_parent_path=active_session_figures_out_path)\n",
    "# plt.close() # closes the current figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71511c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display('_display_short_long_firing_rate_index_comparison', long_short_fr_indicies_analysis_results['active_context'], fig_save_parent_path=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e5e3dc",
   "metadata": {
    "tags": [
     "NOW_05_25"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# configure backend here\n",
    "# matplotlib.use('Qt5Agg')\n",
    "# backend_qt5agg\n",
    "matplotlib.use('Qt5Agg') # non-interactive backend ## 2022-08-16 - Surprisingly this works to make the matplotlib figures render only to .png file, not appear on the screen!\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import _plot_long_short_firing_rate_indicies\n",
    "\n",
    "\n",
    "# Plot long|short firing rate index:\n",
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "x_frs_dict, y_frs_dict = long_short_fr_indicies_analysis_results['x_frs_index'], long_short_fr_indicies_analysis_results['y_frs_index'] # use the all_results_dict as the computed data value\n",
    "active_context = long_short_fr_indicies_analysis_results['active_context']\n",
    "fig, _temp_full_fig_save_path = _plot_long_short_firing_rate_indicies(x_frs_dict, y_frs_dict, active_context, fig_save_parent_path=None, debug_print=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fcb225",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.gca()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7a776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.spines[['top', 'right']].set_visible(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0165676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_long_short_firing_rate_analyses'], fail_on_exception=True, debug_print=False) # fail_on_exception MUST be True or error handling is all messed up \n",
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "x_frs_dict, y_frs_dict = long_short_fr_indicies_analysis_results['x_frs_index'], long_short_fr_indicies_analysis_results['y_frs_index'] # use the all_results_dict as the computed data value\n",
    "active_context = long_short_fr_indicies_analysis_results['active_context']\n",
    "long_short_fr_indicies_analysis_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0409e08",
   "metadata": {},
   "source": [
    "# Other Programmatic Figures"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ecc42a2",
   "metadata": {},
   "source": [
    "### 2023-05-25 - Neptune Figure Uploads from `registered_output_files`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f32c5ea",
   "metadata": {
    "tags": [
     "NOW_05-25"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveWrapper import neptune_output_figures\n",
    "\n",
    "# curr_active_pipeline.registered_output_files\n",
    "# curr_active_pipeline.register_output_file(output_path=test_path, output_metadata={})\n",
    "\n",
    "neptune_output_figures(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86bf7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_output_files\n",
    "# curr_active_pipeline.registered_output_files_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a53d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import create_daily_programmatic_display_function_testing_folder_if_needed, session_context_to_relative_path, programmatic_display_to_PDF\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import build_pdf_metadata_from_display_context # newer version of build_pdf_export_metadata\n",
    "from neuropy.core.neuron_identities import PlotStringBrevityModeEnum\n",
    "from neuropy.plotting.ratemaps import BackgroundRenderingOptions\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "mpl.rcParams['toolbar'] = 'None' # disable toolbars\n",
    "matplotlib.use('AGG') # non-interactive backend ## 2022-08-16 - Surprisingly this works to make the matplotlib figures render only to .png file, not appear on the screen!\n",
    "# active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "# programmatic_display_to_PDF(curr_active_pipeline, curr_display_function_name='_display_1d_placefields', debug_print=False) #  Now seems to be working and saving to PDF!! Still using matplotlib.use('Qt5Agg') mode and plots still appear.\n",
    "# programmatic_display_to_PDF(curr_active_pipeline, curr_display_function_name='_display_1d_placefield_validations') # , filter_name=active_config_name  Now seems to be working and saving to PDF!! Still using matplotlib.use('Qt5Agg') mode and plots still appear. Moderate visual improvements can still be made (titles overlap and stuff). Works with %%capture\n",
    "# programmatic_display_to_PDF(curr_active_pipeline, curr_display_function_name='_display_2d_placefield_result_plot_ratemaps_2D') #   Now seems to be working and saving to PDF!! Still using matplotlib.use('Qt5Agg') mode and plots still appear.\n",
    "programmatic_display_to_PDF(curr_active_pipeline, curr_display_function_name='_display_2d_placefield_occupancy') #   Now seems to be working and saving to PDF!! Still using matplotlib.use('Qt5Agg') mode and plots still appear.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a5a83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "active_identifying_session_ctx, active_session_figures_out_path, active_out_figures_list = batch_programmatic_figures(curr_active_pipeline)\n",
    "batch_extended_programmatic_figures(curr_active_pipeline=curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7172c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_helper = curr_active_pipeline.plot\n",
    "curr_active_pipeline.registered_display_function_docs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2926235",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display_output_history_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933f9937",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cbba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# '_display_2d_placefield_result_plot_ratemaps_2D'\n",
    "# %matplotlib inline\n",
    "%matplotlib qt\n",
    "# curr_active_pipeline.display('_display_2d_placefield_result_plot_ratemaps_2D', long_epoch_context) # MatplotlibRenderPlots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48029c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# long_pf2D.plot_occupancy()\n",
    "_out = short_one_step_decoder_2D.pf.plot_ratemaps_2D(included_unit_neuron_IDs=[2,4,5], bg_rendering_mode=BackgroundRenderingOptions.EMPTY, use_special_overlayed_title=False, missing_aclu_string_formatter=None, debug_print=False, brev_mode=PlotStringBrevityModeEnum.NONE)\n",
    "\n",
    "## Single column output: subplots=(None, 9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14977e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "active_display_to_pdf_fn(curr_active_pipeline, curr_display_function_name='_display_1d_placefields', debug_print=False) #  Now seems to be working and saving to PDF!! Still using matplotlib.use('Qt5Agg') mode and plots still appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2686e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_shared_aclus_only_decoder.pf.plot_occupancy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ae6c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "long_one_step_decoder_2D.pf.plot_occupancy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8006610",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_one_step_decoder_2D.pf.plot_ratemaps_2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49dcc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.display('_display_short_long_pf1D_comparison', active_session_configuration_context=global_epoch_context, single_figure=False)\n",
    "\n",
    "short_one_step_decoder_1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402834bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "\n",
    "long_single_cell_pfmap_processing_fn = None\n",
    "short_single_cell_pfmap_processing_fn = None\n",
    "sort_idx = None\n",
    "\n",
    "out = curr_active_pipeline.display('_display_short_long_pf1D_comparison', active_identifying_session_ctx, single_figure=False, debug_print=False, fignum='Short v Long pf1D Comparison',\n",
    "                                   long_kwargs={'sortby': sort_idx, 'single_cell_pfmap_processing_fn': long_single_cell_pfmap_processing_fn},\n",
    "                                   short_kwargs={'sortby': sort_idx, 'single_cell_pfmap_processing_fn': short_single_cell_pfmap_processing_fn, 'curve_hatch_style': {'hatch':'///', 'edgecolor':'k'}},\n",
    "                                  )\n",
    "\n",
    "# ax = out.axes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cfbb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_idx = np.argsort(product_overlap_scalars_df.prod_overlap.to_numpy())[::-1] # the `[::-1]` term reverses the array, which by defaul is returned in ascending order and we want descending\n",
    "sort_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe831b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_ratemap = long_one_step_decoder_1D.pf.ratemap\n",
    "curr_ratemap.get_sort_indicies()\n",
    "# .pf1D.ratemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23228854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create `master_dock_win` - centralized plot output window to collect individual figures/controls in (2022-08-18)\n",
    "\n",
    "active_identifying_session_ctx = curr_active_pipeline.filtered_contexts['maze']\n",
    "display_output = curr_active_pipeline.display('_display_context_nested_docks', active_identifying_session_ctx, enable_gui=False, debug_print=True) # returns {'master_dock_win': master_dock_win, 'app': app, 'out_items': out_items}\n",
    "master_dock_win = display_output['master_dock_win']\n",
    "app = display_output['app']\n",
    "out_items = display_output['out_items']\n",
    "\n",
    "# def _get_curr_figure_format_config():\n",
    "# \t\"\"\" Aims to fetch the current figure_format_config and context from the figure_format_config widget:    \n",
    "# \tImplicitly captures: `out_items`, `active_config_name`, `active_identifying_filtered_session_ctx` \n",
    "# \t\"\"\"\n",
    "# \t## Get the figure_format_config from the figure_format_config widget:\n",
    "# \t# Fetch the context from the GUI:\n",
    "# \t_curr_gui_session_ctx, _curr_gui_out_display_items = out_items[active_config_name]\n",
    "# \t_curr_gui_figure_format_config_widget = _curr_gui_out_display_items[active_identifying_filtered_session_ctx.adding_context('display_fn', display_fn_name='figure_format_config_widget')] # [0] is seemingly not needed to unpack the tuple\n",
    "# \tif _curr_gui_figure_format_config_widget is not None:\n",
    "# \t\t# has GUI for config\n",
    "# \t\tfigure_format_config = _curr_gui_figure_format_config_widget.figure_format_config\n",
    "# \telse:\n",
    "# \t\t# has non-GUI provider of figure_format_config\n",
    "# \t\tfigure_format_config = _curr_gui_figure_format_config_widget.figure_format_config\n",
    "\n",
    "# \tif debug_print:\n",
    "# \t\tprint(f'recovered gui figure_format_config: {figure_format_config}')\n",
    "\n",
    "# \treturn figure_format_config\n",
    "\n",
    "# figure_format_config = _get_curr_figure_format_config()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1e8629a",
   "metadata": {},
   "source": [
    "# 2023-04-27 - Idea: Candidate Replay \"Quality\" Metric\n",
    "Observed that I visually distinguish \"good\" replays from bad ones based on their mostly-monotonically increasing nature.\n",
    "\n",
    "#### They don't have to:\n",
    "\tSpan the whole track\n",
    "\tStart or end at an end-cap\n",
    "\tIncrease linearly\n",
    "\n",
    "#### The algorithm must:\n",
    "\ttolerate ocasional jumps in an otherwise linear sequence\n",
    "\tallow sequences to \"start\" only halfway through. They should extract out the coherent sequence\n",
    "\n",
    "#### Ideas:\n",
    "\t- just a linear fit\n",
    "\t- a monotonicity check using some sort of cumulative sum over the differences in position.\n",
    "\t- \"radon transform\"?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8fad7d0f",
   "metadata": {
    "tags": [
     "radon_transform",
     "testing"
    ]
   },
   "source": [
    "# 20230-05-25 - Radon Transform approach to finding line of best fit for each replay Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b5fbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import get_radon_transform\n",
    "\n",
    "## 2023-05-25 - Get the 1D Posteriors for each replay epoch so they can be analyzed via score_posterior(...) with a Radon Transform approch to find the line of best fit (which gives the velocity).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "active_epoch_decoder_result = long_results_obj.all_included_filter_epochs_decoder_result\n",
    "epochs_linear_fit_df = compute_radon_transforms(active_epoch_decoder_result)\n",
    "epochs_linear_fit_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de511aa5",
   "metadata": {},
   "source": [
    "# 2023-05-02 - Session Validation Check Info\n",
    "Generate info about the number of laps detected, the duration, the number of cells, the number of replays, etc for the active session so that it can be ensured that there wasn't an error that is messing up the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15697281",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.active_sess_config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5045805",
   "metadata": {},
   "source": [
    "# Pipeline Comprehensive:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c49561b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Top level objects:\n",
    "curr_active_pipeline.active_sess_config\n",
    "curr_active_pipeline.sess\n",
    "\n",
    "\n",
    "\n",
    "# Function of config names or contexts:\n",
    "curr_active_pipeline.filtered_contexts\n",
    "\n",
    "curr_active_pipeline.filtered_sessions\n",
    "curr_active_pipeline.active_configs # each is a `InteractivePlaceCellConfig` type object\n",
    "\tcurr_active_pipeline._stage.active_configs['maze1']\n",
    "\n",
    "\n",
    "\n",
    "curr_active_pipeline.computation_results\n",
    "\n",
    "\n",
    "curr_active_pipeline.global_computation_results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f30d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = curr_active_pipeline.sess\n",
    "sess.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05560f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import EpochsAccessor, Epoch\n",
    "\n",
    "sess = curr_active_pipeline.sess\n",
    "# sess.replay.epochs.debug_print_info('replays')\n",
    "\n",
    "\n",
    "def debug_print_session_epochs_info(sess, session_name:str):\n",
    "\t\"\"\" \n",
    "\n",
    "\tExample:\n",
    "\t\tdebug_print_session_epochs_info(curr_active_pipeline.sess, 'sess')\n",
    "\t\tdebug_print_session_epochs_info(long_session, 'long_session')\n",
    "\t\tdebug_print_session_epochs_info(short_session, 'short_session')\n",
    "\t\tdebug_print_session_epochs_info(global_session, 'global_session')\n",
    "\n",
    "\tsess:\n",
    "\t\tnum replays: 1729\n",
    "\t\tnum laps: 80\n",
    "\tlong_session:\n",
    "\t\tnum replays: 661\n",
    "\t\tnum laps: 40\n",
    "\tshort_session:\n",
    "\t\tnum replays: 1068\n",
    "\t\tnum laps: 40\n",
    "\tglobal_session:\n",
    "\t\tnum replays: 1729\n",
    "\t\tnum laps: 80\n",
    "\t\t\n",
    "\t\n",
    "\t\"\"\"\t\n",
    "\n",
    "\treplays_df = sess.replay\n",
    "\tlaps_df = sess.laps.as_epoch_obj().to_dataframe()\n",
    "\tprint(f'{session_name}:')\n",
    "\tprint(f'\\tnum replays: {replays_df.epochs.n_epochs}')\n",
    "\tprint(f'\\tnum laps: {laps_df.epochs.n_epochs}')\n",
    "\n",
    "# (long_one_step_decoder_1D, short_one_step_decoder_1D), (long_one_step_decoder_2D, short_one_step_decoder_2D) = compute_short_long_constrained_decoders(curr_active_pipeline, recalculate_anyway=True)\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_epoch_context, short_epoch_context, global_epoch_context = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_epoch_name, short_epoch_name, global_epoch_name)]\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "# long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "# long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "# long_pf2D, short_pf2D, global_pf2D = long_results.pf2D, short_results.pf2D, global_results.pf2D\n",
    "# decoding_time_bin_size = long_one_step_decoder_1D.time_bin_size # 1.0/30.0 # 0.03333333333333333\n",
    "\n",
    "debug_print_session_epochs_info(curr_active_pipeline.sess, 'sess')\n",
    "debug_print_session_epochs_info(long_session, 'long_session')\n",
    "debug_print_session_epochs_info(short_session, 'short_session')\n",
    "debug_print_session_epochs_info(global_session, 'global_session')\n",
    "\n",
    "\n",
    "# epoch_df = sess.laps.to_dataframe()\n",
    "\n",
    "# epoch_df.epochs.n_epochs\n",
    "\n",
    "# epoch_name = 'laps'\n",
    "# num_epochs = epoch_df.epochs.n_epochs # np.shape(epoch_df)[0]\n",
    "# print(f'num {epoch_name}: {num_epochs}')\n",
    "\n",
    "# sess.replay.to_dataframe()\n",
    "\n",
    "# def debug_print_session_epochs_info(num_updated_total_items: int, num_original_total_items: int, item_label=None, subsession_name=None):\n",
    "#     print('{}/{} total {} remain in subsession {}'.format(num_updated_total_items, num_original_total_items, (item_label or \"items\"), (subsession_name or \"\")))\n",
    "\n",
    "# debug_print_subsession_epochs_differences(num_updated_total_items=len(long_session.replay), num_original_total_items=len(long_session.replay_backup), item_label='replays', subsession_name='\"long\"')\n",
    "# debug_print_subsession_epochs_differences(num_updated_total_items=len(short_session.replay), num_original_total_items=len(short_session.replay_backup), item_label='replays', subsession_name='\"short\"')\n",
    "\n",
    "(long_epoch_name, short_epoch_name, global_epoch_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75cf03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BUG 2023-05-25 - Found ERROR for a loaded pipeline where for some reason the filtered_contexts[long_epoch_name]'s actual context was the same as the short maze ('...maze2'). Unsure how this happened.\n",
    "ctx = curr_active_pipeline.filtered_contexts[long_epoch_name]\n",
    "ctx.filter_name = long_epoch_name\n",
    "assert ctx.filter_name == long_epoch_name, f\"ctx.filter_name: {ctx.filter_name} != long_epoch_name: {long_epoch_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8874b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(curr_active_pipeline.active_configs.keys())\n",
    "list(curr_active_pipeline.filtered_sessions.keys())\n",
    "list(curr_active_pipeline.filtered_contexts.keys())\n",
    "# curr_active_pipeline.filtered_sessions\n",
    "curr_active_pipeline.filtered_contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed69eafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def debug_print_subsession_epochs_differences(num_updated_total_items: int, num_original_total_items: int, item_label=None, subsession_name=None):\n",
    "    print('{}/{} total {} remain in subsession {}'.format(num_updated_total_items, num_original_total_items, (item_label or \"items\"), (subsession_name or \"\")))\n",
    "\n",
    "debug_print_subsession_epochs_differences(num_updated_total_items=len(long_session.replay), num_original_total_items=len(long_session.replay_backup), item_label='replays', subsession_name='\"long\"')\n",
    "debug_print_subsession_epochs_differences(num_updated_total_items=len(short_session.replay), num_original_total_items=len(short_session.replay_backup), item_label='replays', subsession_name='\"short\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e67e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_print_subsession_epochs_differences(num_updated_total_items=len(long_session.laps), num_original_total_items=len(long_session.replay_backup), item_label='laps', subsession_name='\"long\"')\n",
    "debug_print_subsession_epochs_differences(num_updated_total_items=len(short_session.laps), num_original_total_items=len(short_session.replay_backup), item_label='laps', subsession_name='\"short\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f714aa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_num_rows = self.n_epochs        \n",
    "filtered_epochs = convert_PortionInterval_to_epochs_df(_convert_start_end_tuples_list_to_PortionInterval(zip(self.starts, self.stops)))\n",
    "after_num_rows = np.shape(filtered_epochs)[0]\n",
    "changed_num_rows = after_num_rows - before_num_rows\n",
    "print(f'Dataframe Changed from {before_num_rows} -> {after_num_rows} ({changed_num_rows = })')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8caf529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.debug_helpers import debug_print_placefield, debug_print_spike_counts, debug_print_subsession_neuron_differences, print_aligned_columns\n",
    "from neuropy.utils.misc import print_seconds_human_readable\n",
    "\n",
    "debug_print_spike_counts(global_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80205471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import _compare_computation_results\n",
    "# curr_active_pipeline.computation_results\n",
    "# pf_neurons_diff = _compare_computation_results(curr_active_pipeline.computation_results.maze1_PYR, curr_active_pipeline.computation_results.maze2_PYR)\n",
    "pf_neurons_diff = _compare_computation_results(long_results, short_results)\n",
    "pf_neurons_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0000ecb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pf_neurons_diff)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7125b9f7",
   "metadata": {},
   "source": [
    "### Plotting Validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b942014",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "short_one_step_decoder_1D.pf.plot_ratemaps_1D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfe7eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_results.pf1D_Decoder.pf.plot_ratemaps_1D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bed5960",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_results.pf2D_Decoder.pf.plot_ratemaps_2D()\n",
    "short_one_step_decoder_2D.pf.plot_ratemaps_2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ea99e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "long_session.plot_laps_2d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d18bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.laps import plot_laps_2d\n",
    "\n",
    "%matplotlib qt\n",
    "fig, out_axes_list = plot_laps_2d(global_session, legacy_plotting_mode=False)\n",
    "out_axes_list[0].set_title('New Pho Position Thresholding Estimated Laps')\n",
    "fig.canvas.manager.set_window_title('New Pho Position Thresholding Estimated Laps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae2e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Laps \n",
    "from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.Mixins.LapsVisualizationMixin import LapsVisualizationMixin\n",
    "\n",
    "curr_position_df, lap_specific_position_dfs = LapsVisualizationMixin._compute_laps_specific_position_dfs(curr_active_pipeline.sess)\n",
    "lap_specific_position_dfs = [curr_position_df.groupby('lap').get_group(i)[['t','x','y','lin_pos']] for i in curr_active_pipeline.sess.laps.lap_id] # dataframes split for each ID:\n",
    "laps_position_times_list = [np.squeeze(lap_pos_df[['t']].to_numpy()) for lap_pos_df in lap_specific_position_dfs]\n",
    "laps_position_traces_list = [lap_pos_df[['x','y']].to_numpy().T for lap_pos_df in lap_specific_position_dfs]\n",
    "## Build Epochs:\n",
    "epochs = curr_active_pipeline.sess.laps.to_dataframe()\n",
    "epoch_slices = epochs[['start', 'stop']].to_numpy()\n",
    "epoch_description_list = [f'lap {epoch_tuple.lap_id} (maze: {epoch_tuple.maze_id}, direction: {epoch_tuple.lap_dir})' for epoch_tuple in epochs[['lap_id','maze_id','lap_dir']].itertuples()]\n",
    "# print(f'epoch_description_list: {epoch_description_list}') # epoch_descriptions: ['lap 41 (maze: 2, direction: 1)', 'lap 42 (maze: 2, direction: 0)', 'lap 43 (maze: 2, direction: 1)', 'lap 44 (maze: 2, direction: 0)', 'lap 45 (maze: 2, direction: 1)', 'lap 46 (maze: 2, direction: 0)', 'lap 47 (maze: 2, direction: 1)', 'lap 48 (maze: 2, direction: 0)', 'lap 49 (maze: 2, direction: 1)', 'lap 50 (maze: 2, direction: 0)', 'lap 51 (maze: 2, direction: 1)', 'lap 52 (maze: 2, direction: 0)', 'lap 53 (maze: 2, direction: 1)', 'lap 54 (maze: 2, direction: 0)', 'lap 55 (maze: 2, direction: 1)', 'lap 56 (maze: 2, direction: 0)', 'lap 57 (maze: 2, direction: 1)', 'lap 58 (maze: 2, direction: 0)', 'lap 59 (maze: 2, direction: 1)', 'lap 60 (maze: 2, direction: 0)', 'lap 61 (maze: 2, direction: 1)', 'lap 62 (maze: 2, direction: 0)', 'lap 63 (maze: 2, direction: 1)', 'lap 64 (maze: 2, direction: 0)', 'lap 65 (maze: 2, direction: 1)', 'lap 66 (maze: 2, direction: 0)', 'lap 67 (maze: 2, direction: 1)', 'lap 68 (maze: 2, direction: 0)', 'lap 69 (maze: 2, direction: 1)', 'lap 70 (maze: 2, direction: 0)', 'lap 71 (maze: 2, direction: 1)', 'lap 72 (maze: 2, direction: 0)', 'lap 73 (maze: 2, direction: 1)', 'lap 74 (maze: 2, direction: 0)', 'lap 75 (maze: 2, direction: 1)', 'lap 76 (maze: 2, direction: 0)', 'lap 77 (maze: 2, direction: 1)', 'lap 78 (maze: 2, direction: 0)', 'lap 79 (maze: 2, direction: 1)']\n",
    "# -"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
