{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Typehints with semantic menaings:\n",
    "\n",
    "I desire typehints that specify semantic meanings in addition to their type, like for Dict and Tuples.\n",
    "\n",
    "I currently have a python dictionary named `sessions` of type `Dict[str, Tuple[Path, datetime]]`, an example entry would be: \n",
    "```python \n",
    "sessions['kdiba_gor01_one_2006-6-08_14-26-15']\n",
    ">> {'ripple_time_bin_marginals_df': (Path('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-01-24_0745AM-kdiba_gor01_one_2006-6-08_14-26-15-(ripple_time_bin_marginals_df).csv'),\n",
    "  datetime.datetime(2024, 1, 24, 7, 45)),\n",
    " 'ripple_marginals_df': (Path('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-01-24_0745AM-kdiba_gor01_one_2006-6-08_14-26-15-(ripple_marginals_df).csv'),\n",
    "  datetime.datetime(2024, 1, 24, 7, 45)),\n",
    " 'laps_time_bin_marginals_df': (Path('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-01-24_0745AM-kdiba_gor01_one_2006-6-08_14-26-15-(laps_time_bin_marginals_df).csv'),\n",
    "  datetime.datetime(2024, 1, 24, 7, 45)),\n",
    " 'laps_marginals_df': (Path('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-01-24_0745AM-kdiba_gor01_one_2006-6-08_14-26-15-(laps_marginals_df).csv'),\n",
    "  datetime.datetime(2024, 1, 24, 7, 45))}\n",
    "```\n",
    "I'd like to be able to specify the semantic menaing of the dictionary elements in the type definition, for reference later (documentation) and potentially (down the road) to enforce consistency by implementing checks on certain properties. I'm hoping for something like: `Dict[session_id:str, Tuple[file_path:Path, parsed_datetime:datetime]]` instead of `Dict[str, Tuple[Path, datetime]]`.\n",
    "\n",
    "Dict[str, Tuple[Path, datetime]]\n",
    "Dict[session_id:str, Tuple[file_path:Path, parsed_datetime:datetime]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: `typing.NewType` to define aliases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple, NewType\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# defining type aliases\n",
    "session_id = NewType('session_id', str)\n",
    "file_path = NewType('file_path', Path)\n",
    "parsed_datetime = NewType('parsed_datetime', datetime)\n",
    "\n",
    "# now you can define your dictionary in terms of these new types\n",
    "sessions: Dict[session_id, Tuple[file_path, parsed_datetime]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option 2: Inline `attrs` classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import attrs\n",
    "from collections import namedtuple\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import Zscorer\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import LongShortStatsTuple\n",
    "\n",
    "# dict(zip(['long_stats_z_scorer', 'short_stats_z_scorer', 'long_short_z_diff', 'long_short_naive_z_diff', 'is_forward_replay'], [Zscorer, Zscorer, float, float, bool]))\n",
    "LongShortStatsOutput = attrs.make_class('LongShortStatsOutput', ['long_stats_z_scorer', 'short_stats_z_scorer', 'long_short_z_diff', 'long_short_naive_z_diff', 'is_forward_replay'], slots=False, order=True)  # , bases=[LongShortStatsTuple]\n",
    "\n",
    "# attrs.define(\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating class using make_class\n",
    "SessionEntry = attrs.make_class(\"SessionEntry\", [\"file_path\", \"parsed_datetime\"], frozen=True, slots=True)\n",
    "\n",
    "# Assign types to attributes\n",
    "attrs.set_run_validators(SessionEntry, {\n",
    "    \"file_path\": attrs.validators.instance_of(Path),\n",
    "    \"parsed_datetime\": attrs.validators.instance_of(datetime)\n",
    "})\n",
    "\n",
    "entry = SessionEntry(file_path=Path('/path/to/file'), parsed_datetime=datetime.now())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2024-08-12 - typing.Annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing import Dict, List, Tuple, Optional, Callable, Union, Any, NewType, TypeVar\n",
    "from typing_extensions import TypeAlias\n",
    "import numpy as np\n",
    "from numpy.typing import NDArray\n",
    "\n",
    "Shape = Tuple[int, ...]\n",
    "\n",
    "def validate_shape(array: NDArray, shape: Shape) -> NDArray:\n",
    "    if array.shape != shape:\n",
    "        raise ValueError(f\"Expected array with shape {shape}, but got {array.shape}.\")\n",
    "    return array\n",
    "\n",
    "ArrayWithShape = Annotated[NDArray, validate_shape]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_predicted_t_bins = TypeVar('n_predicted_t_bins')\n",
    "n_x_bins = TypeVar('n_x_bins')\n",
    "n_t_bins = TypeVar('n_t_bins')\n",
    "\n",
    "# DecoderListDict: TypeAlias = Dict[str, List[T]]\n",
    "\n",
    "ArrayWithShape = Annotated[NDArray[Tuple[int, int, int]], (n_predicted_t_bins, n_x_bins, n_t_bins)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage\n",
    "Array5x24 = Annotated[NDArray[Tuple[int, int]], (5, 24)]\n",
    "\n",
    "# To validate at runtime\n",
    "def create_array(array: NDArray, shape: Shape) -> ArrayWithShape:\n",
    "    return validate_shape(array, shape)\n",
    "\n",
    "# Usage\n",
    "# array: ArrayWithShape = np.random.rand(5, 24)\n",
    "array: ArrayWithShape = np.random.rand(5, 5)\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_array = create_array(array, (5, 24))  # This will pass\n",
    "validated_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.random.rand(5, 2)\n",
    "validated_array = create_array(array, (5, 24))  # This will pass\n",
    "validated_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SizedArray(np.ndarray):\n",
    "    def __new__(cls, input_array, *args, **kwargs):\n",
    "        obj = np.asarray(input_array).view(cls)\n",
    "        # Additional initialization can be done here if needed\n",
    "        return obj\n",
    "    \n",
    "    def custom_method(self):\n",
    "        # Define your custom method here\n",
    "        return np.sum(self)  # Example: sum of the array elements\n",
    "\n",
    "    def __array_finalize__(self, obj):\n",
    "        # This method is called automatically to finalize the array object.\n",
    "        if obj is None: return\n",
    "        # Copy any attributes from `obj` to `self` if needed\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_yellow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
