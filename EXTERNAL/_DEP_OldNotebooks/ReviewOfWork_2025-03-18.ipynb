{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33f7f339",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[0Ô∏è‚É£ ReviewOfWork (Main Notebook) - Imports](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b492ba",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [0Ô∏è‚É£ ReviewOfWork (Main Notebook) - Imports](#toc1_)    \n",
    "- [0Ô∏è‚É£ Load Pipeline](#toc2_)    \n",
    "  - [2024-06-25 - Load from saved custom](#toc2_1_)    \n",
    "  - [0Ô∏è‚É£ RESUME Normal Pipeline Load](#toc2_2_)    \n",
    "  - [0Ô∏è‚É£ Normal Pipeline Load](#toc2_3_)    \n",
    "  - [0Ô∏è‚É£ Shared Post-Pipeline load stuff](#toc2_4_)    \n",
    "  - [Specific Recomputations](#toc2_5_)    \n",
    "  - [üíæ Continue Saving/Exporting stuff](#toc2_6_)    \n",
    "  - [‚öì2025-02-19 8:20am - FIXUP Pipeline](#toc2_7_)    \n",
    "  - [Custom Save-Pipeleine As](#toc2_8_)    \n",
    "      - [Get computation times/info:](#toc2_8_1_1_)    \n",
    "    - [Custom Split Result Outputs](#toc2_8_2_)    \n",
    "- [0Ô∏è‚É£ Pho Interactive Pipeline Jupyter Widget](#toc3_)    \n",
    "- [1Ô∏è‚É£ End Run](#toc4_)    \n",
    "- [1Ô∏è‚É£ POST-Compute:](#toc5_)    \n",
    "    - [2024-06-25 - Advanced Time-dependent decoding:](#toc5_1_1_)    \n",
    "- [/ üõë End Run Section üõë](#toc6_)    \n",
    "- [üé® 2024-02-06 - Other Plotting](#toc7_)    \n",
    "    - [2025-01-20 - Decoding step-by-step](#toc7_1_1_)    \n",
    "    - [üîù Dock Track Widgets](#toc7_1_2_)    \n",
    "  - [2025-02-17 - Dock Item \"Track\" sizing](#toc7_2_)    \n",
    "      - [Spike3DRasterWindow - Right Sidebar Widgets](#toc7_2_1_1_)    \n",
    "  - [üíØ 2025-01-22 - Add Selection Widget for SpikeRaster3DWindow](#toc7_3_)    \n",
    "- [3D Lap Plotting Experimentation](#toc8_)    \n",
    "    - [üî∂‚ùó 2025-01-15 - Lap Transition Matrix Analysis](#toc8_1_1_)    \n",
    "    - [‚úÖüñºÔ∏èüé® 2024-06-06 - Works to render the contour curve at a fixed promenence (the shape of the placefield's cap/crest) for each placefield:](#toc8_1_2_)    \n",
    "    - [2024-06-06 - Works to disable/hide all elements except the contour curves:](#toc8_1_3_)    \n",
    "    - [Plot specific `PhoPaginatedMultiDecoderDecodedEpochsWindow`](#toc8_1_4_)    \n",
    "- [üñºÔ∏èüé® 2024-02-28 - WE gotta see the replays on the 3D track. Or the 2D track.](#toc9_)    \n",
    "  - [add to 3D plotter:](#toc9_1_)    \n",
    "    - [üñºÔ∏èüé® Plot laps via `PhoPaginatedMultiDecoderDecodedEpochsWindow`:](#toc9_1_1_)    \n",
    "- [Other Misc Plotting Stuff](#toc10_)    \n",
    "    - [Resume display stuff](#toc10_1_1_)    \n",
    "- [2024-11-20 - Find specific posterior from a start_t (e.g. 747.3501248767134)](#toc11_)    \n",
    "  - [2024-11-25 - New Heuristics](#toc11_1_)    \n",
    "  - [Find indicies that are included in `high_heuristic_only_filtered_decoder_filter_epochs_decoder_result_dict` from `filtered_decoder_filter_epochs_decoder_result_dict`](#toc11_2_)    \n",
    "  - [Add the high-heuristic PBEs as an interval-rect dataseries to the continuous viewer](#toc11_3_)    \n",
    "- [üñºÔ∏èüé®`PhoPaginatedMultiDecoderDecodedEpochsWindow.plot_full_paginated_decoded_epochs_window(..)` combined windows](#toc12_)    \n",
    "    - [test for missed Radon Transform thingies: active_filter_epochs_df['score']](#toc12_1_1_)    \n",
    "    - [test for missed WCorr epochs: active_filter_epochs_df['pearsonr'], 'wcorr'](#toc12_1_2_)    \n",
    "    - [Attached raster viewer widget](#toc12_1_3_)    \n",
    "    - [2024-02-29 3pm - Get the active user-annotated epoch times from the `paginated_multi_decoder_decoded_epochs_window` and use these to filter `filtered_ripple_simple_pf_pearson_merged_df`](#toc12_1_4_)    \n",
    "  - [:‚úÖ:üéØ 2024-09-27 - Test programmatic/background saving of stacked decoded epoch figures](#toc12_2_)    \n",
    "    - [2024-11-26 - try HDF5 posterior export so they can be loaded more easily](#toc12_2_1_)    \n",
    "  - [üíæ Export Paginated Content](#toc12_3_)    \n",
    "  - [2024-04-30 Heuristic](#toc12_4_)    \n",
    "  - [üî∑üé® 2024-03-06 - Uni Page Scrollable Version](#toc12_5_)    \n",
    "- [üíæ 2024-03-04 - Export `DecoderDecodedEpochsResult` CSVs with user annotations for epochs:](#toc13_)    \n",
    "- [2024-03-04 - Filter out the epochs based on the criteria:](#toc14_)    \n",
    "  - [Track Position Classification (is_endcap, etc)](#toc14_1_)    \n",
    "- [‚ùïüü¢ 2024-10-07 - Rigorous Decoder Performance assessment](#toc15_)    \n",
    "    - [Display the `TrainTestSplitResult` in a `PhoPaginatedMultiDecoderDecodedEpochsWindow`](#toc15_1_1_)    \n",
    "- [2024-05-29 - Trial-by-Trial Activity](#toc16_)    \n",
    "    - [‚úÖ 2024-08-14-:üñºÔ∏è  Normal Matplotlib-based figure output for the `trial_by_trial_correlation_matrix.z_scored_tuning_map_matrix` to show the reliably of each place cell across laps](#toc16_1_1_)    \n",
    "  - [2024-10-14 - Add Track Shapes to the Trial-by-Trial figures](#toc16_2_)    \n",
    "- [2024-06-07 - PhoDiba2023Paper figure generation](#toc17_)    \n",
    "- [üî∑ 2024-07-02 - New epoch decoding and CSV export:](#toc18_)    \n",
    "- [PhoJonathanPlotHelpers](#toc19_)    \n",
    "- [#TODO 2025-03-04 17:17: - [ ] Documentation for all `DirectionalPlacefieldGlobalComputationFunction.py` classes](#toc20_)    \n",
    "- [‚úÖ `batch_user_completion_helpers` Batch Computation Testing](#toc21_)    \n",
    "    - [Call `compute_and_export_session_trial_by_trial_performance_completion_function`](#toc21_1_1_)    \n",
    "    - [Call `export_rank_order_results_completion_function`](#toc21_1_2_)    \n",
    "    - [Call `compute_and_export_session_wcorr_shuffles_completion_function`](#toc21_1_3_)    \n",
    "    - [Call `compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function`](#toc21_1_4_)    \n",
    "    - [Call `perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function`](#toc21_1_5_)    \n",
    "    - [Call `compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function`](#toc21_1_6_)    \n",
    "    - [Call `compute_and_export_session_trial_by_trial_performance_completion_function`](#toc21_1_7_)    \n",
    "    - [Call `compute_and_export_cell_first_spikes_characteristics_completion_function`](#toc21_1_8_)    \n",
    "    - [Call `kdiba_session_post_fixup_completion_function`](#toc21_1_9_)    \n",
    "    - [Call `generalized_decode_epochs_dict_and_export_results_completion_function`](#toc21_1_10_)    \n",
    "- [2025-01-09 - Playing with SpikeRaster2D Sort Order and Cell Emphasis](#toc22_)    \n",
    "    - [Global Recompute:](#toc22_1_1_)    \n",
    "- [2025-01-27 - Include all activity except the detected PBEs as training data](#toc23_)    \n",
    "- [2025-03-04 - Final Histogram](#toc24_)    \n",
    "    - [Plotting Tracks on Spike2DRaster](#toc24_1_1_)    \n",
    "    - [Plotting Histograms Directly](#toc24_1_2_)    \n",
    "- [‚öìüü¢üéØ 2025-02-20 - Compute Merged Placefields for Non-PBE Epochs for Long/Short](#toc25_)    \n",
    "    - [üößüîú 2025-02-26 -  Plot 1D pseudo2D Continuous Decodings and their marginals over TrackID on SpikeRaster2D track - uses `AddNewDecodedPosteriors_MatplotlibPlotCommand.prepare_and_perform_custom_decoder_decoded_epochs(...)`](#toc25_1_1_)    \n",
    "- [PyQtGraph rendering](#toc26_)    \n",
    "    - [BinByBinDecodingDebugger](#toc26_1_1_)    \n",
    "    - [`DataSlicingVisualizer` - 2D Decoded Posterior Visualizer](#toc26_1_2_)    \n",
    "    - [Old Stuff](#toc26_1_3_)    \n",
    "      - [üñºÔ∏è Test Single Epoch/Axes `DecodedTrajectoryMatplotlibPlotter` with slider to choose epoch](#toc26_1_3_1_)    \n",
    "- [3D PyVista Plotter](#toc27_)    \n",
    "- [2025-02-18 - Napari](#toc28_)    \n",
    "- [2025-01-30 - Rat Heading-Angle from Position Change Derivation](#toc29_)    \n",
    "  - [Binning Position, Angle](#toc29_1_)    \n",
    "- [2025-02-10 - Proper Timeline Slider Widget](#toc30_)    \n",
    "- [2025-02-10 - Final Filtering by qclu/neuron_IDs/etc](#toc31_)    \n",
    "- [2025-02-20 - `Pseudo-PosByContextDecoder`](#toc32_)    \n",
    "  - [In general, the requirement for building a Pseudo2D (or more general a Pseudo-PosByContextDecoder) is that all bins are mutually exclusive](#toc32_1_)    \n",
    "  - [Get 1D representations of the Pseudo2D track (4 decoders) so they can be plotted on seperate tracks and bin-debugged independently.](#toc32_2_)    \n",
    "- [Mice, Mark 1](#toc33_)    \n",
    "- [General Decoding Record with Frozen Decoding Parameters Tuples](#toc34_)    \n",
    "    - [üößüîú 2025-02-26 -  Plot 1D pseudo2D Continuous Decodings and their marginals over TrackID on SpikeRaster2D track - uses `AddNewDecodedPosteriors_MatplotlibPlotCommand.prepare_and_perform_custom_decoder_decoded_epochs(...)`](#toc34_1_1_)    \n",
    "- [2025-03-10 Evaluate the differences between `epochs_spkcount` and `_OLD_epochs_spkcount`](#toc35_)    \n",
    "- [2025-03-11 Apply the masking strategy introduced with the non-PBE epoch analyses on the other `DecodedFilterEpochsResult`s produced by the lap-constructed decoders (TrackTemplates)](#toc36_)    \n",
    "        - [2025-03-11 11:13 not sure if this is the old version or if it adds something to the `a_new_fully_generic_result`](#toc36_1_1_1_1_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77d98a7b",
   "metadata": {
    "tags": [
     "run-group-0-interactive",
     "run-group-0"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "doc_output_parent_folder: C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\EXTERNAL\\DEVELOPER_NOTES\\DataStructureDocumentation\n",
      "field.name: \"merged_directional_placefields\", variable_name: \"merged_directional_placefields\"\n",
      "field.name: \"rank_order_shuffle_analysis\", variable_name: \"rank_order_shuffle_analysis\"\n",
      "field.name: \"directional_decoders_decode_continuous\", variable_name: \"directional_decoders_decode_continuous\"\n",
      "field.name: \"directional_decoders_evaluate_epochs\", variable_name: \"directional_decoders_evaluate_epochs\"\n",
      "field.name: \"directional_decoders_epoch_heuristic_scoring\", variable_name: \"directional_decoders_epoch_heuristic_scoring\"\n",
      "field.name: \"directional_train_test_split\", variable_name: \"directional_train_test_split\"\n",
      "field.name: \"long_short_decoding_analyses\", variable_name: \"long_short_decoding_analyses\"\n",
      "field.name: \"long_short_rate_remapping\", variable_name: \"long_short_rate_remapping\"\n",
      "field.name: \"long_short_inst_spike_rate_groups\", variable_name: \"long_short_inst_spike_rate_groups\"\n",
      "field.name: \"wcorr_shuffle_analysis\", variable_name: \"wcorr_shuffle_analysis\"\n",
      "field.name: \"non_pbe_epochs_results\", variable_name: \"non_pbe_epochs_results\"\n",
      "field.name: \"position_decoding\", variable_name: \"position_decoding\"\n",
      "field.name: \"perform_specific_epochs_decoding\", variable_name: \"perform_specific_epochs_decoding\"\n",
      "field.name: \"DEP_ratemap_peaks\", variable_name: \"DEP_ratemap_peaks\"\n",
      "field.name: \"ratemap_peaks_prominence2d\", variable_name: \"ratemap_peaks_prominence2d\"\n",
      "DAY_DATE_STR: 2025-03-18, DAY_DATE_TO_USE: 2025-03-18\n",
      "NOW_DATETIME: 2025-03-18_0345PM, NOW_DATETIME_TO_USE: 2025-03-18_0345PM\n",
      "global_data_root_parent_path changed to W:\\Data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c6b8f7b9674a5f8db8758e9bbb1c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='Data Root:', layout=Layout(width='auto'), options=(WindowsPath('W:/Data'),), style=ToggleButtonsStyle(button_width='max-content'), tooltip='global_data_root_parent_path', value=WindowsPath('W:/Data'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "# %xmode Verbose\n",
    "# %xmode context\n",
    "%pdb off\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "# # Add exclusions for metaclass-using modules\n",
    "# %aimport -neuropy.core.session.dataSession\n",
    "# %aimport -neuropy.core.session.Formats.BaseDataSessionFormats\n",
    "# %aimport -neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat\n",
    "# %aimport -neuropy.core.session.Formats.Specific.BapunDataSessionFormat \n",
    "# %aimport -neuropy.core.session.Formats.Specific.RachelDataSessionFormat\n",
    "# %aimport -neuropy.core.session.Formats.Specific.HiroDataSessionFormat\n",
    "\n",
    "# !pip install viztracer\n",
    "%load_ext viztracer\n",
    "from viztracer import VizTracer\n",
    "\n",
    "%load_ext memory_profiler\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "os.environ['QT_API'] = 'pyqt5'\n",
    "os.environ['PYQTGRAPH_QT_LIB'] = 'PyQt5'\n",
    "\n",
    "# from PyQt5.QtWebEngineWidgets import QWebEngineView ## this must come first, before any QtApplication is made: 'ImportError: QtWebEngineWidgets must be imported or Qt.AA_ShareOpenGLContexts must be set before a QCoreApplication instance is created'\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "import importlib\n",
    "from copy import deepcopy\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "# pd.options.mode.dtype_backend = 'pyarrow' # use new pyarrow backend instead of numpy\n",
    "\n",
    "from attrs import define, field, fields, Factory, make_class\n",
    "import tables as tb\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Pho's Formatting Preferences\n",
    "import builtins\n",
    "\n",
    "import IPython\n",
    "from IPython.core.formatters import PlainTextFormatter\n",
    "from IPython import get_ipython\n",
    "\n",
    "from pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\n",
    "set_pho_preferences_concise()\n",
    "# Jupyter-lab enable printing for any line on its own (instead of just the last one in the cell)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# BEGIN PPRINT CUSTOMIZATION ___________________________________________________________________________________________ #\n",
    "\n",
    "## IPython pprint\n",
    "from pyphocorehelpers.pprint import wide_pprint, wide_pprint_ipython, wide_pprint_jupyter, MAX_LINE_LENGTH\n",
    "# Override default pprint\n",
    "builtins.pprint = wide_pprint\n",
    "\n",
    "ip = get_ipython()\n",
    "\n",
    "from pyphocorehelpers.ipython_helpers import CustomFormatterMagics\n",
    "\n",
    "# Register the magic\n",
    "get_ipython().register_magics(CustomFormatterMagics)\n",
    "\n",
    "# from pho_jupyter_preview_widget.display_helpers import array_repr_with_graphical_preview\n",
    "# from pho_jupyter_preview_widget.ipython_helpers import PreviewWidgetMagics\n",
    "\n",
    "# # Register the magic\n",
    "# ip.register_magics(PreviewWidgetMagics)\n",
    "\n",
    "# # %config_ndarray_preview width=500\n",
    "\n",
    "# # Register the custom display function for NumPy arrays\n",
    "# # ip.display_formatter.formatters['text/html'].for_type(np.ndarray, lambda arr: array_preview_with_graphical_shape_repr_html(arr))\n",
    "# # ip = array_repr_with_graphical_shape(ip=ip)\n",
    "# ip = array_repr_with_graphical_preview(ip=ip)\n",
    "# # ip = dataframe_show_more_button(ip=ip)\n",
    "\n",
    "text_formatter: PlainTextFormatter = ip.display_formatter.formatters['text/plain']\n",
    "text_formatter.max_width = MAX_LINE_LENGTH\n",
    "text_formatter.for_type(object, wide_pprint_jupyter)\n",
    "\n",
    "\n",
    "# END PPRINT CUSTOMIZATION ___________________________________________________________________________________________ #\n",
    "\n",
    "from pyphocorehelpers.print_helpers import get_now_time_str, get_now_day_str\n",
    "from pyphocorehelpers.indexing_helpers import get_dict_subset\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path, file_uri_from_path\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "import pyphocorehelpers.programming_helpers as programming_helpers\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "# from neuropy import core\n",
    "from typing import Dict, List, Tuple, Optional, Callable, Union, Any\n",
    "from typing_extensions import TypeAlias\n",
    "import nptyping as ND\n",
    "from nptyping import NDArray\n",
    "import neuropy.utils.type_aliases as types\n",
    "\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder, find_local_session_paths\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.core.epoch import NamedTimerange, Epoch\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.utils.matplotlib_helpers import matplotlib_file_only, matplotlib_configuration, matplotlib_configuration_update\n",
    "from neuropy.core.neuron_identities import NeuronIdentityTable, neuronTypesList, neuronTypesEnum\n",
    "from neuropy.utils.mixins.AttrsClassHelpers import AttrsBasedClassHelperMixin, serialized_field, serialized_attribute_field, non_serialized_field, custom_define\n",
    "from neuropy.utils.mixins.HDF5_representable import HDF_DeserializationMixin, post_deserialize, HDF_SerializationMixin, HDFMixin, HDF_Converter\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.neurons import NeuronType\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from neuropy.core.position import Position\n",
    "from neuropy.core.session.dataSession import DataSession\n",
    "from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent, PlacefieldSnapshot\n",
    "from neuropy.utils.debug_helpers import debug_print_placefield, debug_print_subsession_neuron_differences, debug_print_ratemap, debug_print_spike_counts, debug_plot_2d_binning, print_aligned_columns, parameter_sweeps, _plot_parameter_sweep, compare_placefields_info\n",
    "from neuropy.utils.indexing_helpers import NumpyHelpers, union_of_arrays, intersection_of_arrays, find_desired_sort_indicies, paired_incremental_sorting\n",
    "from pyphocorehelpers.print_helpers import print_object_memory_usage, print_dataframe_memory_usage, print_value_overview_only, DocumentationFilePrinter, print_keys_if_possible, generate_html_string, document_active_variables\n",
    "from pyphocorehelpers.programming_helpers import metadata_attributes\n",
    "from pyphocorehelpers.function_helpers import function_attributes\n",
    "## Pho Programming Helpers:\n",
    "import inspect\n",
    "from pyphocorehelpers.print_helpers import DocumentationFilePrinter, TypePrintMode, print_keys_if_possible, debug_dump_object_member_shapes, print_value_overview_only, document_active_variables\n",
    "from pyphocorehelpers.programming_helpers import IPythonHelpers, PythonDictionaryDefinitionFormat, MemoryManagement, inspect_callable_arguments, get_arguments_as_optional_dict, GeneratedClassDefinitionType, CodeConversion\n",
    "from pyphocorehelpers.notebook_helpers import NotebookCellExecutionLogger\n",
    "from pyphocorehelpers.gui.Qt.TopLevelWindowHelper import TopLevelWindowHelper, print_widget_hierarchy\n",
    "from pyphocorehelpers.indexing_helpers import reorder_columns, reorder_columns_relative, dict_to_full_array\n",
    "from pyphocorehelpers.DataStructure.RenderPlots.MatplotLibRenderPlots import MatplotlibRenderPlots\n",
    "\n",
    "doc_output_parent_folder: Path = Path('EXTERNAL/DEVELOPER_NOTES/DataStructureDocumentation').resolve() # ../.\n",
    "print(f\"doc_output_parent_folder: {doc_output_parent_folder}\")\n",
    "assert doc_output_parent_folder.exists()\n",
    "\n",
    "_notebook_path:Path = Path(IPythonHelpers.try_find_notebook_filepath(IPython.extract_module_locals())).resolve() # Finds the path of THIS notebook\n",
    "# _notebook_execution_logger: NotebookCellExecutionLogger = NotebookCellExecutionLogger(notebook_path=_notebook_path, enable_logging_to_file=False) # Builds a logger that records info about this notebook\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_load_session, batch_extended_computations, batch_evaluate_required_computations, batch_extended_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme # used in perform_pipeline_save\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import PipelineJupyterHelpers, CustomProcessingPhases\n",
    "\n",
    "\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "pg.setConfigOptions(useOpenGL=True)    # Use OpenGL for rendering which handles larger coordinates\n",
    "\n",
    "from pyphocorehelpers.exception_helpers import ExceptionPrintingContext, CapturedException\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import _find_any_context_neurons\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchSessionCompletionHandler # for `post_compute_validate(...)`\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BasePositionDecoder\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsResults\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends # for `_perform_long_short_instantaneous_spike_rate_groups_analysis`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import SingleBarResult, InstantaneousSpikeRateGroupsComputation, TruncationCheckingResults # for `BatchSessionCompletionHandler`, `AcrossSessionsAggregator`\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import SplitPartitionMembership\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalComputationFunctions, DirectionalLapsResult, TrackTemplates, DecoderDecodedEpochsResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderGlobalComputationFunctions,  RankOrderComputationsContainer, RankOrderResult, RankOrderAnalyses\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import EpochComputationFunctions, EpochComputationsComputationsContainer, DecodingResultND, Compute_NonPBE_Epochs, KnownFilterEpochs\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.SequenceBasedComputations import WCorrShuffle, SequenceBasedComputationsContainer\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.ComputationFunctionRegistryHolder import ComputationFunctionRegistryHolder, computation_precidence_specifying_function, global_function\n",
    "\n",
    "from neuropy.utils.mixins.binning_helpers import transition_matrix\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import TransitionMatrixComputations\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates, get_proper_global_spikes_df\n",
    "\n",
    "from pyphocorehelpers.Filesystem.path_helpers import set_posix_windows\n",
    "\n",
    "from pyphocorehelpers.assertion_helpers import Assert\n",
    "\n",
    "# Plotting\n",
    "# import pylustrator # customization of figures\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "\n",
    "matplotlib.use('Qt5Agg')\n",
    "# %matplotlib inline\n",
    "# %matplotlib auto\n",
    "\n",
    "# _restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# import pylustrator # call `pylustrator.start()` before creating your first figure in code.\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap, visualize_heatmap_pyqtgraph # used in `plot_kourosh_activity_style_figure`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot, plot_raster_plot\n",
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import UnitColoringMode, DataSeriesColorHelpers\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import _build_default_tick, build_scatter_plot_kwargs\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.Render2DScrollWindowPlot import Render2DScrollWindowPlotMixin, ScatterItemData\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_extended_programmatic_figures, batch_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "from pyphoplacecellanalysis.General.Mixins.SpikesRenderingBaseMixin import SpikeEmphasisState\n",
    "from pyphoplacecellanalysis.General.Model.SpecificComputationParameterTypes import ComputationKWargParameters\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PAPER_FIGURE_figure_1_add_replay_epoch_rasters, PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_3, main_complete_figure_generations\n",
    "# from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import *\n",
    "\n",
    "# Jupyter Widget Interactive\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import interactive_pipeline_widget, interactive_pipeline_files\n",
    "from pyphocorehelpers.gui.Jupyter.simple_widgets import fullwidth_path_widget, render_colors\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import PipelineJupyterHelpers, CustomProcessingPhases, PipelinePickleFileSelectorWidget\n",
    "\n",
    "from datetime import datetime, date, timedelta\n",
    "from pyphocorehelpers.print_helpers import get_now_day_str, get_now_rounded_time_str\n",
    "\n",
    "DAY_DATE_STR: str = date.today().strftime(\"%Y-%m-%d\")\n",
    "DAY_DATE_TO_USE = f'{DAY_DATE_STR}' # used for filenames throught the notebook\n",
    "print(f'DAY_DATE_STR: {DAY_DATE_STR}, DAY_DATE_TO_USE: {DAY_DATE_TO_USE}')\n",
    "\n",
    "NOW_DATETIME: str = get_now_rounded_time_str()\n",
    "NOW_DATETIME_TO_USE = f'{NOW_DATETIME}' # used for filenames throught the notebook\n",
    "print(f'NOW_DATETIME: {NOW_DATETIME}, NOW_DATETIME_TO_USE: {NOW_DATETIME_TO_USE}')\n",
    "\n",
    "def get_global_variable(var_name):\n",
    "    \"\"\" used by `PipelineJupyterHelpers._build_pipeline_custom_processing_mode_selector_widget(...)` to update the notebook's variables \"\"\"\n",
    "    return globals()[var_name]\n",
    "    \n",
    "\n",
    "def update_global_variable(var_name, value):\n",
    "    \"\"\" used by `PipelineJupyterHelpers._build_pipeline_custom_processing_mode_selector_widget(...)` to update the notebook's variables \"\"\"\n",
    "    globals()[var_name] = value\n",
    "\n",
    "from pyphocorehelpers.gui.Jupyter.simple_widgets import build_global_data_root_parent_path_selection_widget\n",
    "all_paths = [Path(r'/home/halechr/FastData'), Path('/Volumes/SwapSSD/Data'), Path('/Users/pho/data'), Path(r'/media/halechr/MAX/Data'), Path(r'W:\\Data'), Path(r'/home/halechr/cloud/turbo/Data'), Path(r'/Volumes/MoverNew/data'), Path(r'/home/halechr/turbo/Data'), Path(r'/Users/pho/cloud/turbo/Data')] # Path('/Volumes/FedoraSSD/FastData'), \n",
    "global_data_root_parent_path = None\n",
    "def on_user_update_path_selection(new_path: Path):\n",
    "    global global_data_root_parent_path\n",
    "    new_global_data_root_parent_path = new_path.resolve()\n",
    "    global_data_root_parent_path = new_global_data_root_parent_path\n",
    "    print(f'global_data_root_parent_path changed to {global_data_root_parent_path}')\n",
    "    assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "            \n",
    "global_data_root_parent_path_widget = build_global_data_root_parent_path_selection_widget(all_paths, on_user_update_path_selection)\n",
    "global_data_root_parent_path_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e81646",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[0Ô∏è‚É£ Load Pipeline](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f07773d",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-0",
     "all",
     "run-group-0-interactive"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basedir: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad20f17eced14d2b9672162d2e8524c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(ToggleButtons(description='CustomProcessingPhases:', options=('clean_run', 'continued_run', 'final_run'), style=ToggleButtonsStyle(description_width='initial'), tooltips=('Select clean_run', 'Select continued_run', 'Select final_run'), value='clean_run'), Label(value='Empty')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving_mode: PipelineSavingScheme.SKIP_SAVING, force_reload: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['lap_direction_determination',\n",
       " 'pf_computation',\n",
       " 'pfdt_computation',\n",
       " 'position_decoding',\n",
       " 'firing_rate_trends',\n",
       " 'extended_stats',\n",
       " 'long_short_decoding_analyses',\n",
       " 'jonathan_firing_rate_analysis',\n",
       " 'long_short_fr_indicies_analyses',\n",
       " 'long_short_post_decoding',\n",
       " 'long_short_inst_spike_rate_groups',\n",
       " 'long_short_endcap_analysis',\n",
       " 'split_to_directional_laps',\n",
       " 'merged_directional_placefields',\n",
       " 'directional_decoders_decode_continuous',\n",
       " 'directional_decoders_evaluate_epochs',\n",
       " 'directional_decoders_epoch_heuristic_scoring',\n",
       " 'non_PBE_epochs_results']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.2.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 9;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.2.2.min.js\", \"https://cdn.holoviz.org/panel/1.2.3/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      Bokeh = root.Bokeh;\n      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      if (!reloading && (!bokeh_loaded || is_dev)) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='49ccfcfc-438e-4f1a-8e04-5ff73f392d22'>\n",
       "  <div id=\"e005e15b-7a1d-4e69-aca7-bf839910fa35\" data-root-id=\"49ccfcfc-438e-4f1a-8e04-5ff73f392d22\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"43203941-7701-4d70-9018-eba137c171af\":{\"version\":\"3.2.2\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"49ccfcfc-438e-4f1a-8e04-5ff73f392d22\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"f0cbe0aa-0bb8-4c95-abd1-7b48ef69303d\",\"attributes\":{\"plot_id\":\"49ccfcfc-438e-4f1a-8e04-5ff73f392d22\",\"comm_id\":\"6e22fb6d532f42a78d93115cb0d44db1\",\"client_comm_id\":\"25b6b1793dd345a99529c8eedd081038\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"43203941-7701-4d70-9018-eba137c171af\",\"roots\":{\"49ccfcfc-438e-4f1a-8e04-5ff73f392d22\":\"e005e15b-7a1d-4e69-aca7-bf839910fa35\"},\"root_ids\":[\"49ccfcfc-438e-4f1a-8e04-5ff73f392d22\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  const is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1\n",
       "  function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version && !is_dev) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "49ccfcfc-438e-4f1a-8e04-5ff73f392d22"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.2.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n  var reloading = true;\n  var Bokeh = root.Bokeh;\n  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'tabulator': 'https://cdn.jsdelivr.net/npm/tabulator-tables@5.5.0/dist/js/tabulator', 'moment': 'https://cdn.jsdelivr.net/npm/luxon/build/global/luxon.min', 'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"tabulator\"], function(Tabulator) {\n\twindow.Tabulator = Tabulator\n\ton_load()\n      })\n      require([\"moment\"], function(moment) {\n\twindow.moment = moment\n\ton_load()\n      })\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 11;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['Tabulator'] !== undefined) && (!(window['Tabulator'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/js/tabulator.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['moment'] !== undefined) && (!(window['moment'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/luxon/build/global/luxon.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/js/tabulator.js\", \"https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/luxon/build/global/luxon.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [\"https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/css/tabulator_simple.min.css\"];\n  var inline_js = [    function(Bokeh) {\n      inject_raw_css(\".tabulator{position:relative;border:1px solid #999;font-size:14px;text-align:left;overflow:hidden;-webkit-transform:translateZ(0);-moz-transform:translateZ(0);-ms-transform:translateZ(0);-o-transform:translateZ(0);transform:translateZ(0)}.tabulator[tabulator-layout=fitDataFill] .tabulator-tableholder .tabulator-table{min-width:100%}.tabulator[tabulator-layout=fitDataTable]{display:inline-block}.tabulator.tabulator-block-select{user-select:none}.tabulator .tabulator-header{position:relative;box-sizing:border-box;width:100%;border-bottom:1px solid #999;background-color:#fff;color:#555;font-weight:700;white-space:nowrap;overflow:hidden;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none}.tabulator .tabulator-header.tabulator-header-hidden{display:none}.tabulator .tabulator-header .tabulator-header-contents{position:relative;overflow:hidden}.tabulator .tabulator-header .tabulator-header-contents .tabulator-headers{display:inline-block}.tabulator .tabulator-header .tabulator-col{display:inline-flex;position:relative;box-sizing:border-box;flex-direction:column;justify-content:flex-start;border-right:1px solid #ddd;background:#fff;text-align:left;vertical-align:bottom;overflow:hidden}.tabulator .tabulator-header .tabulator-col.tabulator-moving{position:absolute;border:1px solid #999;background:#e6e6e6;pointer-events:none}.tabulator .tabulator-header .tabulator-col .tabulator-col-content{box-sizing:border-box;position:relative;padding:4px}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-header-popup-button{padding:0 8px}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-header-popup-button:hover{cursor:pointer;opacity:.6}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title-holder{position:relative}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title{box-sizing:border-box;width:100%;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;vertical-align:bottom}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title.tabulator-col-title-wrap{white-space:normal;text-overflow:clip}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title .tabulator-title-editor{box-sizing:border-box;width:100%;border:1px solid #999;padding:1px;background:#fff}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title .tabulator-header-popup-button+.tabulator-title-editor{width:calc(100% - 22px)}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-sorter{display:flex;align-items:center;position:absolute;top:0;bottom:0;right:4px}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{width:0;height:0;border-left:6px solid transparent;border-right:6px solid transparent;border-bottom:6px solid #bbb}.tabulator .tabulator-header .tabulator-col.tabulator-col-group .tabulator-col-group-cols{position:relative;display:flex;border-top:1px solid #ddd;overflow:hidden;margin-right:-1px}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter{position:relative;box-sizing:border-box;margin-top:2px;width:100%;text-align:center}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter textarea{height:auto!important}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter svg{margin-top:3px}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter input::-ms-clear{width:0;height:0}.tabulator .tabulator-header .tabulator-col.tabulator-sortable .tabulator-col-title{padding-right:25px}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable.tabulator-col-sorter-element:hover{cursor:pointer;background-color:#e6e6e6}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=none] .tabulator-col-content .tabulator-col-sorter{color:#bbb}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=none] .tabulator-col-content .tabulator-col-sorter.tabulator-col-sorter-element .tabulator-arrow:hover{cursor:pointer;border-bottom:6px solid #555}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=none] .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{border-top:none;border-bottom:6px solid #bbb}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=ascending] .tabulator-col-content .tabulator-col-sorter{color:#666}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=ascending] .tabulator-col-content .tabulator-col-sorter.tabulator-col-sorter-element .tabulator-arrow:hover{cursor:pointer;border-bottom:6px solid #555}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=ascending] .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{border-top:none;border-bottom:6px solid #666}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=descending] .tabulator-col-content .tabulator-col-sorter{color:#666}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=descending] .tabulator-col-content .tabulator-col-sorter.tabulator-col-sorter-element .tabulator-arrow:hover{cursor:pointer;border-top:6px solid #555}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=descending] .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{border-bottom:none;border-top:6px solid #666;color:#666}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical .tabulator-col-content .tabulator-col-title{writing-mode:vertical-rl;text-orientation:mixed;display:flex;align-items:center;justify-content:center}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-col-vertical-flip .tabulator-col-title{transform:rotate(180deg)}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-sortable .tabulator-col-title{padding-right:0;padding-top:20px}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-sortable.tabulator-col-vertical-flip .tabulator-col-title{padding-right:0;padding-bottom:20px}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-sortable .tabulator-col-sorter{justify-content:center;left:0;right:0;top:4px;bottom:auto}.tabulator .tabulator-header .tabulator-frozen{position:sticky;left:0;z-index:10}.tabulator .tabulator-header .tabulator-frozen.tabulator-frozen-left{border-right:2px solid #ddd}.tabulator .tabulator-header .tabulator-frozen.tabulator-frozen-right{border-left:2px solid #ddd}.tabulator .tabulator-header .tabulator-calcs-holder{box-sizing:border-box;background:#fff!important;border-top:1px solid #ddd;border-bottom:1px solid #ddd}.tabulator .tabulator-header .tabulator-calcs-holder .tabulator-row{background:#fff!important}.tabulator .tabulator-header .tabulator-calcs-holder .tabulator-row .tabulator-col-resize-handle,.tabulator .tabulator-header .tabulator-frozen-rows-holder:empty{display:none}.tabulator .tabulator-tableholder{position:relative;width:100%;white-space:nowrap;overflow:auto;-webkit-overflow-scrolling:touch}.tabulator .tabulator-tableholder:focus{outline:none}.tabulator .tabulator-tableholder .tabulator-placeholder{box-sizing:border-box;display:flex;align-items:center;justify-content:center;width:100%}.tabulator .tabulator-tableholder .tabulator-placeholder[tabulator-render-mode=virtual]{min-height:100%;min-width:100%}.tabulator .tabulator-tableholder .tabulator-placeholder .tabulator-placeholder-contents{display:inline-block;text-align:center;padding:10px;color:#ccc;font-weight:700;font-size:20px;white-space:normal}.tabulator .tabulator-tableholder .tabulator-table{position:relative;display:inline-block;background-color:#fff;white-space:nowrap;overflow:visible;color:#333}.tabulator .tabulator-tableholder .tabulator-table .tabulator-row.tabulator-calcs{font-weight:700;background:#f2f2f2!important}.tabulator .tabulator-tableholder .tabulator-table .tabulator-row.tabulator-calcs.tabulator-calcs-top{border-bottom:2px solid #ddd}.tabulator .tabulator-tableholder .tabulator-table .tabulator-row.tabulator-calcs.tabulator-calcs-bottom{border-top:2px solid #ddd}.tabulator .tabulator-footer{border-top:1px solid #999;background-color:#fff;color:#555;font-weight:700;white-space:nowrap;user-select:none;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none}.tabulator .tabulator-footer .tabulator-footer-contents{display:flex;flex-direction:row;align-items:center;justify-content:space-between;padding:5px 10px}.tabulator .tabulator-footer .tabulator-footer-contents:empty{display:none}.tabulator .tabulator-footer .tabulator-calcs-holder{box-sizing:border-box;width:100%;text-align:left;background:#fff!important;border-bottom:1px solid #ddd;border-top:1px solid #ddd;overflow:hidden}.tabulator .tabulator-footer .tabulator-calcs-holder .tabulator-row{display:inline-block;background:#fff!important}.tabulator .tabulator-footer .tabulator-calcs-holder .tabulator-row .tabulator-col-resize-handle{display:none}.tabulator .tabulator-footer .tabulator-calcs-holder:only-child{margin-bottom:-5px;border-bottom:none}.tabulator .tabulator-footer>*+.tabulator-page-counter{margin-left:10px}.tabulator .tabulator-footer .tabulator-page-counter{font-weight:400}.tabulator .tabulator-footer .tabulator-paginator{flex:1;text-align:right;color:#555;font-family:inherit;font-weight:inherit;font-size:inherit}.tabulator .tabulator-footer .tabulator-page-size{display:inline-block;margin:0 5px;padding:2px 5px;border:1px solid #aaa;border-radius:3px}.tabulator .tabulator-footer .tabulator-pages{margin:0 7px}.tabulator .tabulator-footer .tabulator-page{display:inline-block;margin:0 2px;padding:2px 5px;border:1px solid #aaa;border-radius:3px;background:hsla(0,0%,100%,.2)}.tabulator .tabulator-footer .tabulator-page.active{color:#d00}.tabulator .tabulator-footer .tabulator-page:disabled{opacity:.5}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-footer .tabulator-page:not(.disabled):hover{cursor:pointer;background:rgba(0,0,0,.2);color:#fff}}.tabulator .tabulator-col-resize-handle{position:relative;display:inline-block;width:6px;margin-left:-3px;margin-right:-3px;z-index:10;vertical-align:middle}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-col-resize-handle:hover{cursor:ew-resize}}.tabulator .tabulator-col-resize-handle:last-of-type{width:3px;margin-right:0}.tabulator .tabulator-alert{position:absolute;display:flex;align-items:center;top:0;left:0;z-index:100;height:100%;width:100%;background:rgba(0,0,0,.4);text-align:center}.tabulator .tabulator-alert .tabulator-alert-msg{display:inline-block;margin:0 auto;padding:10px 20px;border-radius:10px;background:#fff;font-weight:700;font-size:16px}.tabulator .tabulator-alert .tabulator-alert-msg.tabulator-alert-state-msg{border:4px solid #333;color:#000}.tabulator .tabulator-alert .tabulator-alert-msg.tabulator-alert-state-error{border:4px solid #d00;color:#590000}.tabulator-row{position:relative;box-sizing:border-box;min-height:22px}.tabulator-row,.tabulator-row.tabulator-row-even{background-color:#fff}@media (hover:hover) and (pointer:fine){.tabulator-row.tabulator-selectable:hover{background-color:#bbb;cursor:pointer}}.tabulator-row.tabulator-selected{background-color:#9abcea}@media (hover:hover) and (pointer:fine){.tabulator-row.tabulator-selected:hover{background-color:#769bcc;cursor:pointer}}.tabulator-row.tabulator-row-moving{border:1px solid #000;background:#fff}.tabulator-row.tabulator-moving{position:absolute;border-top:1px solid #ddd;border-bottom:1px solid #ddd;pointer-events:none;z-index:15}.tabulator-row .tabulator-row-resize-handle{position:absolute;right:0;bottom:0;left:0;height:5px}.tabulator-row .tabulator-row-resize-handle.prev{top:0;bottom:auto}@media (hover:hover) and (pointer:fine){.tabulator-row .tabulator-row-resize-handle:hover{cursor:ns-resize}}.tabulator-row .tabulator-responsive-collapse{box-sizing:border-box;padding:5px;border-top:1px solid #ddd;border-bottom:1px solid #ddd}.tabulator-row .tabulator-responsive-collapse:empty{display:none}.tabulator-row .tabulator-responsive-collapse table{font-size:14px}.tabulator-row .tabulator-responsive-collapse table tr td{position:relative}.tabulator-row .tabulator-responsive-collapse table tr td:first-of-type{padding-right:10px}.tabulator-row .tabulator-cell{display:inline-block;position:relative;box-sizing:border-box;padding:4px;border-right:1px solid #ddd;vertical-align:middle;white-space:nowrap;overflow:hidden;text-overflow:ellipsis}.tabulator-row .tabulator-cell.tabulator-frozen{display:inline-block;position:sticky;left:0;background-color:inherit;z-index:10}.tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-left{border-right:2px solid #ddd}.tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-right{border-left:2px solid #ddd}.tabulator-row .tabulator-cell.tabulator-editing{border:1px solid #1d68cd;outline:none;padding:0}.tabulator-row .tabulator-cell.tabulator-editing input,.tabulator-row .tabulator-cell.tabulator-editing select{border:1px;background:transparent;outline:none}.tabulator-row .tabulator-cell.tabulator-validation-fail{border:1px solid #d00}.tabulator-row .tabulator-cell.tabulator-validation-fail input,.tabulator-row .tabulator-cell.tabulator-validation-fail select{border:1px;background:transparent;color:#d00}.tabulator-row .tabulator-cell.tabulator-row-handle{display:inline-flex;align-items:center;justify-content:center;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none}.tabulator-row .tabulator-cell.tabulator-row-handle .tabulator-row-handle-box{width:80%}.tabulator-row .tabulator-cell.tabulator-row-handle .tabulator-row-handle-box .tabulator-row-handle-bar{width:100%;height:3px;margin-top:2px;background:#666}.tabulator-row .tabulator-cell .tabulator-data-tree-branch{display:inline-block;vertical-align:middle;height:9px;width:7px;margin-top:-9px;margin-right:5px;border-bottom-left-radius:1px;border-left:2px solid #ddd;border-bottom:2px solid #ddd}.tabulator-row .tabulator-cell .tabulator-data-tree-control{display:inline-flex;justify-content:center;align-items:center;vertical-align:middle;height:11px;width:11px;margin-right:5px;border:1px solid #333;border-radius:2px;background:rgba(0,0,0,.1);overflow:hidden}@media (hover:hover) and (pointer:fine){.tabulator-row .tabulator-cell .tabulator-data-tree-control:hover{cursor:pointer;background:rgba(0,0,0,.2)}}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-collapse{display:inline-block;position:relative;height:7px;width:1px;background:transparent}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-collapse:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-expand{display:inline-block;position:relative;height:7px;width:1px;background:#333}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-expand:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle{display:inline-flex;align-items:center;justify-content:center;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none;height:15px;width:15px;border-radius:20px;background:#666;color:#fff;font-weight:700;font-size:1.1em}@media (hover:hover) and (pointer:fine){.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle:hover{opacity:.7;cursor:pointer}}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle.open .tabulator-responsive-collapse-toggle-close{display:initial}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle.open .tabulator-responsive-collapse-toggle-open{display:none}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle svg{stroke:#fff}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle .tabulator-responsive-collapse-toggle-close{display:none}.tabulator-row .tabulator-cell .tabulator-traffic-light{display:inline-block;height:14px;width:14px;border-radius:14px}.tabulator-row.tabulator-group{box-sizing:border-box;border-bottom:1px solid #999;border-right:1px solid #ddd;border-top:1px solid #999;padding:5px 5px 5px 10px;background:#ccc;font-weight:700;min-width:100%}@media (hover:hover) and (pointer:fine){.tabulator-row.tabulator-group:hover{cursor:pointer;background-color:rgba(0,0,0,.1)}}.tabulator-row.tabulator-group.tabulator-group-visible .tabulator-arrow{margin-right:10px;border-left:6px solid transparent;border-right:6px solid transparent;border-top:6px solid #666;border-bottom:0}.tabulator-row.tabulator-group.tabulator-group-level-1{padding-left:30px}.tabulator-row.tabulator-group.tabulator-group-level-2{padding-left:50px}.tabulator-row.tabulator-group.tabulator-group-level-3{padding-left:70px}.tabulator-row.tabulator-group.tabulator-group-level-4{padding-left:90px}.tabulator-row.tabulator-group.tabulator-group-level-5{padding-left:110px}.tabulator-row.tabulator-group .tabulator-group-toggle{display:inline-block}.tabulator-row.tabulator-group .tabulator-arrow{display:inline-block;width:0;height:0;margin-right:16px;border-top:6px solid transparent;border-bottom:6px solid transparent;border-right:0;border-left:6px solid #666;vertical-align:middle}.tabulator-row.tabulator-group span{margin-left:10px;color:#d00}.tabulator-popup-container{position:absolute;display:inline-block;box-sizing:border-box;background:#fff;border:1px solid #ddd;box-shadow:0 0 5px 0 rgba(0,0,0,.2);font-size:14px;overflow-y:auto;-webkit-overflow-scrolling:touch;z-index:10000}.tabulator-popup{padding:5px;border-radius:3px}.tabulator-tooltip{max-width:Min(500px,100%);padding:3px 5px;border-radius:2px;box-shadow:none;font-size:12px;pointer-events:none}.tabulator-menu .tabulator-menu-item{position:relative;box-sizing:border-box;padding:5px 10px;user-select:none}.tabulator-menu .tabulator-menu-item.tabulator-menu-item-disabled{opacity:.5}@media (hover:hover) and (pointer:fine){.tabulator-menu .tabulator-menu-item:not(.tabulator-menu-item-disabled):hover{cursor:pointer;background:#fff}}.tabulator-menu .tabulator-menu-item.tabulator-menu-item-submenu{padding-right:25px}.tabulator-menu .tabulator-menu-item.tabulator-menu-item-submenu:after{display:inline-block;position:absolute;top:calc(5px + .4em);right:10px;height:7px;width:7px;content:\\\"\\\";border-color:#ddd;border-style:solid;border-width:1px 1px 0 0;vertical-align:top;transform:rotate(45deg)}.tabulator-menu .tabulator-menu-separator{border-top:1px solid #ddd}.tabulator-edit-list{max-height:200px;font-size:14px;overflow-y:auto;-webkit-overflow-scrolling:touch}.tabulator-edit-list .tabulator-edit-list-item{padding:4px;color:#333;outline:none}.tabulator-edit-list .tabulator-edit-list-item.active{color:#fff;background:#1d68cd}.tabulator-edit-list .tabulator-edit-list-item.active.focused{outline:1px solid hsla(0,0%,100%,.5)}.tabulator-edit-list .tabulator-edit-list-item.focused{outline:1px solid #1d68cd}@media (hover:hover) and (pointer:fine){.tabulator-edit-list .tabulator-edit-list-item:hover{cursor:pointer;color:#fff;background:#1d68cd}}.tabulator-edit-list .tabulator-edit-list-placeholder{padding:4px;color:#333;text-align:center}.tabulator-edit-list .tabulator-edit-list-group{border-bottom:1px solid #ddd;padding:6px 4px 4px;color:#333;font-weight:700}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-2,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-2{padding-left:12px}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-3,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-3{padding-left:20px}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-4,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-4{padding-left:28px}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-5,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-5{padding-left:36px}.tabulator.tabulator-ltr{direction:ltr}.tabulator.tabulator-rtl{text-align:initial;direction:rtl}.tabulator.tabulator-rtl .tabulator-header .tabulator-col{text-align:initial;border-left:1px solid #ddd;border-right:initial}.tabulator.tabulator-rtl .tabulator-header .tabulator-col.tabulator-col-group .tabulator-col-group-cols{margin-right:0;margin-left:-1px}.tabulator.tabulator-rtl .tabulator-header .tabulator-col.tabulator-sortable .tabulator-col-title{padding-right:0;padding-left:25px}.tabulator.tabulator-rtl .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-sorter{left:8px;right:auto}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell{border-right:initial;border-left:1px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell .tabulator-data-tree-branch{margin-right:0;margin-left:5px;border-bottom-left-radius:0;border-bottom-right-radius:1px;border-left:initial;border-right:2px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell .tabulator-data-tree-control{margin-right:0;margin-left:5px}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-left{border-left:2px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-right{border-right:2px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-col-resize-handle:last-of-type{width:3px;margin-left:0;margin-right:-3px}.tabulator.tabulator-rtl .tabulator-footer .tabulator-calcs-holder{text-align:initial}.tabulator-print-fullscreen{position:absolute;top:0;bottom:0;left:0;right:0;z-index:10000}body.tabulator-print-fullscreen-hide>:not(.tabulator-print-fullscreen){display:none!important}.tabulator-print-table{border-collapse:collapse}.tabulator-print-table .tabulator-data-tree-branch{display:inline-block;vertical-align:middle;height:9px;width:7px;margin-top:-9px;margin-right:5px;border-bottom-left-radius:1px;border-left:2px solid #ddd;border-bottom:2px solid #ddd}.tabulator-print-table .tabulator-print-table-group{box-sizing:border-box;border-bottom:1px solid #999;border-right:1px solid #ddd;border-top:1px solid #999;padding:5px 5px 5px 10px;background:#ccc;font-weight:700;min-width:100%}@media (hover:hover) and (pointer:fine){.tabulator-print-table .tabulator-print-table-group:hover{cursor:pointer;background-color:rgba(0,0,0,.1)}}.tabulator-print-table .tabulator-print-table-group.tabulator-group-visible .tabulator-arrow{margin-right:10px;border-left:6px solid transparent;border-right:6px solid transparent;border-top:6px solid #666;border-bottom:0}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-1 td{padding-left:30px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-2 td{padding-left:50px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-3 td{padding-left:70px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-4 td{padding-left:90px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-5 td{padding-left:110px!important}.tabulator-print-table .tabulator-print-table-group .tabulator-group-toggle{display:inline-block}.tabulator-print-table .tabulator-print-table-group .tabulator-arrow{display:inline-block;width:0;height:0;margin-right:16px;border-top:6px solid transparent;border-bottom:6px solid transparent;border-right:0;border-left:6px solid #666;vertical-align:middle}.tabulator-print-table .tabulator-print-table-group span{color:#d00}.tabulator-print-table .tabulator-data-tree-control{display:inline-flex;justify-content:center;align-items:center;vertical-align:middle;height:11px;width:11px;margin-right:5px;border:1px solid #333;border-radius:2px;background:rgba(0,0,0,.1);overflow:hidden}@media (hover:hover) and (pointer:fine){.tabulator-print-table .tabulator-data-tree-control:hover{cursor:pointer;background:rgba(0,0,0,.2)}}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-collapse{display:inline-block;position:relative;height:7px;width:1px;background:transparent}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-collapse:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-expand{display:inline-block;position:relative;height:7px;width:1px;background:#333}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-expand:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator{border:none;background-color:#fff}.tabulator .tabulator-header .tabulator-calcs-holder{background:#f2f2f2!important;border-bottom:1px solid #999}.tabulator .tabulator-header .tabulator-calcs-holder .tabulator-row{background:#f2f2f2!important}.tabulator .tabulator-tableholder .tabulator-placeholder span{color:#000}.tabulator .tabulator-footer .tabulator-calcs-holder{background:#f2f2f2!important;border-bottom:1px solid #fff}.tabulator .tabulator-footer .tabulator-calcs-holder .tabulator-row{background:#f2f2f2!important}.tabulator-row{border-bottom:1px solid #ddd}.tabulator-row .tabulator-cell:last-of-type{border-right:none}.tabulator-row.tabulator-group span{color:#666}.tabulator-print-table .tabulator-print-table-group span{margin-left:10px;color:#666}\\n/*# sourceMappingURL=tabulator_simple.min.css.map */\");\n    },    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      Bokeh = root.Bokeh;\n      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      if (!reloading && (!bokeh_loaded || is_dev)) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.2.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n  var reloading = true;\n  var Bokeh = root.Bokeh;\n  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'tabulator': 'https://cdn.jsdelivr.net/npm/tabulator-tables@5.5.0/dist/js/tabulator', 'moment': 'https://cdn.jsdelivr.net/npm/luxon/build/global/luxon.min', 'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"tabulator\"], function(Tabulator) {\n\twindow.Tabulator = Tabulator\n\ton_load()\n      })\n      require([\"moment\"], function(moment) {\n\twindow.moment = moment\n\ton_load()\n      })\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 11;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['Tabulator'] !== undefined) && (!(window['Tabulator'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/js/tabulator.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['moment'] !== undefined) && (!(window['moment'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/luxon/build/global/luxon.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/js/tabulator.js\", \"https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/luxon/build/global/luxon.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [\"https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/css/tabulator_simple.min.css\"];\n  var inline_js = [    function(Bokeh) {\n      inject_raw_css(\".tabulator{position:relative;border:1px solid #999;font-size:14px;text-align:left;overflow:hidden;-webkit-transform:translateZ(0);-moz-transform:translateZ(0);-ms-transform:translateZ(0);-o-transform:translateZ(0);transform:translateZ(0)}.tabulator[tabulator-layout=fitDataFill] .tabulator-tableholder .tabulator-table{min-width:100%}.tabulator[tabulator-layout=fitDataTable]{display:inline-block}.tabulator.tabulator-block-select{user-select:none}.tabulator .tabulator-header{position:relative;box-sizing:border-box;width:100%;border-bottom:1px solid #999;background-color:#fff;color:#555;font-weight:700;white-space:nowrap;overflow:hidden;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none}.tabulator .tabulator-header.tabulator-header-hidden{display:none}.tabulator .tabulator-header .tabulator-header-contents{position:relative;overflow:hidden}.tabulator .tabulator-header .tabulator-header-contents .tabulator-headers{display:inline-block}.tabulator .tabulator-header .tabulator-col{display:inline-flex;position:relative;box-sizing:border-box;flex-direction:column;justify-content:flex-start;border-right:1px solid #ddd;background:#fff;text-align:left;vertical-align:bottom;overflow:hidden}.tabulator .tabulator-header .tabulator-col.tabulator-moving{position:absolute;border:1px solid #999;background:#e6e6e6;pointer-events:none}.tabulator .tabulator-header .tabulator-col .tabulator-col-content{box-sizing:border-box;position:relative;padding:4px}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-header-popup-button{padding:0 8px}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-header-popup-button:hover{cursor:pointer;opacity:.6}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title-holder{position:relative}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title{box-sizing:border-box;width:100%;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;vertical-align:bottom}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title.tabulator-col-title-wrap{white-space:normal;text-overflow:clip}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title .tabulator-title-editor{box-sizing:border-box;width:100%;border:1px solid #999;padding:1px;background:#fff}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title .tabulator-header-popup-button+.tabulator-title-editor{width:calc(100% - 22px)}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-sorter{display:flex;align-items:center;position:absolute;top:0;bottom:0;right:4px}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{width:0;height:0;border-left:6px solid transparent;border-right:6px solid transparent;border-bottom:6px solid #bbb}.tabulator .tabulator-header .tabulator-col.tabulator-col-group .tabulator-col-group-cols{position:relative;display:flex;border-top:1px solid #ddd;overflow:hidden;margin-right:-1px}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter{position:relative;box-sizing:border-box;margin-top:2px;width:100%;text-align:center}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter textarea{height:auto!important}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter svg{margin-top:3px}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter input::-ms-clear{width:0;height:0}.tabulator .tabulator-header .tabulator-col.tabulator-sortable .tabulator-col-title{padding-right:25px}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable.tabulator-col-sorter-element:hover{cursor:pointer;background-color:#e6e6e6}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=none] .tabulator-col-content .tabulator-col-sorter{color:#bbb}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=none] .tabulator-col-content .tabulator-col-sorter.tabulator-col-sorter-element .tabulator-arrow:hover{cursor:pointer;border-bottom:6px solid #555}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=none] .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{border-top:none;border-bottom:6px solid #bbb}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=ascending] .tabulator-col-content .tabulator-col-sorter{color:#666}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=ascending] .tabulator-col-content .tabulator-col-sorter.tabulator-col-sorter-element .tabulator-arrow:hover{cursor:pointer;border-bottom:6px solid #555}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=ascending] .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{border-top:none;border-bottom:6px solid #666}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=descending] .tabulator-col-content .tabulator-col-sorter{color:#666}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=descending] .tabulator-col-content .tabulator-col-sorter.tabulator-col-sorter-element .tabulator-arrow:hover{cursor:pointer;border-top:6px solid #555}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=descending] .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{border-bottom:none;border-top:6px solid #666;color:#666}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical .tabulator-col-content .tabulator-col-title{writing-mode:vertical-rl;text-orientation:mixed;display:flex;align-items:center;justify-content:center}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-col-vertical-flip .tabulator-col-title{transform:rotate(180deg)}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-sortable .tabulator-col-title{padding-right:0;padding-top:20px}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-sortable.tabulator-col-vertical-flip .tabulator-col-title{padding-right:0;padding-bottom:20px}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-sortable .tabulator-col-sorter{justify-content:center;left:0;right:0;top:4px;bottom:auto}.tabulator .tabulator-header .tabulator-frozen{position:sticky;left:0;z-index:10}.tabulator .tabulator-header .tabulator-frozen.tabulator-frozen-left{border-right:2px solid #ddd}.tabulator .tabulator-header .tabulator-frozen.tabulator-frozen-right{border-left:2px solid #ddd}.tabulator .tabulator-header .tabulator-calcs-holder{box-sizing:border-box;background:#fff!important;border-top:1px solid #ddd;border-bottom:1px solid #ddd}.tabulator .tabulator-header .tabulator-calcs-holder .tabulator-row{background:#fff!important}.tabulator .tabulator-header .tabulator-calcs-holder .tabulator-row .tabulator-col-resize-handle,.tabulator .tabulator-header .tabulator-frozen-rows-holder:empty{display:none}.tabulator .tabulator-tableholder{position:relative;width:100%;white-space:nowrap;overflow:auto;-webkit-overflow-scrolling:touch}.tabulator .tabulator-tableholder:focus{outline:none}.tabulator .tabulator-tableholder .tabulator-placeholder{box-sizing:border-box;display:flex;align-items:center;justify-content:center;width:100%}.tabulator .tabulator-tableholder .tabulator-placeholder[tabulator-render-mode=virtual]{min-height:100%;min-width:100%}.tabulator .tabulator-tableholder .tabulator-placeholder .tabulator-placeholder-contents{display:inline-block;text-align:center;padding:10px;color:#ccc;font-weight:700;font-size:20px;white-space:normal}.tabulator .tabulator-tableholder .tabulator-table{position:relative;display:inline-block;background-color:#fff;white-space:nowrap;overflow:visible;color:#333}.tabulator .tabulator-tableholder .tabulator-table .tabulator-row.tabulator-calcs{font-weight:700;background:#f2f2f2!important}.tabulator .tabulator-tableholder .tabulator-table .tabulator-row.tabulator-calcs.tabulator-calcs-top{border-bottom:2px solid #ddd}.tabulator .tabulator-tableholder .tabulator-table .tabulator-row.tabulator-calcs.tabulator-calcs-bottom{border-top:2px solid #ddd}.tabulator .tabulator-footer{border-top:1px solid #999;background-color:#fff;color:#555;font-weight:700;white-space:nowrap;user-select:none;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none}.tabulator .tabulator-footer .tabulator-footer-contents{display:flex;flex-direction:row;align-items:center;justify-content:space-between;padding:5px 10px}.tabulator .tabulator-footer .tabulator-footer-contents:empty{display:none}.tabulator .tabulator-footer .tabulator-calcs-holder{box-sizing:border-box;width:100%;text-align:left;background:#fff!important;border-bottom:1px solid #ddd;border-top:1px solid #ddd;overflow:hidden}.tabulator .tabulator-footer .tabulator-calcs-holder .tabulator-row{display:inline-block;background:#fff!important}.tabulator .tabulator-footer .tabulator-calcs-holder .tabulator-row .tabulator-col-resize-handle{display:none}.tabulator .tabulator-footer .tabulator-calcs-holder:only-child{margin-bottom:-5px;border-bottom:none}.tabulator .tabulator-footer>*+.tabulator-page-counter{margin-left:10px}.tabulator .tabulator-footer .tabulator-page-counter{font-weight:400}.tabulator .tabulator-footer .tabulator-paginator{flex:1;text-align:right;color:#555;font-family:inherit;font-weight:inherit;font-size:inherit}.tabulator .tabulator-footer .tabulator-page-size{display:inline-block;margin:0 5px;padding:2px 5px;border:1px solid #aaa;border-radius:3px}.tabulator .tabulator-footer .tabulator-pages{margin:0 7px}.tabulator .tabulator-footer .tabulator-page{display:inline-block;margin:0 2px;padding:2px 5px;border:1px solid #aaa;border-radius:3px;background:hsla(0,0%,100%,.2)}.tabulator .tabulator-footer .tabulator-page.active{color:#d00}.tabulator .tabulator-footer .tabulator-page:disabled{opacity:.5}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-footer .tabulator-page:not(.disabled):hover{cursor:pointer;background:rgba(0,0,0,.2);color:#fff}}.tabulator .tabulator-col-resize-handle{position:relative;display:inline-block;width:6px;margin-left:-3px;margin-right:-3px;z-index:10;vertical-align:middle}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-col-resize-handle:hover{cursor:ew-resize}}.tabulator .tabulator-col-resize-handle:last-of-type{width:3px;margin-right:0}.tabulator .tabulator-alert{position:absolute;display:flex;align-items:center;top:0;left:0;z-index:100;height:100%;width:100%;background:rgba(0,0,0,.4);text-align:center}.tabulator .tabulator-alert .tabulator-alert-msg{display:inline-block;margin:0 auto;padding:10px 20px;border-radius:10px;background:#fff;font-weight:700;font-size:16px}.tabulator .tabulator-alert .tabulator-alert-msg.tabulator-alert-state-msg{border:4px solid #333;color:#000}.tabulator .tabulator-alert .tabulator-alert-msg.tabulator-alert-state-error{border:4px solid #d00;color:#590000}.tabulator-row{position:relative;box-sizing:border-box;min-height:22px}.tabulator-row,.tabulator-row.tabulator-row-even{background-color:#fff}@media (hover:hover) and (pointer:fine){.tabulator-row.tabulator-selectable:hover{background-color:#bbb;cursor:pointer}}.tabulator-row.tabulator-selected{background-color:#9abcea}@media (hover:hover) and (pointer:fine){.tabulator-row.tabulator-selected:hover{background-color:#769bcc;cursor:pointer}}.tabulator-row.tabulator-row-moving{border:1px solid #000;background:#fff}.tabulator-row.tabulator-moving{position:absolute;border-top:1px solid #ddd;border-bottom:1px solid #ddd;pointer-events:none;z-index:15}.tabulator-row .tabulator-row-resize-handle{position:absolute;right:0;bottom:0;left:0;height:5px}.tabulator-row .tabulator-row-resize-handle.prev{top:0;bottom:auto}@media (hover:hover) and (pointer:fine){.tabulator-row .tabulator-row-resize-handle:hover{cursor:ns-resize}}.tabulator-row .tabulator-responsive-collapse{box-sizing:border-box;padding:5px;border-top:1px solid #ddd;border-bottom:1px solid #ddd}.tabulator-row .tabulator-responsive-collapse:empty{display:none}.tabulator-row .tabulator-responsive-collapse table{font-size:14px}.tabulator-row .tabulator-responsive-collapse table tr td{position:relative}.tabulator-row .tabulator-responsive-collapse table tr td:first-of-type{padding-right:10px}.tabulator-row .tabulator-cell{display:inline-block;position:relative;box-sizing:border-box;padding:4px;border-right:1px solid #ddd;vertical-align:middle;white-space:nowrap;overflow:hidden;text-overflow:ellipsis}.tabulator-row .tabulator-cell.tabulator-frozen{display:inline-block;position:sticky;left:0;background-color:inherit;z-index:10}.tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-left{border-right:2px solid #ddd}.tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-right{border-left:2px solid #ddd}.tabulator-row .tabulator-cell.tabulator-editing{border:1px solid #1d68cd;outline:none;padding:0}.tabulator-row .tabulator-cell.tabulator-editing input,.tabulator-row .tabulator-cell.tabulator-editing select{border:1px;background:transparent;outline:none}.tabulator-row .tabulator-cell.tabulator-validation-fail{border:1px solid #d00}.tabulator-row .tabulator-cell.tabulator-validation-fail input,.tabulator-row .tabulator-cell.tabulator-validation-fail select{border:1px;background:transparent;color:#d00}.tabulator-row .tabulator-cell.tabulator-row-handle{display:inline-flex;align-items:center;justify-content:center;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none}.tabulator-row .tabulator-cell.tabulator-row-handle .tabulator-row-handle-box{width:80%}.tabulator-row .tabulator-cell.tabulator-row-handle .tabulator-row-handle-box .tabulator-row-handle-bar{width:100%;height:3px;margin-top:2px;background:#666}.tabulator-row .tabulator-cell .tabulator-data-tree-branch{display:inline-block;vertical-align:middle;height:9px;width:7px;margin-top:-9px;margin-right:5px;border-bottom-left-radius:1px;border-left:2px solid #ddd;border-bottom:2px solid #ddd}.tabulator-row .tabulator-cell .tabulator-data-tree-control{display:inline-flex;justify-content:center;align-items:center;vertical-align:middle;height:11px;width:11px;margin-right:5px;border:1px solid #333;border-radius:2px;background:rgba(0,0,0,.1);overflow:hidden}@media (hover:hover) and (pointer:fine){.tabulator-row .tabulator-cell .tabulator-data-tree-control:hover{cursor:pointer;background:rgba(0,0,0,.2)}}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-collapse{display:inline-block;position:relative;height:7px;width:1px;background:transparent}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-collapse:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-expand{display:inline-block;position:relative;height:7px;width:1px;background:#333}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-expand:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle{display:inline-flex;align-items:center;justify-content:center;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none;height:15px;width:15px;border-radius:20px;background:#666;color:#fff;font-weight:700;font-size:1.1em}@media (hover:hover) and (pointer:fine){.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle:hover{opacity:.7;cursor:pointer}}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle.open .tabulator-responsive-collapse-toggle-close{display:initial}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle.open .tabulator-responsive-collapse-toggle-open{display:none}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle svg{stroke:#fff}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle .tabulator-responsive-collapse-toggle-close{display:none}.tabulator-row .tabulator-cell .tabulator-traffic-light{display:inline-block;height:14px;width:14px;border-radius:14px}.tabulator-row.tabulator-group{box-sizing:border-box;border-bottom:1px solid #999;border-right:1px solid #ddd;border-top:1px solid #999;padding:5px 5px 5px 10px;background:#ccc;font-weight:700;min-width:100%}@media (hover:hover) and (pointer:fine){.tabulator-row.tabulator-group:hover{cursor:pointer;background-color:rgba(0,0,0,.1)}}.tabulator-row.tabulator-group.tabulator-group-visible .tabulator-arrow{margin-right:10px;border-left:6px solid transparent;border-right:6px solid transparent;border-top:6px solid #666;border-bottom:0}.tabulator-row.tabulator-group.tabulator-group-level-1{padding-left:30px}.tabulator-row.tabulator-group.tabulator-group-level-2{padding-left:50px}.tabulator-row.tabulator-group.tabulator-group-level-3{padding-left:70px}.tabulator-row.tabulator-group.tabulator-group-level-4{padding-left:90px}.tabulator-row.tabulator-group.tabulator-group-level-5{padding-left:110px}.tabulator-row.tabulator-group .tabulator-group-toggle{display:inline-block}.tabulator-row.tabulator-group .tabulator-arrow{display:inline-block;width:0;height:0;margin-right:16px;border-top:6px solid transparent;border-bottom:6px solid transparent;border-right:0;border-left:6px solid #666;vertical-align:middle}.tabulator-row.tabulator-group span{margin-left:10px;color:#d00}.tabulator-popup-container{position:absolute;display:inline-block;box-sizing:border-box;background:#fff;border:1px solid #ddd;box-shadow:0 0 5px 0 rgba(0,0,0,.2);font-size:14px;overflow-y:auto;-webkit-overflow-scrolling:touch;z-index:10000}.tabulator-popup{padding:5px;border-radius:3px}.tabulator-tooltip{max-width:Min(500px,100%);padding:3px 5px;border-radius:2px;box-shadow:none;font-size:12px;pointer-events:none}.tabulator-menu .tabulator-menu-item{position:relative;box-sizing:border-box;padding:5px 10px;user-select:none}.tabulator-menu .tabulator-menu-item.tabulator-menu-item-disabled{opacity:.5}@media (hover:hover) and (pointer:fine){.tabulator-menu .tabulator-menu-item:not(.tabulator-menu-item-disabled):hover{cursor:pointer;background:#fff}}.tabulator-menu .tabulator-menu-item.tabulator-menu-item-submenu{padding-right:25px}.tabulator-menu .tabulator-menu-item.tabulator-menu-item-submenu:after{display:inline-block;position:absolute;top:calc(5px + .4em);right:10px;height:7px;width:7px;content:\\\"\\\";border-color:#ddd;border-style:solid;border-width:1px 1px 0 0;vertical-align:top;transform:rotate(45deg)}.tabulator-menu .tabulator-menu-separator{border-top:1px solid #ddd}.tabulator-edit-list{max-height:200px;font-size:14px;overflow-y:auto;-webkit-overflow-scrolling:touch}.tabulator-edit-list .tabulator-edit-list-item{padding:4px;color:#333;outline:none}.tabulator-edit-list .tabulator-edit-list-item.active{color:#fff;background:#1d68cd}.tabulator-edit-list .tabulator-edit-list-item.active.focused{outline:1px solid hsla(0,0%,100%,.5)}.tabulator-edit-list .tabulator-edit-list-item.focused{outline:1px solid #1d68cd}@media (hover:hover) and (pointer:fine){.tabulator-edit-list .tabulator-edit-list-item:hover{cursor:pointer;color:#fff;background:#1d68cd}}.tabulator-edit-list .tabulator-edit-list-placeholder{padding:4px;color:#333;text-align:center}.tabulator-edit-list .tabulator-edit-list-group{border-bottom:1px solid #ddd;padding:6px 4px 4px;color:#333;font-weight:700}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-2,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-2{padding-left:12px}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-3,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-3{padding-left:20px}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-4,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-4{padding-left:28px}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-5,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-5{padding-left:36px}.tabulator.tabulator-ltr{direction:ltr}.tabulator.tabulator-rtl{text-align:initial;direction:rtl}.tabulator.tabulator-rtl .tabulator-header .tabulator-col{text-align:initial;border-left:1px solid #ddd;border-right:initial}.tabulator.tabulator-rtl .tabulator-header .tabulator-col.tabulator-col-group .tabulator-col-group-cols{margin-right:0;margin-left:-1px}.tabulator.tabulator-rtl .tabulator-header .tabulator-col.tabulator-sortable .tabulator-col-title{padding-right:0;padding-left:25px}.tabulator.tabulator-rtl .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-sorter{left:8px;right:auto}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell{border-right:initial;border-left:1px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell .tabulator-data-tree-branch{margin-right:0;margin-left:5px;border-bottom-left-radius:0;border-bottom-right-radius:1px;border-left:initial;border-right:2px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell .tabulator-data-tree-control{margin-right:0;margin-left:5px}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-left{border-left:2px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-right{border-right:2px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-col-resize-handle:last-of-type{width:3px;margin-left:0;margin-right:-3px}.tabulator.tabulator-rtl .tabulator-footer .tabulator-calcs-holder{text-align:initial}.tabulator-print-fullscreen{position:absolute;top:0;bottom:0;left:0;right:0;z-index:10000}body.tabulator-print-fullscreen-hide>:not(.tabulator-print-fullscreen){display:none!important}.tabulator-print-table{border-collapse:collapse}.tabulator-print-table .tabulator-data-tree-branch{display:inline-block;vertical-align:middle;height:9px;width:7px;margin-top:-9px;margin-right:5px;border-bottom-left-radius:1px;border-left:2px solid #ddd;border-bottom:2px solid #ddd}.tabulator-print-table .tabulator-print-table-group{box-sizing:border-box;border-bottom:1px solid #999;border-right:1px solid #ddd;border-top:1px solid #999;padding:5px 5px 5px 10px;background:#ccc;font-weight:700;min-width:100%}@media (hover:hover) and (pointer:fine){.tabulator-print-table .tabulator-print-table-group:hover{cursor:pointer;background-color:rgba(0,0,0,.1)}}.tabulator-print-table .tabulator-print-table-group.tabulator-group-visible .tabulator-arrow{margin-right:10px;border-left:6px solid transparent;border-right:6px solid transparent;border-top:6px solid #666;border-bottom:0}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-1 td{padding-left:30px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-2 td{padding-left:50px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-3 td{padding-left:70px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-4 td{padding-left:90px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-5 td{padding-left:110px!important}.tabulator-print-table .tabulator-print-table-group .tabulator-group-toggle{display:inline-block}.tabulator-print-table .tabulator-print-table-group .tabulator-arrow{display:inline-block;width:0;height:0;margin-right:16px;border-top:6px solid transparent;border-bottom:6px solid transparent;border-right:0;border-left:6px solid #666;vertical-align:middle}.tabulator-print-table .tabulator-print-table-group span{color:#d00}.tabulator-print-table .tabulator-data-tree-control{display:inline-flex;justify-content:center;align-items:center;vertical-align:middle;height:11px;width:11px;margin-right:5px;border:1px solid #333;border-radius:2px;background:rgba(0,0,0,.1);overflow:hidden}@media (hover:hover) and (pointer:fine){.tabulator-print-table .tabulator-data-tree-control:hover{cursor:pointer;background:rgba(0,0,0,.2)}}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-collapse{display:inline-block;position:relative;height:7px;width:1px;background:transparent}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-collapse:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-expand{display:inline-block;position:relative;height:7px;width:1px;background:#333}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-expand:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator{border:none;background-color:#fff}.tabulator .tabulator-header .tabulator-calcs-holder{background:#f2f2f2!important;border-bottom:1px solid #999}.tabulator .tabulator-header .tabulator-calcs-holder .tabulator-row{background:#f2f2f2!important}.tabulator .tabulator-tableholder .tabulator-placeholder span{color:#000}.tabulator .tabulator-footer .tabulator-calcs-holder{background:#f2f2f2!important;border-bottom:1px solid #fff}.tabulator .tabulator-footer .tabulator-calcs-holder .tabulator-row{background:#f2f2f2!important}.tabulator-row{border-bottom:1px solid #ddd}.tabulator-row .tabulator-cell:last-of-type{border-right:none}.tabulator-row.tabulator-group span{color:#666}.tabulator-print-table .tabulator-print-table-group span{margin-left:10px;color:#666}\\n/*# sourceMappingURL=tabulator_simple.min.css.map */\");\n    },    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      Bokeh = root.Bokeh;\n      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      if (!reloading && (!bokeh_loaded || is_dev)) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.2.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n  var reloading = true;\n  var Bokeh = root.Bokeh;\n  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'tabulator': 'https://cdn.jsdelivr.net/npm/tabulator-tables@5.5.0/dist/js/tabulator', 'moment': 'https://cdn.jsdelivr.net/npm/luxon/build/global/luxon.min', 'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"tabulator\"], function(Tabulator) {\n\twindow.Tabulator = Tabulator\n\ton_load()\n      })\n      require([\"moment\"], function(moment) {\n\twindow.moment = moment\n\ton_load()\n      })\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 11;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['Tabulator'] !== undefined) && (!(window['Tabulator'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/js/tabulator.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['moment'] !== undefined) && (!(window['moment'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/luxon/build/global/luxon.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/js/tabulator.js\", \"https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/luxon/build/global/luxon.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [\"https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/css/tabulator_simple.min.css\"];\n  var inline_js = [    function(Bokeh) {\n      inject_raw_css(\".tabulator{position:relative;border:1px solid #999;font-size:14px;text-align:left;overflow:hidden;-webkit-transform:translateZ(0);-moz-transform:translateZ(0);-ms-transform:translateZ(0);-o-transform:translateZ(0);transform:translateZ(0)}.tabulator[tabulator-layout=fitDataFill] .tabulator-tableholder .tabulator-table{min-width:100%}.tabulator[tabulator-layout=fitDataTable]{display:inline-block}.tabulator.tabulator-block-select{user-select:none}.tabulator .tabulator-header{position:relative;box-sizing:border-box;width:100%;border-bottom:1px solid #999;background-color:#fff;color:#555;font-weight:700;white-space:nowrap;overflow:hidden;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none}.tabulator .tabulator-header.tabulator-header-hidden{display:none}.tabulator .tabulator-header .tabulator-header-contents{position:relative;overflow:hidden}.tabulator .tabulator-header .tabulator-header-contents .tabulator-headers{display:inline-block}.tabulator .tabulator-header .tabulator-col{display:inline-flex;position:relative;box-sizing:border-box;flex-direction:column;justify-content:flex-start;border-right:1px solid #ddd;background:#fff;text-align:left;vertical-align:bottom;overflow:hidden}.tabulator .tabulator-header .tabulator-col.tabulator-moving{position:absolute;border:1px solid #999;background:#e6e6e6;pointer-events:none}.tabulator .tabulator-header .tabulator-col .tabulator-col-content{box-sizing:border-box;position:relative;padding:4px}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-header-popup-button{padding:0 8px}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-header-popup-button:hover{cursor:pointer;opacity:.6}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title-holder{position:relative}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title{box-sizing:border-box;width:100%;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;vertical-align:bottom}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title.tabulator-col-title-wrap{white-space:normal;text-overflow:clip}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title .tabulator-title-editor{box-sizing:border-box;width:100%;border:1px solid #999;padding:1px;background:#fff}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title .tabulator-header-popup-button+.tabulator-title-editor{width:calc(100% - 22px)}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-sorter{display:flex;align-items:center;position:absolute;top:0;bottom:0;right:4px}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{width:0;height:0;border-left:6px solid transparent;border-right:6px solid transparent;border-bottom:6px solid #bbb}.tabulator .tabulator-header .tabulator-col.tabulator-col-group .tabulator-col-group-cols{position:relative;display:flex;border-top:1px solid #ddd;overflow:hidden;margin-right:-1px}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter{position:relative;box-sizing:border-box;margin-top:2px;width:100%;text-align:center}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter textarea{height:auto!important}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter svg{margin-top:3px}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter input::-ms-clear{width:0;height:0}.tabulator .tabulator-header .tabulator-col.tabulator-sortable .tabulator-col-title{padding-right:25px}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable.tabulator-col-sorter-element:hover{cursor:pointer;background-color:#e6e6e6}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=none] .tabulator-col-content .tabulator-col-sorter{color:#bbb}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=none] .tabulator-col-content .tabulator-col-sorter.tabulator-col-sorter-element .tabulator-arrow:hover{cursor:pointer;border-bottom:6px solid #555}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=none] .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{border-top:none;border-bottom:6px solid #bbb}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=ascending] .tabulator-col-content .tabulator-col-sorter{color:#666}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=ascending] .tabulator-col-content .tabulator-col-sorter.tabulator-col-sorter-element .tabulator-arrow:hover{cursor:pointer;border-bottom:6px solid #555}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=ascending] .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{border-top:none;border-bottom:6px solid #666}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=descending] .tabulator-col-content .tabulator-col-sorter{color:#666}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=descending] .tabulator-col-content .tabulator-col-sorter.tabulator-col-sorter-element .tabulator-arrow:hover{cursor:pointer;border-top:6px solid #555}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=descending] .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{border-bottom:none;border-top:6px solid #666;color:#666}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical .tabulator-col-content .tabulator-col-title{writing-mode:vertical-rl;text-orientation:mixed;display:flex;align-items:center;justify-content:center}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-col-vertical-flip .tabulator-col-title{transform:rotate(180deg)}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-sortable .tabulator-col-title{padding-right:0;padding-top:20px}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-sortable.tabulator-col-vertical-flip .tabulator-col-title{padding-right:0;padding-bottom:20px}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-sortable .tabulator-col-sorter{justify-content:center;left:0;right:0;top:4px;bottom:auto}.tabulator .tabulator-header .tabulator-frozen{position:sticky;left:0;z-index:10}.tabulator .tabulator-header .tabulator-frozen.tabulator-frozen-left{border-right:2px solid #ddd}.tabulator .tabulator-header .tabulator-frozen.tabulator-frozen-right{border-left:2px solid #ddd}.tabulator .tabulator-header .tabulator-calcs-holder{box-sizing:border-box;background:#fff!important;border-top:1px solid #ddd;border-bottom:1px solid #ddd}.tabulator .tabulator-header .tabulator-calcs-holder .tabulator-row{background:#fff!important}.tabulator .tabulator-header .tabulator-calcs-holder .tabulator-row .tabulator-col-resize-handle,.tabulator .tabulator-header .tabulator-frozen-rows-holder:empty{display:none}.tabulator .tabulator-tableholder{position:relative;width:100%;white-space:nowrap;overflow:auto;-webkit-overflow-scrolling:touch}.tabulator .tabulator-tableholder:focus{outline:none}.tabulator .tabulator-tableholder .tabulator-placeholder{box-sizing:border-box;display:flex;align-items:center;justify-content:center;width:100%}.tabulator .tabulator-tableholder .tabulator-placeholder[tabulator-render-mode=virtual]{min-height:100%;min-width:100%}.tabulator .tabulator-tableholder .tabulator-placeholder .tabulator-placeholder-contents{display:inline-block;text-align:center;padding:10px;color:#ccc;font-weight:700;font-size:20px;white-space:normal}.tabulator .tabulator-tableholder .tabulator-table{position:relative;display:inline-block;background-color:#fff;white-space:nowrap;overflow:visible;color:#333}.tabulator .tabulator-tableholder .tabulator-table .tabulator-row.tabulator-calcs{font-weight:700;background:#f2f2f2!important}.tabulator .tabulator-tableholder .tabulator-table .tabulator-row.tabulator-calcs.tabulator-calcs-top{border-bottom:2px solid #ddd}.tabulator .tabulator-tableholder .tabulator-table .tabulator-row.tabulator-calcs.tabulator-calcs-bottom{border-top:2px solid #ddd}.tabulator .tabulator-footer{border-top:1px solid #999;background-color:#fff;color:#555;font-weight:700;white-space:nowrap;user-select:none;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none}.tabulator .tabulator-footer .tabulator-footer-contents{display:flex;flex-direction:row;align-items:center;justify-content:space-between;padding:5px 10px}.tabulator .tabulator-footer .tabulator-footer-contents:empty{display:none}.tabulator .tabulator-footer .tabulator-calcs-holder{box-sizing:border-box;width:100%;text-align:left;background:#fff!important;border-bottom:1px solid #ddd;border-top:1px solid #ddd;overflow:hidden}.tabulator .tabulator-footer .tabulator-calcs-holder .tabulator-row{display:inline-block;background:#fff!important}.tabulator .tabulator-footer .tabulator-calcs-holder .tabulator-row .tabulator-col-resize-handle{display:none}.tabulator .tabulator-footer .tabulator-calcs-holder:only-child{margin-bottom:-5px;border-bottom:none}.tabulator .tabulator-footer>*+.tabulator-page-counter{margin-left:10px}.tabulator .tabulator-footer .tabulator-page-counter{font-weight:400}.tabulator .tabulator-footer .tabulator-paginator{flex:1;text-align:right;color:#555;font-family:inherit;font-weight:inherit;font-size:inherit}.tabulator .tabulator-footer .tabulator-page-size{display:inline-block;margin:0 5px;padding:2px 5px;border:1px solid #aaa;border-radius:3px}.tabulator .tabulator-footer .tabulator-pages{margin:0 7px}.tabulator .tabulator-footer .tabulator-page{display:inline-block;margin:0 2px;padding:2px 5px;border:1px solid #aaa;border-radius:3px;background:hsla(0,0%,100%,.2)}.tabulator .tabulator-footer .tabulator-page.active{color:#d00}.tabulator .tabulator-footer .tabulator-page:disabled{opacity:.5}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-footer .tabulator-page:not(.disabled):hover{cursor:pointer;background:rgba(0,0,0,.2);color:#fff}}.tabulator .tabulator-col-resize-handle{position:relative;display:inline-block;width:6px;margin-left:-3px;margin-right:-3px;z-index:10;vertical-align:middle}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-col-resize-handle:hover{cursor:ew-resize}}.tabulator .tabulator-col-resize-handle:last-of-type{width:3px;margin-right:0}.tabulator .tabulator-alert{position:absolute;display:flex;align-items:center;top:0;left:0;z-index:100;height:100%;width:100%;background:rgba(0,0,0,.4);text-align:center}.tabulator .tabulator-alert .tabulator-alert-msg{display:inline-block;margin:0 auto;padding:10px 20px;border-radius:10px;background:#fff;font-weight:700;font-size:16px}.tabulator .tabulator-alert .tabulator-alert-msg.tabulator-alert-state-msg{border:4px solid #333;color:#000}.tabulator .tabulator-alert .tabulator-alert-msg.tabulator-alert-state-error{border:4px solid #d00;color:#590000}.tabulator-row{position:relative;box-sizing:border-box;min-height:22px}.tabulator-row,.tabulator-row.tabulator-row-even{background-color:#fff}@media (hover:hover) and (pointer:fine){.tabulator-row.tabulator-selectable:hover{background-color:#bbb;cursor:pointer}}.tabulator-row.tabulator-selected{background-color:#9abcea}@media (hover:hover) and (pointer:fine){.tabulator-row.tabulator-selected:hover{background-color:#769bcc;cursor:pointer}}.tabulator-row.tabulator-row-moving{border:1px solid #000;background:#fff}.tabulator-row.tabulator-moving{position:absolute;border-top:1px solid #ddd;border-bottom:1px solid #ddd;pointer-events:none;z-index:15}.tabulator-row .tabulator-row-resize-handle{position:absolute;right:0;bottom:0;left:0;height:5px}.tabulator-row .tabulator-row-resize-handle.prev{top:0;bottom:auto}@media (hover:hover) and (pointer:fine){.tabulator-row .tabulator-row-resize-handle:hover{cursor:ns-resize}}.tabulator-row .tabulator-responsive-collapse{box-sizing:border-box;padding:5px;border-top:1px solid #ddd;border-bottom:1px solid #ddd}.tabulator-row .tabulator-responsive-collapse:empty{display:none}.tabulator-row .tabulator-responsive-collapse table{font-size:14px}.tabulator-row .tabulator-responsive-collapse table tr td{position:relative}.tabulator-row .tabulator-responsive-collapse table tr td:first-of-type{padding-right:10px}.tabulator-row .tabulator-cell{display:inline-block;position:relative;box-sizing:border-box;padding:4px;border-right:1px solid #ddd;vertical-align:middle;white-space:nowrap;overflow:hidden;text-overflow:ellipsis}.tabulator-row .tabulator-cell.tabulator-frozen{display:inline-block;position:sticky;left:0;background-color:inherit;z-index:10}.tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-left{border-right:2px solid #ddd}.tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-right{border-left:2px solid #ddd}.tabulator-row .tabulator-cell.tabulator-editing{border:1px solid #1d68cd;outline:none;padding:0}.tabulator-row .tabulator-cell.tabulator-editing input,.tabulator-row .tabulator-cell.tabulator-editing select{border:1px;background:transparent;outline:none}.tabulator-row .tabulator-cell.tabulator-validation-fail{border:1px solid #d00}.tabulator-row .tabulator-cell.tabulator-validation-fail input,.tabulator-row .tabulator-cell.tabulator-validation-fail select{border:1px;background:transparent;color:#d00}.tabulator-row .tabulator-cell.tabulator-row-handle{display:inline-flex;align-items:center;justify-content:center;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none}.tabulator-row .tabulator-cell.tabulator-row-handle .tabulator-row-handle-box{width:80%}.tabulator-row .tabulator-cell.tabulator-row-handle .tabulator-row-handle-box .tabulator-row-handle-bar{width:100%;height:3px;margin-top:2px;background:#666}.tabulator-row .tabulator-cell .tabulator-data-tree-branch{display:inline-block;vertical-align:middle;height:9px;width:7px;margin-top:-9px;margin-right:5px;border-bottom-left-radius:1px;border-left:2px solid #ddd;border-bottom:2px solid #ddd}.tabulator-row .tabulator-cell .tabulator-data-tree-control{display:inline-flex;justify-content:center;align-items:center;vertical-align:middle;height:11px;width:11px;margin-right:5px;border:1px solid #333;border-radius:2px;background:rgba(0,0,0,.1);overflow:hidden}@media (hover:hover) and (pointer:fine){.tabulator-row .tabulator-cell .tabulator-data-tree-control:hover{cursor:pointer;background:rgba(0,0,0,.2)}}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-collapse{display:inline-block;position:relative;height:7px;width:1px;background:transparent}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-collapse:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-expand{display:inline-block;position:relative;height:7px;width:1px;background:#333}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-expand:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle{display:inline-flex;align-items:center;justify-content:center;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none;height:15px;width:15px;border-radius:20px;background:#666;color:#fff;font-weight:700;font-size:1.1em}@media (hover:hover) and (pointer:fine){.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle:hover{opacity:.7;cursor:pointer}}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle.open .tabulator-responsive-collapse-toggle-close{display:initial}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle.open .tabulator-responsive-collapse-toggle-open{display:none}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle svg{stroke:#fff}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle .tabulator-responsive-collapse-toggle-close{display:none}.tabulator-row .tabulator-cell .tabulator-traffic-light{display:inline-block;height:14px;width:14px;border-radius:14px}.tabulator-row.tabulator-group{box-sizing:border-box;border-bottom:1px solid #999;border-right:1px solid #ddd;border-top:1px solid #999;padding:5px 5px 5px 10px;background:#ccc;font-weight:700;min-width:100%}@media (hover:hover) and (pointer:fine){.tabulator-row.tabulator-group:hover{cursor:pointer;background-color:rgba(0,0,0,.1)}}.tabulator-row.tabulator-group.tabulator-group-visible .tabulator-arrow{margin-right:10px;border-left:6px solid transparent;border-right:6px solid transparent;border-top:6px solid #666;border-bottom:0}.tabulator-row.tabulator-group.tabulator-group-level-1{padding-left:30px}.tabulator-row.tabulator-group.tabulator-group-level-2{padding-left:50px}.tabulator-row.tabulator-group.tabulator-group-level-3{padding-left:70px}.tabulator-row.tabulator-group.tabulator-group-level-4{padding-left:90px}.tabulator-row.tabulator-group.tabulator-group-level-5{padding-left:110px}.tabulator-row.tabulator-group .tabulator-group-toggle{display:inline-block}.tabulator-row.tabulator-group .tabulator-arrow{display:inline-block;width:0;height:0;margin-right:16px;border-top:6px solid transparent;border-bottom:6px solid transparent;border-right:0;border-left:6px solid #666;vertical-align:middle}.tabulator-row.tabulator-group span{margin-left:10px;color:#d00}.tabulator-popup-container{position:absolute;display:inline-block;box-sizing:border-box;background:#fff;border:1px solid #ddd;box-shadow:0 0 5px 0 rgba(0,0,0,.2);font-size:14px;overflow-y:auto;-webkit-overflow-scrolling:touch;z-index:10000}.tabulator-popup{padding:5px;border-radius:3px}.tabulator-tooltip{max-width:Min(500px,100%);padding:3px 5px;border-radius:2px;box-shadow:none;font-size:12px;pointer-events:none}.tabulator-menu .tabulator-menu-item{position:relative;box-sizing:border-box;padding:5px 10px;user-select:none}.tabulator-menu .tabulator-menu-item.tabulator-menu-item-disabled{opacity:.5}@media (hover:hover) and (pointer:fine){.tabulator-menu .tabulator-menu-item:not(.tabulator-menu-item-disabled):hover{cursor:pointer;background:#fff}}.tabulator-menu .tabulator-menu-item.tabulator-menu-item-submenu{padding-right:25px}.tabulator-menu .tabulator-menu-item.tabulator-menu-item-submenu:after{display:inline-block;position:absolute;top:calc(5px + .4em);right:10px;height:7px;width:7px;content:\\\"\\\";border-color:#ddd;border-style:solid;border-width:1px 1px 0 0;vertical-align:top;transform:rotate(45deg)}.tabulator-menu .tabulator-menu-separator{border-top:1px solid #ddd}.tabulator-edit-list{max-height:200px;font-size:14px;overflow-y:auto;-webkit-overflow-scrolling:touch}.tabulator-edit-list .tabulator-edit-list-item{padding:4px;color:#333;outline:none}.tabulator-edit-list .tabulator-edit-list-item.active{color:#fff;background:#1d68cd}.tabulator-edit-list .tabulator-edit-list-item.active.focused{outline:1px solid hsla(0,0%,100%,.5)}.tabulator-edit-list .tabulator-edit-list-item.focused{outline:1px solid #1d68cd}@media (hover:hover) and (pointer:fine){.tabulator-edit-list .tabulator-edit-list-item:hover{cursor:pointer;color:#fff;background:#1d68cd}}.tabulator-edit-list .tabulator-edit-list-placeholder{padding:4px;color:#333;text-align:center}.tabulator-edit-list .tabulator-edit-list-group{border-bottom:1px solid #ddd;padding:6px 4px 4px;color:#333;font-weight:700}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-2,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-2{padding-left:12px}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-3,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-3{padding-left:20px}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-4,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-4{padding-left:28px}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-5,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-5{padding-left:36px}.tabulator.tabulator-ltr{direction:ltr}.tabulator.tabulator-rtl{text-align:initial;direction:rtl}.tabulator.tabulator-rtl .tabulator-header .tabulator-col{text-align:initial;border-left:1px solid #ddd;border-right:initial}.tabulator.tabulator-rtl .tabulator-header .tabulator-col.tabulator-col-group .tabulator-col-group-cols{margin-right:0;margin-left:-1px}.tabulator.tabulator-rtl .tabulator-header .tabulator-col.tabulator-sortable .tabulator-col-title{padding-right:0;padding-left:25px}.tabulator.tabulator-rtl .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-sorter{left:8px;right:auto}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell{border-right:initial;border-left:1px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell .tabulator-data-tree-branch{margin-right:0;margin-left:5px;border-bottom-left-radius:0;border-bottom-right-radius:1px;border-left:initial;border-right:2px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell .tabulator-data-tree-control{margin-right:0;margin-left:5px}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-left{border-left:2px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-right{border-right:2px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-col-resize-handle:last-of-type{width:3px;margin-left:0;margin-right:-3px}.tabulator.tabulator-rtl .tabulator-footer .tabulator-calcs-holder{text-align:initial}.tabulator-print-fullscreen{position:absolute;top:0;bottom:0;left:0;right:0;z-index:10000}body.tabulator-print-fullscreen-hide>:not(.tabulator-print-fullscreen){display:none!important}.tabulator-print-table{border-collapse:collapse}.tabulator-print-table .tabulator-data-tree-branch{display:inline-block;vertical-align:middle;height:9px;width:7px;margin-top:-9px;margin-right:5px;border-bottom-left-radius:1px;border-left:2px solid #ddd;border-bottom:2px solid #ddd}.tabulator-print-table .tabulator-print-table-group{box-sizing:border-box;border-bottom:1px solid #999;border-right:1px solid #ddd;border-top:1px solid #999;padding:5px 5px 5px 10px;background:#ccc;font-weight:700;min-width:100%}@media (hover:hover) and (pointer:fine){.tabulator-print-table .tabulator-print-table-group:hover{cursor:pointer;background-color:rgba(0,0,0,.1)}}.tabulator-print-table .tabulator-print-table-group.tabulator-group-visible .tabulator-arrow{margin-right:10px;border-left:6px solid transparent;border-right:6px solid transparent;border-top:6px solid #666;border-bottom:0}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-1 td{padding-left:30px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-2 td{padding-left:50px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-3 td{padding-left:70px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-4 td{padding-left:90px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-5 td{padding-left:110px!important}.tabulator-print-table .tabulator-print-table-group .tabulator-group-toggle{display:inline-block}.tabulator-print-table .tabulator-print-table-group .tabulator-arrow{display:inline-block;width:0;height:0;margin-right:16px;border-top:6px solid transparent;border-bottom:6px solid transparent;border-right:0;border-left:6px solid #666;vertical-align:middle}.tabulator-print-table .tabulator-print-table-group span{color:#d00}.tabulator-print-table .tabulator-data-tree-control{display:inline-flex;justify-content:center;align-items:center;vertical-align:middle;height:11px;width:11px;margin-right:5px;border:1px solid #333;border-radius:2px;background:rgba(0,0,0,.1);overflow:hidden}@media (hover:hover) and (pointer:fine){.tabulator-print-table .tabulator-data-tree-control:hover{cursor:pointer;background:rgba(0,0,0,.2)}}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-collapse{display:inline-block;position:relative;height:7px;width:1px;background:transparent}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-collapse:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-expand{display:inline-block;position:relative;height:7px;width:1px;background:#333}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-expand:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator{border:none;background-color:#fff}.tabulator .tabulator-header .tabulator-calcs-holder{background:#f2f2f2!important;border-bottom:1px solid #999}.tabulator .tabulator-header .tabulator-calcs-holder .tabulator-row{background:#f2f2f2!important}.tabulator .tabulator-tableholder .tabulator-placeholder span{color:#000}.tabulator .tabulator-footer .tabulator-calcs-holder{background:#f2f2f2!important;border-bottom:1px solid #fff}.tabulator .tabulator-footer .tabulator-calcs-holder .tabulator-row{background:#f2f2f2!important}.tabulator-row{border-bottom:1px solid #ddd}.tabulator-row .tabulator-cell:last-of-type{border-right:none}.tabulator-row.tabulator-group span{color:#666}.tabulator-print-table .tabulator-print-table-group span{margin-left:10px;color:#666}\\n/*# sourceMappingURL=tabulator_simple.min.css.map */\");\n    },    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      Bokeh = root.Bokeh;\n      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      if (!reloading && (!bokeh_loaded || is_dev)) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5a4b473bab74769b578d5a4f8c66a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Column\n",
       "    [0] Tabulator(disabled=True, height=400, page_size=10, pagination='local', selection=[0], show_index=False, sorters=[{'field': 'Modification D...], value=              ...)\n",
       "    [1] Tabulator(disabled=True, height=400, page_size=10, pagination='local', selection=[0], show_index=False, sorters=[{'field': 'Modification D...], value=              ...)\n",
       "    [2] Row\n",
       "        [0] Button(button_type='success', name='Save')\n",
       "        [1] Button(button_type='primary', name='Load')\n",
       "        [2] Button(button_type='warning', name='Compute')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Load Data                                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "active_data_mode_name = 'kdiba'\n",
    "local_session_root_parent_context = IdentifyingContext(format_name=active_data_mode_name) # , animal_name='', configuration_name='one', session_name=a_sess.session_name\n",
    "local_session_root_parent_path = global_data_root_parent_path.joinpath('KDIBA')\n",
    "\n",
    "# [*] - indicates bad or session with a problem\n",
    "# 0, 1, 2, 3, 4, 5, 6, 7, [8], [9], 10, 11, [12], 13, 14, [15], [16], 17, \n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15') # Recomputed 2025-01-20 19:59 -- `ReviewOfWork_2025-01-20.ipynb`\n",
    "curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43') # Recomputed 2025-01-15 18:52 -- ``\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31') # Recomputed 2025-01-16 03:21 \n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19') # Recomputed 2025-01-07 13:31 \n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46') # Recomputed 2024-12-16 19:23 \n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30') ## BLOCKING ERROR with pf2D computation (empty) for 5Hz 2024-12-02 15:24 \n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50') # Recomputed 2024-12-16 19:45 \n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54') # Recomputed 2024-12-16 19:29 -- about 3 good replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3') # Recomputed 2024-12-16 19:32 \n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25') # Recomputed 2024-12-16 19:33 -- about 5 good replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54') # Recomputed 2024-12-16 19:36 -- TONS of good replays, 10+ pages of them \n",
    "\n",
    "local_session_parent_path: Path = local_session_root_parent_path.joinpath(curr_context.animal, curr_context.exper_name) # 'gor01', 'one' - probably not needed anymore\n",
    "basedir: Path = local_session_parent_path.joinpath(curr_context.session_name).resolve()\n",
    "print(f'basedir: {str(basedir)}')\n",
    "\n",
    "\n",
    "\n",
    "epoch_name_includelist = None\n",
    "active_computation_functions_name_includelist=['lap_direction_determination',\n",
    "                                                'pf_computation',\n",
    "                                                'pfdt_computation',\n",
    "                                                # 'firing_rate_trends',\n",
    "                                                # 'pf_dt_sequential_surprise', \n",
    "                                            #    'ratemap_peaks_prominence2d',\n",
    "                                                'position_decoding', \n",
    "                                                # 'position_decoding_two_step', #'directional_decoders_epoch_heuristic_scoring',\n",
    "                                            #    'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping',\n",
    "                                            #     'long_short_inst_spike_rate_groups',\n",
    "                                            #     'long_short_endcap_analysis',\n",
    "                                            \n",
    "]\n",
    "\n",
    "## 'split_to_directional_laps' -- is global\n",
    "\n",
    "\n",
    "\n",
    "# Read if possible:\n",
    "saving_mode = PipelineSavingScheme.SKIP_SAVING\n",
    "force_reload = False\n",
    "\n",
    "# # Force write:\n",
    "# saving_mode = PipelineSavingScheme.TEMP_THEN_OVERWRITE\n",
    "# saving_mode = PipelineSavingScheme.OVERWRITE_IN_PLACE\n",
    "# force_reload = True\n",
    "\n",
    "selector, on_value_change = PipelineJupyterHelpers._build_pipeline_custom_processing_mode_selector_widget(update_global_variable_fn=update_global_variable, debug_print=False, enable_full_view=True)\n",
    "# selector.value = 'clean_run'\n",
    "selector.value = 'continued_run'\n",
    "# selector.value = 'final_run'\n",
    "on_value_change(dict(new=selector.value)) ## do update manually so the workspace variables reflect the set values\n",
    "## TODO: if loading is not possible, we need to change the `saving_mode` so that the new results are properly saved.\n",
    "print(f\"saving_mode: {saving_mode}, force_reload: {force_reload}\")\n",
    "\n",
    "extended_computations_include_includelist_phase_dict: Dict[str, CustomProcessingPhases] = CustomProcessingPhases.get_extended_computations_include_includelist_phase_dict()\n",
    "\n",
    "current_phase: CustomProcessingPhases = CustomProcessingPhases[selector.value]  # Assuming selector.value is an instance of CustomProcessingPhases\n",
    "extended_computations_include_includelist: List[str] = [key for key, value in extended_computations_include_includelist_phase_dict.items() if value <= current_phase]\n",
    "display(extended_computations_include_includelist)\n",
    "force_recompute_override_computations_includelist = None\n",
    "# force_recompute_override_computations_includelist = ['split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous'] # \n",
    "\n",
    "# ## INPUTS: basedir\n",
    "active_session_pickle_file_widget = PipelinePickleFileSelectorWidget(directory=basedir, on_update_global_variable_callback=update_global_variable, on_get_global_variable_callback=get_global_variable)\n",
    "\n",
    "_subfn_load, _subfn_save, _subfn_compute = active_session_pickle_file_widget._build_load_save_callbacks(global_data_root_parent_path=global_data_root_parent_path, active_data_mode_name=active_data_mode_name, basedir=basedir, saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                                             extended_computations_include_includelist=extended_computations_include_includelist, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist)\n",
    "\n",
    "## try selecting the first\n",
    "did_find_valid_selection: bool = active_session_pickle_file_widget.try_select_first_valid_files()\n",
    "\n",
    "# Display the widget\n",
    "active_session_pickle_file_widget.servable()\n",
    "# active_session_pickle_file_widget.try_select_first_valid_files()\n",
    "\n",
    "# OUTPUTS: active_session_pickle_file_widget, widget.active_local_pkl, widget.active_global_pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc6e0657",
   "metadata": {
    "tags": [
     "run-group-0-interactive"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_suffix: \"_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 8, 9]-frateThresh_5.0\"\n",
      "Computing loaded session pickle file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/loadedSessPickle_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 8, 9]-frateThresh_5.0.pkl\"... \tdone.\n",
      "\tdone.\n",
      "\tdone.\n",
      "\tdone.\n",
      "\tdone.\n",
      "\tdone.\n",
      "\tdone.\n",
      "\tdone.\n",
      "\tdone.\n",
      "\tdone.\n",
      "\tdone.\n",
      "\tdone.\n",
      "\tdone.\n",
      "\tdone.\n",
      "\tdone.\n",
      "build_logger(full_logger_string=\"2025-03-18_15-03-59.Apogee.kdiba.gor01.one.2006-6-09_1-22-43\", file_logging_dir: None):\n",
      "done.\n",
      "Loading pickled pipeline success: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\loadedSessPickle_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 8, 9]-frateThresh_5.0.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['lap_direction_determination', 'pf_computation', 'firing_rate_trends', 'position_decoding']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "\t !!!||||||||||||||||||> RUNNING `PostHocPipelineFixup.FINAL_UPDATE_ALL(...)`:\n",
      "starting `PostHocPipelineFixup.FINAL_UPDATE_ALL(...)`...\n",
      "\t !!!||||||||||||||||||> RUNNING `PostHocPipelineFixup.FINAL_FIX_GRID_BIN_BOUNDS(...)`:\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.position_info.mat\"... done.\n",
      "No grid bin bounds were changed. Everything should be up-to-date!\n",
      "\t =================> RUNNING `PostHocPipelineFixup.FINAL_UPDATE_FILEPATHS(...)`:\n",
      "\t =================> RUNNING `PostHocPipelineFixup.FINAL_UPDATE_NON_PBE_EPOCHS(...)`:\n",
      "computing non_PBE epochs for session...\n",
      "\n",
      "Saving non_pbe results results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.non_pbe.npy\"... 2006-6-09_1-22-43.non_pbe.npy saved\n",
      "done.\n",
      "\tDirectionalLapsResult.init_from_pipeline_natural_epochs(...): was_modified: False\n",
      "\tPostHocPipelineFixup.FINAL_UPDATE_ALL(...): did_any_change: False\n",
      "Pipeline loaded from custom pickle!!\n",
      "# ==================================================================================================================== #\n",
      "        # on_load_local -- COMPLETE -- \n",
      "        # ==================================================================================================================== #\n",
      "override_global_computation_results_pickle_path: \"W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43\\output\\global_computation_results_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 8, 9]-frateThresh_5.0.pkl\"\n",
      "included includelist is specified: ['lap_direction_determination', 'pf_computation', 'pfdt_computation', 'position_decoding', 'firing_rate_trends', 'extended_stats', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis', 'split_to_directional_laps', 'merged_directional_placefields', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring', 'non_PBE_epochs_results'], so only performing these extended computations.\n",
      "Running batch_evaluate_required_computations(...) with global_epoch_name: \"maze_any\"\n",
      "heuristic_score_col_names: ['avg_jump_cm', 'travel', 'coverage', 'total_distance_traveled', 'track_coverage_score', 'mseq_len', 'mseq_len_ignoring_intrusions', 'mseq_len_ignoring_intrusions_and_repeats', 'mseq_len_ratio_ignoring_intrusions_and_repeats', 'mseq_tcov', 'mseq_dtrav']\n",
      "done with all batch_evaluate_required_computations(...).\n",
      "Pre-load global computations: needs_computation_output_dict: []\n",
      "Computing loaded session pickle file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/global_computation_results_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 8, 9]-frateThresh_5.0.pkl\"... done.\n",
      "sucessfully_updated_keys: ['DirectionalLaps', 'DirectionalMergedDecoders', 'long_short_leave_one_out_decoding_analysis', 'short_long_pf_overlap_analyses', 'long_short_fr_indicies_analysis', 'jonathan_firing_rate_analysis', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups', 'long_short_endcap', 'DirectionalDecodersDecoded', 'DirectionalDecodersEpochsEvaluations', 'Heuristics', 'TrialByTrialActivity', 'EpochComputations']\n",
      "successfully_loaded_keys: ['DirectionalLaps', 'DirectionalMergedDecoders', 'long_short_leave_one_out_decoding_analysis', 'short_long_pf_overlap_analyses', 'long_short_fr_indicies_analysis', 'jonathan_firing_rate_analysis', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups', 'long_short_endcap', 'DirectionalDecodersDecoded', 'DirectionalDecodersEpochsEvaluations', 'Heuristics', 'TrialByTrialActivity', 'EpochComputations']\n",
      "included includelist is specified: ['lap_direction_determination', 'pf_computation', 'pfdt_computation', 'position_decoding', 'firing_rate_trends', 'extended_stats', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis', 'split_to_directional_laps', 'merged_directional_placefields', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring', 'non_PBE_epochs_results'], so only performing these extended computations.\n",
      "Running batch_evaluate_required_computations(...) with global_epoch_name: \"maze_any\"\n",
      "heuristic_score_col_names: ['avg_jump_cm', 'travel', 'coverage', 'total_distance_traveled', 'track_coverage_score', 'mseq_len', 'mseq_len_ignoring_intrusions', 'mseq_len_ignoring_intrusions_and_repeats', 'mseq_len_ratio_ignoring_intrusions_and_repeats', 'mseq_tcov', 'mseq_dtrav']\n",
      "done with all batch_evaluate_required_computations(...).\n",
      "Post-load global computations: needs_computation_output_dict: []\n",
      "included includelist is specified: ['lap_direction_determination', 'pf_computation', 'pfdt_computation', 'position_decoding', 'firing_rate_trends', 'extended_stats', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis', 'split_to_directional_laps', 'merged_directional_placefields', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring', 'non_PBE_epochs_results'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze_any\"\n",
      "heuristic_score_col_names: ['avg_jump_cm', 'travel', 'coverage', 'total_distance_traveled', 'track_coverage_score', 'mseq_len', 'mseq_len_ignoring_intrusions', 'mseq_len_ignoring_intrusions_and_repeats', 'mseq_len_ratio_ignoring_intrusions_and_repeats', 'mseq_tcov', 'mseq_dtrav']\n",
      "done with all batch_extended_computations(...).\n",
      "no changes in global results.\n",
      "included includelist is specified: ['lap_direction_determination', 'pf_computation', 'pfdt_computation', 'position_decoding', 'firing_rate_trends', 'extended_stats', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis', 'split_to_directional_laps', 'merged_directional_placefields', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring', 'non_PBE_epochs_results'], so only performing these extended computations.\n",
      "Running batch_evaluate_required_computations(...) with global_epoch_name: \"maze_any\"\n",
      "heuristic_score_col_names: ['avg_jump_cm', 'travel', 'coverage', 'total_distance_traveled', 'track_coverage_score', 'mseq_len', 'mseq_len_ignoring_intrusions', 'mseq_len_ignoring_intrusions_and_repeats', 'mseq_len_ratio_ignoring_intrusions_and_repeats', 'mseq_tcov', 'mseq_dtrav']\n",
      "done with all batch_evaluate_required_computations(...).\n",
      "Post-compute validation: needs_computation_output_dict: []\n",
      "included includelist is specified: ['lap_direction_determination', 'pf_computation', 'pfdt_computation', 'position_decoding', 'firing_rate_trends', 'extended_stats', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis', 'split_to_directional_laps', 'merged_directional_placefields', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring', 'non_PBE_epochs_results'], so only performing these extended computations.\n",
      "Running batch_evaluate_required_computations(...) with global_epoch_name: \"maze_any\"\n",
      "heuristic_score_col_names: ['avg_jump_cm', 'travel', 'coverage', 'total_distance_traveled', 'track_coverage_score', 'mseq_len', 'mseq_len_ignoring_intrusions', 'mseq_len_ignoring_intrusions_and_repeats', 'mseq_len_ratio_ignoring_intrusions_and_repeats', 'mseq_tcov', 'mseq_dtrav']\n",
      "done with all batch_evaluate_required_computations(...).\n",
      "Post-load global computations: needs_computation_output_dict: []\n",
      "# ==================================================================================================================== #\n",
      "        # on_load_global -- COMPLETE -- \n",
      "        # ==================================================================================================================== #\n"
     ]
    }
   ],
   "source": [
    "if did_find_valid_selection:\n",
    "\t_subfn_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac6b6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set default local comp pkl:\n",
    "default_selected_local_file_name: str = 'loadedSessPickle.pkl'\n",
    "default_local_section_indicies = [active_session_pickle_file_widget.local_file_browser_widget._data['File Name'].tolist().index(default_selected_local_file_name)]\n",
    "active_session_pickle_file_widget.local_file_browser_widget.selection = default_local_section_indicies\n",
    "\n",
    "## Set default global computation pkl:\n",
    "default_selected_global_file_name: str = 'global_computation_results.pkl'\n",
    "default_global_section_indicies = [active_session_pickle_file_widget.global_file_browser_widget._data['File Name'].tolist().index(default_selected_global_file_name)]\n",
    "active_session_pickle_file_widget.global_file_browser_widget.selection = default_global_section_indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c072a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.IPyWidgets.SaveAsWidget import PipelineBackupWidget\n",
    "\n",
    "backup_widget = PipelineBackupWidget(curr_active_pipeline)\n",
    "backup_widget.servable()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb1135e",
   "metadata": {},
   "source": [
    "## <a id='toc2_1_'></a>[2024-06-25 - Load from saved custom](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5515d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline, custom_suffix, proposed_load_pkl_path = active_session_pickle_file_widget.on_load_local(global_data_root_parent_path=global_data_root_parent_path, active_data_mode_name=active_data_mode_name, basedir=basedir, saving_mode=saving_mode, force_reload=force_reload)\n",
    "curr_active_pipeline = active_session_pickle_file_widget.on_load_global(curr_active_pipeline=curr_active_pipeline, basedir=basedir, extended_computations_include_includelist=extended_computations_include_includelist, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist,\n",
    "                                       skip_global_load=False, force_reload=False, override_global_computation_results_pickle_path=active_session_pickle_file_widget.active_global_pkl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9337ddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads custom pipeline pickles that were saved out via `custom_save_filepaths['pipeline_pkl'] = curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE, active_pickle_filename=custom_save_filenames['pipeline_pkl'])`\n",
    "\n",
    "## INPUTS: global_data_root_parent_path, active_data_mode_name, basedir, saving_mode, force_reload, custom_save_filenames\n",
    "# custom_suffix: str = '_withNewKamranExportedReplays'\n",
    "\n",
    "# custom_suffix: str = '_withNewComputedReplays'\n",
    "# custom_suffix: str = '_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0'\n",
    "\n",
    "# custom_save_filenames = {\n",
    "#     'pipeline_pkl':f'loadedSessPickle{custom_suffix}.pkl',\n",
    "#     'global_computation_pkl':f\"global_computation_results{custom_suffix}.pkl\",\n",
    "#     'pipeline_h5':f'pipeline{custom_suffix}.h5',\n",
    "# }\n",
    "# print(f'custom_save_filenames: {custom_save_filenames}')\n",
    "# custom_save_filepaths = {k:v for k, v in custom_save_filenames.items()}\n",
    "\n",
    "# # ==================================================================================================================== #\n",
    "# # PIPELINE LOADING                                                                                                     #\n",
    "# # ==================================================================================================================== #\n",
    "# # load the custom saved outputs\n",
    "# active_pickle_filename = custom_save_filenames['pipeline_pkl'] # 'loadedSessPickle_withParameters.pkl'\n",
    "# print(f'active_pickle_filename: \"{active_pickle_filename}\"')\n",
    "# # assert active_pickle_filename.exists()\n",
    "# active_session_h5_filename = custom_save_filenames['pipeline_h5'] # 'pipeline_withParameters.h5'\n",
    "# print(f'active_session_h5_filename: \"{active_session_h5_filename}\"')\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "## DO NOT allow recompute if the file doesn't exist!!\n",
    "# Computing loaded session pickle file results : \"W:/Data/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle_withNewComputedReplays.pkl\"... done.\n",
    "# Failure loading W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\loadedSessPickle_withNewComputedReplays.pkl.\n",
    "# proposed_load_pkl_path = basedir.joinpath(active_pickle_filename).resolve()\n",
    "\n",
    "## INPUTS: widget.active_global_pkl, widget.active_global_pkl\n",
    "\n",
    "if active_session_pickle_file_widget.active_global_pkl is None:\n",
    "    skip_global_load: bool = True\n",
    "    override_global_computation_results_pickle_path = None\n",
    "else:\n",
    "    skip_global_load: bool = False\n",
    "    override_global_computation_results_pickle_path = active_session_pickle_file_widget.active_global_pkl.resolve()\n",
    "    Assert.path_exists(override_global_computation_results_pickle_path)\n",
    "    override_global_computation_results_pickle_path\n",
    "\n",
    "\n",
    "proposed_load_pkl_path = active_session_pickle_file_widget.active_local_pkl.resolve()\n",
    "Assert.path_exists(proposed_load_pkl_path)\n",
    "proposed_load_pkl_path\n",
    "\n",
    "custom_suffix: str = active_session_pickle_file_widget.try_extract_custom_suffix()\n",
    "print(f'custom_suffix: \"{custom_suffix}\"')\n",
    "\n",
    "## OUTPUTS: custom_suffix, proposed_load_pkl_path, (override_global_computation_results_pickle_path, skip_global_load)\n",
    "from pyphocorehelpers.Filesystem.path_helpers import set_posix_windows\n",
    "## INPUTS: proposed_load_pkl_path\n",
    "assert proposed_load_pkl_path.exists(), f\"for a saved custom the file must exist!\"\n",
    "\n",
    "epoch_name_includelist=None\n",
    "active_computation_functions_name_includelist=['lap_direction_determination', 'pf_computation','firing_rate_trends', 'position_decoding']\n",
    "\n",
    "with set_posix_windows():\n",
    "    curr_active_pipeline: NeuropyPipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_includelist=epoch_name_includelist,\n",
    "                                            computation_functions_name_includelist=active_computation_functions_name_includelist,\n",
    "                                            saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                            skip_extended_batch_computations=True, debug_print=False, fail_on_exception=True, active_pickle_filename=proposed_load_pkl_path) # , active_pickle_filename = 'loadedSessPickle_withParameters.pkl'\n",
    "\n",
    "## Post Compute Validate 2023-05-16:\n",
    "was_updated = BatchSessionCompletionHandler.post_compute_validate(curr_active_pipeline) ## TODO: need to potentially re-save if was_updated. This will fail because constained versions not ran yet.\n",
    "if was_updated:\n",
    "    print(f'was_updated: {was_updated}')\n",
    "    try:\n",
    "        if saving_mode == PipelineSavingScheme.SKIP_SAVING:\n",
    "            print(f'WARNING: PipelineSavingScheme.SKIP_SAVING but need to save post_compute_validate changes!!')\n",
    "        else:\n",
    "            curr_active_pipeline.save_pipeline(saving_mode=saving_mode)\n",
    "    except Exception as e:\n",
    "        ## TODO: catch/log saving error and indicate that it isn't saved.\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'ERROR RE-SAVING PIPELINE after update. error: {e}')\n",
    "\n",
    "print(f'Pipeline loaded from custom pickle!!')\n",
    "## OUTPUT: curr_active_pipeline\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Global computations loading:                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "# Loads saved global computations that were saved out via: `custom_save_filepaths['global_computation_pkl'] = curr_active_pipeline.save_global_computation_results(override_global_pickle_filename=custom_save_filenames['global_computation_pkl'])`\n",
    "## INPUTS: custom_save_filenames\n",
    "## INPUTS: curr_active_pipeline, override_global_computation_results_pickle_path, extended_computations_include_includelist\n",
    "\n",
    "override_global_computation_results_pickle_path = None\n",
    "# override_global_computation_results_pickle_path = custom_save_filenames['global_computation_pkl']\n",
    "print(f'override_global_computation_results_pickle_path: \"{override_global_computation_results_pickle_path}\"')\n",
    "\n",
    "# Pre-load ___________________________________________________________________________________________________________ #\n",
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Pre-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "# valid_computed_results_output_list\n",
    "\n",
    "# Try Unpickling Global Computations to update pipeline ______________________________________________________________ #\n",
    "if (not force_reload) and (not skip_global_load): # not just force_reload, needs to recompute whenever the computation fails.\n",
    "    try:\n",
    "        # INPUTS: override_global_computation_results_pickle_path\n",
    "        with set_posix_windows():\n",
    "            sucessfully_updated_keys, successfully_loaded_keys = curr_active_pipeline.load_pickled_global_computation_results(override_global_computation_results_pickle_path=override_global_computation_results_pickle_path,\n",
    "                                                                                            allow_overwrite_existing=True, allow_overwrite_existing_allow_keys=extended_computations_include_includelist, ) # is new\n",
    "            print(f'sucessfully_updated_keys: {sucessfully_updated_keys}\\nsuccessfully_loaded_keys: {successfully_loaded_keys}')\n",
    "            did_any_paths_change: bool = curr_active_pipeline.post_load_fixup_sess_basedirs(updated_session_basepath=deepcopy(basedir)) ## use INPUT: basedir\n",
    "            \n",
    "    except FileNotFoundError as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'cannot load global results because pickle file does not exist! Maybe it has never been created? {e}')\n",
    "    except Exception as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'Unhandled exception: cannot load global results: {e}')\n",
    "        raise\n",
    "\n",
    "# Post-Load __________________________________________________________________________________________________________ #\n",
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "\n",
    "\n",
    "\n",
    "## fixup missing paths\n",
    "# self.basepath: WindowsPath('/nfs/turbo/umms-kdiba/KDIBA/gor01/one/2006-6-09_1-22-43')\n",
    "\n",
    "## INPUTS: basedir\n",
    "did_any_paths_change: bool = curr_active_pipeline.post_load_fixup_sess_basedirs(updated_session_basepath=deepcopy(basedir)) ## use INPUT: basedir\n",
    "\n",
    "# Compute ____________________________________________________________________________________________________________ #\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "force_recompute_global = force_reload\n",
    "# force_recompute_global = True\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "if (len(newly_computed_values) > 0):\n",
    "    print(f'newly_computed_values: {newly_computed_values}.')\n",
    "    if (saving_mode.value != 'skip_saving'):\n",
    "        print(f'Saving global results...')\n",
    "        try:\n",
    "            # curr_active_pipeline.global_computation_results.persist_time = datetime.now()\n",
    "            # Try to write out the global computation function results:\n",
    "            curr_active_pipeline.save_global_computation_results()\n",
    "        except Exception as e:\n",
    "            exception_info = sys.exc_info()\n",
    "            e = CapturedException(e, exception_info)\n",
    "            print(f'\\n\\n!!WARNING!!: saving the global results threw the exception: {e}')\n",
    "            print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "    else:\n",
    "        print(f'\\n\\n!!WARNING!!: changes to global results have been made but they will not be saved since saving_mode.value == \"skip_saving\"')\n",
    "        print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "else:\n",
    "    print(f'no changes in global results.')\n",
    "\n",
    "# Post-compute _______________________________________________________________________________________________________ #\n",
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=False, force_recompute_override_computations_includelist=[], debug_print=True)\n",
    "print(f'Post-compute validation: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "\n",
    "# Post-Load __________________________________________________________________________________________________________ #\n",
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "\n",
    "print(f'force_reload: {force_reload}, saving_mode: {saving_mode}')\n",
    "force_reload\n",
    "saving_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f813f01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## indicate that it was loaded with a custom suffix\n",
    "curr_active_pipeline.pickle_path ## correct\n",
    "curr_active_pipeline.global_computation_results_pickle_path ## correct\n",
    "\n",
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE, override_pickle_path=curr_active_pipeline.pickle_path, active_pickle_filename=curr_active_pipeline.pickle_path.name) #active_pickle_filename=\n",
    "curr_active_pipeline.save_global_computation_results(override_global_pickle_path=curr_active_pipeline.global_computation_results_pickle_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49de9fb9",
   "metadata": {},
   "source": [
    "## <a id='toc2_2_'></a>[0Ô∏è‚É£ RESUME Normal Pipeline Load](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9ba82e",
   "metadata": {},
   "source": [
    "## <a id='toc2_3_'></a>[0Ô∏è‚É£ Normal Pipeline Load](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8167df1c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-0",
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-full_session_LOO_decoding_analysis.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "# epoch_name_includelist = ['maze']\n",
    "\n",
    "curr_active_pipeline: NeuropyPipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_includelist=epoch_name_includelist,\n",
    "                                        computation_functions_name_includelist=active_computation_functions_name_includelist,\n",
    "                                        saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                        skip_extended_batch_computations=True, debug_print=True, fail_on_exception=False) #, time_bin_size = 0.025 time_bin_size = 0.058, override_parameters_flat_keypaths_dict = dict(), \n",
    "# , active_pickle_filename = 'loadedSessPickle_withParameters.pkl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b125667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.get_failed_computations()\n",
    "curr_active_pipeline.clear_all_failed_computations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76c7dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# {'maze1_odd': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze2_odd': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze_odd': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze1_even': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze2_even': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze_even': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze1_any': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze2_any': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze_any': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')}}\n",
    "\n",
    "_out = curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_split_to_directional_laps'], fail_on_exception=True, debug_print=True)\n",
    "\n",
    "\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_split_to_directional_laps'], computation_kwargs_list=[{}], \n",
    "#                                                   enabled_filter_names=None, fail_on_exception=True, debug_print=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8edcd94",
   "metadata": {
    "tags": [
     "run-group-0"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "## Post Compute Validate 2023-05-16:\n",
    "# was_updated = BatchSessionCompletionHandler.post_compute_validate(curr_active_pipeline) ## TODO: need to potentially re-save if was_updated. This will fail because constained versions not ran yet.\n",
    "was_updated = False\n",
    "if was_updated:\n",
    "    print(f'was_updated: {was_updated}')\n",
    "    try:\n",
    "        curr_active_pipeline.save_pipeline(saving_mode=saving_mode)\n",
    "    except Exception as e:\n",
    "        ## TODO: catch/log saving error and indicate that it isn't saved.\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'ERROR RE-SAVING PIPELINE after update. error: {e}')\n",
    "\n",
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Pre-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "# valid_computed_results_output_list\n",
    "if not force_reload: # not just force_reload, needs to recompute whenever the computation fails.\n",
    "    try:\n",
    "        # curr_active_pipeline.load_pickled_global_computation_results()\n",
    "        with set_posix_windows():\n",
    "            sucessfully_updated_keys, successfully_loaded_keys = curr_active_pipeline.load_pickled_global_computation_results(allow_overwrite_existing=True, allow_overwrite_existing_allow_keys=extended_computations_include_includelist) # is new\n",
    "            \n",
    "        print(f'sucessfully_updated_keys: {sucessfully_updated_keys}\\nsuccessfully_loaded_keys: {successfully_loaded_keys}')\n",
    "    except FileNotFoundError as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'cannot load global results because pickle file does not exist! Maybe it has never been created? {e}')\n",
    "    except Exception as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'Unhandled exception: cannot load global results: {e}')\n",
    "        raise\n",
    "\n",
    "# Recomputing active_epoch_placefields... \t done.\n",
    "# Recomputing active_epoch_placefields2D... \t done.\n",
    "# WARN: f\"len(self.is_non_firing_time_bin): 30459, self.num_time_windows: 30762\", trying to recompute them....\n",
    "# UNHANDLED EXCEPTION: Unable to allocate 3.46 GiB for an array with shape (15124, 30724) and data type float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9809aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.accumulated_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcac55a8",
   "metadata": {
    "tags": [
     "run-group-0",
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "force_recompute_global = force_reload # Post-load global computations: needs_computation_output_dict: ['rank_order_shuffle_analysis', 'directional_train_test_split', 'short_long_pf_overlap_analyses', 'wcorr_shuffle_analysis', 'extended_pf_peak_information', 'position_decoding_two_step']\n",
    "# force_recompute_global = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4321d2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fail_on_exception = False\n",
    "\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=fail_on_exception, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "if (len(newly_computed_values) > 0):\n",
    "    print(f'newly_computed_values: {newly_computed_values}.')\n",
    "    if (saving_mode.value != 'skip_saving'):\n",
    "        print(f'Saving global results...')\n",
    "        try:\n",
    "            # curr_active_pipeline.global_computation_results.persist_time = datetime.now()\n",
    "            # Try to write out the global computation function results:\n",
    "            curr_active_pipeline.save_global_computation_results()\n",
    "        except Exception as e:\n",
    "            exception_info = sys.exc_info()\n",
    "            e = CapturedException(e, exception_info)\n",
    "            print(f'\\n\\n!!WARNING!!: saving the global results threw the exception: {e}')\n",
    "            print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "    else:\n",
    "        print(f'\\n\\n!!WARNING!!: changes to global results have been made but they will not be saved since saving_mode.value == \"skip_saving\"')\n",
    "        print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "else:\n",
    "    print(f'no changes in global results.')\n",
    "\n",
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=fail_on_exception, progress_print=True,\n",
    "                                                    force_recompute=False, force_recompute_override_computations_includelist=[], debug_print=True)\n",
    "print(f'Post-compute validation: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615018da",
   "metadata": {},
   "source": [
    "## <a id='toc2_4_'></a>[0Ô∏è‚É£ Shared Post-Pipeline load stuff](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c842f5e4",
   "metadata": {
    "tags": [
     "run-group-0-interactive"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding custom suffix: \"_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 8, 9]-frateThresh_5.0\" - BATCH_DATE_TO_USE: \"2025-03-18_Apogee_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 8, 9]-frateThresh_5.0\"\n",
      "collected_outputs_path: C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\output\\collected_outputs\n",
      "CURR_BATCH_OUTPUT_PREFIX: \"2025-03-18_Apogee_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 8, 9]-frateThresh_5.0-2006-6-09_1-22-43\"\n"
     ]
    }
   ],
   "source": [
    "# BATCH_DATE_TO_USE: str = f'{DAY_DATE_TO_USE}_GL'\n",
    "# BATCH_DATE_TO_USE: str = f'{DAY_DATE_TO_USE}_rMBP' # TODO: Change this as needed, templating isn't actually doing anything rn.\n",
    "BATCH_DATE_TO_USE: str = f'{DAY_DATE_TO_USE}_Apogee'\n",
    "# BATCH_DATE_TO_USE: str = f'{DAY_DATE_TO_USE}_Lab'\n",
    " \n",
    "try:\n",
    "    if custom_suffix is not None:\n",
    "        BATCH_DATE_TO_USE = f'{BATCH_DATE_TO_USE}{custom_suffix}'\n",
    "        print(f'Adding custom suffix: \"{custom_suffix}\" - BATCH_DATE_TO_USE: \"{BATCH_DATE_TO_USE}\"')\n",
    "except NameError as err:\n",
    "    custom_suffix = None\n",
    "    print(f'NO CUSTOM SUFFIX.')\n",
    "\n",
    "known_collected_output_paths = [Path(v).resolve() for v in ['/nfs/turbo/umms-kdiba/Data/Output/collected_outputs', '/home/halechr/FastData/collected_outputs/',\n",
    "                                                           '/home/halechr/cloud/turbo/Data/Output/collected_outputs',\n",
    "                                                           r'C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\output\\collected_outputs',\n",
    "                                                           r\"K:\\scratch\\collected_outputs\",\n",
    "                                                           '/Users/pho/data/collected_outputs',\n",
    "                                                          'output/gen_scripts/']]\n",
    "collected_outputs_path = find_first_extant_path(known_collected_output_paths)\n",
    "assert collected_outputs_path.exists(), f\"collected_outputs_path: {collected_outputs_path} does not exist! Is the right computer's config commented out above?\"\n",
    "# fullwidth_path_widget(scripts_output_path, file_name_label='Scripts Output Path:')\n",
    "print(f'collected_outputs_path: {collected_outputs_path}')\n",
    "# collected_outputs_path.mkdir(exist_ok=True)\n",
    "# assert collected_outputs_path.exists()\n",
    "\n",
    "## Build the output prefix from the session context:\n",
    "active_context = curr_active_pipeline.get_session_context()\n",
    "curr_session_name: str = curr_active_pipeline.session_name # '2006-6-08_14-26-15'\n",
    "CURR_BATCH_OUTPUT_PREFIX: str = f\"{BATCH_DATE_TO_USE}-{curr_session_name}\"\n",
    "print(f'CURR_BATCH_OUTPUT_PREFIX: \"{CURR_BATCH_OUTPUT_PREFIX}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606e8116",
   "metadata": {},
   "source": [
    "## <a id='toc2_5_'></a>[Specific Recomputations](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f010d1a9",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "any_most_recent_computation_time, each_epoch_latest_computation_time, each_epoch_each_result_computation_completion_times, (global_computations_latest_computation_time, global_computation_completion_times) = curr_active_pipeline.get_computation_times(debug_print=False)\n",
    "# each_epoch_latest_computation_time\n",
    "each_epoch_each_result_computation_completion_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3d4f61",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd11d0f",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.clear_all_failed_computations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ff30b7",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computation_config.instantaneous_time_bin_size_seconds = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58db94e",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "force_recompute_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f285cd23",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "force_recompute_global = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47820977",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "extended_computations_include_includelist=['lap_direction_determination', 'pf_computation', 'firing_rate_trends', 'pfdt_computation',\n",
    "    # 'pf_dt_sequential_surprise',\n",
    "    #  'ratemap_peaks_prominence2d',\n",
    "    'extended_stats',\n",
    "    'long_short_decoding_analyses',\n",
    "    'jonathan_firing_rate_analysis',\n",
    "    'long_short_fr_indicies_analyses',\n",
    "    'short_long_pf_overlap_analyses',\n",
    "    'long_short_post_decoding',\n",
    "    # 'long_short_rate_remapping',\n",
    "    'long_short_inst_spike_rate_groups',\n",
    "    'long_short_endcap_analysis',\n",
    "    # 'spike_burst_detection',\n",
    "    'split_to_directional_laps',\n",
    "    'merged_directional_placefields',\n",
    "    # 'rank_order_shuffle_analysis',\n",
    "    # 'directional_decoders_decode_continuous',\n",
    "    # 'directional_decoders_evaluate_epochs',\n",
    "    # 'directional_decoders_epoch_heuristic_scoring',\n",
    "] # do only specified\n",
    "\n",
    "# ['split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous']\n",
    "\n",
    "# force_recompute_override_computations_includelist = [\n",
    "#     'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring',\n",
    "#     'split_to_directional_laps', 'lap_direction_determination', 'DirectionalLaps',\n",
    "#     'merged_directional_placefields',\n",
    "#     'directional_decoders_decode_continuous',\n",
    "# ]\n",
    "force_recompute_override_computations_includelist = None\n",
    "\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "newly_computed_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc0a702",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# extended_computations_include_includelist=['ratemap_peaks_prominence2d', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring',] # do only specified\n",
    "extended_computations_include_includelist=['rank_order_shuffle_analysis', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'ratemap_peaks_prominence2d', ] # do only specified\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db62d145",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "newly_computed_values = curr_active_pipeline.batch_extended_computations(include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = curr_active_pipeline.batch_evaluate_required_computations(include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02779f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27120a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "newly_computed_values = curr_active_pipeline.batch_extended_computations(include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3927a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = curr_active_pipeline.batch_evaluate_required_computations(include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8b307a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d357f9",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# mmm ## lots of m's to break computations\n",
    "\n",
    "## Next wave of computations\n",
    "extended_computations_include_includelist=['directional_decoders_epoch_heuristic_scoring',] # do only specified\n",
    "force_recompute_override_computations_includelist = deepcopy(extended_computations_include_includelist)\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272e20f8",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# 'rank_order_shuffle_analysis',\n",
    "## Next wave of computations\n",
    "extended_computations_include_includelist=['rank_order_shuffle_analysis'] # do only specified\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3efc4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'lap_direction_determination'\n",
    "extended_computations_include_includelist=['_split_to_directional_laps'] # do only specified\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=True)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_split_to_directional_laps'], computation_kwargs_list=None, enabled_filter_names=None, fail_on_exception=True, debug_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d834f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "curr_active_pipeline.get_failed_computations() # 'maze1_odd': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:973<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')}\n",
    "\n",
    "# curr_active_pipeline.rerun_failed_computations()\n",
    "# curr_active_pipeline.stage.rerun_failed_computations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74119ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Computation import ComputedPipelineStage, PipelineWithComputedPipelineStageMixin\n",
    "\n",
    "curr_active_pipeline.clear_all_failed_computations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d510c66",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# # Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "# newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True,\n",
    "#                                                     force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "\n",
    "\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['rank_order_shuffle_analysis','_add_extended_pf_peak_information',\n",
    " '_build_trial_by_trial_activity_metrics',\n",
    " '_decode_and_evaluate_epochs_using_directional_decoders',\n",
    " '_decode_continuous_using_directional_decoders',\n",
    " '_decoded_epochs_heuristic_scoring',\n",
    " '_split_train_test_laps_data',\n",
    " 'perform_wcorr_shuffle_analysis'], computation_kwargs_list=[{'num_shuffles': 100, 'skip_laps': False, 'minimum_inclusion_fr_Hz':2.0, 'included_qclu_values':[1,2,4,5,6,7]}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "\n",
    "\n",
    "force_recompute_override_computation_kwargs_dict = {'rank_order_shuffle_analysis': {'num_shuffles': 100, 'skip_laps': False, 'minimum_inclusion_fr_Hz':2.0, 'included_qclu_values':[1,2,4,5,6,7]},\n",
    " \n",
    "}\n",
    "\n",
    "force_recompute_override_computations_includelist = list(force_recompute_override_computation_kwargs_dict.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9bb808",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['rank_order_shuffle_analysis'], computation_kwargs_list=[{'num_shuffles': 5, 'skip_laps': False, 'minimum_inclusion_fr_Hz':2.0, 'included_qclu_values':[1,2,4,5,6,7]}], \n",
    "                                                  enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b985437c",
   "metadata": {
    "tags": [
     "run-continuous-decoding"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'],\n",
    "                                                  # computation_kwargs_list=[{'time_bin_size': 0.016, 'should_disable_cache':False}], \n",
    "                                                  computation_kwargs_list=[{'time_bin_size': 0.025, 'should_disable_cache':True}], \n",
    "                                                  # computation_kwargs_list=[{'time_bin_size': 0.058, 'should_disable_cache':False}], \n",
    "                                                  enabled_filter_names=None, fail_on_exception=True, debug_print=True)\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'], computation_kwargs_list=[{'time_bin_size': 0.058}], #computation_kwargs_list=[{'time_bin_size': 0.025}], \n",
    "#                                                   enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5c35cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.accumulated_errors\n",
    "curr_active_pipeline.global_computation_results.computation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99a2f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ac9f88",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# curr_active_pipeline.reload_default_computation_functions()\n",
    "# force_recompute_override_computations_includelist = ['_decode_continuous_using_directional_decoders']\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_decode_continuous_using_directional_decoders'], force_recompute_override_computations_includelist=force_recompute_override_computations_includelist,\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t   enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_decode_continuous_using_directional_decoders'], computation_kwargs_list=[{'time_bin_size': 0.025}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "# curr_active_pipeline.perform_specific_computation(extended_computations_include_includelist=['_decode_continuous_using_directional_decoders'], computation_kwargs_list=[{'time_bin_size': 0.02}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['merged_directional_placefields', 'directional_decoders_decode_continuous'], computation_kwargs_list=[{'laps_decoding_time_bin_size': 0.058}, {'time_bin_size': 0.058, 'should_disable_cache':False}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['merged_directional_placefields'], computation_kwargs_list=[{'laps_decoding_time_bin_size': 0.025}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "\n",
    "# 2024-04-20 - HACK -- FIXME: Invert the 'is_LR_dir' column since it is clearly reversed. No clue why.\n",
    "# fails due to some types thing?\n",
    "# \terr: Length of values (82) does not match length of index (80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd3dca2",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f748deeb",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# minimum ~10ms\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['merged_directional_placefields'], computation_kwargs_list=[{'ripple_decoding_time_bin_size': 0.002, 'laps_decoding_time_bin_size': 0.002}], enabled_filter_names=None, fail_on_exception=True, debug_print=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9ffa88",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# minimum ~10ms\n",
    "\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_evaluate_epochs'], computation_kwargs_list=[{'should_skip_radon_transform': True}], enabled_filter_names=None, fail_on_exception=True, debug_print=True)\n",
    "# ## produces: 'DirectionalDecodersEpochsEvaluations'\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_epoch_heuristic_scoring'], enabled_filter_names=None, fail_on_exception=True, debug_print=False) # OK FOR PICKLE\n",
    "\n",
    "time_bin_size: float = 0.058\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['merged_directional_placefields', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring'],\n",
    "                                                   computation_kwargs_list=[{'ripple_decoding_time_bin_size': time_bin_size, 'laps_decoding_time_bin_size': time_bin_size}, {'time_bin_size': time_bin_size}, {'should_skip_radon_transform': True},\n",
    "                                                                             {'same_thresh_fraction_of_track': 0.05, 'max_ignore_bins': 2, 'use_bin_units_instead_of_realworld': False, 'max_jump_distance_cm': 60.0}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b6a587",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring'],\n",
    "                                                   computation_kwargs_list=[{'should_skip_radon_transform': True},\n",
    "                                                                             {'same_thresh_fraction_of_track': 0.05, 'max_ignore_bins': 2, 'use_bin_units_instead_of_realworld': False, 'max_jump_distance_cm': 60.0}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e2eddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_global_computation_function_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0479935f",
   "metadata": {
    "tags": [
     "run-heuristic-filter-recompute"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_epoch_heuristic_scoring'],\n",
    "                                                   computation_kwargs_list=[{'same_thresh_fraction_of_track': 0.05, 'max_ignore_bins': 2, 'use_bin_units_instead_of_realworld': False, 'max_jump_distance_cm': 60.0}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92db81b",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# MemoryError: Unable to allocate 9.74 GiB for an array with shape (57, 22940809) and data type float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc02d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.SpecificComputationValidation import SpecificComputationValidator\n",
    "\n",
    "curr_active_pipeline.find_validators_providing_results('DirectionalDecodersEpochsEvaluations') ## answer: '_decode_and_evaluate_epochs_using_directional_decoders' or 'directional_decoders_evaluate_epochs'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f372737e",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['ratemap_peaks_prominence2d'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39417243",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['lap_direction_determination'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb81c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['non_PBE_epochs_results'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89757a66",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.utils.efficient_interval_search import filter_epochs_by_num_active_units\n",
    "\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_perform_long_short_firing_rate_analyses'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2745bd",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['EloyAnalysis'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4130eb2e",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_train_test_split'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72d567e",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['trial_by_trial_metrics'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da92d47",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['perform_wcorr_shuffle_analysis'], computation_kwargs_list=[{'num_shuffles': 350}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52a8eb8",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['merged_directional_placefields', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring'], computation_kwargs_list=[{'laps_decoding_time_bin_size': 0.025}, {'time_bin_size': 0.025}, {'should_skip_radon_transform': True}, {}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4dec23",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['merged_directional_placefields', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs',], computation_kwargs_list=[{'laps_decoding_time_bin_size': 0.002}, {'time_bin_size': 0.002}, {'should_skip_radon_transform': True},], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d012effc",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "['split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62493eb3",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=[\n",
    "    'merged_directional_placefields', \n",
    "    'long_short_decoding_analyses', #'pipeline_complete_compute_long_short_fr_indicies',\n",
    "    'jonathan_firing_rate_analysis',\n",
    "    'long_short_fr_indicies_analyses',\n",
    "    'short_long_pf_overlap_analyses',\n",
    "    'long_short_post_decoding',\n",
    "    'long_short_rate_remapping',\n",
    "    'long_short_inst_spike_rate_groups',\n",
    "    'long_short_endcap_analysis',\n",
    "    ], enabled_filter_names=None, fail_on_exception=False, debug_print=False) # , computation_kwargs_list=[{'should_skip_radon_transform': False}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ca34a0",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=[\n",
    "    # 'long_short_decoding_analyses', #'pipeline_complete_compute_long_short_fr_indicies',\n",
    "    'jonathan_firing_rate_analysis',\n",
    "    # 'long_short_fr_indicies_analyses',\n",
    "    'short_long_pf_overlap_analyses',\n",
    "    'long_short_post_decoding',\n",
    "    'long_short_inst_spike_rate_groups',\n",
    "    'long_short_endcap_analysis',\n",
    "    ], enabled_filter_names=None, fail_on_exception=False, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99749819",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "if 'TrainTestSplit' in curr_active_pipeline.global_computation_results.computed_data:\n",
    "    directional_train_test_split_result: TrainTestSplitResult = curr_active_pipeline.global_computation_results.computed_data.get('TrainTestSplit', None)\n",
    "    training_data_portion: float = directional_train_test_split_result.training_data_portion\n",
    "    test_data_portion: float = directional_train_test_split_result.test_data_portion\n",
    "    test_epochs_dict: Dict[str, pd.DataFrame] = directional_train_test_split_result.test_epochs_dict\n",
    "    train_epochs_dict: Dict[str, pd.DataFrame] = directional_train_test_split_result.train_epochs_dict\n",
    "    train_lap_specific_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_train_test_split_result.train_lap_specific_pf1D_Decoder_dict\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed38171",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData\n",
    "\n",
    "# directional_decoders_epochs_decode_result\n",
    "# save_path = Path(\"/Users/pho/data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-04-25_CustomDecodingResults.pkl\").resolve()\n",
    "# save_path = curr_active_pipeline.get_output_path().joinpath(\"2024-04-28_CustomDecodingResults.pkl\").resolve()\n",
    "save_path = curr_active_pipeline.get_output_path().joinpath(f\"{DAY_DATE_TO_USE}_CustomDecodingResults.pkl\").resolve()\n",
    "\n",
    "xbin = deepcopy(long_pf2D.xbin)\n",
    "xbin_centers = deepcopy(long_pf2D.xbin_centers)\n",
    "ybin = deepcopy(long_pf2D.ybin)\n",
    "ybin_centers = deepcopy(long_pf2D.ybin_centers)\n",
    "\n",
    "print(xbin_centers)\n",
    "save_dict = {\n",
    "'directional_decoders_epochs_decode_result': directional_decoders_epochs_decode_result.__getstate__(),\n",
    "'xbin': xbin, 'xbin_centers': xbin_centers}\n",
    "\n",
    "saveData(save_path, save_dict)\n",
    "print(f'save_path: {save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464b4531",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# üíæ Export CSVs: \n",
    "## INPUTS: directional_decoders_epochs_decode_result,\n",
    "\n",
    "extracted_merged_scores_df = directional_decoders_epochs_decode_result.build_complete_all_scores_merged_df()\n",
    "# extracted_merged_scores_df\n",
    "\n",
    "print(f'\\tAll scores df CSV exporting...')\n",
    "\n",
    "## Export CSVs:\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "export_df_dict = {'ripple_all_scores_merged_df': extracted_merged_scores_df}\n",
    "_csv_export_paths = directional_decoders_epochs_decode_result.perform_export_dfs_dict_to_csvs(extracted_dfs_dict=export_df_dict, parent_output_path=collected_outputs_path.resolve(), active_context=active_context, session_name=curr_session_name, curr_session_t_delta=t_delta,\n",
    "                                                                            #   user_annotation_selections={'ripple': any_good_selected_epoch_times},\n",
    "                                                                            #   valid_epochs_selections={'ripple': filtered_valid_epoch_times},\n",
    "                                                                            )\n",
    "\n",
    "print(f'\\t\\tsuccessfully exported ripple_all_scores_merged_df to {collected_outputs_path}!')\n",
    "_output_csv_paths_info_str: str = '\\n'.join([f'{a_name}: \"{file_uri_from_path(a_path)}\"' for a_name, a_path in _csv_export_paths.items()])\n",
    "print(f'\\t\\t\\tCSV Paths: {_output_csv_paths_info_str}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ac96c6",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "t_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a860a1",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "decoder_ripple_radon_transform_df_dict\n",
    "decoder_ripple_radon_transform_extras_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cbf34d",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "decoder_ripple_radon_transform_df_dict\n",
    "decoder_ripple_radon_transform_extras_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbcbb0c",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# filtered_laps_simple_pf_pearson_merged_df\n",
    "# filtered_ripple_simple_pf_pearson_merged_df\n",
    "# decoder_ripple_weighted_corr_df_dict\n",
    "ripple_weighted_corr_merged_df['ripple_start_t']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a95450",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "wcorr_column_names = ['wcorr_long_LR', 'wcorr_long_RL', 'wcorr_short_LR', 'wcorr_short_RL']\n",
    "filtered_ripple_simple_pf_pearson_merged_df.label = filtered_ripple_simple_pf_pearson_merged_df.label.astype('int64')\n",
    "ripple_weighted_corr_merged_df['label'] = ripple_weighted_corr_merged_df['ripple_idx'].astype('int64')\n",
    "\n",
    "filtered_ripple_simple_pf_pearson_merged_df.join(ripple_weighted_corr_merged_df[wcorr_column_names], on='start') # , on='label'\n",
    "# filtered_ripple_simple_pf_pearson_merged_df.merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4bc77f",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "ripple_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac433aac",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "print(list(ripple_weighted_corr_merged_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98e2381",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "a_decoded_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "a_decoded_filter_epochs_decoder_result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3599f8",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# paginated_multi_decoder_decoded_epochs_window.save_selections()\n",
    "\n",
    "a_decoded_filter_epochs_decoder_result_dict.epochs.find_data_indicies_from_epoch_times([380.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899ee133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_general_decoder_dict_decoded_epochs_dict_result: GeneralDecoderDictDecodedEpochsDictResult = serialized_field(default=None, is_computable=True, repr=False, metadata={'field_added': '2025.03.09_0'})\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import GeneralDecoderDictDecodedEpochsDictResult, EpochComputationsComputationsContainer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3438b16",
   "metadata": {},
   "source": [
    "## <a id='toc2_6_'></a>[üíæ Continue Saving/Exporting stuff](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce2cb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_global_computation_results() # newly_computed_values: [('pfdt_computation', 'maze_any')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57544dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_save_folder, split_save_paths, split_save_output_types, failed_keys = curr_active_pipeline.save_split_global_computation_results(debug_print=True,\n",
    "                                                                                                                                    #    include_includelist=['long_short_inst_spike_rate_groups'],\n",
    "                                                                                                                                       ) # encountered issue with pickling `long_short_post_decoding`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94911277",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.export_pipeline_to_h5() # NotImplementedError: a_field_attr: Attribute(name='LxC_aclus', default=None, validator=None, repr=True, eq=True, eq_key=None, order=True, order_key=None, hash=None, init=False, metadata=mappingproxy({'tags': ['dataset'], 'serialization': {'hdf': True}, 'custom_serialization_fn': None, 'hdf_metadata': {'track_eXclusive_cells': 'LxC'}}), type=<class 'numpy.ndarray'>, converter=None, kw_only=False, inherited=False, on_setattr=None, alias='LxC_aclus') could not be serialized and _ALLOW_GLOBAL_NESTED_EXPANSION is not allowed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78feaef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_drop_computed_result(computed_data_keys_to_drop=['SequenceBased'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c6fb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.clear_display_outputs()\n",
    "curr_active_pipeline.clear_registered_output_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b937bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import neuropy.core.session.dataSession as ds\n",
    "reload(ds)\n",
    "\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder, find_local_session_paths, DataSessionFormatBaseRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f232acb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE) ## #TODO 2024-02-16 14:25: - [ ] PicklingError: Can't pickle <function make_set_closure_cell.<locals>.set_closure_cell at 0x7fd35e66b700>: it's not found as attr._compat.make_set_closure_cell.<locals>.set_closure_cell\n",
    "# curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.OVERWRITE_IN_PLACE)\n",
    "# TypeError: cannot pickle 'traceback' object\n",
    "# Exception: Can't pickle <enum 'PipelineSavingScheme'>: it's not the same object as pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline.PipelineSavingScheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3950b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.pickle_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048e564d",
   "metadata": {},
   "source": [
    "## <a id='toc2_7_'></a>[‚öì2025-02-19 8:20am - FIXUP Pipeline](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc9846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_default_extended_postload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0523bcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = curr_active_pipeline.sess\n",
    "# session.pbe\n",
    "session.basepath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6293513c",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.non_pbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090748d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "did_fixup_any_missing_basepath = curr_active_pipeline.post_load_fixup_sess_basedirs(updated_session_basepath=deepcopy(curr_active_pipeline.sess.basepath), force_update=True)\n",
    "did_fixup_any_missing_basepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6563c13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.stage.sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a6cdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder, DataSessionFormatBaseRegisteredClass\n",
    "# from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "\n",
    "# type(curr_active_pipeline.sess.non_pbe)\n",
    "\n",
    "\n",
    "curr_active_pipeline.stage.sess = KDibaOldDataSessionFormatRegisteredClass._default_extended_postload(curr_active_pipeline.stage.sess.filePrefix, curr_active_pipeline.stage.sess, force_recompute=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6707bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import Compute_NonPBE_Epochs\n",
    "\n",
    "did_any_non_pbe_epochs_change, curr_active_pipeline.stage.sess, curr_active_pipeline.stage.filtered_sessions = Compute_NonPBE_Epochs.update_session_non_pbe_epochs(curr_active_pipeline.sess, filtered_sessions=curr_active_pipeline.filtered_sessions)\n",
    "did_any_non_pbe_epochs_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6411b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.stage.sess.filePrefix # WindowsPath('/nfs/turbo/umms-kdiba/KDIBA/gor01/one/2006-6-08_14-26-15/2006-6-08_14-26-15')\n",
    "\n",
    "\n",
    "curr_active_pipeline.stage.sess.basepath\n",
    "curr_active_pipeline.stage.sess.get_output_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f357d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.get_merged_computation_function_validators()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66acdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.PipelineComputationWidget.PipelineComputationWidget import PipelineComputationWidget\n",
    "\n",
    "win = PipelineComputationWidget(owning_pipeline=curr_active_pipeline)\n",
    "win.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdc3697",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyphoplacecellanalysis.General.Model.SpecificComputationValidation import ComputationValidatorsTreeWidget\n",
    "\n",
    "# Create and display the widget\n",
    "validator_widget = ComputationValidatorsTreeWidget(curr_active_pipeline)\n",
    "validator_widget.display()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983225fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c185fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['non_PBE_epochs_results'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207f3ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['non_PBE_epochs_results'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6748af",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0342ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['non_PBE_epochs_results'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3894d269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long_session.epochs\n",
    "\n",
    "sess = deepcopy(long_session)\n",
    "\n",
    "sess.t_start, sess.t_stop\n",
    "\n",
    "\n",
    "# sess.name\n",
    "# sess.epochs.label\n",
    "\n",
    "sess.get_description()\n",
    "# sess.pbe\n",
    "# sess.paradigm\n",
    "\n",
    "epochs_df: pd.DataFrame = deepcopy(sess.epochs).epochs.adding_global_epoch_row()\n",
    "epochs_df\n",
    "\n",
    "global_epoch_only_df: pd.DataFrame = epochs_df.epochs.label_slice('maze')\n",
    "global_epoch_only_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbfca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.active_completed_computation_result_names\n",
    "curr_active_pipeline.active_incomplete_computation_result_status_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d5410a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.clear_all_failed_computations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cde3645",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.get_complete_session_context()\n",
    "custom_save_filepaths, custom_save_filenames, custom_suffix = curr_active_pipeline.get_custom_pipeline_filenames_from_parameters()\n",
    "custom_save_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492affd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "\n",
    "\n",
    "override_dicts = UserAnnotationsManager.get_hardcoded_specific_session_override_dict() # .get(sess.get_context(), {})\n",
    "# print(list(override_dicts.keys()))\n",
    "\n",
    "print(',\\n'.join([v.get_initialization_code_string() for v in list(override_dicts.keys())]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7aac4f",
   "metadata": {},
   "source": [
    "## <a id='toc2_8_'></a>[Custom Save-Pipeleine As](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62302c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get from pipeline's parameters\n",
    "custom_save_filepaths, custom_save_filenames, custom_suffix = curr_active_pipeline.get_custom_pipeline_filenames_from_parameters()\n",
    "pickle_path = custom_save_filenames['pipeline_pkl']\n",
    "global_computation_pkl = custom_save_filenames['global_computation_pkl']\n",
    "\n",
    "# pickle_path = 'loadedSessPickle_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0_2025-01-20.pkl'\n",
    "# global_computation_pkl = 'global_computation_results_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0_2025-01-20.pkl'\n",
    "\n",
    "# pickle_path = 'loadedSessPickle_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0_2025-01-20.pkl'\n",
    "# global_computation_pkl = 'global_computation_results_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0_2025-01-20.pkl'\n",
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE, active_pickle_filename=pickle_path)\n",
    "curr_active_pipeline.save_global_computation_results(override_global_pickle_filename=global_computation_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a96e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286756d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_session_pickle_file_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88078363",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_session_pickle_file_widget.active_local_pkl\n",
    "active_session_pickle_file_widget.active_global_pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a5c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.get_complete_session_context()\n",
    "custom_save_filepaths, custom_save_filenames, custom_suffix = curr_active_pipeline.get_custom_pipeline_filenames_from_parameters()\n",
    "custom_save_filepaths\n",
    "custom_save_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057d6831",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_custom_modified_filenames, did_save_success = curr_active_pipeline.try_save_pipeline_with_custom_user_modifiers(user_prefix='', user_suffix='2025-02-19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa97ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "did_save_success: bool = _try_user_custom_save_pipeline(curr_active_pipeline=curr_active_pipeline, user_custom_modified_filenames=user_custom_modified_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3242e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.pickle_path\n",
    "curr_active_pipeline.global_computation_results_pickle_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1147ec40",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_save_filenames['pipeline_pkl']\n",
    "custom_save_filenames['global_computation_pkl']\n",
    "\n",
    "pickle_path = 'loadedSessPickle_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0_2025-01-20.pkl'\n",
    "global_computation_pkl = 'global_computation_results_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0_2025-01-20.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123d9ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## indicate that it was loaded with a custom suffix\n",
    "curr_active_pipeline.pickle_path ## correct\n",
    "curr_active_pipeline.global_computation_results_pickle_path ## correct\n",
    "\n",
    "# curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE, override_pickle_path=curr_active_pipeline.pickle_path, active_pickle_filename=curr_active_pipeline.pickle_path.name) #active_pickle_filename=\n",
    "# curr_active_pipeline.save_global_computation_results(override_global_pickle_path=curr_active_pipeline.global_computation_results_pickle_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df1bdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE, override_pickle_path=curr_active_pipeline.pickle_path, active_pickle_filename='loadedSessPickle_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0_2025-01-20.pkl') #active_pickle_filename=\n",
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE, active_pickle_filename='loadedSessPickle_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0_FIXED_GRID_BIN_BOUNDS.pkl') #active_pickle_filename="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638c5ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE, active_pickle_filename='loadedSessPickle_withNormalComputedReplays-qclu_[1, 2]-frateThresh_5.0-FIXED_GRID_BIN_BOUNDS.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832773ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_global_computation_results(override_global_pickle_filename='global_computation_results_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0_FIXED_GRID_BIN_BOUNDS.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11015340",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE, active_pickle_filename='loadedSessPickle.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd8063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_global_computation_results(override_global_pickle_filename='global_computation_results.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944eedd6",
   "metadata": {},
   "source": [
    "#### <a id='toc2_8_1_1_'></a>[Get computation times/info:](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31cab8e",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "any_most_recent_computation_time, each_epoch_latest_computation_time, each_epoch_each_result_computation_completion_times, (global_computations_latest_computation_time, global_computation_completion_times) = curr_active_pipeline.get_computation_times(debug_print=False)\n",
    "# each_epoch_latest_computation_time\n",
    "# each_epoch_each_result_computation_completion_times\n",
    "# global_computation_completion_times\n",
    "\n",
    "# curr_active_pipeline.get_merged_computation_function_validators()\n",
    "# Get the names of the global and non-global computations:\n",
    "all_validators_dict = curr_active_pipeline.get_merged_computation_function_validators()\n",
    "global_only_validators_dict = {k:v for k, v in all_validators_dict.items() if v.is_global}\n",
    "non_global_only_validators_dict = {k:v for k, v in all_validators_dict.items() if (not v.is_global)}\n",
    "non_global_comp_names: List[str] = [v.short_name for k, v in non_global_only_validators_dict.items() if (not v.short_name.startswith('_DEP'))] # ['firing_rate_trends', 'spike_burst_detection', 'pf_dt_sequential_surprise', 'extended_stats', 'placefield_overlap', 'ratemap_peaks_prominence2d', 'velocity_vs_pf_simplified_count_density', 'EloyAnalysis', '_perform_specific_epochs_decoding', 'recursive_latent_pf_decoding', 'position_decoding_two_step', 'position_decoding', 'lap_direction_determination', 'pfdt_computation', 'pf_computation']\n",
    "global_comp_names: List[str] = [v.short_name for k, v in global_only_validators_dict.items() if (not v.short_name.startswith('_DEP'))] # ['long_short_endcap_analysis', 'long_short_inst_spike_rate_groups', 'long_short_post_decoding', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_decoding_analyses', 'PBE_stats', 'rank_order_shuffle_analysis', 'directional_decoders_epoch_heuristic_scoring', 'directional_decoders_evaluate_epochs', 'directional_decoders_decode_continuous', 'merged_directional_placefields', 'split_to_directional_laps']\n",
    "\n",
    "# mappings between the long computation function names and their short names:\n",
    "non_global_comp_names_map: Dict[str, str] = {v.computation_fn_name:v.short_name for k, v in non_global_only_validators_dict.items() if (not v.short_name.startswith('_DEP'))}\n",
    "global_comp_names_map: Dict[str, str] = {v.computation_fn_name:v.short_name for k, v in global_only_validators_dict.items() if (not v.short_name.startswith('_DEP'))} # '_perform_long_short_endcap_analysis': 'long_short_endcap_analysis', '_perform_long_short_instantaneous_spike_rate_groups_analysis': 'long_short_inst_spike_rate_groups', ...}\n",
    "\n",
    "# convert long function names to short-names:\n",
    "each_epoch_each_result_computation_completion_times = {an_epoch:{non_global_comp_names_map.get(k, k):v for k,v in a_results_dict.items()} for an_epoch, a_results_dict in each_epoch_each_result_computation_completion_times.items()}\n",
    "global_computation_completion_times = {global_comp_names_map.get(k, k):v for k,v in global_computation_completion_times.items()}\n",
    "\n",
    "each_epoch_each_result_computation_completion_times\n",
    "global_computation_completion_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81933aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "required_num_computation_rows: int = np.max([len(a_results_dict) for an_epoch, a_results_dict in each_epoch_each_result_computation_completion_times.items()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9852ae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[non_global_comp_names_map.get(k, k) for k,v in a_results_dict.items()] for an_epoch, a_results_dict in each_epoch_each_result_computation_completion_times.items()]\n",
    "\n",
    "# unique_comp_names_set = set([])\n",
    "unique_comp_names_list = []\n",
    "for an_epoch, a_results_dict in each_epoch_each_result_computation_completion_times.items():\n",
    "    for k,v in a_results_dict.items():\n",
    "        curr_comp_name: str = non_global_comp_names_map.get(k, k)\n",
    "        # unique_comp_names_set.add(curr_comp_name)\n",
    "        if curr_comp_name not in unique_comp_names_list:\n",
    "            unique_comp_names_list.append(curr_comp_name) ## preserving order\n",
    "        \n",
    "unique_comp_names_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da11a611",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_global_comp_names\n",
    "each_epoch_each_result_computation_completion_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d40193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use `curr_active_pipeline.filtered_epochs`\n",
    "filtered_epoch_column_names = deepcopy(list(curr_active_pipeline.filtered_epochs.keys()))\n",
    "num_filtered_epoch_columns: int = len(filtered_epoch_column_names)\n",
    "\n",
    "\n",
    "filtered_epoch_column_names\n",
    "num_filtered_epoch_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a769d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.PipelineComputationWidget.PipelineComputationWidget import PipelineComputationWidget\n",
    "\n",
    "win = PipelineComputationWidget(owning_pipeline=curr_active_pipeline)\n",
    "win.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144700b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.Extensions.pyqtgraph_helpers import TableSizingHelpers\n",
    "\n",
    "table_view = win.ui.tbl_EpochLocalResults\n",
    "total_height: float = TableSizingHelpers.determine_required_table_height(table_view)\n",
    "print(f'total_height: {total_height}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96580849",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_view.setMinimumHeight(total_height)  # Set the required height\n",
    "table_view.setMaximumHeight(total_height)  # Prevent scrolling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee4b1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_width: float = TableSizingHelpers.determine_required_table_width(table_view)\n",
    "print(f'total_width: {total_width}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967369f1",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_evaluate_required_computations\n",
    "\n",
    "# force_recompute_global = force_reload\n",
    "force_recompute_global = True\n",
    "# force_recompute_global = False\n",
    "active_probe_includelist = extended_computations_include_includelist\n",
    "# active_probe_includelist = ['lap_direction_determination']\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=active_probe_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "needs_computation_output_dict\n",
    "# valid_computed_results_output_list\n",
    "# remaining_include_function_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9aeeda",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "['merged_directional_placefields', ]\n",
    "\n",
    "['long_short_decoding_analyses', 'long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'extended_stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85822a88",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "replay_estimation_parameters = curr_active_pipeline.sess.config.preprocessing_parameters.epoch_estimation_parameters.replays\n",
    "assert replay_estimation_parameters is not None\n",
    "replay_estimation_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3799ab99",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "recompute_earlier_than_date = datetime(2024, 4, 1, 0, 0, 0)\n",
    "recompute_earlier_than_date\n",
    "\n",
    "each_epoch_needing_recompute = [an_epoch for an_epoch, last_computed_datetime in each_epoch_latest_computation_time.items() if (last_computed_datetime < recompute_earlier_than_date)]\n",
    "each_epoch_needing_recompute\n",
    "each_epoch_each_result_needing_recompute = {an_epoch:{a_computation_name:last_computed_datetime for a_computation_name, last_computed_datetime in last_computed_datetimes_dict.items() if (last_computed_datetime < recompute_earlier_than_date)} for an_epoch, last_computed_datetimes_dict in each_epoch_each_result_computation_completion_times.items()}\n",
    "each_epoch_each_result_needing_recompute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2792e869",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computation_times\n",
    "curr_active_pipeline.global_computation_results\n",
    "# curr_active_pipeline.try_load_split_pickled_global_computation_results\n",
    "\n",
    "global_computation_times = deepcopy(curr_active_pipeline.global_computation_results.computation_times.to_dict()) # DynamicParameters({'perform_rank_order_shuffle_analysis': datetime.datetime(2024, 4, 3, 5, 41, 31, 287680), '_decode_continuous_using_directional_decoders': datetime.datetime(2024, 4, 3, 5, 12, 7, 337326), '_perform_long_short_decoding_analyses': datetime.datetime(2024, 4, 3, 5, 43, 10, 361685), '_perform_long_short_pf_overlap_analyses': datetime.datetime(2024, 4, 3, 5, 43, 10, 489296), '_perform_long_short_firing_rate_analyses': datetime.datetime(2024, 4, 3, 5, 45, 3, 73472), '_perform_jonathan_replay_firing_rate_analyses': datetime.datetime(2024, 4, 3, 5, 45, 5, 168790), '_perform_long_short_post_decoding_analysis': datetime.datetime(2024, 2, 16, 18, 13, 4, 734621), '_perform_long_short_endcap_analysis': datetime.datetime(2024, 4, 3, 5, 45, 24, 274261), '_decode_and_evaluate_epochs_using_directional_decoders': datetime.datetime(2024, 4, 3, 5, 14, 37, 935482), '_perform_long_short_instantaneous_spike_rate_groups_analysis': datetime.datetime(2024, 4, 3, 5, 45, 24, 131955), '_split_to_directional_laps': datetime.datetime(2024, 4, 3, 5, 11, 22, 627789), '_build_merged_directional_placefields': datetime.datetime(2024, 4, 3, 5, 11, 28, 376078)})\n",
    "global_computation_times\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f8c99f",
   "metadata": {},
   "source": [
    "### <a id='toc2_8_2_'></a>[Custom Split Result Outputs](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce82b33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.print_helpers import print_object_memory_usage, print_filesystem_file_size\n",
    "\n",
    "print('test')\n",
    "curr_active_pipeline.global_computation_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac259988",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_object_memory_usage(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5e99c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.active_configs\n",
    "# Define default print format function if no custom one is provided:\n",
    "# see DocumentationFilePrinter._plain_text_format_curr_value and DocumentationFilePrinter._rich_text_format_curr_value for examples\n",
    "# custom_item_formatter = DocumentationFilePrinter._default_plain_text_formatter\n",
    "## Plaintext:\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "# custom_value_formatting_fn = partial(DocumentationFilePrinter.string_rep_if_short_enough, max_length=280, max_num_lines=1)\n",
    "custom_value_formatting_fn = partial(DocumentationFilePrinter.value_memory_usage_MB)\n",
    "custom_item_formatter = partial(DocumentationFilePrinter._default_plain_text_formatter, value_formatting_fn=custom_value_formatting_fn)\n",
    "\n",
    "# ## Rich:\n",
    "# custom_value_formatting_fn = partial(DocumentationFilePrinter.string_rep_if_short_enough, max_length=280, max_num_lines=1)\n",
    "# custom_item_formatter = partial(DocumentationFilePrinter._default_rich_text_formatter, value_formatting_fn=custom_value_formatting_fn)\n",
    "\n",
    "\n",
    "# print_keys_if_possible('curr_active_pipeline', curr_active_pipeline, max_depth=1, custom_item_formatter=custom_item_formatter)\n",
    "\n",
    "# curr_active_pipeline._stage: pyphoplacecellanalysis.General.Pipeline.Stages.Display.DisplayPipelineStage 6483.868 MB\n",
    "# \t‚îÇ   ‚îú‚îÄ‚îÄ stage_name: str 0.000 MB\n",
    "# \t‚îÇ   ‚îú‚îÄ‚îÄ basedir: pathlib.WindowsPath 0.001 MB\n",
    "# \t‚îÇ   ‚îú‚îÄ‚îÄ load_function: NoneType\n",
    "# \t‚îÇ   ‚îú‚îÄ‚îÄ post_load_functions: list 0.000 MB - (0,)\n",
    "# \t‚îÇ   ‚îú‚îÄ‚îÄ loaded_data: dict 189.974 MB\n",
    "# \t‚îÇ   ‚îú‚îÄ‚îÄ registered_load_function_dict: dict (children omitted)(all scalar values) - size: 0\n",
    "# \t‚îÇ   ‚îú‚îÄ‚îÄ filtered_sessions: dict 1641.733 MB\n",
    "# \t‚îÇ   ‚îú‚îÄ‚îÄ filtered_epochs: dict 0.004 MB\n",
    "# \t‚îÇ   ‚îú‚îÄ‚îÄ filtered_contexts: pyphocorehelpers.DataStructure.dynamic_parameters.DynamicParameters 0.005 MB\n",
    "# \t‚îÇ   ‚îú‚îÄ‚îÄ active_configs: dict 1.040 MB\n",
    "# \t‚îÇ   ‚îú‚îÄ‚îÄ computation_results: dict 3791.355 MB\n",
    "# \t‚îÇ   ‚îú‚îÄ‚îÄ global_computation_results: pyphoplacecellanalysis.General.Model.ComputationResults.ComputationResult 2691.828 MB\n",
    "# \t‚îÇ   ‚îú‚îÄ‚îÄ registered_computation_function_dict: collections.OrderedDict 0.003 MB\n",
    "# \t‚îÇ   ‚îú‚îÄ‚îÄ registered_global_computation_function_dict: collections.OrderedDict 0.003 MB\n",
    "\n",
    "\n",
    "## Document `curr_active_pipeline`\n",
    "doc_printer = DocumentationFilePrinter(doc_output_parent_folder=doc_output_parent_folder, doc_name='curr_active_pipeline')\n",
    "# doc_printer.save_documentation('curr_active_pipeline', curr_active_pipeline, non_expanded_item_keys=['_reverse_cellID_index_map'], max_depth=2, custom_rich_text_formatter=custom_item_formatter)\n",
    "doc_printer.save_documentation('curr_active_pipeline', curr_active_pipeline, non_expanded_item_keys=['_reverse_cellID_index_map'], max_depth=2, custom_plain_text_formatter=custom_item_formatter)\n",
    "\n",
    "# print_keys_if_possible('curr_active_pipeline._stage', curr_active_pipeline._stage, max_depth=2, custom_item_formatter=custom_item_formatter)\n",
    "\n",
    "# curr_active_pipeline.filtered_sessions\n",
    "\n",
    "# curr_active_pipeline.computation_results # 3791.355 MB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cf1236",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_printer.display_widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b5c928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "from dill.detect import trace\n",
    "\n",
    "# Trace all variables in the current workspace\n",
    "trace(locals())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06acb3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_vars = {k: v for k, v in locals().items() if not k.startswith(\"__\")}\n",
    "trace(workspace_vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5769b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import perform_split_save_dictlike_result\n",
    "\n",
    "split_folder = curr_active_pipeline.get_output_path().joinpath('split')\n",
    "split_folder.mkdir(exist_ok=True)\n",
    "\n",
    "['loaded_data', '']\n",
    "\n",
    "# active_computed_data = self.global_computation_results.computed_data\n",
    "# include_includelist = list(self.global_computation_results.computed_data.keys())\n",
    "# split_save_folder_name: str = f'{global_computation_results_pickle_path.stem}_split'\n",
    "# split_save_folder: Path = global_computation_results_pickle_path.parent.joinpath(split_save_folder_name).resolve()\n",
    "\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# 'computation_results' (local computations)                                                                           #\n",
    "# ==================================================================================================================== #\n",
    "# split_computation_results_dir = split_folder.joinpath('computation_results')\n",
    "# split_computation_results_dir.mkdir(exist_ok=True)\n",
    "# split_save_folder, split_save_paths, split_save_output_types, failed_keys = perform_split_save_dictlike_result(split_save_folder=split_computation_results_dir, active_computed_data=curr_active_pipeline.computation_results)\n",
    "\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# 'filtered_sessions'                                                                                                  #\n",
    "# ==================================================================================================================== #\n",
    "# split_filtered_sessions_dir = split_folder.joinpath('filtered_sessions')\n",
    "# split_filtered_sessions_dir.mkdir(exist_ok=True)\n",
    "# split_save_folder, split_save_paths, split_save_output_types, failed_keys = perform_split_save_dictlike_result(split_save_folder=split_filtered_sessions_dir, active_computed_data=curr_active_pipeline.filtered_sessions)\n",
    "\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# 'global_computation_results' (global computations)                                                                   #\n",
    "# ==================================================================================================================== #\n",
    "split_global_computation_results_dir = split_folder.joinpath('global_computation_results')\n",
    "split_global_computation_results_dir.mkdir(exist_ok=True)\n",
    "split_save_folder, split_save_paths, split_save_output_types, failed_keys = perform_split_save_dictlike_result(split_save_folder=split_global_computation_results_dir, active_computed_data=curr_active_pipeline.global_computation_results.computed_data) # .__dict__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcaf776",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benedict import benedict\n",
    "# curr_active_pipeline.computation_results ## a regular dict, convert to benedict\n",
    "# curr_active_pipeline.computation_results\n",
    "\n",
    "computation_results = benedict(curr_active_pipeline.computation_results)\n",
    "computation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3dc28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_result = computation_results['maze_any'] # ComputationResult\n",
    "# global_computation_results_split\n",
    "a_result_dict = a_result.to_dict()\n",
    "a_result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e982eb",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[0Ô∏è‚É£ Pho Interactive Pipeline Jupyter Widget](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce08192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import interactive_pipeline_widget, interactive_pipeline_files\n",
    "\n",
    "_pipeline_jupyter_widget = interactive_pipeline_widget(curr_active_pipeline=curr_active_pipeline)\n",
    "# display(_pipeline_jupyter_widget)\n",
    "_pipeline_jupyter_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474f4c95",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[1Ô∏è‚É£ End Run](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a533ba8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T23:21:40.700275900Z",
     "start_time": "2023-11-16T23:21:40.584273Z"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1029.316608761903, 1737.1968310000375)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (long_one_step_decoder_1D, short_one_step_decoder_1D), (long_one_step_decoder_2D, short_one_step_decoder_2D) = compute_short_long_constrained_decoders(curr_active_pipeline, recalculate_anyway=True)\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_epoch_context, short_epoch_context, global_epoch_context = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_epoch_name, short_epoch_name, global_epoch_name)]\n",
    "long_epoch_obj, short_epoch_obj = [Epoch(curr_active_pipeline.sess.epochs.to_dataframe().epochs.label_slice(an_epoch_name.removesuffix('_any'))) for an_epoch_name in [long_epoch_name, short_epoch_name]] #TODO 2023-11-10 20:41: - [ ] Issue with getting actual Epochs from sess.epochs for directional laps: emerges because long_epoch_name: 'maze1_any' and the actual epoch label in curr_active_pipeline.sess.epochs is 'maze1' without the '_any' part.\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_computation_config, short_computation_config, global_computation_config = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "long_pf2D, short_pf2D, global_pf2D = long_results.pf2D, short_results.pf2D, global_results.pf2D\n",
    "\n",
    "assert short_epoch_obj.n_epochs > 0, f'long_epoch_obj: {long_epoch_obj}, short_epoch_obj: {short_epoch_obj}'\n",
    "assert long_epoch_obj.n_epochs > 0, f'long_epoch_obj: {long_epoch_obj}, short_epoch_obj: {short_epoch_obj}'\n",
    "\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "t_start, t_delta, t_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa98b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_session.non_pbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e348e0c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>t_seconds</th>\n",
       "      <th>t_rel_seconds</th>\n",
       "      <th>shank</th>\n",
       "      <th>cluster</th>\n",
       "      <th>aclu</th>\n",
       "      <th>qclu</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>speed</th>\n",
       "      <th>traj</th>\n",
       "      <th>lap</th>\n",
       "      <th>maze_relative_lap</th>\n",
       "      <th>maze_id</th>\n",
       "      <th>is_theta</th>\n",
       "      <th>is_ripple</th>\n",
       "      <th>theta_phase_radians</th>\n",
       "      <th>neuron_type</th>\n",
       "      <th>flat_spike_idx</th>\n",
       "      <th>x_loaded</th>\n",
       "      <th>y_loaded</th>\n",
       "      <th>lin_pos</th>\n",
       "      <th>fragile_linear_neuron_IDX</th>\n",
       "      <th>PBE_id</th>\n",
       "      <th>scISI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69.0</td>\n",
       "      <td>643040.535914</td>\n",
       "      <td>0.002120</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>5</td>\n",
       "      <td>149.051586</td>\n",
       "      <td>65.778444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.548105</td>\n",
       "      <td>NeuronType.INTERNEURONS</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155.019823</td>\n",
       "      <td>97</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101.0</td>\n",
       "      <td>643040.536897</td>\n",
       "      <td>0.003103</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>149.051586</td>\n",
       "      <td>65.778444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.686500</td>\n",
       "      <td>NeuronType.PYRAMIDAL</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155.019823</td>\n",
       "      <td>96</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>161.0</td>\n",
       "      <td>643040.538740</td>\n",
       "      <td>0.004946</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>149.051586</td>\n",
       "      <td>65.778444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.811695</td>\n",
       "      <td>NeuronType.INTERNEURONS</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155.019823</td>\n",
       "      <td>19</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>163.0</td>\n",
       "      <td>643040.538801</td>\n",
       "      <td>0.005007</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>149.051586</td>\n",
       "      <td>65.778444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.811695</td>\n",
       "      <td>NeuronType.INTERNEURONS</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155.019823</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>177.0</td>\n",
       "      <td>643040.539231</td>\n",
       "      <td>0.005437</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>149.051586</td>\n",
       "      <td>65.778444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.834456</td>\n",
       "      <td>NeuronType.INTERNEURONS</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155.019823</td>\n",
       "      <td>47</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>220.0</td>\n",
       "      <td>643040.540552</td>\n",
       "      <td>0.006758</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>149.051586</td>\n",
       "      <td>65.778444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>5.923098</td>\n",
       "      <td>NeuronType.INTERNEURONS</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>155.019823</td>\n",
       "      <td>62</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868630</th>\n",
       "      <td>56548011.0</td>\n",
       "      <td>644777.687802</td>\n",
       "      <td>1737.154008</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>205.404022</td>\n",
       "      <td>143.148118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.216732</td>\n",
       "      <td>NeuronType.INTERNEURONS</td>\n",
       "      <td>868630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>203.308819</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.039598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868631</th>\n",
       "      <td>56548849.0</td>\n",
       "      <td>644777.713546</td>\n",
       "      <td>1737.179752</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>205.404022</td>\n",
       "      <td>143.148118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.625988</td>\n",
       "      <td>NeuronType.INTERNEURONS</td>\n",
       "      <td>868631</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>203.308819</td>\n",
       "      <td>19</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.029215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868632</th>\n",
       "      <td>56548865.0</td>\n",
       "      <td>644777.714037</td>\n",
       "      <td>1737.180243</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>97</td>\n",
       "      <td>2</td>\n",
       "      <td>205.404022</td>\n",
       "      <td>143.148118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.625988</td>\n",
       "      <td>NeuronType.PYRAMIDAL</td>\n",
       "      <td>868632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>203.308819</td>\n",
       "      <td>95</td>\n",
       "      <td>-1</td>\n",
       "      <td>22.612919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868633</th>\n",
       "      <td>56548932.0</td>\n",
       "      <td>644777.716096</td>\n",
       "      <td>1737.182302</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>6</td>\n",
       "      <td>205.404022</td>\n",
       "      <td>143.148118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.646839</td>\n",
       "      <td>NeuronType.CONTAMINATED</td>\n",
       "      <td>868633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>203.308819</td>\n",
       "      <td>63</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.262656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868634</th>\n",
       "      <td>56549027.0</td>\n",
       "      <td>644777.719014</td>\n",
       "      <td>1737.185220</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>96</td>\n",
       "      <td>5</td>\n",
       "      <td>205.404022</td>\n",
       "      <td>143.148118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.673228</td>\n",
       "      <td>NeuronType.INTERNEURONS</td>\n",
       "      <td>868634</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>203.308819</td>\n",
       "      <td>94</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.113357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868635</th>\n",
       "      <td>56549311.0</td>\n",
       "      <td>644777.727738</td>\n",
       "      <td>1737.193944</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>99</td>\n",
       "      <td>5</td>\n",
       "      <td>205.404022</td>\n",
       "      <td>143.148118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.708359</td>\n",
       "      <td>NeuronType.INTERNEURONS</td>\n",
       "      <td>868635</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>203.308819</td>\n",
       "      <td>97</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.101990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>868636 rows √ó 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 t      t_seconds  t_rel_seconds  shank  cluster  aclu  qclu           x           y  speed  traj  lap  maze_relative_lap  maze_id  is_theta  is_ripple  theta_phase_radians              neuron_type  flat_spike_idx  x_loaded  y_loaded     lin_pos  fragile_linear_neuron_IDX  PBE_id      scISI\n",
       "0             69.0  643040.535914       0.002120     12        8    99     5  149.051586   65.778444    0.0     0   -1                 -1        1     False      False             5.548105  NeuronType.INTERNEURONS               0       NaN       NaN  155.019823                         97      -1        NaN\n",
       "1            101.0  643040.536897       0.003103     12        7    98     1  149.051586   65.778444    0.0     0   -1                 -1        1     False      False             5.686500     NeuronType.PYRAMIDAL               1       NaN       NaN  155.019823                         96      -1        NaN\n",
       "2            161.0  643040.538740       0.004946      2       17    21     5  149.051586   65.778444    0.0     0   -1                 -1        1     False      False             5.811695  NeuronType.INTERNEURONS               2       NaN       NaN  155.019823                         19      -1        NaN\n",
       "3            163.0  643040.538801       0.005007      1       12     7     5  149.051586   65.778444    0.0     0   -1                 -1        1     False      False             5.811695  NeuronType.INTERNEURONS               3       NaN       NaN  155.019823                          5      -1        NaN\n",
       "4            177.0  643040.539231       0.005437      7       11    49     5  149.051586   65.778444    0.0     0   -1                 -1        1     False      False             5.834456  NeuronType.INTERNEURONS               4       NaN       NaN  155.019823                         47      -1        NaN\n",
       "5            220.0  643040.540552       0.006758      8       19    64     5  149.051586   65.778444    0.0     0   -1                 -1        1     False      False             5.923098  NeuronType.INTERNEURONS               5       NaN       NaN  155.019823                         62      -1        NaN\n",
       "...            ...            ...            ...    ...      ...   ...   ...         ...         ...    ...   ...  ...                ...      ...       ...        ...                  ...                      ...             ...       ...       ...         ...                        ...     ...        ...\n",
       "868630  56548011.0  644777.687802    1737.154008      1       12     7     5  205.404022  143.148118    0.0     0   -1                 -1        2     False      False             4.216732  NeuronType.INTERNEURONS          868630       NaN       NaN  203.308819                          5      -1   0.039598\n",
       "868631  56548849.0  644777.713546    1737.179752      2       17    21     5  205.404022  143.148118    0.0     0   -1                 -1        2     False      False             4.625988  NeuronType.INTERNEURONS          868631       NaN       NaN  203.308819                         19      -1   0.029215\n",
       "868632  56548865.0  644777.714037    1737.180243     12        6    97     2  205.404022  143.148118    0.0     0   -1                 -1        2     False      False             4.625988     NeuronType.PYRAMIDAL          868632       NaN       NaN  203.308819                         95      -1  22.612919\n",
       "868633  56548932.0  644777.716096    1737.182302      8       20    65     6  205.404022  143.148118    0.0     0   -1                 -1        2     False      False             4.646839  NeuronType.CONTAMINATED          868633       NaN       NaN  203.308819                         63      -1   0.262656\n",
       "868634  56549027.0  644777.719014    1737.185220     12        5    96     5  205.404022  143.148118    0.0     0   -1                 -1        2     False      False             4.673228  NeuronType.INTERNEURONS          868634       NaN       NaN  203.308819                         94      -1   0.113357\n",
       "868635  56549311.0  644777.727738    1737.193944     12        8    99     5  205.404022  143.148118    0.0     0   -1                 -1        2     False      False             4.708359  NeuronType.INTERNEURONS          868635       NaN       NaN  203.308819                         97      -1   0.101990\n",
       "\n",
       "[868636 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# directional_merged_decoders_result = deepcopy(directional_decoders_epochs_decode_result)\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "\n",
    "spikes_df = deepcopy(curr_active_pipeline.sess.spikes_df)\n",
    "spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "528460fb",
   "metadata": {
    "tags": [
     "run-group-end-run"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "global_computation_results = curr_active_pipeline.global_computation_results\n",
    "\n",
    "rank_order_results = curr_active_pipeline.global_computation_results.computed_data.get('RankOrder', None) # : \"RankOrderComputationsContainer\"\n",
    "if rank_order_results is not None:\n",
    "    minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "else:        \n",
    "    ## get from parameters:\n",
    "    minimum_inclusion_fr_Hz: float = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.included_qclu_values\n",
    "\n",
    "\n",
    "directional_laps_results: DirectionalLapsResult = global_computation_results.computed_data['DirectionalLaps']\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\n",
    "# print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "# print(f'included_qclu_values: {included_qclu_values}')\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "ripple_decoding_time_bin_size: float = directional_merged_decoders_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_merged_decoders_result.laps_decoding_time_bin_size\n",
    "# pos_bin_size = _recover_position_bin_size(track_templates.get_decoders()[0]) # 3.793023081021702\n",
    "# print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}, ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}, pos_bin_size: {pos_bin_size}')\n",
    "# pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "\n",
    "## Simple Pearson Correlation\n",
    "assert spikes_df is not None\n",
    "(laps_simple_pf_pearson_merged_df, ripple_simple_pf_pearson_merged_df), corr_column_names = directional_merged_decoders_result.compute_simple_spike_time_v_pf_peak_x_by_epoch(track_templates=track_templates, spikes_df=deepcopy(spikes_df))\n",
    "## OUTPUTS: (laps_simple_pf_pearson_merged_df, ripple_simple_pf_pearson_merged_df), corr_column_names\n",
    "## Computes the highest-valued decoder for this score:\n",
    "try:\n",
    "    best_decoder_index_col_name: str = 'best_decoder_index'\n",
    "    laps_simple_pf_pearson_merged_df[best_decoder_index_col_name] = laps_simple_pf_pearson_merged_df[corr_column_names].abs().apply(lambda row: np.argmax(row.values), axis=1)\n",
    "    ripple_simple_pf_pearson_merged_df[best_decoder_index_col_name] = ripple_simple_pf_pearson_merged_df[corr_column_names].abs().apply(lambda row: np.argmax(row.values), axis=1)\n",
    "except KeyError as e:\n",
    "    pass # KeyError: \"None of [Index(['long_LR_pf_peak_x_pearsonr', 'long_RL_pf_peak_x_pearsonr', 'short_LR_pf_peak_x_pearsonr', 'short_RL_pf_peak_x_pearsonr'], dtype='object')] are in the [columns]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed4d1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_directional_pf1D_Decoder = directional_merged_decoders_result.all_directional_pf1D_Decoder\n",
    "pf1D = all_directional_pf1D_Decoder.pf\n",
    "# all_directional_pf1D_Decoder\n",
    "pf1D\n",
    "# all_directional_pf1D_Decoder.pf.plot_occupancy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1dc2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sort from left to right by peak location, and bottom-to-top by context\n",
    "# pf1D.peak_indicies\n",
    "# pf1D.peak_tuning_curve_center_of_mass_bin_coordinates\n",
    "\n",
    "# pf1D.get_tuning_curve_peak_df\n",
    "# pf1D.tuning_curves_dict\n",
    "# pf1D.tuning_curves\n",
    "\n",
    "pf1D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eed3e0c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(active_epochs_df): 412\n",
      "min_num_unique_aclu_inclusions: 16\n",
      "pos_bin_size: 4.877453969028168\n",
      "ripple_decoding_time_bin_size: 0.016\n",
      "laps_decoding_time_bin_size: 0.025\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult, SingleEpochDecodedResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)\n",
    "\n",
    "pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict\n",
    "decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict\n",
    "\n",
    "print(f'pos_bin_size: {pos_bin_size}')\n",
    "print(f'ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}')\n",
    "print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}')\n",
    "\n",
    "# Radon Transforms:\n",
    "decoder_laps_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_df_dict\n",
    "decoder_ripple_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_df_dict\n",
    "decoder_laps_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_extras_dict\n",
    "decoder_ripple_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_extras_dict\n",
    "\n",
    "# Weighted correlations:\n",
    "laps_weighted_corr_merged_df: pd.DataFrame = directional_decoders_epochs_decode_result.laps_weighted_corr_merged_df\n",
    "ripple_weighted_corr_merged_df: pd.DataFrame = directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "decoder_laps_weighted_corr_df_dict: Dict[str, pd.DataFrame] = directional_decoders_epochs_decode_result.decoder_laps_weighted_corr_df_dict\n",
    "decoder_ripple_weighted_corr_df_dict: Dict[str, pd.DataFrame] = directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict\n",
    "\n",
    "# Pearson's correlations:\n",
    "laps_simple_pf_pearson_merged_df: pd.DataFrame = directional_decoders_epochs_decode_result.laps_simple_pf_pearson_merged_df\n",
    "ripple_simple_pf_pearson_merged_df: pd.DataFrame = directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df\n",
    "\n",
    "# laps_simple_pf_pearson_merged_df\n",
    "# ripple_simple_pf_pearson_merged_df\n",
    "\n",
    "# ## Drop rows where all are missing\n",
    "# corr_column_names = ['long_LR_pf_peak_x_pearsonr', 'long_RL_pf_peak_x_pearsonr', 'short_LR_pf_peak_x_pearsonr', 'short_RL_pf_peak_x_pearsonr']\n",
    "# # ripple_simple_pf_pearson_merged_df.dropna(subset=corr_column_names, axis='index', how='all') # 350/412 rows\n",
    "# filtered_laps_simple_pf_pearson_merged_df: pd.DataFrame = laps_simple_pf_pearson_merged_df.dropna(subset=corr_column_names, axis='index', how='any') # 320/412 rows\n",
    "# filtered_ripple_simple_pf_pearson_merged_df: pd.DataFrame = ripple_simple_pf_pearson_merged_df.dropna(subset=corr_column_names, axis='index', how='any') # 320/412 rows\n",
    "\n",
    "## Update the `decoder_ripple_filter_epochs_decoder_result_dict` with the included epochs:\n",
    "# decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_ripple_filter_epochs_decoder_result_dict[a_name].filtered_by_epochs(filtered_ripple_simple_pf_pearson_merged_df.index) for a_name, a_df in decoder_ripple_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_laps_filter_epochs_decoder_result_dict[a_name].filtered_by_epochs(filtered_laps_simple_pf_pearson_merged_df.index) for a_name, a_df in decoder_laps_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_ripple_filter_epochs_decoder_result_dict[a_name].filtered_by_epoch_times(filtered_ripple_simple_pf_pearson_merged_df[['start', 'stop']].to_numpy()) for a_name, a_df in decoder_ripple_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_laps_filter_epochs_decoder_result_dict[a_name].filtered_by_epoch_times(filtered_laps_simple_pf_pearson_merged_df[['start', 'stop']].to_numpy()) for a_name, a_df in decoder_laps_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_ripple_filter_epochs_decoder_result_dict[a_name].filtered_by_epoch_times(filtered_ripple_simple_pf_pearson_merged_df['start'].to_numpy()) for a_name, a_df in decoder_ripple_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_laps_filter_epochs_decoder_result_dict[a_name].filtered_by_epoch_times(filtered_laps_simple_pf_pearson_merged_df['start'].to_numpy()) for a_name, a_df in decoder_laps_filter_epochs_decoder_result_dict.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92b35196",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Context(format_name= 'kdiba', animal= 'gor01', exper_name= 'one', session_name= '2006-6-09_1-22-43')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006-6-09_1-22-43:\tt_start: 0.0, t_delta: 1029.316608761903, t_end: 1737.1968310000375\n"
     ]
    }
   ],
   "source": [
    "# I have several python variables I want to print: t_start, t_delta, t_end\n",
    "# I want to generate a print statement that explicitly lists the variable name prior to its value like `print(f't_start: {t_start}, t_delta: {t_delta}, t_end: {t_end}')`\n",
    "# Currently I have to t_start, t_delta, t_end\n",
    "curr_active_pipeline.get_session_context()\n",
    "\n",
    "print(f'{curr_active_pipeline.session_name}:\\tt_start: {t_start}, t_delta: {t_delta}, t_end: {t_end}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c49f5d4f",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# Unpack all directional variables:\n",
    "## {\"even\": \"RL\", \"odd\": \"LR\"}\n",
    "long_LR_name, short_LR_name, global_LR_name, long_RL_name, short_RL_name, global_RL_name, long_any_name, short_any_name, global_any_name = ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "\n",
    "# Most popular\n",
    "# long_LR_name, short_LR_name, long_RL_name, short_RL_name, global_any_name\n",
    "\n",
    "# Unpacking for `(long_LR_name, long_RL_name, short_LR_name, short_RL_name)`\n",
    "(long_LR_context, long_RL_context, short_LR_context, short_RL_context) = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj, global_any_laps_epochs_obj = [curr_active_pipeline.computation_results[an_epoch_name].computation_config.pf_params.computation_epochs for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name, global_any_name)] # note has global also\n",
    "(long_LR_session, long_RL_session, short_LR_session, short_RL_session) = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)] # sessions are correct at least, seems like just the computation parameters are messed up\n",
    "(long_LR_results, long_RL_results, short_LR_results, short_RL_results) = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_computation_config, long_RL_computation_config, short_LR_computation_config, short_RL_computation_config) = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_pf1D, long_RL_pf1D, short_LR_pf1D, short_RL_pf1D) = (long_LR_results.pf1D, long_RL_results.pf1D, short_LR_results.pf1D, short_RL_results.pf1D)\n",
    "(long_LR_pf2D, long_RL_pf2D, short_LR_pf2D, short_RL_pf2D) = (long_LR_results.pf2D, long_RL_results.pf2D, short_LR_results.pf2D, short_RL_results.pf2D)\n",
    "(long_LR_pf1D_Decoder, long_RL_pf1D_Decoder, short_LR_pf1D_Decoder, short_RL_pf1D_Decoder) = (long_LR_results.pf1D_Decoder, long_RL_results.pf1D_Decoder, short_LR_results.pf1D_Decoder, short_RL_results.pf1D_Decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7104fc37",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum_inclusion_fr_Hz: 5.0\n",
      "included_qclu_values: [1, 2, 4, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult, DirectionalLapsResult, DirectionalDecodersContinuouslyDecodedResult\n",
    "\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']   \n",
    "rank_order_results: RankOrderComputationsContainer = curr_active_pipeline.global_computation_results.computed_data.get('RankOrder', None)\n",
    "if rank_order_results is not None:\n",
    "    minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "else:        \n",
    "    ## get from parameters:\n",
    "    minimum_inclusion_fr_Hz: float = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.included_qclu_values\n",
    "\n",
    "print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "print(f'included_qclu_values: {included_qclu_values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a6eab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_merged_decoders_result.laps_time_bin_marginals_df\n",
    "directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00672033",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_laps_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bb2118",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result ## here is a single result, but not a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f90757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_build_individual_time_bin_decoded_posteriors_df\n",
    "\n",
    "## From `directional_merged_decoders_result`\n",
    "# transfer_column_names_list: List[str] = ['maze_id', 'lap_dir', 'lap_id']\n",
    "transfer_column_names_list: List[str] = []\n",
    "filtered_laps_time_bin_marginals_df = _perform_build_individual_time_bin_decoded_posteriors_df(curr_active_pipeline, track_templates=track_templates, all_directional_laps_filter_epochs_decoder_result=directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result, transfer_column_names_list=transfer_column_names_list)\n",
    "filtered_laps_time_bin_marginals_df['lap_id'] = filtered_laps_time_bin_marginals_df['parent_epoch_label'].astype(int) + 1\n",
    "filtered_laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4c2073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result\n",
    "\n",
    "# directional_merged_decoders_result.all_directional_decoder_dict\n",
    "directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df77e66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import PhoPaginatedMultiDecoderDecodedEpochsWindow, DecodedEpochSlicesPaginatedFigureController, EpochSelectionsObject, ClickActionCallbacks\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.ThinButtonBar.ThinButtonBarWidget import ThinButtonBarWidget\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.PaginationCtrl.PaginationControlWidget import PaginationControlWidget, PaginationControlWidgetState\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from pyphoplacecellanalysis.Resources import GuiResources, ActionIcons, silx_resources_rc\n",
    "## INPUTS filtered_decoder_filter_epochs_decoder_result_dict\n",
    "# decoder_decoded_epochs_result_dict: generic\n",
    "\n",
    "app, paginated_multi_decoder_decoded_epochs_window, pagination_controller_dict = PhoPaginatedMultiDecoderDecodedEpochsWindow.init_from_track_templates(curr_active_pipeline, track_templates,\n",
    "                                                                                                # decoder_decoded_epochs_result_dict=decoder_ripple_filter_epochs_decoder_result_dict, epochs_name='ripple',\n",
    "                                                                                                # decoder_decoded_epochs_result_dict=filtered_decoder_filter_epochs_decoder_result_dict, epochs_name='ripple',\n",
    "                                                                                                # decoder_decoded_epochs_result_dict=filtered_ripple_simple_pf_pearson_merged_df, epochs_name='ripple',\n",
    "                                                                                                decoder_decoded_epochs_result_dict=long_like_during_post_delta_only_filtered_decoder_filter_epochs_decoder_result_dict, epochs_name='ripple', title='Long-like post-Delta Ripples Only', ## RIPPLE\n",
    "                                                                                                # decoder_decoded_epochs_result_dict=decoder_laps_filter_epochs_decoder_result_dict, epochs_name='laps', ## LAPS\n",
    "                                                                                                included_epoch_indicies=None, debug_print=False,\n",
    "                                                                                                params_kwargs={'enable_per_epoch_action_buttons': False,\n",
    "                                                                                                    'skip_plotting_most_likely_positions': True, 'skip_plotting_measured_positions': True, \n",
    "                                                                                                    'enable_decoded_most_likely_position_curve': False, 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': True,\n",
    "                                                                                                    # 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': False,\n",
    "                                                                                                    # 'disable_y_label': True,\n",
    "                                                                                                    'isPaginatorControlWidgetBackedMode': True,\n",
    "                                                                                                    'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True,\n",
    "                                                                                                    # 'debug_print': True,\n",
    "                                                                                                    'max_subplots_per_page': 10,\n",
    "                                                                                                    'scrollable_figure': False,\n",
    "                                                                                                    # 'scrollable_figure': True,\n",
    "                                                                                                    # 'posterior_heatmap_imshow_kwargs': dict(vmin=0.0075),\n",
    "                                                                                                    'use_AnchoredCustomText': False,\n",
    "                                                                                                    'should_suppress_callback_exceptions': False,\n",
    "                                                                                                    # 'build_fn': 'insets_view',\n",
    "                                                                                                })\n",
    "\n",
    "### attached raster viewer widget:\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.RankOrderRastersDebugger import RankOrderRastersDebugger\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import get_proper_global_spikes_df\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "\n",
    "## INPUTS: active_spikes_df\n",
    "# active_spikes_df = get_proper_global_spikes_df(curr_active_pipeline, minimum_inclusion_fr_Hz=5)\n",
    "\n",
    "# PosteriorExporting._perform_export_current_epoch_marginal_and_raster_images\n",
    "\n",
    "# _out_ripple_rasters, update_attached_raster_viewer_epoch_callback = build_attached_raster_viewer_widget(paginated_multi_decoder_decoded_epochs_window=paginated_multi_decoder_decoded_epochs_window, track_templates=track_templates, active_spikes_df=active_spikes_df, filtered_ripple_simple_pf_pearson_merged_df=filtered_epochs_df) ## BEST\n",
    "# _out_ripple_rasters, update_attached_raster_viewer_epoch_callback = build_attached_raster_viewer_widget(paginated_multi_decoder_decoded_epochs_window=paginated_multi_decoder_decoded_epochs_window, track_templates=track_templates, active_spikes_df=active_spikes_df, filtered_ripple_simple_pf_pearson_merged_df=filtered_ripple_simple_pf_pearson_merged_df) # original\n",
    "# _out_ripple_rasters, update_attached_raster_viewer_epoch_callback = build_attached_raster_viewer_widget(paginated_multi_decoder_decoded_epochs_window=paginated_multi_decoder_decoded_epochs_window, track_templates=track_templates, active_spikes_df=active_spikes_df, filtered_ripple_simple_pf_pearson_merged_df=extracted_merged_scores_df)\n",
    "_out_ripple_rasters, update_attached_raster_viewer_epoch_callback = paginated_multi_decoder_decoded_epochs_window.build_attached_raster_viewer_widget(track_templates=track_templates, active_spikes_df=active_spikes_df, filtered_epochs_df=long_like_during_post_delta_only_filter_epochs_df) # Long-like-during-post-delta\n",
    "\n",
    "\n",
    "# all_directional_laps_filter_epochs_decoder_result_value\n",
    "# laps_filter_epochs = ensure_dataframe(deepcopy(decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)) \n",
    "# _out_ripple_rasters, update_attached_raster_viewer_epoch_callback = build_attached_raster_viewer_widget(paginated_multi_decoder_decoded_epochs_window=paginated_multi_decoder_decoded_epochs_window, track_templates=track_templates, active_spikes_df=laps_spikes_df, filtered_ripple_simple_pf_pearson_merged_df=filtered_laps_simple_pf_pearson_merged_df) ## LAPS\n",
    "\n",
    "# _out_ripple_rasters: RankOrderRastersDebugger\n",
    "### Add yellow-blue marginals to `paginated_multi_decoder_decoded_epochs_window`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_decoded_epoch_slices\n",
    "from pyphocorehelpers.gui.Qt.widget_positioning_helpers import WidgetPositioningHelpers, DesiredWidgetLocation, WidgetGeometryInfo\n",
    "\n",
    "yellow_blue_trackID_marginals_plot_tuple = paginated_multi_decoder_decoded_epochs_window.build_attached_yellow_blue_track_identity_marginal_window(directional_merged_decoders_result, global_session, ripple_decoding_time_bin_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fee2d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean and max number of active aclus per time bin for each epoch (lap)\n",
    "filtered_laps_time_bin_marginals_df.groupby(['lap_id']).agg(n_unique_aclus_mean=('n_unique_aclus', 'mean'), n_unique_aclus_max=('n_unique_aclus', 'max')).reset_index()\n",
    "filtered_laps_time_bin_marginals_df.groupby(['maze_id']).agg(n_unique_aclus_mean=('n_unique_aclus', 'mean'), n_unique_aclus_max=('n_unique_aclus', 'max')).reset_index() ## per maze\n",
    "filtered_laps_time_bin_marginals_df.groupby(['maze_id', 'lap_dir']).agg(n_unique_aclus_mean=('n_unique_aclus', 'mean'), n_unique_aclus_max=('n_unique_aclus', 'max')).reset_index() # per maze x lap_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93346114",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "\t !!!||||||||||||||||||> RUNNING `PostHocPipelineFixup.FINAL_UPDATE_ALL(...)`:\n",
      "starting `PostHocPipelineFixup.FINAL_UPDATE_ALL(...)`...\n",
      "\t !!!||||||||||||||||||> RUNNING `PostHocPipelineFixup.FINAL_FIX_GRID_BIN_BOUNDS(...)`:\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.position_info.mat\"... done.\n",
      "No grid bin bounds were changed. Everything should be up-to-date!\n",
      "\t =================> RUNNING `PostHocPipelineFixup.FINAL_UPDATE_FILEPATHS(...)`:\n",
      "\t =================> RUNNING `PostHocPipelineFixup.FINAL_UPDATE_NON_PBE_EPOCHS(...)`:\n",
      "computing non_PBE epochs for session...\n",
      "\n",
      "Saving non_pbe results results : \"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/2006-6-09_1-22-43.non_pbe.npy\"... 2006-6-09_1-22-43.non_pbe.npy saved\n",
      "done.\n",
      "\tDirectionalLapsResult.init_from_pipeline_natural_epochs(...): was_modified: False\n",
      "\tPostHocPipelineFixup.FINAL_UPDATE_ALL(...): did_any_change: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.BatchCompletionHandler import BatchSessionCompletionHandler\n",
    "\n",
    "BatchSessionCompletionHandler.post_compute_validate(curr_active_pipeline=curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0617e7a3",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['maze1_odd', 'maze1_even', 'maze2_odd', 'maze2_even']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(directional_laps_results.directional_lap_specific_configs.keys()) # ['maze1_odd', 'maze1_even', 'maze2_odd', 'maze2_even']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "912656a7",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(active_epochs_df): 412\n",
      "min_num_unique_aclu_inclusions: 16\n",
      "pos_bin_size = 4.877453969028168, ripple_decoding_time_bin_size = 0.016, laps_decoding_time_bin_size = 0.025\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "from neuropy.utils.indexing_helpers import NumpyHelpers\n",
    "\n",
    "if ('DirectionalDecodersEpochsEvaluations' in curr_active_pipeline.global_computation_results.computed_data) and (curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations'] is not None):\n",
    "    directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "    directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)\n",
    "\n",
    "    ## UNPACK HERE via direct property access:\n",
    "    pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "    ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "    laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "    print(f'{pos_bin_size = }, {ripple_decoding_time_bin_size = }, {laps_decoding_time_bin_size = }') # pos_bin_size = 3.8054171165052444, ripple_decoding_time_bin_size = 0.025, laps_decoding_time_bin_size = 0.2\n",
    "    decoder_laps_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict\n",
    "    decoder_ripple_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict\n",
    "    decoder_laps_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_df_dict\n",
    "    decoder_ripple_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_df_dict\n",
    "\n",
    "    # New items:\n",
    "    decoder_laps_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_extras_dict\n",
    "    decoder_ripple_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_extras_dict\n",
    "\n",
    "    # Weighted correlations:\n",
    "    laps_weighted_corr_merged_df = directional_decoders_epochs_decode_result.laps_weighted_corr_merged_df\n",
    "    ripple_weighted_corr_merged_df = directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "    decoder_laps_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_laps_weighted_corr_df_dict\n",
    "    decoder_ripple_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict\n",
    "\n",
    "    # Pearson's correlations:\n",
    "    laps_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.laps_simple_pf_pearson_merged_df\n",
    "    ripple_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df\n",
    "    \n",
    "    # for k, v in directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict.items():\n",
    "    #     print(f'{k}: v.decoding_time_bin_size: {v.decoding_time_bin_size}')\n",
    "    \n",
    "    individual_result_ripple_time_bin_sizes = [v.decoding_time_bin_size for k, v in directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict.items()]\n",
    "    if not np.allclose(ripple_decoding_time_bin_size, individual_result_ripple_time_bin_sizes):\n",
    "        individual_result_ripple_time_bin_size = individual_result_ripple_time_bin_sizes[0] # get the first\n",
    "        assert np.allclose(individual_result_ripple_time_bin_size, individual_result_ripple_time_bin_sizes), f\"`individual_result_ripple_time_bin_size ({individual_result_ripple_time_bin_size}) does not equal the individual result time bin sizes: {individual_result_ripple_time_bin_sizes}`. This can occur when there are epochs smaller than the desired size ({ripple_decoding_time_bin_size}) for the result and epochs_filtering_mode=EpochFilteringMode.ConstrainDecodingTimeBinSizeToMinimum\"\n",
    "        print(f'WARN: overriding directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size (original value: {directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size}) with individual_result_ripple_time_bin_size: {individual_result_ripple_time_bin_size}')\n",
    "        directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size = individual_result_ripple_time_bin_size # override the time_bin_size with the actually used one\n",
    "        ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "        print(f'{pos_bin_size = }, {ripple_decoding_time_bin_size = }, {laps_decoding_time_bin_size = }') # pos_bin_size = 3.8054171165052444, ripple_decoding_time_bin_size = 0.025, laps_decoding_time_bin_size = 0.2\n",
    "    else:\n",
    "        # all are close, it's good\n",
    "        pass\n",
    "\n",
    "    # assert np.allclose(ripple_decoding_time_bin_size, individual_result_ripple_time_bin_sizes), f\"`directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size ({ripple_decoding_time_bin_size}) does not equal the individual result time bin sizes: {individual_result_ripple_time_bin_sizes}`. This can occur when there are epochs smaller than the desired size ({ripple_decoding_time_bin_size}) for the result and epochs_filtering_mode=EpochFilteringMode.ConstrainDecodingTimeBinSizeToMinimum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06f1c291",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          start         stop label  duration  lap_id  lap_dir     score   velocity     intercept      speed     wcorr  P_decoder  pearsonr  mseq_len  mseq_len_ignoring_intrusions  mseq_len_ignoring_intrusions_and_repeats  mseq_len_ratio_ignoring_intrusions_and_repeats  mseq_tcov  mseq_dtrav  avg_jump_cm    travel  coverage  total_distance_traveled  track_coverage_score  longest_sequence_length  longest_sequence_length_ratio  direction_change_bin_ratio  congruent_dir_bins_ratio  total_congruent_direction_change  total_variation  integral_second_derivative  stddev_of_diff\n",
       "0      3.054774     4.723224     0  1.668450       1        1  0.091862  33.016611    381.724597  33.016611  0.056035        NaN  0.267227         4                             4                                         1                                        0.076923   0.000000    0.000000    90.011196  0.427084  0.576271                 0.898305              0.898305                        4                       0.160000                    0.538462                  0.400000                       2970.369467      5940.738934                2.977025e+06      127.217211\n",
       "1      6.356765     8.926857     1  2.570092       2        0  0.106566  17.384984    391.183176  17.384984  0.057187        NaN  0.215698        11                            11                                         1                                        0.043478   0.000000    0.000000    84.638172  0.399421  0.508475                 0.898305              0.898305                       11                       0.183333                    0.405941                  0.277228                       4428.728204      8633.093525                5.085541e+06      132.287338\n",
       "2     45.195989    50.869954     2  5.673965       3        1  0.148741  39.886735   2039.775524  39.886735 -0.334347        NaN -0.565427        14                            14                                         3                                        0.035714   0.084746  102.426533    62.500472  0.293356  0.491525                 0.898305              0.898305                       14                       0.103704                    0.435556                  0.453333                       7062.553347     14125.106694                6.204412e+06       97.236421\n",
       "3     65.785018    72.223040     3  6.438022       4        0  0.215587   0.762102    296.455858   0.762102  0.439627        NaN  0.610514        36                            36                                         1                                        0.014493   0.033898  107.303987    60.142613  0.282138  0.288136                 0.898305              0.898305                       36                       0.232258                    0.394531                  0.421875                       7803.926350     15456.651628                6.507705e+06       92.917601\n",
       "4     84.303384    91.044238     4  6.740854       5        1  0.178041  46.566639   4240.742515  46.566639 -0.575330        NaN -0.800972        12                            12                                         3                                        0.033333   0.186441  112.181441    56.933849  0.267039  0.389831                 0.898305              0.898305                       12                       0.065934                    0.373134                  0.436567                       7657.602731     15315.205463                7.396554e+06       97.748160\n",
       "5    106.425978   112.964646     5  6.538668       6        0  0.184772  -2.251133    -12.805518   2.251133  0.410802        NaN  0.612442        29                            29                                         1                                        0.014925   0.050847   73.161810    61.369957  0.287878  0.254237                 0.898305              0.898305                       29                       0.177914                    0.392308                  0.361538                       8130.715766     16017.558834                6.973266e+06       98.448381\n",
       "..          ...          ...   ...       ...     ...      ...       ...        ...           ...        ...       ...        ...       ...       ...                           ...                                       ...                                             ...        ...         ...          ...       ...       ...                      ...                   ...                      ...                            ...                         ...                       ...                               ...              ...                         ...             ...\n",
       "78  1604.668520  1607.804303    78  3.135783      79        1  0.136393  53.494656  86015.009468  53.494656 -0.159785        NaN -0.433614         8                             8                                         3                                        0.073171   0.186441  126.813803    44.872577  0.211376  0.440678                 0.711864              0.711864                        8                       0.119403                    0.443548                  0.459677                       2892.330204      5609.072064                1.539589e+06       64.830478\n",
       "79  1608.839610  1614.145200    79  5.305590      80        0  0.165647  -6.472451 -10201.046822   6.472451  0.450108        NaN  0.591013        29                            29                                         2                                        0.025000   0.135593   97.549079    53.398918  0.250710  0.254237                 0.898305              0.898305                       29                       0.192053                    0.360190                  0.402844                       5682.233874     11320.570662                4.237372e+06       87.885699\n",
       "80  1620.117294  1625.623997    80  5.506703      81        1  0.161557  24.053198  39161.961594  24.053198 -0.367990        NaN -0.537991         7                             7                                         1                                        0.010309   0.000000    0.000000    53.785015  0.252479  0.474576                 0.898305              0.898305                        7                       0.046667                    0.410959                  0.438356                       5916.351664     11832.703329                4.026906e+06       81.066539\n",
       "81  1628.792203  1632.596083    81  3.803880      82        0  0.210492   2.584082   4460.153098   2.584082  0.290495        NaN  0.443326        13                            13                                         1                                        0.019608   0.033898   29.264724    76.178130  0.358330  0.305085                 0.898305              0.898305                       13                       0.144444                    0.463576                  0.357616                       5789.537861     11579.075722                6.157213e+06      115.667060\n",
       "82  1645.812118  1652.718007    82  6.905889      83        1  0.124477  48.335129  79900.521022  48.335129 -0.303850        NaN -0.544471        15                            14                                         4                                        0.045977   0.237288  180.465797    60.172938  0.282204  0.372881                 0.898305              0.898305                       14                       0.082840                    0.418182                  0.410909                       8364.833557     16607.730765                7.035476e+06       96.746195\n",
       "83  1652.750230  1658.090188    83  5.339958      84        0  0.151447 -10.123018 -16533.409437  10.123018  0.419116        NaN  0.597148         9                             9                                         2                                        0.028571   0.067797   48.774540    74.581538  0.350156  0.355932                 0.898305              0.898305                        9                       0.080357                    0.504717                  0.457547                       8047.799049     15885.867577                7.861426e+06      111.041450\n",
       "\n",
       "[84 rows x 32 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dce38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_decoders_epochs_decode_result # DecoderDecodedEpochsResult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "881402df",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'maze_any'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# active_config_name: str = 'maze_any'\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "active_config_name: str = global_epoch_name # 'maze_any'\n",
    "active_config_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b80230",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "## INPUTS: curr_active_pipeline, active_config_name\n",
    "active_peak_prominence_2d_results = curr_active_pipeline.computation_results[active_config_name].computed_data.get('RatemapPeaksAnalysis', {}).get('PeakProminence2D', None)\n",
    "if active_peak_prominence_2d_results is None:\n",
    "    curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['ratemap_peaks_prominence2d'], enabled_filter_names=None, fail_on_exception=False, debug_print=False)\n",
    "    # curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['ratemap_peaks_prominence2d'], enabled_filter_names=[short_LR_name, short_RL_name, long_any_name, short_any_name], fail_on_exception=False, debug_print=False) # or at least\n",
    "    active_peak_prominence_2d_results = curr_active_pipeline.computation_results[active_config_name].computed_data.get('RatemapPeaksAnalysis', {}).get('PeakProminence2D', None)\n",
    "    assert active_peak_prominence_2d_results is not None, f\"bad even after computation\"\n",
    "\n",
    "# active_peak_prominence_2d_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "238f67cb",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all",
     "run-continuous-decoding"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previously_decoded time_bin_sizes: [0.025]\n",
      "time_bin_size: 0.025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'long_LR': DecodedFilterEpochsResult(decoding_time_bin_size: float,\n",
       " \tfilter_epochs: neuropy.core.epoch.Epoch,\n",
       " \tnum_filter_epochs: int,\n",
       " \tmost_likely_positions_list: list | shape (n_epochs),\n",
       " \tp_x_given_n_list: list | shape (n_epochs),\n",
       " \tmarginal_x_list: list | shape (n_epochs),\n",
       " \tmarginal_y_list: list | shape (n_epochs),\n",
       " \tmost_likely_position_indicies_list: list | shape (n_epochs),\n",
       " \tspkcount: list | shape (n_epochs),\n",
       " \tnbins: numpy.ndarray | shape (n_epochs),\n",
       " \ttime_bin_containers: list | shape (n_epochs),\n",
       " \ttime_bin_edges: list | shape (n_epochs),\n",
       " \tepoch_description_list: list | shape (n_epochs),\n",
       " \tpos_bin_edges: numpy.ndarray | shape (n_pos_bins+1)\n",
       " ),\n",
       " 'long_RL': DecodedFilterEpochsResult(decoding_time_bin_size: float,\n",
       " \tfilter_epochs: neuropy.core.epoch.Epoch,\n",
       " \tnum_filter_epochs: int,\n",
       " \tmost_likely_positions_list: list | shape (n_epochs),\n",
       " \tp_x_given_n_list: list | shape (n_epochs),\n",
       " \tmarginal_x_list: list | shape (n_epochs),\n",
       " \tmarginal_y_list: list | shape (n_epochs),\n",
       " \tmost_likely_position_indicies_list: list | shape (n_epochs),\n",
       " \tspkcount: list | shape (n_epochs),\n",
       " \tnbins: numpy.ndarray | shape (n_epochs),\n",
       " \ttime_bin_containers: list | shape (n_epochs),\n",
       " \ttime_bin_edges: list | shape (n_epochs),\n",
       " \tepoch_description_list: list | shape (n_epochs),\n",
       " \tpos_bin_edges: numpy.ndarray | shape (n_pos_bins+1)\n",
       " ),\n",
       " 'short_LR': DecodedFilterEpochsResult(decoding_time_bin_size: float,\n",
       " \tfilter_epochs: neuropy.core.epoch.Epoch,\n",
       " \tnum_filter_epochs: int,\n",
       " \tmost_likely_positions_list: list | shape (n_epochs),\n",
       " \tp_x_given_n_list: list | shape (n_epochs),\n",
       " \tmarginal_x_list: list | shape (n_epochs),\n",
       " \tmarginal_y_list: list | shape (n_epochs),\n",
       " \tmost_likely_position_indicies_list: list | shape (n_epochs),\n",
       " \tspkcount: list | shape (n_epochs),\n",
       " \tnbins: numpy.ndarray | shape (n_epochs),\n",
       " \ttime_bin_containers: list | shape (n_epochs),\n",
       " \ttime_bin_edges: list | shape (n_epochs),\n",
       " \tepoch_description_list: list | shape (n_epochs),\n",
       " \tpos_bin_edges: numpy.ndarray | shape (n_pos_bins+1)\n",
       " ),\n",
       " 'short_RL': DecodedFilterEpochsResult(decoding_time_bin_size: float,\n",
       " \tfilter_epochs: neuropy.core.epoch.Epoch,\n",
       " \tnum_filter_epochs: int,\n",
       " \tmost_likely_positions_list: list | shape (n_epochs),\n",
       " \tp_x_given_n_list: list | shape (n_epochs),\n",
       " \tmarginal_x_list: list | shape (n_epochs),\n",
       " \tmarginal_y_list: list | shape (n_epochs),\n",
       " \tmost_likely_position_indicies_list: list | shape (n_epochs),\n",
       " \tspkcount: list | shape (n_epochs),\n",
       " \tnbins: numpy.ndarray | shape (n_epochs),\n",
       " \ttime_bin_containers: list | shape (n_epochs),\n",
       " \ttime_bin_edges: list | shape (n_epochs),\n",
       " \tepoch_description_list: list | shape (n_epochs),\n",
       " \tpos_bin_edges: numpy.ndarray | shape (n_pos_bins+1)\n",
       " ),\n",
       " 'pseudo2D': DecodedFilterEpochsResult(decoding_time_bin_size: float,\n",
       " \tfilter_epochs: neuropy.core.epoch.Epoch,\n",
       " \tnum_filter_epochs: int,\n",
       " \tmost_likely_positions_list: list | shape (n_epochs),\n",
       " \tp_x_given_n_list: list | shape (n_epochs),\n",
       " \tmarginal_x_list: list | shape (n_epochs),\n",
       " \tmarginal_y_list: list | shape (n_epochs),\n",
       " \tmost_likely_position_indicies_list: list | shape (n_epochs),\n",
       " \tspkcount: list | shape (n_epochs),\n",
       " \tnbins: numpy.ndarray | shape (n_epochs),\n",
       " \ttime_bin_containers: list | shape (n_epochs),\n",
       " \ttime_bin_edges: list | shape (n_epochs),\n",
       " \tepoch_description_list: list | shape (n_epochs),\n",
       " \tpos_bin_edges: numpy.ndarray | shape (n_pos_bins+1)\n",
       " )}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'long_LR': array([[3.58916e-25, 1.15182e-12, 4.93332e-24, ..., 0.0117785, 1.41119e-05, 0.0117785],\n",
       "        [6.45748e-22, 4.87362e-11, 2.96825e-20, ..., 0.0117207, 6.58797e-05, 0.0117207],\n",
       "        [4.2095e-19, 1.23186e-09, 6.55771e-17, ..., 0.011487, 0.000267975, 0.011487],\n",
       "        ...,\n",
       "        [1.59724e-20, 2.34827e-10, 4.84745e-18, ..., 0.0110011, 0.000100111, 0.0110011],\n",
       "        [9.27711e-24, 5.79955e-12, 1.17106e-21, ..., 0.0115528, 1.99171e-05, 0.0115528],\n",
       "        [0, 0, 0, ..., 0.0117268, 2.9009e-06, 0.0117268]]),\n",
       " 'long_RL': array([[0, 0, 0, ..., 0.0112739, 0.0109804, 0.0112739],\n",
       "        [0, 0, 0, ..., 0.0107413, 0.0200399, 0.0107413],\n",
       "        [0, 0, 0, ..., 0.00970296, 0.0338786, 0.00970296],\n",
       "        ...,\n",
       "        [7.21528e-25, 1.60366e-12, 4.14478e-20, ..., 0.0113576, 0.000175994, 0.0113576],\n",
       "        [4.10164e-28, 3.87634e-14, 1.56172e-23, ..., 0.0116735, 3.38727e-05, 0.0116735],\n",
       "        [0, 0, 0, ..., 0.0117631, 4.74621e-06, 0.0117631]]),\n",
       " 'short_LR': array([[0, 0, 0, ..., 0.0117938, 0, 0.0117938],\n",
       "        [0, 0, 0, ..., 0.0117938, 0, 0.0117938],\n",
       "        [0, 0, 0, ..., 0.0117938, 0, 0.0117938],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0.0117938, 0, 0.0117938],\n",
       "        [0, 0, 0, ..., 0.0117938, 0, 0.0117938],\n",
       "        [0, 0, 0, ..., 0.0117938, 0, 0.0117938]]),\n",
       " 'short_RL': array([[0, 0, 0, ..., 0.0117938, 0, 0.0117938],\n",
       "        [0, 0, 0, ..., 0.0117938, 0, 0.0117938],\n",
       "        [0, 0, 0, ..., 0.0117938, 0, 0.0117938],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0.0117938, 0, 0.0117938],\n",
       "        [0, 0, 0, ..., 0.0117938, 0, 0.0117938],\n",
       "        [0, 0, 0, ..., 0.0117938, 0, 0.0117938]])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalDecodersContinuouslyDecodedResult\n",
    "\n",
    "if 'DirectionalDecodersDecoded' in curr_active_pipeline.global_computation_results.computed_data:\n",
    "    directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "    all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "    pseudo2D_decoder: BasePositionDecoder = directional_decoders_decode_result.pseudo2D_decoder\n",
    "    spikes_df = directional_decoders_decode_result.spikes_df\n",
    "    continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "    previously_decoded_keys: List[float] = list(continuously_decoded_result_cache_dict.keys()) # [0.03333]\n",
    "    print(F'previously_decoded time_bin_sizes: {previously_decoded_keys}')\n",
    "    \n",
    "    time_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\n",
    "    print(f'time_bin_size: {time_bin_size}')\n",
    "    continuously_decoded_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_decode_result.most_recent_continuously_decoded_dict\n",
    "    all_directional_continuously_decoded_dict = continuously_decoded_dict or {} ## what is plotted in the `f'{a_decoder_name}_ContinuousDecode'` rows by `AddNewDirectionalDecodedEpochs_MatplotlibPlotCommand`\n",
    "    all_directional_continuously_decoded_dict\n",
    "\n",
    "    pseudo2D_decoder_continuously_decoded_result: DecodedFilterEpochsResult = continuously_decoded_dict.get('pseudo2D', None)\n",
    "    assert len(pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list) == 1\n",
    "    p_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0]\n",
    "    # p_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0]['p_x_given_n']\n",
    "    time_bin_containers = pseudo2D_decoder_continuously_decoded_result.time_bin_containers[0]\n",
    "    time_window_centers = time_bin_containers.centers\n",
    "    # p_x_given_n.shape # (62, 4, 209389)\n",
    "\n",
    "    ## Split across the 2nd axis to make 1D posteriors that can be displayed in separate dock rows:\n",
    "    assert p_x_given_n.shape[1] == 4, f\"expected the 4 pseudo-y bins for the decoder in p_x_given_n.shape[1]. but found p_x_given_n.shape: {p_x_given_n.shape}\"\n",
    "    split_pseudo2D_posteriors_dict = {k:np.squeeze(p_x_given_n[:, i, :]) for i, k in enumerate(('long_LR', 'long_RL', 'short_LR', 'short_RL'))}\n",
    "    split_pseudo2D_posteriors_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d92b4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_decoders_decode_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e1ee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_directional_pf1D_Decoder_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7b4e959",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceBased is not computed.\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.SequenceBasedComputations import WCorrShuffle, SequenceBasedComputationsContainer\n",
    "\n",
    "wcorr_shuffle_results: SequenceBasedComputationsContainer = curr_active_pipeline.global_computation_results.computed_data.get('SequenceBased', None)\n",
    "if wcorr_shuffle_results is not None:    \n",
    "    wcorr_ripple_shuffle: WCorrShuffle = wcorr_shuffle_results.wcorr_ripple_shuffle\n",
    "    if wcorr_ripple_shuffle is not None:\n",
    "        print(f'wcorr_ripple_shuffle.n_completed_shuffles: {wcorr_ripple_shuffle.n_completed_shuffles}')\n",
    "    else:\n",
    "        print(f'SequenceBased is computed but `wcorr_shuffle_results.wcorr_ripple_shuffle` is None.')        \n",
    "else:\n",
    "    print(f'SequenceBased is not computed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e9cc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['trial_by_trial_metrics'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "directional_trial_by_trial_activity_result = curr_active_pipeline.global_computation_results.computed_data.get('TrialByTrialActivity', None) ## try again to get the result\n",
    "assert directional_trial_by_trial_activity_result is not None, f\"directional_trial_by_trial_activity_result is None even after forcing recomputation!!\"\n",
    "print(f'\\t done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10d7394a",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.reliability import TrialByTrialActivity\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrialByTrialActivityResult\n",
    "\n",
    "directional_trial_by_trial_activity_result: TrialByTrialActivityResult = curr_active_pipeline.global_computation_results.computed_data.get('TrialByTrialActivity', None)\n",
    "if directional_trial_by_trial_activity_result is None:\n",
    "    # if `KeyError: 'TrialByTrialActivity'` recompute\n",
    "    print(f'TrialByTrialActivity is not computed, computing it...')\n",
    "    curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['trial_by_trial_metrics'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "    directional_trial_by_trial_activity_result = curr_active_pipeline.global_computation_results.computed_data.get('TrialByTrialActivity', None) ## try again to get the result\n",
    "    assert directional_trial_by_trial_activity_result is not None, f\"directional_trial_by_trial_activity_result is None even after forcing recomputation!!\"\n",
    "    print(f'\\t done.')\n",
    "\n",
    "## unpack either way:\n",
    "any_decoder_neuron_IDs = directional_trial_by_trial_activity_result.any_decoder_neuron_IDs\n",
    "active_pf_dt: PfND_TimeDependent = directional_trial_by_trial_activity_result.active_pf_dt\n",
    "directional_lap_epochs_dict: Dict[str, Epoch] = directional_trial_by_trial_activity_result.directional_lap_epochs_dict\n",
    "directional_active_lap_pf_results_dicts: Dict[str, TrialByTrialActivity] = directional_trial_by_trial_activity_result.directional_active_lap_pf_results_dicts\n",
    "stability_dict = {k:list(v.aclu_to_stability_score_dict.values()) for k,v in directional_active_lap_pf_results_dicts.items()}\n",
    "stability_df: pd.DataFrame = pd.DataFrame({'aclu': any_decoder_neuron_IDs, **stability_dict})\n",
    "## OUTPUTS: stability_df, stability_dict\n",
    "\n",
    "## OUTPUTS: directional_trial_by_trial_activity_result, directional_active_lap_pf_results_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94fad74c",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceBased is not computed.\n"
     ]
    }
   ],
   "source": [
    "wcorr_shuffle_results: SequenceBasedComputationsContainer = curr_active_pipeline.global_computation_results.computed_data.get('SequenceBased', None)\n",
    "if wcorr_shuffle_results is not None:    \n",
    "    wcorr_ripple_shuffle: WCorrShuffle = wcorr_shuffle_results.wcorr_ripple_shuffle\n",
    "    if wcorr_ripple_shuffle is not None:  \n",
    "        print(f'wcorr_ripple_shuffle.n_completed_shuffles: {wcorr_ripple_shuffle.n_completed_shuffles}')\n",
    "    else:\n",
    "        print(f'SequenceBased is computed but wcorr_ripple_shuffle is None.')\n",
    "else:\n",
    "    print(f'SequenceBased is not computed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3ed0870",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "run-continuous-decoding"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_bin_size: 0.025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SingleEpochDecodedResult(p_x_given_n: numpy.ndarray,\n",
       "\tepoch_info_tuple: pandas.core.frame.EpochTuple,\n",
       "\tmost_likely_positions: numpy.ndarray,\n",
       "\tmost_likely_position_indicies: numpy.ndarray,\n",
       "\tnbins: numpy.int32,\n",
       "\ttime_bin_container: neuropy.utils.mixins.binning_helpers.BinningContainer,\n",
       "\ttime_bin_edges: numpy.ndarray,\n",
       "\tmarginal_x: neuropy.utils.dynamic_container.DynamicContainer,\n",
       "\tmarginal_y: neuropy.utils.dynamic_container.DynamicContainer,\n",
       "\tepoch_data_index: int\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult, SingleEpochDecodedResult\n",
    "\n",
    "most_recent_time_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\n",
    "# most_recent_time_bin_size\n",
    "most_recent_continuously_decoded_dict = deepcopy(directional_decoders_decode_result.most_recent_continuously_decoded_dict)\n",
    "# most_recent_continuously_decoded_dict\n",
    "\n",
    "## Adds in the 'pseudo2D' decoder in:\n",
    "time_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\n",
    "# time_bin_size: float = 0.01\n",
    "print(f'time_bin_size: {time_bin_size}')\n",
    "continuously_decoded_dict = continuously_decoded_result_cache_dict[time_bin_size]\n",
    "pseudo2D_decoder_continuously_decoded_result = continuously_decoded_dict.get('pseudo2D', None)\n",
    "if pseudo2D_decoder_continuously_decoded_result is None:\n",
    "    # compute here...\n",
    "    ## Currently used for both cases to decode:\n",
    "    t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "    single_global_epoch_df: pd.DataFrame = pd.DataFrame({'start': [t_start], 'stop': [t_end], 'label': [0]}) # Build an Epoch object containing a single epoch, corresponding to the global epoch for the entire session:\n",
    "    single_global_epoch: Epoch = Epoch(single_global_epoch_df)\n",
    "    spikes_df = directional_decoders_decode_result.spikes_df\n",
    "    pseudo2D_decoder_continuously_decoded_result: DecodedFilterEpochsResult = pseudo2D_decoder.decode_specific_epochs(spikes_df=deepcopy(spikes_df), filter_epochs=single_global_epoch, decoding_time_bin_size=time_bin_size, debug_print=False)\n",
    "    continuously_decoded_dict['pseudo2D'] = pseudo2D_decoder_continuously_decoded_result\n",
    "    continuously_decoded_dict\n",
    "    \n",
    "pseudo2D_decoder_continuously_decoded_single_result: SingleEpochDecodedResult = pseudo2D_decoder_continuously_decoded_result.get_result_for_epoch(0)\n",
    "pseudo2D_decoder_continuously_decoded_single_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eab4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudo2D_decoder_continuously_decoded_single_result.epoch_info_tuple\n",
    "pseudo2D_decoder_continuously_decoded_single_result.nbins\n",
    "pseudo2D_decoder_continuously_decoded_single_result.p_x_given_n\n",
    "pseudo2D_decoder_continuously_decoded_single_result.p_x_given_n.shape # (57, 4, 29951)\n",
    "\n",
    "\n",
    "short_RL_only = pseudo2D_decoder_continuously_decoded_single_result.p_x_given_n[:, 3, :]\n",
    "np.shape(short_RL_only)\n",
    "\n",
    "debug_portion_short_RL_only = short_RL_only[:, :1000]\n",
    "\n",
    "\n",
    "plt.figure(clear=True)\n",
    "plt.imshow(debug_portion_short_RL_only)\n",
    "# plt.plot(np.sum(short_RL_only, axis=0))\n",
    "# plt.plot(np.cumsum(np.sum(short_RL_only, axis=0)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f48287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88344ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import SingleEpochDecodedResult\n",
    "\n",
    "\n",
    "only_result.p_x_given_n\n",
    "only_result.time_bin_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ee77bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo2D_decoder_continuously_decoded_result.filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa2dc5fe",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# NEW 2023-11-22 method: Get the templates (which can be filtered by frate first) and the from those get the decoders):        \n",
    "# track_templates: TrackTemplates = directional_laps_results.get_shared_aclus_only_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # shared-only\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, included_qclu_values=included_qclu_values) # non-shared-only\n",
    "long_LR_decoder, long_RL_decoder, short_LR_decoder, short_RL_decoder = track_templates.get_decoders()\n",
    "\n",
    "# Unpack all directional variables:\n",
    "## {\"even\": \"RL\", \"odd\": \"LR\"}\n",
    "long_LR_name, short_LR_name, global_LR_name, long_RL_name, short_RL_name, global_RL_name, long_any_name, short_any_name, global_any_name = ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "# Unpacking for `(long_LR_name, long_RL_name, short_LR_name, short_RL_name)`\n",
    "(long_LR_context, long_RL_context, short_LR_context, short_RL_context) = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj, global_any_laps_epochs_obj = [curr_active_pipeline.computation_results[an_epoch_name].computation_config.pf_params.computation_epochs for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name, global_any_name)] # note has global also\n",
    "(long_LR_session, long_RL_session, short_LR_session, short_RL_session) = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)] # sessions are correct at least, seems like just the computation parameters are messed up\n",
    "(long_LR_results, long_RL_results, short_LR_results, short_RL_results) = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_computation_config, long_RL_computation_config, short_LR_computation_config, short_RL_computation_config) = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_pf1D, long_RL_pf1D, short_LR_pf1D, short_RL_pf1D) = (long_LR_results.pf1D, long_RL_results.pf1D, short_LR_results.pf1D, short_RL_results.pf1D)\n",
    "(long_LR_pf2D, long_RL_pf2D, short_LR_pf2D, short_RL_pf2D) = (long_LR_results.pf2D, long_RL_results.pf2D, short_LR_results.pf2D, short_RL_results.pf2D)\n",
    "(long_LR_pf1D_Decoder, long_RL_pf1D_Decoder, short_LR_pf1D_Decoder, short_RL_pf1D_Decoder) = (long_LR_results.pf1D_Decoder, long_RL_results.pf1D_Decoder, short_LR_results.pf1D_Decoder, short_RL_results.pf1D_Decoder)\n",
    "\n",
    "if rank_order_results is not None:\n",
    "    # `LongShortStatsItem` form (2024-01-02):\n",
    "    # LR_results_real_values = np.array([(a_result_item.long_stats_z_scorer.real_value, a_result_item.short_stats_z_scorer.real_value) for epoch_id, a_result_item in rank_order_results.LR_ripple.ranked_aclus_stats_dict.items()])\n",
    "    # RL_results_real_values = np.array([(a_result_item.long_stats_z_scorer.real_value, a_result_item.short_stats_z_scorer.real_value) for epoch_id, a_result_item in rank_order_results.RL_ripple.ranked_aclus_stats_dict.items()])\n",
    "    LR_results_long_short_z_diffs = np.array([a_result_item.long_short_z_diff for epoch_id, a_result_item in rank_order_results.LR_ripple.ranked_aclus_stats_dict.items()])\n",
    "    RL_results_long_short_z_diff = np.array([a_result_item.long_short_z_diff for epoch_id, a_result_item in rank_order_results.RL_ripple.ranked_aclus_stats_dict.items()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c260739a4f36c662",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrainTestSplitResult\n",
    "\n",
    "if 'TrainTestSplit' in curr_active_pipeline.global_computation_results.computed_data:\n",
    "    directional_train_test_split_result: TrainTestSplitResult = curr_active_pipeline.global_computation_results.computed_data.get('TrainTestSplit', None)\n",
    "    training_data_portion: float = directional_train_test_split_result.training_data_portion\n",
    "    test_data_portion: float = directional_train_test_split_result.test_data_portion\n",
    "    test_epochs_dict: Dict[str, pd.DataFrame] = directional_train_test_split_result.test_epochs_dict\n",
    "    train_epochs_dict: Dict[str, pd.DataFrame] = directional_train_test_split_result.train_epochs_dict\n",
    "    train_lap_specific_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_train_test_split_result.train_lap_specific_pf1D_Decoder_dict\n",
    "    \n",
    "long_LR_name, short_LR_name, global_LR_name, long_RL_name, short_RL_name, global_RL_name, long_any_name, short_any_name, global_any_name = ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj = [curr_active_pipeline.computation_results[an_epoch_name].computation_config.pf_params.computation_epochs for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)] # note has global also\n",
    "long_LR_name, long_RL_name, short_LR_name, short_RL_name = track_templates.get_decoder_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec18cf18",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "if 'burst_detection' in curr_active_pipeline.computation_results[global_epoch_name].computed_data:\n",
    "    active_burst_intervals = curr_active_pipeline.computation_results[global_epoch_name].computed_data['burst_detection']['burst_intervals']\n",
    "# active_burst_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d31f37d",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "active_extended_stats = global_results.get('extended_stats', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9554d3bf5955d9d3",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# Time-dependent\n",
    "long_pf1D_dt, short_pf1D_dt, global_pf1D_dt = long_results.pf1D_dt, short_results.pf1D_dt, global_results.pf1D_dt\n",
    "long_pf2D_dt, short_pf2D_dt, global_pf2D_dt = long_results.pf2D_dt, short_results.pf2D_dt, global_results.pf2D_dt\n",
    "global_pf1D_dt: PfND_TimeDependent = global_results.pf1D_dt\n",
    "global_pf2D_dt: PfND_TimeDependent = global_results.pf2D_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7a8050",
   "metadata": {},
   "outputs": [],
   "source": [
    "## long_short_endcap_analysis: checks for cells localized to the endcaps that have their placefields truncated after shortening the track\n",
    "truncation_checking_result: TruncationCheckingResults = curr_active_pipeline.global_computation_results.computed_data.long_short_endcap\n",
    "disappearing_endcap_aclus = truncation_checking_result.disappearing_endcap_aclus\n",
    "# disappearing_endcap_aclus\n",
    "trivially_remapping_endcap_aclus = truncation_checking_result.minor_remapping_endcap_aclus\n",
    "# trivially_remapping_endcap_aclus\n",
    "significant_distant_remapping_endcap_aclus = truncation_checking_result.significant_distant_remapping_endcap_aclus\n",
    "# significant_distant_remapping_endcap_aclus\n",
    "# appearing_aclus = jonathan_firing_rate_analysis_result.neuron_replay_stats_df[jonathan_firing_rate_analysis_result.neuron_replay_stats_df['track_membership'] == SplitPartitionMembership.RIGHT_ONLY].index\n",
    "# appearing_aclus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8ff5d1",
   "metadata": {},
   "source": [
    "# <a id='toc5_'></a>[1Ô∏è‚É£ POST-Compute:](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "728c46e6",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "21"
    },
    "tags": [
     "unwrap",
     "initial",
     "run-group-end-run",
     "all"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum_inclusion_fr_Hz: 5.0\n",
      "included_qclu_values: [1, 2, 4, 6, 7, 8, 9]\n",
      "laps_decoding_time_bin_size: 0.025, ripple_decoding_time_bin_size: 0.025\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalDisplayFunctions\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multi_sort_raster_browser\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.RankOrderRastersDebugger import RankOrderRastersDebugger\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import paired_separately_sort_neurons, paired_incremental_sort_neurons # _display_directional_template_debugger\n",
    "from neuropy.utils.indexing_helpers import paired_incremental_sorting, union_of_arrays, intersection_of_arrays, find_desired_sort_indicies\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.ScrollBarWithSpinBox.ScrollBarWithSpinBox import ScrollBarWithSpinBox\n",
    "\n",
    "from neuropy.utils.mixins.HDF5_representable import HDF_SerializationMixin\n",
    "from pyphoplacecellanalysis.General.Model.ComputationResults import ComputedResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderAnalyses, RankOrderResult, ShuffleHelper, Zscorer, LongShortStatsTuple, DirectionalRankOrderLikelihoods, DirectionalRankOrderResult, RankOrderComputationsContainer\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import TimeColumnAliasesProtocol\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderComputationsContainer\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import DirectionalRankOrderResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "\n",
    "## Display Testing\n",
    "# from pyphoplacecellanalysis.External.pyqtgraph import QtGui\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.Extensions.pyqtgraph_helpers import pyqtplot_build_image_bounds_extent, pyqtplot_plot_image\n",
    "\n",
    "spikes_df = curr_active_pipeline.sess.spikes_df\n",
    "rank_order_results: RankOrderComputationsContainer = curr_active_pipeline.global_computation_results.computed_data.get('RankOrder', None)\n",
    "if rank_order_results is not None:\n",
    "    minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "    ripple_result_tuple, laps_result_tuple = rank_order_results.ripple_most_likely_result_tuple, rank_order_results.laps_most_likely_result_tuple\n",
    "\n",
    "else:        \n",
    "    ## get from parameters:\n",
    "    minimum_inclusion_fr_Hz: float = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.included_qclu_values\n",
    "\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, included_qclu_values=included_qclu_values) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\n",
    "print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "print(f'included_qclu_values: {included_qclu_values}')\n",
    "# ripple_result_tuple\n",
    "\n",
    "## Unpacks `rank_order_results`: \n",
    "# global_replays = Epoch(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].replay))\n",
    "# global_replays = TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].replay))\n",
    "# active_replay_epochs, active_epochs_df, active_selected_spikes_df = combine_rank_order_results(rank_order_results, global_replays, track_templates=track_templates)\n",
    "# active_epochs_df\n",
    "\n",
    "# ripple_result_tuple.directional_likelihoods_tuple.long_best_direction_indices\n",
    "dir_index_to_direction_name_map: Dict[int, str] = {0:'LR', 1:\"RL\"}\n",
    "\n",
    "if rank_order_results is not None:\n",
    "    ## All three DataFrames are the same number of rows, each with one row corresponding to an Epoch:\n",
    "    active_replay_epochs_df = deepcopy(rank_order_results.LR_ripple.epochs_df)\n",
    "    # active_replay_epochs_df\n",
    "\n",
    "    # Change column type to int8 for columns: 'long_best_direction_indices', 'short_best_direction_indices'\n",
    "    # directional_likelihoods_df = pd.DataFrame.from_dict(ripple_result_tuple.directional_likelihoods_tuple._asdict()).astype({'long_best_direction_indices': 'int8', 'short_best_direction_indices': 'int8'})\n",
    "    directional_likelihoods_df = ripple_result_tuple.directional_likelihoods_df\n",
    "    # directional_likelihoods_df\n",
    "\n",
    "    # 2023-12-15 - Newest method:\n",
    "    laps_merged_complete_epoch_stats_df: pd.DataFrame = rank_order_results.laps_merged_complete_epoch_stats_df ## New method\n",
    "    ripple_merged_complete_epoch_stats_df: pd.DataFrame = rank_order_results.ripple_merged_complete_epoch_stats_df ## New method\n",
    "\n",
    "\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "\n",
    "all_directional_decoder_dict_value = directional_merged_decoders_result.all_directional_decoder_dict\n",
    "all_directional_pf1D_Decoder_value = directional_merged_decoders_result.all_directional_pf1D_Decoder\n",
    "# long_directional_pf1D_Decoder_value = directional_merged_decoders_result.long_directional_pf1D_Decoder\n",
    "# long_directional_decoder_dict_value = directional_merged_decoders_result.long_directional_decoder_dict\n",
    "# short_directional_pf1D_Decoder_value = directional_merged_decoders_result.short_directional_pf1D_Decoder\n",
    "# short_directional_decoder_dict_value = directional_merged_decoders_result.short_directional_decoder_dict\n",
    "\n",
    "all_directional_laps_filter_epochs_decoder_result_value = directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result\n",
    "all_directional_ripple_filter_epochs_decoder_result_value = directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result\n",
    "\n",
    "laps_directional_marginals, laps_directional_all_epoch_bins_marginal, laps_most_likely_direction_from_decoder, laps_is_most_likely_direction_LR_dir  = directional_merged_decoders_result.laps_directional_marginals_tuple\n",
    "laps_track_identity_marginals, laps_track_identity_all_epoch_bins_marginal, laps_most_likely_track_identity_from_decoder, laps_is_most_likely_track_identity_Long = directional_merged_decoders_result.laps_track_identity_marginals_tuple\n",
    "ripple_directional_marginals, ripple_directional_all_epoch_bins_marginal, ripple_most_likely_direction_from_decoder, ripple_is_most_likely_direction_LR_dir  = directional_merged_decoders_result.ripple_directional_marginals_tuple\n",
    "ripple_track_identity_marginals, ripple_track_identity_all_epoch_bins_marginal, ripple_most_likely_track_identity_from_decoder, ripple_is_most_likely_track_identity_Long = directional_merged_decoders_result.ripple_track_identity_marginals_tuple\n",
    "\n",
    "ripple_decoding_time_bin_size: float = directional_merged_decoders_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_merged_decoders_result.laps_decoding_time_bin_size\n",
    "\n",
    "print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}, ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}')\n",
    "\n",
    "laps_all_epoch_bins_marginals_df = directional_merged_decoders_result.laps_all_epoch_bins_marginals_df\n",
    "ripple_all_epoch_bins_marginals_df = directional_merged_decoders_result.ripple_all_epoch_bins_marginals_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "753ca336",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "all",
     "run-group-end-run"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(active_epochs_df): 412\n",
      "min_num_unique_aclu_inclusions: 16\n",
      "df_column_names: [['start', 'stop', 'label', 'duration', 'score', 'velocity', 'intercept', 'speed', 'wcorr', 'P_decoder', 'pearsonr', 'mseq_len', 'mseq_len_ignoring_intrusions', 'mseq_len_ignoring_intrusions_and_repeats', 'mseq_len_ratio_ignoring_intrusions_and_repeats', 'mseq_tcov', 'mseq_dtrav', 'avg_jump_cm', 'travel', 'coverage', 'total_distance_traveled', 'track_coverage_score', 'longest_sequence_length', 'longest_sequence_length_ratio', 'direction_change_bin_ratio', 'congruent_dir_bins_ratio', 'total_congruent_direction_change', 'total_variation', 'integral_second_derivative', 'stddev_of_diff', 'is_user_annotated_epoch', 'is_valid_epoch', 'session_name', 'delta_aligned_start_t', 'pre_post_delta_category', 'maze_id'], ['start', 'stop', 'label', 'duration', 'score', 'velocity', 'intercept', 'speed', 'wcorr', 'P_decoder', 'pearsonr', 'mseq_len', 'mseq_len_ignoring_intrusions', 'mseq_len_ignoring_intrusions_and_repeats', 'mseq_len_ratio_ignoring_intrusions_and_repeats', 'mseq_tcov', 'mseq_dtrav', 'avg_jump_cm', 'travel', 'coverage', 'total_distance_traveled', 'track_coverage_score', 'longest_sequence_length', 'longest_sequence_length_ratio', 'direction_change_bin_ratio', 'congruent_dir_bins_ratio', 'total_congruent_direction_change', 'total_variation', 'integral_second_derivative', 'stddev_of_diff', 'is_user_annotated_epoch', 'is_valid_epoch', 'session_name', 'delta_aligned_start_t', 'pre_post_delta_category', 'maze_id'], ['start', 'stop', 'label', 'duration', 'score', 'velocity', 'intercept', 'speed', 'wcorr', 'P_decoder', 'pearsonr', 'mseq_len', 'mseq_len_ignoring_intrusions', 'mseq_len_ignoring_intrusions_and_repeats', 'mseq_len_ratio_ignoring_intrusions_and_repeats', 'mseq_tcov', 'mseq_dtrav', 'avg_jump_cm', 'travel', 'coverage', 'total_distance_traveled', 'track_coverage_score', 'longest_sequence_length', 'longest_sequence_length_ratio', 'direction_change_bin_ratio', 'congruent_dir_bins_ratio', 'total_congruent_direction_change', 'total_variation', 'integral_second_derivative', 'stddev_of_diff', 'is_user_annotated_epoch', 'is_valid_epoch', 'session_name', 'delta_aligned_start_t', 'pre_post_delta_category', 'maze_id'], ['start', 'stop', 'label', 'duration', 'score', 'velocity', 'intercept', 'speed', 'wcorr', 'P_decoder', 'pearsonr', 'mseq_len', 'mseq_len_ignoring_intrusions', 'mseq_len_ignoring_intrusions_and_repeats', 'mseq_len_ratio_ignoring_intrusions_and_repeats', 'mseq_tcov', 'mseq_dtrav', 'avg_jump_cm', 'travel', 'coverage', 'total_distance_traveled', 'track_coverage_score', 'longest_sequence_length', 'longest_sequence_length_ratio', 'direction_change_bin_ratio', 'congruent_dir_bins_ratio', 'total_congruent_direction_change', 'total_variation', 'integral_second_derivative', 'stddev_of_diff', 'is_user_annotated_epoch', 'is_valid_epoch', 'session_name', 'delta_aligned_start_t', 'pre_post_delta_category', 'maze_id']]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>label</th>\n",
       "      <th>duration</th>\n",
       "      <th>flat_replay_idx</th>\n",
       "      <th>n_unique_aclus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93.027055</td>\n",
       "      <td>93.465245</td>\n",
       "      <td>4</td>\n",
       "      <td>0.438190</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105.400143</td>\n",
       "      <td>105.562560</td>\n",
       "      <td>8</td>\n",
       "      <td>0.162417</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113.213433</td>\n",
       "      <td>113.613960</td>\n",
       "      <td>9</td>\n",
       "      <td>0.400527</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120.645089</td>\n",
       "      <td>120.861972</td>\n",
       "      <td>11</td>\n",
       "      <td>0.216883</td>\n",
       "      <td>11</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125.060134</td>\n",
       "      <td>125.209802</td>\n",
       "      <td>14</td>\n",
       "      <td>0.149668</td>\n",
       "      <td>14</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>132.511389</td>\n",
       "      <td>132.791003</td>\n",
       "      <td>17</td>\n",
       "      <td>0.279613</td>\n",
       "      <td>17</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1705.053099</td>\n",
       "      <td>1705.140866</td>\n",
       "      <td>405</td>\n",
       "      <td>0.087767</td>\n",
       "      <td>405</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1707.712068</td>\n",
       "      <td>1707.918998</td>\n",
       "      <td>406</td>\n",
       "      <td>0.206930</td>\n",
       "      <td>406</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1714.307771</td>\n",
       "      <td>1714.651681</td>\n",
       "      <td>409</td>\n",
       "      <td>0.343910</td>\n",
       "      <td>409</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1725.278891</td>\n",
       "      <td>1725.595092</td>\n",
       "      <td>414</td>\n",
       "      <td>0.316201</td>\n",
       "      <td>414</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>1729.689083</td>\n",
       "      <td>1730.227666</td>\n",
       "      <td>417</td>\n",
       "      <td>0.538583</td>\n",
       "      <td>417</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>1731.111480</td>\n",
       "      <td>1731.287905</td>\n",
       "      <td>418</td>\n",
       "      <td>0.176425</td>\n",
       "      <td>418</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           start         stop  label  duration flat_replay_idx  n_unique_aclus\n",
       "0      93.027055    93.465245      4  0.438190               4              31\n",
       "1     105.400143   105.562560      8  0.162417               8              26\n",
       "2     113.213433   113.613960      9  0.400527               9              18\n",
       "3     120.645089   120.861972     11  0.216883              11              26\n",
       "4     125.060134   125.209802     14  0.149668              14              25\n",
       "5     132.511389   132.791003     17  0.279613              17              33\n",
       "..           ...          ...    ...       ...             ...             ...\n",
       "158  1705.053099  1705.140866    405  0.087767             405              18\n",
       "159  1707.712068  1707.918998    406  0.206930             406              22\n",
       "160  1714.307771  1714.651681    409  0.343910             409              22\n",
       "161  1725.278891  1725.595092    414  0.316201             414              29\n",
       "162  1729.689083  1730.227666    417  0.538583             417              34\n",
       "163  1731.111480  1731.287905    418  0.176425             418              21\n",
       "\n",
       "[164 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "# from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import HeuristicReplayScoring\n",
    "from neuropy.core.epoch import find_data_indicies_from_epoch_times\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_filter_replay_epochs\n",
    "\n",
    "# filtered_epochs_df, filtered_decoder_filter_epochs_decoder_result_dict, filtered_ripple_all_epoch_bins_marginals_df = None, None, None\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-_perform_filter_replay_epochs.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "filtered_epochs_df, filtered_decoder_filter_epochs_decoder_result_dict, filtered_ripple_all_epoch_bins_marginals_df = _perform_filter_replay_epochs(curr_active_pipeline, global_epoch_name, track_templates, decoder_ripple_filter_epochs_decoder_result_dict, ripple_all_epoch_bins_marginals_df, ripple_decoding_time_bin_size=ripple_decoding_time_bin_size,\n",
    "                                                                                                                            should_only_include_user_selected_epochs=False)\n",
    "\n",
    "filtered_epochs_df\n",
    "# filtered_ripple_all_epoch_bins_marginals_df\n",
    "\n",
    "## 1m 38s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92aad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_sess: DataSession = curr_active_pipeline.sess\n",
    "global_session.compute_pbe_epochs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca48dd6",
   "metadata": {},
   "source": [
    "### <a id='toc5_1_1_'></a>[2024-06-25 - Advanced Time-dependent decoding:](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c76fbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Directional Versions: 'long_LR':\n",
    "from neuropy.core.epoch import subdivide_epochs, ensure_dataframe\n",
    "\n",
    "\n",
    "## INPUTS: long_LR_epochs_obj, long_LR_results\n",
    "\n",
    "a_pf1D_dt: PfND_TimeDependent = deepcopy(long_LR_results.pf1D_dt)\n",
    "a_pf2D_dt: PfND_TimeDependent = deepcopy(long_LR_results.pf2D_dt)\n",
    "\n",
    "# Example usage\n",
    "df: pd.DataFrame = ensure_dataframe(deepcopy(long_LR_epochs_obj)) \n",
    "df['epoch_type'] = 'lap'\n",
    "df['interval_type_id'] = 666\n",
    "\n",
    "# subdivide_bin_size = 0.200  # Specify the size of each sub-epoch in seconds\n",
    "subdivide_bin_size = 0.050\n",
    "subdiv_df: pd.DataFrame = subdivide_epochs(df, subdivide_bin_size)\n",
    "# print(subdivided_df)\n",
    "\n",
    "## Evolve the ratemaps:\n",
    "_a_pf1D_dt_snapshots = a_pf1D_dt.batch_snapshotting(subdiv_df, reset_at_start=True)\n",
    "_a_pf2D_dt_snapshots = a_pf2D_dt.batch_snapshotting(subdiv_df, reset_at_start=True)\n",
    "# a_pf2D_dt.plot_ratemaps_2D()\n",
    "\n",
    "## takes about 2 mins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788d8b7e",
   "metadata": {},
   "source": [
    "# <a id='toc6_'></a>[/ üõë End Run Section üõë](#toc0_)\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7433b81f",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "## Find the time series of Long-likely events\n",
    "# type(long_RL_results) # DynamicParameters\n",
    "long_LR_pf1D_Decoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d2363d",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "type(all_directional_decoder_dict_value)\n",
    "list(all_directional_decoder_dict_value.keys()) # ['long_LR', 'long_RL', 'short_LR', 'short_RL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634e6027",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "laps_all_epoch_bins_marginals_df\n",
    "laps_most_likely_direction_from_decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdabd71",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "type(ripple_result_tuple) # pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations.DirectionalRankOrderResult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fca534c",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "assert isinstance(ripple_result_tuple, DirectionalRankOrderResult) \n",
    "\n",
    "ripple_result_tuple.plot_histograms(num='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15629dae",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import DirectionalRankOrderResult\n",
    "from pyphocorehelpers.DataStructure.RenderPlots.MatplotLibRenderPlots import MatplotlibRenderPlots \n",
    "\n",
    "# @register_type_display(DirectionalRankOrderResult)\n",
    "def plot_histograms(self: DirectionalRankOrderResult, **kwargs) -> \"MatplotlibRenderPlots\":\n",
    "    \"\"\" \n",
    "    num='RipplesRankOrderZscore'\n",
    "    \"\"\"\n",
    "    print(f'.plot_histograms(..., kwargs: {kwargs})')\n",
    "    fig = plt.figure(layout=\"constrained\", **kwargs)\n",
    "    ax_dict = fig.subplot_mosaic(\n",
    "        [\n",
    "            [\"long_short_best_z_score_diff\", \"long_short_best_z_score_diff\"],\n",
    "            [\"long_best_z_scores\", \"short_best_z_scores\"],\n",
    "        ],\n",
    "    )\n",
    "    plots = (pd.DataFrame({'long_best_z_scores': self.long_best_dir_z_score_values}).hist(ax=ax_dict['long_best_z_scores'], bins=21, alpha=0.8),\n",
    "        pd.DataFrame({'short_best_z_scores': self.short_best_dir_z_score_values}).hist(ax=ax_dict['short_best_z_scores'], bins=21, alpha=0.8),\n",
    "        pd.DataFrame({'long_short_best_z_score_diff': self.long_short_best_dir_z_score_diff_values}).hist(ax=ax_dict['long_short_best_z_score_diff'], bins=21, alpha=0.8),\n",
    "    )\n",
    "    return MatplotlibRenderPlots(name='plot_histogram_figure', figures=[fig], axes=ax_dict)\n",
    "\n",
    "\n",
    "# register_type_display(plot_histograms, DirectionalRankOrderResult)\n",
    "## Call the newly added `plot_histograms` function on the `ripple_result_tuple` object which is of type `DirectionalRankOrderResult`:\n",
    "assert isinstance(ripple_result_tuple, DirectionalRankOrderResult) \n",
    "ripple_result_tuple.plot_histograms(num='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c291690",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "ripple_result_tuple.plot_histograms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b30bcb",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# üíæ CSVs \n",
    "print(f'\\t try saving to CSV...')\n",
    "merged_complete_epoch_stats_df = rank_order_results.ripple_merged_complete_epoch_stats_df ## New method\n",
    "merged_complete_epoch_stats_df\n",
    "merged_complete_ripple_epoch_stats_df_output_path = curr_active_pipeline.get_output_path().joinpath(f'{DAY_DATE_TO_USE}_merged_complete_epoch_stats_df.csv').resolve()\n",
    "merged_complete_epoch_stats_df.to_csv(merged_complete_ripple_epoch_stats_df_output_path)\n",
    "print(f'\\t saving to CSV: {merged_complete_ripple_epoch_stats_df_output_path} done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60749347",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "all",
     "active-2025-01-20"
    ]
   },
   "outputs": [],
   "source": [
    "print(f'\\tdone. building global result.')\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "selected_spikes_df = deepcopy(curr_active_pipeline.global_computation_results.computed_data['RankOrder'].LR_ripple.selected_spikes_df)\n",
    "# active_epochs = global_computation_results.computed_data['RankOrder'].ripple_most_likely_result_tuple.active_epochs\n",
    "active_epochs = deepcopy(curr_active_pipeline.global_computation_results.computed_data['RankOrder'].LR_ripple.epochs_df)\n",
    "track_templates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz)\n",
    "\n",
    "ripple_combined_epoch_stats_df, ripple_new_output_tuple = RankOrderAnalyses.pandas_df_based_correlation_computations(selected_spikes_df=selected_spikes_df, active_epochs_df=active_epochs, track_templates=track_templates, num_shuffles=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2789bab9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313886d9",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# new_output_tuple (output_active_epoch_computed_values, valid_stacked_arrays, real_stacked_arrays, n_valid_shuffles) = ripple_new_output_tuple\n",
    "curr_active_pipeline.global_computation_results.computed_data['RankOrder'].ripple_combined_epoch_stats_df, curr_active_pipeline.global_computation_results.computed_data['RankOrder'].ripple_new_output_tuple = ripple_combined_epoch_stats_df, ripple_new_output_tuple\n",
    "print(f'done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6f086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Display the `TrainTestSplitResult` in a `PhoPaginatedMultiDecoderDecodedEpochsWindow`\n",
    "from neuropy.core.epoch import Epoch, ensure_dataframe\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import add_laps_groundtruth_information_to_dataframe\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import PhoPaginatedMultiDecoderDecodedEpochsWindow\n",
    "\n",
    "## INPUTS: train_decoded_results_dict\n",
    "# decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs # looks like 'lap_dir' column is wrong\n",
    "\n",
    "# active_results: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(decoder_laps_filter_epochs_decoder_result_dict)\n",
    "active_results: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy({k:v.decoder_result for k, v in _out_separate_decoder_results[0].items()})\n",
    "\n",
    "laps_app, laps_paginated_multi_decoder_decoded_epochs_window, laps_pagination_controller_dict = PhoPaginatedMultiDecoderDecodedEpochsWindow.init_from_track_templates(curr_active_pipeline, track_templates,\n",
    "                            decoder_decoded_epochs_result_dict=active_results, epochs_name='laps', included_epoch_indicies=None, \n",
    "    params_kwargs={'enable_per_epoch_action_buttons': False,\n",
    "    'skip_plotting_most_likely_positions': False, 'skip_plotting_measured_positions': False, \n",
    "    # 'enable_decoded_most_likely_position_curve': False, 'enable_radon_transform_info': True, 'enable_weighted_correlation_info': False,\n",
    "    'enable_decoded_most_likely_position_curve': True, 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': False,\n",
    "    # 'disable_y_label': True,\n",
    "    # 'isPaginatorControlWidgetBackedMode': True,\n",
    "    # 'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True,\n",
    "    # 'debug_print': True,\n",
    "    'max_subplots_per_page': 10,\n",
    "    'scrollable_figure': True,\n",
    "    # 'posterior_heatmap_imshow_kwargs': dict(vmin=0.0075),\n",
    "    'use_AnchoredCustomText': False,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3d15bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_build_individual_time_bin_decoded_posteriors_df\n",
    "\n",
    "transfer_column_names_list: List[str] = ['maze_id', 'lap_dir', 'lap_id']\n",
    "filtered_laps_time_bin_marginals_df = _perform_build_individual_time_bin_decoded_posteriors_df(curr_active_pipeline, track_templates=track_templates, all_directional_laps_filter_epochs_decoder_result=all_directional_laps_filter_epochs_decoder_result, transfer_column_names_list=transfer_column_names_list)\n",
    "filtered_laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e0053b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import co_filter_epochs_and_spikes\n",
    "\n",
    "## INPUTS: all_directional_laps_filter_epochs_decoder_result\n",
    "transfer_column_names_list: List[str] = ['maze_id', 'lap_dir', 'lap_id']\n",
    "TIME_OVERLAP_PREVENTION_EPSILON: float = 1e-12\n",
    "(laps_directional_marginals_tuple, laps_track_identity_marginals_tuple, laps_non_marginalized_decoder_marginals_tuple), laps_marginals_df = all_directional_laps_filter_epochs_decoder_result.compute_marginals(epoch_idx_col_name='lap_idx', epoch_start_t_col_name='lap_start_t',\n",
    "                                                                                                                                                    additional_transfer_column_names=['start','stop','label','duration','lap_id','lap_dir','maze_id','is_LR_dir'])\n",
    "laps_directional_marginals, laps_directional_all_epoch_bins_marginal, laps_most_likely_direction_from_decoder, laps_is_most_likely_direction_LR_dir  = laps_directional_marginals_tuple\n",
    "laps_track_identity_marginals, laps_track_identity_all_epoch_bins_marginal, laps_most_likely_track_identity_from_decoder, laps_is_most_likely_track_identity_Long = laps_track_identity_marginals_tuple\n",
    "non_marginalized_decoder_marginals, non_marginalized_decoder_all_epoch_bins_marginal, most_likely_decoder_idxs, non_marginalized_decoder_all_epoch_bins_decoder_probs_df = laps_non_marginalized_decoder_marginals_tuple\n",
    "laps_time_bin_marginals_df: pd.DataFrame = all_directional_laps_filter_epochs_decoder_result.build_per_time_bin_marginals_df(active_marginals_tuple=(laps_directional_marginals, laps_track_identity_marginals, non_marginalized_decoder_marginals),\n",
    "                                                                                                                              columns_tuple=(['P_LR', 'P_RL'], ['P_Long', 'P_Short'], ['long_LR', 'long_RL', 'short_LR', 'short_RL']), transfer_column_names_list=transfer_column_names_list)\n",
    "laps_time_bin_marginals_df['start'] = laps_time_bin_marginals_df['start'] + TIME_OVERLAP_PREVENTION_EPSILON ## ENSURE NON-OVERLAPPING\n",
    "\n",
    "## INPUTS: laps_time_bin_marginals_df\n",
    "# active_min_num_unique_aclu_inclusions_requirement: int = track_templates.min_num_unique_aclu_inclusions_requirement(curr_active_pipeline, required_min_percentage_of_active_cells=0.33333333333333)\n",
    "active_min_num_unique_aclu_inclusions_requirement = None # must be none for individual `time_bin` periods\n",
    "filtered_laps_time_bin_marginals_df, active_spikes_df = co_filter_epochs_and_spikes(active_spikes_df=get_proper_global_spikes_df(curr_active_pipeline, minimum_inclusion_fr_Hz=curr_active_pipeline.global_computation_config.rank_order_shuffle_analysis.minimum_inclusion_fr_Hz),\n",
    "                                                                  active_epochs_df=laps_time_bin_marginals_df, included_aclus=track_templates.any_decoder_neuron_IDs, min_num_unique_aclu_inclusions=active_min_num_unique_aclu_inclusions_requirement,\n",
    "                                                                epoch_id_key_name='lap_individual_time_bin_id', no_interval_fill_value=-1, add_unique_aclus_list_column=True, drop_non_epoch_spikes=True)\n",
    "filtered_laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff8fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean and max number of active aclus per time bin for each epoch (lap)\n",
    "filtered_laps_time_bin_marginals_df.groupby(['lap_id']).agg(n_unique_aclus_mean=('n_unique_aclus', 'mean'), n_unique_aclus_max=('n_unique_aclus', 'max')).reset_index()\n",
    "filtered_laps_time_bin_marginals_df.groupby(['maze_id']).agg(n_unique_aclus_mean=('n_unique_aclus', 'mean'), n_unique_aclus_max=('n_unique_aclus', 'max')).reset_index() ## per maze\n",
    "filtered_laps_time_bin_marginals_df.groupby(['maze_id', 'lap_dir']).agg(n_unique_aclus_mean=('n_unique_aclus', 'mean'), n_unique_aclus_max=('n_unique_aclus', 'max')).reset_index() # per maze x lap_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e6cdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cb39d3",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# {frozenset({('desired_shared_decoding_time_bin_size', 0.025), ('minimum_event_duration', 0.05), ('use_single_time_bin_per_epoch', False)}): 0.025,\n",
    "#  frozenset({('desired_shared_decoding_time_bin_size', 0.03), ('minimum_event_duration', 0.05), ('use_single_time_bin_per_epoch', False)}): 0.03,\n",
    "#  frozenset({('desired_shared_decoding_time_bin_size', 0.044), ('minimum_event_duration', 0.05), ('use_single_time_bin_per_epoch', False)}): 0.044,\n",
    "#  frozenset({('desired_shared_decoding_time_bin_size', 0.05), ('minimum_event_duration', 0.05), ('use_single_time_bin_per_epoch', False)}): 0.05}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d4ce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_trial_by_trial_result.directional_active_lap_pf_results_dicts\n",
    "a_trial_by_trial_result.directional_lap_epochs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944c59a0",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "several_time_bin_sizes_ripple_df\n",
    "\n",
    "ripple_out_path # 'K:/scratch/collected_outputs/2024-07-05-kdiba_gor01_two_2006-6-07_16-40-19__withNewKamranExportedReplays-(ripple_marginals_df).csv'\n",
    "# 'K:/scratch/collected_outputs/2024-07-05-kdiba_gor01_two_2006-6-07_16-40-19__withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-(ripple_marginals_df).csv'\n",
    "several_time_bin_sizes_time_bin_ripple_df\n",
    "\n",
    "ripple_time_bin_marginals_out_path # 'K:/scratch/collected_outputs/2024-07-05-kdiba_gor01_two_2006-6-07_16-40-19__withNewKamranExportedReplays-(ripple_time_bin_marginals_df).csv'\n",
    "# 'K:/scratch/collected_outputs/2024-07-05-kdiba_gor01_two_2006-6-07_16-40-19__withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-(ripple_time_bin_marginals_df).csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2dfa3e",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "v: DecoderDecodedEpochsResult = list(output_directional_decoders_epochs_decode_results_dict.values())[0]\n",
    "v.add_all_extra_epoch_columns(curr_active_pipeline=curr_active_pipeline, track_templates=track_templates)\n",
    "# _out = v.export_csvs(parent_output_path=collected_outputs_path, active_context=curr_active_pipeline.get_session_context(), session_name=curr_active_pipeline.session_name, curr_session_t_delta=t_delta)\n",
    "\n",
    "# assert self.collected_outputs_path.exists()\n",
    "# curr_session_name: str = curr_active_pipeline.session_name # '2006-6-08_14-26-15'\n",
    "# CURR_BATCH_OUTPUT_PREFIX: str = f\"{self.BATCH_DATE_TO_USE}-{curr_session_name}\"\n",
    "# print(f'CURR_BATCH_OUTPUT_PREFIX: {CURR_BATCH_OUTPUT_PREFIX}')\n",
    "\n",
    "# from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_extended_computations\n",
    "# curr_active_pipeline.reload_default_computation_functions()\n",
    "# batch_extended_computations(curr_active_pipeline, include_includelist=['merged_directional_placefields'], include_global_functions=True, fail_on_exception=True, force_recompute=False)\n",
    "# directional_merged_decoders_result = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "\n",
    "# active_context = curr_active_pipeline.get_session_context()\n",
    "# _out = directional_merged_decoders_result.compute_and_export_marginals_df_csvs(parent_output_path=self.collected_outputs_path, active_context=active_context)\n",
    "# print(f'successfully exported marginals_df_csvs to {self.collected_outputs_path}!')\n",
    "# (laps_marginals_df, laps_out_path), (ripple_marginals_df, ripple_out_path) = _out\n",
    "# (laps_marginals_df, laps_out_path, laps_time_bin_marginals_df, laps_time_bin_marginals_out_path), (ripple_marginals_df, ripple_out_path, ripple_time_bin_marginals_df, ripple_time_bin_marginals_out_path) = _out\n",
    "# print(f'\\tlaps_out_path: {laps_out_path}\\n\\tripple_out_path: {ripple_out_path}\\n\\tdone.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58b6311",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa94d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "_across_session_results_extended_dict['perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260a8b74",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "## Take extra computations from `_decode_and_evaluate_epochs_using_directional_decoders` and integrate into the multi-time-bin results from `perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _compute_all_df_score_metrics\n",
    "\n",
    "should_skip_radon_transform = True\n",
    "## Recompute the epoch scores/metrics such as radon transform and wcorr:\n",
    "\n",
    "a_sweep_tuple, a_pseudo_2D_result = list(output_full_directional_merged_decoders_result.items())[0]\n",
    "a_decoder_laps_filter_epochs_decoder_result_dict = deepcopy(a_pseudo_2D_result.all_directional_laps_filter_epochs_decoder_result)\n",
    "a_decoder_ripple_filter_epochs_decoder_result_dict = deepcopy(a_pseudo_2D_result.all_directional_ripple_filter_epochs_decoder_result)\n",
    "\n",
    "(decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict), merged_df_outputs_tuple, raw_dict_outputs_tuple = _compute_all_df_score_metrics(directional_merged_decoders_result, track_templates,\n",
    "                                                                                                                                                                                    decoder_laps_filter_epochs_decoder_result_dict=a_decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict=a_decoder_ripple_filter_epochs_decoder_result_dict,\n",
    "                                                                                                                                                                                    spikes_df=deepcopy(curr_active_pipeline.sess.spikes_df),\n",
    "                                                                                                                                                                                    should_skip_radon_transform=should_skip_radon_transform)\n",
    "laps_radon_transform_merged_df, ripple_radon_transform_merged_df, laps_weighted_corr_merged_df, ripple_weighted_corr_merged_df, laps_simple_pf_pearson_merged_df, ripple_simple_pf_pearson_merged_df = merged_df_outputs_tuple\n",
    "decoder_laps_radon_transform_df_dict, decoder_ripple_radon_transform_df_dict, decoder_laps_radon_transform_extras_dict, decoder_ripple_radon_transform_extras_dict, decoder_laps_weighted_corr_df_dict, decoder_ripple_weighted_corr_df_dict = raw_dict_outputs_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfda868",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# `_perform_compute_custom_epoch_decoding`\n",
    "\n",
    "a_sweep_tuple\n",
    "# a_pseudo_2D_result.all_directional_laps_filter_epochs_decoder_result\n",
    "# a_pseudo_2D_result\n",
    "# a_pseudo_2D_result.short_directional_decoder_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9603a0",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# print_keys_if_possible('several_time_bin_sizes_laps_df', several_time_bin_sizes_laps_df)\n",
    "print_keys_if_possible('output_full_directional_merged_decoders_result', output_full_directional_merged_decoders_result, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a71abd",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# get_file_pat\n",
    "collected_outputs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c0f606",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "output_laps_decoding_accuracy_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dd6f87",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# from neuropy.utils.matplotlib_helpers import pho_jointplot\n",
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import pho_jointplot, plot_histograms\n",
    "sns.set_theme(style=\"ticks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4b238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# from neuropy.utils.matplotlib_helpers import pho_jointplot\n",
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import pho_jointplot, plot_histograms\n",
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "# def pho_jointplot(*args, **kwargs):\n",
    "# \t\"\"\" wraps sns.jointplot to allow adding titles/axis labels/etc.\"\"\"\n",
    "# \ttitle = kwargs.pop('title', None)\n",
    "# \t_out = sns.jointplot(*args, **kwargs)\n",
    "# \tif title is not None:\n",
    "# \t\tplt.suptitle(title)\n",
    "# \treturn _out\n",
    "\n",
    "common_kwargs = dict(ylim=(0,1), hue='time_bin_size') # , marginal_kws=dict(bins=25, fill=True)\n",
    "# sns.jointplot(data=a_laps_all_epoch_bins_marginals_df, x='lap_start_t', y='P_Long', kind=\"scatter\", color=\"#4CB391\")\n",
    "pho_jointplot(data=several_time_bin_sizes_laps_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Laps: per epoch') #color=\"#4CB391\")\n",
    "pho_jointplot(data=several_time_bin_sizes_ripple_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Ripple: per epoch')\n",
    "pho_jointplot(data=several_time_bin_sizes_time_bin_ripple_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Ripple: per time bin')\n",
    "pho_jointplot(data=several_time_bin_sizes_time_bin_laps_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Laps: per time bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43311ee",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import plot_histograms\n",
    "\n",
    "# You can use it like this:\n",
    "plot_histograms('Laps', 'One Session', several_time_bin_sizes_time_bin_laps_df, \"several\")\n",
    "plot_histograms('Ripples', 'One Session', several_time_bin_sizes_time_bin_ripple_df, \"several\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a33b924",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "several_time_bin_sizes_ripple_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2a9d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.displot(\n",
    "#     several_time_bin_sizes_laps_df, x=\"P_Long\", col=\"species\", row=\"time_bin_size\",\n",
    "#     binwidth=3, height=3, facet_kws=dict(margin_titles=True),\n",
    "# )\n",
    "\n",
    "sns.displot(\n",
    "    several_time_bin_sizes_laps_df, x='delta_aligned_start_t', y='P_Long', row=\"time_bin_size\",\n",
    "    binwidth=3, height=3, facet_kws=dict(margin_titles=True),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495ef2bb",
   "metadata": {},
   "source": [
    "# <a id='toc7_'></a>[üé® 2024-02-06 - Other Plotting](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5623a2",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": [
     "all",
     "run-group-display",
     "run-spike_raster_window_test"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.TimeSynchronizedPlacefieldsPlotter import TimeSynchronizedPlacefieldsPlotter\n",
    "\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "\n",
    "#  Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "curr_active_pipeline.prepare_for_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83293544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots\n",
    "\n",
    "_out = batch_perform_all_plots(curr_active_pipeline, debug_print=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86d59de",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968df7ce",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Display import DisplayFunctionItem\n",
    "from pyphocorehelpers.gui.Qt.tree_helpers import find_tree_item_by_text\n",
    "from pyphoplacecellanalysis.GUI.Qt.MainApplicationWindows.LauncherWidget.LauncherWidget import LauncherWidget\n",
    "\n",
    "widget = LauncherWidget()\n",
    "# widget.debug_print = True\n",
    "treeWidget = widget.mainTreeWidget # QTreeWidget\n",
    "widget.build_for_pipeline(curr_active_pipeline=curr_active_pipeline)\n",
    "widget.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b653dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = dict()\n",
    "_out['_display_directional_laps_overview'] = curr_active_pipeline.display(display_function='_display_directional_laps_overview', active_session_configuration_context=None) # _display_directional_laps_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce79ac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import perform_add_1D_track_bounds_lines\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out = dict()\n",
    "_out['_display_grid_bin_bounds_validation_y'] = curr_active_pipeline.display(display_function='_display_grid_bin_bounds_validation', active_session_configuration_context=None, is_x_axis=False) # _display_grid_bin_bounds_validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465a1575",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out['_display_grid_bin_bounds_validation_x'] = curr_active_pipeline.display(display_function='_display_grid_bin_bounds_validation', active_session_configuration_context=None, is_x_axis=True) # _display_grid_bin_bounds_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6595b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps).trimmed_to_non_overlapping() \n",
    "global_laps_epochs_df = global_laps.to_dataframe()\n",
    "_out_ripple_rasters: RankOrderRastersDebugger = RankOrderRastersDebugger.init_rank_order_debugger(global_spikes_df, deepcopy(global_laps_epochs_df),\n",
    "                                                                                                track_templates, None,\n",
    "                                                                                                None, None,\n",
    "                                                                                                dock_add_locations = dict(zip(('long_LR', 'long_RL', 'short_LR', 'short_RL'), (['right'], ['right'], ['right'], ['right']))),\n",
    "                                                                                                )\n",
    "_out_ripple_rasters.set_top_info_bar_visibility(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed34de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.Extensions.pyqtgraph_helpers import LayoutScrollability, pyqtplot_build_image_bounds_extent\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.TemplateDebugger import BaseTemplateDebuggingMixin, build_pf1D_heatmap_with_labels_and_peaks, TrackTemplates\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.BinByBinDecodingDebugger import BinByBinDecodingDebugger \n",
    "\n",
    "# Example usage:\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps).trimmed_to_non_overlapping() \n",
    "global_laps_epochs_df = global_laps.to_dataframe()\n",
    "global_laps_epochs_df\n",
    "\n",
    "## INPUTS: \n",
    "time_bin_size: float = 0.250\n",
    "a_lap_id: int = 9\n",
    "a_decoder_name = 'long_LR'\n",
    "epoch_id_col_name = 'lap_id'\n",
    "## COMPUTED: \n",
    "a_decoder_idx: int = track_templates.get_decoder_names().index(a_decoder_name)\n",
    "a_decoder = deepcopy(track_templates.long_LR_decoder)\n",
    "(_out_decoded_time_bin_edges, _out_decoded_unit_specific_time_binned_spike_counts, _out_decoded_active_unit_lists, _out_decoded_active_p_x_given_n, _out_decoded_active_plots_data) = BinByBinDecodingDebugger.build_spike_counts_and_decoder_outputs(a_decoder=a_decoder, epochs_df=global_laps_epochs_df, spikes_df=global_spikes_df, epoch_id_col_name=epoch_id_col_name, time_bin_size=time_bin_size)\n",
    "win, out_pf1D_decoder_template_objects, (_out_decoded_active_plots, _out_decoded_active_plots_data) = BinByBinDecodingDebugger.build_time_binned_decoder_debug_plots(a_decoder=a_decoder, an_epoch_id=a_lap_id, _out_decoded_time_bin_edges=_out_decoded_time_bin_edges, _out_decoded_active_p_x_given_n=_out_decoded_active_p_x_given_n,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  _out_decoded_active_unit_lists=_out_decoded_active_unit_lists, _out_decoded_active_plots_data=_out_decoded_active_plots_data, debug_print=True)\n",
    "\n",
    "## All-in-one mode:\n",
    "# win, out_pf1D_decoder_template_objects, (_out_decoded_active_plots, _out_decoded_active_plots_data) = BinByBinDecodingDebugger.plot_bin_by_bin_decoding_example(curr_active_pipeline=curr_active_pipeline, track_templates=track_templates, time_bin_size=time_bin_size, a_lap_id=a_lap_id, a_decoder_name=a_decoder_name)\n",
    "\n",
    "print(f\"Returned window: {win}\")\n",
    "print(f\"Returned decoder objects: {out_pf1D_decoder_template_objects}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5b12f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "win.setWindowTitle('BinByBinDecodingDebugger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345ec76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_cm_x_grid_bin_bounds\n",
    "\n",
    "global_session.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e03666",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pf1D_decoder_template_objects[0].plots_data.spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe2e4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lap_specific_spikes_df = _out_decoded_active_plots_data[a_lap_id].spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb7178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_plot = plots['root_plot']\n",
    "# Create a vertical line at x=3\n",
    "v_line = CustomInfiniteLine(pos=0.0, angle=90, pen=pg.mkPen('r', width=2), label='first lap spike')\n",
    "root_plot.addItem(v_line)\n",
    "plots['v_line'] = v_line\n",
    "\n",
    "## Set Labels\n",
    "# plots['root_plot'].set_xlabel('First PBE spike relative to first lap spike (t=0)')\n",
    "# plots['root_plot'].set_ylabel('Cell')\n",
    "plots['root_plot'].setTitle(\"First PBE spike relative to first lap spike (t=0)\", color='white', size='24pt')\n",
    "# plots['root_plot'].setLabel('top', 'First PBE spike relative to first lap spike (t=0)', size='22pt') # , color='blue'\n",
    "plots['root_plot'].setLabel('left', 'Cell ID', color='white', size='12pt') # , units='V', color='red'\n",
    "plots['root_plot'].setLabel('bottom', 'Time (relative to first lap spike for each cell)', color='white', units='s', size='12pt') # , color='blue'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f9d837",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_lap_id: int = 6\n",
    "# time_bin_edges = _out_decoded_unit_specific_time_binned_spike_counts[a_lap_id]\n",
    "time_bin_edges = _out_decoded_time_bin_edges[a_lap_id]\n",
    "n_epoch_time_bins: int = len(time_bin_edges) - 1\n",
    "print(f'a_lap_id: {a_lap_id}, n_epoch_time_bins: {n_epoch_time_bins}')\n",
    "\n",
    "## INPUTS: a_lap_id, an_img_extents, _out_decoded_unit_specific_time_binned_spike_counts, _out_decoded_active_unit_lists\n",
    "# Create a main GraphicsLayoutWidget\n",
    "win = pg.GraphicsLayoutWidget()\n",
    "\n",
    "# Store plot references\n",
    "plots = []\n",
    "out_pf1D_decoder_template_objects = []\n",
    "\n",
    "# Add a single plot that spans the entire width\n",
    "# spanning_plot = pg.PlotItem(title=\"Spanning Plot\")\n",
    "# win.addItem(spanning_plot, row=win.ci.rowCount() - 1, col=0, colspan=n_epoch_time_bins)\n",
    "spanning_posterior_plot = win.addPlot(title=\"P_x_given_n Plot\", row=0, rowspan=1, col=0, colspan=n_epoch_time_bins)  # Add the plot , col=0\n",
    "spanning_posterior_plot.setTitle(\"P_x_given_n Plot - Covers Entire Width\")\n",
    "\n",
    "most_likely_positions, p_x_given_n, most_likely_position_indicies, flat_outputs_container = _out_decoded_active_p_x_given_n[a_lap_id] ## UNPACK\n",
    "\n",
    "# _obj.pf1D_heatmap\n",
    "flat_p_x_given_n = deepcopy(p_x_given_n) #active_lap_decoded_pos_outputs['flat_p_x_given_n']\n",
    "# most_likely_position_flat_indicies = active_lap_decoded_pos_outputs['most_likely_position_flat_indicies']\n",
    "img_item = _simply_plot_posterior_in_pyqtgraph_plotitem(curr_plot=spanning_posterior_plot, image=flat_p_x_given_n, xbin_edges=np.arange(n_epoch_time_bins+1), ybin_edges=deepcopy(a_decoder.xbin))\n",
    "\n",
    "win.nextRow()  # Move to the next row\n",
    "\n",
    "\n",
    "## Get data\n",
    "active_bin_unit_specific_time_binned_spike_counts = _out_decoded_unit_specific_time_binned_spike_counts[a_lap_id]\n",
    "active_lap_active_aclu_spike_counts_list = _out_decoded_active_unit_lists[a_lap_id]\n",
    "active_lap_decoded_pos_outputs = _out_decoded_active_p_x_given_n[a_lap_id]\n",
    "# Add PlotItems to the layout horizontally\n",
    "# Add n_epoch_time_bins plots to the first row\n",
    "for a_time_bin_idx in np.arange(n_epoch_time_bins):\n",
    "    active_bin_active_aclu_spike_counts_dict = active_lap_active_aclu_spike_counts_list[a_time_bin_idx]\n",
    "    active_bin_active_aclu_spike_count_values = np.array(list(active_bin_active_aclu_spike_counts_dict.values()))\n",
    "    active_bin_active_aclu_bin_normalized_spike_count_values = active_bin_active_aclu_spike_count_values / np.sum(active_bin_active_aclu_spike_count_values) # relative number of spikes ... todo.. prioritizes high-firing\n",
    "    aclu_override_alpha_weights = 0.8 + (0.2 * active_bin_active_aclu_bin_normalized_spike_count_values) # ensure the items are at least 0.8 opaque, and allow them to scale between 0.8-1.0\n",
    "    \n",
    "    active_bin_aclus = np.array(list(active_bin_active_aclu_spike_counts_dict.keys()))\n",
    "    # active_aclu_override_alpha_weights_dict = dict(zip(active_bin_aclus, active_bin_active_aclu_bin_normalized_spike_count_values))\n",
    "    active_solo_override_num_spikes_weights = dict(zip(active_bin_aclus, active_bin_active_aclu_bin_normalized_spike_count_values))\n",
    "    active_aclu_override_alpha_weights_dict = dict(zip(active_bin_aclus, aclu_override_alpha_weights))\n",
    "    print(f'a_time_bin_idx: {a_time_bin_idx}/{n_epoch_time_bins} - active_bin_aclus: {active_bin_aclus}')\n",
    "    ## build the plot:\n",
    "    # plot = win.addPlot(title=f\"Plot {a_time_bin_idx+1}\")\n",
    "    plot = win.addPlot(title=f\"Plot {a_time_bin_idx+1}\", row=1, rowspan=1, col=a_time_bin_idx, colspan=1)\n",
    "    plot.getViewBox().setBorder(color=(200, 200, 200), width=1)  # Red border, 2px thick\n",
    "    # Enable the grid only along the x-axis\n",
    "    spanning_posterior_plot.showGrid(x=True, y=True)\n",
    "    # Set the x-axis tick spacing to 1 unit\n",
    "    x_axis = spanning_posterior_plot.getAxis('bottom')\n",
    "    x_axis.setTickSpacing(major=5, minor=1)  # Set major tick intervals to 1 unit\n",
    "\n",
    "    plots.append(plot)  # Store the reference\n",
    "    # curr_img, out_colors_heatmap_image_matrix = build_pf1D_heatmap_with_labels_and_peaks(pf1D_decoder=a_decoder, visible_aclus=active_bin_aclus, plot_item=plot, img_extents_rect=an_img_extents, a_decoder_aclu_to_color_map=a_decoder_aclu_to_color_map)\n",
    "    # _obj = BaseTemplateDebuggingMixin.init_from_decoder(a_decoder=a_decoder, win=win)\n",
    "    _obj = BaseTemplateDebuggingMixin.init_from_decoder(a_decoder=a_decoder, win=plot)\n",
    "    _obj.update_base_decoder_debugger_data(included_neuron_ids=active_bin_aclus, solo_override_alpha_weights=active_aclu_override_alpha_weights_dict, solo_override_num_spikes_weights=active_solo_override_num_spikes_weights)\n",
    "    out_pf1D_decoder_template_objects.append(_obj)  # Store the reference\n",
    "    \n",
    "    # active_bin_active_aclu_bin_normalized_spike_count_values\n",
    "    \n",
    "    # if a_time_bin_idx < (n_epoch_time_bins - 1):\n",
    "    #     win.nextColumn()  # Move to the next column for horizontal layout\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# Add a new row with a single plot spanning the entire width\n",
    "win.nextRow()  # Move to the next row\n",
    "# # Add a single plot that spans the entire width\n",
    "# # spanning_plot = pg.PlotItem(title=\"Spanning Plot\")\n",
    "# # win.addItem(spanning_plot, row=win.ci.rowCount() - 1, col=0, colspan=n_epoch_time_bins)\n",
    "# spanning_plot = win.addPlot(title=\"Spanning Plot\", colspan=n_epoch_time_bins)  # Add the plot , col=0\n",
    "# spanning_plot.setTitle(\"Spanning Plot - Covers Entire Width\")\n",
    "\n",
    "# most_likely_positions, p_x_given_n, most_likely_position_indicies, flat_outputs_container = _out_decoded_active_p_x_given_n[a_lap_id] ## UNPACK\n",
    "\n",
    "# # _obj.pf1D_heatmap\n",
    "# flat_p_x_given_n = deepcopy(p_x_given_n) #active_lap_decoded_pos_outputs['flat_p_x_given_n']\n",
    "# # most_likely_position_flat_indicies = active_lap_decoded_pos_outputs['most_likely_position_flat_indicies']\n",
    "# img_item = _simply_plot_posterior_in_pyqtgraph_plotitem(curr_plot=spanning_plot, image=flat_p_x_given_n, xbin_edges=np.arange(n_epoch_time_bins+1), ybin_edges=deepcopy(a_decoder.xbin))\n",
    "\n",
    "# Show the layout\n",
    "win.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb562f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable the grid only along the x-axis\n",
    "spanning_posterior_plot.showGrid(x=True, y=True)\n",
    "# Set the x-axis tick spacing to 1 unit\n",
    "x_axis = spanning_posterior_plot.getAxis('bottom')\n",
    "x_axis.setTickSpacing(major=5, minor=1)  # Set major tick intervals to 1 unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31b3422",
   "metadata": {},
   "outputs": [],
   "source": [
    "spanning_posterior_plot.showGrid(True, True, 0.7)\n",
    "# Adjust the view to ensure the image fills the entire plot width\n",
    "spanning_posterior_plot.setAspectLocked(False)  # Allow non-uniform scaling\n",
    "spanning_posterior_plot.getViewBox().setLimits(xMin=0, xMax=your_image_data.shape[1], yMin=0, yMax=your_image_data.shape[0])\n",
    "\n",
    "# Scale the image to fill the entire width\n",
    "spanning_posterior_plot.getViewBox().enableAutoRange()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25283bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch_time_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1529c71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = dict()\n",
    "_out['_display_directional_merged_pfs'] = curr_active_pipeline.display(display_function='_display_directional_merged_pfs', active_session_configuration_context=None) # _display_directional_merged_pfs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece249c2",
   "metadata": {},
   "source": [
    "n_epoch_time_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721d7f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "win.nextRow()\n",
    "lbl = win.addLabel(text='HUGE', colspan=n_epoch_time_bins) # , row=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a0506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the span to cover all columns in the row\n",
    "win.ci.layout.setRowStretchFactor(win.ci.rowCount() - 1, 1)  # Adjust the stretch factor for the new row\n",
    "win.ci.layout.setColumnStretchFactor(0, n_epoch_time_bins)   # Ensure it spans all columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f91cc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "spanning_plot2 = win.addPlot(title=\"Spanning Plot3\", row=1, rowspan=1, col=0, colspan=n_epoch_time_bins)  # Add the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7a808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spanning_plot2.setTitle(\"Spanning Plot - Covers Entire Width\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f611651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the span to cover all columns in the row\n",
    "win.ci.layout.setRowStretchFactor(win.ci.rowCount() - 1, 1)  # Adjust the stretch factor for the new row\n",
    "win.ci.layout.setColumnStretchFactor(0, n_epoch_time_bins)   # Ensure it spans all columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cae0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.decoder_difference import display_predicted_position_difference\n",
    "\n",
    "active_computed_data = curr_active_pipeline.computation_results[global_epoch_name]\n",
    "active_resampled_pos_df = active_computed_data.extended_stats.time_binned_position_df.copy() # active_computed_data.extended_stats.time_binned_position_df  # 1717 rows √ó 16 columns\n",
    "active_resampled_measured_positions = active_resampled_pos_df[['x','y']].to_numpy() # The measured positions resampled (interpolated) at the window centers. \n",
    "display_predicted_position_difference(active_one_step_decoder, active_two_step_decoder, active_resampled_measured_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd6298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(p_x_given_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1738f798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.TemplateDebugger import BaseTemplateDebuggingMixin, build_pf1D_heatmap_with_labels_and_peaks, TrackTemplates\n",
    "\n",
    "_obj = BaseTemplateDebuggingMixin.init_from_decoder(a_decoder=a_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe064948",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "curr_img, out_colors_heatmap_image_matrix = build_pf1D_heatmap_with_labels_and_peaks(pf1D_decoder=a_decoder, visible_aclus=active_bin_aclus, plot_item=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c18797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.TemplateDebugger import TemplateDebugger\n",
    "\n",
    "_out_TemplateDebugger: TemplateDebugger = TemplateDebugger.init_templates_debugger(track_templates) # , included_any_context_neuron_ids\n",
    "\n",
    "# _out_ui.root_dockAreaWindow\n",
    "# _out_ui.dock_widgets[a_decoder_name]\n",
    "\n",
    "## Plots:\n",
    "# _out_plots.pf1D_heatmaps[a_decoder_name] = visualize_heatmap_pyqtgraph(curr_curves, title=title_str, show_value_labels=False, show_xticks=False, show_yticks=False, show_colorbar=False, win=None, defer_show=True) # Sort to match first decoder (long_LR)\n",
    "# Adds aclu text labels with appropriate colors to y-axis: uses `sorted_shared_sort_neuron_IDs`:\n",
    "# curr_win, curr_img = _out_plots.pf1D_heatmaps[a_decoder_name] # win, img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eecf66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: \n",
    "a_decoder_aclu_to_color_map = deepcopy(_out_TemplateDebugger.plots_data['sort_helper_neuron_id_to_neuron_colors_dicts'][a_decoder_idx])\n",
    "a_decoder_aclu_to_color_map\n",
    "# _out_TemplateDebugger.plots_data['out_colors_heatmap_image_matrix_dicts'][a_decoder_idx]\n",
    "an_img_extents = deepcopy(_out_TemplateDebugger.plots_data['active_pfs_img_extents_dict'])[a_decoder_name] # [0.0, 0, 289.2117008543986, 35.0]\n",
    "an_img_extents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0aa9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out_TemplateDebugger.params\n",
    "# _out_TemplateDebugger.plots_data.data_keys\n",
    "\n",
    "a_decoder_name\n",
    "\n",
    "\n",
    "a_decoder_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd155ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd6e7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time_bin_size: float = 0.500 # 500ms\n",
    "t_start = 0.0\n",
    "t_end = 2093.8978568242164\n",
    "_decoded_pos_outputs, (unit_specific_time_binned_spike_counts, time_bin_edges, spikes_df) = easy_independent_decoding(long_LR_decoder, spikes_df=spikes_df, time_bin_size=time_bin_size, t_start=t_start, t_end=t_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9e1715",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_template_debugger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9851ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_t_bin_idx: int = 0\n",
    "# active_aclus_list = _out_decoded_active_unit_lists[a_row.lap_id][a_t_bin_idx]\n",
    "\n",
    "_out_TemplateDebugger.update_cell_emphasis(solo_emphasized_aclus=active_bin_aclus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4173061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_TemplateDebugger.pf1D_heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b761e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.indexing_helpers import compute_paginated_grid_config\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.pyqtplot_common import pyqtplot_common_setup\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.Extensions.pyqtgraph_helpers import LayoutScrollability, pyqtplot_build_image_bounds_extent, set_small_title\n",
    "from neuropy.utils.matplotlib_helpers import _scale_current_placefield_to_acceptable_range, _build_neuron_identity_label # for display_all_pf_2D_pyqtgraph_binned_image_rendering\n",
    "from pyphocorehelpers.gui.Qt.color_helpers import ColormapHelpers\n",
    "\n",
    "class HeatmapLayout(pg.QtWidgets.QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Create layout\n",
    "        layout = pg.QtWidgets.QVBoxLayout(self)\n",
    "        layout.setContentsMargins(0, 0, 0, 0)\n",
    "        layout.setSpacing(0)\n",
    "        \n",
    "        # Top row: variable number of heatmaps\n",
    "        self.top_row = pg.GraphicsLayoutWidget()\n",
    "        self.top_row.setContentsMargins(0, 0, 0, 0)\n",
    "        self.top_plots = []\n",
    "        layout.addWidget(self.top_row)\n",
    "\n",
    "        # Bottom row: single heatmap\n",
    "        self.bottom_row = pg.GraphicsLayoutWidget()\n",
    "        self.bottom_row.setContentsMargins(0, 0, 0, 0)\n",
    "        self.bottom_plot = self.bottom_row.addPlot()\n",
    "        self.bottom_plot.setContentsMargins(0, 0, 0, 0)\n",
    "        self.bottom_img = pg.ImageItem()\n",
    "        self.bottom_plot.addItem(self.bottom_img)\n",
    "        layout.addWidget(self.bottom_row)\n",
    "        \n",
    "        # Style plots\n",
    "        for p in [self.bottom_plot]:\n",
    "            p.showAxis('left', True)\n",
    "            p.showAxis('bottom', True)\n",
    "            p.getAxis('left').setLabel(\"Y-Axis\")\n",
    "            p.getAxis('bottom').setLabel(\"X-Axis\")\n",
    "            p.setContentsMargins(0, 0, 0, 0)\n",
    "            p.setDefaultPadding(0)\n",
    "            \n",
    "\n",
    "    def update_top_heatmaps(self, data_list):\n",
    "        self.top_row.clear()\n",
    "        self.top_plots = []\n",
    "        for data in data_list:\n",
    "            plot = self.top_row.addPlot()\n",
    "            plot.setContentsMargins(0, 0, 0, 0)\n",
    "            plot.setDefaultPadding(0)\n",
    "            img = pg.ImageItem(data)\n",
    "            plot.addItem(img)\n",
    "            plot.showAxis('left', True)\n",
    "            plot.getAxis('left').setLabel(\"Y-Axis\")\n",
    "            plot.hideAxis('bottom')\n",
    "            self.top_plots.append(plot)\n",
    "            self.top_row.nextRow()\n",
    "\n",
    "    def update_bottom_heatmap(self, data):\n",
    "        self.bottom_img.setImage(data)\n",
    "\n",
    "## Testing\n",
    "window = pg.QtWidgets.QMainWindow()\n",
    "widget = HeatmapLayout()\n",
    "\n",
    "# Example data\n",
    "top_data_list = [np.random.rand(10, 10), np.random.rand(15, 10)]\n",
    "bottom_data = np.random.rand(20, 20)\n",
    "\n",
    "widget.update_top_heatmaps(top_data_list)\n",
    "widget.update_bottom_heatmap(bottom_data)\n",
    "\n",
    "window.setCentralWidget(widget)\n",
    "window.resize(800, 600)\n",
    "window.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99251ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parent_root_widget = None\n",
    "root_render_widget = None\n",
    "# Need to go from (n_epochs, n_neurons, n_pos_bins) -> (n_neurons, n_xbins, n_ybins)\n",
    "n_epochs, n_neurons, n_pos_bins = np.shape(z_scored_tuning_map_matrix)\n",
    "images = z_scored_tuning_map_matrix.transpose(1, 2, 0) # (71, 57, 22)\n",
    "xbin_edges=active_one_step_decoder.xbin\n",
    "assert (len(xbin_edges)-1) == n_pos_bins, f\"n_pos_bins: {n_pos_bins}, len(xbin_edges): {len(xbin_edges)} \"\n",
    "# ybin_edges=active_one_step_decoder.ybin\n",
    "ybin_edges = np.arange(n_epochs+1) - 0.5 # correct ybin_edges are n_epochs\n",
    "root_render_widget, parent_root_widget, app = pyqtplot_common_setup(f'TrialByTrialActivityArray: {np.shape(images)}', app=app, parent_root_widget=parent_root_widget, root_render_widget=root_render_widget) ## üöß TODO: BUG: this makes a new QMainWindow to hold this item, which is inappropriate if it's to be rendered as a child of another control\n",
    "\n",
    "pg.setConfigOptions(imageAxisOrder='col-major') # this causes the placefields to be rendered horizontally, like they were in _temp_pyqtplot_plot_image_array\n",
    "\n",
    "\n",
    "\n",
    "## build pg.GraphicsLayoutWidget(...) required to hold the decoding preview\n",
    "root = pg.GraphicsLayoutWidget(title='Decoding Example')\n",
    "\n",
    "\n",
    "root.addItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b18f74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.SpecificComputationValidation import SpecificComputationValidator\n",
    "\n",
    "def _build_default_required_computation_keys_computation_validator_fn_factory():\n",
    "    def _subfn(curr_active_pipeline, computation_filter_name='maze'):\n",
    "        has_all_required_local_keys: bool = np.all(np.isin((a_fn_callable.input_requires or []),  list(curr_active_pipeline.computation_results[computation_filter_name].computed_data.keys())))\n",
    "        has_all_required_global_keys: bool = np.all(np.isin((a_fn_callable.requires_global_keys or []),  list(curr_active_pipeline.global_computation_results.computed_data.keys())))\n",
    "        has_all_required_keys: bool = (has_all_required_local_keys and has_all_required_global_keys)\n",
    "        return has_all_required_keys\n",
    "    return _subfn\n",
    "\n",
    "\n",
    "should_use_nice_display_names: bool = False\n",
    "display_function_items = widget.get_display_function_items()\n",
    "display_fn_validators_dict = {}\n",
    "\n",
    "for a_fcn_name, a_disp_fn_item in display_function_items.items():\n",
    "    # extract the info from the function:\n",
    "    # if hasattr(a_fcn, 'short_name') and a_fcn.short_name is not None:\n",
    "    #     active_name = a_fcn.short_name or a_fcn_name\n",
    "    # else:\n",
    "    #     active_name = a_fcn_name\n",
    "\n",
    "    # active_name: str = a_disp_fn_item.name\n",
    "    if should_use_nice_display_names:\n",
    "        active_name: str = a_disp_fn_item.best_display_name\n",
    "    else:\n",
    "        active_name: str = a_disp_fn_item.name # function name\n",
    "\n",
    "    a_fn_callable = a_disp_fn_item.fn_callable\n",
    "\n",
    "    if ((not hasattr(a_fn_callable, 'validate_computation_test')) or (a_fn_callable.validate_computation_test is None)):\n",
    "        a_fn_callable.validate_computation_test = _build_default_required_computation_keys_computation_validator_fn_factory()\n",
    "\n",
    "    display_fn_validators_dict[a_fcn_name] = SpecificComputationValidator.init_from_decorated_fn(a_fn_callable)\n",
    "    # a_disp_fn_item\n",
    "    # a_fn_handle = widget.curr_active_pipeline.plot.__getattr__(a_disp_fn_item.name)\n",
    "    # a_fn_handle\n",
    "\n",
    "    # a_validate_computation_test = lambda curr_active_pipeline, computation_filter_name='maze': (curr_active_pipeline.computation_results[computation_filter_name].computed_data['pf1D_Decoder'], curr_active_pipeline.computation_results[computation_filter_name].computed_data['pf2D_Decoder'])\n",
    "\n",
    "\n",
    "# display_function_items\n",
    "# a_fn_handle.\n",
    "display_fn_validators_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3bbc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "display_fn_validators_dict = {}\n",
    "\n",
    "\n",
    "{k:SpecificComputationValidator.init_from_decorated_fn(v) for k,v in self.registered_merged_computation_function_dict.items() if hasattr(v, 'validate_computation_test') and (v.validate_computation_test is not None)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1050885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3bcde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.global_computation_results.computed_data\n",
    "\n",
    "\n",
    "\n",
    "# a_fn_callable.requires_global_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5676d544",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_requires=[\"computation_result.computation_config.pf_params.time_bin_size\", \"computation_result.computed_data['pf1D']\", \"computation_result.computed_data['pf2D']\"], output_provides=[\"computation_result.computed_data['pf1D_Decoder']\", \"computation_result.computed_data['pf2D_Decoder']\"], uses=['BayesianPlacemapPositionDecoder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1a2a44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e930d3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.find_immediate_dependencies("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d2c89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.computation_results['maze_any'].computed_data\n",
    "\n",
    "_out = curr_active_pipeline.display('_display_plot_marginal_1D_most_likely_position_comparisons', active_session_configuration_context='maze_any', most_likely_positions_mode='standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0170fae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out = dict()\n",
    "# _out['_display_1d_placefield_occupancy'] = curr_active_pipeline.display('_display_1d_placefield_occupancy') # _display_1d_placefield_occupancy\n",
    "\n",
    "# _out = dict()\n",
    "# _out['_display_1d_placefield_occupancy'] = curr_active_pipeline.display(display_function='_display_1d_placefield_occupancy', active_session_configuration_context='kdiba_gor01_one_2006-6-09_1-22-43_maze_any_any') # _display_1d_placefield_occupancy\n",
    "\n",
    "_out = dict()\n",
    "_out['_display_1d_placefield_occupancy'] = curr_active_pipeline.display(display_function='_display_1d_placefield_occupancy', active_session_configuration_context=IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43',filter_name='maze1_any',lap_dir='any'), plot_pos_bin_axes=False) # _display_1d_placefield_occupancy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce055b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsWidgets.EpochsEditorItem import EpochsEditor # perform_plot_laps_diagnoser\n",
    "\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_epoch_context, short_epoch_context, global_epoch_context = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_epoch_name, short_epoch_name, global_epoch_name)]\n",
    "long_epoch_obj, short_epoch_obj = [Epoch(curr_active_pipeline.sess.epochs.to_dataframe().epochs.label_slice(an_epoch_name.removesuffix('_any'))) for an_epoch_name in [long_epoch_name, short_epoch_name]] #TODO 2023-11-10 20:41: - [ ] Issue with getting actual Epochs from sess.epochs for directional laps: emerges because long_epoch_name: 'maze1_any' and the actual epoch label in curr_active_pipeline.sess.epochs is 'maze1' without the '_any' part.\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "\n",
    "# sess = curr_active_pipeline.sess\n",
    "sess = global_session\n",
    "\n",
    "# pos_df = sess.compute_position_laps() # ensures the laps are computed if they need to be:\n",
    "position_obj = deepcopy(sess.position)\n",
    "position_obj.compute_higher_order_derivatives()\n",
    "pos_df = position_obj.compute_smoothed_position_info(N=20) ## Smooth the velocity curve to apply meaningful logic to it\n",
    "pos_df = position_obj.to_dataframe()\n",
    "# Drop rows with missing data in columns: 't', 'velocity_x_smooth' and 2 other columns. This occurs from smoothing\n",
    "pos_df = pos_df.dropna(subset=['t', 'x_smooth', 'velocity_x_smooth', 'acceleration_x_smooth']).reset_index(drop=True)\n",
    "curr_laps_df = sess.laps.to_dataframe()\n",
    "curr_laps_df\n",
    "epochs_editor = EpochsEditor.init_laps_diagnoser(pos_df, curr_laps_df, include_velocity=True, include_accel=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1b2f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show step-by-step how the decoder works\n",
    "\n",
    "## Show pseudo2D merged placefields:\n",
    "_out = dict()\n",
    "_out['_display_directional_merged_pfs'] = curr_active_pipeline.display(display_function='_display_directional_merged_pfs', active_session_configuration_context=None) # _display_directional_merged_pfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6c97ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.sess.neurons\n",
    "\n",
    "# co_filter_epochs_and_spikes("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed02317",
   "metadata": {},
   "source": [
    "### <a id='toc7_1_1_'></a>[2025-01-20 - Decoding step-by-step](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7d8dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import get_proper_global_spikes_df\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import easy_independent_decoding\n",
    "\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "all_directional_pf1D_Decoder: BasePositionDecoder = deepcopy(directional_merged_decoders_result.all_directional_pf1D_Decoder) # all-directions\n",
    "# directional_merged_decoders_result\n",
    "\n",
    "# a_1D_decoder: PfND = directional_merged_decoders_result.all_directional_decoder_dict['long_LR']\n",
    "\n",
    "long_LR_decoder: BasePositionDecoder = deepcopy(track_templates.long_LR_decoder)\n",
    "\n",
    "# ratemap: Ratemap = all_directional_pf1D_Decoder.ratemap\n",
    "\n",
    "## Pass in epochs to decode, for example, the laps\n",
    "laps = deepcopy(curr_active_pipeline.sess.laps)\n",
    "\n",
    "spikes_df: pd.DataFrame = deepcopy(curr_active_pipeline.sess.spikes_df)\n",
    "# spikes_df: pd.DataFrame = get_proper_global_spikes_df(curr_active_pipeline)\n",
    "# spikes_df = spikes_df.spikes.sliced_by_neuron_id(all_directional_pf1D_Decoder.neuron_IDs)\n",
    "# spikes_df\n",
    "\n",
    "## Given a list of discrete, equally-sized `time_bin_edges`, and a `spikes_df` pd.DataFrame of neuron spike times:\n",
    "\n",
    "## use the column 'aclu', which contains a distinct unit ID\n",
    "\n",
    "## count up the number of spikes occuring for each neuron (aclu-value) in each time bin, according to the column 't_rel_seconds' and collect the result in a numpy matrix `unit_specific_time_binned_spike_counts`\n",
    "\n",
    "\n",
    "# _ratemap\n",
    "# neuron_ids = deepcopy(spikes_df.spikes.neuron_ids) # array([ 5, 10, 14, 15, 24, 25, 26, 31, 32, 33, 41, 49, 50, 51, 55, 58, 64, 69, 70, 73, 74, 75, 76, 78, 82, 83, 85, 86, 90, 92, 93, 96])\n",
    "# array([  3,   4,   5,   7,   9,  10,  11,  14,  15,  16,  17,  21,  24,  25,  26,  31,  32,  33,  34,  35,  36,  37,  41,  45,  48,  49,  50,  51,  53,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  66,  67,  68,  69,  70,  71,  73,  74,  75,  76,  78,  82,  83,  84,  85,  86,  88,  89,  90,  92,  93,  96,  98, 100, 102, 107, 108])\n",
    "# neuron_ids\n",
    "# neuron_IDs = deepcopy(all_directional_pf1D_Decoder.neuron_IDs) # array([  2,   5,   8,  10,  14,  15,  23,  24,  25,  26,  31,  32,  33,  41,  49,  50,  51,  55,  58,  64,  69,  70,  73,  74,  75,  76,  78,  82,  83,  85,  86,  90,  92,  93,  96, 109])\n",
    "# neuron_IDs\n",
    "\n",
    "neuron_IDs = deepcopy(long_LR_decoder.neuron_IDs) # array([  2,   5,   8,  10,  14,  15,  23,  24,  25,  26,  31,  32,  33,  41,  49,  50,  51,  55,  58,  64,  69,  70,  73,  74,  75,  76,  78,  82,  83,  85,  86,  90,  92,  93,  96, 109])\n",
    "neuron_IDs\n",
    "\n",
    "# all_directional_pf1D_Decoder.slic\n",
    "spikes_df = spikes_df.spikes.sliced_by_neuron_id(neuron_IDs) ## filter everything down\n",
    "# all_directional_pf1D_Decoder.pf.spikes_df = deepcopy(spikes_df)\n",
    "## Need to update .pf._filtered_spikes_df now:\n",
    "\n",
    "# all_directional_pf1D_Decoder = all_directional_pf1D_Decoder.get_by_id(ids=neuron_IDs, defer_compute_all=True)\n",
    "# all_directional_pf1D_Decoder\n",
    "\n",
    "# ratemap = ratemap.get_by_id(ids=neuron_IDs)\n",
    "# all_directional_pf1D_Decoder._ratemap = ratemap\n",
    "# all_directional_pf1D_Decoder.compute()\n",
    "# ratemap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3b046d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.filtered_epochs\n",
    "time_bin_size: float = 0.025\n",
    "t_start = 0.0\n",
    "t_end = 2093.8978568242164\n",
    "time_bin_edges: NDArray = np.arange(t_start, t_end + time_bin_size, time_bin_size)\n",
    "# time_bin_edges\n",
    "unique_units = np.unique(spikes_df['aclu']) # sorted\n",
    "unit_specific_time_binned_spike_counts: NDArray = np.array([\n",
    "    np.histogram(spikes_df.loc[spikes_df['aclu'] == unit, 't_rel_seconds'], bins=time_bin_edges)[0]\n",
    "    for unit in unique_units\n",
    "])\n",
    "unit_specific_time_binned_spike_counts\n",
    " \n",
    "## OUTPUT: time_bin_edges, unit_specific_time_binned_spike_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a7916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## `easy_independent_decoding`\n",
    "_decoded_pos_outputs, (unit_specific_time_binned_spike_counts, time_bin_edges, spikes_df) = easy_independent_decoding(long_LR_decoder, spikes_df=spikes_df, time_bin_size=time_bin_size, t_start=t_start, t_end=t_end)\n",
    "most_likely_positions, p_x_given_n, most_likely_position_indicies, flat_outputs_container = _decoded_pos_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1b3216",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_x_given_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809362d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(most_likely_positions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2a6c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "_decoded_pos_outputs = long_LR_decoder.decode(unit_specific_time_binned_spike_counts=unit_specific_time_binned_spike_counts, time_bin_size=time_bin_size, output_flat_versions=True, debug_print=True)\n",
    "# _decoded_pos_outputs = all_directional_pf1D_Decoder.decode(unit_specific_time_binned_spike_counts=unit_specific_time_binned_spike_counts, time_bin_size=0.020, output_flat_versions=True, debug_print=True)\n",
    "_decoded_pos_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbae7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_directional_pf1D_Decoder.neuron_IDs # array([  2,   5,   8,  10,  14,  15,  23,  24,  25,  26,  31,  32,  33,  41,  49,  50,  51,  55,  58,  64,  69,  70,  73,  74,  75,  76,  78,  82,  83,  85,  86,  90,  92,  93,  96, 109])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ee5251",
   "metadata": {},
   "outputs": [],
   "source": [
    "_decoded_pos_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c71ddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.laps import Laps\n",
    "\n",
    "\n",
    "curr_laps_df = Laps._compute_lap_dir_from_smoothed_velocity(laps_df=curr_laps_df, global_session=global_session, replace_existing=True)\n",
    "curr_laps_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd23d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_editor.plots.lap_epoch_widgets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe294f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.get_session_context()\n",
    "\n",
    "# Context(format_name= 'kdiba', animal= 'gor01', exper_name= 'one', session_name= '2006-6-09_1-22-43')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56697b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_df = deepcopy(epochs_editor.get_user_labeled_epochs_df())\n",
    "laps_df\n",
    "laps_df.to_clipboard(sep=',', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341aaedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop the first two laps:\n",
    "laps_df = laps_df[laps_df['lap_id'] > 2].reset_index(drop=True)\n",
    "laps_df\n",
    "## re-index\n",
    "laps_df['lap_id'] = laps_df.index\n",
    "laps_df['label'] = laps_df.index\n",
    "laps_df.to_clipboard(sep=',', excel=False)\n",
    "# laps_df[['start', 'stop', 'lap_dir']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad33e3c",
   "metadata": {
    "tags": [
     "active-2025-01-13"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import override_laps\n",
    "\n",
    "override_laps_df: Optional[pd.DataFrame] = UserAnnotationsManager.get_hardcoded_laps_override_dict().get(curr_active_pipeline.get_session_context(), None)\n",
    "if override_laps_df is not None:\n",
    "    print(f'overriding laps....')\n",
    "    display(override_laps_df)\n",
    "    override_laps(curr_active_pipeline, override_laps_df=override_laps_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ea0059",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacing_computation_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff3fcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "override_laps_df\n",
    "# override_laps_obj.filtered_by_lap_flat_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c601c54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_filtered_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b80e699",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.replace_session_laps_with_estimates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2482b0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.plotting.placemaps import plot_placefield_occupancy\n",
    "\n",
    "plot_placefield_occupancy(global_pf1D, plot_pos_bin_axes=True)\n",
    "# global_pf1D.plot_occupancy(plot_pos_bin_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2808c7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to separate out the main-track vs.the platforms so that I can impose continuity constraints (for filtering replays via step-sizes) only on the bins of the main track.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd9d391",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.epochs\n",
    "# global_session.epochs\n",
    "# long_session.epochs\n",
    "# short_session.epochs\n",
    "## find first lap\n",
    "global_laps\n",
    "\n",
    "# curr_active_pipeline.sess.position.to_dataframe()\n",
    "long_session.position.to_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca411f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "active_sess_config = deepcopy(curr_active_pipeline.active_sess_config)\n",
    "# absolute_start_timestamp: float = active_sess_config.absolute_start_timestamp\n",
    "loaded_track_limits = active_sess_config.loaded_track_limits # x_midpoint, \n",
    "loaded_track_limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d8bd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "(first_valid_pos_time, last_valid_pos_time) = curr_active_pipeline.find_first_and_last_valid_position_times()\n",
    "first_valid_pos_time, last_valid_pos_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f464ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.get_all_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e68bec8",
   "metadata": {
    "tags": [
     "active",
     "great"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.plotting.figure import pretty_plot\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.placefield import plot_1d_placecell_validations\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.placefield import plot_single_cell_1D_placecell_validation\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.placefield import _subfn_plot_pf1D_placefield\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import test_plotRaw_v_time\n",
    "\n",
    "\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "\n",
    "\n",
    "# global_session.config.plotting_config\n",
    "active_config = deepcopy(curr_active_pipeline.active_configs[global_epoch_name])\n",
    "active_pf1D = deepcopy(global_pf1D)\n",
    "\n",
    "fig = plt.figure(figsize=(23, 9.7), clear=True, num='test_plotRaw_v_time')\n",
    "# Need axes:\n",
    "# Layout Subplots in Figure:\n",
    "gs = fig.add_gridspec(1, 8)\n",
    "gs.update(wspace=0, hspace=0.05) # set the spacing between axes. # `wspace=0`` is responsible for sticking the pf and the activity axes together with no spacing\n",
    "ax_activity_v_time = fig.add_subplot(gs[0, :-1]) # all except the last element are the trajectory over time\n",
    "ax_pf_tuning_curve = fig.add_subplot(gs[0, -1], sharey=ax_activity_v_time) # The last element is the tuning curve\n",
    "# if should_include_labels:\n",
    "    # ax_pf_tuning_curve.set_title('Normalized Placefield', fontsize='14')\n",
    "ax_pf_tuning_curve.set_xticklabels([])\n",
    "ax_pf_tuning_curve.set_yticklabels([])\n",
    "\n",
    "\n",
    "cellind: int = 2\n",
    "\n",
    "kwargs = {}\n",
    "# jitter the curve_value for each spike based on the time it occured along the curve:\n",
    "spikes_color_RGB = kwargs.get('spikes_color', (0, 0, 0))\n",
    "spikes_alpha = kwargs.get('spikes_alpha', 0.8)\n",
    "# print(f'spikes_color: {spikes_color_RGB}')\n",
    "should_plot_bins_grid = kwargs.get('should_plot_bins_grid', False)\n",
    "\n",
    "should_include_trajectory = kwargs.get('should_include_trajectory', True) # whether the plot should include \n",
    "should_include_labels = kwargs.get('should_include_labels', True) # whether the plot should include text labels, like the title, axes labels, etc\n",
    "should_include_plotRaw_v_time_spikes = kwargs.get('should_include_spikes', True) # whether the plot should include plotRaw_v_time-spikes, should be set to False to plot completely with the new all spikes mode\n",
    "use_filtered_positions: bool = kwargs.pop('use_filtered_positions', False)\n",
    "\n",
    "# position_plot_kwargs = {'color': '#393939c8', 'linewidth': 1.0, 'zorder':5} | kwargs.get('position_plot_kwargs', {}) # passed into `active_epoch_placefields1D.plotRaw_v_time`\n",
    "position_plot_kwargs = {'color': '#757575c8', 'linewidth': 1.0, 'zorder':5} | kwargs.get('position_plot_kwargs', {}) # passed into `active_epoch_placefields1D.plotRaw_v_time`\n",
    "\n",
    "\n",
    "# _out = test_plotRaw_v_time(active_pf1D=active_pf1D, cellind=cellind)\n",
    "# spike_plot_kwargs = {'linestyle':'none', 'markersize':5.0, 'marker': '.', 'markerfacecolor':spikes_color_RGB, 'markeredgecolor':spikes_color_RGB, 'zorder':10} ## OLDER\n",
    "spike_plot_kwargs = {'zorder':10} ## OLDER\n",
    "\n",
    "\n",
    "# active_pf1D.plotRaw_v_time(cellind, ax=ax_activity_v_time, spikes_alpha=spikes_alpha,\n",
    "# \tposition_plot_kwargs=position_plot_kwargs,\n",
    "# \tspike_plot_kwargs=spike_plot_kwargs,\n",
    "# \tshould_include_labels=should_include_labels, should_include_trajectory=should_include_trajectory, should_include_spikes=should_include_plotRaw_v_time_spikes,\n",
    "# \tuse_filtered_positions=use_filtered_positions,\n",
    "# ) # , spikes_color=spikes_color, spikes_alpha=spikes_alpha\n",
    "\n",
    "_out = test_plotRaw_v_time(active_pf1D=active_pf1D, cellind=cellind, ax=ax_activity_v_time, spikes_alpha=spikes_alpha,\n",
    "    position_plot_kwargs=position_plot_kwargs,\n",
    "    spike_plot_kwargs=spike_plot_kwargs,\n",
    "    should_include_labels=should_include_labels, should_include_trajectory=should_include_trajectory, should_include_spikes=should_include_plotRaw_v_time_spikes,\n",
    "    use_filtered_positions=use_filtered_positions,\n",
    ")\n",
    "\n",
    "_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be863cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_out = _subfn_plot_pf1D_placefield(active_epoch_placefields1D=active_pf1D, placefield_cell_index=cellind,\n",
    "                                ax_activity_v_time=ax_activity_v_time, ax_pf_tuning_curve=ax_pf_tuning_curve, pf_tuning_curve_ax_position='right')\n",
    "_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b30c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as itt\n",
    "from mpl_multitab import MplMultiTab\n",
    "\n",
    "n_cells = active_placefields1D.ratemap.n_neurons\n",
    "out_figures_list = []\n",
    "out_axes_list = []\n",
    "\n",
    "if should_save:\n",
    "    curr_parent_out_path = plotting_config.active_output_parent_dir.joinpath('1d Placecell Validation')\n",
    "    curr_parent_out_path.mkdir(parents=True, exist_ok=True)        \n",
    "    \n",
    "# Tabbed Matplotlib Figure Mode:\n",
    "ui = MplMultiTab(title='plot_1d_placecell_validations')\n",
    "\n",
    "\n",
    "for a_decoder_name, a_decoder in track_templates.get_decoders_dict().items():\n",
    "    print(f'a_decoder_name: {a_decoder}')\n",
    "    curr_pf1D = a_decoder.pf\n",
    "    curr_pf1D.    \n",
    "\n",
    "    fig = ui.add_tab(f'Dataset {c.upper()}', f'Observation {m}')\n",
    "    ax = fig.subplots()\n",
    "    \n",
    "\n",
    "\n",
    "for i in np.arange(n_cells):\n",
    "    curr_cell_id = active_placefields1D.cell_ids[i]\n",
    "    # fig = ui.add_tab(f'Dataset {modifier_string}', f'Cell {curr_cell_id}') # Tabbed mode only\n",
    "    fig = ui.add_tab(f'Cell{curr_cell_id}')\n",
    "\n",
    "    fig, axs = plot_single_cell_1D_placecell_validation(active_placefields1D, i, extant_fig=fig, **(plot_kwargs or {}))\n",
    "    out_figures_list.append(fig)\n",
    "    out_axes_list.append(axs)\n",
    "\n",
    "# once done, save out as specified\n",
    "common_basename = active_placefields1D.str_for_filename(prefix_string=modifier_string)\n",
    "if should_save:\n",
    "    common_basename = active_placefields1D.str_for_filename(prefix_string=modifier_string)\n",
    "    if save_mode == 'separate_files':\n",
    "        # make a subdirectory for this run (with these parameters and such)\n",
    "        curr_specific_parent_out_path = curr_parent_out_path.joinpath(common_basename)\n",
    "        curr_specific_parent_out_path.mkdir(parents=True, exist_ok=True)\n",
    "        print(f'Attempting to write {n_cells} separate figures to {str(curr_specific_parent_out_path)}')\n",
    "        for i in np.arange(n_cells):\n",
    "            print('Saving figure {} of {}...'.format(i, n_cells))\n",
    "            curr_cell_id = active_placefields1D.cell_ids[i]\n",
    "            fig = out_figures_list[i]\n",
    "            # curr_cell_filename = 'pf1D-' + modifier_string + _filename_for_placefield(active_placefields1D, curr_cell_id) + '.png'\n",
    "            curr_cell_basename = '-'.join([common_basename, f'cell_{curr_cell_id:02d}'])\n",
    "            # add the file extension\n",
    "            curr_cell_filename = f'{curr_cell_basename}.png'\n",
    "            active_pf_curr_cell_output_filepath = curr_specific_parent_out_path.joinpath(curr_cell_filename)\n",
    "            fig.savefig(active_pf_curr_cell_output_filepath)\n",
    "    elif save_mode == 'pdf':\n",
    "        print('saving multipage pdf...')\n",
    "        curr_cell_basename = common_basename\n",
    "        # add the file extension\n",
    "        curr_cell_filename = f'{curr_cell_basename}-multipage_pdf.pdf'\n",
    "        pdf_save_path = curr_parent_out_path.joinpath(curr_cell_filename)\n",
    "        save_to_multipage_pdf(out_figures_list, save_file_path=pdf_save_path)\n",
    "    else:\n",
    "        raise ValueError\n",
    "    print('\\t done.')\n",
    "\n",
    "\n",
    "# ui.show() # Tabbed mode only\n",
    "_final_out = MatplotlibRenderPlots(name=f'{common_basename}', figures=out_figures_list, axes=out_axes_list, ui=ui)\n",
    "## OUTPUT: _final_out\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38ee8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_pf1D.run_spk_pos\n",
    "active_pf1D.spk_pos\n",
    "active_pf1D.run_spk_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c8e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_pf1D.ratemap_spiketrains\n",
    "active_pf1D.ratemap_spiketrains_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d290ccab",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = plot_1d_placecell_validations(active_pf1D, active_config.plotting_config, modifier_string='lap_only', should_save=False)\n",
    "# _out = curr_active_pipeline.display('_display_1d_placefield_validations', 'maze_any')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f853e158",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out.ui.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71088cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib_configuration_update(\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e362334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with matplotlib_interactivity(is_interactive=True):\n",
    "_out.figures[0].show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc6123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qclu_included_aclus = curr_active_pipeline.determine_good_aclus_by_qclu(included_qclu_values=[1,2,4,9])\n",
    "qclu_included_aclus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9e4db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_neuron_ids_list = [a_decoder.pf.ratemap.neuron_ids for a_decoder in (long_LR_decoder, long_RL_decoder, short_LR_decoder, short_RL_decoder)]\n",
    "original_neuron_ids_list = [a_decoder.pf.ratemap.neuron_ids for a_decoder in track_templates.get_decoders_dict().values()]\n",
    "original_neuron_ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9a96b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_names = track_templates.get_decoder_names() # ('long_LR', 'long_RL', 'short_LR', 'short_RL')\n",
    "decoder_names = TrackTemplates.get_decoder_names() # ('long_LR', 'long_RL', 'short_LR', 'short_RL')\n",
    "\n",
    "link = #00fff7\n",
    "link_visited = #ffaaff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a46a4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_print = True\n",
    "## INPUTS: included_qclu_values\n",
    "included_qclu_values = [1, 2]\n",
    "\n",
    "# modified_neuron_ids_dict = track_templates.determine_decoder_aclus_filtered_by_qclu(included_qclu_values=included_qclu_values)\n",
    "\n",
    "# filtered_track_templates = track_templates.filtered_by_frate_and_qclu(minimum_inclusion_fr_Hz=None, included_qclu_values=None)\n",
    "# filtered_track_templates = track_templates.filtered_by_frate_and_qclu(included_qclu_values=included_qclu_values)\n",
    "filtered_track_templates = track_templates.filtered_by_frate_and_qclu(minimum_inclusion_fr_Hz=5.0, included_qclu_values=[1, 2])\n",
    "\n",
    "# modified_neuron_ids_dict\n",
    "filtered_track_templates.decoder_neuron_IDs_list\n",
    "_out = dict()\n",
    "_out['_display_short_long_firing_rate_index_comparison'] = curr_active_pipeline.display(display_function='_display_short_long_firing_rate_index_comparison', active_session_configuration_context=None) # _display_short_long_firing_rate_index_comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a1ed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_included_aclus_dict = {}\n",
    "# for a_decoder in track_templates.get_decoders_dict().values():\n",
    "    # a_decoder.pf.spikes_df\n",
    "for a_decoder_name, a_decoder in track_templates.get_decoders_dict().items():\n",
    "    neuron_identities: pd.DataFrame = deepcopy(a_decoder.pf.filtered_spikes_df).spikes.extract_unique_neuron_identities()\n",
    "    if debug_print:\n",
    "        print(f\"original {len(neuron_identities)}\")\n",
    "    filtered_neuron_identities: pd.DataFrame = neuron_identities[neuron_identities.neuron_type == NeuronType.PYRAMIDAL]\n",
    "    if debug_print:\n",
    "        print(f\"post PYRAMIDAL filtering {len(filtered_neuron_identities)}\")\n",
    "    filtered_neuron_identities = filtered_neuron_identities[['aclu', 'shank', 'cluster', 'qclu']]\n",
    "    filtered_neuron_identities = filtered_neuron_identities[np.isin(filtered_neuron_identities.qclu, included_qclu_values)] # drop [6, 7], which are said to have double fields - 80 remain\n",
    "    if debug_print:\n",
    "        print(f\"post (qclu != [6, 7]) filtering {len(filtered_neuron_identities)}\")\n",
    "    # filtered_neuron_identities\n",
    "    final_included_aclus = filtered_neuron_identities['aclu'].to_numpy()\n",
    "    final_included_aclus_dict[a_decoder_name] = final_included_aclus.tolist()\n",
    "\n",
    "\n",
    "final_included_aclus_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543a7317",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display_output_history_list\n",
    "curr_active_pipeline.display_output_last_added_context\n",
    "curr_active_pipeline.last_added_display_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd79d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_templates.any_decoder_neuron_IDs\n",
    "track_templates.decoder_neuron_IDs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acad4458",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650eea58",
   "metadata": {
    "tags": [
     "all",
     "spike_raster_window",
     "display",
     "gui",
     "run-spike_raster_window_test"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import Spike2DRaster\n",
    "from pyphoplacecellanalysis.GUI.Qt.SpikeRasterWindows.Spike3DRasterWindowWidget import Spike3DRasterWindowWidget\n",
    "from pyphoplacecellanalysis.GUI.Qt.PlaybackControls.Spike3DRasterBottomPlaybackControlBarWidget import Spike3DRasterBottomPlaybackControlBar\n",
    "\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.spike_raster_widgets import _setup_spike_raster_window_for_debugging\n",
    "\n",
    "# Gets the existing SpikeRasterWindow or creates a new one if one doesn't already exist:\n",
    "spike_raster_window, (active_2d_plot, active_3d_plot, main_graphics_layout_widget, main_plot_widget, background_static_scroll_plot_widget) = Spike3DRasterWindowWidget.find_or_create_if_needed(curr_active_pipeline, force_create_new=True)\n",
    "\n",
    "\n",
    "all_global_menus_actionsDict, global_flat_action_dict = _setup_spike_raster_window_for_debugging(spike_raster_window)\n",
    "\n",
    "# preview_overview_scatter_plot: pg.ScatterPlotItem  = active_2d_plot.plots.preview_overview_scatter_plot # ScatterPlotItem \n",
    "# preview_overview_scatter_plot.setDownsampling(auto=True, method='subsample', dsRate=10)\n",
    "main_graphics_layout_widget: pg.GraphicsLayoutWidget = active_2d_plot.ui.main_graphics_layout_widget\n",
    "wrapper_layout: pg.QtWidgets.QVBoxLayout = active_2d_plot.ui.wrapper_layout\n",
    "main_content_splitter = active_2d_plot.ui.main_content_splitter # QSplitter\n",
    "layout = active_2d_plot.ui.layout\n",
    "background_static_scroll_window_plot = active_2d_plot.plots.background_static_scroll_window_plot # PlotItem\n",
    "main_plot_widget = active_2d_plot.plots.main_plot_widget # PlotItem\n",
    "active_window_container_layout = active_2d_plot.ui.active_window_container_layout # GraphicsLayout, first item of `main_graphics_layout_widget` -- just the active raster window I think, there is a strange black space above it\n",
    "bottom_bar: Spike3DRasterBottomPlaybackControlBar = spike_raster_window.bottom_playback_control_bar_widget\n",
    "# bottom_bar.log_print('test manual log entry')\n",
    "bottom_bar.add_log_line('test manual log entry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a68e979",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_plot_widget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccad938",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(spike_raster_window.spike_raster_plt_2d.params.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c754c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_dock_ids_list = active_2d_plot.get_group_only_flat_dock_identifiers_list()\n",
    "leaf_dock_ids_list = active_2d_plot.get_leaf_only_flat_dock_identifiers_list()\n",
    "group_dock_ids_list\n",
    "\n",
    "\n",
    "group_dock_raw_identifiers_list = [v.lstrip('GROUP[').rstrip(']') for v in group_dock_ids_list] # 'GROUP[ContinuousDecode_0.03]' -> 'ContinuousDecode_0.03'\n",
    "group_dock_raw_identifiers_list\n",
    "# spike_raster_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb984228",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_group_container_id: str = group_dock_ids_list[0] # 'GROUP[ContinuousDecode_0.03]'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e70360",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dock_items_dict: Dict[str, List[Dock]] = active_2d_plot.get_dockGroup_dock_dict()\n",
    "grouped_dock_items_dict\n",
    "\n",
    "# {'ContinuousDecode_ - t_bin_size: 0.025': [<Dock ContinuousDecode_long_LR - t_bin_size: 0.025 (65, 200)>,\n",
    "#   <Dock ContinuousDecode_long_RL - t_bin_size: 0.025 (65, 200)>,\n",
    "#   <Dock ContinuousDecode_short_LR - t_bin_size: 0.025 (65, 200)>,\n",
    "#   <Dock ContinuousDecode_short_RL - t_bin_size: 0.025 (65, 200)>],\n",
    "#  'ContinuousDecode_0.03': [<Dock DirectionalDecodersDecoded[long_LR]0.03 (65, 200)>,\n",
    "#   <Dock DirectionalDecodersDecoded[long_RL]0.03 (65, 200)>,\n",
    "#   <Dock DirectionalDecodersDecoded[short_LR]0.03 (65, 200)>,\n",
    "#   <Dock DirectionalDecodersDecoded[short_RL]0.03 (65, 200)>]}\n",
    "\n",
    "a_group_container_id: str = group_dock_ids_list[0]\n",
    "a_group_id: str = group_dock_raw_identifiers_list[0]\n",
    "flat_group_dockitems_list: List[Dock] = grouped_dock_items_dict[a_group_id]\n",
    "flat_group_dockitems_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba94a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup children:\n",
    "for a_dock in flat_group_dockitems_list:\n",
    "    # a_dock_identifier: str = a_dock.name()\n",
    "    # ## format nested child docks:\n",
    "    # a_dock.config.showCloseButton = False\n",
    "    # a_dock.config.showCollapseButton = False\n",
    "    # a_dock.config.showGroupButton = False\n",
    "    # a_dock.config.corner_radius='0px'\n",
    "    # a_dock.updateStyle()\n",
    "    active_2d_plot.dock_manager_widget.displayDockArea.addDock(dock=a_dock) ## move the dock items as children to the new container\n",
    "    # active_2d_plot.displayDockArea.moveDock(\n",
    "    # nested_dynamic_docked_widget_container.displayDockArea.addDock(dock=a_dock) ## move the dock items as children to the new container\n",
    "    \n",
    "## remove the group\n",
    "active_2d_plot.dock_manager_widget.remove_display_dock(identifier=a_group_container_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d570e8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.dock_manager_widget.unwrap_docks_in_nested_dock_area(dock_group_name='ContinuousDecode_0.03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fa4144",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dock all Grouped results from `'DockedWidgets.Pseudo2DDecodedEpochsDockedMatplotlibView'`\n",
    "## INPUTS: active_2d_plot\n",
    "nested_dock_items, nested_dynamic_docked_widget_container_widgets = active_2d_plot.ui.dynamic_docked_widget_container.layout_dockGroups()\n",
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()\n",
    "## OUTPUTS: nested_dock_items, nested_dynamic_docked_widget_container_widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8362a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import add_continuous_decoded_posterior\n",
    "\n",
    "(nested_dock_items, nested_dynamic_docked_widget_container_widgets), (a_continuously_decoded_dict, pseudo2D_decoder, all_directional_pf1D_Decoder_dict) = add_continuous_decoded_posterior(spike_raster_window=spike_raster_window, curr_active_pipeline=curr_active_pipeline, desired_time_bin_size=0.05, debug_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967df72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Increase the window duration centered\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import plot_attached_BinByBinDecodingDebugger\n",
    "\n",
    "## INPUTS: a_decoder, a_decoded_result\n",
    "win, out_pf1D_decoder_template_objects, (plots_container, plots_data), _on_update_fcn = plot_attached_BinByBinDecodingDebugger(spike_raster_window, curr_active_pipeline, a_decoder=a_decoder, a_decoded_result=a_decoded_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62a8afa",
   "metadata": {
    "tags": [
     "active-2025-02-25"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import plot_attached_BinByBinDecodingDebugger\n",
    "## Plot one of the continuous results for the most recently computed time_bin_size:\n",
    "\n",
    "\n",
    "# all_directional_pf1D_Decoder_dict\n",
    "a_decoder_name: str = 'long'\n",
    "a_decoder = results1D.decoders[a_decoder_name]\n",
    "a_decoded_result = results1D.continuous_results[a_decoder_name]\n",
    "\n",
    "## INPUTS: a_decoder, a_decoded_result\n",
    "win, out_pf1D_decoder_template_objects, (plots_container, plots_data), _on_update_fcn = plot_attached_BinByBinDecodingDebugger(spike_raster_window, curr_active_pipeline, a_decoder=a_decoder, a_decoded_result=a_decoded_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a20a893",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_main_raster_plot: bool = (active_2d_plot.plots.main_plot_widget is not None)\n",
    "_raster_tracks_out_dict = active_2d_plot.prepare_pyqtgraph_rasterPlot_track(name_modifier_suffix='raster_window', should_link_to_main_plot_widget=has_main_raster_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcbc56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.External.pyqtgraph.dockarea.Dock import Dock, DockDisplayConfig\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import FigureWidgetDockDisplayConfig\n",
    "\n",
    "flat_dock_item_tuple_dict: Dict[str, Tuple] = active_2d_plot.get_flat_dock_item_tuple_dict()\n",
    "group_only_flat_dockwidgets_dict = {k:a_widget for k, (a_dock, a_widget) in flat_dock_item_tuple_dict.items() if ('GROUP' == a_dock.config.additional_metadata.get('type', 'LEAF')) }\n",
    "leaf_only_flat_dockwidgets_dict = {k:a_widget for k, (a_dock, a_widget) in flat_dock_item_tuple_dict.items() if ('LEAF' == a_dock.config.additional_metadata.get('type', 'LEAF')) }\n",
    "group_only_flat_dockwidgets_dict\n",
    "leaf_only_flat_dockwidgets_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea403e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "active_2d_plot.get_flat_dockitems_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff28fdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import AddNewDecodedPosteriors_MatplotlibPlotCommand\n",
    "from pyphoplacecellanalysis.External.pyqtgraph.dockarea.Dock import Dock, DockDisplayConfig\n",
    "\n",
    "flat_dock_item_tuple_dict: Dict[str, Tuple] = active_2d_plot.get_flat_dock_item_tuple_dict()\n",
    "flat_dock_item_tuple_dict\n",
    "\n",
    "# flat_docks_dict = {k:a_dock for k, (a_dock, a_widget) in flat_dock_item_tuple_dict.items() if ('ContinuousDecode_ - t_bin_size: 0.025' in a_dock.config.dock_group_names) }\n",
    "flat_dockwidgets_dict = {k:a_widget for k, (a_dock, a_widget) in flat_dock_item_tuple_dict.items() if ('ContinuousDecode_ - t_bin_size: 0.025' in a_dock.config.dock_group_names) }\n",
    "flat_dockwidgets_dict\n",
    "\n",
    "# flat_dock_item_tuple_dict = {k:a_widget if a_dock.grou for k, (a_dock, a_widget) in flat_dock_item_tuple_dict.items()}\n",
    "\n",
    "# flat_dockwidgets_list = active_2d_plot.get_flat_widgets_list()\n",
    "# flat_dockwidgets_list\n",
    "# active_2d_plot.get_dock_groups()\n",
    "\n",
    "_all_tracks_out_artists = {}\n",
    "for k, a_widget in flat_dockwidgets_dict.items():\n",
    "    _out_artists = AddNewDecodedPosteriors_MatplotlibPlotCommand._perform_overlay_measured_position(identifier_name=k, widget=a_widget, matplotlib_fig=a_widget.fig, matplotlib_fig_axes=a_widget.axes, measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()))\n",
    "    _all_tracks_out_artists[k] = _out_artists\n",
    "    a_widget.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8fc993",
   "metadata": {},
   "outputs": [],
   "source": [
    "_all_tracks_out_artists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8580701",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, a_widget in flat_dockwidgets_dict.items():\n",
    "    a_widget.plots.measured_position_artists = _all_tracks_out_artists[k]\n",
    "    \n",
    "    # a_widget.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21b7f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_playback_control_bar_widget = spike_raster_window.bottom_playback_control_bar_widget # Spike3DRasterBottomPlaybackControlBar \n",
    "comboActiveJumpTargetSeries = bottom_playback_control_bar_widget.ui.comboActiveJumpTargetSeries # QComboBox \n",
    "comboActiveJumpTargetSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd1d42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Dock all Grouped results from `'DockedWidgets.Pseudo2DDecodedEpochsDockedMatplotlibView'`\n",
    "## INPUTS: active_2d_plot\n",
    "nested_dock_items, nested_dynamic_docked_widget_container_widgets = active_2d_plot.ui.dynamic_docked_widget_container.layout_dockGroups()\n",
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()\n",
    "## OUTPUTS: nested_dock_items, nested_dynamic_docked_widget_container_widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191b20f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()\n",
    "grouped_dock_items_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8084d27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.ui.dynamic_docked_widget_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53ed9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.NestedDockAreaWidget import NestedDockAreaWidget\n",
    "\n",
    "dock_manager_widget: NestedDockAreaWidget = active_2d_plot.dock_manager_widget\n",
    "grouped_dock_items_dict = dock_manager_widget.get_dockGroup_dock_dict()\n",
    "grouped_dock_items_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3ee32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dock_items_dict = active_2d_plot.dock_manager_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c521a076",
   "metadata": {},
   "outputs": [],
   "source": [
    "comboActiveJumpTargetSeries.setCurrentText('Laps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5ebfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.Specific2DRenderTimeEpochs import General2DRenderTimeEpochs, Replays_2DRenderTimeEpochs, Ripples_2DRenderTimeEpochs, SessionEpochs2DRenderTimeEpochs, PBE_2DRenderTimeEpochs, Laps2DRenderTimeEpochs, SpikeBurstIntervals_2DRenderTimeEpochs, NewNonPBE_2DRenderTimeEpochs # Time Intervals/Epochs\n",
    "\n",
    "background_static_scroll_window_plot = active_2d_plot.plots.background_static_scroll_window_plot # PlotItem\n",
    "main_plot_widget = active_2d_plot.plots.main_plot_widget # PlotItem\n",
    "\n",
    "for an_interval_rendering_plot in active_2d_plot.interval_rendering_plots:\n",
    "    _out = NewNonPBE_2DRenderTimeEpochs.add_render_time_epochs(curr_sess=curr_active_pipeline.sess.non_pbe, destination_plot=an_interval_rendering_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f45c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.params.debug_print = True\n",
    "spike_raster_window.enable_debug_print = True\n",
    "active_2d_plot.params.debug_print = True\n",
    "# active_2d_plot.debug_print = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61371822",
   "metadata": {},
   "outputs": [],
   "source": [
    "extant_conn = spike_raster_window.ui.additional_connections.get('spike_3d_to_2d_window_crosshair_connection', None)\n",
    "extant_conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7200fc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.ui.left_side_bar_connections = spike_raster_window.SpikeRasterLeftSidebarControlsMixin_connectSignals(spike_raster_window.ui.leftSideToolbarWidget)\n",
    "spike_raster_window.ui.left_side_bar_connections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0491ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fix window title to display the session context post-hoc\n",
    "desired_window_title: str = curr_active_pipeline.get_complete_session_identifier_string() # 'kdiba_gor01_two_2006-6-07_16-40-19__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 8, 9]-frateThresh_5.0'\n",
    "spike_raster_window.window().setWindowTitle(desired_window_title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b12684",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.params.is_crosshair_trace_enabled = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c0c6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_crosshairs to `active_2d_plot`\n",
    "active_time_sync_pyqtgraph_widgets: Dict[str, PyqtgraphTimeSynchronizedWidget] = {identifier:active_matplotlib_view_widget for identifier, active_matplotlib_view_widget in active_2d_plot.ui.matplotlib_view_widgets.items() if active_matplotlib_view_widget.is_pyqtgraph_based()}\n",
    "active_time_sync_pyqtgraph_widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da93cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_name, a_time_sync_widget in active_2d_plot.ui.matplotlib_view_widgets.items():\n",
    "    print(f'a_name: {a_name}')\n",
    "    # a_time_sync_widget.plots_data\n",
    "    a_time_sync_widget.plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd315de",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_side_bar_controls = spike_raster_window.ui.leftSideToolbarWidget\n",
    "left_side_bar_controls.crosshair_trace_time = \"test\"\n",
    "\n",
    "left_side_bar_controls.ui.lblCrosshairTraceStaticLabel.setVisible(True)\n",
    "left_side_bar_controls.ui.lblCrosshairTraceValue.setVisible(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d4effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.PyqtgraphTimeSynchronizedWidget import PyqtgraphTimeSynchronizedWidget\n",
    "\n",
    "def on_crosshair_updated_signal(self, name, trace_value):\n",
    "    print(f'on_crosshair_updated_signal(self: {self}, name: \"{name}\", trace_value: \"{trace_value}\")')\n",
    "    left_side_bar_controls = spike_raster_window.ui.leftSideToolbarWidget\n",
    "    left_side_bar_controls.crosshair_trace_time = trace_value\n",
    "    \n",
    "    # self.ui.lblCrosshairTraceStaticLabel.setVisible(True)\n",
    "    # self.ui.lblCrosshairTraceValue.setVisible(True)\n",
    "\n",
    "\n",
    "for a_name, a_time_sync_widget in active_2d_plot.ui.matplotlib_view_widgets.items():\n",
    "    print(f'a_name: {a_name}')\n",
    "    try:\n",
    "        a_time_sync_widget.update_crosshair_trace(wants_crosshairs_trace=True)\n",
    "        a_time_sync_widget.sigCrosshairsUpdated.connect(on_crosshair_updated_signal)\n",
    "    except KeyError as e:\n",
    "        # KeyError: 'connections'\n",
    "        pass\n",
    "        print(f'\\tfailed.')\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6843c773",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_time_sync_pyqtgraph_widgets['new_curves_separate_plot'].update_crosshair_trace(wants_crosshairs_trace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76ab4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277a736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4254723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(spike_raster_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05d7666",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.plots.main_plot_widget\n",
    "\n",
    "main_plot_widget = active_2d_plot.plots.main_plot_widget # PlotItem\n",
    "main_plot_widget.setMinimumHeight(20.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9cf1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_window_container_layout\n",
    "# main_graphics_layout_widget.ci # GraphicsLayout\n",
    "main_graphics_layout_widget.ci.childItems()\n",
    "# main_graphics_layout_widget.setHidden(True) ## hides too much\n",
    "main_graphics_layout_widget.setHidden(False)\n",
    "\n",
    "# main_graphics_layout_widget\n",
    "\n",
    "active_window_container_layout.setBorder(pg.mkPen('yellow', width=4.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7399378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_window_container_layout.allChildItems()\n",
    "active_window_container_layout.setPreferredHeight(200.0)\n",
    "active_window_container_layout.setMaximumHeight(800.0)\n",
    "active_window_container_layout.setSpacing(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a6aaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set stretch factors to control priority\n",
    "main_graphics_layout_widget.ci.layout.setRowStretchFactor(0, 400)  # Plot1: lowest priority\n",
    "main_graphics_layout_widget.ci.layout.setRowStretchFactor(1, 2)  # Plot2: mid priority\n",
    "main_graphics_layout_widget.ci.layout.setRowStretchFactor(2, 2)  # Plot3: highest priority\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5f61dd",
   "metadata": {
    "tags": [
     "_perform_plot_multi_decoder_meas_pred_position_track",
     "active-2025-01-16"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalDecodersContinuouslyDecodedResult\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import SynchronizedPlotMode\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_1D_most_likely_position_comparsions\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DecoderIdentityColors\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_plot_multi_decoder_meas_pred_position_track\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "\n",
    "## Build the new dock track:\n",
    "dock_identifier: str = 'Continuous Decoding Performance'\n",
    "ts_widget, fig, ax_list = active_2d_plot.add_new_matplotlib_render_plot_widget(name=dock_identifier)\n",
    "## Get the needed data:\n",
    "directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "previously_decoded_keys: List[float] = list(continuously_decoded_result_cache_dict.keys()) # [0.03333]\n",
    "print(F'previously_decoded time_bin_sizes: {previously_decoded_keys}')\n",
    "\n",
    "time_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\n",
    "print(f'time_bin_size: {time_bin_size}')\n",
    "continuously_decoded_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_decode_result.most_recent_continuously_decoded_dict\n",
    "all_directional_continuously_decoded_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = {k:v for k, v in (continuously_decoded_dict or {}).items() if k in TrackTemplates.get_decoder_names()} ## what is plotted in the `f'{a_decoder_name}_ContinuousDecode'` rows by `AddNewDirectionalDecodedEpochs_MatplotlibPlotCommand`\n",
    "## OUT: all_directional_continuously_decoded_dict\n",
    "## Draw the position meas/decoded on the plot widget\n",
    "## INPUT: fig, ax_list, all_directional_continuously_decoded_dict, track_templates\n",
    "\n",
    "_out_artists =  _perform_plot_multi_decoder_meas_pred_position_track(curr_active_pipeline, fig, ax_list, desired_time_bin_size=1.0, enable_flat_line_drawing=True)\n",
    "\n",
    "## sync up the widgets\n",
    "active_2d_plot.sync_matplotlib_render_plot_widget(dock_identifier, sync_mode=SynchronizedPlotMode.TO_WINDOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b589d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Need to figure out what the heck is going on, why are they all decoding to the same position?\n",
    "curr_active_pipeline.find_validators_providing_results(probe_provided_result_keys=['DirectionalDecodersDecoded'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb84d393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders'] # uses `DirectionalMergedDecoders`.\n",
    "\n",
    "# all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_merged_decoders_result.all_directional_decoder_dict # This does not work, because the values in the returned dictionary are PfND, not 1D decoders\n",
    "all_directional_pf1D_Decoder_value = directional_merged_decoders_result.all_directional_pf1D_Decoder\n",
    "\n",
    "pseudo2D_decoder: BasePositionDecoder = all_directional_pf1D_Decoder_value\n",
    "pseudo2D_decoder.xbin_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6256a7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder2D_result: DecodedFilterEpochsResult = continuously_decoded_dict['pseudo2D']\n",
    "decoder2D_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcd9f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder2D_result.filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a618e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_name:types.DecoderName = 'long_LR'\n",
    "\n",
    "\n",
    "result: DecodedFilterEpochsResult = all_directional_continuously_decoded_dict[decoder_name]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5477803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.binning_helpers import BinningContainer\n",
    "\n",
    "time_binning_container: BinningContainer = result.time_bin_containers[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd34e905",
   "metadata": {},
   "outputs": [],
   "source": [
    "marginals_out = result.compute_marginals()\n",
    "marginals_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677f13f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_x_given_n = result.p_x_given_n_list[0]\n",
    "p_x_given_n.shape # (63, 36101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33f6342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1dbc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow, LayoutScrollability\n",
    "\n",
    "out = BasicBinnedImageRenderingWindow(p_x_given_n.T, xbins=time_binning_container.centers, ybins=pseudo2D_decoder.xbin_centers, name='p_x_given_n', title=\"Continuously Decoded Position Posterior\", variable_label='p_x_given_n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc6a81e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38325e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df['truth_decoder_name'] = pos_df['truth_decoder_name'].fillna('')\n",
    "pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bed9c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_color_dict: Dict[types.DecoderName, str] = DecoderIdentityColors.build_decoder_color_dict()\n",
    "\n",
    "decoded_pos_line_kwargs = dict(lw=1.0, color='gray', alpha=0.8, marker='+', markersize=6, animated=False)\n",
    "inactive_decoded_pos_line_kwargs = dict(lw=0.3, alpha=0.2, marker='.', markersize=2, animated=False)\n",
    "active_decoded_pos_line_kwargs = dict(lw=1.0, alpha=0.8, marker='+', markersize=6, animated=False)\n",
    "\n",
    "\n",
    "_out_data = {}\n",
    "_out_data_plot_kwargs = {}\n",
    "# curr_active_pipeline.global_computation_results.t\n",
    "for a_decoder_name, a_decoder in track_templates.get_decoders_dict().items():\n",
    "    a_continuously_decoded_result = all_directional_continuously_decoded_dict[a_decoder_name]\n",
    "    a_decoder_color = decoder_color_dict[a_decoder_name]\n",
    "    \n",
    "    assert len(a_continuously_decoded_result.p_x_given_n_list) == 1\n",
    "    p_x_given_n = a_continuously_decoded_result.p_x_given_n_list[0]\n",
    "    # p_x_given_n = a_continuously_decoded_result.p_x_given_n_list[0]['p_x_given_n']\n",
    "    time_bin_containers = a_continuously_decoded_result.time_bin_containers[0]\n",
    "    time_window_centers = time_bin_containers.centers\n",
    "    # p_x_given_n.shape # (62, 4, 209389)\n",
    "    a_marginal_x = a_continuously_decoded_result.marginal_x_list[0]\n",
    "    # active_time_window_variable = a_decoder.active_time_window_centers\n",
    "    active_time_window_variable = time_window_centers\n",
    "    active_most_likely_positions_x = a_marginal_x['most_likely_positions_1D'] # a_decoder.most_likely_positions[:,0].T\n",
    "    _out_data[a_decoder_name] = pd.DataFrame({'t': time_window_centers, 'x': active_most_likely_positions_x, 'binned_time': np.arange(len(time_window_centers))})\n",
    "    _out_data[a_decoder_name] = _out_data[a_decoder_name].position.adding_lap_info(laps_df=laps_df, inplace=False)\n",
    "    _out_data[a_decoder_name] = _out_data[a_decoder_name].time_point_event.adding_true_decoder_identifier(t_start=t_start, t_delta=t_delta, t_end=t_end) ## ensures ['maze_id', 'is_LR_dir']\n",
    "    _out_data[a_decoder_name]['is_active_decoder_time'] = (_out_data[a_decoder_name]['truth_decoder_name'].fillna('', inplace=False) == a_decoder_name)\n",
    "\n",
    "    # is_active_decoder_time = (_out_data[a_decoder_name]['truth_decoder_name'] == a_decoder_name)\n",
    "    active_decoder_time_points = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] == a_decoder_name]['t'].to_numpy()\n",
    "    active_decoder_most_likely_positions_x = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] == a_decoder_name]['x'].to_numpy()\n",
    "    active_decoder_inactive_time_points = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] != a_decoder_name]['t'].to_numpy()\n",
    "    active_decoder_inactive_most_likely_positions_x = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] != a_decoder_name]['x'].to_numpy()\n",
    "    ## could fill y with np.nan instead of getting shorter?\n",
    "    _out_data_plot_kwargs[a_decoder_name] = (dict(x=active_decoder_time_points, y=active_decoder_most_likely_positions_x, color=a_decoder_color, **active_decoded_pos_line_kwargs), dict(x=active_decoder_inactive_time_points, y=active_decoder_inactive_most_likely_positions_x, color=a_decoder_color, **inactive_decoded_pos_line_kwargs))\n",
    "\n",
    "_out_data_plot_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8972db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out_data[a_decoder_name] = _out_data[a_decoder_name].position.adding_lap_info(laps_df=laps_df, inplace=False)\n",
    "# _out_data[a_decoder_name] = _out_data[a_decoder_name].time_point_event.adding_true_decoder_identifier(t_start=t_start, t_delta=t_delta, t_end=t_end) ## ensures ['maze_id', 'is_LR_dir']\n",
    "\n",
    "# is_active_decoder_time = (_out_data[a_decoder_name]['truth_decoder_name'] == a_decoder_name)\n",
    "active_decoder_time_points = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] == a_decoder_name]['t'].to_numpy()\n",
    "active_decoder_most_likely_positions_x = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] == a_decoder_name]['x'].to_numpy()\n",
    "active_decoder_inactive_time_points = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] != a_decoder_name]['t'].to_numpy()\n",
    "active_decoder_inactive_most_likely_positions_x = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] != a_decoder_name]['x'].to_numpy()\n",
    "\n",
    "_out_data[a_decoder_name] = ((active_decoder_time_points, active_decoder_most_likely_positions_x), (active_decoder_inactive_time_points, active_decoder_inactive_most_likely_positions_x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dd7358",
   "metadata": {},
   "outputs": [],
   "source": [
    "partitioned_dfs = partition_df_dict(pos_df, partitionColumn='truth_decoder_name')\n",
    "\n",
    "a_decoder_name: str = 'short_LR'\n",
    "a_binned_time_grouped_df = partitioned_dfs[a_decoder_name].groupby('binned_time', axis='index', dropna=True)\n",
    "a_binned_time_grouped_df = a_binned_time_grouped_df.median().dropna(axis='index', subset=['x']) ## without the `.dropna(axis='index', subset=['x'])` part it gets an exhaustive df for all possible values of 'binned_time', even those not listed\n",
    "\n",
    "a_matching_binned_times = a_binned_time_grouped_df.reset_index(drop=False)['binned_time']\n",
    "a_matching_binned_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f61fd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "## split into two dfs for each decoder -- the supported and the unsupported\n",
    "partition\n",
    "\n",
    "PandasHelpers.safe_pandas_get_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f2e753",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df.dropna(axis='index', subset=['lap', 'truth_decoder_name'], inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604e0329",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_df: pd.DataFrame = global_laps_obj.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990b67c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import find_epochs_overlapping_other_epochs\n",
    "\n",
    "## INPUTS: global_laps\n",
    "_out_split_pseudo2D_posteriors_dict = {}\n",
    "_out_split_pseudo2D_out_dict = {}\n",
    "pre_filtered_col_names = ['pre_filtered_most_likely_position_indicies', 'pre_filtered_most_likely_position'] # 'pre_filtered_time_bin_containers', 'pre_filtered_p_x_given_n', \n",
    "post_filtered_col_names = [a_col_name.removeprefix('pre_filtered_') for a_col_name in pre_filtered_col_names] # ['time_bin_containers', 'most_likely_position_indicies', 'most_likely_position']\n",
    "print(post_filtered_col_names)\n",
    "for a_time_bin_size, pseudo2D_decoder_continuously_decoded_result in continuously_decoded_pseudo2D_decoder_dict.items():\n",
    "    print(f'a_time_bin_size: {a_time_bin_size}')\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size] = {'pre_filtered_p_x_given_n': None, 'pre_filtered_time_bin_containers': None, 'pre_filtered_most_likely_position_indicies': None, 'pre_filtered_most_likely_position': None, \n",
    "                                                     'is_timebin_included': None, 'p_x_given_n': None} # , 'time_window_centers': None\n",
    "    # pseudo2D_decoder_continuously_decoded_result: DecodedFilterEpochsResult = continuously_decoded_dict.get('pseudo2D', None)\n",
    "    assert len(pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list) == 1\n",
    "    p_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0]\n",
    "    # p_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0]['p_x_given_n']\n",
    "    time_bin_containers = pseudo2D_decoder_continuously_decoded_result.time_bin_containers[0]\n",
    "    # time_window_centers = time_bin_containers.centers\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position_indicies'] = deepcopy(pseudo2D_decoder_continuously_decoded_result.most_likely_position_indicies_list[0])\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position'] = deepcopy(pseudo2D_decoder_continuously_decoded_result.most_likely_positions_list[0])\n",
    "    ## INPUTS: time_bin_containers, global_laps\n",
    "    left_edges = deepcopy(time_bin_containers.left_edges)\n",
    "    right_edges = deepcopy(time_bin_containers.right_edges)\n",
    "    continuous_time_binned_computation_epochs_df: pd.DataFrame = pd.DataFrame({'start': left_edges, 'stop': right_edges, 'label': np.arange(len(left_edges))})\n",
    "    is_timebin_included: NDArray = find_epochs_overlapping_other_epochs(epochs_df=continuous_time_binned_computation_epochs_df, epochs_df_required_to_overlap=deepcopy(global_laps))\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_p_x_given_n'] = p_x_given_n\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_time_bin_containers'] = time_bin_containers\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['is_timebin_included'] = is_timebin_included\n",
    "    # continuous_time_binned_computation_epochs_df['is_in_laps'] = is_timebin_included\n",
    "    ## filter by whether it's included or not:\n",
    "    p_x_given_n = p_x_given_n[:, :, is_timebin_included]\n",
    "    # time_window_centers = \n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['p_x_given_n'] = p_x_given_n\n",
    "    # _out_split_pseudo2D_out_dict[a_time_bin_size]['time_window_centers'] = time_window_centers[is_timebin_included]\n",
    "    # p_x_given_n.shape # (62, 4, 209389)\n",
    "\n",
    "    ## Split across the 2nd axis to make 1D posteriors that can be displayed in separate dock rows:\n",
    "    assert p_x_given_n.shape[1] == 4, f\"expected the 4 pseudo-y bins for the decoder in p_x_given_n.shape[1]. but found p_x_given_n.shape: {p_x_given_n.shape}\"\n",
    "    # split_pseudo2D_posteriors_dict = {k:np.squeeze(p_x_given_n[:, i, :]) for i, k in enumerate(('long_LR', 'long_RL', 'short_LR', 'short_RL'))}\n",
    "    _out_split_pseudo2D_posteriors_dict[a_time_bin_size] = deepcopy(p_x_given_n)\n",
    "    \n",
    "    # for a_col_name in pre_filtered_col_names:\n",
    "    #     filtered_col_name = a_col_name.removeprefix('pre_filtered_')\n",
    "    #     print(f'a_col_name: {a_col_name}, filtered_col_name: {filtered_col_name}, shape: {np.shape(_out_split_pseudo2D_out_dict[a_time_bin_size][a_col_name])}')\n",
    "    #     _out_split_pseudo2D_out_dict[a_time_bin_size][filtered_col_name] = _out_split_pseudo2D_out_dict[a_time_bin_size][a_col_name][is_timebin_included, :]\n",
    "        \n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['most_likely_position_indicies'] = _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position_indicies'][:, is_timebin_included]\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['most_likely_position'] = _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position'][is_timebin_included, :]\n",
    "    \n",
    "\n",
    "p_x_given_n.shape # (n_position_bins, n_decoding_models, n_time_bins) - (57, 4, 29951)\n",
    "\n",
    "## OUTPUTS: _out_split_pseudo2D_posteriors_dict, _out_split_pseudo2D_out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d25155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_most_likely_position_comparsions\n",
    "\n",
    "# fig, axs = plot_most_likely_position_comparsions(pho_custom_decoder, axs=ax, sess.position.to_dataframe())\n",
    "fig, axs = plot_most_likely_position_comparsions(computation_result.computed_data['pf2D_Decoder'], computation_result.sess.position.to_dataframe(), **overriding_dict_with(lhs_dict={'show_posterior':True, 'show_one_step_most_likely_positions_plots':True}, **kwargs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93036009",
   "metadata": {},
   "source": [
    "### <a id='toc7_1_2_'></a>[üîù Dock Track Widgets](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fc1767",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import DockDisplayColors, CustomDockDisplayConfig\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.NestedDockAreaWidget import NestedDockAreaWidget\n",
    "\n",
    "name='group_dock_widget'\n",
    "dockSize=(500,50*4)\n",
    "dockAddLocationOpts=['bottom']\n",
    "\n",
    "display_config = CustomDockDisplayConfig(showCloseButton=True, showCollapseButton=True, showGroupButton=True, orientation='horizontal')\n",
    "## Add the container to hold dynamic matplotlib plot widgets:\n",
    "nested_dynamic_docked_widget_container = NestedDockAreaWidget()\n",
    "nested_dynamic_docked_widget_container.setObjectName(\"nested_dynamic_docked_widget_container\")\n",
    "nested_dynamic_docked_widget_container.setSizePolicy(pg.QtGui.QSizePolicy.Expanding, pg.QtGui.QSizePolicy.Preferred)\n",
    "nested_dynamic_docked_widget_container.setMinimumHeight(40)\n",
    "nested_dynamic_docked_widget_container.setContentsMargins(0, 0, 0, 0)\n",
    "_, dDisplayItem = active_2d_plot.ui.dynamic_docked_widget_container.add_display_dock(name, dockSize=dockSize, display_config=display_config, widget=nested_dynamic_docked_widget_container, dockAddLocationOpts=dockAddLocationOpts, autoOrientation=False)\n",
    "dDisplayItem.setOrientation('horizontal', force=True)\n",
    "dDisplayItem.updateStyle()\n",
    "dDisplayItem.update() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0aea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_docked_widget_container: NestedDockAreaWidget  = active_2d_plot.ui.dynamic_docked_widget_container\n",
    "# dynamic_docked_widget_container.dynamic_display_dict\n",
    "\n",
    "name_list = ['intervals', 'rasters[raster_window]', 'new_curves_separate_plot']\n",
    "for a_name in name_list:\n",
    "    a_dock = dynamic_docked_widget_container.find_display_dock(a_name)\n",
    "    a_dock\n",
    "    a_dock.hideTitleBar()\n",
    "    # a_dock.labelHidden = True\n",
    "    a_dock.updateStyle()\n",
    "    \n",
    "\n",
    "\n",
    "# dynamic_docked_widget_container.find_display_dock('intervals').hideTitleBar()\n",
    "# dynamic_docked_widget_container.find_display_dock('rasters[raster_window]').hideTitleBar()\n",
    "# dynamic_docked_widget_container.find_display_dock('new_curves_separate_plot').hideTitleBar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c932dcce",
   "metadata": {
    "tags": [
     "dock-widgets"
    ]
   },
   "outputs": [],
   "source": [
    "flat_widgets_list = active_2d_plot.ui.dynamic_docked_widget_container.get_flat_widgets_list()\n",
    "flat_dockitems_list = active_2d_plot.ui.dynamic_docked_widget_container.get_flat_dockitems_list()\n",
    "flat_dock_identifiers_list = active_2d_plot.ui.dynamic_docked_widget_container.get_flat_dock_identifiers_list()\n",
    "# flat_dockitems_list\n",
    "flat_dock_identifiers_list\n",
    "# flat_widgets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03657d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "rasters_dock = active_2d_plot.ui.dynamic_docked_widget_container.find_display_dock('rasters[raster_window]')\n",
    "rasters_dock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98199475",
   "metadata": {},
   "outputs": [],
   "source": [
    "rasters_dock.stretch()\n",
    "rasters_dock.setStretch(y=240)\n",
    "rasters_dock.stretch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4405ffad",
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_dock_items = {}\n",
    "nested_dynamic_docked_widget_container_widgets = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fd4da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()\n",
    "# flat_widgets_list = active_2d_plot.ui.dynamic_docked_widget_container.get_flat_widgets_list()\n",
    "# dock_group_name: str = 'ContinuousDecode_ - t_bin_size: 0.025'\n",
    "dock_group_name: str = 'ContinuousDecode_ - t_bin_size: 0.05'\n",
    "flat_group_dockitems_list = grouped_dock_items_dict[dock_group_name]\n",
    "dDisplayItem, nested_dynamic_docked_widget_container = active_2d_plot.ui.dynamic_docked_widget_container.build_wrapping_nested_dock_area(flat_group_dockitems_list, dock_group_name=dock_group_name)\n",
    "nested_dock_items[dock_group_name] = dDisplayItem\n",
    "nested_dynamic_docked_widget_container_widgets[dock_group_name] = nested_dynamic_docked_widget_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432310ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: active_2d_plot\n",
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()\n",
    "nested_dock_items = {}\n",
    "nested_dynamic_docked_widget_container_widgets = {}\n",
    "for dock_group_name, flat_group_dockitems_list in grouped_dock_items_dict.items():\n",
    "    dDisplayItem, nested_dynamic_docked_widget_container = active_2d_plot.ui.dynamic_docked_widget_container.build_wrapping_nested_dock_area(flat_group_dockitems_list, dock_group_name=dock_group_name)\n",
    "    nested_dock_items[dock_group_name] = dDisplayItem\n",
    "    nested_dynamic_docked_widget_container_widgets[dock_group_name] = nested_dynamic_docked_widget_container\n",
    "\n",
    "## OUTPUTS: nested_dock_items, nested_dynamic_docked_widget_container_widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d095b42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_wrapping_nested_dock_area\n",
    "\n",
    "dynamic_docked_widget_container = active_2d_plot.ui.dynamic_docked_widget_container # NestedDockAreaWidget \n",
    "dynamic_docked_widget_container.build_wrapping_nested_dock_area(f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0f9b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_crosshairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85366f3c",
   "metadata": {},
   "source": [
    "## <a id='toc7_2_'></a>[2025-02-17 - Dock Item \"Track\" sizing](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f80e740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.NestedDockAreaWidget import NestedDockAreaWidget\n",
    "\n",
    "dock_manager_widget: NestedDockAreaWidget  = active_2d_plot.dock_manager_widget\n",
    "dock_manager_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7954acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()\n",
    "grouped_dock_items_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbc4bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_dock_items, nested_dynamic_docked_widget_container_widgets = dock_manager_widget.layout_dockGroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9b64d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dock_manager_widget.get_flat_dockitems_list()\n",
    "\n",
    "flat_dockitems_list = dock_manager_widget.get_flat_dockitems_list() ## get the non-grouped dockitems\n",
    "flat_dockitems_list\n",
    "# flat_dockitems_list[0].widgets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497f2289",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dock: Dock = flat_dockitems_list[-1]\n",
    "a_dock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9496b8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_dock_stretch_sizes_list = [a_dock.stretch() for a_dock in flat_dockitems_list] # [(500, 40), (500, 50), (65, 200), (65, 200), (65, 200), (65, 200), (500, 321), (500, 25)]\n",
    "flat_dock_stretch_sizes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d0b1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_dock_stretch_sizes = np.array(flat_dock_stretch_sizes_list)\n",
    "total_height: float = np.sum(flat_dock_stretch_sizes, axis=0)[-1] ## total height of all docks\n",
    "total_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c6c246",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_dock_configs_list = [a_dock.config for a_dock in flat_dockitems_list]\n",
    "flat_dock_configs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dad856",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dock: Dock = flat_dockitems_list[0]\n",
    "a_dock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71138bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_keys_if_possible(curr_key='dynamic_display_dict', curr_value=dock_manager_widget.dynamic_display_dict, max_depth=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb42af97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.External.pyqtgraph.dockarea.Dock import Dock, DockDisplayConfig, DockLabel\n",
    "\n",
    "print(f'active_2d_plot.get_leaf_only_flat_dock_identifiers_list(): {active_2d_plot.get_leaf_only_flat_dock_identifiers_list()}')\n",
    "leaf_only_flat_docks_dict: Dict[str, Dock] = {k:active_2d_plot.find_display_dock(k) for k in active_2d_plot.get_leaf_only_flat_dock_identifiers_list()}\n",
    "print(f'leaf_only_flat_docks_dict: {leaf_only_flat_docks_dict}')\n",
    "\n",
    "leaf_only_flat_docks_geometry_size_list = [(a_dock.width(), a_dock.height()) for k, a_dock in leaf_only_flat_docks_dict.items()] # [(1855, 69), (1855, 69), (1855, 71), (1855, 71), (1855, 71), (1855, 73), (1855, 64), (1855, 85), (1855, 30)]\n",
    "leaf_only_flat_docks_geometry_sizes = np.vstack(leaf_only_flat_docks_geometry_size_list)\n",
    "leaf_only_flat_docks_geometry_sizes\n",
    "\n",
    "\n",
    "single_track_height_unit: int = 30 ## how tall a single track height unit is, determining the minimum height of a track\n",
    "\n",
    "\n",
    "total_leaf_only_flat_docks_geometry_size = np.sum(leaf_only_flat_docks_geometry_sizes, axis=0)\n",
    "total_leaf_only_flat_docks_geometry_size\n",
    "\n",
    "leaf_only_flat_docks_stretch_list = [a_dock.stretch() for k, a_dock in leaf_only_flat_docks_dict.items()] # [(500, 40), (500, 50), (65, 200), (65, 200), (65, 200), (65, 200), (10, 4), (10, 4), (10, 1)]\n",
    "leaf_only_flat_docks_stretchs = np.vstack(leaf_only_flat_docks_stretch_list)\n",
    "leaf_only_flat_docks_stretchs\n",
    "\n",
    "# leaf_only_flat_docks_dict\n",
    "\n",
    "# active_2d_plot.get_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb50aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_only_flat_docks_dict['intervals'].setStretch(x=10, y=4)\n",
    "\n",
    "leaf_only_flat_docks_dict['new_curves_separate_plot'].setStretch(x=10, y=4)\n",
    "for a_name in ['ContinuousDecode_long_LR - t_bin_size: 0.025', 'ContinuousDecode_long_RL - t_bin_size: 0.025', 'ContinuousDecode_short_LR - t_bin_size: 0.025', 'ContinuousDecode_short_RL - t_bin_size: 0.025']:\n",
    "\tleaf_only_flat_docks_dict[a_name].setStretch(x=10, y=4)\n",
    "\tleaf_only_flat_docks_dict[a_name].setMinimumHeight(30)  # Set a smaller minimum height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591bd986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.External.pyqtgraph.dockarea.Dock import debug_widget_geometry\n",
    "\n",
    "# active_2d_plot.get_leaf_only_flat_dock_identifiers_list()\n",
    "\n",
    "dock_items_dict = {k:v[-1] for k, v in output_dict.items()}\n",
    "# dock_items_dict = {k:v[-1] for k, v in MASKED_output_dict.items()}\n",
    "dock_items_dict\n",
    "\n",
    "a_dock_item = dock_items_dict['PBE_marginal_over_track_ID']\n",
    "a_dock_item.setStretch(x=10, y=1)  # Same larger height stretch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b0acc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for k, v in dock_items_dict.items():\n",
    "    print(f'k: {k}')\n",
    "    # debug_widget_geometry(v, widget_name=k)\n",
    "    # Allow one dock to be smaller than its minimum size hint\n",
    "    v.widgetArea.setMinimumHeight(30)  # Set a smaller minimum height\n",
    "    \n",
    "    v.debug_print(widget_name=k)\n",
    "    # Assuming you have three docks\n",
    "    # v.stretch()  # Small height stretch\n",
    "\n",
    "    # smallDock.setStretch(x=10, y=1)  # Small height stretch\n",
    "    # tallDock1.setStretch(x=10, y=3)  # Larger height stretch\n",
    "    # tallDock2.setStretch(x=10, y=3)  # Same larger height stretch\n",
    "\n",
    "    # v.label.debug_print(label_name=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3fe261",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.dissolve_all_dockGroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db33f073",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.layout_dockGroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c45eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dock_items_dict: Dict[str, List[Dock]] = active_2d_plot.get_dockGroup_dock_dict()\n",
    "grouped_dock_items_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693f5fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.dock_manager_widget.nested_dock_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9046712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a_group_id, a_group_dock in active_2d_plot.dock_manager_widget.nested_dock_items.items():\n",
    "# \ta_group_container_id: str = f'GROUP[{a_group_id}]'\n",
    "# \tdel active_2d_plot.dock_manager_widget.nested_dock_items[a_group_id]\n",
    "\t\n",
    "# active_2d_plot.dock_manager_widget.nested_dock_items.clear()\n",
    "active_2d_plot.dock_manager_widget.nested_dock_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99688c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_dock_ids_list = active_2d_plot.get_group_only_flat_dock_identifiers_list()\n",
    "group_dock_ids_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6059b40a",
   "metadata": {},
   "source": [
    "#### <a id='toc7_2_1_1_'></a>[Spike3DRasterWindow - Right Sidebar Widgets](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eff235",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.on_update_right_sidebar_visible_interval_info_tables()\n",
    "spike_raster_window.build_dock_area_managing_tree_widget()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9d696e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.EpochRenderConfigWidget.EpochRenderConfigWidget import EpochRenderConfigWidget, EpochRenderConfigsListWidget\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import DockDisplayColors, CustomDockDisplayConfig\n",
    "\n",
    "an_epochs_display_list_widget: EpochRenderConfigsListWidget = spike_raster_window.build_epoch_intervals_visual_configs_widget()\n",
    "an_epochs_display_list_widget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549f454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_raster_plot.ui.epochs_render_configs_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa59d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.build_neuron_visual_configs_widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3738059c",
   "metadata": {},
   "source": [
    "## <a id='toc7_3_'></a>[üíØ 2025-01-22 - Add Selection Widget for SpikeRaster3DWindow](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bb8383",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_plt_2d: Spike2DRaster = spike_raster_window.spike_raster_plt_2d\n",
    "a_range_selection_widget, range_selection_root_graphics_layout_widget, range_selection_plot_item, range_selection_dDisplayItem = spike_raster_plt_2d.add_new_embedded_pyqtgraph_render_plot_widget(name='range_selection_capture_widget', dockSize=(500,25))\n",
    "range_selection_dDisplayItem.setMaximumHeight(25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cde7d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c1edcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attrs import define, field, Factory\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsObjects.CustomInfiniteLine import CustomInfiniteLine\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsObjects.CustomLinearRegionItem import CustomLinearRegionItem\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsObjects.CustomIntervalRectsItem import CustomIntervalRectsItem\n",
    "\n",
    "\n",
    "@define(slots=False)\n",
    "class UserTimelineSelections:\n",
    "    point_selections: List[pg.TargetItem] = field(default=Factory(list))\n",
    "    line_selections: List[CustomInfiniteLine] = field(default=Factory(list))\n",
    "    range_selections: List[CustomLinearRegionItem] = field(default=Factory(list))\n",
    "    \n",
    "\n",
    "selections: UserTimelineSelections = UserTimelineSelections()\n",
    "selections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af0c666",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Add three infinite lines with labels\n",
    "inf1 = pg.InfiniteLine(movable=True, angle=90, label='x={value:0.2f}', \n",
    "                       labelOpts={'position':0.1, 'color': (200,200,100), 'fill': (200,200,200,50), 'movable': True})\n",
    "inf2 = pg.InfiniteLine(movable=True, angle=0, pen=(0, 0, 200), bounds = [-20, 20], hoverPen=(0,200,0), label='y={value:0.2f}mm', \n",
    "                       labelOpts={'color': (200,0,0), 'movable': True, 'fill': (0, 0, 200, 100)})\n",
    "inf3 = pg.InfiniteLine(movable=True, angle=45, pen='g', label='diagonal',\n",
    "                       labelOpts={'rotateAxis': [1, 0], 'fill': (0, 200, 0, 100), 'movable': True})\n",
    "inf1.setPos([2,2])\n",
    "p1.addItem(inf1)\n",
    "p1.addItem(inf2)\n",
    "p1.addItem(inf3)\n",
    "\n",
    "targetItem1 = pg.TargetItem()\n",
    "\n",
    "targetItem2 = pg.TargetItem(\n",
    "    pos=(30, 5),\n",
    "    size=20,\n",
    "    symbol=\"star\",\n",
    "    pen=\"#F4511E\",\n",
    "    label=\"vert={1:0.2f}\",\n",
    "    labelOpts={\n",
    "        \"offset\": QtCore.QPoint(15, 15)\n",
    "    }\n",
    ")\n",
    "targetItem2.label().setAngle(45)\n",
    "\n",
    "targetItem3 = pg.TargetItem(\n",
    "    pos=(10, 10),\n",
    "    size=10,\n",
    "    symbol=\"x\",\n",
    "    pen=\"#00ACC1\",\n",
    ")\n",
    "targetItem3.setLabel(\n",
    "    \"Third Label\",\n",
    "    {\n",
    "        \"anchor\": QtCore.QPointF(0.5, 0.5),\n",
    "        \"offset\": QtCore.QPointF(30, 0),\n",
    "        \"color\": \"#558B2F\",\n",
    "        \"rotateAxis\": (0, 1)\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "def callableFunction(x, y):\n",
    "    return f\"Square Values: ({x**2:.4f}, {y**2:.4f})\"\n",
    "\n",
    "targetItem4 = pg.TargetItem(\n",
    "    pos=(10, -10),\n",
    "    label=callableFunction\n",
    ")\n",
    "\n",
    "p1.addItem(targetItem1)\n",
    "p1.addItem(targetItem2)\n",
    "p1.addItem(targetItem3)\n",
    "p1.addItem(targetItem4)\n",
    "\n",
    "# Add a linear region with a label\n",
    "lr = pg.LinearRegionItem(values=[70, 80])\n",
    "p1.addItem(lr)\n",
    "label = pg.InfLineLabel(lr.lines[1], \"region 1\", position=0.95, rotateAxis=(1,0), anchor=(1, 1))\n",
    "\n",
    "\n",
    "\n",
    "vb=DragSelectViewBox()\n",
    "plotItem=pg.PlotItem(viewBox=vb)\n",
    "plotWidget=pg.PlotWidget(plotItem=plotItem)\n",
    "plotWidget.plot([0,1,2,3],[10,5,7,3],pen='b')\n",
    "plotWidget.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be99f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QMainWindow, QVBoxLayout, QWidget\n",
    "import pyqtgraph as pg\n",
    "\n",
    "class PlotWithSelection(pg.PlotWidget):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        # Initialize variables to track the selection\n",
    "        self.start_pos = None\n",
    "        self.end_pos = None\n",
    "        self.is_selecting = False\n",
    "        \n",
    "        # Disable default panning\n",
    "        self.setMouseTracking(True)\n",
    "        self.plotItem.vb.setMouseEnabled(x=False, y=False)  # Disable default panning/zooming\n",
    "\n",
    "    def mousePressEvent(self, event):\n",
    "        if event.button() == Qt.LeftButton:\n",
    "            # Get the position where the mouse was clicked\n",
    "            pos = self.plotItem.vb.mapSceneToView(event.pos())\n",
    "            self.start_pos = pos.x()\n",
    "            self.is_selecting = True\n",
    "        else:\n",
    "            super().mousePressEvent(event)\n",
    "\n",
    "    def mouseMoveEvent(self, event):\n",
    "        if self.is_selecting:\n",
    "            # Update the end position while dragging\n",
    "            pos = self.plotItem.vb.mapSceneToView(event.pos())\n",
    "            self.end_pos = pos.x()\n",
    "            self.update_selection()\n",
    "        else:\n",
    "            super().mouseMoveEvent(event)\n",
    "\n",
    "    def mouseReleaseEvent(self, event):\n",
    "        if event.button() == Qt.LeftButton and self.is_selecting:\n",
    "            # Get the final position where the mouse was released\n",
    "            pos = self.plotItem.vb.mapSceneToView(event.pos())\n",
    "            self.end_pos = pos.x()\n",
    "\n",
    "            # Ensure that the start and end positions are valid\n",
    "            if self.start_pos is not None and self.end_pos is not None:\n",
    "                # Create a new LinearRegionItem\n",
    "                region = pg.LinearRegionItem(values=(min(self.start_pos, self.end_pos), max(self.start_pos, self.end_pos)))\n",
    "                self.addItem(region)\n",
    "\n",
    "            # Reset the selection state\n",
    "            self.start_pos = None\n",
    "            self.end_pos = None\n",
    "            self.is_selecting = False\n",
    "        else:\n",
    "            super().mouseReleaseEvent(event)\n",
    "\n",
    "    def update_selection(self):\n",
    "        # Optionally, you can draw a temporary selection line here\n",
    "        pass\n",
    "\n",
    "# Example usage\n",
    "win = QMainWindow()\n",
    "central_widget = QWidget()\n",
    "layout = QVBoxLayout(central_widget)\n",
    "\n",
    "plot_widget = PlotWithSelection()\n",
    "plot_widget.plot([1, 5, 2, 4, 3], pen='r')  # Example data\n",
    "\n",
    "layout.addWidget(plot_widget)\n",
    "win.setCentralWidget(central_widget)\n",
    "win.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599e7a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_selection_plot_item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b800212a",
   "metadata": {},
   "source": [
    "# <a id='toc8_'></a>[3D Lap Plotting Experimentation](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3c731f",
   "metadata": {
    "tags": [
     "laps"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.laps import plot_lap_trajectories_3d\n",
    "## single_combined_plot == True mode (mode 1.):\n",
    "p, laps_pages = plot_lap_trajectories_3d(curr_active_pipeline.sess, single_combined_plot=True)\n",
    "p.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc5eb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import LinearTrackDimensions3D\n",
    "\n",
    "a_track_dims = LinearTrackDimensions3D()\n",
    "merged_boxes_pdata = a_track_dims.build_maze_geometry()\n",
    "\n",
    "## Plotting:\n",
    "# plotter = pv.Plotter()\n",
    "\n",
    "# # Add boxes to the plotter\n",
    "# plotter.add_mesh(platform1, color=\"blue\")\n",
    "# plotter.add_mesh(platform2, color=\"red\")\n",
    "# plotter.add_mesh(track_body, color=\"green\")\n",
    "\n",
    "p[0,0].add_mesh(merged_boxes_pdata, color=\"lightgray\")\n",
    "\n",
    "# Add the merged geometry to the plotter\n",
    "# plotter.add_mesh(merged_boxes_pdata, color=\"lightgray\")\n",
    "\n",
    "# Show the plot\n",
    "# plotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd759803",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## single_combined_plot == False mode (mode 2.):        \n",
    "p, laps_pages = plot_lap_trajectories_3d(curr_active_pipeline.sess, single_combined_plot=False, curr_num_subplots=len(curr_active_pipeline.sess.laps.lap_id), active_page_index=1)\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22347d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lap_trajectories_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13be6121",
   "metadata": {},
   "outputs": [],
   "source": [
    "p, laps_pages = _plot_lap_trajectories_combined_plot_3d(curr_kdiba_pipeline.sess, curr_num_subplots=5, single_combined_plot=False)\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb407455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44449680",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_name, a_nested_dock in nested_dock_items.items():\n",
    "    # a_nested_dock.stretch()\n",
    "    # a_nested_dock.setStretch(y=400)\n",
    "    a_nested_dock\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcc3fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_nested_dock.config.showCloseButton = False\n",
    "a_nested_dock.config.showCollapseButton = False\n",
    "a_nested_dock.config.showGroupButton = False\n",
    "a_nested_dock.config.corner_radius='0px'\n",
    "a_nested_dock.updateStyle()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eee4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_remove_dockgroup(active_2d_plot, flat_group_dockitems_list):\n",
    "    # a_widget_to_remove = {}\n",
    "    a_dock_to_remove = {}\n",
    "    for a_dock in flat_group_dockitems_list:\n",
    "        a_dock_identifier: str = a_dock.name()\n",
    "        print(f'a_dock_identifier: \"{a_dock_identifier}\"')\n",
    "        active_2d_plot.remove_matplotlib_render_plot_widget(identifier=a_dock_identifier)\n",
    "        # active_2d_plot._perform_remove_embedded_pyqtgraph_render_plot_widget(name=a_dock_identifier)\n",
    "        \n",
    "        # for a_child_widget in a_dock.widgets:\n",
    "        #     a_widget_to_remove[a_dock_identifier] = a_child_widget\n",
    "        #     a_child_widget.deleteLater()\n",
    "        a_dock_to_remove[a_dock_identifier] = a_dock\n",
    "        a_dock.close()\n",
    "    return a_dock_to_remove\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeabe3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()\n",
    "# flat_widgets_list = active_2d_plot.ui.dynamic_docked_widget_container.get_flat_widgets_list()\n",
    "grouped_dock_items_dict\n",
    "# flat_widgets_list\n",
    "\n",
    "# flat_group_dockitems_list = grouped_dock_items_dict['ContinuousDecode_ - t_bin_size: 0.025']\n",
    "# flat_group_dockitems_list = grouped_dock_items_dict['ContinuousDecode_ - t_bin_size: 0.05']\n",
    "# flat_group_dockitems_list = grouped_dock_items_dict['ContinuousDecode_ - t_bin_size: 0.5']\n",
    "\n",
    "dock_group_name: str = 'ContinuousDecode_ - t_bin_size: 0.025'\n",
    "flat_group_dockitems_list = grouped_dock_items_dict[dock_group_name]\n",
    "\n",
    "num_child_docks: int = len(flat_group_dockitems_list)\n",
    "total_height: float = np.sum([a_dock.height() for a_dock in flat_group_dockitems_list])\n",
    "total_height\n",
    "\n",
    "for a_dock in flat_group_dockitems_list:\n",
    "    a_dock_identifier: str = a_dock.name()\n",
    "    print(f'a_dock_identifier: \"{a_dock_identifier}\"')\n",
    "    # a_dock.height()\n",
    "    \n",
    "    nested_dynamic_docked_widget_container.displayDockArea.addDock(dock=a_dock)\n",
    "    \n",
    "    # a_dock.moveTo(\n",
    "    # active_2d_plot.remove_matplotlib_render_plot_widget(identifier=a_dock_identifier)\n",
    "    # active_2d_plot._perform_remove_embedded_pyqtgraph_render_plot_widget(name=a_dock_identifier)\n",
    "    \n",
    "    # for a_child_widget in a_dock.widgets:\n",
    "    #     a_widget_to_remove[a_dock_identifier] = a_child_widget\n",
    "    #     a_child_widget.deleteLater()\n",
    "    # a_dock_to_remove[a_dock_identifier] = a_dock\n",
    "    # a_dock.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a1daf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_2d_plot._perform_remove_embedded_pyqtgraph_render_plot_widget(name=\"ContinuousDecode_long_LR - t_bin_size: 0.05\")    \n",
    "\n",
    "active_2d_plot.remove_matplotlib_render_plot_widget(identifier=\"ContinuousDecode_long_LR - t_bin_size: 0.05\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d97155",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_dockitems_list = active_2d_plot.ui.dynamic_docked_widget_container.get_flat_dockitems_list()\n",
    "# active_2d_plot.ui.dynamic_docked_widget_container.get_flat_widgets_list()\n",
    "\n",
    "grouped_dock_items_dict = {}\n",
    "for a_dock in flat_dockitems_list:\n",
    "    ## have a dock\n",
    "    for a_group_name in a_dock.config.dock_group_names: # a dock can belong to multiple groups\n",
    "        if a_group_name not in grouped_dock_items_dict:\n",
    "            grouped_dock_items_dict[a_group_name] = [] ## initialize to empty list\n",
    "        grouped_dock_items_dict[a_group_name].append(a_dock) ## add the dock to the group\n",
    "        \n",
    "grouped_dock_items_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3767ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_plot_widget.hide()\n",
    "active_window_container_layout.setVisible(False)\n",
    "active_window_container_layout.setMaximumHeight(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584313c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spike_raster_window.ui.leftSideToolbarWidget.lblCrosshairTraceValue\n",
    "\n",
    "\n",
    "leftSideToolbarWidget = spike_raster_window.ui.leftSideToolbarWidget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3842bfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# self.ui.lblCrosshairTraceValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8183514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name: str = 'pyqtgraph_view_widget'\n",
    "\n",
    "name_modifier_suffix: str = 'raster_window'\n",
    "name: str = f'rasters[{name_modifier_suffix}]'\n",
    "# find_matplotlib_render_plot_widget\n",
    "\n",
    "dDisplayItem = active_2d_plot.ui.dynamic_docked_widget_container.find_display_dock(identifier=name) # Dock\n",
    " # Already had the widget\n",
    "print(f'already had the valid pyqtgraph view widget and its display dock. Returning extant.')\n",
    "root_graphics_layout_widget = active_2d_plot.ui.matplotlib_view_widgets[name].getRootGraphicsLayoutWidget()\n",
    "plot_item = active_2d_plot.ui.matplotlib_view_widgets[name].getRootPlotItem() # PlotItem\n",
    "plot_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b5517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross hair\n",
    "vLine = pg.InfiniteLine(angle=90, movable=False)\n",
    "plot_item.addItem(vLine, ignoreBounds=True)\n",
    "\n",
    "vb = plot_item.vb\n",
    "\n",
    "def mouseMoved(evt):\n",
    "    \"\"\" captures: plot_item \n",
    "    \"\"\"\n",
    "    pos = evt[0]  ## using signal proxy turns original arguments into a tuple\n",
    "    if plot_item.sceneBoundingRect().contains(pos):\n",
    "        mousePoint = vb.mapSceneToView(pos)\n",
    "        # index = int(mousePoint.x())\n",
    "        # if index > 0 and index < len(data1):\n",
    "        leftSideToolbarWidget.crosshair_trace_time = mousePoint.x()\n",
    "            # label.setText(\"<span style='font-size: 12pt'>x=%0.1f,   <span style='color: red'>y1=%0.1f</span>,   <span style='color: green'>y2=%0.1f</span>\" % (mousePoint.x(), data1[index], data2[index]))\n",
    "        vLine.setPos(mousePoint.x())\n",
    "\n",
    "\n",
    "\n",
    "proxy = pg.SignalProxy(plot_item.scene().sigMouseMoved, rateLimit=60, slot=mouseMoved)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff77b54e",
   "metadata": {
    "tags": [
     "crosshairs",
     "active-2025-01-13"
    ]
   },
   "outputs": [],
   "source": [
    "@function_attributes(short_name=None, tags=['crosshairs', 'pyqtgraph'], input_requires=[], output_provides=[], uses=[], used_by=[], creation_date='2025-01-14 01:08', related_items=[])\n",
    "def update_trace_crosshairs(spike_raster_window):\n",
    "    \"\"\" adds a cross-hairs to the pyqtgraph plots\n",
    "    \n",
    "    \n",
    "    Captures: leftSideToolbarWidget\n",
    "    \n",
    "    \"\"\"\n",
    "    active_2d_plot = spike_raster_window.ui.active_2d_plot\n",
    "    leftSideToolbarWidget = spike_raster_window.ui.leftSideToolbarWidget\n",
    "    \n",
    "\n",
    "    #cross hair\n",
    "    name_modifier_suffix: str = 'raster_window'\n",
    "    name: str = f'rasters[{name_modifier_suffix}]'\n",
    "    # find_matplotlib_render_plot_widget\n",
    "\n",
    "    dDisplayItem = active_2d_plot.ui.dynamic_docked_widget_container.find_display_dock(identifier=name) # Dock\n",
    "    # Already had the widget\n",
    "    print(f'already had the valid pyqtgraph view widget and its display dock. Returning extant.')\n",
    "    root_graphics_layout_widget = active_2d_plot.ui.matplotlib_view_widgets[name].getRootGraphicsLayoutWidget()\n",
    "    plot_item = active_2d_plot.ui.matplotlib_view_widgets[name].getRootPlotItem() # PlotItem\n",
    "    plot_item\n",
    "\n",
    "    vLine = pg.InfiniteLine(angle=90, movable=False)\n",
    "    plot_item.addItem(vLine, ignoreBounds=True)\n",
    "    vb = plot_item.vb\n",
    "\n",
    "    def mouseMoved(evt):\n",
    "        \"\"\" captures: plot_item \n",
    "        \"\"\"\n",
    "        pos = evt[0]  ## using signal proxy turns original arguments into a tuple\n",
    "        if plot_item.sceneBoundingRect().contains(pos):\n",
    "            mousePoint = vb.mapSceneToView(pos)\n",
    "            # index = int(mousePoint.x())\n",
    "            # if index > 0 and index < len(data1):\n",
    "            leftSideToolbarWidget.crosshair_trace_time = mousePoint.x()\n",
    "                # label.setText(\"<span style='font-size: 12pt'>x=%0.1f,   <span style='color: red'>y1=%0.1f</span>,   <span style='color: green'>y2=%0.1f</span>\" % (mousePoint.x(), data1[index], data2[index]))\n",
    "            vLine.setPos(mousePoint.x())\n",
    "\n",
    "\n",
    "\n",
    "    proxy = pg.SignalProxy(plot_item.scene().sigMouseMoved, rateLimit=60, slot=mouseMoved)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f9c195",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "active_window_container_layout.setVisible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac66b8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_crosshairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a278c508",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = dict()\n",
    "_out['_display_plot_marginal_1D_most_likely_position_comparisons'] = curr_active_pipeline.display(display_function='_display_plot_marginal_1D_most_likely_position_comparisons', active_session_configuration_context=IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31',filter_name='maze_any',lap_dir='any')) # _display_plot_marginal_1D_most_likely_position_comparisons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f49880",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27df992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visible_event_intervals_added(added_rows):\n",
    "    print(f'visible_event_intervals_added(added_rows: {added_rows})')\n",
    "    spike_raster_window.bottom_playback_control_bar_logger.add_log_line(f'visible_event_intervals_added(added_rows: {added_rows})')\n",
    "    \n",
    "def visible_event_intervals_removed(removed_rows):\n",
    "    print(f'visible_event_intervals_removed(removed_rows: {removed_rows})')\n",
    "    spike_raster_window.bottom_playback_control_bar_logger.add_log_line(f'visible_event_intervals_removed(removed_rows: {removed_rows})')\n",
    "\n",
    "connections = {}\n",
    "connections['LiveWindowEventIntervalMonitoringMixin_entered'] = active_2d_plot.sigOnIntervalEnteredWindow.connect(visible_event_intervals_added)\n",
    "connections['LiveWindowEventIntervalMonitoringMixin_exited'] = active_2d_plot.sigOnIntervalExitedindow.connect(visible_event_intervals_removed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6218eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.Datasources.IntervalDatasource import IntervalsDatasource\n",
    "\n",
    "# get interval_datasource corresponding to the active epoch intervals\n",
    "# active_2d_plot.inter\n",
    "\n",
    "interval_info = active_2d_plot.list_all_rendered_intervals()\n",
    "# interval_info\n",
    "\n",
    "datasources: Dict[str, IntervalsDatasource] = {k:v for k, v in active_2d_plot.interval_datasources.data_items()}\n",
    "datasources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55bb1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "visible_intervals_info_widget_container, visible_intervals_ctrl_layout_widget =  spike_raster_window._perform_build_attached_visible_interval_info_widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bee295",
   "metadata": {},
   "outputs": [],
   "source": [
    "['sigRenderedIntervalsListChanged', 'sigRenderedIntervalsListChanged', 'sigRenderedIntervalsListChanged']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cedb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.set_right_sidebar_visibility(is_visible=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a37a1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "visible_intervals_info_widget_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afef131",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.on_window_update\n",
    "\n",
    "LiveWindowEventIntervalMonitoringMixin_on_window_update\n",
    "\n",
    "spike_raster_window.connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef58d723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spike_raster_window.bottom_playback_control_bar_logger.log_print('test')\n",
    "# spike_raster_window.bottom_playback_control_bar_logger.add_log_line('test')\n",
    "\n",
    "spike_raster_window.spike_raster_plt_2d.window_scrolled.connect(active_2d_plot.on_window_changed)\n",
    "\n",
    "\n",
    "# (next_start_timestamp, next_end_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d208ad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsWidgets.EpochsEditorItem import EpochsEditor # perform_plot_laps_diagnoser\n",
    "\n",
    "sess = global_session\n",
    "\n",
    "# pos_df = sess.compute_position_laps() # ensures the laps are computed if they need to be:\n",
    "position_obj = deepcopy(sess.position)\n",
    "position_obj.compute_higher_order_derivatives()\n",
    "pos_df = position_obj.compute_smoothed_position_info(N=20) ## Smooth the velocity curve to apply meaningful logic to it\n",
    "pos_df = position_obj.to_dataframe()\n",
    "# Drop rows with missing data in columns: 't', 'velocity_x_smooth' and 2 other columns. This occurs from smoothing\n",
    "pos_df = pos_df.dropna(subset=['t', 'x_smooth', 'velocity_x_smooth', 'acceleration_x_smooth']).reset_index(drop=True)\n",
    "curr_laps_df = sess.laps.to_dataframe()\n",
    "\n",
    "epochs_editor = EpochsEditor.init_laps_diagnoser(pos_df, curr_laps_df, include_velocity=True, include_accel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7b3ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.log_print('new_test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27c71c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.bottom_playback_control_bar_widget.log_print('newest_test')\n",
    "spike_raster_window.bottom_playback_control_bar_widget.log_print('new_test')\n",
    "# spike_raster_window.bottom_playback_control_bar_logger.log_print('new_test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2391a07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set stretch factors to control priority\n",
    "main_graphics_layout_widget.ci.layout.setRowStretchFactor(0, 1)  # Plot1: lowest priority\n",
    "main_graphics_layout_widget.ci.layout.setRowStretchFactor(1, 2)  # Plot2: medium priority\n",
    "\n",
    "main_plot_widget.setMinimumHeight(0.0)\n",
    "# Hide the first plot\n",
    "main_plot_widget.hide()  # This will make plot1 invisible but still part of the layout\n",
    "\n",
    "# main_plot_widget.setFixedHeight(20.0)\n",
    "# main_plot_widget.setHeight(20.0)\n",
    "# main_plot_widget.setMinimumHeight(0.0)\n",
    "background_static_scroll_window_plot.setMinimumHeight(50.0)\n",
    "background_static_scroll_window_plot.setMaximumHeight(75.0)\n",
    "# background_static_scroll_window_plot.setFixedHeight(50.0)\n",
    "\n",
    "\n",
    "active_2d_plot.params.use_docked_pyqtgraph_plots = True\n",
    "# Set stretch factors to control priority\n",
    "main_graphics_layout_widget.ci.layout.setRowStretchFactor(0, 1)  # Plot1: lowest priority\n",
    "main_graphics_layout_widget.ci.layout.setRowStretchFactor(1, 2)  # Plot2: mid priority\n",
    "main_graphics_layout_widget.ci.layout.setRowStretchFactor(2, 3)  # Plot3: highest priority\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c11afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, CustomCyclicColorsDockDisplayConfig, NamedColorScheme\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.Render2DScrollWindowPlot import Render2DScrollWindowPlotMixin\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import new_plot_raster_plot, NewSimpleRaster\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsObjects.CustomInfiniteLine import CustomInfiniteLine\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "\n",
    "dock_config = CustomCyclicColorsDockDisplayConfig(named_color_scheme=NamedColorScheme.grey, showCloseButton=True, corner_radius=0)\n",
    "name = f'background_static_scroll_timeline'\n",
    "background_static_scroll_time_sync_pyqtgraph_widget, background_static_scroll_root_graphics_layout_widget, background_static_scroll_plot_item = active_2d_plot.add_new_embedded_pyqtgraph_render_plot_widget(name=name, dockSize=(500, 120), display_config=dock_config)\n",
    "# _interval_tracks_out_dict[name] = (dock_config, background_static_scroll_time_sync_pyqtgraph_widget, background_static_scroll_root_graphics_layout_widget, background_static_scroll_plot_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72be32ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.plots_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9082a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Includes2DActiveWindowScatter\n",
    "active_2d_plot.plots.scatter_plot\n",
    "active_2d_plot.plots_data.all_spots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0c335b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "active_2d_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7277168f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def plot_test_spike_scatter_figure(self, defer_show = False):\n",
    "    \"\"\" plots a raster plot showing the first spike for each PBE for each cell (rows) relative to the first lap spike (t=0)\n",
    "    \n",
    "    test_obj: CellsFirstSpikeTimes = CellsFirstSpikeTimes.init_from_batch_hdf5_exports(first_spike_activity_data_h5_files=first_spike_activity_data_h5_files)\n",
    "    app, win, plots, plots_data = test_obj.plot_first_lap_spike_relative_first_PBE_spike_scatter_figure()\n",
    "    \n",
    "    \"\"\"\n",
    "    from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import new_plot_raster_plot, NewSimpleRaster\n",
    "    from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsObjects.CustomInfiniteLine import CustomInfiniteLine\n",
    "    import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "\n",
    "    ## INPUTS: active_config\n",
    "    # type(active_config.plotting_config.pf_colormap)\n",
    "    ## align to first lap spike (first_spike_lap)\n",
    "    self.all_cells_first_spike_time_df['lap_spike_relative_first_spike'] = self.all_cells_first_spike_time_df['first_spike_PBE'] - self.all_cells_first_spike_time_df['first_spike_lap']\n",
    "    # self.all_cells_first_spike_time_df['color'] = self.all_cells_first_spike_time_df['aclu'].map(lambda x: aclu_to_color_map.get(x, [1.0, 1.0, 0.0, 1.0]))\n",
    "    # column_names = ['first_spike_any', 'first_spike_theta', 'first_spike_lap', 'first_spike_PBE']\n",
    "\n",
    "    ## plot the spike timecourse:\n",
    "    # spike_scatter_kwargs = dict(s=25)\n",
    "\n",
    "    ## find extrema\n",
    "    # active_col_names = column_names\n",
    "    active_col_names = ['lap_spike_relative_first_spike', ]\n",
    "    earliest_first_spike_t: float = self.all_cells_first_spike_time_df[active_col_names].min(axis=0).min()\n",
    "    latest_first_spike_t: float = self.all_cells_first_spike_time_df[active_col_names].max(axis=0).max()\n",
    "    # ax.set_xlim(earliest_first_spike_t, latest_first_spike_t)\n",
    "\n",
    "\n",
    "    # _temp_active_spikes_df = deepcopy(test_obj.all_cells_first_spike_time_df)[['aclu', 'neuron_uid', 'lap_spike_relative_first_spike']].rename(columns={'lap_spike_relative_first_spike':'t_rel_seconds'})\n",
    "    _temp_active_spikes_df = deepcopy(self.all_cells_first_spike_time_df)[['neuron_uid', 'lap_spike_relative_first_spike']].rename(columns={'lap_spike_relative_first_spike':'t_rel_seconds'})\n",
    "    # Use pd.factorize to create new integer codes for 'neuron_uid'\n",
    "    _temp_active_spikes_df['aclu'], uniques = pd.factorize(_temp_active_spikes_df['neuron_uid'])\n",
    "    # Optionally, add 1 to start 'aclu' from 1 instead of 0\n",
    "    _temp_active_spikes_df['aclu'] = _temp_active_spikes_df['aclu'] + 1\n",
    "    # Now, 'aclu' contains unique integer IDs corresponding to 'neuron_uid'\n",
    "    print(_temp_active_spikes_df[['neuron_uid', 'aclu']].drop_duplicates())\n",
    "\n",
    "    _temp_active_spikes_df\n",
    "    # shared_aclus = deepcopy(_temp_active_spikes_df['neuron_uid'].unique())\n",
    "    shared_aclus = deepcopy(_temp_active_spikes_df['aclu'].unique())\n",
    "    shared_aclus\n",
    "    # Assuming _temp_active_spikes_df is your DataFrame\n",
    "\n",
    "\n",
    "    app, win, plots, plots_data = new_plot_raster_plot(_temp_active_spikes_df, shared_aclus, scatter_plot_kwargs=None,\n",
    "                                                        scatter_app_name=f'lap_spike_relative_first_spike_raster', defer_show=defer_show, active_context=None)\n",
    "\n",
    "    root_plot = plots['root_plot']\n",
    "    # Create a vertical line at x=3\n",
    "    v_line = CustomInfiniteLine(pos=0.0, angle=90, pen=pg.mkPen('r', width=2), label='first lap spike')\n",
    "    root_plot.addItem(v_line)\n",
    "    plots['v_line'] = v_line\n",
    "    \n",
    "    ## Set Labels\n",
    "    # plots['root_plot'].set_xlabel('First PBE spike relative to first lap spike (t=0)')\n",
    "    # plots['root_plot'].set_ylabel('Cell')\n",
    "    plots['root_plot'].setTitle(\"First PBE spike relative to first lap spike (t=0)\", color='white', size='24pt')\n",
    "    # plots['root_plot'].setLabel('top', 'First PBE spike relative to first lap spike (t=0)', size='22pt') # , color='blue'\n",
    "    plots['root_plot'].setLabel('left', 'Cell ID', color='white', size='12pt') # , units='V', color='red'\n",
    "    plots['root_plot'].setLabel('bottom', 'Time (relative to first lap spike for each cell)', color='white', units='s', size='12pt') # , color='blue'\n",
    "\n",
    "\n",
    "    return app, win, plots, plots_data\n",
    "\n",
    "\n",
    "app, win, plots, plots_data = new_plot_raster_plot(_temp_active_spikes_df, shared_aclus)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673b1333",
   "metadata": {
    "tags": [
     "active-2025-01-10"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['merged_directional_placefields', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring'], computation_kwargs_list=[{'laps_decoding_time_bin_size': 0.025}, {'time_bin_size': 0.025}, {'should_skip_radon_transform': True}, {}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "\n",
    "\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring'], computation_kwargs_list=[{'time_bin_size': 0.025}, {'should_skip_radon_transform': True}, {}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'], computation_kwargs_list=[{'time_bin_size': 0.058, 'should_disable_cache': False}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6108127e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['merged_directional_placefields', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs',], computation_kwargs_list=[{'laps_decoding_time_bin_size': 0.050}, {'time_bin_size': 0.050}, {'should_skip_radon_transform': True},], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3a36f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['merged_directional_placefields', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring'], computation_kwargs_list=[{'laps_decoding_time_bin_size': 0.025}, {'time_bin_size': 0.025}, {'should_skip_radon_transform': True}, {}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "\n",
    "\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring'], computation_kwargs_list=[{'time_bin_size': 0.025}, {'should_skip_radon_transform': True}, {}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'], computation_kwargs_list=[{'time_bin_size': 0.050, 'should_disable_cache': False}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4d8d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'], computation_kwargs_list=[{'time_bin_size': 0.250, 'should_disable_cache': False}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f78cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'], computation_kwargs_list=[{'time_bin_size': 0.100, 'should_disable_cache': False}], enabled_filter_names=None, fail_on_exception=True, debug_print=False) # 100ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0538565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'], computation_kwargs_list=[{'time_bin_size': 0.50, 'should_disable_cache': False}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eba1c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'], computation_kwargs_list=[{'time_bin_size': 0.025}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cc4048",
   "metadata": {
    "tags": [
     "active-2025-01-15",
     "directional_decoders_decode_continuous"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'], computation_kwargs_list=[{'time_bin_size': 0.025, 'should_disable_cache': False}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'], computation_kwargs_list=[{'time_bin_size': 0.050}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'], computation_kwargs_list=[{'time_bin_size': 0.075}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'], computation_kwargs_list=[{'time_bin_size': 0.100}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'], computation_kwargs_list=[{'time_bin_size': 0.250}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6a9140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'], computation_kwargs_list=[{'time_bin_size': 0.025}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'], computation_kwargs_list=[{'time_bin_size': 0.050}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'], computation_kwargs_list=[{'time_bin_size': 0.075}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'], computation_kwargs_list=[{'time_bin_size': 0.250}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'], computation_kwargs_list=[{'time_bin_size': 0.500}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'], computation_kwargs_list=[{'time_bin_size': 0.750}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c494eaa4",
   "metadata": {},
   "source": [
    "### <a id='toc8_1_1_'></a>[üî∂‚ùó 2025-01-15 - Lap Transition Matrix Analysis](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e61f50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalDecodersContinuouslyDecodedResult\n",
    "\n",
    "## Uses the `global_computation_results.computed_data['DirectionalDecodersDecoded']`\n",
    "directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "# all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "pseudo2D_decoder: BasePositionDecoder = directional_decoders_decode_result.pseudo2D_decoder\n",
    "\n",
    "# all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "continuously_decoded_pseudo2D_decoder_dict = directional_decoders_decode_result.continuously_decoded_pseudo2D_decoder_dict\n",
    "# continuously_decoded_result_cache_dict\n",
    "continuously_decoded_pseudo2D_decoder_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef79f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "global_session = curr_active_pipeline.filtered_sessions[global_epoch_name]\n",
    "\n",
    "# global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps) # .trimmed_to_non_overlapping()\n",
    "global_laps_epochs_df = global_laps.to_dataframe()\n",
    "# active_test_epochs_df: pd.DataFrame = deepcopy(global_laps_epochs_df)\n",
    "global_laps_epochs_df\n",
    "debug_print = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262a657a",
   "metadata": {
    "tags": [
     "active-2025-01-14",
     "lap-decoder-correctness"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import find_epochs_overlapping_other_epochs\n",
    "\n",
    "## INPUTS: global_laps\n",
    "_out_split_pseudo2D_posteriors_dict = {}\n",
    "_out_split_pseudo2D_out_dict = {}\n",
    "pre_filtered_col_names = ['pre_filtered_most_likely_position_indicies', 'pre_filtered_most_likely_position'] # 'pre_filtered_time_bin_containers', 'pre_filtered_p_x_given_n', \n",
    "post_filtered_col_names = [a_col_name.removeprefix('pre_filtered_') for a_col_name in pre_filtered_col_names] # ['time_bin_containers', 'most_likely_position_indicies', 'most_likely_position']\n",
    "print(post_filtered_col_names)\n",
    "for a_time_bin_size, pseudo2D_decoder_continuously_decoded_result in continuously_decoded_pseudo2D_decoder_dict.items():\n",
    "    print(f'a_time_bin_size: {a_time_bin_size}')\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size] = {'pre_filtered_p_x_given_n': None, 'pre_filtered_time_bin_containers': None, 'pre_filtered_most_likely_position_indicies': None, 'pre_filtered_most_likely_position': None, \n",
    "                                                     'is_timebin_included': None, 'p_x_given_n': None} # , 'time_window_centers': None\n",
    "    # pseudo2D_decoder_continuously_decoded_result: DecodedFilterEpochsResult = continuously_decoded_dict.get('pseudo2D', None)\n",
    "    assert len(pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list) == 1\n",
    "    p_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0]\n",
    "    # p_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0]['p_x_given_n']\n",
    "    time_bin_containers = pseudo2D_decoder_continuously_decoded_result.time_bin_containers[0]\n",
    "    # time_window_centers = time_bin_containers.centers\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position_indicies'] = deepcopy(pseudo2D_decoder_continuously_decoded_result.most_likely_position_indicies_list[0])\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position'] = deepcopy(pseudo2D_decoder_continuously_decoded_result.most_likely_positions_list[0])\n",
    "    ## INPUTS: time_bin_containers, global_laps\n",
    "    left_edges = deepcopy(time_bin_containers.left_edges)\n",
    "    right_edges = deepcopy(time_bin_containers.right_edges)\n",
    "    continuous_time_binned_computation_epochs_df: pd.DataFrame = pd.DataFrame({'start': left_edges, 'stop': right_edges, 'label': np.arange(len(left_edges))})\n",
    "    is_timebin_included: NDArray = find_epochs_overlapping_other_epochs(epochs_df=continuous_time_binned_computation_epochs_df, epochs_df_required_to_overlap=deepcopy(global_laps))\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_p_x_given_n'] = p_x_given_n\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_time_bin_containers'] = time_bin_containers\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['is_timebin_included'] = is_timebin_included\n",
    "    continuous_time_binned_computation_epochs_df['is_in_laps'] = is_timebin_included\n",
    "    ## filter by whether it's included or not:\n",
    "    p_x_given_n = p_x_given_n[:, :, is_timebin_included]\n",
    "    # time_window_centers = \n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['p_x_given_n'] = p_x_given_n\n",
    "    # _out_split_pseudo2D_out_dict[a_time_bin_size]['time_window_centers'] = time_window_centers[is_timebin_included]\n",
    "    # p_x_given_n.shape # (62, 4, 209389)\n",
    "\n",
    "    ## Split across the 2nd axis to make 1D posteriors that can be displayed in separate dock rows:\n",
    "    assert p_x_given_n.shape[1] == 4, f\"expected the 4 pseudo-y bins for the decoder in p_x_given_n.shape[1]. but found p_x_given_n.shape: {p_x_given_n.shape}\"\n",
    "    # split_pseudo2D_posteriors_dict = {k:np.squeeze(p_x_given_n[:, i, :]) for i, k in enumerate(('long_LR', 'long_RL', 'short_LR', 'short_RL'))}\n",
    "    _out_split_pseudo2D_posteriors_dict[a_time_bin_size] = deepcopy(p_x_given_n)\n",
    "    \n",
    "    # for a_col_name in pre_filtered_col_names:\n",
    "    #     filtered_col_name = a_col_name.removeprefix('pre_filtered_')\n",
    "    #     print(f'a_col_name: {a_col_name}, filtered_col_name: {filtered_col_name}, shape: {np.shape(_out_split_pseudo2D_out_dict[a_time_bin_size][a_col_name])}')\n",
    "    #     _out_split_pseudo2D_out_dict[a_time_bin_size][filtered_col_name] = _out_split_pseudo2D_out_dict[a_time_bin_size][a_col_name][is_timebin_included, :]\n",
    "        \n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['most_likely_position_indicies'] = _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position_indicies'][:, is_timebin_included]\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['most_likely_position'] = _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position'][is_timebin_included, :]\n",
    "    \n",
    "\n",
    "p_x_given_n.shape # (n_position_bins, n_decoding_models, n_time_bins) - (57, 4, 29951)\n",
    "\n",
    "## OUTPUTS: _out_split_pseudo2D_posteriors_dict, _out_split_pseudo2D_out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54de7c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo2D_decoder_continuously_decoded_result.most_likely_position_indicies_list[0].shape # (2, 6948)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b07b5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_timebin_included\n",
    "\n",
    "_out_split_pseudo2D_out_dict_p_x_given_x = {k:v['pre_filtered_p_x_given_n'] for k, v in _out_split_pseudo2D_out_dict.items()}\n",
    "_out_split_pseudo2D_out_dict_p_x_given_x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac9ce67",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_time_binned_computation_epochs_df = continuous_time_binned_computation_epochs_df[continuous_time_binned_computation_epochs_df['is_in_laps']].drop(columns=['is_in_laps'])\n",
    "continuous_time_binned_computation_epochs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb2cce2",
   "metadata": {
    "tags": [
     "lap-decoder-correctness",
     "active-2025-01-14"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import build_position_by_decoder_transition_matrix, plot_blocked_transition_matrix\n",
    "from neuropy.utils.matplotlib_helpers import perform_update_title_subtitle\n",
    "\n",
    "## INPUTS: _out_split_pseudo2D_posteriors_dict\n",
    "a_time_bin_size: float = 0.025\n",
    "# a_time_bin_size: float = 0.050\n",
    "# a_time_bin_size: float = 0.058\n",
    "# a_time_bin_size: float = 0.250\n",
    "# a_time_bin_size: float = 0.500\n",
    "# a_time_bin_size: float = 0.750\n",
    "\n",
    "print(f'{list(_out_split_pseudo2D_posteriors_dict.keys())}')\n",
    "\n",
    "p_x_given_n = _out_split_pseudo2D_posteriors_dict[a_time_bin_size]\n",
    "is_timebin_included = _out_split_pseudo2D_out_dict[a_time_bin_size]['is_timebin_included']\n",
    "pre_filtered_p_x_given_n = _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_p_x_given_n']\n",
    "pre_filtered_time_bin_containers = _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_time_bin_containers']\n",
    "pre_filtered_most_likely_position_indicies = _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position_indicies']\n",
    "most_likely_position_indicies = _out_split_pseudo2D_out_dict[a_time_bin_size]['most_likely_position_indicies']\n",
    "\n",
    "\n",
    "did_change = np.diff(is_timebin_included, n=1)\n",
    "split_indicies = np.where(did_change)[0] + 1 # the +1 compensates for the 0-based nature of the indicies, indicating we want to split BEFORE the specified index\n",
    "\n",
    "# lap_split_p_x_given_n_list = np.split(p_x_given_n, split_indicies, axis=-1) # split along the time-bin axis (-1)\n",
    "lap_split_p_x_given_n_list: List[NDArray] = np.split(pre_filtered_p_x_given_n, split_indicies, axis=-1) # split along the time-bin axis (-1)\n",
    "# lap_split_p_x_given_n_list\n",
    "\n",
    "pre_filtered_most_likely_position_indicies_x = np.squeeze(pre_filtered_most_likely_position_indicies[0, :])\n",
    "most_likely_position_indicies_x = np.squeeze(most_likely_position_indicies[0, :])\n",
    "# most_likely_position_indicies_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a451d8",
   "metadata": {
    "tags": [
     "active-2025-01-14"
    ]
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6)); sns.histplot(pre_filtered_most_likely_position_indicies_x); perform_update_title_subtitle(title_string=f\"hist: pre_filtered_most_likely_position_indicies_x - t_bin: {a_time_bin_size}\"); plt.show();\n",
    "plt.figure(figsize=(8,6)); sns.histplot(most_likely_position_indicies_x); perform_update_title_subtitle(title_string=f\"hist: most_likely_position_indicies_x - t_bin: {a_time_bin_size}\"); plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7047e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bdc38a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97068bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: p_x_given_n\n",
    "n_position_bins, n_decoding_models, n_time_bins = p_x_given_n.shape\n",
    "\n",
    "out_tuples = [build_position_by_decoder_transition_matrix(a_p_x_given_n) for a_p_x_given_n in lap_split_p_x_given_n_list]\n",
    "\n",
    "A_position = [v[0] for i, v in enumerate(out_tuples) if (i % 2 == 1)]\n",
    "A_model = [v[1] for i, v in enumerate(out_tuples) if (i % 2 == 1)]\n",
    "A_big = [v[2] for i, v in enumerate(out_tuples) if (i % 2 == 1)]\n",
    "\n",
    "len(A_position)\n",
    "A_position[0].shape\n",
    "A_position[1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6f85c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import TransitionMatrixComputations\n",
    "\n",
    "# Visualization ______________________________________________________________________________________________________ #\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow, LayoutScrollability\n",
    "\n",
    "binned_x_transition_matrix_higher_order_list_dict: Dict[types.DecoderName, NDArray] = track_templates.compute_decoder_transition_matricies(n_powers=3)\n",
    "out = TransitionMatrixComputations.plot_transition_matricies(decoders_dict=track_templates.get_decoders_dict(), binned_x_transition_matrix_higher_order_list_dict=binned_x_transition_matrix_higher_order_list_dict)\n",
    "# out\n",
    "\n",
    "\n",
    "# binned_x_transition_matrix_higher_order_list_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd46da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_position_overall = np.sum(np.stack(A_position), axis=0) #.shape # (81, 57, 57)\n",
    "# A_position_overall.shape\n",
    "plt.figure(figsize=(8,6)); sns.heatmap(A_position_overall, cmap='viridis'); perform_update_title_subtitle(title_string=f\"Transition Matrix A_position_overall - t_bin: {a_time_bin_size}\"); plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e35175",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(A_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c839b638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example data: linear array\n",
    "# data = [np.random.rand(10, 10) for _ in range(12)]  # 12 heatmaps of size 10x10\n",
    "data = A_position[:20]\n",
    "columns = 5  # Number of columns in the grid\n",
    "\n",
    "# Compute grid dimensions\n",
    "rows = -(-len(data) // columns)  # Ceiling division for number of rows\n",
    "print(f'rows: {rows}, columns: {columns}')\n",
    "\n",
    "# Plot the grid\n",
    "fig, axes = plt.subplots(rows, columns, figsize=(15, 3 * rows))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < len(data):\n",
    "        heatmap = data[i]\n",
    "        # im = ax.imshow(heatmap, cmap='viridis')\n",
    "        sns.heatmap(heatmap, cmap='viridis', ax=ax) ## position\n",
    "        ax.set_title(f\"Heatmap {i + 1}\")\n",
    "    else:\n",
    "        ax.axis('off')  # Turn off unused axes\n",
    "\n",
    "# fig.colorbar(im, ax=axes, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f09b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\"D\" is E\"pic\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ed76ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_position, A_model, A_big = build_position_by_decoder_transition_matrix(p_x_given_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42247a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# plt.figure(figsize=(8,6)); sns.heatmap(A_big, cmap='viridis'); plt.title(\"Transition Matrix A_big\"); plt.show()\n",
    "plt.figure(figsize=(8,6)); sns.heatmap(A_position, cmap='viridis'); perform_update_title_subtitle(title_string=f\"Transition Matrix A_position - t_bin: {a_time_bin_size}\"); plt.show(); \n",
    "plt.figure(figsize=(8,6)); sns.heatmap(A_model, cmap='viridis'); perform_update_title_subtitle(title_string=f\"Transition Matrix A_model - t_bin: {a_time_bin_size}\"); plt.show()\n",
    "\n",
    "_out = plot_blocked_transition_matrix(A_big, n_position_bins, n_decoding_models, extra_title_suffix=f' - t_bin: {a_time_bin_size}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20a4491",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuously_decoded_result_cache_dict[0.025]['pseudo2D'] # DecodedFilterEpochsResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844ed827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @function_attributes(short_name=None, tags=['intervals', 'tracks', 'pyqtgraph'], input_requires=[], output_provides=[], uses=[], used_by=[], creation_date='2024-12-31 07:29', related_items=[])\n",
    "# def prepare_pyqtgraph_intervalPlot_tracks(active_2d_plot, enable_interval_overview_track: bool = False):\n",
    "#     \"\"\" adds to separate pyqtgraph-backed tracks to the SpikeRaster2D plotter for rendering intervals, and updates `active_2d_plot.params.custom_interval_rendering_plots` so the intervals are rendered on these new tracks in addition to any normal ones\n",
    "    \n",
    "#     enable_interval_overview_track: bool: if True, renders a track to show all the intervals during the sessions (overview) in addition to the track for the intervals within the current active window\n",
    "    \n",
    "#     Updates:\n",
    "#         active_2d_plot.params.custom_interval_rendering_plots\n",
    "        \n",
    "        \n",
    "#     \"\"\"\n",
    "#     from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, CustomCyclicColorsDockDisplayConfig, NamedColorScheme\n",
    "\n",
    "#     _interval_tracks_out_dict = {}\n",
    "#     if enable_interval_overview_track:\n",
    "#         dock_config = CustomCyclicColorsDockDisplayConfig(named_color_scheme=NamedColorScheme.grey, showCloseButton=True, corner_radius=0)\n",
    "#         intervals_overview_time_sync_pyqtgraph_widget, intervals_overview_root_graphics_layout_widget, intervals_overview_plot_item = active_2d_plot.add_new_embedded_pyqtgraph_render_plot_widget(name='interval_overview', dockSize=(500, 60), display_config=dock_config)\n",
    "#         _interval_tracks_out_dict['interval_overview'] = (dock_config, intervals_overview_time_sync_pyqtgraph_widget, intervals_overview_root_graphics_layout_widget, intervals_overview_plot_item)\n",
    "#     ## Enables creating a new pyqtgraph-based track to display the intervals/epochs\n",
    "#     interval_window_dock_config = CustomCyclicColorsDockDisplayConfig(named_color_scheme=NamedColorScheme.grey, showCloseButton=True, corner_radius=0)\n",
    "#     intervals_time_sync_pyqtgraph_widget, intervals_root_graphics_layout_widget, intervals_plot_item = active_2d_plot.add_new_embedded_pyqtgraph_render_plot_widget(name='intervals', dockSize=(500, 40), display_config=interval_window_dock_config)\n",
    "#     active_2d_plot.params.custom_interval_rendering_plots = [active_2d_plot.plots.background_static_scroll_window_plot, active_2d_plot.plots.main_plot_widget, intervals_plot_item]\n",
    "#     # active_2d_plot.params.custom_interval_rendering_plots = [active_2d_plot.plots.background_static_scroll_window_plot, active_2d_plot.plots.main_plot_widget, intervals_plot_item, intervals_overview_plot_item]\n",
    "#     if enable_interval_overview_track:\n",
    "#         active_2d_plot.params.custom_interval_rendering_plots.append(intervals_overview_plot_item)\n",
    "        \n",
    "#     # active_2d_plot.interval_rendering_plots\n",
    "#     main_plot_widget = active_2d_plot.plots.main_plot_widget # PlotItem\n",
    "#     intervals_plot_item.setXLink(main_plot_widget) # works to synchronize the main zoomed plot (current window) with the epoch_rect_separate_plot (rectangles plotter)\n",
    "    \n",
    "#     _interval_tracks_out_dict['intervals'] = (interval_window_dock_config, intervals_time_sync_pyqtgraph_widget, intervals_root_graphics_layout_widget, intervals_plot_item)\n",
    "#     ## #TODO 2024-12-31 07:20: - [ ] need to clear/re-add the epochs to make this work\n",
    "#     return _interval_tracks_out_dict\n",
    "\n",
    "\n",
    "_interval_tracks_out_dict = active_2d_plot.prepare_pyqtgraph_intervalPlot_tracks(enable_interval_overview_track=False, name_modifier_suffix='_bottom')\n",
    "interval_window_dock_config, intervals_time_sync_pyqtgraph_widget, intervals_root_graphics_layout_widget, intervals_plot_item = _interval_tracks_out_dict['intervals_bottom']\n",
    "# dock_config, intervals_overview_time_sync_pyqtgraph_widget, intervals_overview_root_graphics_layout_widget, intervals_overview_plot_item = _interval_tracks_out_dict['interval_overview']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3887ba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_time_sync_pyqtgraph_widget.geometry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fcc0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_container_parent_widget = intervals_time_sync_pyqtgraph_widget.parent()\n",
    "_container_parent_widget.geometry() # PyQt5.QtCore.QRect(12, 0, 1841, 69)\n",
    "_container_parent_widget.layout().setContentsMargins(0, 0, 0, 0)\n",
    "_container_parent_widget.geometry()\n",
    "_container_parent_widget.setGeometry(0, 0, 1853, 69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f4035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dock_parent = intervals_time_sync_pyqtgraph_widget.parent().parent() # Dock  \n",
    "dock_parent.geometry() # PyQt5.QtCore.QRect(0, 363, 1853, 69)\n",
    "dock_parent.layout.setContentsMargins(0, 0, 0, 0)\n",
    "dock_parent.layout.geometry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36665a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout = intervals_time_sync_pyqtgraph_widget.ui.layout\n",
    "layout\n",
    "layout.setContentsMargins(0, 0, 0, 0)\n",
    "layout.geometry()\n",
    "# self.ui.root_vbox.setContentsMargins(0, 0, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9716c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_root_graphics_layout_widget.getContentsMargins()\n",
    "intervals_root_graphics_layout_widget.geometry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c1aeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.list_all_rendered_intervals(debug_print=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c192dd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extant_rendered_interval_plots_lists = {k:list(v.keys()) for k, v in active_2d_plot.list_all_rendered_intervals(debug_print=False).items()}\n",
    "# active_target_interval_render_plots = active_2d_plot.params.custom_interval_rendering_plots\n",
    "\n",
    "# active_target_interval_render_plots = [v.objectName() for v in active_2d_plot.interval_rendering_plots]\n",
    "active_target_interval_render_plots_dict = {v.objectName():v for v in active_2d_plot.interval_rendering_plots}\n",
    "active_target_interval_render_plots_dict\n",
    "extant_rendered_interval_plots_lists\n",
    "\n",
    "for a_name in active_2d_plot.interval_datasource_names:\n",
    "    a_ds =  active_2d_plot.interval_datasources[a_name]\n",
    "    an_already_added_plot_list = extant_rendered_interval_plots_lists[a_name]\n",
    "    print(f'a_name: {a_name}\\n\\tan_already_added_plot_list: {an_already_added_plot_list}')\n",
    "    extant_already_added_plots = {k:v for k, v in active_target_interval_render_plots_dict.items() if k in an_already_added_plot_list}\n",
    "    extant_already_added_plots_list = list(extant_already_added_plots.values())\n",
    "    remaining_new_plots = {k:v for k, v in active_target_interval_render_plots_dict.items() if k not in an_already_added_plot_list}\n",
    "    remaining_new_plots_list = list(remaining_new_plots.values())\n",
    "    # remaining_new_plots_list\n",
    "    \n",
    "    # active_2d_plot.remove_rendered_intervals(name=a_name, child_plots_removal_list=extant_already_added_plots_list)\n",
    "    active_2d_plot.add_rendered_intervals(interval_datasource=a_ds, name=a_name, child_plots=remaining_new_plots_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9919445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_2d_plot.add_rendered_intervals\n",
    "\n",
    "\n",
    "intervals_plot_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2296af",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.clear_all_rendered_intervals()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d998e8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Manually call `AddNewDecodedEpochMarginal_MatplotlibPlotCommand` to add the custom marginals track to the active SpikeRaster3DWindow\n",
    "# list(curr_active_pipeline.display_output.keys())\n",
    "\n",
    "# active_display_fn_identifying_ctx = IdentifyingContext(format_name= 'kdiba', animal= 'gor01', exper_name= 'one', session_name= '2006-6-09_1-22-43', filter_name= 'maze_any', lap_dir= 'any', display_fn_name= 'display_spike_rasters_window')\n",
    "active_display_fn_identifying_ctx = IdentifyingContext(format_name= 'kdiba', animal= 'gor01', exper_name= 'one', session_name= '2006-6-09_1-22-43', filter_name= 'maze_any', lap_dir= 'any', display_fn_name= '_display_spike_rasters_pyqtplot_2D')\n",
    "display_output = curr_active_pipeline.display_output[active_display_fn_identifying_ctx]\n",
    "display_output\n",
    "# active_config_name: str = 'maze_any'\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "active_config_name: str = global_epoch_name # 'maze_any'\n",
    "active_config_name\n",
    "## INPUTS: active_config_name, active_display_fn_identifying_ctx, display_output\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import AddNewDecodedEpochMarginal_MatplotlibPlotCommand\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalDecodersContinuouslyDecodedResult\n",
    "\n",
    "# output_references = _build_additional_window_menus(spike_raster_window, owning_pipeline_reference, computation_result, active_display_fn_identifying_ctx)\n",
    "# _docked_menu_provider.DockedWidgets_MenuProvider_on_buildUI(spike_raster_window=spike_raster_window, owning_pipeline_reference=owning_pipeline_reference, context=active_display_fn_identifying_ctx, active_config_name=active_config_name, display_output=owning_pipeline_reference.display_output[active_display_fn_identifying_ctx])\n",
    "\n",
    "_cmd = AddNewDecodedEpochMarginal_MatplotlibPlotCommand(spike_raster_window, curr_active_pipeline,\n",
    "                                                         active_config_name=active_config_name, active_context=active_display_fn_identifying_ctx, display_output=display_output, action_identifier='actionContinuousPseudo2DDecodedMarginalsDockedMatplotlibView')\n",
    "_cmd\n",
    "\n",
    "# ## To begin, the destination plot must have a matplotlib widget plot to render to:\n",
    "# # print(f'AddNewDecodedEpochMarginal_MatplotlibPlotCommand.execute(...)')\n",
    "# active_2d_plot = _cmd._spike_raster_window.spike_raster_plt_2d\n",
    "# enable_rows_config_kwargs = dict(enable_non_marginalized_raw_result=_cmd.enable_non_marginalized_raw_result, enable_marginal_over_direction=_cmd.enable_marginal_over_direction, enable_marginal_over_track_ID=_cmd.enable_marginal_over_track_ID)\n",
    "\n",
    "# # output_dict = self.add_pseudo2D_decoder_decoded_epoch_marginals(self._active_pipeline, active_2d_plot, **enable_rows_config_kwargs)\n",
    "# output_dict = AddNewDecodedEpochMarginal_MatplotlibPlotCommand.add_all_computed_time_bin_sizes_pseudo2D_decoder_decoded_epoch_marginals(_cmd._active_pipeline, active_2d_plot, **enable_rows_config_kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d55afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _cmd.prepare_and_perform_add_pseudo2D_decoder_decoded_epoch_marginals(curr_active_pipeline=curr_active_pipeline\n",
    "                                                                      \n",
    "# output_dict = _cmd.add_pseudo2D_decoder_decoded_epoch_marginals(_cmd._active_pipeline, active_2d_plot)\n",
    "# output_dict = _cmd.add_pseudo2D_decoder_decoded_epoch_marginals(_cmd._active_pipeline, active_2d_plot=active_2d_plot)\n",
    "_cmd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bde81a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_continuously_decoded_result_cache_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4af62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "# directional_decoders_decode_result\n",
    "continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "continuously_decoded_result_cache_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224a84a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_time_bin_sizes_output_dict['non_marginalized_raw_result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c68acab",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6fa935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_2d_plot.params.use_docked_pyqtgraph_plots\n",
    "use_docked_pyqtgraph_plots: bool = active_2d_plot.params.setdefault('use_docked_pyqtgraph_plots', True)\n",
    "use_docked_pyqtgraph_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7c21a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_time_sync_pyqtgraph_widget, root_graphics_layout_widget, plot_item = active_2d_plot.add_new_embedded_pyqtgraph_render_plot_widget(name='test_pyqtgraph_view_widget', dockSize=(500,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c43f48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## most recent only:\n",
    "time_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\n",
    "if debug_print:\n",
    "    print(f'time_bin_size: {time_bin_size}')\n",
    "\n",
    "info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "\n",
    "most_recent_continuously_decoded_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(directional_decoders_decode_result.most_recent_continuously_decoded_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d209cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.plots.preview_overview_scatter_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137ef140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599f3885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7681a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.Render2DScrollWindowPlot import Render2DScrollWindowPlotMixin\n",
    "\n",
    "active_2d_plot.plots.background_static_scroll_window_plot = active_2d_plot.ScrollRasterPreviewWindow_on_BuildUI(active_2d_plot.plots.background_static_scroll_window_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79eb5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.params.scroll_window_plot_downsampling_rate = 200 #.preview_overview_scatter_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232e74ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_x_min, curr_x_max, curr_y_min, curr_y_max = active_2d_plot.get_render_intervals_plot_range()\n",
    "curr_y_min, curr_y_max # (-4.513488936201152, 108.50378019833708)\n",
    "\n",
    "min_required_height_for_epochs: float = (curr_y_max - curr_y_min)\n",
    "min_required_height_for_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db5baa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_info = active_2d_plot.list_all_rendered_intervals()\n",
    "interval_info_dict = active_2d_plot.get_all_rendered_intervals_dict()\n",
    "interval_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f870e7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.clear_all_rendered_intervals()\n",
    "# active_2d_plot.remove_rendered_intervals(name='PBEs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c25b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_rects_item = interval_info_dict['Replays']['main_plot_widget'] # IntervalRectsItem \n",
    "replay_rects_item.height()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234d20b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.update_rendered_interval_heights(absolute_combined_height_px=40.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a184707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "active_2d_plot.update_rendered_intervals_visualization_properties(scaled_epochs_update_dict)\n",
    "# active_2d_plot.update_rendered_intervals_visualization_properties(epochs_update_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b6be90",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.rendered_epochs\n",
    "active_2d_plot.get_all_rendered_intervals_dict()\n",
    "active_2d_plot.list_all_rendered_intervals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc69c336",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_series_positioning_dfs, all_series_compressed_positioning_dfs, all_series_compressed_positioning_update_dicts = active_2d_plot.recover_interval_datasources_update_dict_properties()\n",
    "# all_series_positioning_dfs\n",
    "# all_series_compressed_positioning_dfs\n",
    "\n",
    "# all_series_positioning_dfs\n",
    "all_series_compressed_positioning_update_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5081f84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_series_compressed_positioning_update_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79209038",
   "metadata": {},
   "outputs": [],
   "source": [
    "scroll_window_plot_downsampling_rate: int = active_2d_plot.params.setdefault('scroll_window_plot_downsampling_rate', 200)\n",
    "scroll_window_plot_downsampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4943285",
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_overview_scatter_plot: pg.ScatterPlotItem  = active_2d_plot.plots.preview_overview_scatter_plot # ScatterPlotItem \n",
    "# preview_overview_scatter_plot.setDownsampling(auto=True, method='subsample', dsRate=10)\n",
    "main_graphics_layout_widget: pg.GraphicsLayoutWidget = active_2d_plot.ui.main_graphics_layout_widget\n",
    "wrapper_layout: pg.QtWidgets.QVBoxLayout = active_2d_plot.ui.wrapper_layout\n",
    "main_content_splitter = active_2d_plot.ui.main_content_splitter # QSplitter\n",
    "layout = active_2d_plot.ui.layout\n",
    "\n",
    "# wrapper_layout\n",
    "main_content_splitter.geometry()\n",
    "main_content_splitter.getContentsMargins()\n",
    "main_content_splitter.size()\n",
    "# main_content_splitter.\n",
    "background_static_scroll_window_plot = active_2d_plot.plots.background_static_scroll_window_plot # PlotItem \n",
    "# background_static_scroll_window_plot.removeItem(preview_overview_scatter_plot)\n",
    "background_static_scroll_window_plot.geometry() # PyQt5.QtCore.QRectF(9.0, 529.0457142857142, 1835.0, 427.9542857142857)\n",
    "background_static_scroll_window_plot.setMinimumHeight(50.0)\n",
    "background_static_scroll_window_plot.setFixedHeight(50.0)\n",
    "background_static_scroll_window_plot.geometry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50f8ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_static_scroll_window_plot.setFixedHeight(50.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94accb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot = spike_raster_window.spike_raster_plt_2d\n",
    "active_2d_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5b3903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe09c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc99f955",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_static_scroll_plot_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b569a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.rendered_epoch_series_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83fe8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.menu_action_history_list # ['Directionaldecodedepochsdockedmatplotlibview', 'Directionaldecodedepochsdockedmatplotlibview', 'Pseudo2ddecodedepochsdockedmatplotlibview']\n",
    "# ['DirectionalDecodedEpochsDockedMatplotlibView', 'DirectionalDecodedEpochsDockedMatplotlibView', 'Pseudo2DDecodedEpochsDockedMatplotlibView']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a96c5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.menu_action_history_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6ce217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(list(active_2d_plot.list_all_rendered_intervals().keys()))\n",
    "\n",
    "# interval_info = active_2d_plot.list_all_rendered_intervals()\n",
    "for series_name, series_datasource in interval_info.items():\n",
    "    print(f'series_name: {series_name}')\n",
    "    print(f'\\tseries_datasource: {series_datasource}')\n",
    "# print_keys_if_possible('interval_info', interval_info, max_depth=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caf7024",
   "metadata": {
    "tags": [
     "active-2024-12-19"
    ]
   },
   "outputs": [],
   "source": [
    "# active_2d_plot.start_t\n",
    "# active_2d_plot.animation_active_time_window\n",
    "included_series_names=['Replays', 'Laps', 'PBEs']\n",
    "active_2d_plot.find_event_intervals_in_active_window(included_series_names=included_series_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea2247e",
   "metadata": {},
   "outputs": [],
   "source": [
    "included_series_names=active_2d_plot.rendered_epoch_series_names\n",
    "included_series_names\n",
    "active_2d_plot.find_event_intervals_in_active_window(included_series_names=included_series_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72617113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fed29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the events/intervals that are within the currently active render window:\n",
    "## Get current time window:\n",
    "curr_time_window = active_2d_plot.animation_active_time_window.active_time_window # (45.12114057149739, 60.12114057149739)\n",
    "start_t, end_t = curr_time_window\n",
    "print(f'curr_time_window: {curr_time_window}')\n",
    "\n",
    "active_window_series_events_dict: Dict[str, pd.DataFrame] = {}\n",
    "for series_name, series_datasource in get_dict_subset(active_2d_plot.interval_datasources, included_keys=active_2d_plot.rendered_epoch_series_names, require_all_keys=True).items():\n",
    "    print(f'series_name: {series_name}, series_datasource: {series_datasource}')\n",
    "    # active_df = series_datasource.df\n",
    "    # active_df['t_start']\n",
    "    active_df = series_datasource.get_updated_data_window(new_start=start_t, new_end=end_t)\n",
    "    # series_datasource.time_column_values\n",
    "    active_window_series_events_dict[series_name] = active_df\n",
    "    # .active_windowed_df\n",
    "    \n",
    "active_window_series_events_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824fc22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spike_raster_window.spikes_window.start\n",
    "\n",
    "# interval_datasources = active_2d_plot.interval_datasources\n",
    "# interval_datasources\n",
    "\n",
    "# active_2d_plot.rendered_epoch_series_names\n",
    "# curr_time_window = active_2d_plot.animation_active_time_window.active_time_window\n",
    "\n",
    "_out_intervals_within_active_window = active_2d_plot.find_intervals_in_active_window()\n",
    "_out_intervals_within_active_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e18acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_target_jump_times_dict = active_2d_plot.find_next_jump_intervals_in_active_window(is_jump_left=True) # {'Replays': 633.6662150828633, 'Laps': 584.5415960000828, 'SessionEpochs': 0.0}\n",
    "prev_target_jump_times_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079c9b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_target_jump_times_dict = active_2d_plot.find_next_jump_intervals_in_active_window(is_jump_left=False) # {'Replays': 1736.8927964709, 'Laps': 1652.750230000005, 'SessionEpochs': 1029.316608761903}\n",
    "next_target_jump_times_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84e2a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform_restore_renderables\n",
    "curr_start_time: float = spike_raster_window.animation_active_time_window.active_window_start_time\n",
    "curr_end_time: float = spike_raster_window.animation_active_time_window.active_window_start_time + spike_raster_window.animation_active_time_window.window_duration\n",
    "curr_start_time\n",
    "curr_end_time\n",
    "bottomPlaybackControlBarWidget = spike_raster_window.ui.bottomPlaybackControlBarWidget\n",
    "bottomPlaybackControlBarWidget.ui.doubleSpinBox_ActiveWindowStartTime.setValue(curr_start_time)\n",
    "bottomPlaybackControlBarWidget.ui.doubleSpinBox_ActiveWindowEndTime.setValue(curr_end_time)\n",
    "\n",
    "\n",
    "bottomPlaybackControlBarWidget.on_window_changed(curr_start_time, curr_end_time)\n",
    "\n",
    "curr_end_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfec5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.enable_interaction_events_debug_print = False\n",
    "spike_raster_window.enable_debug_print = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48bc0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottomPlaybackControlBarWidget = spike_raster_window.ui.bottomPlaybackControlBarWidget\n",
    "\n",
    "# are_controls_editable: bool = False\n",
    "are_controls_editable: bool = True\n",
    "bottomPlaybackControlBarWidget.on_start_end_doubleSpinBox_edit_mode_changed(are_controls_editable=are_controls_editable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e319843b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doubleSpinBox_ActiveWindowEndTime\n",
    "# doubleSpinBox_ActiveWindowStartTime\n",
    "bottomPlaybackControlBarWidget.ui.doubleSpinBox_ActiveWindowStartTime.value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb3dc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "\n",
    "## Uses the `global_computation_results.computed_data['DirectionalDecodersDecoded']`\n",
    "directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "# continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "time_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\n",
    "print(f'time_bin_size: {time_bin_size}')\n",
    "continuously_decoded_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_decode_result.most_recent_continuously_decoded_dict\n",
    "all_directional_continuously_decoded_dict = continuously_decoded_dict or {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa46054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PhoMenuHelper.try_get_menu_window(spike_raster_window).ui.menus._menu_action_history_list\n",
    "PhoMenuHelper.try_get_menu_window(spike_raster_window) # .ui.menus PhoBaseMainWindow\n",
    "PhoMenuHelper.try_get_menu_window(spike_raster_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaa5208",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(spike_raster_window.menu_action_history_list))\n",
    "for cmd in spike_raster_window.menu_action_history_list:\n",
    "    print(f'cmd: {cmd}, .__class__.__name__: {cmd.__class__.__name__}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb45077",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_global_menus_actionsDict, global_flat_action_dict = spike_raster_window.build_all_menus_actions_dict()\n",
    "all_global_menus_actionsDict\n",
    "print(list(global_flat_action_dict.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023d6c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "Spike3DRasterWindowWidget.enable_interaction_events_debug_print = True\n",
    "spike_raster_window.enable_debug_print = True\n",
    "# spike_raster_window.should_debug_print_interaction_events = True\n",
    "spike_raster_window.should_debug_print_interaction_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8f2ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add ability to dial to a specific time (such as the periods that Kamran wants to look at)\n",
    "spike_raster_window.programmatically_scroll_to_time("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f212536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a51052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_window = spike_raster_window.spikes_window # SpikesDataframeWindow; pyphoplacecellanalysis.General.Model.TimeWindow.TimeWindow\n",
    "spikes_window.update_window_start_end(451.8908457518555, 451.9895490613999) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccf69eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.Menus.SpecificMenus.DockedWidgets_MenuProvider import DockedWidgets_MenuProvider\n",
    "from neuropy.utils.mixins.indexing_helpers import get_dict_subset\n",
    "from neuropy.utils.indexing_helpers import flatten_dict\n",
    "from pyphoplacecellanalysis.GUI.Qt.Menus.PhoMenuHelper import PhoMenuHelper\n",
    "from benedict import benedict\n",
    "from pyphocorehelpers.programming_helpers import VariableNameCaseFormat\n",
    "\n",
    "all_global_menus_actionsDict = {}\n",
    "# active_2d_plot.activeMenuReference\n",
    "# active_2d_plot.ui.menus # .global_window_menus.docked_widgets.actions_dict\n",
    "_docked_menu_provider: DockedWidgets_MenuProvider = spike_raster_window.main_menu_window.ui.menus.global_window_menus.docked_widgets.menu_provider_obj\n",
    "all_global_menus_actionsDict.update(_docked_menu_provider.DockedWidgets_MenuProvider_actionsDict)\n",
    "all_global_menus_actionsDict\n",
    "\n",
    "\n",
    "# ['AddMatplotlibPlot'\n",
    "#  'DecodedPosition'\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ae70b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_final = PhoMenuHelper.build_programmatic_menu_command_dict(active_2d_plot=active_2d_plot, container_format=dict)\n",
    "print_keys_if_possible('out_final', out_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cc1acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7091293c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23a5a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_flat_action_dict: Dict[str, QtWidgets.QAction] = flatten_dict({k:v for k, v in all_global_menus_actionsDict.items()}, sep='.')\n",
    "global_flat_action_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd31a973",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.gui.Qt.TopLevelWindowHelper import print_widget_hierarchy\n",
    "\n",
    "\n",
    "for a_name, a_time_sync_widget in spike_raster_window.ui.spike_raster_plt_2d.ui.matplotlib_view_widgets.items():\n",
    "    print(f'a_name: {a_name}')\n",
    "    # a_time_sync_widget.dumpObjectTree()\n",
    "    print_widget_hierarchy(a_time_sync_widget)\n",
    "    # a_time_sync_widget.parent().parent().parent().parent().parent().parent().parent().parent().parent() \n",
    "    a_time_sync_widget.ui.canvas\n",
    "    \n",
    "    # MatplotlibTimeSynchronizedWidget  > QWidget > Dock > VContainer > DockArea > NestedDockAreaWidget > QWidget > QSplitter > Spike2DRaster\n",
    "    # MatplotlibTimeSynchronizedWidget  > QWidget > Dock > VContainer > DockArea > self.ui.dynamic_docked_widget_container (NestedDockAreaWidget) > self.ui.wrapper_widget (QWidget) > self.ui.main_content_splitter (QSplitter) > Spike2DRaster\n",
    "\n",
    "    # a_time_sync_widget.installEventFilter(spike_raster_window) # plots.preview_overview_scatter_plot is a ScatterPlotItem ... does it have to be a pyqtgraph subclass to do this? I'm worried it does\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39436e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pickle `spike_raster_window` and everything needed to run it\n",
    "spike_raster_window.update_scrolling_event_filters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583697ff",
   "metadata": {
    "tags": [
     "stylesheetinspector"
    ]
   },
   "outputs": [],
   "source": [
    "from qt_style_sheet_inspector import StyleSheetInspector\n",
    "from PyQt5.QtCore import Qt\n",
    "from PyQt5.QtGui import QIcon, QKeySequence, QColor\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.DebugWidgetStylesheetInspector import ConnectStyleSheetInspector\n",
    "\n",
    "ConnectStyleSheetInspector(main_window=spike_raster_window, shortcut=QKeySequence(Qt.CTRL + Qt.SHIFT + Qt.Key_F12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95289eb",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "add_renderables_menu = active_2d_plot.ui.menus.custom_context_menus.add_renderables[0].programmatic_actions_dict\n",
    "menu_commands = ['AddTimeIntervals.PBEs', 'AddTimeIntervals.Ripples', 'AddTimeIntervals.Replays', 'AddTimeIntervals.Laps'] # , 'AddTimeIntervals.SessionEpochs'\n",
    "for a_command in menu_commands:\n",
    "    add_renderables_menu[a_command].trigger()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193d06e5",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "print_keys_if_possible('active_2d_plot.ui.menus.custom_context_menus', active_2d_plot.ui.menus.custom_context_menus, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766bf9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.get_session_context()\n",
    "\n",
    "## Bad/Icky Bimodal Cells:\n",
    "{IdentifyingContext(format_name= 'kdiba', animal= 'vvp01', exper_name= 'one', session_name= '2006-4-10_12-25-50'): [7, 36, 31, 4, 32, 27, 13, ],\n",
    " \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10994e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import NestedDockAreaWidget\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.MatplotlibTimeSynchronizedWidget import MatplotlibTimeSynchronizedWidget\n",
    "\n",
    "# test_long_LR_ContinuousDecode: MatplotlibTimeSynchronizedWidget = active_2d_plot.ui['matplotlib_view_widgets']['long_LR_ContinuousDecode'] # {'long_LR_ContinuousDecode': <pyphoplacecellanalysis.Pho2D.matplotlib.MatplotlibTimeSynchronizedWidget.MatplotlibTimeSynchronizedWidget, ...}\n",
    "# test_long_LR_ContinuousDecode.parent()\n",
    "\n",
    "dockAreaWidget: NestedDockAreaWidget = active_2d_plot.ui.dynamic_docked_widget_container\n",
    "\n",
    "dockArea = dockAreaWidget.displayDockArea\n",
    "dockArea\n",
    "# dockAreaWidget.displayDockArea\n",
    "# dockAreaWidget.ui.layout.setVerticalSpacing(0)\n",
    "# dockAreaWidget.ui.layout.setVerticalSpacing(2)\n",
    "# Access the internal layout and increase spacing\n",
    "dockAreaWidget.ui.layout.setContentsMargins(0, 0, 0, 0)  # Set margins around the DockArea (L, TOP, R, BOT)\n",
    "\n",
    "dockArea.layout.setSpacing(50)  # Set spacing between docks to 20 pixels\n",
    "# dockArea.layout.setVerticalSpacing(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54161ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_2d_plot.ui.dynamic_docked_widget_container.\n",
    "# ['main_content_splitter]\n",
    "a_name: str = 'long_LR_ContinuousDecode'\n",
    "dDisplayItem = active_2d_plot.ui.dynamic_docked_widget_container.find_display_dock(identifier=a_name) # Dock\n",
    "dDisplayItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3d0bf7",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.Menus.PhoMenuHelper import PhoMenuHelper\n",
    "\n",
    "_menu_commands_dict = PhoMenuHelper.build_programmatic_menu_command_dict(active_2d_plot)\n",
    "print_keys_if_possible('_menu_commands_dict', _menu_commands_dict, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7e1345",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "add_renderables_menu    \n",
    "menu_commands = ['AddMatplotlibPlot.DecodedPosition', 'AddTimeIntervals.Ripples', 'AddTimeIntervals.Replays', 'AddTimeIntervals.Laps'] # , 'AddTimeIntervals.SessionEpochs'\n",
    "for a_command in menu_commands:\n",
    "    add_renderables_menu[a_command].trigger()\n",
    "\n",
    "# ['AddMatplotlibPlot'\n",
    "#  'DecodedPosition'\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfb6d31",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "[f'AddTimeCurves.{k}' for k in add_renderables_menu['AddTimeCurves']] # ['AddTimeCurves.Position', 'AddTimeCurves.Velocity', 'AddTimeCurves.Random', 'AddTimeCurves.RelativeEntropySurprise', 'AddTimeCurves.Custom']\n",
    "[f'AddMatplotlibPlot.{k}' for k in add_renderables_menu['AddMatplotlibPlot']] # ['AddMatplotlibPlot.DecodedPosition', 'AddMatplotlibPlot.Custom']\n",
    "[f'Clear.{k}' for k in add_renderables_menu['Clear']] # ['Clear.all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13876513",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out = curr_active_pipeline.display(display_function='_display_trial_to_trial_reliability', active_session_configuration_context=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac20997",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "win = _out.root_render_widget\n",
    "# Set column stretches to adjust column widths\n",
    "# win.ci.setColumnStretch(0, 5)  # First column, stretch factor of 5\n",
    "# win.ci.setColumnStretch(1, 5)  # Second column, stretch factor of 5\n",
    "# win.ci.setColumnStretch(6, 1)  # Last column, stretch factor of 1 (smaller width)\n",
    "\n",
    "max_col_idx: int = 5\n",
    "# for i in np.arange(max_col_idx+1):\n",
    "# \twin.ci.layout.setColumnPreferredWidth(i, 250) # larger\n",
    "win.ci.layout.setColumnPreferredWidth(max_col_idx, 5)   # Last column width (smaller)\n",
    "win.ci.layout.setColumnFixedWidth(max_col_idx, 5)\n",
    "win.ci.layout.setColumnMaximumWidth(max_col_idx, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02c762d",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# Create a label item for the footer\n",
    "footer = pg.LabelItem(justify='center')\n",
    "footer.setText('Footer Text Here')\n",
    "\n",
    "# Add the footer label below the plot\n",
    "win.addItem(footer, row=2, col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c2bb17",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "print_keys_if_possible('add_renderables_menu', add_renderables_menu, max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a70360",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "spike_raster_window.build_epoch_intervals_visual_configs_widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b41f353",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "## Downsample the preview background scroller for more fluid scrolling? Or is that not the problem?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ab62cd",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "## Disconnect the connection to see if that's what lagging out the scrolling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0571368d",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "spike_raster_window.connection_man.active_connections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ce9f36",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "active_2d_plot.rate_limited_signal_scrolled_proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e77367",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "active_2d_plot.enable_debug_print = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccf6288",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "## Add the legends:\n",
    "legends_dict = active_2d_plot.build_or_update_all_epoch_interval_rect_legends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d468776b",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "## Remove the legends\n",
    "active_2d_plot.remove_all_epoch_interval_rect_legends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72734c24",
   "metadata": {
    "tags": [
     "all",
     "epochrenderconfigslistwidget, render_configs, widget, ui"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.mixins.epochs_plotting_mixins import EpochDisplayConfig, _get_default_epoch_configs\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.EpochRenderConfigWidget.EpochRenderConfigWidget import EpochRenderConfigWidget, EpochRenderConfigsListWidget\n",
    "\n",
    "## Build right-sidebar epoch interval configs widget:\n",
    "spike_raster_window.build_epoch_intervals_visual_configs_widget()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a702de2a",
   "metadata": {
    "tags": [
     "all",
     "epochrenderconfigslistwidget, render_configs, widget, ui"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\" `Plotted Rects` -> `configs widget`\"\"\" \n",
    "active_2d_plot.build_or_update_epoch_render_configs_widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25608e70",
   "metadata": {
    "tags": [
     "all",
     "epochrenderconfigslistwidget, render_configs, widget, ui"
    ]
   },
   "outputs": [],
   "source": [
    "## Update plots from configs:\n",
    "#     configs widget -> `Plotted Rects` \n",
    "active_2d_plot.update_epochs_from_configs_widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd250fb",
   "metadata": {
    "tags": [
     "all",
     "epochrenderconfigslistwidget, render_configs, widget, ui"
    ]
   },
   "outputs": [],
   "source": [
    "an_epochs_display_list_widget = active_2d_plot.ui['epochs_render_configs_widget']\n",
    "_out_configs = deepcopy(an_epochs_display_list_widget.configs_from_states())\n",
    "_out_configs\n",
    "\n",
    "# {'diba_evt_file': EpochDisplayConfig(brush_color='#008000', brush_opacity=0.7843137254901961, desired_height_ratio=1.0, height=10.0, isVisible=True, name='diba_evt_file', pen_color='#008000', pen_opacity=0.6078431372549019, y_location=-52.0),\n",
    "#  'initial_loaded': EpochDisplayConfig(brush_color='#ffffff', brush_opacity=0.7843137254901961, desired_height_ratio=1.0, height=10.0, isVisible=True, name='initial_loaded', pen_color='#ffffff', pen_opacity=0.6078431372549019, y_location=-42.0),\n",
    "#  'PBEs': EpochDisplayConfig(brush_color='#aa55ff', brush_opacity=0.7843137254901961, desired_height_ratio=1.0, height=10.0, isVisible=True, name='PBEs', pen_color='#aaaaff', pen_opacity=0.6078431372549019, y_location=-32.0),\n",
    "#  'Ripples': EpochDisplayConfig(brush_color='#0000ff', brush_opacity=0.7843137254901961, desired_height_ratio=1.0, height=10.0, isVisible=True, name='Ripples', pen_color='#0000ff', pen_opacity=0.6078431372549019, y_location=-22.0),\n",
    "#  'Laps': EpochDisplayConfig(brush_color='#ff0000', brush_opacity=0.7843137254901961, desired_height_ratio=1.0, height=10.0, isVisible=True, name='Laps', pen_color='#ff0000', pen_opacity=0.6078431372549019, y_location=-12.0),\n",
    "#  'normal_computed': EpochDisplayConfig(brush_color='#800080', brush_opacity=0.7843137254901961, desired_height_ratio=1.0, height=10.0, isVisible=True, name='normal_computed', pen_color='#800080', pen_opacity=0.6078431372549019, y_location=-62.0),\n",
    "#  'diba_quiescent_method_replay_epochs': EpochDisplayConfig(brush_color='#ffa500', brush_opacity=0.7843137254901961, desired_height_ratio=1.0, height=10.0, isVisible=True, name='diba_quiescent_method_replay_epochs', pen_color='#ffa500', pen_opacity=0.6078431372549019, y_location=-72.0)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86465b06",
   "metadata": {
    "tags": [
     "all",
     "epochrenderconfigslistwidget, render_configs, widget, ui"
    ]
   },
   "outputs": [],
   "source": [
    "update_dict = {k:v.to_dict() for k, v in _out_configs.items()}\n",
    "update_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e187827b",
   "metadata": {
    "tags": [
     "all",
     "epochrenderconfigslistwidget, render_configs, widget, ui"
    ]
   },
   "outputs": [],
   "source": [
    "def _on_update_rendered_intervals(active_2d_plot):\n",
    "    print(f'_on_update_rendered_intervals(...)')\n",
    "    _legends_dict = active_2d_plot.build_or_update_all_epoch_interval_rect_legends()\n",
    "    epoch_display_configs = active_2d_plot.extract_interval_display_config_lists()\n",
    "    an_epochs_display_list_widget = active_2d_plot.ui.get('epochs_render_configs_widget', None)\n",
    "    if an_epochs_display_list_widget is None:\n",
    "        # create a new one:    \n",
    "        an_epochs_display_list_widget:EpochRenderConfigsListWidget = EpochRenderConfigsListWidget(epoch_display_configs, parent=a_layout_widget)\n",
    "        active_2d_plot.ui.epochs_render_configs_widget = an_epochs_display_list_widget\n",
    "    else:\n",
    "        an_epochs_display_list_widget.update_from_configs(configs=epoch_display_configs)\n",
    "\n",
    "_a_connection = active_2d_plot.sigRenderedIntervalsListChanged.connect(_on_update_rendered_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3096fc",
   "metadata": {
    "tags": [
     "all",
     "epochrenderconfigslistwidget, render_configs, widget, ui"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import EpochRenderingMixin\n",
    "\n",
    "# @function_attributes(short_name=None, tags=['epoch_intervals', 'layout', 'update', 'IMPORTANT'], input_requires=[], output_provides=[], uses=[], used_by=[], creation_date='2024-07-03 05:21', related_items=[])\n",
    "def rebuild_epoch_interval_layouts_given_normalized_heights(active_2d_plot, desired_epoch_render_stack_height:float=70.0):\n",
    "    \"\"\" Re-builds the stacked epoch layout to prevent them from overlapping and to normalize their height\n",
    "    \n",
    "    desired_epoch_render_stack_height: total height for all of the epochs\n",
    "    \n",
    "    \"\"\"\n",
    "    from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import EpochRenderingMixin\n",
    "    active_epochs_formatting_dict = active_2d_plot.extract_interval_display_config_lists() ## gets existing formatting dict\n",
    "\n",
    "    # extracts only the height, considers only the first config if the entry is a list:\n",
    "    # original_epoch_display_config_heights = {k:v[0].to_dict()['height'] for k, v in active_epochs_formatting_dict.items()} # {'Replays': 1.9, 'Laps': 0.9, 'diba_evt_file': 10.0, 'initial_loaded': 10.0, 'diba_quiescent_method_replay_epochs': 10.0, 'Ripples': 0.9, 'normal_computed': 10.0}\n",
    "    # original_epoch_display_config_heights ## original heights\n",
    "    required_vertical_offsets, required_interval_heights = EpochRenderingMixin.build_stacked_epoch_layout((len(active_epochs_formatting_dict) * [1.0]), epoch_render_stack_height=desired_epoch_render_stack_height, interval_stack_location='below') # ratio of heights to each interval\n",
    "    stacked_epoch_layout_dict = {interval_key:dict(y_location=y_location, height=height) for interval_key, y_location, height in zip(list(active_epochs_formatting_dict.keys()), required_vertical_offsets, required_interval_heights)} # Build a stacked_epoch_layout_dict to update the display\n",
    "    # stacked_epoch_layout_dict # {'LapsAll': {'y_location': -3.6363636363636367, 'height': 3.6363636363636367}, 'LapsTrain': {'y_location': -21.818181818181817, 'height': 18.18181818181818}, 'LapsTest': {'y_location': -40.0, 'height': 18.18181818181818}}\n",
    "    # stacked_epoch_layout_dict\n",
    "\n",
    "    # replaces 'y_location', 'position' for each dict:\n",
    "    update_dict = {k:(v[0].to_dict()|stacked_epoch_layout_dict[k]) for k, v in active_epochs_formatting_dict.items()} # builds a proper update dict from the `active_epochs_formatting_dict` and the new position and height adjustments\n",
    "    # update_dict\n",
    "    active_2d_plot.update_rendered_intervals_visualization_properties(update_dict=update_dict)\n",
    "\n",
    "rebuild_epoch_interval_layouts_given_normalized_heights(active_2d_plot, desired_epoch_render_stack_height=60.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd03f18",
   "metadata": {
    "tags": [
     "all",
     "epochrenderconfigslistwidget, render_configs, widget, ui"
    ]
   },
   "outputs": [],
   "source": [
    "# epoch_display_configs = {k:get_dict_subset(v[0].to_dict(), ['height', 'y_location']) for k, v in active_2d_plot.extract_interval_display_config_lists().items()}\n",
    "# epoch_display_configs\n",
    "\n",
    "## Re-build the stacked epochs to prevent them from overlapping:\n",
    "\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import EpochRenderingMixin\n",
    "\n",
    "\n",
    "active_epochs_formatting_dict = active_2d_plot.extract_interval_display_config_lists()\n",
    "\n",
    "epoch_display_config_heights = {k:v[0].to_dict()['height'] for k, v in active_epochs_formatting_dict.items()} # {'Replays': 1.9, 'Laps': 0.9, 'diba_evt_file': 10.0, 'initial_loaded': 10.0, 'diba_quiescent_method_replay_epochs': 10.0, 'Ripples': 0.9, 'normal_computed': 10.0}\n",
    "epoch_display_config_heights\n",
    "required_vertical_offsets, required_interval_heights = EpochRenderingMixin.build_stacked_epoch_layout((len(active_epochs_formatting_dict) * [1.0]), epoch_render_stack_height=70.0, interval_stack_location='below') # ratio of heights to each interval\n",
    "stacked_epoch_layout_dict = {interval_key:dict(y_location=y_location, height=height) for interval_key, y_location, height in zip(list(active_epochs_formatting_dict.keys()), required_vertical_offsets, required_interval_heights)} # Build a stacked_epoch_layout_dict to update the display\n",
    "# stacked_epoch_layout_dict # {'LapsAll': {'y_location': -3.6363636363636367, 'height': 3.6363636363636367}, 'LapsTrain': {'y_location': -21.818181818181817, 'height': 18.18181818181818}, 'LapsTest': {'y_location': -40.0, 'height': 18.18181818181818}}\n",
    "# stacked_epoch_layout_dict\n",
    "\n",
    "# replaces 'y_location', 'position' for each dict:\n",
    "update_dict = {k:(v[0].to_dict()|stacked_epoch_layout_dict[k]) for k, v in active_epochs_formatting_dict.items()}\n",
    "update_dict\n",
    "\n",
    "\n",
    "active_2d_plot.update_rendered_intervals_visualization_properties(update_dict=update_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11c93e8",
   "metadata": {
    "tags": [
     "all",
     "epochrenderconfigslistwidget, render_configs, widget, ui"
    ]
   },
   "outputs": [],
   "source": [
    "## Extract/Save all active epochs:\n",
    "active_epochs_formatting_dict: Dict[str, List[EpochDisplayConfig]] = deepcopy(active_2d_plot.extract_interval_display_config_lists())\n",
    "active_epochs_formatting_dict\n",
    "\n",
    "# an_epochs_display_list_widget.configs_from_states()\n",
    "\n",
    "\n",
    "an_epochs_display_list_widget = active_2d_plot.ui.get('epochs_render_configs_widget', None)\n",
    "if an_epochs_display_list_widget is None:\n",
    "    raise NotImplementedError\n",
    "    # create a new one:    \n",
    "    an_epochs_display_list_widget:EpochRenderConfigsListWidget = EpochRenderConfigsListWidget(active_epochs_formatting_dict, parent=a_layout_widget)\n",
    "    active_2d_plot.ui.epochs_render_configs_widget = an_epochs_display_list_widget\n",
    "else:\n",
    "    an_epochs_display_list_widget.update_from_configs(configs=active_epochs_formatting_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ad3bd7",
   "metadata": {
    "tags": [
     "all",
     "epochrenderconfigslistwidget, render_configs, widget, ui"
    ]
   },
   "outputs": [],
   "source": [
    "active_epochs_confgs_dict: Dict[str, EpochDisplayConfig] = deepcopy(an_epochs_display_list_widget.configs_from_states())\n",
    "active_epochs_confgs_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f93d7e",
   "metadata": {
    "tags": [
     "all",
     "epochrenderconfigslistwidget, render_configs, widget, ui"
    ]
   },
   "outputs": [],
   "source": [
    "saveData('SpikeRaster2D_saved_Epochs.pkl', active_epochs_confgs_dict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900d679d",
   "metadata": {
    "tags": [
     "all",
     "epochrenderconfigslistwidget, render_configs, widget, ui"
    ]
   },
   "outputs": [],
   "source": [
    "active_epochs_formatting_dict['Replays'][0].brush_QColor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7318fbb",
   "metadata": {
    "tags": [
     "all",
     "epochrenderconfigslistwidget, render_configs, widget, ui"
    ]
   },
   "outputs": [],
   "source": [
    "## Restore/Load all active epochs:\n",
    "# update_dict = {k:(v[0].to_dict()|stacked_epoch_layout_dict[k]) for k, v in active_epochs_formatting_dict.items()}\n",
    "\n",
    "update_dict = {k:v.to_dict() for k, v in active_epochs_confgs_dict.items()} ## from active_epochs_confgs_dict\n",
    "update_dict\n",
    "\n",
    "## Updates intervals themselves\n",
    "active_2d_plot.update_rendered_intervals_visualization_properties(update_dict=update_dict)\n",
    "\n",
    "## updates configs:\n",
    "# active_2d_plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673515f9",
   "metadata": {
    "tags": [
     "all",
     "epochrenderconfigslistwidget, render_configs, widget, ui"
    ]
   },
   "outputs": [],
   "source": [
    "_out_all_rendered_intervals_dict = active_2d_plot.get_all_rendered_intervals_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1292a3",
   "metadata": {
    "tags": [
     "all",
     "epochrenderconfigslistwidget, render_configs, widget, ui"
    ]
   },
   "outputs": [],
   "source": [
    "active_epochs_interval_datasources_dict: Dict[str, IntervalsDatasource] = active_2d_plot.interval_datasources\n",
    "active_epochs_interval_datasources_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb58bafd",
   "metadata": {
    "tags": [
     "all",
     "epochrenderconfigslistwidget, render_configs, widget, ui"
    ]
   },
   "outputs": [],
   "source": [
    "out_dict = {}\n",
    "rendered_epoch_names = active_2d_plot.interval_datasource_names\n",
    "print(f'rendered_epoch_names: {rendered_epoch_names}')\n",
    "for a_name in rendered_epoch_names:\n",
    "    a_render_container = active_2d_plot.rendered_epochs[a_name]\n",
    "    out_dict[a_name] = a_render_container\n",
    "\n",
    "out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91e0ccf",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "main_plot_widget.setVisible(False) ## top plot disappeared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedfcbfd",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "main_plot_widget.setVisible(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78c7a9b",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "## Find Connections\n",
    "active_2d_plot.setVisible(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdaaca1",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# active_2d_plot.get_all_rendered_intervals_dict()\n",
    "active_2d_plot.interval_datasources\n",
    "# active_2d_plot.interval_rendering_plots\n",
    "active_2d_plot.interval_datasource_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaca430",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "active_2d_plot.setVisible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c1badb",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "spike_raster_window.isVisible()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697d558a",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import ensure_Epoch, Epoch, ensure_dataframe\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.Specific2DRenderTimeEpochs import General2DRenderTimeEpochs, inline_mkColor\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import Spike2DRaster\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.EpochRenderingMixin import EpochRenderingMixin, RenderedEpochsItemsContainer\n",
    "from pyphoplacecellanalysis.General.Model.Datasources.IntervalDatasource import IntervalsDatasource\n",
    "from neuropy.utils.mixins.time_slicing import TimeColumnAliasesProtocol\n",
    "\n",
    "## Add various replay epochs as interval rects:\n",
    "\n",
    "## INPUTS: replay_epoch_variations\n",
    "\n",
    "# replay_epoch_variations\n",
    "\n",
    "\n",
    "## Use the three dataframes as separate Epoch series:\n",
    "custom_replay_dfs_dict = {k:ensure_dataframe(deepcopy(v)) for k, v in replay_epoch_variations.items()}\n",
    "custom_replay_keys = list(custom_replay_dfs_dict.keys()) # \n",
    "print(f'{custom_replay_keys}') # ['initial_loaded', 'normal_computed', 'diba_evt_file', 'diba_quiescent_method_replay_epochs']\n",
    "\n",
    "\n",
    "_color_rotation_order = ['white', 'purple', 'green', 'orange', 'pink', 'red']\n",
    "\n",
    "custom_replay_epochs_formatting_dict = {\n",
    "    'initial_loaded':dict(pen_color=inline_mkColor('white', 0.8), brush_color=inline_mkColor('white', 0.5)),\n",
    "    'normal_computed':dict(pen_color=inline_mkColor('purple', 0.8), brush_color=inline_mkColor('purple', 0.5)),\n",
    "    'diba_evt_file':dict(pen_color=inline_mkColor('green', 0.8), brush_color=inline_mkColor('green', 0.5)),\n",
    "    'diba_quiescent_method_replay_epochs':dict(pen_color=inline_mkColor('orange', 0.8), brush_color=inline_mkColor('orange', 0.5)),\n",
    "}\n",
    "\n",
    "# required_vertical_offsets, required_interval_heights = EpochRenderingMixin.build_stacked_epoch_layout((len(custom_replay_dfs_dict) * [1.0]), epoch_render_stack_height=40.0, interval_stack_location='below') # ratio of heights to each interval\n",
    "# stacked_epoch_layout_dict = {interval_key:dict(y_location=y_location, height=height) for interval_key, y_location, height in zip(list(custom_replay_epochs_formatting_dict.keys()), required_vertical_offsets, required_interval_heights)} # Build a stacked_epoch_layout_dict to update the display\n",
    "stacked_epoch_layout_dict = {interval_key:dict(y_location=y_location, height=height) for interval_key, y_location, height in zip(list(custom_replay_epochs_formatting_dict.keys()), *EpochRenderingMixin.build_stacked_epoch_layout((len(custom_replay_dfs_dict) * [1.0]), epoch_render_stack_height=40.0, interval_stack_location='below'))} # Build a stacked_epoch_layout_dict to update the display\n",
    "# replaces 'y_location', 'position' for each dict:\n",
    "custom_replay_epochs_formatting_dict = {k:(v|stacked_epoch_layout_dict[k]) for k, v in custom_replay_epochs_formatting_dict.items()}\n",
    "# custom_replay_epochs_formatting_dict\n",
    "\n",
    "# OUTPUTS: train_test_split_laps_dfs_dict, custom_replay_epochs_formatting_dict\n",
    "## INPUTS: train_test_split_laps_dfs_dict\n",
    "custom_replay_dfs_dict = {k:TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(df=v, required_columns_synonym_dict=IntervalsDatasource._time_column_name_synonyms) for k, v in custom_replay_dfs_dict.items()}\n",
    "\n",
    "## Build interval datasources for them:\n",
    "custom_replay_dfs_datasources_dict = {k:General2DRenderTimeEpochs.build_render_time_epochs_datasource(v) for k, v in custom_replay_dfs_dict.items()}\n",
    "## INPUTS: active_2d_plot, train_test_split_laps_epochs_formatting_dict, train_test_split_laps_dfs_datasources_dict\n",
    "assert len(custom_replay_epochs_formatting_dict) == len(custom_replay_dfs_datasources_dict)\n",
    "for k, an_interval_ds in custom_replay_dfs_datasources_dict.items():\n",
    "    an_interval_ds.update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, **(custom_replay_epochs_formatting_dict[k] | kwargs)))\n",
    "\n",
    "\n",
    "## Full output: train_test_split_laps_dfs_datasources_dict\n",
    "\n",
    "\n",
    "# actually add the epochs:\n",
    "for k, an_interval_ds in custom_replay_dfs_datasources_dict.items():\n",
    "    active_2d_plot.add_rendered_intervals(an_interval_ds, name=f'{k}', debug_print=False) # adds the interval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34342d9",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "active_2d_plot.params.enable_time_interval_legend_in_right_margin = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51663689",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "## They can later be updated via:\n",
    "active_2d_plot.update_rendered_intervals_visualization_properties(custom_replay_epochs_formatting_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d073b9ae",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# new_replay_epochs.to_file('new_replays.csv')\n",
    "new_replay_epochs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d680b0e1",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "rank_order_results.minimum_inclusion_fr_Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc7f309",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "track_templates.long_LR_decoder.neuron_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274e8b3d",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\n",
    "active_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.plot._display_spike_rasters_pyqtplot_2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a672c4",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# Gets the existing SpikeRasterWindow or creates a new one if one doesn't already exist:\n",
    "from pyphocorehelpers.gui.Qt.TopLevelWindowHelper import TopLevelWindowHelper\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg # Used to get the app for TopLevelWindowHelper.top_level_windows\n",
    "## For searching with `TopLevelWindowHelper.all_widgets(...)`:\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import Spike2DRaster\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike3DRaster import Spike3DRaster\n",
    "from pyphoplacecellanalysis.GUI.Qt.SpikeRasterWindows.Spike3DRasterWindowWidget import Spike3DRasterWindowWidget\n",
    "\n",
    "found_spike_raster_windows = TopLevelWindowHelper.all_widgets(pg.mkQApp(), searchType=Spike3DRasterWindowWidget)\n",
    "\n",
    "if len(found_spike_raster_windows) < 1:\n",
    "    # no existing spike_raster_windows. Make a new one\n",
    "    print(f'no existing SpikeRasterWindow. Creating a new one.')\n",
    "    # Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\n",
    "    active_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.plot._display_spike_rasters_pyqtplot_2D()\n",
    "\n",
    "else:\n",
    "    print(f'found {len(found_spike_raster_windows)} existing Spike3DRasterWindowWidget windows using TopLevelWindowHelper.all_widgets(...). Will use the most recent.')\n",
    "    # assert len(found_spike_raster_windows) == 1, f\"found {len(found_spike_raster_windows)} Spike3DRasterWindowWidget windows using TopLevelWindowHelper.all_widgets(...) but require exactly one.\"\n",
    "    # Get the most recent existing one and reuse that:\n",
    "    spike_raster_window = found_spike_raster_windows[0]\n",
    "\n",
    "\n",
    "# Extras:\n",
    "active_2d_plot = spike_raster_window.spike_raster_plt_2d # <pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster.Spike2DRaster at 0x196c7244280>\n",
    "active_3d_plot = spike_raster_window.spike_raster_plt_3d # <pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster.Spike2DRaster at 0x196c7244280>\n",
    "main_graphics_layout_widget = active_2d_plot.ui.main_graphics_layout_widget # GraphicsLayoutWidget\n",
    "main_plot_widget = active_2d_plot.plots.main_plot_widget # PlotItem\n",
    "background_static_scroll_plot_widget = active_2d_plot.plots.background_static_scroll_window_plot # PlotItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63113267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.helpers import recover_graphics_layout_widget_item_indicies\n",
    "\n",
    "found_item_rows, found_item_cols, found_items_list, (found_max_row, found_max_col) = recover_graphics_layout_widget_item_indicies(main_graphics_layout_widget, debug_print=True)\n",
    "found_items_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb61eb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_graphics_layout_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b2f20e",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_display_items = widget.get_display_function_items()\n",
    "_display_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9df0c9d",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "a_fcn_name = '_display_batch_pho_jonathan_replay_firing_rate_comparison'\n",
    "a_fn_handle = widget._perform_get_display_function_code(a_fcn_name=a_fcn_name)\n",
    "assert a_fn_handle is not None\n",
    "# args = []\n",
    "# kwargs = {}\n",
    "a_disp_fn_item = widget.get_display_function_item(a_fn_name=a_fcn_name)\n",
    "assert a_disp_fn_item is not None, f\"a_disp_fn_item is None! for a_fn_name='{a_fcn_name}'\"\n",
    "\n",
    "a_disp_fn_item.is_global\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c91ed7b",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display(display_function=a_fcn_name, active_session_configuration_context=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363d0cff",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "long_short_display_config_manager = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca4fb13",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_display_spike_rasters_pyqtplot_3D_with_2D_controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691c70b4",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "print(list(_display_items.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29925698",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphocorehelpers.DataStructure.RenderPlots.MatplotLibRenderPlots import FigureCollector\n",
    "from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import fig_remapping_cells\n",
    "\n",
    "collector: FigureCollector = fig_remapping_cells(curr_active_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2606a58c",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "if not isinstance(curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis, JonathanFiringRateAnalysisResult):\n",
    "    jonathan_firing_rate_analysis_result = JonathanFiringRateAnalysisResult(**curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.to_dict())\n",
    "else:\n",
    "    jonathan_firing_rate_analysis_result = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis\n",
    "\n",
    "neuron_replay_stats_df = jonathan_firing_rate_analysis_result.neuron_replay_stats_df.copy()\n",
    "neuron_replay_stats_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398b348a",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_sorted_neuron_stats_df = neuron_replay_stats_df.sort_values(by=sortby, ascending=[True, True, True], inplace=False).copy() # also did test_df = neuron_replay_stats_df.sort_values(by=['long_pf_peak_x'], inplace=False, ascending=True).copy()\n",
    "_sorted_neuron_stats_df = _sorted_neuron_stats_df[np.isin(_sorted_neuron_stats_df.index, curr_any_context_neurons)] # clip to only those neurons included in `curr_any_context_neurons`\n",
    "_sorted_aclus = _sorted_neuron_stats_df.index.to_numpy()\n",
    "_sorted_neuron_IDXs = _sorted_neuron_stats_df.neuron_IDX.to_numpy()\n",
    "if debug_print:\n",
    "    print(f'_sorted_aclus: {_sorted_aclus}')\n",
    "    print(f'_sorted_neuron_IDXs: {_sorted_neuron_IDXs}')\n",
    "\n",
    "## Use this sort for the 'curr_any_context_neurons' sort order:\n",
    "new_all_aclus_sort_indicies, desired_sort_arr = find_desired_sort_indicies(curr_any_context_neurons, _sorted_aclus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea2cd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _directional_laps_overview = curr_active_pipeline.plot._display_directional_laps_overview(curr_active_pipeline.computation_results, a)\n",
    "# _directional_laps_overview = curr_active_pipeline.display('_display_directional_laps_overview')\n",
    "# _directional_laps_overview = curr_active_pipeline.display('_display_grid_bin_bounds_validation')\n",
    "_directional_laps_overview = curr_active_pipeline.display('_display_long_short_pf1D_comparison')\n",
    "\n",
    "_directional_laps_overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c501945c",
   "metadata": {},
   "source": [
    "### <a id='toc8_1_2_'></a>[‚úÖüñºÔ∏èüé® 2024-06-06 - Works to render the contour curve at a fixed promenence (the shape of the placefield's cap/crest) for each placefield:](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d0a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho3D.PyVista.peak_prominences import render_all_neuron_peak_prominence_2d_results_on_pyvista_plotter\n",
    "\n",
    "display_output = {}\n",
    "active_config_name = long_LR_name\n",
    "print(f'active_config_name: {active_config_name}')\n",
    "active_peak_prominence_2d_results = curr_active_pipeline.computation_results[active_config_name].computed_data.get('RatemapPeaksAnalysis', {}).get('PeakProminence2D', None)\n",
    "pActiveTuningCurvesPlotter = None\n",
    "\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "active_config_modifiying_kwargs = {\n",
    "    'plotting_config': {'should_use_linear_track_geometry': True, \n",
    "                        't_start': t_start, 't_delta': t_delta, 't_end': t_end,\n",
    "                        }\n",
    "}\n",
    "display_output = display_output | curr_active_pipeline.display('_display_3d_interactive_tuning_curves_plotter', active_config_name, extant_plotter=display_output.get('pActiveTuningCurvesPlotter', None),\n",
    "                                                panel_controls_mode='Qt', should_nan_non_visited_elements=False, zScalingFactor=2000.0, active_config_modifiying_kwargs=active_config_modifiying_kwargs,\n",
    "                                                params_kwargs=dict(should_use_linear_track_geometry=True, **{'t_start': t_start, 't_delta': t_delta, 't_end': t_end}),\n",
    "                                            ) # Works now!\n",
    "ipcDataExplorer = display_output['ipcDataExplorer']\n",
    "display_output['pActiveTuningCurvesPlotter'] = display_output.pop('plotter') # rename the key from the generic \"plotter\" to \"pActiveSpikesBehaviorPlotter\" to avoid collisions with others\n",
    "pActiveTuningCurvesPlotter = display_output['pActiveTuningCurvesPlotter']\n",
    "root_dockAreaWindow, placefieldControlsContainerWidget, pf_widgets = display_output['pane'] # for Qt mode\n",
    "\n",
    "active_peak_prominence_2d_results = curr_active_pipeline.computation_results[active_config_name].computed_data.get('RatemapPeaksAnalysis', {}).get('PeakProminence2D', None)\n",
    "render_all_neuron_peak_prominence_2d_results_on_pyvista_plotter(ipcDataExplorer, active_peak_prominence_2d_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ed8f47",
   "metadata": {},
   "source": [
    "### <a id='toc8_1_3_'></a>[2024-06-06 - Works to disable/hide all elements except the contour curves:](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027ff05b",
   "metadata": {
    "tags": [
     "3d",
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "all_placefield_surfaces_are_hidden: bool = True\n",
    "all_placefield_points_are_hidden: bool = True\n",
    "\n",
    "disabled_peak_subactors_names_list = ['boxes', 'text', 'peak_points']\n",
    "# disabled_peak_subactors_names_list = ['text', 'peak_points']\n",
    "for active_neuron_id, a_plot_dict in ipcDataExplorer.plots['tuningCurvePlotActors'].items():\n",
    "    if a_plot_dict is not None:\n",
    "        # a_plot_dict.peaks\n",
    "        print(f'active_neuron_id: {active_neuron_id}, a_plot_dict.keys(): {list(a_plot_dict.keys())}')\n",
    "        # ['main', 'points', 'peaks']\n",
    "        if a_plot_dict.main is not None:\n",
    "            if all_placefield_surfaces_are_hidden:\n",
    "                a_plot_dict.main.SetVisibility(False)\n",
    "                # pass\n",
    "            \n",
    "        if a_plot_dict.points is not None:\n",
    "            if all_placefield_points_are_hidden:\n",
    "                a_plot_dict.points.SetVisibility(False)\n",
    "                # pass\n",
    "\n",
    "        if a_plot_dict.peaks is not None:\n",
    "            print(f'active_neuron_id: {active_neuron_id}, a_plot_dict.peaks: {list(a_plot_dict.peaks.keys())}')\n",
    "            for a_subactor_name in disabled_peak_subactors_names_list:\n",
    "                a_subactor = a_plot_dict.peaks.get(a_subactor_name, None)\n",
    "                if a_subactor is not None:\n",
    "                    a_subactor.SetVisibility(False)\n",
    "            # if all_placefield_surfaces_are_hidden:\n",
    "            #     a_plot_dict.main.SetVisibility(False) # Change the visibility to match the current tuning_curve_visibility_state\n",
    "\n",
    "# Once done, render\n",
    "ipcDataExplorer.p.render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7be129",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "\n",
    "graphics_output_dict = curr_active_pipeline.display('_display_long_short_laps')\n",
    "graphics_output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedac3f3",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "fig, axs, plot_data = graphics_output_dict['fig'], graphics_output_dict['axs'], graphics_output_dict['plot_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccb3e9c",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_display_grid_bin_bounds_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68008d6e",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.plot._display_long_short_laps()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685113bf",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\n",
    "# active_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.plot._display_spike_rasters_pyqtplot_2D()\n",
    "\n",
    "_out_graphics_dict = curr_active_pipeline.display('_display_spike_rasters_pyqtplot_2D', 'maze_any') # 'maze_any'\n",
    "assert isinstance(_out_graphics_dict, dict)\n",
    "active_2d_plot, active_3d_plot, spike_raster_window = _out_graphics_dict['spike_raster_plt_2d'], _out_graphics_dict['spike_raster_plt_3d'], _out_graphics_dict['spike_raster_window']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d3db27",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "add_renderables_menu = active_2d_plot.ui.menus.custom_context_menus.add_renderables[0].programmatic_actions_dict\n",
    "menu_commands = ['AddTimeIntervals.PBEs', 'AddTimeIntervals.Ripples', 'AddTimeIntervals.Replays', 'AddTimeIntervals.Laps', 'AddTimeIntervals.SessionEpochs']\n",
    "for a_command in menu_commands:\n",
    "    add_renderables_menu[a_command].trigger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5650ac",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "print(list(add_renderables_menu.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9a83aa",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "print_keys_if_possible('add_renderables_menu', add_renderables_menu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfbad2e",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# 3d_interactive_tuning_curves_plotter\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "active_config_modifiying_kwargs = {\n",
    "    'plotting_config': {'should_use_linear_track_geometry': True, \n",
    "                        't_start': t_start, 't_delta': t_delta, 't_end': t_end,\n",
    "                        }\n",
    "}\n",
    "_out_graphics_dict = curr_active_pipeline.display('_display_3d_interactive_tuning_curves_plotter', active_session_configuration_context=global_epoch_context,\n",
    "                                            active_config_modifiying_kwargs=active_config_modifiying_kwargs,\n",
    "                                            params_kwargs=dict(should_use_linear_track_geometry=True, **{'t_start': t_start, 't_delta': t_delta, 't_end': t_end}),\n",
    "                                           )\n",
    "ipcDataExplorer = _out_graphics_dict['ipcDataExplorer'] # InteractivePlaceCellTuningCurvesDataExplorer \n",
    "p = _out_graphics_dict['plotter']\n",
    "pane = _out_graphics_dict['pane']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a16e010",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.prepare_for_display()\n",
    "_out = curr_active_pipeline.display(display_function='_display_3d_interactive_spike_and_behavior_browser', active_session_configuration_context=global_epoch_context) # , computation_kwargs_list=[{'laps_decoding_time_bin_size': 0.025}]\n",
    "ipspikesDataExplorer = _out['ipspikesDataExplorer']\n",
    "p = _out['plotter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccc5550",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "iplapsDataExplorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8d3f4b",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.prepare_for_display()\n",
    "\n",
    "an_image_file_path = Path('an_image.png').resolve()\n",
    "_out = curr_active_pipeline.display(display_function='_display_3d_image_plotter', active_session_configuration_context=global_epoch_context, image_file=an_image_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74ce93e",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "for a_name, a_config in curr_active_pipeline.active_configs.items():\n",
    "    print(f'a_config.plotting_config.should_use_linear_track_geometry: {a_config.plotting_config.should_use_linear_track_geometry}')\n",
    "    a_config.plotting_config.should_use_linear_track_geometry = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d560b4",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.External.pyqtgraph_extensions.PlotWidget.CustomPlotWidget import CustomPlotWidget\n",
    "from pyphoplacecellanalysis.External.pyqtgraph_extensions.graphicsItems.SelectableTextItem import SelectableTextItem\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.TemplateDebugger import TemplateDebugger\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap\n",
    "\n",
    "_out: TemplateDebugger = TemplateDebugger.init_templates_debugger(track_templates) # , included_any_context_neuron_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbe9142",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out.get_selected_aclus(return_only_selected_aclus=True) # 'long_LR': [45, 24, 18, 35, 32], 'long_RL': [], 'short_LR': [], 'short_RL': []}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c64cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_win, an_img_item = _out.pf1D_heatmaps['long_LR']\n",
    "# an_img_item.sceneBoundingRect()\n",
    "# a_win.getViewBox()\n",
    "# an_img_item.getViewBox()\n",
    "# a_win.setObjectName()\n",
    "a_win.objectName()\n",
    "an_img_item.objectName()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b965c4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_pfs_ymin_ymax_tuple_list_dict = _out.plots_data.active_pfs_ymin_ymax_tuple_list_dict\n",
    "active_pfs_ymin_ymax_tuple_list_dict['long_LR']\n",
    "active_pfs_ymin_ymax_tuple_list_dict['long_RL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813b02d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_data.sorted_neuron_IDs_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8213de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.External.pyqtgraph.GraphicsScene.mouseEvents import MouseClickEvent\n",
    "\n",
    "# clicked plot 0x7bf9b6060040, event: <MouseClickEvent (176,249) button=1>\n",
    "# self.on_mouse_click(...)\n",
    "# \tevent: <MouseClickEvent (176,249) button=1>\n",
    "def custom_on_mouse_clicked(self, custom_plot_widget, event):\n",
    "    \n",
    "    debug_print: bool = False\n",
    "    if debug_print:\n",
    "        print(f'custom_on_mouse_clicked(event: {event})')\n",
    "    # if not isinstance(event, MouseClickEvent):\n",
    "    if not hasattr(event, 'scenePos'):\n",
    "        if debug_print:\n",
    "            print(f'not MouseClickEvent. skipping.')\n",
    "        return\n",
    "    else:    \n",
    "        pos = event.scenePos() # 'QMouseEvent' object has no attribute 'scenePos'\n",
    "\n",
    "        if debug_print:\n",
    "            print(f'\\tscenePos: {pos}')\n",
    "            print(f'\\tscreenPos: {event.screenPos()}')\n",
    "            print(f'\\tpos: {event.pos()}')\n",
    "            \n",
    "        item_data = custom_plot_widget.item_data\n",
    "        if debug_print:\n",
    "            print(f'\\titem_data: {item_data}')\n",
    "        found_decoder_idx = item_data.get('decoder_idx', None)\n",
    "        found_decoder_name = item_data.get('decoder_name', None)\n",
    "        \n",
    "        ## find the clicked decoder\n",
    "        # found_decoder_idx = None\n",
    "        # found_decoder_name = None\n",
    "        # for a_decoder_idx, (a_decoder_name, (a_win, an_img_item)) in enumerate(self.pf1D_heatmaps.items()):\n",
    "        #     if ((found_decoder_idx is None) and (found_decoder_name is None)):\n",
    "        #         if an_img_item.sceneBoundingRect().contains(pos):\n",
    "        #             ## found correct decoder here:\n",
    "        #             found_decoder_idx = a_decoder_idx\n",
    "        #             found_decoder_name = a_decoder_name\n",
    "                    \n",
    "        if ((found_decoder_idx is None) and (found_decoder_name is None)):\n",
    "            print(f'WARNING: could not find correct decoder name/idx')\n",
    "        else:\n",
    "            if debug_print:\n",
    "                print(f'found valid decoder: found_decoder_name: \"{found_decoder_name}\", found_decoder_idx\" {found_decoder_idx}')\n",
    "            a_win, an_img_item = self.pf1D_heatmaps[found_decoder_name]\n",
    "            mouse_point = a_win.getViewBox().mapSceneToView(pos)\n",
    "            if debug_print:\n",
    "                print(f\"Clicked at: x={mouse_point.x()}, y={mouse_point.y()}\")\n",
    "            found_y_point: float = mouse_point.y()\n",
    "            ## round down\n",
    "            found_y_idx: int = int(found_y_point)\n",
    "            if debug_print:\n",
    "                print(f'found_y_idx: {found_y_idx}')\n",
    "            found_aclu: int = self.plots_data.sorted_neuron_IDs_lists[found_decoder_idx][found_y_idx]\n",
    "            print(f'found_aclu: {found_aclu}')\n",
    "            prev_selected_aclus = self.get_any_decoder_selected_aclus().tolist()\n",
    "            # prev_selected_aclus\n",
    "            prev_selected_aclus.append(found_aclu)\n",
    "            self.set_selected_aclus_for_all_decoders(any_selected_aclus=prev_selected_aclus)\n",
    "\n",
    "    # a_win, an_img_item = self.pf1D_heatmaps['long_LR']\n",
    "    # plot = an_img_item\n",
    "    # if plot.sceneBoundingRect().contains(pos):\n",
    "    #     # mouse_point = plot.vb.mapSceneToView(pos)\n",
    "    #     mouse_point = a_win.getViewBox().mapSceneToView(pos)\n",
    "    #     if debug_print:\n",
    "    #         print(f\"Clicked at: x={mouse_point.x()}, y={mouse_point.y()}\")\n",
    "    #     found_y_point: float = mouse_point.y()\n",
    "    #     ## round down\n",
    "    #     found_y_idx: int = int(found_y_point)\n",
    "    #     print(f'found_y_idx: {found_y_idx}')\n",
    "    #     found_aclu: int = self.plots_data.sorted_neuron_IDs_lists[0][found_y_idx]\n",
    "    #     print(f'found_aclu: {found_aclu}')\n",
    "\n",
    "_out.params.on_mouse_clicked_callback_fn_dict = {\n",
    "'custom_on_mouse_clicked': custom_on_mouse_clicked,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18950a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_pfs_img_extents = _out.plots_data.active_pfs_img_extents_dict[a_decoder_name] # [37.0773897438341, 0, 213.87855429166422, 25.0] # these extents are  (x, y, w, h)\n",
    "x, y, w, h = active_pfs_img_extents\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf253d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out.get_any_decoder_selected_aclus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebe6956",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_selected_aclus = _out.get_any_decoder_selected_aclus().tolist()\n",
    "prev_selected_aclus\n",
    "prev_selected_aclus.append(found_aclu)\n",
    "_out.set_selected_aclus_for_all_decoders(any_selected_aclus=[18, 24, 31, 32, 35, 45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8309d364",
   "metadata": {},
   "outputs": [],
   "source": [
    "synchronize_selected_aclus_across_decoders: bool = _out.params.setdefault('synchronize_selected_aclus_across_decoders', True)\n",
    "synchronize_selected_aclus_across_decoders\n",
    "\n",
    "curr_selected_aclus_dict = _out.get_selected_aclus(return_only_selected_aclus=True) # 'long_LR': [45, 24, 18, 35, 32], 'long_RL': [], 'short_LR': [], 'short_RL': []}\n",
    "if synchronize_selected_aclus_across_decoders:\n",
    "    any_decoder_selectioned_aclus = union_of_arrays(*list(curr_selected_aclus_dict.values()))\n",
    "    any_decoder_selectioned_aclus\n",
    "    # for a_decoder_name, a_decoder_selections in curr_selected_aclus_dict.items():\n",
    "    #     # select missing selections\n",
    "    #     curr_missing_selections = any_decoder_selectioned_aclus[np.isin(any_decoder_selectioned_aclus, a_decoder_selections)]\n",
    "    #     curr_missing_selections\n",
    "        \n",
    "    # for a_decoder_name, a_text_items_dict in _out.ui.text_items_dict.items():\n",
    "    #     for aclu in any_decoder_selectioned_aclus:\n",
    "    #         a_text_item = a_text_items_dict.get(aclu, None)\n",
    "    #         if a_text_item is not None:\n",
    "    #             # set the selection\n",
    "    #             # a_text_item.is_selected = True\n",
    "    #             a_text_item.perform_update_selected(new_is_selected=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab600bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_pfs_img_extents = _out.plots_data.active_pfs_img_extents_dict[a_decoder_name] # [37.0773897438341, 0, 213.87855429166422, 25.0] # these extents are  (x, y, w, h)\n",
    "x, y, w, h = active_pfs_img_extents\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c3e7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "aclu = 7\n",
    "a_decoder_name = 'long_LR'\n",
    "text: SelectableTextItem = _out.ui.text_items_dict[a_decoder_name][aclu]\n",
    "active_pfs_img_extents = _out.plots_data.active_pfs_img_extents_dict[a_decoder_name] # [37.0773897438341, 0, 213.87855429166422, 25.0] # these extents are  (x, y, w, h)\n",
    "x, y, w, h = active_pfs_img_extents\n",
    "rect = text.boundingRect()\n",
    "rect\n",
    "# # text.getViewBox().boundingRect()\n",
    "# text.getBoundingParents()\n",
    "# text.anchor\n",
    "# text\n",
    "\n",
    "# # Get the bounding rectangle of the text\n",
    "# br = text.textItem.boundingRect()\n",
    "# br\n",
    "# # Calculate the position adjustment based on the anchor\n",
    "# anchor_x = -br.left() - br.width() * text.anchor[0]\n",
    "# anchor_y = -br.top() - br.height() * text.anchor[1]\n",
    "\n",
    "# anchor_x\n",
    "# anchor_y\n",
    "\n",
    "# # text.rect_item.setRect(text.boundingRect())\n",
    "# transformed_rect = text.mapRectToParent(text.boundingRect())\n",
    "# transformed_rect\n",
    "rect.setWidth(text.parentWidget().width())\n",
    "rect.setHeight(h)\n",
    "\n",
    "# test_rect = QRectF(-10.104885544514367, -0.3724311354808627, 9.104885544514367, 1.3724311354808627)\n",
    "rect\n",
    "# text.rect_item.setRect(transformed_rect)\n",
    "text.rect_item.setRect(rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f62f457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5.QtCore import QRectF\n",
    "\n",
    "# test_rect = QRectF(-10.104885544514367, -0.3724311354808627, 9.104885544514367, 1.3724311354808627)\n",
    "# test_rect = QRectF(-14.0, 0.0, 14.0, 21.0) # looks good\n",
    "# test_rect = text.boundingRect()\n",
    "rect = text.boundingRect()\n",
    "# parent_test_rect = text.parentWidget().boundingRect()\n",
    "if text.parentWidget() is not None:\n",
    "    parent_width = text.parentWidget().width()\n",
    "    if parent_width > rect.width():\n",
    "        rect.setWidth(parent_width)\n",
    "        \n",
    "rect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab736093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_rect = QRectF(0.0, 0.0, 14.0, 21.0) # misaligned\n",
    "# test_rect\n",
    "\n",
    "# test_rect.setWidth(100.0)\n",
    "test_rect.setWidth(text.parentWidget().width())\n",
    "test_rect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6272095b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1e8cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.rect_item.setRect(rect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58dbf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.rect_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0339c5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out.update_cell_emphasis(solo_emphasized_aclus=[7, 40, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53c0a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out._build_internal_callback_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b5126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "connections = _out.ui.setdefault('connections', {})\n",
    "connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50bf97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test_on_mouse_clicked(event):\n",
    "    print(f'_test_on_mouse_clicked(...)')\n",
    "    print(f'\\tevent: {event}')\n",
    "    print('\\tend.')\n",
    "\n",
    "def _test_on_mouse_moved(pos):\n",
    "    print(f'_test_on_mouse_moved(pos: {pos})')\n",
    "    \n",
    "\n",
    "_out.params.on_mouse_clicked_callback_fn_dict = {'_test_on_mouse_clicked': _test_on_mouse_clicked}\n",
    "_out.params.on_mouse_moved_callback_fn_dict = {'_test_on_mouse_moved': _test_on_mouse_moved}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be160b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out.params.on_mouse_clicked_callback_fn_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d010f23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test_on_mouse_clicked(event):\n",
    "    print(f'_test_on_mouse_clicked(...)')\n",
    "    print(f'\\tevent: {event}')\n",
    "    print('\\tend.')\n",
    "\n",
    "def _test_on_mouse_moved(pos):\n",
    "    print(f'_test_on_mouse_moved(pos: {pos})')\n",
    "    \n",
    "\n",
    "# _connections = {}\n",
    "for a_decoder_name, (curr_win, curr_img) in _out.pf1D_heatmaps.items():\n",
    "    print(f'a_decoder_name: {a_decoder_name}')\n",
    "    print(f'\\t curr_win: {curr_win}')\n",
    "    print(f'\\t curr_img: {curr_img}')\n",
    "    curr_win.sigMouseClicked.connect(_out.on_mouse_click)\n",
    "    view_box: pg.ViewBox = curr_win.getViewBox()\n",
    "    print(f'\\t view_box: {view_box}')\n",
    "    a_scene: pg.GraphicsScene = view_box.scene()\n",
    "    print(f'\\t a_scene: {a_scene}')\n",
    "    a_scene.setClickRadius(4.0)\n",
    "    # _connections[a_decoder_name] = view_box.scene().sigMouseClicked.connect(_test_on_mouse_clicked)\n",
    "    # _connections[a_decoder_name] = a_scene.sigMouseClicked.connect(_test_on_mouse_clicked)\n",
    "    # _connections[a_decoder_name] = \n",
    "    # a_scene.sigMouseClicked.connect(_test_on_mouse_clicked)\n",
    "    # view_box.scene().sigMouseMoved.connect(_test_on_mouse_moved)\n",
    "    print(f'\\t \"{a_decoder_name}\" connections done.')\n",
    "    \n",
    "    # view_box.scene().sigSceneMousePress.connect(_test_on_SceneMousePress)\n",
    "    # view_box.scene().sigMousePressed.connect(lambda event: print(f'Mouse pressed at: {event.scenePos()}'))\n",
    "\n",
    "print(f'all connections done.')\n",
    "# a_scene.setClickRadius(4.0)\n",
    "# a_scene.sigMouseClicked\n",
    "# a_scene.sigMouseMoved\n",
    "# a_scene.sigMouseHover\n",
    "\n",
    "# GraphicsView:\n",
    "# sigSceneMouseMoved\n",
    "# sigMouseReleased\n",
    "\n",
    "# PlotWidget(GraphicsView)\n",
    "# sigRangeChanged = QtCore.Signal(object, object)\n",
    "# sigTransformChanged = QtCore.Signal(object)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f420f308",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in _connections.items():\n",
    "    v.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f91c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out_ui.order_location_lines_dict[a_decoder_name][aclu] # Dict[types.DecoderName, Dict[types.aclu, pg.TextItem]]\n",
    "\n",
    "_out.pf1D_heatmaps\n",
    "\n",
    "# Dict[types.DecoderName, Tuple[pg.PlotWidget, pg.ImageItem]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4757c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a791edb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1323cc",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots\n",
    "\n",
    "\n",
    "_out = batch_perform_all_plots(curr_active_pipeline=curr_active_pipeline, enable_neptune=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270d9015",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# Sample 2D matrix\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import pv\n",
    "\n",
    "matrix = np.random.rand(10, 10)\n",
    "\n",
    "# Coordinates\n",
    "x, y = np.meshgrid(np.arange(matrix.shape[1]), np.arange(matrix.shape[0]))\n",
    "z = matrix.flatten()\n",
    "\n",
    "# Colors based on recency of updates (for example purposes, random values)\n",
    "colors = np.random.rand(matrix.size)\n",
    "\n",
    "# Create the plotter\n",
    "plotter = pv.Plotter()\n",
    "\n",
    "# Add points (dots)\n",
    "points = np.column_stack((x.flatten(), y.flatten(), z))\n",
    "point_cloud = pv.PolyData(points)\n",
    "point_cloud['colors'] = colors\n",
    "plotter.add_mesh(point_cloud, render_points_as_spheres=True, point_size=10, scalars='colors', cmap='viridis')\n",
    "\n",
    "# Add stems\n",
    "for i in range(len(z)):\n",
    "    line = pv.Line([x.flatten()[i], y.flatten()[i], 0], [x.flatten()[i], y.flatten()[i], z[i]])\n",
    "    plotter.add_mesh(line, color='black')\n",
    "\n",
    "# Show plot\n",
    "plotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23611eac",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.plot.display_function_items\n",
    "\n",
    "# '_display_directional_template_debugger'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9d9ea5",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2b60f6",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.prepare_for_display()\n",
    "directional_laps_overview = curr_active_pipeline.display(display_function='_display_directional_laps_overview')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36ee6cb",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_pic_placefields = curr_active_pipeline.display('_display_1d_placefields', long_LR_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0867cad3",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_pic_placefields_short_LR = curr_active_pipeline.display('_display_1d_placefields', short_LR_context)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c334080",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_display_function_docs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fca22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_display_function_docs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f049ee8",
   "metadata": {},
   "source": [
    "### <a id='toc8_1_4_'></a>[Plot specific `PhoPaginatedMultiDecoderDecodedEpochsWindow`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16284f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import PhoPaginatedMultiDecoderDecodedEpochsWindow, DecodedEpochSlicesPaginatedFigureController, EpochSelectionsObject, ClickActionCallbacks\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.ThinButtonBar.ThinButtonBarWidget import ThinButtonBarWidget\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.PaginationCtrl.PaginationControlWidget import PaginationControlWidget, PaginationControlWidgetState\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from pyphoplacecellanalysis.Resources import GuiResources, ActionIcons, silx_resources_rc\n",
    "## INPUTS filtered_decoder_filter_epochs_decoder_result_dict\n",
    "# decoder_decoded_epochs_result_dict: generic\n",
    "\n",
    "app, paginated_multi_decoder_decoded_epochs_window, pagination_controller_dict = PhoPaginatedMultiDecoderDecodedEpochsWindow.init_from_track_templates(curr_active_pipeline, track_templates,\n",
    "                                                                                                # decoder_decoded_epochs_result_dict=decoder_ripple_filter_epochs_decoder_result_dict, epochs_name='ripple',\n",
    "                                                                                                # decoder_decoded_epochs_result_dict=filtered_decoder_filter_epochs_decoder_result_dict, epochs_name='ripple',\n",
    "                                                                                                # decoder_decoded_epochs_result_dict=filtered_ripple_simple_pf_pearson_merged_df, epochs_name='ripple',\n",
    "                                                                                                # decoder_decoded_epochs_result_dict=long_like_during_post_delta_only_filtered_decoder_filter_epochs_decoder_result_dict, epochs_name='ripple', title='Long-like post-Delta Ripples Only', ## RIPPLE\n",
    "                                                                                                decoder_decoded_epochs_result_dict=decoder_laps_filter_epochs_decoder_result_dict, epochs_name='laps', ## LAPS\n",
    "                                                                                                included_epoch_indicies=None, debug_print=False,\n",
    "                                                                                                params_kwargs={'enable_per_epoch_action_buttons': False,\n",
    "                                                                                                    'skip_plotting_most_likely_positions': True, 'skip_plotting_measured_positions': True, \n",
    "                                                                                                    'enable_decoded_most_likely_position_curve': False, 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': True,\n",
    "                                                                                                    # 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': False,\n",
    "                                                                                                    # 'disable_y_label': True,\n",
    "                                                                                                    'isPaginatorControlWidgetBackedMode': True,\n",
    "                                                                                                    'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True,\n",
    "                                                                                                    # 'debug_print': True,\n",
    "                                                                                                    'max_subplots_per_page': 10,\n",
    "                                                                                                    'scrollable_figure': False,\n",
    "                                                                                                    # 'scrollable_figure': True,\n",
    "                                                                                                    # 'posterior_heatmap_imshow_kwargs': dict(vmin=0.0075),\n",
    "                                                                                                    'use_AnchoredCustomText': False,\n",
    "                                                                                                    'should_suppress_callback_exceptions': False,\n",
    "                                                                                                    # 'build_fn': 'insets_view',\n",
    "                                                                                                })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c501151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.add_data_overlays(decoder_ripple_filter_epochs_decoder_result_dict=deepcopy(filtered_decoder_filter_epochs_decoder_result_dict),\n",
    " included_columns=['P_decoder', 'wcorr',\n",
    "#'avg_jump_cm', 'max_jump_cm',\n",
    "'longest_sequence_length', 'continuous_seq_sort', 'ratio_jump_valid_bins',\n",
    "], defer_refresh=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d612cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.remove_data_overlays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c137f7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.indexing_helpers import NumpyHelpers, PandasHelpers\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import get_track_length_dict\n",
    "\n",
    "## INPUTS: track_templates, a_decoded_filter_epochs_decoder_result_dict\n",
    "decoder_grid_bin_bounds_dict = {a_name:a_decoder.pf.config.grid_bin_bounds for a_name, a_decoder in track_templates.get_decoders_dict().items()}\n",
    "assert NumpyHelpers.all_allclose(list(decoder_grid_bin_bounds_dict.values())), f\"all decoders should have the same grid_bin_bounds (independent of whether they are built on long/short, etc but they do not! This violates following assumptions.\"\n",
    "grid_bin_bounds = list(decoder_grid_bin_bounds_dict.values())[0] # tuple\n",
    "actual_track_length_dict, idealized_track_length_dict = get_track_length_dict(grid_bin_bounds, grid_bin_bounds)\n",
    "# idealized_track_length_dict # {'long': 214.0, 'short': 144.0}\n",
    "decoder_track_length_dict = {a_name:idealized_track_length_dict[a_name.split('_', maxsplit=1)[0]] for a_name, a_result in a_decoded_filter_epochs_decoder_result_dict.items()} # \n",
    "decoder_track_length_dict # {'long_LR': 214.0, 'long_RL': 214.0, 'short_LR': 144.0, 'short_RL': 144.0}\n",
    "## OUTPUTS: decoder_track_length_dict\n",
    "\n",
    "same_thresh_fraction_of_track: float = 0.1 ## up to 10% of the track\n",
    "same_thresh_cm: float = {k:(v * same_thresh_fraction_of_track) for k, v in decoder_track_length_dict.items()}\n",
    "# same_thresh_n_bin_units: float = {k:(v * same_thresh_fraction_of_track) for k, v in decoder_track_length_dict.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe6fd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.indexing_helpers import ListHelpers\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring, HeuristicScoresTuple, SubsequencesPartitioningResult, is_valid_sequence_index\n",
    "\n",
    "\n",
    "a_result: DecodedFilterEpochsResult = filtered_decoder_filter_epochs_decoder_result_dict['long_LR']\n",
    "# a_result: DecodedFilterEpochsResult = a_decoded_filter_epochs_decoder_result_dict['long_LR'] # 1D\n",
    "an_epoch_idx: int = 5\n",
    "\n",
    "\n",
    "## INPUTS: a_result: DecodedFilterEpochsResult, an_epoch_idx: int = 1, a_decoder_track_length: float\n",
    "a_most_likely_positions_list = a_result.most_likely_positions_list[an_epoch_idx]\n",
    "a_p_x_given_n = a_result.p_x_given_n_list[an_epoch_idx] # np.shape(a_p_x_given_n): (62, 9)\n",
    "n_time_bins: int = a_result.nbins[an_epoch_idx]\n",
    "n_pos_bins: int = np.shape(a_p_x_given_n)[0]\n",
    "time_window_centers = a_result.time_window_centers[an_epoch_idx]\n",
    "# a_track_length_cm: float = same_thresh_cm['long_LR']\n",
    "a_same_thresh_cm: float = same_thresh_cm['long_LR']\n",
    "\n",
    "\n",
    "print(f'n_time_bins: {n_time_bins}')\n",
    "\n",
    "# INPUTS: a_most_likely_positions_list, n_pos_bins\n",
    "\n",
    "a_first_order_diff = np.diff(a_most_likely_positions_list, n=1, prepend=[a_most_likely_positions_list[0]])\n",
    "assert len(a_first_order_diff) == len(a_most_likely_positions_list), f\"the prepend above should ensure that the sequence and its first-order diff are the same length.\"\n",
    "# Calculate the signs of the differences\n",
    "# a_first_order_diff_sign = np.sign(a_first_order_diff)\n",
    "# Calculate where the sign changes occur (non-zero after taking diff of signs)\n",
    "# sign_change_indices = np.where(np.diff(a_first_order_diff_sign) != 0)[0] + 1  # Add 1 because np.diff reduces the index by 1\n",
    "\n",
    "## 2024-05-09 Smarter method that can handle relatively constant decoded positions with jitter:\n",
    "# partition_result: SubsequencesPartitioningResult = SubsequencesPartitioningResult.partition_subsequences_ignoring_repeated_similar_positions(a_first_order_diff, same_thresh=same_thresh)  # Add 1 because np.diff reduces the index by 1\n",
    "partition_result: SubsequencesPartitioningResult = SubsequencesPartitioningResult.init_from_positions_list(a_most_likely_positions_list, n_pos_bins=n_pos_bins, max_ignore_bins=2, same_thresh=a_same_thresh_cm)\n",
    "\n",
    "partition_result\n",
    "# sign_change_indices = np.where(np.abs(np.diff(a_first_order_diff_sign.astype(float))) > 0.0)[0] + 1  # Add 1 because np.diff reduces the index by 1 -- Oh no, is this right when I preserve length?\n",
    "\n",
    "# total_first_order_change: float = np.nansum(a_first_order_diff[1:]) # this is very susceptable to misplaced bins\n",
    "# epoch_change_direction: float = np.sign(total_first_order_change) # -1.0 or 1.0\n",
    "                        \n",
    "# position = deepcopy(a_most_likely_positions_list)\n",
    "# velocity = a_first_order_diff / float(a_result.decoding_time_bin_size) # velocity with real world units of cm/sec\n",
    "# acceleration = np.diff(velocity, n=1, prepend=[velocity[0]])\n",
    "\n",
    "# position_derivatives_df: pd.DataFrame = pd.DataFrame({'t': time_window_centers, 'x': position, 'vel_x': velocity, 'accel_x': acceleration})\n",
    "\n",
    "# position_derivative_column_names = ['x', 'vel_x', 'accel_x']\n",
    "# position_derivative_means = position_derivatives_df.mean(axis='index')[position_derivative_column_names].to_numpy()\n",
    "# position_derivative_medians = position_derivatives_df.median(axis='index')[position_derivative_column_names].to_numpy()\n",
    "# # position_derivative_medians = position_derivatives_df(axis='index')[position_derivative_column_names].to_numpy()\n",
    "\n",
    "# position_derivatives_df: pd.DataFrame = _compute_pos_derivs(time_window_centers=time_window_centers, position=a_most_likely_positions_list, debug_print=False)\n",
    "\n",
    "# Now split the array at each point where a direction change occurs\n",
    "\n",
    "\n",
    "# num_direction_changes: int = len(sign_change_indices)\n",
    "# direction_change_bin_ratio: float = float(num_direction_changes) / (float(n_time_bins)-1) ## OUT: direction_change_bin_ratio\n",
    "\n",
    "# Split the array at each index where a sign change occurs\n",
    "relative_indicies_arr = np.arange(n_pos_bins)\n",
    "\n",
    "# active_split_indicies = deepcopy(partition_result.split_indicies) ## this is what it should be, but all the splits are +1 later than they should be\n",
    "active_split_indicies = deepcopy(partition_result.diff_split_indicies) ## this is what it should be, but all the splits are +1 later than they should be\n",
    "\n",
    "split_relative_indicies = np.split(relative_indicies_arr, active_split_indicies)\n",
    "split_most_likely_positions_arrays = np.split(a_most_likely_positions_list, active_split_indicies)\n",
    "split_most_likely_positions_arrays\n",
    "\n",
    "# split_first_order_diff_arrays = np.split(a_first_order_diff, partition_result.split_indicies)\n",
    "split_first_order_diff_arrays = np.split(a_first_order_diff, partition_result.diff_split_indicies)\n",
    "\n",
    "# continuous_sequence_lengths = np.array([len(a_split_first_order_diff_array) for a_split_first_order_diff_array in split_first_order_diff_arrays])\n",
    "# longest_sequence_length: int = np.nanmax(continuous_sequence_lengths) # Now find the length of the longest non-changing sequence\n",
    "# longest_sequence_start_idx: int = np.nanargmax(continuous_sequence_lengths)\n",
    "\n",
    "# longest_sequence_indicies = split_relative_indicies[longest_sequence_start_idx]\n",
    "# longest_sequence = split_most_likely_positions_arrays[longest_sequence_start_idx]\n",
    "# longest_sequence_diff = split_first_order_diff_arrays[longest_sequence_start_idx]\n",
    "\n",
    "# longest_sequence\n",
    "split_diff_index_subsequence_index_arrays = np.split(np.arange(partition_result.n_diff_bins), partition_result.diff_split_indicies) # subtract 1 again to get the diff_split_indicies instead\n",
    "no_low_magnitude_diff_index_subsequence_indicies = [v[np.isin(v, partition_result.low_magnitude_change_indicies, invert=True)] for v in split_diff_index_subsequence_index_arrays] # get the list of indicies for each subsequence without the low-magnitude ones\n",
    "num_subsequence_bins = np.array([len(v) for v in split_diff_index_subsequence_index_arrays]) # np.array([4, 6])\n",
    "num_subsequence_bins_no_repeats = np.array([len(v) for v in no_low_magnitude_diff_index_subsequence_indicies]) # np.array([1, 1])\n",
    "\n",
    "# num_subsequence_bins: number of tbins in each split sequence\n",
    "# num_subsequence_bins_no_repeats\n",
    "\n",
    "total_num_subsequence_bins = np.sum(num_subsequence_bins)\n",
    "total_num_subsequence_bins_no_repeats = np.sum(num_subsequence_bins_no_repeats)\n",
    "\n",
    "# continuous_sequence_lengths = np.array([len(a_split_first_order_diff_array) for a_split_first_order_diff_array in split_diff_index_subsequence_index_arrays])\n",
    "# longest_sequence_length: int = np.nanmax(continuous_sequence_lengths) # Now find the length of the longest non-changing sequence\n",
    "# longest_sequence_start_idx: int = np.nanargmax(continuous_sequence_lengths)\n",
    "\n",
    "longest_sequence_length_no_repeats: int = int(np.nanmax(num_subsequence_bins_no_repeats)) # Now find the length of the longest non-changing sequence\n",
    "longest_sequence_no_repeats_start_idx: int = int(np.nanargmax(num_subsequence_bins_no_repeats)) ## the actual start index of the longest sequence!\n",
    "# longest_sequence_no_repeats_start_idx\n",
    "\n",
    "fig, ax = _debug_plot_time_bins_multiple(positions_list=split_most_likely_positions_arrays)\n",
    "\n",
    "## \n",
    "max_ignore_bins: int = 2\n",
    "# (left_congruent_flanking_sequence, left_congruent_flanking_index), (right_congruent_flanking_sequence, right_congruent_flanking_index) = _compute_sequences_spanning_ignored_intrusions(split_first_order_diff_arrays, continuous_sequence_lengths, longest_sequence_start_idx=longest_sequence_start_idx, max_ignore_bins=max_ignore_bins)\n",
    "# (left_congruent_flanking_sequence, left_congruent_flanking_index), (right_congruent_flanking_sequence, right_congruent_flanking_index) = _compute_sequences_spanning_ignored_intrusions(split_first_order_diff_arrays, num_subsequence_bins_no_repeats, target_subsequence_idx=longest_sequence_no_repeats_start_idx, max_ignore_bins=max_ignore_bins)\n",
    "# left_congruent_flanking_sequence\n",
    "# right_congruent_flanking_sequence\n",
    "\n",
    "_tmp_merge_split_positions_arrays, final_out_subsequences, (subsequence_replace_dict, subsequences_to_add, subsequences_to_remove) = partition_result.merge_over_ignored_intrusions(max_ignore_bins=max_ignore_bins)\n",
    "\n",
    "\n",
    "fig2, ax2 = _debug_plot_time_bins_multiple(positions_list=final_out_subsequences, num='debug_plot_merged_time_binned_positions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6496dfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_result.low_magnitude_change_indicies\n",
    "partition_result.split_indicies\n",
    "partition_result.num_merged_subsequence_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c2a582",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ignore_bins: int = 2\n",
    "_tmp_merge_split_positions_arrays, final_out_subsequences, (subsequence_replace_dict, subsequences_to_add, subsequences_to_remove) = partition_result.merge_over_ignored_intrusions(max_ignore_bins=max_ignore_bins)\n",
    "_tmp_merge_split_positions_arrays\n",
    "subsequence_replace_dict\n",
    "final_out_subsequences\n",
    "\n",
    "# subsequences = deepcopy(partition_result.split_positions_arrays)\n",
    "# subsequences\n",
    "\n",
    "# remaining_subsequence_list= [[119.191, 142.107, 180.3, 191.757, 245.227], [84.8181, 84.8181, 84.8181]]\n",
    "# remaining_subsequence_list.reverse()\n",
    "# remaining_subsequence_list\n",
    "# curr_subsequence, remaining_subsequence_list = merge_subsequences([138.288, 134.469], remaining_subsequence_list=remaining_subsequence_list)\n",
    "\n",
    "# merged_subsequences = merge_subsequences(subsequences, max_ignore_bins=1)\n",
    "# merged_subsequences\n",
    "fig2, ax2 = _debug_plot_time_bins_multiple(positions_list=final_out_subsequences, num='debug_plot_merged_time_binned_positions')\n",
    "\n",
    "# array([138.288, 134.469]), array([69.5411]), array([249.046, 249.046, 249.046])\n",
    "# array([138.288, 134.469, 69.5411, 249.046, 249.046, 249.046])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5700142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# (left_congruent_flanking_sequence, left_congruent_flanking_index), (right_congruent_flanking_sequence, right_congruent_flanking_index) = _compute_sequences_spanning_ignored_intrusions(split_first_order_diff_arrays, continuous_sequence_lengths, longest_sequence_start_idx=longest_sequence_start_idx, max_ignore_bins=max_ignore_bins)\n",
    "(left_congruent_flanking_sequence, left_congruent_flanking_index), (right_congruent_flanking_sequence, right_congruent_flanking_index) = _compute_sequences_spanning_ignored_intrusions(split_first_order_diff_arrays, num_subsequence_bins_no_repeats,\n",
    "                                                                                                                                                                                        target_subsequence_idx=longest_sequence_no_repeats_start_idx, max_ignore_bins=max_ignore_bins)\n",
    "print(f\"{left_congruent_flanking_sequence}: {left_congruent_flanking_sequence}\")\n",
    "print(f\"{right_congruent_flanking_sequence}: {right_congruent_flanking_sequence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dc55ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_result.low_magnitude_change_indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe419bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_result.list_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ecd774",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "_debug_plot_time_binned_positions(a_most_likely_positions_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8283660",
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_sequence_length_ratio = HeuristicReplayScoring.bin_wise_continuous_sequence_sort_score_fn(a_result=a_result, an_epoch_idx=an_epoch_idx, a_decoder_track_length=170.0, same_thresh=same_thresh)\n",
    "longest_sequence_length_ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2222ed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_filter_epochs_df = deepcopy(decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)\n",
    "active_filter_epochs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18893078",
   "metadata": {},
   "source": [
    "# <a id='toc9_'></a>[üñºÔ∏èüé® 2024-02-28 - WE gotta see the replays on the 3D track. Or the 2D track.](#toc0_)\n",
    "2024-04-28 - This is working in both 3D and 2D!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714ad549",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "## INPUTS: directional_laps_results, global_replays, decoder_ripple_filter_epochs_decoder_result_dict\n",
    "\n",
    "# global_pf1D\n",
    "# long_replays\n",
    "# direction_max_indices = ripple_all_epoch_bins_marginals_df[['P_Long', 'P_Short']].values.argmax(axis=1)\n",
    "# track_identity_max_indices = ripple_all_epoch_bins_marginals_df[['P_Long', 'P_Short']].values.argmax(axis=1)\n",
    "\n",
    "## How do I get the replays?\n",
    "# long_replay_df: pd.DataFrame = long_replays.to_dataframe() ## These work.\n",
    "# global_replay_df: pd.DataFrame = global_replays.to_dataframe() ## These work.\n",
    "# global_replay_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721e8e2b",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "## 1D version:\n",
    "## INPUTS: directional_laps_results, decoder_ripple_filter_epochs_decoder_result_dict\n",
    "xbin = deepcopy(directional_laps_results.get_decoders()[0].xbin)\n",
    "xbin_centers = deepcopy(directional_laps_results.get_decoders()[0].xbin_centers)\n",
    "ybin_centers = None\n",
    "ybin = None\n",
    "\n",
    "a_decoded_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(decoder_laps_filter_epochs_decoder_result_dict)\n",
    "# a_decoded_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "# a_decoded_filter_epochs_decoder_result_dict\n",
    "\n",
    "## 1D:\n",
    "a_result: DecodedFilterEpochsResult = a_decoded_filter_epochs_decoder_result_dict['long_LR'] # 1D\n",
    "\n",
    "## OUTPUTS: a_decoded_filter_epochs_decoder_result_dict, xbin_centers, ybin_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31cdc1d",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "## 2D version:\n",
    "from neuropy.analyses.placefields import PfND\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BayesianPlacemapPositionDecoder\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _compute_lap_and_ripple_epochs_decoding_for_decoder\n",
    "\n",
    "## INPUTS: long_results, short_results\n",
    "# long_one_step_decoder_2D\n",
    "\n",
    "long_one_step_decoder_2D, short_one_step_decoder_2D  = [results_data.get('pf2D_Decoder', None) for results_data in (long_results, short_results)]\n",
    "one_step_decoder_dict_2D: Dict[str, BayesianPlacemapPositionDecoder] = dict(zip(('long', 'short'), (long_one_step_decoder_2D, short_one_step_decoder_2D)))\n",
    "long_pf2D = long_results.pf2D\n",
    "# short_pf2D = short_results.pf2D\n",
    "\n",
    "xbin = deepcopy(long_pf2D.xbin)\n",
    "xbin_centers = deepcopy(long_pf2D.xbin_centers)\n",
    "ybin = deepcopy(long_pf2D.ybin)\n",
    "ybin_centers = deepcopy(long_pf2D.ybin_centers)\n",
    "\n",
    "## OUTPUTS: one_step_decoder_dict_2D, xbin_centers, ybin_centers\n",
    "\n",
    "## INPUTS: one_step_decoder_dict_2D\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "ripple_decoding_time_bin_size: float = directional_merged_decoders_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_merged_decoders_result.laps_decoding_time_bin_size\n",
    "pos_bin_size: Tuple[float, float] = list(one_step_decoder_dict_2D.values())[0].pos_bin_size\n",
    "\n",
    "print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}, ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}, pos_bin_size: {pos_bin_size}')\n",
    "\n",
    "## Decode epochs for the two decoders ('long', 'short'):\n",
    "LS_decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {}\n",
    "LS_decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {}\n",
    "\n",
    "for a_name, a_decoder in one_step_decoder_dict_2D.items():\n",
    "    LS_decoder_laps_filter_epochs_decoder_result_dict[a_name], LS_decoder_ripple_filter_epochs_decoder_result_dict[a_name] = _compute_lap_and_ripple_epochs_decoding_for_decoder(a_decoder, curr_active_pipeline, desired_laps_decoding_time_bin_size=laps_decoding_time_bin_size, desired_ripple_decoding_time_bin_size=ripple_decoding_time_bin_size)\n",
    "\n",
    "# LS_decoder_ripple_filter_epochs_decoder_result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e591738c",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "## 2D:\n",
    "# Choose the ripple epochs to plot:\n",
    "a_decoded_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(LS_decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "a_result: DecodedFilterEpochsResult = a_decoded_filter_epochs_decoder_result_dict['long'] # 2D\n",
    "# Choose the laps epochs to plot:\n",
    "# a_decoded_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(LS_decoder_laps_filter_epochs_decoder_result_dict)\n",
    "# a_decoded_filter_epochs_decoder_result_dict\n",
    "\n",
    "\n",
    "# a_result: DecodedFilterEpochsResult = LS_decoder_laps_filter_epochs_decoder_result_dict['long'] # 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d526136c",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_merged_decoders_result.perform_compute_marginals()\n",
    "directional_merged_decoders_result.laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdd1b42",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.mixins.decoder_plotting_mixins import DecodedTrajectoryMatplotlibPlotter\n",
    "\n",
    "## INPUTS: a_result: DecodedFilterEpochsResult, an_epoch_idx: int = 18\n",
    "# e.g. `a_result: DecodedFilterEpochsResult = a_decoded_filter_epochs_decoder_result_dict['long_LR']`\n",
    "\n",
    "# a_result: DecodedFilterEpochsResult = a_decoded_filter_epochs_decoder_result_dict['long_LR'] # 1D\n",
    "\n",
    "## Convert to plottable posteriors\n",
    "# an_epoch_idx: int = 0\n",
    "\n",
    "# valid_aclus = deepcopy(decoder_aclu_peak_location_df_merged.aclu.unique())\n",
    "num_filter_epochs: int = a_result.num_filter_epochs\n",
    "a_decoded_traj_plotter = DecodedTrajectoryMatplotlibPlotter(a_result=a_result, xbin=xbin, xbin_centers=xbin_centers, ybin=ybin, ybin_centers=ybin_centers)\n",
    "fig, axs, laps_pages = a_decoded_traj_plotter.plot_decoded_trajectories_2d(global_session, curr_num_subplots=8, active_page_index=0, plot_actual_lap_lines=False, use_theoretical_tracks_instead=True)\n",
    "\n",
    "integer_slider = a_decoded_traj_plotter.plot_epoch_with_slider_widget(an_epoch_idx=6)\n",
    "integer_slider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f60583e",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "type(laps_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ff87b5",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "heatmaps[0].remove()\n",
    "\n",
    "# an_ax.remove(heatmaps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfd94ef",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "an_ax = axs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fe2a86",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# plotActors, data_dict = plot_3d_stem_points(pCustom, active_epoch_placefields2D.ratemap.xbin, active_epoch_placefields2D.ratemap.ybin, active_epoch_placefields2D.ratemap.occupancy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8044b24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_plot(value=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5fd9d8",
   "metadata": {},
   "source": [
    "## <a id='toc9_1_'></a>[add to 3D plotter:](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12058a97",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.InteractiveCustomDataExplorer import InteractiveCustomDataExplorer\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.mixins.decoder_plotting_mixins import DecodedTrajectoryPyVistaPlotter\n",
    "from pyphoplacecellanalysis.Pho3D.PyVista.graphs import plot_3d_stem_points, plot_3d_binned_bars\n",
    "\n",
    "curr_active_pipeline.prepare_for_display()\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "_out = curr_active_pipeline.display(display_function='_display_3d_interactive_custom_data_explorer', active_session_configuration_context=global_epoch_context,\n",
    "                                    params_kwargs=dict(should_use_linear_track_geometry=True, **{'t_start': t_start, 't_delta': t_delta, 't_end': t_end}),\n",
    "                                    )\n",
    "iplapsDataExplorer: InteractiveCustomDataExplorer = _out['iplapsDataExplorer']\n",
    "pActiveInteractiveLapsPlotter = _out['plotter']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b011ca5",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "## INPUTS: a_result, xbin_centers, ybin_centers, iplapsDataExplorer\n",
    "# a_decoded_trajectory_pyvista_plotter: DecodedTrajectoryPyVistaPlotter = DecodedTrajectoryPyVistaPlotter(a_result=a_result, xbin=xbin, xbin_centers=xbin_centers, ybin=ybin, ybin_centers=ybin_centers, p=iplapsDataExplorer.p)\n",
    "# a_decoded_trajectory_pyvista_plotter.build_ui()\n",
    "# a_decoded_trajectory_pyvista_plotter: DecodedTrajectoryPyVistaPlotter = iplapsDataExplorer.add_decoded_posterior_bars(a_result=a_result, xbin=xbin, xbin_centers=xbin_centers, ybin=ybin, ybin_centers=ybin_centers, enable_plot_all_time_bins_in_epoch_mode=True)\n",
    "\n",
    "\n",
    "a_decoded_trajectory_pyvista_plotter: DecodedTrajectoryPyVistaPlotter = iplapsDataExplorer.add_decoded_posterior_bars(a_result=a_result, xbin=xbin, xbin_centers=xbin_centers, ybin=ybin, ybin_centers=ybin_centers, enable_plot_all_time_bins_in_epoch_mode=False, active_plot_fn=plot_3d_stem_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24cd81d",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "a_decoded_trajectory_pyvista_plotter: DecodedTrajectoryPyVistaPlotter = iplapsDataExplorer.add_decoded_posterior_bars(a_result=a_result, xbin=xbin, xbin_centers=xbin_centers, ybin=ybin, ybin_centers=ybin_centers, enable_plot_all_time_bins_in_epoch_mode=False, active_plot_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf0e317",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "iplapsDataExplorer.clear_all_added_decoded_posterior_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968821ca",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "a_decoded_trajectory_pyvista_plotter.data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7d6646",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "update_plot_fn = a_decoded_trajectory_pyvista_plotter.data_dict['plot_3d_binned_bars[55.63197815967686]']['update_plot_fn']\n",
    "# update_plot_fn(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3038982b",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# a_posterior_p_x_given_n, n_epoch_timebins = a_decoded_trajectory_pyvista_plotter._perform_get_curr_posterior(a_result=a_result, an_epoch_idx=a_decoded_trajectory_pyvista_plotter.curr_epoch_idx, time_bin_index=np.arange(a_decoded_trajectory_pyvista_plotter.curr_n_time_bins))\n",
    "# np.shape(a_posterior_p_x_given_n)\n",
    "\n",
    "\n",
    "a_posterior_p_x_given_n, n_epoch_timebins = a_decoded_trajectory_pyvista_plotter.get_curr_posterior(an_epoch_idx=a_decoded_trajectory_pyvista_plotter.curr_epoch_idx, time_bin_index=np.arange(a_decoded_trajectory_pyvista_plotter.curr_n_time_bins))\n",
    "np.shape(a_posterior_p_x_given_n)\n",
    "\n",
    "n_epoch_timebins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9878ed8b",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "v = a_decoded_trajectory_pyvista_plotter.plotActors['plot_3d_binned_bars[49.11980797704307]']\n",
    "# v['main'].remove()\n",
    "\n",
    "a_decoded_trajectory_pyvista_plotter.p.remove_actor(v['main'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6dc498",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho3D.PyVista.graphs import clear_3d_binned_bars_plots\n",
    "\n",
    "clear_3d_binned_bars_plots(p=a_decoded_trajectory_pyvista_plotter.p, plotActors=a_decoded_trajectory_pyvista_plotter.plotActors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1026b38b",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "a_decoded_trajectory_pyvista_plotter.plotActors_CenterLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aec258c",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "a_decoded_trajectory_pyvista_plotter.perform_update_plot_epoch_time_bin_range(value=None) # select all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e721a086",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "a_decoded_trajectory_pyvista_plotter.perform_clear_existing_decoded_trajectory_plots()\n",
    "iplapsDataExplorer.p.update()\n",
    "iplapsDataExplorer.p.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4795182a",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "time_bin_index = np.arange(a_decoded_trajectory_pyvista_plotter.curr_n_time_bins)\n",
    "type(time_bin_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7059eeac",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "a_decoded_trajectory_pyvista_plotter.slider_epoch.RemoveAllObservers()\n",
    "a_decoded_trajectory_pyvista_plotter.slider_epoch.Off()\n",
    "# a_decoded_trajectory_pyvista_plotter.slider_epoch.FastDelete()\n",
    "a_decoded_trajectory_pyvista_plotter.slider_epoch = None\n",
    "\n",
    "a_decoded_trajectory_pyvista_plotter.slider_epoch_time_bin.RemoveAllObservers()\n",
    "a_decoded_trajectory_pyvista_plotter.slider_epoch_time_bin.Off()\n",
    "# a_decoded_trajectory_pyvista_plotter.slider_epoch_time_bin.FastDelete()\n",
    "a_decoded_trajectory_pyvista_plotter.slider_epoch_time_bin = None\n",
    "iplapsDataExplorer.p.clear_slider_widgets()\n",
    "iplapsDataExplorer.p.update()\n",
    "iplapsDataExplorer.p.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01736aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.mixins.decoder_plotting_mixins import DecoderRenderingPyVistaMixin\n",
    "\n",
    "(plotActors, data_dict), (plotActors_CenterLabels, data_dict_CenterLabels) = DecoderRenderingPyVistaMixin.perform_plot_posterior_bars(iplapsDataExplorer.p, xbin=xbin, ybin=ybin, xbin_centers=xbin_centers, ybin_centers=ybin_centers, posterior_p_x_given_n=a_posterior_p_x_given_n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16dc768",
   "metadata": {},
   "source": [
    "### <a id='toc9_1_1_'></a>[üñºÔ∏èüé® Plot laps via `PhoPaginatedMultiDecoderDecodedEpochsWindow`:](#toc0_)\n",
    "TODO üíØ‚ùó 2024-08-15 22:58: - [ ] PhoPaginatedMultiDecoderDecodedEpochsWindow renders the list of subplots on a page with the first being on the BOTTOM and then increasing up towards the top. This is very counter-intuitive and potentially explains issues with ordering and indexing of plots. üíØ‚ùó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a564edc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_decoded_epoch_slices\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import PhoPaginatedMultiDecoderDecodedEpochsWindow, DecodedEpochSlicesPaginatedFigureController, EpochSelectionsObject, ClickActionCallbacks\n",
    "\n",
    "laps_app, laps_paginated_multi_decoder_decoded_epochs_window, laps_pagination_controller_dict = PhoPaginatedMultiDecoderDecodedEpochsWindow.init_from_track_templates(curr_active_pipeline, track_templates,\n",
    "                            decoder_decoded_epochs_result_dict=decoder_laps_filter_epochs_decoder_result_dict, epochs_name='laps',\n",
    "                            # decoder_decoded_epochs_result_dict=decoder_ripple_filter_epochs_decoder_result_dict, epochs_name='ripple',\n",
    "                            included_epoch_indicies=None, \n",
    "    params_kwargs={'enable_per_epoch_action_buttons': False,\n",
    "    'skip_plotting_most_likely_positions': True, 'skip_plotting_measured_positions': False, \n",
    "    'enable_decoded_most_likely_position_curve': False, 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': False,\n",
    "    # 'enable_decoded_most_likely_position_curve': False, 'enable_radon_transform_info': True, 'enable_weighted_correlation_info': True,\n",
    "    # 'disable_y_label': True,\n",
    "    # 'isPaginatorControlWidgetBackedMode': True,\n",
    "    # 'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True,\n",
    "    # 'debug_print': True,\n",
    "    # 'max_subplots_per_page': 10,\n",
    "    # 'scrollable_figure': False,\n",
    "    'max_subplots_per_page': 50,\n",
    "    'scrollable_figure': True,\n",
    "    # 'posterior_heatmap_imshow_kwargs': dict(vmin=0.0075),\n",
    "    'use_AnchoredCustomText': False,\n",
    "    # 'build_fn': 'insets_view',\n",
    "    })\n",
    "\n",
    "#TODO üíØ‚ùó 2024-08-15 22:58: - [ ] PhoPaginatedMultiDecoderDecodedEpochsWindow renders the list of subplots on a page with the first being on the BOTTOM and then increasing up towards the top. This is very counter-intuitive and potentially explains issues with ordering and indexing of plots. üíØ‚ùó\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bd3f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "yellow_blue_trackID_marginals_plot_tuple = laps_paginated_multi_decoder_decoded_epochs_window.build_attached_yellow_blue_track_identity_marginal_window(decoder_laps_filter_epochs_decoder_result_dict, global_session, 0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2e0dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult, SingleEpochDecodedResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.computer_vision import ComputerVisionComputations\n",
    "from pyphocorehelpers.plotting.media_output_helpers import img_data_to_greyscale\n",
    "\n",
    "parent_output_folder = Path(r'K:/scratch/collected_outputs/figures/_temp_individual_posteriors').resolve()\n",
    "# parent_output_folder = Path(r\"E:\\Dropbox (Personal)\\Active\\Kamran Diba Lab\\Pho-Kamran-Meetings\\2024-08-20 - Finalizing Transition Matrix\\_temp_individual_posteriors\").resolve()\n",
    "posterior_out_folder = parent_output_folder.joinpath(DAY_DATE_TO_USE).resolve()\n",
    "posterior_out_folder.mkdir(parents=True, exist_ok=True)\n",
    "save_path = posterior_out_folder.resolve()\n",
    "_parent_save_context: IdentifyingContext = curr_active_pipeline.build_display_context_for_session('perform_export_all_decoded_posteriors_as_images')\n",
    "out_paths = ComputerVisionComputations.perform_export_all_decoded_posteriors_as_images(decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict, _save_context=_parent_save_context, parent_output_folder=save_path, desired_height=None)\n",
    "# out_paths\n",
    "fullwidth_path_widget(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8736da11",
   "metadata": {},
   "source": [
    "# <a id='toc10_'></a>[Other Misc Plotting Stuff](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521bba12",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.plot._display_directional_template_debugger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb5ba90",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_template_debugger')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e9208a",
   "metadata": {},
   "source": [
    "### <a id='toc10_1_1_'></a>[Resume display stuff](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50f2ef8",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from flexitext import flexitext\n",
    "from neuropy.utils.matplotlib_helpers import FormattedFigureText, FigureMargins ## flexitext version\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out = curr_active_pipeline.display('_display_directional_track_template_pf1Ds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d2b444",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# _restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080c1041",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_two_step_decoder_prediction_error_2D', global_epoch_context, variable_name='p_x_given_n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e05b045",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_plot_most_likely_position_comparisons', global_epoch_context) # , variable_name='p_x_given_n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddebd9e",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_laps_overview')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d805c37",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_laps_overview')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3c3cea",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "'_display_directional_laps_overview'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb98e796",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# '_display_directional_merged_pfs'\n",
    "_out = curr_active_pipeline.display('_display_directional_merged_pfs', plot_all_directions=False, plot_long_directional=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47076a61",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "'_display_1d_placefield_occupancy'\n",
    "'_display_placemaps_pyqtplot_2D'\n",
    " '_display_2d_placefield_occupancy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481df233",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_2d_placefield_occupancy', global_any_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694d0a20",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_grid_bin_bounds_validation')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fbe6ee",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "_out = curr_active_pipeline.display('_display_running_and_replay_speeds_over_time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58951b11",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.utils.matplotlib_helpers import add_rectangular_selector, add_range_selector\n",
    "\n",
    "\n",
    "# epoch_name = global_any_name\n",
    "epoch_name = short_epoch_name\n",
    "computation_result = curr_active_pipeline.computation_results[epoch_name]\n",
    "grid_bin_bounds = computation_result.computation_config['pf_params'].grid_bin_bounds\n",
    "epoch_context = curr_active_pipeline.filtered_contexts[epoch_name]\n",
    "print(grid_bin_bounds)     \n",
    "fig, ax = computation_result.computed_data.pf2D.plot_occupancy(identifier_details_list=[epoch_name], active_context=epoch_context) \n",
    "\n",
    "# rect_selector, set_extents, reset_extents = add_rectangular_selector(fig, ax, initial_selection=grid_bin_bounds) # (24.82, 257.88), (125.52, 149.19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada4720b",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import add_vertical_track_bounds_lines\n",
    "\n",
    "grid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\n",
    "long_track_line_collection, short_track_line_collection = add_vertical_track_bounds_lines(grid_bin_bounds=grid_bin_bounds, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b862a66",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.peak_location_representing import compute_placefield_center_of_mass_positions\n",
    "\n",
    "\n",
    "epoch_name = global_any_name\n",
    "computation_result = curr_active_pipeline.computation_results[epoch_name]\n",
    "grid_bin_bounds = deepcopy(computation_result.computation_config['pf_params'].grid_bin_bounds)\n",
    "epoch_context = curr_active_pipeline.filtered_contexts[epoch_name]\n",
    "\n",
    "grid_bin_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65654f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5905e90b",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "grid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\n",
    "grid_bin_bounds\n",
    "long_pf2D.xbin\n",
    "long_pf2D.ybin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befc3d1d",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "occupancy = deepcopy(long_pf2D.occupancy) # occupancy.shape # (60, 15)\n",
    "xbin = deepcopy(long_pf2D.xbin)\n",
    "ybin = deepcopy(long_pf2D.ybin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0416d4",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from scipy import ndimage # used for `compute_placefield_center_of_masses`\n",
    "from neuropy.utils.mixins.peak_location_representing import compute_occupancy_center_of_mass_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6352663",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "occupancy_x_center_dict = {k:compute_occupancy_center_of_mass_positions(v.pf.occupancy, xbin=v.pf.xbin, ybin=v.pf.ybin).item() for k, v in track_templates.get_decoders_dict().items()}\n",
    "occupancy_x_center_dict # {'long_LR': 162.99271603199625, 'long_RL': 112.79866056603696, 'short_LR': 138.45611791646, 'short_RL': 130.78889937230684}\n",
    "\n",
    "occupancy_mask_x_center_dict = {k:compute_occupancy_center_of_mass_positions(v.pf.visited_occupancy_mask, xbin=v.pf.xbin, ybin=v.pf.ybin).item() for k, v in track_templates.get_decoders_dict().items()}\n",
    "occupancy_mask_x_center_dict # {'long_LR': 135.66781520875904, 'long_RL': 130.0042755113645, 'short_LR': 133.77996864296085, 'short_RL': 143.21920147195175}\n",
    "\n",
    "\n",
    "# {k:compute_occupancy_center_of_mass_positions(v.pf.occupancy, xbin=v.pf.xbin, ybin=v.pf.ybin).item() for k, v in track_templates.get_decoders_dict().items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb029d8",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "occupancy = deepcopy(long_pf2D.occupancy) # occupancy.shape # (60, 15)\n",
    "xbin = deepcopy(long_pf2D.xbin)\n",
    "ybin = deepcopy(long_pf2D.ybin)\n",
    "\n",
    "# masked_nonzero_occupancy = deepcopy(long_pf2D.nan_never_visited_occupancy)\n",
    "\n",
    "masked_nonzero_occupancy = deepcopy(long_pf2D.visited_occupancy_mask)\n",
    "\n",
    "# occupancy_CoM_positions = compute_occupancy_center_of_mass_positions(occupancy, xbin=long_pf2D.xbin, ybin=long_pf2D.ybin)\n",
    "occupancy_CoM_positions = compute_occupancy_center_of_mass_positions(masked_nonzero_occupancy, xbin=long_pf2D.xbin, ybin=long_pf2D.ybin) # array([127.704, 145.63])\n",
    "occupancy_CoM_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097c3b06",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "long_pf2D.nan_never_visited_occupancy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4caa06",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_display_function_docs_dict# '_display_grid_bin_bounds_validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f963a7",
   "metadata": {
    "tags": [
     "all",
     "2025-01-23"
    ]
   },
   "outputs": [],
   "source": [
    "## Extracting on 2024-02-06 to display the LR/RL directions instead of the All/Long/Short pfs:\n",
    "def _display_directional_merged_pfs(owning_pipeline_reference, global_computation_results, computation_results, active_configs, include_includelist=None, save_figure=True, included_any_context_neuron_ids=None,\n",
    "                                    plot_all_directions=True, plot_long_directional=False, plot_short_directional=False, **kwargs):\n",
    "    \"\"\" Plots the merged pseduo-2D pfs/ratemaps. Plots: All-Directions, Long-Directional, Short-Directional in seperate windows. \n",
    "    \n",
    "    History: this is the Post 2022-10-22 display_all_pf_2D_pyqtgraph_binned_image_rendering-based method:\n",
    "    \"\"\"\n",
    "    from pyphoplacecellanalysis.Pho2D.PyQtPlots.plot_placefields import pyqtplot_plot_image_array, display_all_pf_2D_pyqtgraph_binned_image_rendering\n",
    "    from pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow \n",
    "    from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import LayoutScrollability\n",
    "\n",
    "    defer_render = kwargs.pop('defer_render', False)\n",
    "    directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "    active_merged_pf_plots_data_dict = {} #empty dict\n",
    "    \n",
    "    if plot_all_directions:\n",
    "        active_merged_pf_plots_data_dict[owning_pipeline_reference.build_display_context_for_session(track_config='All-Directions', display_fn_name='display_all_pf_2D_pyqtgraph_binned_image_rendering')] = directional_merged_decoders_result.all_directional_pf1D_Decoder.pf # all-directions\n",
    "    if plot_long_directional:\n",
    "        active_merged_pf_plots_data_dict[owning_pipeline_reference.build_display_context_for_session(track_config='Long-Directional', display_fn_name='display_all_pf_2D_pyqtgraph_binned_image_rendering')] = directional_merged_decoders_result.long_directional_pf1D_Decoder.pf # Long-only\n",
    "    if plot_short_directional:\n",
    "        active_merged_pf_plots_data_dict[owning_pipeline_reference.build_display_context_for_session(track_config='Short-Directional', display_fn_name='display_all_pf_2D_pyqtgraph_binned_image_rendering')] = directional_merged_decoders_result.short_directional_pf1D_Decoder.pf # Short-only\n",
    "\n",
    "    out_plots_dict = {}\n",
    "    \n",
    "    for active_context, active_pf_2D in active_merged_pf_plots_data_dict.items():\n",
    "        # figure_format_config = {} # empty dict for config\n",
    "        neuron_values = deepcopy(active_pf_2D.peak_tuning_curve_center_of_mass_bin_coordinates)\n",
    "        sort_indices = np.lexsort((neuron_values[:, 1], neuron_values[:, 0]))\n",
    "        figure_format_config = {'scrollability_mode': LayoutScrollability.NON_SCROLLABLE, 'included_unit_indicies': sort_indices} # kwargs # kwargs as default figure_format_config\n",
    "        out_all_pf_2D_pyqtgraph_binned_image_fig: BasicBinnedImageRenderingWindow  = display_all_pf_2D_pyqtgraph_binned_image_rendering(active_pf_2D, figure_format_config) # output is BasicBinnedImageRenderingWindow\n",
    "    \n",
    "        # Set the window title from the context\n",
    "        out_all_pf_2D_pyqtgraph_binned_image_fig.setWindowTitle(f'{active_context.get_description()}')\n",
    "        out_plots_dict[active_context] = out_all_pf_2D_pyqtgraph_binned_image_fig\n",
    "\n",
    "        # Tries to update the display of the item:\n",
    "        names_list = [v for v in list(out_all_pf_2D_pyqtgraph_binned_image_fig.plots.keys()) if v not in ('name', 'context')]\n",
    "        for a_name in names_list:\n",
    "            # Adjust the size of the text for the item by passing formatted text\n",
    "            a_plot: pg.PlotItem = out_all_pf_2D_pyqtgraph_binned_image_fig.plots[a_name].mainPlotItem # PlotItem \n",
    "            # no clue why 2 is a good value for this...\n",
    "            a_plot.titleLabel.setMaximumHeight(2)\n",
    "            a_plot.layout.setRowFixedHeight(0, 2)\n",
    "            a_plot.layout.setRowFixedHeight(1, 10)\n",
    "            plot_viewbox = a_plot.getViewBox()\n",
    "            # plot_viewbox.setMinimumHeight(200)  # Set a reasonable minimum height\n",
    "            plot_viewbox.setMaximumHeight(15)  # Set a fixed height to prevent stretching\n",
    "            plot_viewbox.setBorder(None)  # Remove the border\n",
    "            plot_viewbox.setBackgroundColor(None)\n",
    "                        \n",
    "            # # Add a spacer at the bottom\n",
    "            # spacer = pg.QtWidgets.QGraphicsWidget()\n",
    "            # spacer.setSizePolicy(pg.QtWidgets.QSizePolicy.Expanding, pg.QtWidgets.QSizePolicy.Expanding)  # Flexible spacer\n",
    "            # # Add the spacer to the layout\n",
    "            # row_count = a_plot.layout.rowCount()  # Get current row count\n",
    "            # a_plot.layout.addItem(spacer, row_count, 0, 1, a_plot.layout.columnCount())  # Add spacer to the last row\n",
    "            \n",
    "\n",
    "        if not defer_render:\n",
    "            out_all_pf_2D_pyqtgraph_binned_image_fig.show()\n",
    "\n",
    "    return out_plots_dict\n",
    "\n",
    "\n",
    "out_plots_dict = _display_directional_merged_pfs(curr_active_pipeline, curr_active_pipeline.global_computation_results, computation_results=None, active_configs=None, include_includelist=None, save_figure=True, included_any_context_neuron_ids=None,\n",
    "                                    plot_all_directions=True, plot_long_directional=False, plot_short_directional=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15824da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_all_pf_2D_pyqtgraph_binned_image_fig: BasicBinnedImageRenderingWindow = list(out_plots_dict.values())[0]\n",
    "# Tries to update the display of the item:\n",
    "names_list = [v for v in list(out_all_pf_2D_pyqtgraph_binned_image_fig.plots.keys()) if v not in ('name', 'context')]\n",
    "for a_name in names_list:\n",
    "    # Adjust the size of the text for the item by passing formatted text\n",
    "    a_plot: pg.PlotItem = out_all_pf_2D_pyqtgraph_binned_image_fig.plots[a_name].mainPlotItem # PlotItem \n",
    "    # no clue why 2 is a good value for this...\n",
    "    a_plot.titleLabel.setMaximumHeight(2)\n",
    "    a_plot.layout.setRowFixedHeight(0, 2)\n",
    "    a_plot.getViewBox().setBorder(None)  # Remove the border\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c38fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_plot.layoutDirection()\n",
    "a_plot.layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f36e973",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyphocorehelpers.gui.Qt.color_helpers import ColormapHelpers\n",
    "        \n",
    "ColormapHelpers.mpl_to_pg_colormap(color_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf715bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_pf2D = directional_merged_decoders_result.all_directional_pf1D_Decoder.pf # all-directions\n",
    "active_pf2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054feb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.shape()\n",
    "\n",
    "neuron_values = deepcopy(active_pf2D.peak_tuning_curve_center_of_mass_bin_coordinates)\n",
    "\n",
    "sort_indices = np.lexsort((neuron_values[:, 1], neuron_values[:, 0]))\n",
    "sort_indices\n",
    "\n",
    "neuron_values[sort_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfeb03c",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "# _out = curr_active_pipeline.display('_display_directional_merged_pfs', plot_all_directions=True, plot_long_directional=False, plot_short_directional=False)\n",
    "_out = curr_active_pipeline.display('_display_directional_merged_pf_decoded_epochs') # scrollable_figure=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb499f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_merged_pf_decoded_epochs_marginals') # scrollable_figure=True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abeb2e33",
   "metadata": {},
   "source": [
    "# <a id='toc11_'></a>[2024-11-20 - Find specific posterior from a start_t (e.g. 747.3501248767134)](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b3300f",
   "metadata": {
    "tags": [
     "now",
     "run-heuristic-filter"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import ensure_dataframe\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import PhoPaginatedMultiDecoderDecodedEpochsWindow\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import RadonTransformPlotDataProvider\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import PhoPaginatedMultiDecoderDecodedEpochsWindow, DecodedEpochSlicesPaginatedFigureController, EpochSelectionsObject, ClickActionCallbacks\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import co_filter_epochs_and_spikes\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import get_proper_global_spikes_df\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.TemplateDebugger import TemplateDebugger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34597a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_t: float = 747.3501248767134\n",
    "\n",
    "# included_ripple_start_times = [734.2202499993145, 811.4449451802066, 892.33579400, 972.578]\n",
    "\n",
    "# included_ripple_start_times = [1013.39]\n",
    "# included_ripple_start_times = [\n",
    "# # \t683.0109885382699,\n",
    "# #  685.3902820401127,\n",
    "# #  694.509939450887,\n",
    "# #  697.9841853519902,\n",
    "# #  701.9943720988231,\n",
    "# #  705.2988593669143,\n",
    "# #  706.6135825337842,\n",
    "# #  710.4212631442351,\n",
    "# #  712.0747355778003,\n",
    "# #  713.5096046030521,\n",
    "# #  717.7937214495614,\n",
    "# #  721.2997318145353,\n",
    "# #  734.2202499993145,\n",
    "# #  735.2181886882754,\n",
    "# #  738.1171107239788,\n",
    "# #  761.1802617956419,\n",
    "# #  769.0905348656233,\n",
    "# #  794.9678822564892,\n",
    "# #  812.6678770340513,\n",
    "# #  827.2364609349752,\n",
    "# #  835.6428003108595,\n",
    "# #  863.0844400207279,\n",
    "# #  869.0441169693368,\n",
    "# #  892.7914328108309,\n",
    "# #  906.0226529163774,\n",
    "# #  907.6281407343922,\n",
    "# #  909.8543565545696,\n",
    "# #  926.7004279292888,\n",
    "# #  946.198432666366,\n",
    "# #  958.0087306194472,\n",
    "# #  1011.5683166369564,\n",
    "# #  1013.3905032241018,\n",
    "# #  1028.1721302157966,\n",
    "# #  1030.4905367088504,\n",
    "# #  1064.2788637292106,\n",
    "# #  1064.9692339358153,\n",
    "# #  1072.363319110009,\n",
    "# #  1078.64460357395,\n",
    "# #  1079.5288168812403,\n",
    "# #  1107.1022146036848,\n",
    " \n",
    "# 1568.0800317029934,\n",
    "# ]\n",
    "\n",
    "## INPUTS: included_ripple_start_times\n",
    "\n",
    "\n",
    "\n",
    "## INPUTS: included_ripple_start_times\n",
    "# included_heuristic_ripple_start_times, high_heuristic_only_filtered_decoder_filter_epochs_decoder_result_dict, excluded_heuristic_ripple_start_times, low_heuristic_only_filtered_decoder_filter_epochs_decoder_result_dict\n",
    "included_ripple_start_times = included_heuristic_ripple_start_times\n",
    "# included_ripple_start_times = None\n",
    "\n",
    "# 1D_search (only for start times):\n",
    "matching_specific_start_ts_only_filtered_decoder_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(included_ripple_start_times) for a_name, a_result in filtered_decoder_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "\n",
    "# matching_specific_start_ts_only_filtered_decoder_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:deepcopy(a_result) for a_name, a_result in filtered_decoder_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "\n",
    "# matching_specific_start_ts_only_filtered_decoder_filter_epochs_decoder_result_dict\n",
    "matching_specific_start_ts_only_filter_epochs_df = deepcopy(matching_specific_start_ts_only_filtered_decoder_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)\n",
    "matching_specific_start_ts_only_filter_epochs_df\n",
    "\n",
    "# 2024-03-04 - Filter out the epochs based on the criteria:\n",
    "\n",
    "active_spikes_df = get_proper_global_spikes_df(curr_active_pipeline, minimum_inclusion_fr_Hz=5)\n",
    "active_min_num_unique_aclu_inclusions_requirement: int = track_templates.min_num_unique_aclu_inclusions_requirement(curr_active_pipeline, required_min_percentage_of_active_cells=0.333333333)\n",
    "matching_specific_start_ts_only_filter_epochs_df, active_spikes_df = co_filter_epochs_and_spikes(active_spikes_df=active_spikes_df, active_epochs_df=matching_specific_start_ts_only_filter_epochs_df, included_aclus=track_templates.any_decoder_neuron_IDs, min_num_unique_aclu_inclusions=active_min_num_unique_aclu_inclusions_requirement, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1, add_unique_aclus_list_column=True, drop_non_epoch_spikes=True)\n",
    "filtered_epochs_ripple_simple_pf_pearson_merged_df, active_spikes_df = co_filter_epochs_and_spikes(active_spikes_df=active_spikes_df, active_epochs_df=ripple_simple_pf_pearson_merged_df, included_aclus=track_templates.any_decoder_neuron_IDs, min_num_unique_aclu_inclusions=active_min_num_unique_aclu_inclusions_requirement, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1, add_unique_aclus_list_column=True, drop_non_epoch_spikes=True)\n",
    "filtered_epochs_ripple_simple_pf_pearson_merged_df\n",
    "\n",
    "## INPUTS: directional_decoders_epochs_decode_result, filtered_epochs_df\n",
    "decoder_ripple_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "unfiltered_epochs_df = deepcopy(decoder_ripple_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)\n",
    "filtered_decoder_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(filtered_epochs_df[['start', 'stop']].to_numpy()) for a_name, a_result in decoder_ripple_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "\n",
    "ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "print(f'{pos_bin_size = }, {ripple_decoding_time_bin_size = }')\n",
    "\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# BEGIN FCN BODY                                                                                                       #\n",
    "# ==================================================================================================================== #\n",
    "## INPUTS filtered_decoder_filter_epochs_decoder_result_dict\n",
    "# decoder_decoded_epochs_result_dict: generic\n",
    "\n",
    "active_decoder_decoded_epochs_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(matching_specific_start_ts_only_filtered_decoder_filter_epochs_decoder_result_dict)\n",
    "active_filter_epochs_df: pd.DataFrame = deepcopy(matching_specific_start_ts_only_filter_epochs_df)\n",
    "epochs_name='ripple'\n",
    "title='Specificed Start_t PBEs Only'\n",
    "known_epochs_type = 'ripple'\n",
    "\n",
    "active_spikes_df = get_proper_global_spikes_df(curr_active_pipeline)\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations'] ## GENERAL\n",
    "(app, paginated_multi_decoder_decoded_epochs_window, pagination_controller_dict), ripple_rasters_plot_tuple, yellow_blue_trackID_marginals_plot_tuple = PhoPaginatedMultiDecoderDecodedEpochsWindow.plot_full_paginated_decoded_epochs_window(curr_active_pipeline=curr_active_pipeline, track_templates=track_templates, active_spikes_df=active_spikes_df,\n",
    "                                                                                                                                                                                                   active_decoder_decoded_epochs_result_dict=deepcopy(active_decoder_decoded_epochs_result_dict),\n",
    "                                                                                                                                                                                                   directional_decoders_epochs_decode_result=deepcopy(directional_decoders_epochs_decode_result),\n",
    "                                                                                                                                                                                                   active_filter_epochs_df=active_filter_epochs_df, known_epochs_type=known_epochs_type, title=title,\n",
    "                                                                                                                                                                                                   )\n",
    "attached_yellow_blue_marginals_viewer_widget: DecodedEpochSlicesPaginatedFigureController = paginated_multi_decoder_decoded_epochs_window.attached_yellow_blue_marginals_viewer_widget\n",
    "attached_ripple_rasters_widget: RankOrderRastersDebugger = paginated_multi_decoder_decoded_epochs_window.attached_ripple_rasters_widget\n",
    "attached_directional_template_pfs_debugger: TemplateDebugger = paginated_multi_decoder_decoded_epochs_window.attached_directional_template_pfs_debugger\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2943fee",
   "metadata": {},
   "source": [
    "## <a id='toc11_1_'></a>[2024-11-25 - New Heuristics](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8442394e",
   "metadata": {
    "tags": [
     "run-heuristic-filter"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring, HeuristicsResult\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import SerializationHelper_AllCustomDecodingResults, SerializationHelper_CustomDecodingResults\n",
    "from numpy import ma\n",
    "from neuropy.core.epoch import ensure_dataframe\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "\n",
    "## INPUTS: track_templates, a_decoded_filter_epochs_decoder_result_dict\n",
    "decoder_track_length_dict = track_templates.get_track_length_dict() # {'long_LR': 214.0, 'long_RL': 214.0, 'short_LR': 144.0, 'short_RL': 144.0}\n",
    "same_thresh_fraction_of_track: float = 0.05 ## up to 5.0% of the track\n",
    "same_thresh_cm: float = {k:(v * same_thresh_fraction_of_track) for k, v in decoder_track_length_dict.items()}\n",
    "a_same_thresh_cm: float = same_thresh_cm['long_LR']\n",
    "max_jump_distance_cm: float = 60.0\n",
    "print(f'a_same_thresh_cm: {a_same_thresh_cm}')\n",
    "print(f'max_jump_distance_cm: {max_jump_distance_cm}')\n",
    "# print(list(HeuristicReplayScoring.build_all_score_computations_fn_dict().keys())) # ['jump', 'max_jump_cm', 'max_jump_cm_per_sec', 'ratio_jump_valid_bins', 'travel', 'coverage', 'sequential_correlation', 'monotonicity_score', 'laplacian_smoothness']\n",
    "\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps'] # DirectionalLapsResult\n",
    "# a_name: str = 'long_LR'\n",
    "# a_directional_decoders_epochs_decode_result: DecodedFilterEpochsResult = a_decoded_filter_epochs_decoder_result_dict[a_name]\n",
    "\n",
    "## INPUTS: curr_active_pipeline, track_templates, a_decoded_filter_epochs_decoder_result_dict\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = deepcopy(curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']) ## GENERAL\n",
    "a_decoded_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "a_decoded_filter_epochs_decoder_result_dict, _out_new_scores, partition_result_dict = HeuristicReplayScoring.compute_all_heuristic_scores(track_templates=track_templates, a_decoded_filter_epochs_decoder_result_dict=a_decoded_filter_epochs_decoder_result_dict,\n",
    "                                                                                                                    max_ignore_bins=2, same_thresh_cm=a_same_thresh_cm, max_jump_distance_cm=max_jump_distance_cm)\n",
    "# # a_decoded_filter_epochs_decoder_result_dict\n",
    "a_heuristics_result = HeuristicsResult(heuristic_scores_df_dict=_out_new_scores, partition_result_dict=partition_result_dict)\n",
    "\n",
    "directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict = deepcopy(a_decoded_filter_epochs_decoder_result_dict)\n",
    "# directional_decoders_epochs_decode_result.build_complete_all_scores_merged_df\n",
    "curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations'] = directional_decoders_epochs_decode_result ## MIGHT NEED SAVING\n",
    "print(f'PIPELINE MIGHT NEED SAVING')\n",
    "## INPUTS: curr_active_pipeline, track_templates, a_decoded_filter_epochs_decoder_result_dict\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = deepcopy(curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']) ## GENERAL\n",
    "## INPUTS: directional_decoders_epochs_decode_result, filtered_epochs_df\n",
    "\n",
    "decoder_ripple_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "unfiltered_epochs_df = deepcopy(decoder_ripple_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)\n",
    "if filtered_epochs_df is not None:\n",
    "    ## filter\n",
    "    filtered_decoder_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(filtered_epochs_df[['start', 'stop']].to_numpy()) for a_name, a_result in decoder_ripple_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "else:\n",
    "    filtered_decoder_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(unfiltered_epochs_df[['start', 'stop']].to_numpy()) for a_name, a_result in decoder_ripple_filter_epochs_decoder_result_dict.items()} # working unfiltered\n",
    "\n",
    "ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "print(f'{pos_bin_size = }, {ripple_decoding_time_bin_size = }')\n",
    "\n",
    "## OUTPUT: filtered_decoder_filter_epochs_decoder_result_dict, \n",
    "\n",
    "## 3m 2.2s\n",
    "# 59.1s\n",
    "\n",
    "# same_thresh_cm\n",
    "# a_result: DecodedFilterEpochsResult, an_epoch_idx: int, a_decoder_track_length: float, pos_bin_edges: NDArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82ed804",
   "metadata": {
    "tags": [
     "run-heuristic-filter"
    ]
   },
   "outputs": [],
   "source": [
    "save_path = curr_active_pipeline.get_output_path().joinpath(f\"{DAY_DATE_TO_USE}_CustomDecodingResults.pkl\").resolve()\n",
    "save_path = SerializationHelper_CustomDecodingResults.save(a_directional_decoders_epochs_decode_result=directional_decoders_epochs_decode_result, long_pf2D=long_pf2D, save_path=save_path)\n",
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea96a61",
   "metadata": {
    "tags": [
     "run-heuristic-filter"
    ]
   },
   "outputs": [],
   "source": [
    "save_path = curr_active_pipeline.get_output_path().joinpath(f\"{DAY_DATE_TO_USE}_AllCustomDecodingResults.pkl\").resolve()\n",
    "save_path = SerializationHelper_AllCustomDecodingResults.save(track_templates=track_templates, a_directional_decoders_epochs_decode_result=directional_decoders_epochs_decode_result, \n",
    "                                        #    a_decoded_filter_epochs_decoder_result_dict=deepcopy(a_decoded_filter_epochs_decoder_result_dict),\n",
    "                                           pos_bin_size=directional_decoders_epochs_decode_result.pos_bin_size, ripple_decoding_time_bin_size=directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size, save_path=save_path)\n",
    "save_path\n",
    "\n",
    "\n",
    "# load_path = Path(\"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-11-25_AllCustomDecodingResults.pkl\")\n",
    "# track_templates, directional_decoders_epochs_decode_result, xbin, xbin_centers =  SerializationHelper_AllCustomDecodingResults.save(load_path=load_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfe2849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring\n",
    "\n",
    "list(HeuristicReplayScoring.build_all_score_computations_fn_dict().keys()) # ['jump', 'avg_jump_cm', 'max_jump_cm', 'max_jump_cm_per_sec', 'ratio_jump_valid_bins', 'travel', 'coverage', 'continuous_seq_sort', 'sequential_correlation', 'monotonicity_score', 'laplacian_smoothness']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2199669f",
   "metadata": {},
   "source": [
    "## <a id='toc11_2_'></a>[Find indicies that are included in `high_heuristic_only_filtered_decoder_filter_epochs_decoder_result_dict` from `filtered_decoder_filter_epochs_decoder_result_dict`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2667a680",
   "metadata": {
    "tags": [
     "run-heuristic-filter"
    ]
   },
   "outputs": [],
   "source": [
    "## INPUTS: high_heuristic_only_filtered_decoder_filter_epochs_decoder_result_dict, filtered_decoder_filter_epochs_decoder_result_dict\n",
    "# INPUTS: included_heuristic_ripple_start_times, high_heuristic_only_filtered_decoder_filter_epochs_decoder_result_dict, excluded_heuristic_ripple_start_times, low_heuristic_only_filtered_decoder_filter_epochs_decoder_result_dict\n",
    "\n",
    "example_decoder_name = 'long_LR'\n",
    "all_epoch_result: DecodedFilterEpochsResult = deepcopy(filtered_decoder_filter_epochs_decoder_result_dict[example_decoder_name])\n",
    "all_filter_epochs_df: pd.DataFrame = deepcopy(all_epoch_result.filter_epochs)\n",
    "\n",
    "included_filter_epoch_result: DecodedFilterEpochsResult = deepcopy(high_heuristic_only_filtered_decoder_filter_epochs_decoder_result_dict[example_decoder_name])\n",
    "# included_filter_epoch_result: DecodedFilterEpochsResult = deepcopy(low_heuristic_only_filtered_decoder_filter_epochs_decoder_result_dict[example_decoder_name])\n",
    "\n",
    "included_filter_epochs_df: pd.DataFrame = deepcopy(included_filter_epoch_result.filter_epochs)\n",
    "included_filter_epochs_df\n",
    "\n",
    "# included_filter_epoch_times = included_filter_epochs_df[['start', 'stop']].to_numpy() # Both 'start', 'stop' column matching\n",
    "included_filter_epoch_times = included_filter_epochs_df['start'].to_numpy() # Both 'start', 'stop' column matching\n",
    "\n",
    "included_filter_epoch_times_to_all_epoch_index_map = included_filter_epoch_result.find_epoch_times_to_data_indicies_map(epoch_times=included_filter_epoch_times)\n",
    "included_filter_epoch_times_to_all_epoch_index_arr: NDArray = included_filter_epoch_result.find_data_indicies_from_epoch_times(epoch_times=included_filter_epoch_times)\n",
    "len(included_filter_epoch_times_to_all_epoch_index_arr)\n",
    "\n",
    "## OUTPUTS: all_filter_epochs_df, all_filter_epochs_df\n",
    "## OUTPUTS: included_filter_epoch_times_to_all_epoch_index_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadc5e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "included_filter_epochs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4676371f",
   "metadata": {},
   "source": [
    "## <a id='toc11_3_'></a>[Add the high-heuristic PBEs as an interval-rect dataseries to the continuous viewer](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3f5b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: included_filter_epochs_df\n",
    "\n",
    "## Extract the specific results:\n",
    "# included_filter_epochs_df\n",
    "\n",
    "\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.Specific2DRenderTimeEpochs import General2DRenderTimeEpochs, inline_mkColor\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import Spike2DRaster\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.EpochRenderingMixin import EpochRenderingMixin, RenderedEpochsItemsContainer\n",
    "from pyphoplacecellanalysis.General.Model.Datasources.IntervalDatasource import IntervalsDatasource\n",
    "from neuropy.utils.mixins.time_slicing import TimeColumnAliasesProtocol\n",
    "\n",
    "\n",
    "## Use the three dataframes as separate Epoch series:\n",
    "updated_epochs_dfs_dict = {\n",
    "    'HighHeuristic': included_filter_epochs_df,\n",
    "}\n",
    "\n",
    "updated_epochs_formatting_dict = {\n",
    "    'HighHeuristic':dict(y_location=-10.0, height=7.5, pen_color=inline_mkColor('green', 0.8), brush_color=inline_mkColor('green', 0.5)),\n",
    "}\n",
    "\n",
    "required_vertical_offsets, required_interval_heights = EpochRenderingMixin.build_stacked_epoch_layout([1.0], epoch_render_stack_height=40.0, interval_stack_location='below') # ratio of heights to each interval\n",
    "stacked_epoch_layout_dict = {interval_key:dict(y_location=y_location, height=height) for interval_key, y_location, height in zip(list(updated_epochs_formatting_dict.keys()), required_vertical_offsets, required_interval_heights)} # Build a stacked_epoch_layout_dict to update the display\n",
    "# stacked_epoch_layout_dict # {'LapsAll': {'y_location': -3.6363636363636367, 'height': 3.6363636363636367}, 'LapsTrain': {'y_location': -21.818181818181817, 'height': 18.18181818181818}, 'LapsTest': {'y_location': -40.0, 'height': 18.18181818181818}}\n",
    "\n",
    "# replaces 'y_location', 'position' for each dict:\n",
    "updated_epochs_formatting_dict = {k:(v|stacked_epoch_layout_dict[k]) for k, v in updated_epochs_formatting_dict.items()}\n",
    "updated_epochs_formatting_dict\n",
    "\n",
    "# OUTPUTS: updated_epochs_dfs_dict, updated_epochs_formatting_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf05a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: updated_epochs_dfs_dict\n",
    "updated_epochs_dfs_dict = {k:TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(df=v, required_columns_synonym_dict=IntervalsDatasource._time_column_name_synonyms) for k, v in updated_epochs_dfs_dict.items()}\n",
    "\n",
    "## Build interval datasources for them:\n",
    "updated_epochs_dfs_datasources_dict = {k:General2DRenderTimeEpochs.build_render_time_epochs_datasource(v) for k, v in updated_epochs_dfs_dict.items()}\n",
    "## INPUTS: active_2d_plot, train_test_split_laps_epochs_formatting_dict, train_test_split_laps_dfs_datasources_dict\n",
    "assert len(updated_epochs_formatting_dict) == len(updated_epochs_dfs_datasources_dict)\n",
    "for k, an_interval_ds in updated_epochs_dfs_datasources_dict.items():\n",
    "    an_interval_ds.update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, **(updated_epochs_formatting_dict[k] | kwargs)))\n",
    "\n",
    "## Full output: updated_epochs_dfs_datasources_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaa95a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actually add the epochs:\n",
    "for k, an_interval_ds in updated_epochs_dfs_datasources_dict.items():\n",
    "    active_2d_plot.add_rendered_intervals(an_interval_ds, name=f'{k}', debug_print=False) # adds the interval\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ce8cc7",
   "metadata": {},
   "source": [
    "# <a id='toc12_'></a>[üñºÔ∏èüé®`PhoPaginatedMultiDecoderDecodedEpochsWindow.plot_full_paginated_decoded_epochs_window(..)` combined windows](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3949e48a",
   "metadata": {
    "tags": [
     "run-heuristic-filter"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import ensure_dataframe\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import PhoPaginatedMultiDecoderDecodedEpochsWindow, DecodedEpochSlicesPaginatedFigureController, EpochSelectionsObject, ClickActionCallbacks\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import co_filter_epochs_and_spikes, get_proper_global_spikes_df\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.TemplateDebugger import TemplateDebugger\n",
    "\n",
    "from neuropy.utils.matplotlib_helpers import get_heatmap_cmap\n",
    "from pyphocorehelpers.gui.Qt.color_helpers import ColormapHelpers, ColorFormatConverter\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import FixedCustomColormaps\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.ThinButtonBar.ThinButtonBarWidget import ThinButtonBarWidget\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.PaginationCtrl.PaginationControlWidget import PaginationControlWidget, PaginationControlWidgetState\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from pyphoplacecellanalysis.Resources import GuiResources, ActionIcons, silx_resources_rc\n",
    "from neuropy.utils.indexing_helpers import flatten, NumpyHelpers, PandasHelpers\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicThresholdFiltering\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _plot_heuristic_evaluation_epochs\n",
    "\n",
    "\n",
    "## INPUTS: directional_decoders_epochs_decode_result, filtered_epochs_df\n",
    "decoder_ripple_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "unfiltered_epochs_df = deepcopy(decoder_ripple_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)\n",
    "filtered_decoder_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(filtered_epochs_df[['start', 'stop']].to_numpy()) for a_name, a_result in decoder_ripple_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "\n",
    "ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "print(f'{pos_bin_size = }, {ripple_decoding_time_bin_size = }')\n",
    "\n",
    "## OUTPUTS: unfiltered_epochs_df, decoder_ripple_filter_epochs_decoder_result_dict\n",
    "## OUTPUTS: filtered_epochs_df, filtered_decoder_filter_epochs_decoder_result_dict\n",
    "\n",
    "# posterior_heatmap_imshow_kwargs = {'cmap': orange_posterior_cmap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed19b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directional_decoders_evaluate_epochs\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_evaluate_epochs'], computation_kwargs_list=[{'should_skip_radon_transform': False}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c5cf80",
   "metadata": {
    "tags": [
     "active-2025-01-02"
    ]
   },
   "outputs": [],
   "source": [
    "active_filter_epochs_df['P_decoder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd80edeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf064f5a",
   "metadata": {},
   "source": [
    "### <a id='toc12_1_1_'></a>[test for missed Radon Transform thingies: active_filter_epochs_df['score']](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbf7860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_filter_epochs_df: pd.DataFrame = deepcopy(active_decoder_decoded_epochs_result_dict['long_LR'].filter_epochs) # deepcopy(matching_specific_start_ts_only_filter_epochs_df)\n",
    "active_filter_epochs_df: pd.DataFrame = deepcopy(active_decoder_decoded_epochs_result_dict['long_RL'].filter_epochs) # deepcopy(matching_specific_start_ts_only_filter_epochs_df)\n",
    "## Plot Radon Score Distribution\n",
    "plt.figure()\n",
    "active_filter_epochs_df['score'].hist()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82537f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## find results above 0.3\n",
    "radon_score_cutoff: float = 0.3\n",
    "active_filter_epochs_df['is_radon_included'] = (active_filter_epochs_df['score'] >= 0.3)\n",
    "active_filter_epochs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fa24ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "active_filter_epochs_df['is_radon_false_negative'] = np.logical_and(active_filter_epochs_df['is_user_annotated_epoch'], np.logical_not(active_filter_epochs_df['is_radon_included']))\n",
    "active_filter_epochs_df['is_radon_false_positive'] = np.logical_and(active_filter_epochs_df['is_radon_included'], np.logical_not(active_filter_epochs_df['is_user_annotated_epoch']))\n",
    "\n",
    "with pd.option_context('display.max_rows', 46):\n",
    "    # active_filter_epochs_df[active_filter_epochs_df['is_radon_false_negative']]\n",
    "    active_filter_epochs_df[active_filter_epochs_df['is_radon_false_positive']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56715afc",
   "metadata": {},
   "source": [
    "### <a id='toc12_1_2_'></a>[test for missed WCorr epochs: active_filter_epochs_df['pearsonr'], 'wcorr'](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5d08c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_filter_epochs_df: pd.DataFrame = deepcopy(active_decoder_decoded_epochs_result_dict['long_LR'].filter_epochs) # deepcopy(matching_specific_start_ts_only_filter_epochs_df)\n",
    "# active_filter_epochs_df: pd.DataFrame = deepcopy(active_decoder_decoded_epochs_result_dict['long_RL'].filter_epochs) # deepcopy(matching_specific_start_ts_only_filter_epochs_df)\n",
    "## Plot Radon Score Distribution\n",
    "plt.figure()\n",
    "active_filter_epochs_df['wcorr'].hist()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5985e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "## find results above 0.3\n",
    "wcorr_score_cutoff: float = 0.4\n",
    "active_filter_epochs_df['is_wcorr_included'] = (np.abs(active_filter_epochs_df['wcorr']) >= wcorr_score_cutoff)\n",
    "active_filter_epochs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81744011",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "active_filter_epochs_df['is_wcorr_false_negative'] = np.logical_and(active_filter_epochs_df['is_user_annotated_epoch'], np.logical_not(active_filter_epochs_df['is_wcorr_included']))\n",
    "active_filter_epochs_df['is_wcorr_false_positive'] = np.logical_and(active_filter_epochs_df['is_wcorr_included'], np.logical_not(active_filter_epochs_df['is_user_annotated_epoch']))\n",
    "\n",
    "with pd.option_context('display.max_rows', 46):\n",
    "    # active_filter_epochs_df[active_filter_epochs_df['is_wcorr_false_negative']]\n",
    "    active_filter_epochs_df[active_filter_epochs_df['is_wcorr_false_positive']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a66ac9e",
   "metadata": {
    "tags": [
     "active-2025-01-22"
    ]
   },
   "outputs": [],
   "source": [
    "active_filter_epochs_df['is_user_annotated_epoch']\n",
    "\n",
    "## \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28c3294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c13fa8",
   "metadata": {
    "tags": [
     "PhoPaginatedMultiDecoderDecodedEpochsWindow",
     "plot_full_paginated_decoded_epochs_window"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "## INPUTS: included_ripple_start_times\n",
    "# 1D_search (only for start times):\n",
    "# matching_specific_start_ts_only_filtered_decoder_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(included_ripple_start_times) for a_name, a_result in filtered_decoder_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "# matching_specific_start_ts_only_filtered_decoder_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:deepcopy(a_result) for a_name, a_result in filtered_decoder_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "# # matching_specific_start_ts_only_filtered_decoder_filter_epochs_decoder_result_dict\n",
    "# matching_specific_start_ts_only_filter_epochs_df = deepcopy(matching_specific_start_ts_only_filtered_decoder_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)\n",
    "# matching_specific_start_ts_only_filter_epochs_df\n",
    "\n",
    "# # 2024-03-04 - Filter out the epochs based on the criteria:\n",
    "\n",
    "active_spikes_df = get_proper_global_spikes_df(curr_active_pipeline, minimum_inclusion_fr_Hz=5)\n",
    "active_min_num_unique_aclu_inclusions_requirement: int = track_templates.min_num_unique_aclu_inclusions_requirement(curr_active_pipeline, required_min_percentage_of_active_cells=0.333333333)\n",
    "# matching_specific_start_ts_only_filter_epochs_df, active_spikes_df = co_filter_epochs_and_spikes(active_spikes_df=active_spikes_df, active_epochs_df=matching_specific_start_ts_only_filter_epochs_df, included_aclus=track_templates.any_decoder_neuron_IDs, min_num_unique_aclu_inclusions=active_min_num_unique_aclu_inclusions_requirement, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1, add_unique_aclus_list_column=True, drop_non_epoch_spikes=True)\n",
    "# filtered_epochs_ripple_simple_pf_pearson_merged_df, active_spikes_df = co_filter_epochs_and_spikes(active_spikes_df=active_spikes_df, active_epochs_df=ripple_simple_pf_pearson_merged_df, included_aclus=track_templates.any_decoder_neuron_IDs, min_num_unique_aclu_inclusions=active_min_num_unique_aclu_inclusions_requirement, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1, add_unique_aclus_list_column=True, drop_non_epoch_spikes=True)\n",
    "# matching_specific_start_ts_only_filter_epochs_df, active_spikes_df = co_filter_epochs_and_spikes(active_spikes_df=active_spikes_df, active_epochs_df=matching_specific_start_ts_only_filter_epochs_df, included_aclus=track_templates.any_decoder_neuron_IDs, min_num_unique_aclu_inclusions=active_min_num_unique_aclu_inclusions_requirement, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1, add_unique_aclus_list_column=True, drop_non_epoch_spikes=True)\n",
    "\n",
    "# filtered_epochs_ripple_simple_pf_pearson_merged_df\n",
    "\n",
    "# ## INPUTS: directional_decoders_epochs_decode_result, filtered_epochs_df\n",
    "# decoder_ripple_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "# unfiltered_epochs_df = deepcopy(decoder_ripple_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)\n",
    "# filtered_decoder_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(filtered_epochs_df[['start', 'stop']].to_numpy()) for a_name, a_result in decoder_ripple_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "\n",
    "## INPUTS: filtered_decoder_filter_epochs_decoder_result_dict\n",
    "ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "print(f'{pos_bin_size = }, {ripple_decoding_time_bin_size = }')\n",
    "\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# BEGIN FCN BODY                                                                                                       #\n",
    "# ==================================================================================================================== #\n",
    "## INPUTS filtered_decoder_filter_epochs_decoder_result_dict\n",
    "# decoder_decoded_epochs_result_dict: generic\n",
    "active_cmap = FixedCustomColormaps.get_custom_greyscale_with_low_values_dropped_cmap(low_value_cutoff=0.01, full_opacity_threshold=0.25)\n",
    "\n",
    "# Replay/PBEs ________________________________________________________________________________________________________ #\n",
    "active_decoder_decoded_epochs_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(filtered_decoder_filter_epochs_decoder_result_dict)\n",
    "active_filter_epochs_df: pd.DataFrame = deepcopy(active_decoder_decoded_epochs_result_dict['long_LR'].filter_epochs) # deepcopy(matching_specific_start_ts_only_filter_epochs_df)\n",
    "epochs_name='ripple'\n",
    "title='Filtered PBEs'\n",
    "known_epochs_type = 'ripple'\n",
    "\n",
    "# # Laps _______________________________________________________________________________________________________________ #\n",
    "# active_decoder_decoded_epochs_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(decoder_laps_filter_epochs_decoder_result_dict)\n",
    "# active_filter_epochs_df: pd.DataFrame = deepcopy(active_decoder_decoded_epochs_result_dict['long_LR'].filter_epochs) # deepcopy(matching_specific_start_ts_only_filter_epochs_df)\n",
    "# epochs_name='laps'\n",
    "# title='Laps'\n",
    "# known_epochs_type = 'laps'\n",
    "\n",
    "\n",
    "## INPUTS: active_decoder_decoded_epochs_result_dict, active_filter_epochs_df, directional_decoders_epochs_decode_result, curr_active_pipeline, track_templates, active_spikes_df\n",
    "\n",
    "active_spikes_df = get_proper_global_spikes_df(curr_active_pipeline)\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations'] ## GENERAL\n",
    "(app, paginated_multi_decoder_decoded_epochs_window, pagination_controller_dict), ripple_rasters_plot_tuple, yellow_blue_trackID_marginals_plot_tuple = PhoPaginatedMultiDecoderDecodedEpochsWindow.plot_full_paginated_decoded_epochs_window(curr_active_pipeline=curr_active_pipeline, track_templates=track_templates, active_spikes_df=active_spikes_df,\n",
    "                                                                                                                                                                                                   active_decoder_decoded_epochs_result_dict=deepcopy(active_decoder_decoded_epochs_result_dict), # epochs_name='ripple',\n",
    "                                                                                                                                                                                                   directional_decoders_epochs_decode_result=deepcopy(directional_decoders_epochs_decode_result),\n",
    "                                                                                                                                                                                                   active_filter_epochs_df=active_filter_epochs_df, known_epochs_type=known_epochs_type, title=title,\n",
    "                                                                                                params_kwargs={'enable_per_epoch_action_buttons': False,\n",
    "                                                                                                    'skip_plotting_most_likely_positions': True, 'skip_plotting_measured_positions': True, \n",
    "                                                                                                    'enable_decoded_most_likely_position_curve': False, \n",
    "                                                                                                    'enable_decoded_sequence_and_heuristics_curve': True, 'show_pre_merged_debug_sequences': False, 'show_heuristic_criteria_filter_epoch_inclusion_status': True,\n",
    "                                                                                                     'enable_radon_transform_info': False, 'enable_weighted_correlation_info': True, 'enable_weighted_corr_data_provider_modify_axes_rect': False,\n",
    "                                                                                                    # 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': False,\n",
    "                                                                                                    # 'disable_y_label': True,\n",
    "                                                                                                    'isPaginatorControlWidgetBackedMode': True,\n",
    "                                                                                                    'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True,\n",
    "                                                                                                    # 'debug_print': True,\n",
    "                                                                                                    'max_subplots_per_page': 9,\n",
    "                                                                                                    # 'scrollable_figure': False,\n",
    "                                                                                                    'scrollable_figure': True,\n",
    "                                                                                                    # 'posterior_heatmap_imshow_kwargs': dict(vmin=0.0075),\n",
    "                                                                                                    'use_AnchoredCustomText': False,\n",
    "                                                                                                    'should_suppress_callback_exceptions': False,\n",
    "                                                                                                    # 'build_fn': 'insets_view',\n",
    "                                                                                                    'track_length_cm_dict': deepcopy(track_templates.get_track_length_dict()),\n",
    "                                                                                                    'posterior_heatmap_imshow_kwargs': dict(cmap=active_cmap), # , vmin=0.1, vmax=1.0\n",
    "                                                                                                    \n",
    "                                                                                                })\n",
    "attached_yellow_blue_marginals_viewer_widget: DecodedEpochSlicesPaginatedFigureController = paginated_multi_decoder_decoded_epochs_window.attached_yellow_blue_marginals_viewer_widget\n",
    "attached_ripple_rasters_widget: RankOrderRastersDebugger = paginated_multi_decoder_decoded_epochs_window.attached_ripple_rasters_widget\n",
    "attached_directional_template_pfs_debugger: TemplateDebugger = paginated_multi_decoder_decoded_epochs_window.attached_directional_template_pfs_debugger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bc8731",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## INPUTS: filtered_decoder_filter_epochs_decoder_result_dict\n",
    "paginated_multi_decoder_decoded_epochs_window.add_data_overlays(included_columns=[\n",
    "                #    'P_decoder', #'ratio_jump_valid_bins', \n",
    "                #    'wcorr',\n",
    "                    #'avg_jump_cm', 'max_jump_cm',\n",
    "                    'mseq_len', 'mseq_len_ignoring_intrusions', 'mseq_tcov', 'mseq_tdist', # , 'mseq_len_ratio_ignoring_intrusions_and_repeats', 'mseq_len_ignoring_intrusions_and_repeats'\n",
    "], defer_refresh=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb8c0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.remove_data_overlays()\n",
    "# paginated_multi_decoder_decoded_epochs_window.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2488925f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.ui.attached_yellow_blue_marginals_viewer_widget.plots['marginal_label_artists_dict']\n",
    "attached_yellow_blue_marginals_viewer_widget.plots['marginal_label_artists_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90988a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.update_params(show_pre_merged_debug_sequences=False)\n",
    "# paginated_multi_decoder_decoded_epochs_window.update_params(show_pre_merged_debug_sequences=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3afb193",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6823ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_merged_pf_decoded_epochs', render_directional_marginal_laps=False, render_track_identity_marginal_laps=True, render_merged_pseudo2D_decoder_laps=True, save_figure=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f4fc45",
   "metadata": {},
   "source": [
    "### <a id='toc12_1_3_'></a>[Attached raster viewer widget](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c265cd",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.RankOrderRastersDebugger import RankOrderRastersDebugger\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import build_attached_raster_viewer_widget\n",
    "\n",
    "_out_ripple_rasters, update_attached_raster_viewer_epoch_callback = build_attached_raster_viewer_widget(paginated_multi_decoder_decoded_epochs_window=paginated_multi_decoder_decoded_epochs_window, track_templates=track_templates, active_spikes_df=active_spikes_df, filtered_ripple_simple_pf_pearson_merged_df=filtered_ripple_simple_pf_pearson_merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2865a6",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.export_decoder_pagination_controller_figure_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf5b2c2",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# type(_out_ripple_rasters) # RankOrderRastersDebugger\n",
    "# root_plots_dict: Dict[str, pg.PlotItem] = _out_ripple_rasters.root_plots_dict\n",
    "# root_plots_dict\n",
    "\n",
    "rasters_output_path = Path(r\"C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\EXTERNAL\\PhoDibaPaper2024Book\\FIGURES\").resolve()\n",
    "assert rasters_output_path.exists()\n",
    "example_replay_output_folder = rasters_output_path.joinpath('example_replay_2').resolve()\n",
    "example_replay_output_folder.mkdir(parents=False, exist_ok=True)\n",
    "_out_ripple_rasters.save_figure(export_path=example_replay_output_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06f3ff1",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625daf82",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "win = _out_ripple_rasters.ui.root_dockAreaWindow\n",
    "# win.setWindowTitle(f'Debug Directional Template Rasters <Controlled by DecodedEpochSlices window>')\n",
    "win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae668b2",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_out_ripple_rasters.setWindowTitle(f'Debug Directional Template Rasters <Controlled by DecodedEpochSlices window>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2db798a",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# Attempting to set identical low and high xlims makes transformation singular; automatically expanding. Is this what is causing the white posteriors?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f80c795",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ddc065",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# paginated_multi_decoder_decoded_epochs_window.pagination_controllers['long_LR'].params.posterior_heatmap_imshow_kwargs = dict(vmin=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23369f63",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# paginated_multi_decoder_decoded_epochs_window.update_params(posterior_heatmap_imshow_kwargs = dict(vmin=0.0))\n",
    "\n",
    "paginated_multi_decoder_decoded_epochs_window.update_params(enable_per_epoch_action_buttons=True)\n",
    "paginated_multi_decoder_decoded_epochs_window.refresh_current_page()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5370bef3",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.get_children_props('params')\n",
    "# paginated_multi_decoder_decoded_epochs_window.get_children_props('plots')\n",
    "# paginated_multi_decoder_decoded_epochs_window.get_children_props('plots.fig')\n",
    "paginated_multi_decoder_decoded_epochs_window.get_children_props('plots.fig')\n",
    "# paginated_multi_decoder_decoded_epochs_window.get_children_props('params.posterior_heatmap_imshow_kwargs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701ca528",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# paginated_multi_decoder_decoded_epochs_window# AttributeError: 'PhoPaginatedMultiDecoderDecodedEpochsWindow' object has no attribute 'params'\n",
    "\n",
    "paginated_multi_decoder_decoded_epochs_window.pagination_controllers['long_LR'].params.should_suppress_callback_exceptions = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a19394",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.jump_to_page(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea69a1c",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f136d94",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.debug_print = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2150f30",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "for k, v in paginated_multi_decoder_decoded_epochs_window.pagination_controllers.items():\n",
    "    # v.params.enable_radon_transform_info = False\n",
    "    # v.params.enable_weighted_correlation_info = False\n",
    "    v._subfn_clear_selectability_rects()\n",
    "    \n",
    "# paginated_multi_decoder_decoded_epochs_window.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860d5ece",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "for a_name, a_ctrlr in paginated_multi_decoder_decoded_epochs_window.pagination_controllers.items():\n",
    "    a_ctrlr.perform_update_selections(defer_render=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fb8eea",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009775d7",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# with Ctx(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25',display_fn_name='DecodedEpochSlices',epochs='ripple',user_annotation='selections') as ctx:\n",
    "# \tuser_annotations[ctx + Ctx(decoder='long_LR')] = [[785.7379401021171, 785.9232737672282]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='long_RL')] = [[427.4610240198672, 427.55720829055645]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='short_LR')] = [[833.3391086903866, 833.4508065531263]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='short_RL')] = [[491.7975491596153, 492.17844624456484], [940.0164351915009, 940.2191870877286]]\n",
    "\n",
    "# with Ctx(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25',display_fn_name='DecodedEpochSlices',epochs='ripple',user_annotation='selections') as ctx:\n",
    "# \tuser_annotations[ctx + Ctx(decoder='long_LR')] = [array([785.738, 785.923])]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='long_RL')] = [array([427.461, 427.557])]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='short_LR')] = [array([833.339, 833.451])]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='short_RL')] = [array([491.798, 492.178]), array([940.016, 940.219])]\n",
    "\n",
    "# with Ctx(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25',display_fn_name='DecodedEpochSlices',epochs='ripple',user_annotation='selections') as ctx:\n",
    "# \tuser_annotations[ctx + Ctx(decoder='long_LR')] = [[785.7379401021171, 785.9232737672282]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='long_RL')] = [[427.4610240198672, 427.55720829055645]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='short_LR')] = [[833.3391086903866, 833.4508065531263]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='short_RL')] = [[491.7975491596153, 492.17844624456484], [940.0164351915009, 940.2191870877286]]\n",
    "\n",
    "# with Ctx(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0',display_fn_name='DecodedEpochSlices',epochs='ripple',user_annotation='selections') as ctx:\n",
    "# \tuser_annotations[ctx + Ctx(decoder='long_LR')] = [[208.356, 208.523], [693.842, 693.975], [954.574, 954.679]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='long_RL')] = [[224.037, 224.312]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='short_LR')] = [[145.776, 146.022], [198.220, 198.582], [220.041, 220.259], [511.570, 511.874], [865.238, 865.373]]\n",
    "# \tuser_annotations[ctx + Ctx(decoder='short_RL')] = [[191.817, 192.100], [323.147, 323.297]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a776e895",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-paginated_multi_decoder_decoded_epochs_window_page.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "    paginated_multi_decoder_decoded_epochs_window.jump_to_page(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f513296",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.jump_to_page(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970b6ed4",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "decoder_ripple_filter_epochs_decoder_result_dict['long_LR'].filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98478063",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "track_templates.get_decoder_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ec6078",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "for k, v in paginated_multi_decoder_decoded_epochs_window.pagination_controllers.items():\n",
    "    # v.params.enable_radon_transform_info = False\n",
    "    # v.params.enable_weighted_correlation_info = False\n",
    "    v.params.enable_radon_transform_info = True\n",
    "    v.params.enable_weighted_correlation_info = True\n",
    "    v.params.debug_enabled = True\n",
    "\n",
    "paginated_multi_decoder_decoded_epochs_window.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6904027b",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "for k, v in paginated_multi_decoder_decoded_epochs_window.pagination_controllers.items():\n",
    "    print(f'decoder[{k}]:')\n",
    "    v.params.name\n",
    "    # v.params.on_render_page_callbacks\n",
    "    # v.params.enable_radon_transform_info\n",
    "    len(v.plots_data.radon_transform_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1ff3b7",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.debug_print = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7cc2a9",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.debug_print = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3263a3d8",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.add_data_overlays(decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "paginated_multi_decoder_decoded_epochs_window.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b447b8",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.refresh_current_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e215cb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sub_subfn_wrapped_in_brackets(s: str, bracket_strings = (\"[\", \"]\")) -> str:\n",
    "        return bracket_strings[0] + s + bracket_strings[1]\n",
    "    \n",
    "def _sub_subfn_format_nested_list(arr, precision:int=3, num_sep=\", \", array_sep=', ') -> str:\n",
    "    \"\"\"\n",
    "    Converts a nested list of floats into a single string,\n",
    "    with each float formatted to the specified precision.\n",
    "    \n",
    "    arr = np.array([[491.798, 492.178], [940.016, 940.219]])\n",
    "    _sub_subfn_format_nested_list(arr)\n",
    "\n",
    "    >> '[[491.798, 492.178], [940.016, 940.219]]'\n",
    "\n",
    "    arr = np.array([[785.738, 785.923]])\n",
    "    _sub_subfn_format_nested_list(arr)\n",
    "    >> '[[785.738, 785.923]]'\n",
    "    \"\"\"\n",
    "    return _sub_subfn_wrapped_in_brackets(array_sep.join([_sub_subfn_wrapped_in_brackets(num_sep.join([f\"{num:.{precision}f}\" for num in row])) for row in arr]))\n",
    "    \n",
    "# arr = np.array([[491.798, 492.178], [940.016, 940.219]])\n",
    "arr = np.array([[785.738, 785.923]])\n",
    "_sub_subfn_format_nested_list(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135bd3cd",
   "metadata": {},
   "source": [
    "### <a id='toc12_1_4_'></a>[2024-02-29 3pm - Get the active user-annotated epoch times from the `paginated_multi_decoder_decoded_epochs_window` and use these to filter `filtered_ripple_simple_pf_pearson_merged_df`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b653096",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inputs: paginated_multi_decoder_decoded_epochs_window, filtered_ripple_simple_pf_pearson_merged_df\n",
    "any_good_selected_epoch_times = deepcopy(paginated_multi_decoder_decoded_epochs_window.any_good_selected_epoch_times)\n",
    "any_good_selected_epoch_indicies = deepcopy(paginated_multi_decoder_decoded_epochs_window.find_data_indicies_from_epoch_times(paginated_multi_decoder_decoded_epochs_window.any_good_selected_epoch_times))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4051f703",
   "metadata": {},
   "source": [
    "## <a id='toc12_2_'></a>[:‚úÖ:üéØ 2024-09-27 - Test programmatic/background saving of stacked decoded epoch figures](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a819bd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_laps_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict)\n",
    "unfiltered_laps_epochs_df = deepcopy(decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)\n",
    "# filtered_decoder_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(filtered_epochs_df[['start', 'stop']].to_numpy()) for a_name, a_result in decoder_ripple_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "\n",
    "laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "print(f'{pos_bin_size = }, {laps_decoding_time_bin_size = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30801a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using: perform_export_all_decoded_posteriors_as_images\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import HeatmapExportConfig, PosteriorExporting\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import Assert\n",
    "\n",
    "## INPUTS:: filtered_decoder_filter_epochs_decoder_result_dict, long_like_during_post_delta_only_filter_epochs\n",
    "active_epochs_decoder_result_dict = deepcopy(filtered_decoder_filter_epochs_decoder_result_dict)\n",
    "parent_output_folder = Path('output/array_to_images').resolve()\n",
    "\n",
    "# active_epochs_decoder_result_dict = deepcopy(long_like_during_post_delta_only_filtered_decoder_filter_epochs_decoder_result_dict)\n",
    "# parent_output_folder = Path('output/long_like_during_post_delta').resolve()\n",
    "\n",
    "\n",
    "# active_epochs_decoder_result_dict = deepcopy(filtered_decoder_filter_epochs_decoder_result_dict)\n",
    "\n",
    "\n",
    "## Laps:\n",
    "active_epochs_decoder_result_dict = deepcopy(decoder_laps_filter_epochs_decoder_result_dict)\n",
    "\n",
    "\n",
    "\n",
    "parent_output_folder.mkdir(exist_ok=True)\n",
    "Assert.path_exists(parent_output_folder)\n",
    "posterior_out_folder = parent_output_folder.joinpath(DAY_DATE_TO_USE).resolve()\n",
    "posterior_out_folder.mkdir(parents=True, exist_ok=True)\n",
    "save_path = posterior_out_folder.resolve()\n",
    "_parent_save_context: IdentifyingContext = curr_active_pipeline.build_display_context_for_session('perform_export_all_decoded_posteriors_as_images')\n",
    "_specific_session_output_folder = save_path.joinpath(active_context.get_description(subset_excludelist=['format_name'])).resolve()\n",
    "_specific_session_output_folder.mkdir(parents=True, exist_ok=True)\n",
    "print(f'\\tspecific_session_output_folder: \"{_specific_session_output_folder}\"')\n",
    "\n",
    "custom_export_formats: Dict[str, HeatmapExportConfig] = {\n",
    "    'greyscale': HeatmapExportConfig.init_greyscale(desired_height=1200),\n",
    "    'color': HeatmapExportConfig(colormap='Oranges', desired_height=1200),\n",
    "    # 'color': HeatmapExportConfig(colormap=additional_cmaps['long_LR']),\n",
    "    # 'color': HeatmapExportConfig(colormap=cmap1, desired_height=200),\n",
    "}\n",
    "custom_export_formats = None\n",
    "\n",
    "out_paths, out_custom_formats_dict = PosteriorExporting.perform_export_all_decoded_posteriors_as_images(decoder_laps_filter_epochs_decoder_result_dict=None, decoder_ripple_filter_epochs_decoder_result_dict=active_epochs_decoder_result_dict,\n",
    "# out_paths, out_custom_formats_dict = PosteriorExporting.perform_export_all_decoded_posteriors_as_images(decoder_laps_filter_epochs_decoder_result_dict=deepcopy(decoder_laps_filter_epochs_decoder_result_dict), decoder_ripple_filter_epochs_decoder_result_dict=None,\n",
    "                                                                                                            _save_context=_parent_save_context, parent_output_folder=_specific_session_output_folder,\n",
    "                                                                                                            desired_height=1200, custom_export_formats=custom_export_formats, combined_img_padding=6, combined_img_separator_color=(0, 0, 0, 255))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45280fe7",
   "metadata": {},
   "source": [
    "### <a id='toc12_2_1_'></a>[2024-11-26 - try HDF5 posterior export so they can be loaded more easily](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d580ff25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import ensure_dataframe\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring\n",
    "from neuropy.utils.result_context import DisplaySpecifyingIdentifyingContext\n",
    "\n",
    "filtered_epochs_df = None\n",
    "\n",
    "## INPUTS: curr_active_pipeline, track_templates, a_decoded_filter_epochs_decoder_result_dict\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = deepcopy(curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']) ## GENERAL\n",
    "## INPUTS: directional_decoders_epochs_decode_result, filtered_epochs_df\n",
    "\n",
    "decoder_ripple_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "unfiltered_epochs_df = deepcopy(decoder_ripple_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)\n",
    "if filtered_epochs_df is not None:\n",
    "    ## filter\n",
    "    filtered_decoder_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(filtered_epochs_df[['start', 'stop']].to_numpy()) for a_name, a_result in decoder_ripple_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "else:\n",
    "    filtered_decoder_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(unfiltered_epochs_df[['start', 'stop']].to_numpy()) for a_name, a_result in decoder_ripple_filter_epochs_decoder_result_dict.items()} # working unfiltered\n",
    "\n",
    "ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "print(f'{pos_bin_size = }, {ripple_decoding_time_bin_size = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5df7068",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert parent_output_path.exists(), f\"'{parent_output_path}' does not exist!\"\n",
    "output_date_str: str = get_now_rounded_time_str(rounded_minutes=10)\n",
    "# Export CSVs:\n",
    "# def export_df_to_csv(export_df: pd.DataFrame, data_identifier_str: str = f'(laps_marginals_df)', parent_output_path: Path=None):\n",
    "#     \"\"\" captures `active_context`, 'output_date_str'\n",
    "#     \"\"\"\n",
    "#     # parent_output_path: Path = Path('output').resolve()\n",
    "#     # active_context = curr_active_pipeline.get_session_context()\n",
    "#     session_identifier_str: str = active_context.get_description() # 'kdiba_gor01_two_2006-6-12_16-53-46__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_1.0normal_computed-frateThresh_1.0-qclu_[1, 2, 4, 6, 7, 9]'\n",
    "#     # session_identifier_str: str = active_context.get_description(subset_excludelist=['custom_suffix']) # no this is just the session\n",
    "#     assert output_date_str is not None\n",
    "#     out_basename = '-'.join([output_date_str, session_identifier_str, data_identifier_str]) # '2024-11-15_0200PM-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays_qclu_[1, 2, 4, 6, 7, 9]_frateThresh_5.0-(ripple_WCorrShuffle_df)_tbin-0.025'\n",
    "#     out_filename = f\"{out_basename}.csv\"\n",
    "#     out_path = parent_output_path.joinpath(out_filename).resolve()\n",
    "#     export_df.to_csv(out_path)\n",
    "#     return out_path \n",
    "\n",
    "\n",
    "def export_data_to_h5(data_identifier_str: str = f'(laps_marginals_df)', parent_output_path: Path=None):\n",
    "    \"\"\" captures `active_context`, 'output_date_str'\n",
    "    \"\"\"\n",
    "    # parent_output_path: Path = Path('output').resolve()\n",
    "    # active_context = curr_active_pipeline.get_session_context()\n",
    "    session_identifier_str: str = active_context.get_description() # 'kdiba_gor01_two_2006-6-12_16-53-46__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_1.0normal_computed-frateThresh_1.0-qclu_[1, 2, 4, 6, 7, 9]'\n",
    "    # session_identifier_str: str = active_context.get_description(subset_excludelist=['custom_suffix']) # no this is just the session\n",
    "    assert output_date_str is not None\n",
    "    out_basename = '-'.join([output_date_str, session_identifier_str, data_identifier_str]) # '2024-11-15_0200PM-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays_qclu_[1, 2, 4, 6, 7, 9]_frateThresh_5.0-(ripple_WCorrShuffle_df)_tbin-0.025'\n",
    "    out_filename = f\"{out_basename}.h5\"\n",
    "    out_path = parent_output_path.joinpath(out_filename).resolve()\n",
    "    ## can export here\n",
    "    \n",
    "    return out_path \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df93063",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = Path(f'output/{BATCH_DATE_TO_USE}_newest_all_decoded_epoch_posteriors.h5').resolve()\n",
    "\n",
    "complete_session_context, (session_context, additional_session_context) = curr_active_pipeline.get_complete_session_context()\n",
    "_, _, custom_suffix = curr_active_pipeline.get_custom_pipeline_filenames_from_parameters()\n",
    "custom_params_hdf_key: str = custom_suffix.strip('_') # strip leading/trailing underscores\n",
    "# _parent_save_context: IdentifyingContext = curr_active_pipeline.build_display_context_for_session('save_decoded_posteriors_to_HDF5', custom_suffix=custom_suffix)\n",
    "_parent_save_context: DisplaySpecifyingIdentifyingContext = deepcopy(session_context).overwriting_context(custom_suffix=custom_params_hdf_key, display_fn_name='save_decoded_posteriors_to_HDF5')\n",
    "# _parent_save_context: DisplaySpecifyingIdentifyingContext = complete_session_context.overwriting_context(display_fn_name='save_decoded_posteriors_to_HDF5')\n",
    "_parent_save_context.display_dict = {\n",
    "    'custom_suffix': lambda k, v: f\"{v}\", # just include the name\n",
    "    'display_fn_name': lambda k, v: f\"{v}\", # just include the name\n",
    "}\n",
    "\n",
    "\n",
    "out_contexts, _flat_all_out_paths = PosteriorExporting.perform_save_all_decoded_posteriors_to_HDF5(decoder_laps_filter_epochs_decoder_result_dict=None,\n",
    "                                                                             decoder_ripple_filter_epochs_decoder_result_dict=filtered_decoder_filter_epochs_decoder_result_dict,\n",
    "                                                                             _save_context=_parent_save_context.get_raw_identifying_context(), save_path=save_path)\n",
    "out_contexts\n",
    "_flat_all_out_paths\n",
    "\n",
    "# DataTypeWarning: Unsupported type for attribute 'is_user_annotated_epoch' in node '002'. Offending HDF5 class: 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd53b03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "list(dict.fromkeys([v.as_posix() for v in _flat_all_out_paths]).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91396e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'save_path: \"{save_path}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9988fc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = Path('output/2024-11-26_Lab_newest_all_decoded_epoch_posteriors.h5')\n",
    "\n",
    "## used for reconstituting dataset:\n",
    "dataset_type_fields = ['p_x_given_n', 'p_x_given_n_grey', 'most_likely_positions', 'most_likely_position_indicies', 'time_bin_edges', 't_bin_centers']\n",
    "decoder_names = ['long_LR', 'long_RL', 'short_LR', 'short_RL']\n",
    "\n",
    "_out_dict, (session_key_parts, custom_replay_parts) = PosteriorExporting.load_decoded_posteriors_from_HDF5(load_path=load_path, debug_print=True)\n",
    "_out_ripple_only_dict = {k:v['ripple'] for k, v in _out_dict.items()} ## cut down to only the laps\n",
    "\n",
    "## build the final ripple data outputs:\n",
    "ripple_data_field_dict = {}\n",
    "# active_var_key: str = 'p_x_given_n' # dataset_type_fields\t\n",
    "\n",
    "for active_var_key in dataset_type_fields:\n",
    "    ripple_data_field_dict[active_var_key] = {\n",
    "        a_decoder_name: [v for v in _out_ripple_only_dict[a_decoder_name][active_var_key]] for a_decoder_name in decoder_names\n",
    "    }\n",
    "\n",
    "\n",
    "ripple_img_dict = ripple_data_field_dict['p_x_given_n_grey']\n",
    "ripple_img_dict['long_LR'][0]\n",
    "# ripple_0_img = _out_ripple_only_dict['long_LR'][active_var_key][0]\n",
    "# ripple_0_img\n",
    "# lap_0_img = _out_dict['long_LR']['laps']['p_x_given_n_grey'][0]\n",
    "# lap_0_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d14d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_keys_if_possible('loaded_posteriors_dict', _out_dict, max_depth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed0e43d",
   "metadata": {},
   "source": [
    "## <a id='toc12_3_'></a>[üíæ Export Paginated Content](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afec0488",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "laps_paginated_multi_decoder_decoded_epochs_window.export_all_pages(curr_active_pipeline)\n",
    "# paginated_multi_decoder_decoded_epochs_window.export_all_pages(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b8f5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.export_decoder_pagination_controller_figure_page(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f428d3",
   "metadata": {},
   "source": [
    "## <a id='toc12_4_'></a>[2024-04-30 Heuristic](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21abb21",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# *position_relative\": mapped between the ends of the track, 0.0 to 1.0\n",
    "most_likely_position_relative = (np.squeeze(active_captured_single_epoch_result.most_likely_position_indicies) / float(active_captured_single_epoch_result.n_xbins-1))\n",
    "most_likely_position_relative\n",
    "\n",
    "\n",
    "plt.hlines([0], colors='k', xmin=active_captured_single_epoch_result.time_bin_edges[0], xmax=active_captured_single_epoch_result.time_bin_edges[-1])\n",
    "plt.step(active_captured_single_epoch_result.time_bin_container.centers[1:], np.diff(most_likely_position_relative))\n",
    "plt.scatter(active_captured_single_epoch_result.time_bin_container.centers, most_likely_position_relative, color='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29c941e",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring\n",
    "\n",
    "HeuristicReplayScoring.bin_wise_track_coverage_score_fn(a_result=a_decoder_decoded_epochs_result, an_epoch_idx=active_captured_single_epoch_result.epoch_data_index, a_decoder_track_length=170.0)\n",
    "\n",
    "# np.diff(active_captured_single_epoch_result.most_likely_position_indicies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2549b6af",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "ax = _out_pagination_controller.plots.axs[0]\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d52d45",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "ax.format_coord\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f28b01",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# Find ascending sequences of most-likely positions\n",
    "def format_coord(x, y):\n",
    "    col = round(x)\n",
    "    row = round(y)\n",
    "    nrows, ncols = X.shape\n",
    "    if 0 <= col < ncols and 0 <= row < nrows:\n",
    "        z = X[row, col]\n",
    "        return f'x={x:1.4f}, y={y:1.4f}, z={z:1.4f}'\n",
    "    else:\n",
    "        return f'x={x:1.4f}, y={y:1.4f}'\n",
    "\n",
    "\n",
    "ax.format_coord = format_coord\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de603c0",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# _out_pagination_controller.plot_widget.setStatusTip('LONG STATUS TIP TEST')\n",
    "\n",
    "_out_pagination_controller.plot_widget.update_status('LONG STATUS TIP TEST')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b187c8",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# _out_pagination_controller.plots.radon_transform\n",
    "fig = _out_pagination_controller.plots.fig\n",
    "\n",
    "# plt.subplots_adjust(left=0.15, right=0.85, top=0.9, bottom=0.1)\n",
    "# Adjust the margins using subplots_adjust\n",
    "fig.subplots_adjust(left=0.15, right=0.85, bottom=0.15, top=0.85)\n",
    "\n",
    "# Adjust the margins using the Figure object\n",
    "# fig.set_tight_layout(dict(rect=[0.1, 0.2, 0.8, 0.8]))\n",
    "# fig.tight_layout(dict(rect=[0.1, 0.2, 0.8, 0.8]))\n",
    "# fig.tight_layout(pad=1.0, rect=[0.1, 0.1, 0.8, 0.8])\n",
    "_out_pagination_controller.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc2fd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "(a_name, a_decoder) = tuple(track_templates.get_decoders_dict().items())[0]\n",
    "a_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d626a86e",
   "metadata": {},
   "source": [
    "## <a id='toc12_5_'></a>[üî∑üé® 2024-03-06 - Uni Page Scrollable Version](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be9e880",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import PhoPaginatedMultiDecoderDecodedEpochsWindow\n",
    "\n",
    "# decoder_decoded_epochs_result_dict: generic\n",
    "single_page_app, single_page_paginated_multi_decoder_decoded_epochs_window, single_page_pagination_controller_dict = PhoPaginatedMultiDecoderDecodedEpochsWindow.init_from_track_templates(curr_active_pipeline, track_templates,\n",
    "                                                                                                decoder_decoded_epochs_result_dict=decoder_ripple_filter_epochs_decoder_result_dict, epochs_name='ripple',\n",
    "                                                                                                included_epoch_indicies=None, debug_print=False,\n",
    "                                                                                                params_kwargs={'skip_plotting_most_likely_positions': False, 'enable_per_epoch_action_buttons': False,\n",
    "                                                                                                               'enable_radon_transform_info': False, 'enable_weighted_correlation_info': True,\n",
    "                                                                                                                # 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': False,\n",
    "                                                                                                                # 'disable_y_label': True,\n",
    "                                                                                                                'isPaginatorControlWidgetBackedMode': True,\n",
    "                                                                                                                'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True,\n",
    "                                                                                                                # 'debug_print': True,\n",
    "                                                                                                                'max_subplots_per_page': 64,\n",
    "                                                                                                                'scrollable_figure': True,\n",
    "                                                                                                                })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2565e3",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "single_page_paginated_multi_decoder_decoded_epochs_window.add_data_overlays(decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "_tmp_out_selections = single_page_paginated_multi_decoder_decoded_epochs_window.restore_selections_from_user_annotations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90abee48",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# for curr_results_obj: LeaveOneOutDecodingAnalysisResult object\n",
    "num_filter_epochs:int = curr_results_obj.active_filter_epochs.n_epochs\n",
    "\n",
    "# `active_filter_epochs_df` native columns approach\n",
    "active_filter_epochs_df = curr_results_obj.active_filter_epochs.to_dataframe().copy()\n",
    "assert np.isin(['score', 'velocity', 'intercept', 'speed'], active_filter_epochs_df.columns).all()\n",
    "epochs_linear_fit_df = active_filter_epochs_df[['score', 'velocity', 'intercept', 'speed']].copy() # get the `epochs_linear_fit_df` as a subset of the filter epochs df\n",
    "# epochs_linear_fit_df approach\n",
    "assert curr_results_obj.all_included_filter_epochs_decoder_result.num_filter_epochs == np.shape(epochs_linear_fit_df)[0]\n",
    "\n",
    "num_filter_epochs:int = curr_results_obj.all_included_filter_epochs_decoder_result.num_filter_epochs # curr_results_obj.num_filter_epochs\n",
    "try:\n",
    "    time_bin_containers: List[BinningContainer] = deepcopy(curr_results_obj.time_bin_containers)\n",
    "except AttributeError as e:\n",
    "    # AttributeError: 'LeaveOneOutDecodingAnalysisResult' object has no attribute 'time_bin_containers' is expected when `curr_results_obj: LeaveOneOutDecodingAnalysisResult - for Long/Short plotting`\n",
    "    time_bin_containers: List[BinningContainer] = deepcopy(curr_results_obj.all_included_filter_epochs_decoder_result.time_bin_containers) # for curr_results_obj: LeaveOneOutDecodingAnalysisResult - for Long/Short plotting\n",
    "\n",
    "radon_transform_data = RadonTransformPlotDataProvider._subfn_build_radon_transform_plotting_data(active_filter_epochs_df=active_filter_epochs_df,\n",
    "            num_filter_epochs = num_filter_epochs, time_bin_containers = time_bin_containers, radon_transform_column_names=['score', 'velocity', 'intercept', 'speed'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d17b087",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ad266b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _display_long_and_short_stacked_epoch_slices\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out_dict = curr_active_pipeline.display('_display_long_and_short_stacked_epoch_slices', save_figure=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ad5774",
   "metadata": {},
   "source": [
    "# <a id='toc13_'></a>[üíæ 2024-03-04 - Export `DecoderDecodedEpochsResult` CSVs with user annotations for epochs:](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae0ae73",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "pho-run-2024",
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import ensure_dataframe\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring\n",
    "\n",
    "# 2024-03-04 - Filter out the epochs based on the criteria:\n",
    "_, _, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "filtered_epochs_df, active_spikes_df = filter_and_update_epochs_and_spikes(curr_active_pipeline, global_epoch_name, track_templates, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1)\n",
    "filtered_valid_epoch_times = filtered_epochs_df[['start', 'stop']].to_numpy()\n",
    "\n",
    "## 2024-03-08 - Also constrain the user-selected ones (just to try it):\n",
    "decoder_user_selected_epoch_times_dict, any_user_selected_epoch_times = DecoderDecodedEpochsResult.load_user_selected_epoch_times(curr_active_pipeline, track_templates=track_templates)\n",
    "\n",
    "a_result_dict = deepcopy(directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "# {a_name:ensure_dataframe(a_result.filter_epochs) for a_name, a_result in a_result_dict.items()}\n",
    "\n",
    "directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=True)\n",
    "\n",
    "# üü™ 2024-02-29 - `compute_pho_heuristic_replay_scores`\n",
    "directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict, _out_new_scores = HeuristicReplayScoring.compute_all_heuristic_scores(track_templates=track_templates, a_decoded_filter_epochs_decoder_result_dict=directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "\n",
    "## Merge the heuristic columns into the wcorr df columns for exports\n",
    "directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "\n",
    "# {a_name:DecoderDecodedEpochsResult.try_add_is_user_annotated_epoch_column(ensure_dataframe(a_result.filter_epochs), any_good_selected_epoch_times=filtered_valid_epoch_times) for a_name, a_result in a_result_dict.items()}\n",
    "\n",
    "for a_name, a_result in a_result_dict.items():\n",
    "    # a_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=True)\n",
    "\n",
    "    ## Merge the heuristic columns into the wcorr df columns for exports\n",
    "    # directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "    a_wcorr_result = directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict[a_name]\n",
    "    \n",
    "    # did_update_user_annotation_col = DecoderDecodedEpochsResult.try_add_is_user_annotated_epoch_column(ensure_dataframe(a_result.filter_epochs), any_good_selected_epoch_times=any_user_selected_epoch_times, t_column_names=None)\n",
    "    # print(f'did_update_user_annotation_col: {did_update_user_annotation_col}')\n",
    "    # did_update_is_valid = DecoderDecodedEpochsResult.try_add_is_valid_epoch_column(ensure_dataframe(a_result.filter_epochs), any_good_selected_epoch_times=filtered_valid_epoch_times, t_column_names=None)\n",
    "    # print(f'did_update_is_valid: {did_update_is_valid}')\n",
    "\n",
    "# ['start',]\n",
    "\n",
    "a_result_dict = deepcopy(directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "\n",
    "# {a_name:ensure_dataframe(a_result.filter_epochs) for a_name, a_result in a_result_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba9f746",
   "metadata": {
    "tags": [
     "pho-run-2024",
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "from pathlib import Path\n",
    "\n",
    "# üíæ export_csvs\n",
    "\n",
    "# BATCH_DATE_TO_USE: str = f'{get_now_day_str()}_APOGEE' # TODO: Change this as needed, templating isn't actually doing anything rn.\n",
    "\n",
    "known_collected_outputs_paths = [Path(v).resolve() for v in ('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs', '/Users/pho/Dropbox (University of Michigan)/MED-DibaLabDropbox/Data/Pho/Outputs/output/collected_outputs', '/home/halechr/cloud/turbo/Data/Output/collected_outputs', '/home/halechr/FastData/gen_scripts/', '/home/halechr/FastData/collected_outputs/', 'output/gen_scripts/', r'K:\\scratch\\collected_outputs')]\n",
    "collected_outputs_path = find_first_extant_path(known_collected_outputs_paths)\n",
    "assert collected_outputs_path.exists(), f\"collected_outputs_path: '{collected_outputs_path}' does not exist! Is the right computer's config commented out above?\"\n",
    "print(f'collected_outputs_path: \"{collected_outputs_path}\"')\n",
    "active_context = curr_active_pipeline.get_session_context()\n",
    "curr_session_name: str = curr_active_pipeline.session_name # '2006-6-08_14-26-15'\n",
    "CURR_BATCH_OUTPUT_PREFIX: str = f\"{BATCH_DATE_TO_USE}-{curr_session_name}\"\n",
    "print(f'CURR_BATCH_OUTPUT_PREFIX: {CURR_BATCH_OUTPUT_PREFIX}')\n",
    "\n",
    "decoder_user_selected_epoch_times_dict, any_good_selected_epoch_times = DecoderDecodedEpochsResult.load_user_selected_epoch_times(curr_active_pipeline, track_templates=track_templates)\n",
    "print(f'\\tComputation complete. Exporting .CSVs...')\n",
    "\n",
    "# 2024-03-04 - Filter out the epochs based on the criteria:\n",
    "_, _, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "filtered_epochs_df, active_spikes_df = filter_and_update_epochs_and_spikes(curr_active_pipeline, global_epoch_name, track_templates, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1)\n",
    "filtered_valid_epoch_times = filtered_epochs_df[['start', 'stop']].to_numpy()\n",
    "\n",
    "## Export CSVs:\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "_output_csv_paths = directional_decoders_epochs_decode_result.export_csvs(parent_output_path=collected_outputs_path.resolve(), active_context=active_context, session_name=curr_session_name, curr_session_t_delta=t_delta,\n",
    "                                                                              user_annotation_selections={'ripple': any_good_selected_epoch_times},\n",
    "                                                                              valid_epochs_selections={'ripple': filtered_valid_epoch_times})\n",
    "\n",
    "print(f'\\t\\tsuccessfully exported directional_decoders_epochs_decode_result to {collected_outputs_path}!')\n",
    "_output_csv_paths_info_str: str = '\\n'.join([f'{a_name}: \"{file_uri_from_path(a_path)}\"' for a_name, a_path in _output_csv_paths.items()])\n",
    "# print(f'\\t\\t\\tCSV Paths: {_output_csv_paths}\\n')\n",
    "print(f'\\t\\t\\tCSV Paths: {_output_csv_paths_info_str}\\n')\n",
    "\n",
    "# {'laps_weighted_corr_merged_df': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-02-16_0750PM-kdiba_gor01_two_2006-6-07_16-40-19-(laps_weighted_corr_merged_df)_tbin-0.025.csv'),\n",
    "#  'ripple_weighted_corr_merged_df': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-02-16_0750PM-kdiba_gor01_two_2006-6-07_16-40-19-(ripple_weighted_corr_merged_df)_tbin-0.025.csv'),\n",
    "#  'laps_simple_pf_pearson_merged_df': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-02-16_0750PM-kdiba_gor01_two_2006-6-07_16-40-19-(laps_simple_pf_pearson_merged_df)_tbin-0.025.csv'),\n",
    "#  'ripple_simple_pf_pearson_merged_df': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2024-02-16_0750PM-kdiba_gor01_two_2006-6-07_16-40-19-(ripple_simple_pf_pearson_merged_df)_tbin-0.025.csv')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b77273",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ffc939",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "filtered_epochs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11f29ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "any_good_selected_epoch_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a297e18e",
   "metadata": {},
   "source": [
    "# <a id='toc14_'></a>[2024-03-04 - Filter out the epochs based on the criteria:](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c049e59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neuropy.utils.mixins.time_slicing import add_epochs_id_identity\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "\n",
    "# 2024-03-04 - Filter out the epochs based on the criteria:\n",
    "filtered_epochs_df, active_spikes_df = filter_and_update_epochs_and_spikes(curr_active_pipeline, global_epoch_name, track_templates, required_min_percentage_of_active_cells=0.333333, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1)\n",
    "filtered_epochs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db54a34",
   "metadata": {},
   "source": [
    "## <a id='toc14_1_'></a>[Track Position Classification (is_endcap, etc)](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dc4913",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: a_heuristics_result\n",
    "# def classify_position_bins(pos_bin_edges: NDArray):\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import LinearTrackInstance\n",
    "\n",
    "long_track_inst, short_track_inst = LinearTrackInstance.init_tracks_from_session_config(curr_active_pipeline.sess.config)\n",
    "# long_track_inst\n",
    "# track_templates.get_track_length_dict()\n",
    "\n",
    "pos_bin_edges = deepcopy(track_templates.get_decoders_dict()['long_LR'].xbin_centers)\n",
    "# pos_bin_edges\n",
    "## test xbins\n",
    "# is_pos_bin_endcap = [long_track_inst.classify_x_position(x).is_endcap for x in pos_bin_edges]\n",
    "# is_pos_bin_on_maze = [long_track_inst.classify_x_position(x).is_on_maze for x in pos_bin_edges]\n",
    "# is_pos_bin_endcap\n",
    "# is_pos_bin_on_maze\n",
    "\n",
    "long_pos_bin_classification_df: pd.DataFrame = long_track_inst.build_x_position_classification_df(x_arr=pos_bin_edges).add_suffix('_long')\n",
    "short_pos_bin_classification_df: pd.DataFrame = short_track_inst.build_x_position_classification_df(x_arr=pos_bin_edges).add_suffix('_short')\n",
    "\n",
    "long_pos_bin_classification_df\n",
    "short_pos_bin_classification_df\n",
    "\n",
    "# pd.merge(long_pos_bin_classification_df, short_pos_bin_classification_df, suffixes=['_long', '_short'])\n",
    "pos_bin_classification_df = pd.concat([long_pos_bin_classification_df, short_pos_bin_classification_df], axis='columns').rename(columns={'x_long': 'x'}).drop(columns=['x_short']).reset_index(drop=True)\n",
    "pos_bin_classification_df['x_binned'] = pos_bin_classification_df.index.astype(int)\n",
    "pos_bin_classification_df\n",
    "\n",
    "# pos_bin_classification_df\n",
    "# pd.DataFrame({'x': deepcopy(pos_bin_edges), 'is_endcap': is_pos_bin_endcap, 'is_on_maze': is_pos_bin_on_maze})\n",
    "\n",
    "\n",
    "# a_heuristics_result.partition_result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28556b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import LinearTrackInstance\n",
    "\n",
    "long_track_inst, short_track_inst = LinearTrackInstance.init_tracks_from_session_config(curr_active_pipeline.sess.config)\n",
    "long_track_inst\n",
    "# track_templates.get_track_length_dict()\n",
    "\n",
    "pos_bin_edges = deepcopy(track_templates.get_decoders_dict()['long_LR'].xbin_centers)\n",
    "pos_bin_edges\n",
    "# pos_bin_edges\n",
    "## test xbins\n",
    "is_pos_bin_endcap = [long_track_inst.classify_x_position(x).is_endcap for x in pos_bin_edges]\n",
    "is_pos_bin_on_maze = [long_track_inst.classify_x_position(x).is_on_maze for x in pos_bin_edges]\n",
    "is_pos_bin_endcap\n",
    "is_pos_bin_on_maze\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac25593",
   "metadata": {},
   "source": [
    "# <a id='toc15_'></a>[‚ùïüü¢ 2024-10-07 - Rigorous Decoder Performance assessment](#toc0_)\n",
    "2024-03-29 - Quantify cell contributions to decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9715a6",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# Inputs: all_directional_pf1D_Decoder, alt_directional_merged_decoders_result\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrainTestSplitResult, TrainTestLapsSplitting, CustomDecodeEpochsResult, decoder_name, epoch_split_key, get_proper_global_spikes_df, DirectionalPseudo2DDecodersResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _do_train_test_split_decode_and_evaluate\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import PfND\n",
    "from neuropy.core.session.dataSession import Laps\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_run_rigorous_decoder_performance_assessment\n",
    "# from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import compute_weighted_correlations\n",
    "# from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _check_result_laps_epochs_df_performance\n",
    "\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "global_session = curr_active_pipeline.filtered_sessions[global_epoch_name]\n",
    "\n",
    "def _add_extra_epochs_df_columns(epochs_df: pd.DataFrame):\n",
    "    \"\"\" captures: global_session, t_start, t_delta, t_end\n",
    "    \n",
    "    _remerged_laps_dfs_dict[a_decoder_name] = _add_extra_epochs_df_columns(epochs_df=_remerged_laps_dfs_dict[a_decoder_name])\n",
    "    \n",
    "    \"\"\"\n",
    "    epochs_df = epochs_df.sort_values(['start', 'stop', 'label']).reset_index(drop=True) # Sort by columns: 'start' (ascending), 'stop' (ascending), 'label' (ascending)\n",
    "    epochs_df = epochs_df.drop_duplicates(subset=['start', 'stop', 'label'])\n",
    "    epochs_df = epochs_df.epochs.adding_maze_id_if_needed(t_start=t_start, t_delta=t_delta, t_end=t_end)\n",
    "    epochs_df = Laps._compute_lap_dir_from_smoothed_velocity(laps_df=epochs_df, global_session=deepcopy(global_session), replace_existing=True)\n",
    "    return epochs_df\n",
    "\n",
    "directional_train_test_split_result: TrainTestSplitResult = curr_active_pipeline.global_computation_results.computed_data.get('TrainTestSplit', None)\n",
    "force_recompute_directional_train_test_split_result: bool = False\n",
    "if (directional_train_test_split_result is None) or force_recompute_directional_train_test_split_result:\n",
    "    ## recompute\n",
    "    print(f\"'TrainTestSplit' not computed, recomputing...\")\n",
    "    curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_train_test_split'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "    directional_train_test_split_result: TrainTestSplitResult = curr_active_pipeline.global_computation_results.computed_data['TrainTestSplit']\n",
    "    assert directional_train_test_split_result is not None, f\"faiiled even after recomputation\"\n",
    "    print('\\tdone.')\n",
    "\n",
    "training_data_portion: float = directional_train_test_split_result.training_data_portion\n",
    "test_data_portion: float = directional_train_test_split_result.test_data_portion\n",
    "print(f'training_data_portion: {training_data_portion}, test_data_portion: {test_data_portion}')\n",
    "\n",
    "test_epochs_dict: Dict[types.DecoderName, pd.DataFrame] = directional_train_test_split_result.test_epochs_dict\n",
    "train_epochs_dict: Dict[types.DecoderName, pd.DataFrame] = directional_train_test_split_result.train_epochs_dict\n",
    "train_lap_specific_pf1D_Decoder_dict: Dict[types.DecoderName, BasePositionDecoder] = directional_train_test_split_result.train_lap_specific_pf1D_Decoder_dict\n",
    "\n",
    "# OUTPUTS: train_test_split_laps_df_dict\n",
    "# active_laps_decoding_time_bin_size: float = 0.025\n",
    "# active_laps_decoding_time_bin_size: float = 0.058\n",
    "# active_laps_decoding_time_bin_size: float = 0.075 # 75ms\n",
    "# active_laps_decoding_time_bin_size: float = 0.25\n",
    "active_laps_decoding_time_bin_size: float = 1.5\n",
    "# active_laps_decoding_time_bin_size: float = 5.5\n",
    "# included_neuron_IDs=disappearing_aclus\n",
    "included_neuron_IDs=None\n",
    "complete_decoded_context_correctness_tuple, laps_marginals_df, all_directional_pf1D_Decoder, all_test_epochs_df, test_all_directional_decoder_result, all_directional_laps_filter_epochs_decoder_result, _out_separate_decoder_results = _do_train_test_split_decode_and_evaluate(curr_active_pipeline=curr_active_pipeline,\n",
    "                                                                                                                                                                                                                active_laps_decoding_time_bin_size=active_laps_decoding_time_bin_size, included_neuron_IDs=included_neuron_IDs,\n",
    "                                                                                                                                                                                                                force_recompute_directional_train_test_split_result=False, compute_separate_decoder_results=True)\n",
    "(is_decoded_track_correct, is_decoded_dir_correct, are_both_decoded_properties_correct), (percent_laps_track_identity_estimated_correctly, percent_laps_direction_estimated_correctly, percent_laps_estimated_correctly) = complete_decoded_context_correctness_tuple\n",
    "print(f\"percent_laps_track_identity_estimated_correctly: {round(percent_laps_track_identity_estimated_correctly*100.0, ndigits=3)}%\")\n",
    "\n",
    "if _out_separate_decoder_results is not None:\n",
    "    assert len(_out_separate_decoder_results) == 3, f\"_out_separate_decoder_results: {_out_separate_decoder_results}\"\n",
    "    test_decoder_results_dict, train_decoded_results_dict, train_decoded_measured_diff_df_dict = _out_separate_decoder_results\n",
    "    ## OUTPUTS: test_decoder_results_dict, train_decoded_results_dict\n",
    "_remerged_laps_dfs_dict = {}\n",
    "for a_decoder_name, a_test_epochs_df in test_epochs_dict.items():\n",
    "    a_train_epochs_df = train_epochs_dict[a_decoder_name]\n",
    "    a_train_epochs_df['test_train_epoch_type'] = 'train'\n",
    "    a_test_epochs_df['test_train_epoch_type'] = 'test'\n",
    "    _remerged_laps_dfs_dict[a_decoder_name] = pd.concat([a_train_epochs_df, a_test_epochs_df], axis='index')\n",
    "    _remerged_laps_dfs_dict[a_decoder_name] = _add_extra_epochs_df_columns(epochs_df=_remerged_laps_dfs_dict[a_decoder_name])\n",
    "\n",
    "\n",
    "# _add_extra_epochs_df_columns\n",
    "# _remerged_laps_dfs_dict = {k: pd.concat([v, test_epochs_dict[k]], axis='index') for k, v in train_epochs_dict.items()}\t\n",
    "# _remerged_laps_dfs_dict['long_LR']\n",
    "\n",
    "\n",
    "## OUTPUTS: all_test_epochs_df, train_epochs_dict, test_epochs_dict, _remerged_laps_dfs_dict\n",
    "# all_test_epochs_df\n",
    "\n",
    "# Performed 3 aggregations grouped on column: 'lap_id'\n",
    "# all_test_epochs_df = all_test_epochs_df.groupby(['lap_id']).agg(start_min=('start', 'min'), stop_max=('stop', 'max'), maze_id_first=('maze_id', 'first')).reset_index()\n",
    "epochs_bin_by_bin_performance_analysis_df: pd.DataFrame = test_all_directional_decoder_result.epochs_bin_by_bin_performance_analysis_df\n",
    "epochs_bin_by_bin_performance_analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebe0620",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c397b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%scrollable_colored_table\n",
    "\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import TimeBinAggregation\n",
    "\n",
    "\n",
    "# Apply to grouped DataFrame\n",
    "lap_agg_test_df = epochs_bin_by_bin_performance_analysis_df.groupby('lap_id').apply(lambda group: TimeBinAggregation.compute_streak_weighted_p_long(group, column='P_Long')) #.reset_index(name='streak_weighted_P_Long')\n",
    "lap_agg_test_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebda447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import TimeBinAggregation\n",
    "\n",
    "# Merge or add results back to the original DataFrame\n",
    "# streak_weighted_P_Long = lap_agg_test_df['streak_weighted_P_Long'].to_numpy()\n",
    "\n",
    "\n",
    "# from pyphocorehelpers.print_helpers import render_scrollable_colored_table_from_dataframe\n",
    "\n",
    "## Explore aggregation methods:\n",
    "\n",
    "# ## decide on direction first\n",
    "# a_var_name: str = 'P_LR'\n",
    "# lap_agg_test_df = epochs_bin_by_bin_performance_analysis_df.groupby('lap_id')[[a_var_name]].agg(['sum', 'count', 'max'])\n",
    "# lap_agg_test_df[(a_var_name,   'normalized_sum')] = lap_agg_test_df[(a_var_name,   'sum')] / lap_agg_test_df[(a_var_name,   'count')]\n",
    "# lap_agg_test_df\n",
    "\n",
    "# agg_column_names = ['P_Long', 'P_LR']\n",
    "agg_column_names = ['P_Long', 'P_Short', 'P_LR', 'P_RL']\n",
    "\n",
    "lap_agg_test_df = epochs_bin_by_bin_performance_analysis_df.groupby('lap_id')[agg_column_names].agg(['sum', 'count', 'max'])\n",
    "\n",
    "for a_var_name in agg_column_names:\n",
    "    # lap_agg_test_df = epochs_bin_by_bin_performance_analysis_df.groupby('lap_id')[[a_var_name]].agg(['sum', 'count', 'max'])\n",
    "    lap_agg_test_df[(a_var_name,   'normalized_sum')] = lap_agg_test_df[(a_var_name,   'sum')] / lap_agg_test_df[(a_var_name,   'count')]\n",
    "    lap_agg_test_df[(a_var_name,   'streak_wieghted')] = epochs_bin_by_bin_performance_analysis_df.groupby('lap_id').apply(lambda group: TimeBinAggregation.compute_streak_weighted_p_long(group, column=a_var_name)).to_numpy()\n",
    "    lap_agg_test_df[(a_var_name,   'peak_rolling')] = epochs_bin_by_bin_performance_analysis_df.groupby('lap_id').apply(lambda group: TimeBinAggregation.peak_rolling_avg(group, column=a_var_name, window=5)).to_numpy()\n",
    "\n",
    "    # move performance columns to very end:\n",
    "    lap_agg_test_df = reorder_columns_relative(lap_agg_test_df, column_names=list(filter(lambda column: column[0].startswith(f'{a_var_name}'), lap_agg_test_df.columns)), relative_mode='start')\n",
    "        \n",
    "\n",
    "\n",
    "# lap_agg_test_df[('P_Long',   'normalized_sum')] = lap_agg_test_df[('P_Long',   'sum')] / lap_agg_test_df[('P_Long',   'count')]\n",
    "# lap_agg_test_df[('P_Long',   'streak_wieghted')] = epochs_bin_by_bin_performance_analysis_df.groupby('lap_id').apply(lambda group: TimeBinAggregation.compute_streak_weighted_p_long(group, column='P_Long')).to_numpy()\n",
    "\n",
    "# lap_agg_test_df[('P_Long',   'normalized_sum')] = lap_agg_test_df[('P_Long',   'sum')] / lap_agg_test_df[('P_Long',   'count')]\n",
    "# lap_agg_test_df[('P_Long',   'streak_wieghted')] = epochs_bin_by_bin_performance_analysis_df.groupby('lap_id').apply(lambda group: TimeBinAggregation.compute_streak_weighted_p_long(group, column='P_Long')).to_numpy()\n",
    "\n",
    "# reorder_columns_relative(lap_agg_test_df, column_names=\n",
    "lap_agg_test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7702f75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# lap_agg_test_df.head(0)\n",
    "# n_rows, height_px\n",
    "df = deepcopy(lap_agg_test_df)\n",
    "# df\n",
    "\n",
    "# df.columns\n",
    "\n",
    "\n",
    "# 1992 - const_table_parts_height\n",
    "# [[0, 72],\n",
    "# [80, 1992],\n",
    "# ]\n",
    "# render_scrollable_colored_table_from_dataframe(df=lap_agg_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52919fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_lap_id: int = 1\n",
    "a_lap_df = epochs_bin_by_bin_performance_analysis_df[epochs_bin_by_bin_performance_analysis_df['lap_id'] == 1]\n",
    "a_lap_df\n",
    "# a_lap_df[a_var_name].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7609d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "correctness_per_lap = epochs_bin_by_bin_performance_analysis_df.groupby('lap_id')[['estimation_correctness_track_ID']].agg(['sum', 'count', 'max'])\n",
    "correctness_per_lap[('estimation_correctness_track_ID',   'normalized_sum')] = correctness_per_lap[('estimation_correctness_track_ID',   'sum')] / correctness_per_lap[('estimation_correctness_track_ID',   'count')]\n",
    "correctness_per_lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48688256",
   "metadata": {
    "tags": [
     "active-2025-01-14",
     "lap-decoder-correctness"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_run_rigorous_decoder_performance_assessment, TimeBinAggregation, ParticleFilter, EstimationCorrectnessPlots\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import CustomDecodeEpochsResult, MeasuredDecodedPositionComparison, DecodedFilterEpochsResult\n",
    "\n",
    "# laps_marginals_df\n",
    "# active_laps_decoding_time_bin_size: float = 0.025\n",
    "active_laps_decoding_time_bin_size: float = 0.058\n",
    "## INPUTS: active_laps_decoding_time_bin_size: float = 0.025\n",
    "_out_subset_decode_results = _perform_run_rigorous_decoder_performance_assessment(curr_active_pipeline=curr_active_pipeline, included_neuron_IDs=None, active_laps_decoding_time_bin_size=active_laps_decoding_time_bin_size)\n",
    "## extract results:\n",
    "complete_decoded_context_correctness_tuple, laps_marginals_df, all_directional_pf1D_Decoder, all_test_epochs_df, test_all_directional_laps_decoder_result, all_directional_laps_filter_epochs_decoder_result, _out_separate_decoder_results = _out_subset_decode_results\n",
    "(is_decoded_track_correct, is_decoded_dir_correct, are_both_decoded_properties_correct), (percent_laps_track_identity_estimated_correctly, percent_laps_direction_estimated_correctly, percent_laps_estimated_correctly) = complete_decoded_context_correctness_tuple\n",
    "# _out_subset_decode_results_track_id_correct_performance_dict[a_subset_name] = float(percent_laps_track_identity_estimated_correctly)\n",
    "\n",
    "test_all_directional_laps_decoder_result: CustomDecodeEpochsResult = deepcopy(test_all_directional_laps_decoder_result)\n",
    "test_all_directional_laps_decoder_result\n",
    "\n",
    "## INPUTS: train_lap_specific_pf1D_Decoder_dict\n",
    "# active_pf_2D = train_lap_specific_pf1D_Decoder_dict['long_LR'] # active_pf_2D: used for binning position columns\n",
    "active_pf_2D = deepcopy(all_directional_pf1D_Decoder) # active_pf_2D: used for binning position columns\n",
    "laps_epochs_bin_by_bin_performance_analysis_df = test_all_directional_laps_decoder_result.epochs_bin_by_bin_performance_analysis_df\n",
    "laps_epochs_bin_by_bin_performance_analysis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024c2cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import CustomDecodeEpochsResult, MeasuredDecodedPositionComparison, DecodedFilterEpochsResult\n",
    "\n",
    "# all_directional_laps_filter_epochs_decoder_result # DecodedFilterEpochsResult\n",
    "# all_directional_laps_filter_epochs_decoder_result_value\n",
    "\n",
    "\n",
    "# all_directional_laps_filter_epochs_decoder_custom_result: CustomDecodeEpochsResult = CustomDecodeEpochsResult.build_single_measured_decoded_position_comparison(a_decoder_decoding_result=deepcopy(all_directional_laps_filter_epochs_decoder_result), global_measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()).dropna(subset=['lap']))\n",
    "all_directional_laps_filter_epochs_decoder_custom_result: CustomDecodeEpochsResult = CustomDecodeEpochsResult.init_from_single_decoder_decoding_result_and_measured_pos_df(a_decoder_decoding_result=deepcopy(all_directional_laps_filter_epochs_decoder_result),\n",
    "                                                                                                                                                                            global_measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()).dropna(subset=['lap']),\n",
    "                                                                                                                                                                            pf1D_Decoder=deepcopy(all_directional_pf1D_Decoder),\n",
    "                                                                                                                                                                            )\n",
    "all_directional_laps_filter_epochs_decoder_custom_result\n",
    "\n",
    "laps_epochs_bin_by_bin_performance_analysis_df = all_directional_laps_filter_epochs_decoder_custom_result.epochs_bin_by_bin_performance_analysis_df\n",
    "laps_epochs_bin_by_bin_performance_analysis_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea48172",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(num='binned_x_meas_laps hist')\n",
    "sns.histplot(laps_epochs_bin_by_bin_performance_analysis_df['binned_x_meas'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e73547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(num='binned_x_meas_laps hist')\n",
    "sns.histplot(laps_epochs_bin_by_bin_performance_analysis_df['binned_x_meas'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd4357d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_position_bins, n_decoding_models, n_time_bins = p_x_given_n.shape\n",
    "A_position, A_model, A_big = build_position_by_decoder_transition_matrix(p_x_given_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cbe5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.session.dataSession import Laps\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _do_custom_decode_epochs\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Computes bin-by-bin performance analysis for all laps                                                                #\n",
    "# ==================================================================================================================== #\n",
    "# ==================================================================================================================== #\n",
    "# Multiple time-bin-sizes                                                                                              #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "try:\n",
    "        _out_subset_decode_dict\n",
    "except NameError:\n",
    "        _out_subset_decode_dict: Dict[float, List[pd.DataFrame]] = {} \n",
    "except Exception as e:\n",
    "        raise e\n",
    "\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "global_session = curr_active_pipeline.filtered_sessions[global_epoch_name]\n",
    "\n",
    "def _add_extra_epochs_df_columns(epochs_df: pd.DataFrame):\n",
    "    \"\"\" captures: global_session, t_start, t_delta, t_end\n",
    "    \n",
    "    global_laps_epochs_df = _add_extra_epochs_df_columns(epochs_df=global_laps_epochs_df)\n",
    "    \n",
    "    \"\"\"\n",
    "    epochs_df = epochs_df.sort_values(['start', 'stop', 'label']).reset_index(drop=True) # Sort by columns: 'start' (ascending), 'stop' (ascending), 'label' (ascending)\n",
    "    epochs_df = epochs_df.drop_duplicates(subset=['start', 'stop', 'label'])\n",
    "    epochs_df = epochs_df.epochs.adding_maze_id_if_needed(t_start=t_start, t_delta=t_delta, t_end=t_end)\n",
    "    epochs_df = Laps._compute_lap_dir_from_smoothed_velocity(laps_df=epochs_df, global_session=deepcopy(global_session), replace_existing=True)\n",
    "    return epochs_df\n",
    "\n",
    "\n",
    "# global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps) # .trimmed_to_non_overlapping()\n",
    "global_laps_epochs_df = global_laps.to_dataframe()\n",
    "global_laps_epochs_df = _add_extra_epochs_df_columns(epochs_df=global_laps_epochs_df)\n",
    "# active_test_epochs_df: pd.DataFrame = deepcopy(global_laps_epochs_df)\n",
    "global_laps_epochs_df\n",
    "debug_print = False\n",
    "\n",
    "## INPUTS: curr_active_pipeline, all_directional_pf1D_Decoder, all_test_epochs_df, debug_print\n",
    "_out_custom_decode_dict: Dict[float, CustomDecodeEpochsResult] = {}\n",
    "_out_epochs_bin_by_bin_performance_analysis_df_dict: Dict[float, List[pd.DataFrame]] = {} \n",
    "\n",
    "# decoding_time_bin_size_list = [0.025, 0.050, 0.058, 0.125, 0.250, 0.500, 1.0]\n",
    "decoding_time_bin_size_list = [0.025, 0.058] # 0.025, , 1.0\n",
    "\n",
    "for active_laps_decoding_time_bin_size in decoding_time_bin_size_list:\n",
    "    ## INPUTS: active_laps_decoding_time_bin_size: float = 0.025\n",
    "    if active_laps_decoding_time_bin_size not in _out_subset_decode_dict:\n",
    "            ## initialize to new list if doesn't exist\n",
    "            _out_subset_decode_dict[active_laps_decoding_time_bin_size] = []\n",
    "\n",
    "    ## Decoding of the test epochs (what matters) for `all_directional_pf1D_Decoder`:\n",
    "    an_all_directional_decoder_custom_result: CustomDecodeEpochsResult = _do_custom_decode_epochs(global_spikes_df=get_proper_global_spikes_df(curr_active_pipeline), global_measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()).dropna(subset=['lap']),\n",
    "                                                            pf1D_Decoder=all_directional_pf1D_Decoder, epochs_to_decode_df=deepcopy(global_laps_epochs_df),\n",
    "                                                            decoding_time_bin_size=active_laps_decoding_time_bin_size, debug_print=debug_print)\n",
    "    _out_custom_decode_dict[active_laps_decoding_time_bin_size] = an_all_directional_decoder_custom_result\n",
    "    active_pf_2D = deepcopy(all_directional_pf1D_Decoder) # active_pf_2D: used for binning position columns # active_pf_2D: used for binning position columns\n",
    "    epochs_bin_by_bin_performance_analysis_df = an_all_directional_decoder_custom_result.get_lap_bin_by_bin_performance_analysis_df(active_pf_2D, should_include_decoded_pos_columns=True)\n",
    "\n",
    "    # all_directional_laps_filter_epochs_decoder_result: DecodedFilterEpochsResult = an_all_directional_decoder_custom_result.decoder_result\n",
    "    # epochs_track_identity_marginal_df = build_lap_bin_by_bin_performance_analysis_df(test_all_directional_laps_decoder_result, active_pf_2D)\n",
    "        #     epochs_bin_by_bin_performance_analysis_df = an_all_directional_decoder_custom_result.epochs_bin_by_bin_performance_analysis_df\n",
    "\n",
    "    _out_epochs_bin_by_bin_performance_analysis_df_dict[active_laps_decoding_time_bin_size] = epochs_bin_by_bin_performance_analysis_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# OUTPUTS: _out_custom_decode_dict, _out_epochs_bin_by_bin_performance_analysis_df_dict\n",
    "## Merge the independent shuffle dataframes into a dict of single dfs for all shuffles\n",
    "_out_epochs_bin_by_bin_performance_analysis_df_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6b557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(num='binned_x_decode HIST'); sns.histplot(epochs_bin_by_bin_performance_analysis_df['binned_x_decode']); plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f7bc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_run_rigorous_decoder_performance_assessment, EstimationCorrectnessPlots # , build_lap_bin_by_bin_performance_analysis_df\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import CustomDecodeEpochsResult, MeasuredDecodedPositionComparison, DecodedFilterEpochsResult\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Computes bin-by-bin performance analysis for just the test (as opposed to the train) laps                            #\n",
    "# ==================================================================================================================== #\n",
    "# ==================================================================================================================== #\n",
    "# Multiple time-bin-sizes                                                                                              #\n",
    "# ==================================================================================================================== #\n",
    "try:\n",
    "        _out_subset_decode_dict\n",
    "except NameError:\n",
    "        _out_subset_decode_dict: Dict[float, List[pd.DataFrame]] = {} \n",
    "except Exception as e:\n",
    "        raise e\n",
    "\n",
    "n_resamples: int = 8\n",
    "# decoding_time_bin_size_list = [0.025, 0.050, 0.058, 0.125, 0.250, 0.500, 1.0]\n",
    "decoding_time_bin_size_list = [0.025, 0.058] # 0.025, , 1.0\n",
    "\n",
    "for active_laps_decoding_time_bin_size in decoding_time_bin_size_list:\n",
    "        ## INPUTS: active_laps_decoding_time_bin_size: float = 0.025\n",
    "        if active_laps_decoding_time_bin_size not in _out_subset_decode_dict:\n",
    "                ## initialize to new list if doesn't exist\n",
    "                _out_subset_decode_dict[active_laps_decoding_time_bin_size] = []\n",
    "        for i in np.arange(n_resamples):\n",
    "                _out_subset_decode_results = _perform_run_rigorous_decoder_performance_assessment(curr_active_pipeline=curr_active_pipeline, included_neuron_IDs=None, active_laps_decoding_time_bin_size=active_laps_decoding_time_bin_size, force_recompute_directional_train_test_split_result=True)\n",
    "                ## extract results:\n",
    "                complete_decoded_context_correctness_tuple, laps_marginals_df, all_directional_pf1D_Decoder, all_test_epochs_df, test_all_directional_laps_decoder_result, all_directional_laps_filter_epochs_decoder_result, _out_separate_decoder_results = _out_subset_decode_results\n",
    "                (is_decoded_track_correct, is_decoded_dir_correct, are_both_decoded_properties_correct), (percent_laps_track_identity_estimated_correctly, percent_laps_direction_estimated_correctly, percent_laps_estimated_correctly) = complete_decoded_context_correctness_tuple\n",
    "                test_all_directional_laps_decoder_result: CustomDecodeEpochsResult = deepcopy(test_all_directional_laps_decoder_result)\n",
    "                active_pf_2D = deepcopy(all_directional_pf1D_Decoder) # active_pf_2D: used for binning position columns # active_pf_2D: used for binning position columns\n",
    "                # epochs_track_identity_marginal_df = build_lap_bin_by_bin_performance_analysis_df(test_all_directional_laps_decoder_result, active_pf_2D)\n",
    "                epochs_bin_by_bin_performance_analysis_df = test_all_directional_laps_decoder_result.get_lap_bin_by_bin_performance_analysis_df(active_pf_2D, should_include_decoded_pos_columns=True)\n",
    "                # _out_subset_decode_dict[active_laps_decoding_time_bin_size] = epochs_track_identity_marginal_df\n",
    "                epochs_bin_by_bin_performance_analysis_df['shuffle_idx'] = int(i)\n",
    "                _out_subset_decode_dict[active_laps_decoding_time_bin_size].append(epochs_bin_by_bin_performance_analysis_df)\n",
    "\n",
    "\n",
    "# OUTPUTS: _out_subset_decode_dict\n",
    "## Merge the independent shuffle dataframes into a dict of single dfs for all shuffles\n",
    "_out_subset_decode_dfs_dict: Dict[float, pd.DataFrame] = {active_laps_decoding_time_bin_size:pd.concat(v, axis='index').reset_index(drop=True) for active_laps_decoding_time_bin_size, v in _out_subset_decode_dict.items()}\n",
    "_out_subset_decode_dfs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b33ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "_out_subset_decode_dfs_dict = deepcopy(_out_epochs_bin_by_bin_performance_analysis_df_dict)\n",
    "\n",
    "df = deepcopy(_out_subset_decode_dfs_dict[0.058])\n",
    "\n",
    "# Create a combined column to group by both 'binned_x_meas' and 'is_Long'\n",
    "# df['group'] = df['binned_x_meas'].astype(str) + '_' + df['is_Long'].astype(str)\n",
    "\n",
    "# # Plot distribution\n",
    "# fig = px.histogram(\n",
    "#     df,\n",
    "# \t# x='binned_x_meas',\n",
    "#     y='estimation_correctness_track_ID',\n",
    "#     # color='group',\n",
    "#     barmode='overlay',  # Use 'group' for side-by-side bars\n",
    "#     facet_row='binned_x_meas',\n",
    "#     facet_col='is_Long',\n",
    "#     title=\"Distribution of Estimation Correctness by Groups\",\n",
    "#     labels={'estimation_correctness_track_ID': 'Estimation Correctness'},\n",
    "# \tfacet_row_spacing=0.01,  # Adjust this to meet the spacing requirement\n",
    "# )\n",
    "\n",
    "# fig = px.scatter(df, x=\"binned_x_meas\", y=\"estimation_correctness_track_ID\",\n",
    "#                 # color=\"estimation_correctness_track_ID\",\n",
    "#                  facet_row='is_Long',\n",
    "#                 #  error_x=\"e\", error_y=\"e\",\n",
    "#                  )\n",
    "\n",
    "# # Update layout for better spacing\n",
    "# fig.update_layout(height=2000, width=1800)\n",
    "\n",
    "# # Show the plot\n",
    "# fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156f3116",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Example usage\n",
    "# EstimationCorrectnessPlots.plot_estimation_correctness_vertical_stack(\n",
    "#     _out_subset_decode_dict, 'binned_x_meas', 'estimation_correctness_track_ID'\n",
    "# )\n",
    "\n",
    "EstimationCorrectnessPlots.plot_estimation_correctness_vertical_stack(\n",
    "    _out_subset_decode_dfs_dict, 'binned_x_meas', 'estimation_correctness_track_ID'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "# EstimationCorrectnessPlots.plot_estimation_correctness_bean_plot(\n",
    "#     _out_subset_decode_dfs_dict, 'binned_x_meas', 'estimation_correctness_track_ID'\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241ba398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_time_bin_size: float = 0.025\n",
    "active_time_bin_size: float = 0.058\n",
    "\n",
    "np.unique(_out_subset_decode_dfs_dict[active_time_bin_size]['binned_x_meas'].to_numpy()) #.to_csv('output/2025-01-02_estimation_correctness_df.csv')\n",
    "\n",
    "_out_subset_decode_dfs_dict[active_time_bin_size]['binned_x_meas'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe117549",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = deepcopy(_out_subset_decode_dfs_dict[active_time_bin_size])\n",
    "# Grouping by 'binned_x_meas' and calculating the mean of 'estimation_correctness_track_ID'\n",
    "binned_analysis = data.groupby('binned_x_meas')['estimation_correctness_track_ID'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# Renaming columns for clarity\n",
    "binned_analysis.rename(columns={'mean': 'avg_estimation_correctness', 'std': 'std_dev'}, inplace=True)\n",
    "\n",
    "# import ace_tools as tools; tools.display_dataframe_to_user(name=\"Estimation Correctness Analysis by Binned x_meas\", dataframe=binned_analysis)\n",
    "\n",
    "# Visualizing the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(binned_analysis['binned_x_meas'], binned_analysis['avg_estimation_correctness'], \n",
    "             yerr=binned_analysis['std_dev'], fmt='o-', ecolor='red', capsize=5, label='Mean ¬± Std Dev')\n",
    "plt.title('Estimation Correctness Track ID vs. Binned x_meas')\n",
    "plt.xlabel('Binned x_meas')\n",
    "plt.ylabel('Avg Estimation Correctness Track ID')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d75c8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "for active_laps_decoding_time_bin_size, a_epochs_track_identity_marginal_df in _out_subset_decode_dict.items():\n",
    "    EstimationCorrectnessPlots.plot_estimation_correctness_with_raw_data(a_epochs_track_identity_marginal_df, 'binned_x_meas', 'estimation_correctness_track_ID', extra_info_str=f\"t_bin: {active_laps_decoding_time_bin_size}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36be4894",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'disappearing_aclus: {disappearing_aclus}')\n",
    "_alt_directional_train_test_split_result = directional_train_test_split_result.sliced_by_neuron_id(included_neuron_ids=disappearing_aclus)\n",
    "_alt_directional_train_test_split_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b3c702",
   "metadata": {},
   "outputs": [],
   "source": [
    "_alt_directional_train_test_split_result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1f115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_decoded_track_correct ## get an across_session_scatter output like we do for the ripples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab81db6",
   "metadata": {},
   "source": [
    "### <a id='toc15_1_1_'></a>[Display the `TrainTestSplitResult` in a `PhoPaginatedMultiDecoderDecodedEpochsWindow`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d23249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import Epoch, ensure_dataframe\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import add_laps_groundtruth_information_to_dataframe\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import PhoPaginatedMultiDecoderDecodedEpochsWindow\n",
    "\n",
    "## INPUTS: train_decoded_results_dict\n",
    "# decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs # looks like 'lap_dir' column is wrong\n",
    "\n",
    "active_results: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(decoder_laps_filter_epochs_decoder_result_dict)\n",
    "# active_results: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(train_decoded_results_dict)\n",
    "\n",
    "# updated_laps_dfs_dict = {}\n",
    "# ## Update the .filter_epochs:\n",
    "# for k, v in active_results.items():\n",
    "#     updated_laps_dfs_dict[k] = Epoch(add_laps_groundtruth_information_to_dataframe(curr_active_pipeline=curr_active_pipeline, result_laps_epochs_df=ensure_dataframe(v.filter_epochs)))\n",
    "#     active_results[k].filter_epochs =  updated_laps_dfs_dict[k]\n",
    "\n",
    "# updated_laps_dfs_dict['long_LR']\n",
    "# active_results['long_LR'].filter_epochs\n",
    "## INPUTS: track_templates (for get_track_length_dict)\n",
    "laps_app, laps_paginated_multi_decoder_decoded_epochs_window, laps_pagination_controller_dict = PhoPaginatedMultiDecoderDecodedEpochsWindow.init_from_track_templates(curr_active_pipeline, track_templates,\n",
    "                            decoder_decoded_epochs_result_dict=active_results, epochs_name='laps', included_epoch_indicies=None, \n",
    "    params_kwargs={'enable_per_epoch_action_buttons': False,\n",
    "    'skip_plotting_most_likely_positions': False, 'skip_plotting_measured_positions': False, \n",
    "    # 'enable_decoded_most_likely_position_curve': False, 'enable_radon_transform_info': True, 'enable_weighted_correlation_info': False,\n",
    "    'enable_decoded_most_likely_position_curve': True, 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': False,\n",
    "    # 'disable_y_label': True,\n",
    "    # 'isPaginatorControlWidgetBackedMode': True,\n",
    "    # 'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True,\n",
    "    # 'debug_print': True,\n",
    "    'max_subplots_per_page': 10,\n",
    "    'scrollable_figure': True,\n",
    "    # 'posterior_heatmap_imshow_kwargs': dict(vmin=0.0075),\n",
    "    'use_AnchoredCustomText': False,\n",
    "    'track_length_dict': track_templates.get_track_length_dict(),\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9966898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import TrainTestSplitPlotDataProvider, TrainTestSplitPlotData\n",
    "\n",
    "\n",
    "## INPUTS: all_test_epochs_df, train_epochs_dict, test_epochs_dict, _remerged_laps_dfs_dict\n",
    "# a_decoder_name: str='long_LR'\n",
    "# a_ctrlr = laps_pagination_controller_dict[a_decoder_name]\n",
    "\n",
    "for a_decoder_name, a_ctrlr in laps_pagination_controller_dict.items():\n",
    "    # Build Radon Transforms and add them:\n",
    "    train_test_split_epochs_data = TrainTestSplitPlotDataProvider.decoder_build_single_decoded_position_curves_data(all_test_epochs_df=all_test_epochs_df, train_epochs_dict=train_epochs_dict, test_epochs_dict=test_epochs_dict, remerged_laps_dfs_dict=_remerged_laps_dfs_dict, a_decoder_name=a_decoder_name)\n",
    "    if train_test_split_epochs_data is not None:\n",
    "        TrainTestSplitPlotDataProvider.add_data_to_pagination_controller(a_ctrlr, train_test_split_epochs_data, update_controller_on_apply=True)\n",
    "        # TrainTestSplitPlotDataProvider.remove_data_from_pagination_controller(a_pagination_controller=a_ctrlr, should_remove_params=True, update_controller_on_apply=True)\n",
    "\n",
    "laps_paginated_multi_decoder_decoded_epochs_window.refresh_current_page()\n",
    "\n",
    "# on_render_page_callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb93048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_paginated_multi_decoder_decoded_epochs_window.remove_data_overlays()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce176e84",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import pho_jointplot\n",
    "import seaborn as sns\n",
    "\n",
    "plot_key: str = 'err_cm'\n",
    "\n",
    "# Plot each list as a separate time series\n",
    "plt.figure(figsize=(10, 6))\n",
    "for key, value in train_decoded_measured_diff_df_dict.items():\n",
    "    # sns.lineplot(x=range(len(value)), y=value, label=key)\n",
    "    _out_line = sns.lineplot(data=value, x='t', y=plot_key, label=key)\n",
    "    _out_scatter = sns.scatterplot(data=value, x='t', y=plot_key) # no `, label=key` because we only want one entry in the legend\n",
    "\n",
    "plt.xlabel('lap_center_t (sec)')\n",
    "plt.ylabel('mean_error [cm]')\n",
    "plt.title('LAp Decoding Error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea64db14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10117f91",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "active_epochs_dict = {k:Epoch(ensure_dataframe(v.measured_decoded_position_comparion.decoded_measured_diff_df)) for k, v in test_decoder_results_dict.items()}\n",
    "active_epochs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea20e747",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "active_epochs_dict = {k:Epoch(ensure_dataframe(v)) for k, v in train_decoded_measured_diff_df_dict.items()}\n",
    "active_epochs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b61f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['pf_computation', 'pfdt_computation'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a65942",
   "metadata": {},
   "source": [
    "# <a id='toc16_'></a>[2024-05-29 - Trial-by-Trial Activity](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f3cd82",
   "metadata": {
    "tags": [
     "all",
     "required-validations-2024-10-07"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent\n",
    "from pyphoplacecellanalysis.Analysis.reliability import TrialByTrialActivity\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrialByTrialActivityResult\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.TrialByTrialActivityWindow import TrialByTrialActivityWindow\n",
    "from typing import Dict, List, Tuple, Optional, Callable, Union, Any\n",
    "from typing_extensions import TypeAlias\n",
    "from nptyping import NDArray\n",
    "import neuropy.utils.type_aliases as types\n",
    "\n",
    "## INPUTS: curr_active_pipeline, track_templates, global_epoch_name, (long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj)\n",
    "any_decoder_neuron_IDs: NDArray = deepcopy(track_templates.any_decoder_neuron_IDs)\n",
    "# long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "\n",
    "# ## Directional Trial-by-Trial Activity:\n",
    "if 'pf1D_dt' not in curr_active_pipeline.computation_results[global_epoch_name].computed_data:\n",
    "    # if `KeyError: 'pf1D_dt'` recompute\n",
    "    curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['pfdt_computation'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "\n",
    "active_pf_1D_dt: PfND_TimeDependent = deepcopy(curr_active_pipeline.computation_results[global_epoch_name].computed_data['pf1D_dt'])\n",
    "# active_pf_2D_dt: PfND_TimeDependent = deepcopy(curr_active_pipeline.computation_results[global_epoch_name].computed_data['pf2D_dt'])\n",
    "\n",
    "active_pf_dt: PfND_TimeDependent = active_pf_1D_dt\n",
    "# Limit only to the placefield aclus:\n",
    "active_pf_dt = active_pf_dt.get_by_id(ids=any_decoder_neuron_IDs)\n",
    "\n",
    "# active_pf_dt: PfND_TimeDependent = deepcopy(active_pf_2D_dt) # 2D\n",
    "long_LR_name, long_RL_name, short_LR_name, short_RL_name = track_templates.get_decoder_names()\n",
    "directional_lap_epochs_dict = dict(zip((long_LR_name, long_RL_name, short_LR_name, short_RL_name), (long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj)))\n",
    "directional_active_lap_pf_results_dicts: Dict[types.DecoderName, TrialByTrialActivity] = TrialByTrialActivity.directional_compute_trial_by_trial_correlation_matrix(active_pf_dt=active_pf_dt, directional_lap_epochs_dict=directional_lap_epochs_dict, included_neuron_IDs=any_decoder_neuron_IDs)\n",
    "\n",
    "## OUTPUTS: directional_active_lap_pf_results_dicts\n",
    "a_trial_by_trial_result: TrialByTrialActivityResult = TrialByTrialActivityResult(any_decoder_neuron_IDs=any_decoder_neuron_IDs,\n",
    "                                                                                active_pf_dt=active_pf_dt,\n",
    "                                                                                directional_lap_epochs_dict=directional_lap_epochs_dict,\n",
    "                                                                                directional_active_lap_pf_results_dicts=directional_active_lap_pf_results_dicts,\n",
    "                                                                                is_global=True)  # type: Tuple[Tuple[Dict[str, Any], Dict[str, Any]], Dict[str, BasePositionDecoder], Any]\n",
    "\n",
    "directional_lap_epochs_dict: Dict[str, Epoch] = directional_trial_by_trial_activity_result.directional_lap_epochs_dict\n",
    "stability_df, stability_dict = a_trial_by_trial_result.get_stability_df()\n",
    "# appearing_or_disappearing_aclus, appearing_stability_df, appearing_aclus, disappearing_stability_df, disappearing_aclus, (stable_both_aclus, stable_neither_aclus, stable_long_aclus, stable_short_aclus) = a_trial_by_trial_result.get_cell_stability_info(minimum_one_point_stability=0.6, zero_point_stability=0.1)\n",
    "_neuron_group_split_stability_dfs_tuple, _neuron_group_split_stability_aclus_tuple = a_trial_by_trial_result.get_cell_stability_info(minimum_one_point_stability=0.6, zero_point_stability=0.1)\n",
    "appearing_stability_df, disappearing_stability_df, appearing_or_disappearing_stability_df, stable_both_stability_df, stable_neither_stability_df, stable_long_stability_df, stable_short_stability_df = _neuron_group_split_stability_dfs_tuple\n",
    "appearing_aclus, disappearing_aclus, appearing_or_disappearing_aclus, stable_both_aclus, stable_neither_aclus, stable_long_aclus, stable_short_aclus = _neuron_group_split_stability_aclus_tuple\n",
    "override_active_neuron_IDs = deepcopy(appearing_or_disappearing_aclus)\n",
    "override_active_neuron_IDs\n",
    "\n",
    "# stability_df\n",
    "\n",
    "# a_trial_by_trial_result\n",
    "\n",
    "# Time-dependent\n",
    "long_pf1D_dt, short_pf1D_dt, global_pf1D_dt = long_results.pf1D_dt, short_results.pf1D_dt, global_results.pf1D_dt\n",
    "# long_pf2D_dt, short_pf2D_dt, global_pf2D_dt = long_results.pf2D_dt, short_results.pf2D_dt, global_results.pf2D_dt\n",
    "global_pf1D_dt: PfND_TimeDependent = global_results.pf1D_dt\n",
    "# global_pf2D_dt: PfND_TimeDependent = global_results.pf2D_dt\n",
    "_flat_z_scored_tuning_map_matrix, _flat_decoder_identity_arr = a_trial_by_trial_result.build_combined_decoded_epoch_z_scored_tuning_map_matrix() # .shape: (n_epochs, n_neurons, n_pos_bins) \n",
    "modified_directional_active_lap_pf_results_dicts: Dict[types.DecoderName, TrialByTrialActivity] = a_trial_by_trial_result.build_separated_nan_filled_decoded_epoch_z_scored_tuning_map_matrix()\n",
    "# _flat_z_scored_tuning_map_matrix\n",
    "\n",
    "\n",
    "## OUTPUTS: override_active_neuron_IDs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a0767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stability_df\n",
    "appearing_stability_df\n",
    "disappearing_stability_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a45bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['pf_computation', 'pfdt_computation'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a620bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.TrialByTrialActivityWindow import TrialByTrialActivityWindow\n",
    "\n",
    "directional_trial_by_trial_activity_result: TrialByTrialActivityResult = curr_active_pipeline.global_computation_results.computed_data.get('TrialByTrialActivity', None)\n",
    "assert directional_trial_by_trial_activity_result is not None\n",
    "\n",
    "any_decoder_neuron_IDs: NDArray = deepcopy(directional_trial_by_trial_activity_result.any_decoder_neuron_IDs)\n",
    "    \n",
    "## OUTPUTS: directional_trial_by_trial_activity_result, directional_active_lap_pf_results_dicts\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['pf_computation', 'pfdt_computation'], enabled_filter_names=[global_epoch_name], fail_on_exception=True, debug_print=False)\n",
    "\n",
    "# active_pf = deepcopy(curr_active_pipeline.computation_results[global_epoch_name].computed_data['pf2D_dt']) # PfND_TimeDependent\n",
    "\n",
    "# active_pf = deepcopy(curr_active_pipeline.computation_results[global_epoch_name].computed_data['pf2D'])\n",
    "active_pf = deepcopy(curr_active_pipeline.computation_results[global_epoch_name].computed_data['pf1D'])\n",
    "\n",
    "# active_pf = deepcopy(directional_trial_by_trial_activity_result.active_pf_dt) # IndexError: index 65 is out of bounds for axis 0 with size 65\n",
    "\n",
    "any_decoder_neuron_IDs: NDArray = deepcopy(directional_trial_by_trial_activity_result.any_decoder_neuron_IDs)\n",
    "override_active_neuron_IDs = deepcopy(any_decoder_neuron_IDs)\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['pf_computation', 'pfdt_computation'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "drop_below_threshold = 1e-6\n",
    "## Uses `plot_trial_to_trial_reliability_all_decoders_image_stack` to plot the reliability trial-by-trial indicators over time\n",
    "## INPUTS: a_pf2D_dt, z_scored_tuning_map_matrix\n",
    "# directional_active_lap_pf_results_dicts: Dict[types.DecoderName, TrialByTrialActivity] = deepcopy(directional_trial_by_trial_activity_result.directional_active_lap_pf_results_dicts)\n",
    "modified_directional_active_lap_pf_results_dicts: Dict[types.DecoderName, TrialByTrialActivity] = directional_trial_by_trial_activity_result.build_separated_nan_filled_decoded_epoch_z_scored_tuning_map_matrix()\n",
    "modified_directional_active_lap_pf_results_dicts = {k:v.sliced_by_neuron_id(included_neuron_ids=override_active_neuron_IDs) for k, v in modified_directional_active_lap_pf_results_dicts.items()}\n",
    "_a_trial_by_trial_window = TrialByTrialActivityWindow.plot_trial_to_trial_reliability_all_decoders_image_stack(directional_active_lap_pf_results_dicts=modified_directional_active_lap_pf_results_dicts,\n",
    "                                                                                                                active_one_step_decoder=deepcopy(active_pf), drop_below_threshold=drop_below_threshold,\n",
    "                                                                                                                override_active_neuron_IDs=override_active_neuron_IDs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc2e278",
   "metadata": {},
   "source": [
    "### <a id='toc16_1_1_'></a>[‚úÖ 2024-08-14-:üñºÔ∏è  Normal Matplotlib-based figure output for the `trial_by_trial_correlation_matrix.z_scored_tuning_map_matrix` to show the reliably of each place cell across laps](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957f022a",
   "metadata": {
    "tags": [
     "all",
     "required-validations-2024-10-07"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.plot_placefields import display_all_pf_2D_pyqtgraph_binned_image_rendering, pyqtplot_plot_image_array\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.TrialByTrialActivityWindow import TrialByTrialActivityWindow\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "\n",
    "## Uses `plot_trial_to_trial_reliability_all_decoders_image_stack` to plot the reliability trial-by-trial indicators over time\n",
    "# active_pf_dt = deepcopy(curr_active_pipeline.computation_results[global_epoch_name].computed_data['pf1D_dt']) # PfND_TimeDependent\n",
    "# active_pf_dt = a_pf2D_dt\n",
    "\n",
    "# active_pf_dt = deepcopy(global_pf1D_dt)\n",
    "# active_pf_dt = deepcopy(global_pf1D)\n",
    "active_pf_dt = deepcopy(curr_active_pipeline.computation_results[global_epoch_name].computed_data['pf2D'])\n",
    "np.sum(active_pf_dt.occupancy)\n",
    "\n",
    "drop_below_threshold = 0.0000001\n",
    "override_active_neuron_IDs = deepcopy(any_decoder_neuron_IDs)\n",
    "## INPUTS: a_pf2D_dt, z_scored_tuning_map_matrix\n",
    "# directional_active_lap_pf_results_dicts: Dict[types.DecoderName, TrialByTrialActivity] = deepcopy(a_trial_by_trial_result.directional_active_lap_pf_results_dicts)\n",
    "# app, parent_root_widget, root_render_widget, plot_array, img_item_array, other_components_array, plot_data_array, additional_img_items_dict, legend_layout = plot_trial_to_trial_reliability_all_decoders_image_stack(directional_active_lap_pf_results_dicts=directional_active_lap_pf_results_dicts, active_one_step_decoder=deepcopy(active_pf_dt), drop_below_threshold=drop_below_threshold)\n",
    "# _a_trial_by_trial_window = TrialByTrialActivityWindow.plot_trial_to_trial_reliability_all_decoders_image_stack(directional_active_lap_pf_results_dicts=directional_active_lap_pf_results_dicts, active_one_step_decoder=deepcopy(active_pf_dt), drop_below_threshold=drop_below_threshold,\n",
    "#                                                                                                                is_overlaid_heatmaps_mode=False,\n",
    "#                                                                                                                )\n",
    "\n",
    "modified_directional_active_lap_pf_results_dicts: Dict[types.DecoderName, TrialByTrialActivity] = a_trial_by_trial_result.build_separated_nan_filled_decoded_epoch_z_scored_tuning_map_matrix()\n",
    "modified_directional_active_lap_pf_results_dicts = {k:v.sliced_by_neuron_id(included_neuron_ids=override_active_neuron_IDs) for k, v in modified_directional_active_lap_pf_results_dicts.items()}\n",
    "# modified_directional_active_lap_pf_results_dicts['long_RL'] = deepcopy(modified_directional_active_lap_pf_results_dicts['long_LR'])\n",
    "_a_trial_by_trial_window: TrialByTrialActivityWindow = TrialByTrialActivityWindow.plot_trial_to_trial_reliability_all_decoders_image_stack(directional_active_lap_pf_results_dicts=modified_directional_active_lap_pf_results_dicts,\n",
    "                                                                                                                active_one_step_decoder=deepcopy(active_pf_dt), drop_below_threshold=drop_below_threshold,\n",
    "                                                                                                                override_active_neuron_IDs=override_active_neuron_IDs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7e4805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_pf_dt.plot_occupancy()\n",
    "active_pf1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2837d023",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_plot = _a_trial_by_trial_window.plots.position_plot # PlotItem\n",
    "pos_df: pd.DataFrame = deepcopy(active_pf_dt.position.to_dataframe())\n",
    "position_plot.clearPlots()\n",
    "position_plot.plot(x=pos_df['x'].to_numpy(), y=pos_df['t'].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b996a2",
   "metadata": {},
   "source": [
    "## <a id='toc16_2_'></a>[2024-10-14 - Add Track Shapes to the Trial-by-Trial figures](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654233df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import PlottingHelpers\n",
    "\n",
    "## get grid_bin_bounds\n",
    "loaded_track_limits = deepcopy(curr_active_pipeline.active_sess_config.loaded_track_limits)\n",
    "# loaded_track_limits\n",
    "\n",
    "\n",
    "\n",
    "# .x_midpoint\n",
    "# .pix2cm\n",
    "loaded_track_limits['long_xlim']\n",
    "loaded_track_limits['short_xlim']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ed4b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import LinearTrackInstance, LinearTrackDimensions, test_LinearTrackDimensions_2D_pyqtgraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65039374",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_array: List[pg.PlotItem] = _a_trial_by_trial_window.plots.plot_array\n",
    "plot_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f858108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get grid_bin_bounds\n",
    "loaded_track_limits = deepcopy(curr_active_pipeline.active_sess_config.loaded_track_limits)\n",
    "loaded_track_limits\n",
    "\n",
    "# .x_midpoint\n",
    "# .pix2cm\n",
    "loaded_track_limits['long_xlim']\n",
    "loaded_track_limits['short_xlim']\n",
    "\n",
    "grid_bin_bounds = [loaded_track_limits['long_xlim'], [0.0, 0.0]]\n",
    "grid_bin_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf55eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.geometry_helpers import point_tuple_mid_point\n",
    "\n",
    "long_track_instance, short_track_instance = LinearTrackInstance.init_tracks_from_session_config(a_sess_config=curr_active_pipeline.sess.config)\n",
    "# _out_temp = long_track_instance.plot_rects(plot_item=plot_array[0])\n",
    "\n",
    "long_track_dims: LinearTrackDimensions = deepcopy(long_track_instance.track_dimensions)\n",
    "short_track_dims: LinearTrackDimensions = deepcopy(short_track_instance.track_dimensions)\n",
    "\n",
    "\n",
    "# Find center from `grid_bin_bounds` using `point_tuple_mid_point`\n",
    "x_midpoint, y_midpoint = (point_tuple_mid_point(grid_bin_bounds[0]), point_tuple_mid_point(grid_bin_bounds[1])) # grid_bin_bounds_center_point: (145.43, 140.61)\n",
    "\n",
    "long_notable_x_positions, _long_notable_y_positions = long_track_dims._build_component_notable_positions(offset_point=(x_midpoint, y_midpoint))\n",
    "short_notable_x_positions, _short_notable_y_positions = short_track_dims._build_component_notable_positions(offset_point=(x_midpoint, y_midpoint))\n",
    "\n",
    "# Omit the midpoint\n",
    "long_notable_x_platform_positions = long_notable_x_positions[[0,1,3,4]] # [37.0774 59.0774 228.69 250.69]\n",
    "short_notable_x_platform_positions = short_notable_x_positions[[0,1,3,4]] # [72.0132 94.0132 193.754 215.754]\n",
    "\n",
    "long_notable_x_platform_positions\n",
    "short_notable_x_platform_positions\n",
    "# app, w, cw, (ax0, ax1), (long_track_dims, long_rect_items, long_rects), (short_track_dims, short_rect_items, short_rects) = test_LinearTrackDimensions_2D_pyqtgraph(long_track_dims=long_track_instance.track_dimensions,\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tshort_track_dims=short_track_instance.track_dimensions)\n",
    "\n",
    "\n",
    "_out_temp = short_track_dims.plot_rects(plot_item=plot_array[0], offset=[x_midpoint, 0])\n",
    "\n",
    "# _out_temp = long_track_dims.plot_rects(plot_item=plot_array[0], offset=[x_midpoint, 0])\n",
    "# _out_items = long_track_dims.plot_line_collections(plot_item=plot_array[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e7f58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out_temp\n",
    "new_pen = pg.mkPen({'color': \"#ffd9001A\", 'width': 2})\n",
    "new_brush = pg.mkBrush(\"#ffd90010\")\n",
    "new_rendering_properties_tuple = (new_pen, new_brush)\n",
    "new_pen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c257be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "combined_item, rect_items, rects = _out_temp\n",
    "# rect_items\n",
    "for i, ((x, y, w, h, pen, brush), an_item) in enumerate(zip(rects, rect_items)):\n",
    "    # rects\n",
    "    # pen.setColor(\"#ffd9001A\")\n",
    "    # brush.setColor(\"#ffd90010\")\n",
    "    print(f'item[{i}]: {an_item}')\n",
    "    # an_item.set\n",
    "    an_item.setPen(pg.mkPen({'color': \"#ffd9001A\", 'width': 2}))\n",
    "    an_item.setBrush(pg.mkBrush(\"#ffd90010\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b26cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for an_item in rect_items:\n",
    "    plot_array[0].removeItem(an_item)\n",
    "    # an_item.deleteLater()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d907a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'long_LR' not in _a_trial_by_trial_window.plots.additional_img_items_dict:\n",
    "    print(f'added \"long_LR\" to _a_trial_by_trial_window.plots.additional_img_items_dict')\n",
    "    _a_trial_by_trial_window.plots.additional_img_items_dict['long_LR'] = _a_trial_by_trial_window.plots.img_item_array\n",
    "    \n",
    "\n",
    "# _a_trial_by_trial_window.plots.additional_img_items_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39f7eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_decoder_name: str = 'short_LR'\n",
    "# _a_trial_by_trial_window.set_series_opacity(target_decoder_name='long_LR', target_opacity=1.0)\n",
    "# _a_trial_by_trial_window.restore_all_series_opacity()\n",
    "_a_trial_by_trial_window.restore_all_series_opacity(override_all_opacity=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43aee089",
   "metadata": {},
   "outputs": [],
   "source": [
    "_a_trial_by_trial_window.set_series_opacity(target_decoder_name='long_LR', target_opacity=1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ccdfd6",
   "metadata": {},
   "source": [
    "# <a id='toc17_'></a>[2024-06-07 - PhoDiba2023Paper figure generation](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aee7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import main_complete_figure_generations\n",
    "\n",
    "main_complete_figure_generations(curr_active_pipeline, save_figure=True, save_figures_only=True, enable_default_neptune_plots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb606db9",
   "metadata": {},
   "source": [
    "# <a id='toc18_'></a>[üî∑ 2024-07-02 - New epoch decoding and CSV export:](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4eb4c68",
   "metadata": {
    "tags": [
     "pho-run-2024",
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "\n",
    "if ('DirectionalDecodersEpochsEvaluations' in curr_active_pipeline.global_computation_results.computed_data) and (curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations'] is not None):\n",
    "    directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "    directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)\n",
    "\n",
    "    ## UNPACK HERE via direct property access:\n",
    "    pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "    ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "    laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "    print(f'{pos_bin_size = }, {ripple_decoding_time_bin_size = }, {laps_decoding_time_bin_size = }') # pos_bin_size = 3.8054171165052444, ripple_decoding_time_bin_size = 0.025, laps_decoding_time_bin_size = 0.2\n",
    "    decoder_laps_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict\n",
    "    decoder_ripple_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict\n",
    "    decoder_laps_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_df_dict\n",
    "    decoder_ripple_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_df_dict\n",
    "\n",
    "    # New items:\n",
    "    decoder_laps_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_extras_dict\n",
    "    decoder_ripple_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_extras_dict\n",
    "\n",
    "    # Weighted correlations:\n",
    "    laps_weighted_corr_merged_df = directional_decoders_epochs_decode_result.laps_weighted_corr_merged_df\n",
    "    ripple_weighted_corr_merged_df = directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "    decoder_laps_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_laps_weighted_corr_df_dict\n",
    "    decoder_ripple_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict\n",
    "\n",
    "    # Pearson's correlations:\n",
    "    laps_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.laps_simple_pf_pearson_merged_df\n",
    "    ripple_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992bc1db",
   "metadata": {
    "tags": [
     "pho-run-2024",
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_session_name: str = curr_active_pipeline.session_name # '2006-6-08_14-26-15'\n",
    "CURR_BATCH_OUTPUT_PREFIX: str = f\"{BATCH_DATE_TO_USE}-{curr_session_name}\"\n",
    "print(f'CURR_BATCH_OUTPUT_PREFIX: {CURR_BATCH_OUTPUT_PREFIX}')\n",
    "\n",
    "# active_context = curr_active_pipeline.get_session_context().adding_context_if_missing(custom_\n",
    "\n",
    "# session_name: str = curr_active_pipeline.session_name\n",
    "\n",
    "active_context = curr_active_pipeline.get_session_context()\n",
    "session_name: str = f\"{curr_active_pipeline.session_name}{custom_suffix}\" ## appending this here is a hack, but it makes the correct filename\n",
    "active_context = active_context.adding_context_if_missing(suffix=custom_suffix)\n",
    "session_ctxt_key:str = active_context.get_description(separator='|', subset_includelist=(IdentifyingContext._get_session_context_keys() + ['suffix']))\n",
    "\n",
    "earliest_delta_aligned_t_start, t_delta, latest_delta_aligned_t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "active_context\n",
    "session_ctxt_key\n",
    "# Shifts the absolute times to delta-relative values, as would be needed to draw on a 'delta_aligned_start_t' axis:\n",
    "delta_relative_t_start, delta_relative_t_delta, delta_relative_t_end = np.array([earliest_delta_aligned_t_start, t_delta, latest_delta_aligned_t_end]) - t_delta\n",
    "# decoder_user_selected_epoch_times_dict, any_good_selected_epoch_times = DecoderDecodedEpochsResult.load_user_selected_epoch_times(curr_active_pipeline)\n",
    "# any_good_selected_epoch_indicies = filtered_ripple_simple_pf_pearson_merged_df.epochs.matching_epoch_times_slice(any_good_selected_epoch_times)\n",
    "# df = filter_epochs_dfs_by_annotation_times(curr_active_pipeline, any_good_selected_epoch_times, ripple_decoding_time_bin_size=ripple_decoding_time_bin_size, filtered_ripple_simple_pf_pearson_merged_df, ripple_weighted_corr_merged_df)\n",
    "# df\n",
    "\n",
    "# collected_outputs_path = self.collected_outputs_path.resolve()\n",
    "\n",
    "collected_outputs_path = collected_outputs_path.resolve()\n",
    "\n",
    "## Export CSVs:\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "_output_csv_paths = directional_decoders_epochs_decode_result.export_csvs(parent_output_path=collected_outputs_path, active_context=active_context, session_name=curr_session_name, curr_session_t_delta=t_delta,\n",
    "                                                                        # user_annotation_selections={'ripple': any_good_selected_epoch_times},\n",
    "                                                                        # valid_epochs_selections={'ripple': filtered_valid_epoch_times},\n",
    "                                                                        )\n",
    "\n",
    "print(f'\\t\\tsuccessfully exported directional_decoders_epochs_decode_result to {collected_outputs_path}!')\n",
    "_output_csv_paths_info_str: str = '\\n'.join([f'{a_name}: \"{file_uri_from_path(a_path)}\"' for a_name, a_path in _output_csv_paths.items()])\n",
    "# print(f'\\t\\t\\tCSV Paths: {_output_csv_paths}\\n')\n",
    "print(f'\\t\\t\\tCSV Paths: {_output_csv_paths_info_str}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834fa269",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "def _update_ripple_df(a_ripple_df):\n",
    "    \"\"\" captures: session_name, t_start, t_delta, t_end, ripple_decoding_time_bin_size \"\"\"\n",
    "    if ('time_bin_size' not in a_ripple_df.columns) and (ripple_decoding_time_bin_size is not None):\n",
    "        ## add the column\n",
    "        a_ripple_df['time_bin_size'] = ripple_decoding_time_bin_size\n",
    "    # Add the maze_id to the active_filter_epochs so we can see how properties change as a function of which track the replay event occured on:\n",
    "    a_ripple_df = DecoderDecodedEpochsResult.add_session_df_columns(a_ripple_df, session_name=session_name, time_bin_size=None, t_start=t_start, curr_session_t_delta=t_delta, t_end=t_end, time_col='ripple_start_t')\n",
    "    return a_ripple_df\n",
    "\n",
    "directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df = _update_ripple_df(directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df)\n",
    "directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df = _update_ripple_df(directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df)\n",
    "    \n",
    "ripple_weighted_corr_merged_df = directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "ripple_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df\n",
    "\n",
    "## UPDATES: directional_decoders_epochs_decode_result\n",
    "## OUTPUTS: ripple_simple_pf_pearson_merged_df, ripple_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72763c5",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "ripple_simple_pf_pearson_merged_df\n",
    "ripple_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fe34dd",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "# directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict # vector for each decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea151325",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "## Plot: directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_pre_post_delta_scatter\n",
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import plot_histograms\n",
    "\n",
    "ripple_weighted_corr_merged_df = deepcopy(directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df)\n",
    "ripple_weighted_corr_merged_df\n",
    "\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "# You can use it like this:\n",
    "_out0: \"MatplotlibRenderPlots\" = plot_histograms(data_type='Laps', session_spec='All Sessions', data_results_df=all_sessions_laps_time_bin_df, time_bin_duration_str=\"75 ms\")\n",
    "_out1: \"MatplotlibRenderPlots\" = plot_histograms(data_type='Ripples', session_spec='All Sessions', data_results_df=all_sessions_ripple_time_bin_df, time_bin_duration_str=\"75 ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c440a69",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# histogram_bins = 'auto'\n",
    "histogram_bins: int = 25\n",
    "\n",
    "# ripple_weighted_corr_merged_df = ripple_weighted_corr_merged_df[['P_Short','delta_aligned_start_t', 'time_bin_size']]\n",
    "ripple_weighted_corr_merged_df = ripple_weighted_corr_merged_df[['P_Short','delta_aligned_start_t', 'time_bin_size']]\n",
    "new_ripple_fig, new_ripple_fig_context = plotly_pre_post_delta_scatter(data_results_df=ripple_weighted_corr_merged_df, out_scatter_fig=None, histogram_bins=histogram_bins,\n",
    "                                                                        px_scatter_kwargs=dict(title='Ripple'), histogram_variable_name='P_Short')\n",
    "\n",
    "# new_laps_fig = new_laps_fig.update_layout(fig_size_kwargs, \n",
    "#     xaxis_title=\"X Axis Title\",\n",
    "#     yaxis_title=\"Y Axis Title\",\n",
    "#     legend_title=\"Legend Title\",\n",
    "#     font=dict(\n",
    "#         family=\"Courier New, monospace\",\n",
    "#         size=18,\n",
    "#         color=\"RebeccaPurple\"\n",
    "#     ),\n",
    "# )\n",
    "# Update x-axis labels\n",
    "# new_laps_fig.update_xaxes(title_text=\"Num Time Bins\", row=1, col=1)\n",
    "# new_laps_fig.update_xaxes(title_text=\"Delta-aligned Event Time (seconds)\", row=1, col=2)\n",
    "# new_laps_fig.update_xaxes(title_text=\"Num Time Bins\", row=1, col=3)\n",
    "\n",
    "\n",
    "_extras_output_dict = {}\n",
    "_extras_output_dict[\"y_mid_line\"] = new_ripple_fig.add_hline(y=0.5, line=dict(color=\"rgba(0.8,0.8,0.8,.75)\", width=2), row='all', col='all')\n",
    "\n",
    "new_ripple_fig\n",
    "\n",
    "\n",
    "\n",
    "# # Update layout to add a title to the legend\n",
    "# new_fig_ripples.update_layout(\n",
    "#     legend_title_text='Is User Selected'  # Add a title to the legend\n",
    "# )\n",
    "\n",
    "# fig_to_clipboard(new_fig_ripples, **fig_size_kwargs)\n",
    "\n",
    "# new_laps_fig_context: IdentifyingContext = new_laps_fig_context.adding_context_if_missing(epoch='withNewKamranExportedReplays', num_sessions=num_sessions, plot_type='scatter+hist', comparison='pre-post-delta', variable_name=variable_name)\n",
    "# figure_out_paths = save_plotly(a_fig=new_laps_fig, a_fig_context=new_laps_fig_context)\n",
    "# new_laps_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a2236f",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# curr_active_pipeline.__getstate__()\n",
    "curr_active_pipeline.sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37c774c",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# curr_active_pipeline.__getstate__()\n",
    "\n",
    "# _temp_pipeline_dict = get_dict_subset(curr_active_pipeline.__getstate__(), dummy_pipeline_attrs_names_list)\n",
    "_temp_pipeline_dict = get_dict_subset(curr_active_pipeline.stage.__getstate__(), dummy_pipeline_attrs_names_list) | {'sess': deepcopy(curr_active_pipeline.sess)}\n",
    "_temp_pipeline_dict\n",
    "\n",
    "print_keys_if_possible('curr_active_pipeline.stage.__getstate__()', _temp_pipeline_dict, max_depth=2)\n",
    "\n",
    "a_dummy_pipeline: SimpleCurrActivePipelineComputationDummy = SimpleCurrActivePipelineComputationDummy(**_temp_pipeline_dict)\n",
    "a_dummy_pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114e56a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dummy_pipeline = SimpleCurrActivePipelineComputationDummy(**curr_active_pipeline.__getstate__())\n",
    "a_dummy_pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1790cfac",
   "metadata": {},
   "source": [
    "# <a id='toc19_'></a>[PhoJonathanPlotHelpers](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223fa610",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.neuron_identities import NeuronIdentityDataframeAccessor\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import BatchPhoJonathanFiguresHelper\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import LongShortTrackComparingDisplayFunctions, PhoJonathanPlotHelpers\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d35d5ad",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "\n",
    "graphics_output_dict = curr_active_pipeline.display('_display_batch_pho_jonathan_replay_firing_rate_comparison', active_identifying_session_ctx) # MatplotlibRenderPlots\n",
    "# graphics_output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d4fd56",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "debug_print = True\n",
    "## Get global 'jonathan_firing_rate_analysis' results:\n",
    "curr_jonathan_firing_rate_analysis = curr_active_pipeline.global_computation_results.computed_data['jonathan_firing_rate_analysis']\n",
    "neuron_replay_stats_df, rdf, aclu_to_idx, irdf = curr_jonathan_firing_rate_analysis.neuron_replay_stats_df, curr_jonathan_firing_rate_analysis.rdf.rdf, curr_jonathan_firing_rate_analysis.rdf.aclu_to_idx, curr_jonathan_firing_rate_analysis.irdf.irdf\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Batch Output of Figures                                                                                              #\n",
    "# ==================================================================================================================== #\n",
    "## üó®Ô∏èüü¢ 2022-11-05 - Pho-Jonathan Batch Outputs of Firing Rate Figures\n",
    "# %matplotlib qt\n",
    "short_only_df = neuron_replay_stats_df[neuron_replay_stats_df.track_membership == SplitPartitionMembership.RIGHT_ONLY]\n",
    "short_only_aclus = short_only_df.index.values.tolist()\n",
    "long_only_df = neuron_replay_stats_df[neuron_replay_stats_df.track_membership == SplitPartitionMembership.LEFT_ONLY]\n",
    "long_only_aclus = long_only_df.index.values.tolist()\n",
    "shared_df = neuron_replay_stats_df[neuron_replay_stats_df.track_membership == SplitPartitionMembership.SHARED]\n",
    "shared_aclus = shared_df.index.values.tolist()\n",
    "if debug_print:\n",
    "    print(f'shared_aclus: {shared_aclus}')\n",
    "    print(f'long_only_aclus: {long_only_aclus}')\n",
    "    print(f'short_only_aclus: {short_only_aclus}')\n",
    "\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'    \n",
    "## MODE: this mode creates a special folder to contain the outputs for this session.\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Output Figures to File                                                                                               #\n",
    "# ==================================================================================================================== #\n",
    "active_out_figures_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, n_max_page_rows=10, included_unit_neuron_IDs=[49], disable_top_row=True)\n",
    "\n",
    "# /home/halechr/repos/Spike3D/EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2024-09-24/kdiba/vvp01/two/2006-4-17_12-52-15/BatchPhoJonathanReplayFRC_shared_4of4_(39,41,42).png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0302d9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_only_aclus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d518bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_print = True\n",
    "## Get global 'jonathan_firing_rate_analysis' results:\n",
    "curr_jonathan_firing_rate_analysis = curr_active_pipeline.global_computation_results.computed_data['jonathan_firing_rate_analysis']\n",
    "neuron_replay_stats_df, rdf, aclu_to_idx, irdf = curr_jonathan_firing_rate_analysis.neuron_replay_stats_df, curr_jonathan_firing_rate_analysis.rdf.rdf, curr_jonathan_firing_rate_analysis.rdf.aclu_to_idx, curr_jonathan_firing_rate_analysis.irdf.irdf\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Batch Output of Figures                                                                                              #\n",
    "# ==================================================================================================================== #\n",
    "## üó®Ô∏èüü¢ 2022-11-05 - Pho-Jonathan Batch Outputs of Firing Rate Figures\n",
    "# %matplotlib qt\n",
    "short_only_df = neuron_replay_stats_df[neuron_replay_stats_df.track_membership == SplitPartitionMembership.RIGHT_ONLY] \n",
    "short_only_aclus = short_only_df.index.values.tolist()\n",
    "long_only_df = neuron_replay_stats_df[neuron_replay_stats_df.track_membership == SplitPartitionMembership.LEFT_ONLY]\n",
    "long_only_aclus = long_only_df.index.values.tolist()\n",
    "shared_df = neuron_replay_stats_df[neuron_replay_stats_df.track_membership == SplitPartitionMembership.SHARED]\n",
    "shared_aclus = shared_df.index.values.tolist()\n",
    "if debug_print:\n",
    "    print(f'shared_aclus: {shared_aclus}')\n",
    "    print(f'long_only_aclus: {long_only_aclus}')\n",
    "    print(f'short_only_aclus: {short_only_aclus}')\n",
    "\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'    \n",
    "## MODE: this mode creates a special folder to contain the outputs for this session.\n",
    "\n",
    "active_out_figures_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, n_max_page_rows=10, included_unit_neuron_IDs=[49], disable_top_row=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757bc009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2113cbbf",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "jonathan_firing_rate_analysis_result = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis\n",
    "neuron_replay_stats_df, short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset = jonathan_firing_rate_analysis_result.get_cell_track_partitions(frs_index_inclusion_magnitude=0.2)\n",
    "## all cells:\n",
    "# fig_1c_figures_all_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, included_unit_neuron_IDs=None, n_max_page_rows=20, write_vector_format=False, write_png=True, show_only_refined_cells=False, disable_top_row=False)\n",
    "\n",
    "any_decoder_neuron_IDs = deepcopy(track_templates.any_decoder_neuron_IDs)\n",
    "fig_1c_figures_all_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, included_unit_neuron_IDs=any_decoder_neuron_IDs, n_max_page_rows=20, write_vector_format=False, write_png=True, show_only_refined_cells=False, disable_top_row=False)\n",
    "# fig_1c_figures_all_dict\n",
    "\n",
    "## find the output figures from the `curr_active_pipeline.registered_output_files`\n",
    "_found_contexts_dict: Dict[IdentifyingContext, Path] = {}\n",
    "for a_figure_path, an_output_dict in curr_active_pipeline.registered_output_files.items():\n",
    "    a_ctxt = an_output_dict['context']\n",
    "    _found_contexts_dict[a_ctxt] = a_figure_path\n",
    "\n",
    "\n",
    "relevant_figures_dict: Dict[IdentifyingContext, Path] = IdentifyingContext.matching(_found_contexts_dict, criteria={'display_fn_name': 'BatchPhoJonathanReplayFRC'})\n",
    "relevant_figures_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59b3270",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "fig_1c_figures_all_dict\n",
    "\n",
    "# print_keys_if_possible('registered_output_files', curr_active_pipeline.registered_output_files, max_depth=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc90f781",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "{k:active_out_figures_dict[k] for k in relevant_figures_dict.keys()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410ba646",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import BatchPhoJonathanFiguresHelper\n",
    "\n",
    "# PhoJonathan Results:\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "jonathan_firing_rate_analysis_result = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis\n",
    "neuron_replay_stats_df, short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset = jonathan_firing_rate_analysis_result.get_cell_track_partitions(frs_index_inclusion_magnitude=0.2)\n",
    "## all cells:\n",
    "fig_1c_figures_all_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, included_unit_neuron_IDs=LpC_aclus, n_max_page_rows=20, write_vector_format=False, write_png=False, show_only_refined_cells=False, disable_top_row=False, split_by_short_long_shared=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eac284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_spikes_df\n",
    "global_results.sess.spikes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1236e3b",
   "metadata": {},
   "source": [
    "# <a id='toc20_'></a>[#TODO 2025-03-04 17:17: - [ ] Documentation for all `DirectionalPlacefieldGlobalComputationFunction.py` classes](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad6e97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Classes ____________________________________________________________________________________________________ #\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BasePositionDecoder\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import SingleEpochDecodedResult\n",
    "\n",
    "\n",
    "# Specialty Classes __________________________________________________________________________________________________ #\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalLapsResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalDecodersContinuouslyDecodedResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e80f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3cce23e",
   "metadata": {},
   "source": [
    "# <a id='toc21_'></a>[‚úÖ `batch_user_completion_helpers` Batch Computation Testing](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a098a16",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_1_'></a>[Call `compute_and_export_session_trial_by_trial_performance_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd8d05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_session_trial_by_trial_performance_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "return_full_decoding_results: bool = True\n",
    "save_hdf: bool = True\n",
    "save_csvs:bool = True\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "additional_session_context = None\n",
    "try:\n",
    "    if custom_suffix is not None:\n",
    "        additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "        print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "except NameError as err:\n",
    "    additional_session_context = None\n",
    "    print(f'NO CUSTOM SUFFIX.')    \n",
    "    \n",
    "active_laps_decoding_time_bin_size: float = 0.25\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_session_trial_by_trial_performance_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict, active_laps_decoding_time_bin_size=active_laps_decoding_time_bin_size,\n",
    "                                                # # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None)\n",
    "                                                )\n",
    "\n",
    "\n",
    "callback_outputs = _across_session_results_extended_dict['compute_and_export_session_trial_by_trial_performance_completion_function']\n",
    "a_trial_by_trial_result = callback_outputs['a_trial_by_trial_result']\n",
    "subset_neuron_IDs_dict = callback_outputs['subset_neuron_IDs_dict']\n",
    "subset_decode_results_dict = callback_outputs['subset_decode_results_dict']\n",
    "subset_decode_results_track_id_correct_performance_dict = callback_outputs['subset_decode_results_track_id_correct_performance_dict']\n",
    "subset_neuron_IDs_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ecbe84",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_2_'></a>[Call `export_rank_order_results_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22800b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import export_rank_order_results_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "# _across_session_results_extended_dict = {}\n",
    "\n",
    "# additional_session_context = None\n",
    "# try:\n",
    "#     if custom_suffix is not None:\n",
    "#         additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "#         print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "# except NameError as err:\n",
    "#     additional_session_context = None\n",
    "#     print(f'NO CUSTOM SUFFIX.')    \n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | export_rank_order_results_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                # # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None)\n",
    "                                                should_save_pkl=False, should_save_CSV=True,\n",
    "                                                )\n",
    "\n",
    "\n",
    "callback_outputs = _across_session_results_extended_dict['export_rank_order_results_completion_function']\n",
    "merged_complete_ripple_epoch_stats_df_output_path = callback_outputs['merged_complete_ripple_epoch_stats_df_output_path']\n",
    "minimum_inclusion_fr_Hz = callback_outputs['minimum_inclusion_fr_Hz']\n",
    "included_qclu_values = callback_outputs['included_qclu_values']\n",
    "print(f'merged_complete_ripple_epoch_stats_df_output_path: {merged_complete_ripple_epoch_stats_df_output_path}') # \"2024-11-15_Lab-2006-6-09_1-22-43_merged_complete_epoch_stats_df.csv\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34757ebd",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_3_'></a>[Call `compute_and_export_session_wcorr_shuffles_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf5cc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_session_wcorr_shuffles_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "# additional_session_context = None\n",
    "# try:\n",
    "#     if custom_suffix is not None:\n",
    "#         additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "#         print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "# except NameError as err:\n",
    "#     additional_session_context = None\n",
    "#     print(f'NO CUSTOM SUFFIX.')    \n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_session_wcorr_shuffles_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                # # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None)\n",
    "                                                )\n",
    "\n",
    "\n",
    "callback_outputs = _across_session_results_extended_dict['compute_and_export_session_wcorr_shuffles_completion_function']\n",
    "wcorr_shuffles_data_output_filepath = callback_outputs['wcorr_shuffles_data_output_filepath']\n",
    "standalone_MAT_filepath = callback_outputs['standalone_MAT_filepath']\n",
    "ripple_WCorrShuffle_df_export_CSV_path = callback_outputs['ripple_WCorrShuffle_df_export_CSV_path']\n",
    "print(f'wcorr_shuffles_data_output_filepath: {wcorr_shuffles_data_output_filepath}') # \"2024-11-15_Lab-2006-6-09_1-22-43_merged_complete_epoch_stats_df.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5693589d",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_4_'></a>[Call `compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fd5080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _subfn_compute_complete_df_metrics\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "try:\n",
    "    if _across_session_results_extended_dict is not None:\n",
    "        pass\n",
    "    else:\n",
    "        _across_session_results_extended_dict = {}\n",
    "except NameError as err:\n",
    "    _across_session_results_extended_dict = {}\n",
    "    \n",
    "additional_session_context = None\n",
    "try:\n",
    "    if custom_suffix is not None:\n",
    "        additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "        print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "except NameError as err:\n",
    "    additional_session_context = None\n",
    "    print(f'NO CUSTOM SUFFIX.')    \n",
    "\n",
    "# ripple_decoding_time_bin_size_override = 0.058\n",
    "ripple_decoding_time_bin_size_override = 0.025\n",
    "needs_recompute_heuristics = True\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                ripple_decoding_time_bin_size_override=ripple_decoding_time_bin_size_override,\n",
    "                                                laps_decoding_time_bin_size_override=None,\n",
    "                                                needs_recompute_heuristics=needs_recompute_heuristics, allow_append_to_session_h5_file=False, save_hdf=True, force_recompute_all_decoding=True, \n",
    "                                                )\n",
    "\n",
    "callback_outputs = _across_session_results_extended_dict['compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function']\n",
    "ripple_decoding_time_bin_size_override = callback_outputs['ripple_decoding_time_bin_size_override']\n",
    "print(f'ripple_decoding_time_bin_size_override: {ripple_decoding_time_bin_size_override}')\n",
    "output_csv_paths = callback_outputs['output_csv_paths']\n",
    "print(f'output_csv_paths: {output_csv_paths}')\n",
    "output_hdf_paths = callback_outputs['output_hdf_paths']\n",
    "print(f'output_hdf_paths: {output_hdf_paths}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c82f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benedict import benedict\n",
    "\n",
    "_across_session_results_extended_dict = benedict(_across_session_results_extended_dict)\n",
    "out_ripple_all_scores_merged_df_csv = Path(_across_session_results_extended_dict['compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function.output_csv_paths.ripple_all_scores_merged_df']).resolve()\n",
    "Assert.path_exists(out_ripple_all_scores_merged_df_csv)\n",
    "\n",
    "out_ripple_all_scores_merged_df_csv.parent\n",
    "'C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2025-03-08_Apogee-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 8, 9]-frateThresh_5.0-(ripple_all_scores_merged_df)_tbin-0.025.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286f1cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_across_session_results_extended_dict['compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8daa277",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_ripple_all_scores_merged_hdf5_files = [Path(v).resolve() for v in _across_session_results_extended_dict['compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function.output_hdf_paths']]\n",
    "Assert.path_exists(out_ripple_all_scores_merged_hdf5_files[0])\n",
    "print(f'out_ripple_all_scores_merged_hdf5_files[0]: \"{out_ripple_all_scores_merged_hdf5_files[0].as_posix()}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101d7d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_path = '/home/halechr/FastData/collected_outputs/2024-11-22_Lab-kdiba_gor01_one_2006-6-12_15-55-31__withNormalComputedReplays-qclu_[1, 2]-frateThresh_5.0-(ripple_all_scores_merged_df)_tbin-0.025.csv'\n",
    "csv_path = '/home/halechr/FastData/collected_outputs/2024-11-22_Lab-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0-(ripple_all_scores_merged_df)_tbin-0.016.csv'\n",
    "test_df = pd.read_csv(csv_path)\n",
    "test_df\n",
    "\n",
    "\n",
    "test_df[np.logical_not(test_df['short_best_jump'].isnull())]['short_best_jump']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121efeb3",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_5_'></a>[Call `perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5732d32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _subfn_compute_complete_df_metrics\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "return_full_decoding_results: bool = True\n",
    "save_hdf: bool = False\n",
    "save_csvs:bool = False\n",
    "# _across_session_results_extended_dict = {}\n",
    "\n",
    "try:\n",
    "    if _across_session_results_extended_dict is not None:\n",
    "        pass\n",
    "    else:\n",
    "        _across_session_results_extended_dict = {}\n",
    "except NameError as err:\n",
    "    _across_session_results_extended_dict = {}\n",
    "    \n",
    "additional_session_context = None\n",
    "try:\n",
    "    if custom_suffix is not None:\n",
    "        additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "        print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "except NameError as err:\n",
    "    additional_session_context = None\n",
    "    print(f'NO CUSTOM SUFFIX.')    \n",
    "\n",
    "# %pdb on\n",
    "## Combine the output of `perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function` into two dataframes for the laps, one per-epoch and one per-time-bin\n",
    "# desired_shared_decoding_time_bin_sizes = np.linspace(start=0.030, stop=0.5, num=10)\n",
    "# desired_shared_decoding_time_bin_sizes = np.linspace(start=0.005, stop=0.03, num=10)\n",
    "# _across_session_results_extended_dict = _across_session_results_extended_dict | perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function(a_dummy, None,\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\tcurr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\tacross_session_results_extended_dict=_across_session_results_extended_dict, save_hdf=save_hdf, return_full_decoding_results=return_full_decoding_results,\n",
    "#                                                 desired_shared_decoding_time_bin_sizes=desired_shared_decoding_time_bin_sizes,\n",
    "#                                                 )\n",
    "\n",
    "\n",
    "# desired_laps_decoding_time_bin_size = [None] # doesn't work\n",
    "# desired_laps_decoding_time_bin_size = [1.5] # large so it doesn't take long\n",
    "# desired_ripple_decoding_time_bin_size = [0.010, 0.020]\n",
    "# desired_ripple_decoding_time_bin_size = [0.010, 0.020, 0.025]\n",
    "\n",
    "# desired_shared_decoding_time_bin_sizes = np.array([0.025, 0.030, 0.044, 0.050, 0.058, 0.072, 0.086, 0.100])\n",
    "# desired_shared_decoding_time_bin_sizes = np.array([0.025, 0.030, 0.044, 0.050, 0.058,])\n",
    "# desired_shared_decoding_time_bin_sizes = np.array([0.010, 0.025, 0.058,])\n",
    "desired_shared_decoding_time_bin_sizes = np.array([0.025, 0.050,])\n",
    "# desired_shared_decoding_time_bin_sizes = np.array([0.058,])\n",
    "# custom_all_param_sweep_options, param_sweep_option_n_values = parameter_sweeps(desired_laps_decoding_time_bin_size=desired_laps_decoding_time_bin_size,\n",
    "#                                                                                 desired_ripple_decoding_time_bin_size=desired_ripple_decoding_time_bin_size,\n",
    "#                                                                         use_single_time_bin_per_epoch=[False],\n",
    "#                                                                         minimum_event_duration=[desired_ripple_decoding_time_bin_size[-1]])\n",
    "\n",
    "# Shared time bin sizes\n",
    "custom_all_param_sweep_options, param_sweep_option_n_values = parameter_sweeps(desired_shared_decoding_time_bin_size=desired_shared_decoding_time_bin_sizes, use_single_time_bin_per_epoch=[False], minimum_event_duration=[desired_shared_decoding_time_bin_sizes[-1]]) # with Ripples\n",
    "\n",
    "\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict, save_hdf=save_hdf, save_csvs=save_csvs, return_full_decoding_results=return_full_decoding_results,\n",
    "                                                # desired_shared_decoding_time_bin_sizes = np.linspace(start=0.030, stop=0.5, num=4),\n",
    "                                                custom_all_param_sweep_options=custom_all_param_sweep_options, # directly provide the parameter sweeps\n",
    "                                                # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None)\n",
    "                                                additional_session_context = None,\n",
    "                                                )\n",
    "\n",
    "\n",
    "if return_full_decoding_results:\n",
    "    # with `return_full_decoding_results == True`\n",
    "    out_path, output_laps_decoding_accuracy_results_df, output_extracted_result_tuples, combined_multi_timebin_outputs_tuple, output_full_directional_merged_decoders_result, output_directional_decoders_epochs_decode_results_dict, output_saved_individual_sweep_files_dict = _across_session_results_extended_dict['perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function']\n",
    "    # validate the result:\n",
    "    {k:v.all_directional_laps_filter_epochs_decoder_result.decoding_time_bin_size for k,v in output_full_directional_merged_decoders_result.items()}\n",
    "    # assert np.all([np.isclose(dict(k)['desired_shared_decoding_time_bin_size'], v.all_directional_laps_filter_epochs_decoder_result.decoding_time_bin_size) for k,v in output_full_directional_merged_decoders_result.items()]), f\"the desired time_bin_size in the parameters should match the one used that will appear in the decoded result\"\n",
    "\n",
    "else:\n",
    "    # with `return_full_decoding_results == False`\n",
    "    out_path, output_laps_decoding_accuracy_results_df, output_extracted_result_tuples, combined_multi_timebin_outputs_tuple, output_saved_individual_sweep_files_dict = _across_session_results_extended_dict['perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function']\n",
    "    output_full_directional_merged_decoders_result = None\n",
    "\n",
    "\n",
    "(several_time_bin_sizes_laps_df, laps_out_path, several_time_bin_sizes_time_bin_laps_df, laps_time_bin_marginals_out_path), (several_time_bin_sizes_ripple_df, ripple_out_path, several_time_bin_sizes_time_bin_ripple_df, ripple_time_bin_marginals_out_path) = combined_multi_timebin_outputs_tuple\n",
    "\n",
    "#  exported files: {'laps_out_path': WindowsPath('K:/scratch/collected_outputs/2024-09-27-kdiba_gor01_two_2006-6-07_16-40-19_None-(laps_marginals_df).csv'), 'laps_time_bin_marginals_out_path': WindowsPath('K:/scratch/collected_outputs/2024-09-27-kdiba_gor01_two_2006-6-07_16-40-19_None-(laps_time_bin_marginals_df).csv'), 'ripple_out_path': WindowsPath('K:/scratch/collected_outputs/2024-09-27-kdiba_gor01_two_2006-6-07_16-40-19_None-(ripple_marginals_df).csv'), 'ripple_time_bin_marginals_out_path': WindowsPath('K:/scratch/collected_outputs/2024-09-27-kdiba_gor01_two_2006-6-07_16-40-19_None-(ripple_time_bin_marginals_df).csv')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fc9d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.get_all_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc64a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_saved_individual_sweep_files_dict\n",
    "# combined_multi_timebin_outputs_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcd8258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import DisplaySpecifyingIdentifyingContext, CollisionOutcome\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Computation import PipelineWithComputedPipelineStageMixin\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Computation import session_context_filename_formatting_fn\n",
    "from pyphocorehelpers.print_helpers import get_now_day_str, get_now_rounded_time_str\n",
    "\n",
    "curr_active_pipeline.session_name\n",
    "# complete_session_context, (curr_session_context,  additional_session_context) = curr_active_pipeline.get_complete_session_context(parts_separator='_')\n",
    "\n",
    "# complete_session_context.get_description(separator='|') # 'kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays_qclu_[1, 2, 4, 6, 7, 9]_frateThresh_5.0'\n",
    "# complete_session_context.get_specific_purpose_description(specific_purpose='filename_formatting') # 'kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays_qclu_[1, 2, 4, 6, 7, 9]_frateThresh_5.0'\n",
    "# curr_active_pipeline.get_complete_session_identifier_string(parts_separator='_', sub_parts_separator='|') # 'kdiba-gor01-one-2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0'\n",
    "curr_active_pipeline.get_complete_session_identifier_string(parts_separator='_', custom_parameter_keyvalue_parts_separator='-', session_identity_parts_separator='_')\n",
    "\n",
    "# \"kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_1.0\"\n",
    "\n",
    "out_path, out_filename, out_basename = curr_active_pipeline.build_complete_session_identifier_filename_string(output_date_str=None, data_identifier_str=\"(ripple_WCorrShuffle_df)\", parent_output_path=None, out_extension='.csv', extra_parts=None, ensure_no_duplicate_parts=False)\n",
    "out_filename # '2024-11-19_0148AM-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0-(ripple_WCorrShuffle_df).csv'\n",
    "# out_path, out_filename, out_basename = curr_active_pipeline.build_complete_session_identifier_filename_string(output_date_str=get_now_rounded_time_str(), data_identifier_str=\"(ripple_WCorrShuffle_df)\", parent_output_path=None, out_extension='.csv', extra_parts=None, ensure_no_duplicate_parts=False)\n",
    "# out_path, out_filename, out_basename = curr_active_pipeline.build_complete_session_identifier_filename_string(data_identifier_str=\"(ripple_WCorrShuffle_df)\", parent_output_path=None, out_extension='.csv', extra_parts=None, ensure_no_duplicate_parts=True)\n",
    "out_path, out_filename, out_basename = curr_active_pipeline.build_complete_session_identifier_filename_string(data_identifier_str=\"(ripple_WCorrShuffle_df)\", parent_output_path=None, out_extension='.csv', suffix_string='_tbin-0.025')\n",
    "out_filename  # '2024-11-19_0148AM-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0-(ripple_WCorrShuffle_df)_tbin-0.025.csv'\n",
    "\n",
    "# \"2024-11-18_1020PM-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_1.0-(ripple_WCorrShuffle_df)_tbin-0.025.csv\"\n",
    "# \"2024-11-19_0125AM-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0-(ripple_WCorrShuffle_df).csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8b1579",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_session_context.get_raw_identifying_context()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a21cabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_session_context\n",
    "\n",
    "# ['format_name', 'animal', 'exper_name', 'session_name']\n",
    "curr_session_context.get_description()\n",
    "curr_session_context.get_specific_purpose_description(specific_purpose='filename_formatting')\n",
    "\n",
    "curr_session_context.to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82ac92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_test_complete_session_context: DisplaySpecifyingIdentifyingContext = DisplaySpecifyingIdentifyingContext.init_from_context(a_context=curr_active_pipeline.get_session_context(), \n",
    "        specific_purpose_display_dict={'filename_formatting': session_context_filename_formatting_fn,},\n",
    "        #  display_dict={'epochs_source': lambda k, v: to_filename_conversion_dict[v],\n",
    "        #         'included_qclu_values': lambda k, v: f\"qclu_{v}\",\n",
    "        #         'minimum_inclusion_fr_Hz': lambda k, v: f\"frateThresh_{v:.1f}\",\n",
    "        # },\n",
    "    )\n",
    "_test_complete_session_context\n",
    "_test_complete_session_context.get_description()\n",
    "_test_complete_session_context.get_specific_purpose_description(specific_purpose='filename_formatting')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ef185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "additional_session_context.get_description()\n",
    "additional_session_context.get_specific_purpose_description(specific_purpose='filename_formatting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c4da3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _test_complete_session_context: DisplaySpecifyingIdentifyingContext = curr_session_context.adding_context(collision_prefix='_additional', strategy=CollisionOutcome.FAIL_IF_DIFFERENT, **additional_session_context.to_dict())\n",
    "_test_complete_session_context: DisplaySpecifyingIdentifyingContext = curr_session_context.adding_context(collision_prefix='_additional', strategy=CollisionOutcome.FAIL_IF_DIFFERENT, **additional_session_context.get_raw_identifying_context().to_dict())\n",
    "\n",
    "\n",
    "_test_complete_session_context\n",
    "_test_complete_session_context.get_description()\n",
    "_test_complete_session_context.get_specific_purpose_description(specific_purpose='filename_formatting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5026a5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.get_complete_session_identifier_string(parts_separator='_')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14a1e08",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_6_'></a>[Call `compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb60e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import DisplaySpecifyingIdentifyingContext, IdentifyingContext\n",
    "# from pyphoplacecellanalysis.General.Pipeline.Stages.Computation import PipelineWithComputedPipelineStageMixin\n",
    "\n",
    "complete_session_context, (session_context, additional_session_context) = curr_active_pipeline.get_complete_session_context()\n",
    "session_context\n",
    "additional_session_context\n",
    "complete_session_context\n",
    "\n",
    "\n",
    "session_context.get_description()\n",
    "additional_session_context.get_description()\n",
    "complete_session_context.get_description()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0d9a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_session_context.get_specific_purpose_description(specific_purpose='filename_formatting') # additional_session_context.get_specific_purpose_description(specific_purpose='filename_formatting')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76164cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_session_context.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e58214",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_session_context.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c303453",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_session_context.get_specific_purpose_description(specific_purpose='filename_formatting') # '-_withNormalComputedReplays-frateThresh_5.0-qclu_[1, 2, 4, 6, 7, 9]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9185d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_session_context.get_description() # 'kdiba_gor01_two_2006-6-12_16-53-46__withNormalComputedReplays_qclu_[1, 2, 4, 6, 7, 9]_frateThresh_5.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a789e08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_context = complete_session_context\n",
    "active_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc10c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "active_context.get_description()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497465d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "# return_full_decoding_results: bool = True\n",
    "# save_hdf: bool = True\n",
    "# save_csvs:bool = True\n",
    "\n",
    "try:\n",
    "    _across_session_results_extended_dict\n",
    "except NameError as e:\n",
    "    _across_session_results_extended_dict = {} # initialize\n",
    "\n",
    "additional_session_context = None\n",
    "try:\n",
    "    if custom_suffix is not None:\n",
    "        additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "        print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "except NameError as err:\n",
    "    additional_session_context = None\n",
    "    print(f'NO CUSTOM SUFFIX.')    \n",
    "    \n",
    "rank_order_results = curr_active_pipeline.global_computation_results.computed_data.get('RankOrder', None)\n",
    "if rank_order_results is not None:\n",
    "    minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "else:        \n",
    "    ## get from parameters:\n",
    "    minimum_inclusion_fr_Hz: float = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.included_qclu_values\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict, included_qclu_values=included_qclu_values, minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, drop_previous_result_and_compute_fresh=True, num_wcorr_shuffles=1024,\n",
    "                                                # # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None)\n",
    "                                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb49fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function' in _across_session_results_extended_dict\n",
    "compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_output = deepcopy(_across_session_results_extended_dict['compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function'])\n",
    "# compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_output\n",
    "callback_outputs = deepcopy(_across_session_results_extended_dict['compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function'])\n",
    "\n",
    "custom_suffix = callback_outputs['custom_suffix']\n",
    "replay_epoch_variations = callback_outputs['replay_epoch_variations']\n",
    "replay_epoch_outputs = callback_outputs['replay_epoch_outputs']\n",
    "\n",
    "replay_epoch_name = 'normal_computed'\n",
    "a_replay_epoch_variation: Epoch = replay_epoch_variations[replay_epoch_name]\n",
    "a_replay_epoch_outputs = replay_epoch_outputs[replay_epoch_name]\n",
    "\n",
    "## Unpack `a_replay_epoch_outputs`\n",
    "exported_evt_file_path = a_replay_epoch_outputs['exported_evt_file_path']\n",
    "did_change = a_replay_epoch_outputs['did_change']\n",
    "custom_save_filenames = a_replay_epoch_outputs['custom_save_filenames']\n",
    "custom_save_filepaths = a_replay_epoch_outputs['custom_save_filepaths']\n",
    "custom_suffix = a_replay_epoch_outputs['custom_suffix']\n",
    "wcorr_ripple_shuffle_all_df = a_replay_epoch_outputs['wcorr_ripple_shuffle_all_df']\n",
    "all_shuffles_only_best_decoder_wcorr_df = a_replay_epoch_outputs['all_shuffles_only_best_decoder_wcorr_df']\n",
    "standalone_pkl_filepath = a_replay_epoch_outputs['standalone_pkl_filepath']\n",
    "standalone_mat_filepath = a_replay_epoch_outputs['standalone_mat_filepath']\n",
    "active_context = a_replay_epoch_outputs['active_context']\n",
    "export_files_dict = a_replay_epoch_outputs['export_files_dict']\n",
    "# params_description_str = a_replay_epoch_outputs['params_description_str']\n",
    "# footer_annotation_text = a_replay_epoch_outputs['footer_annotation_text']\n",
    "# out_hist_fig_result = a_replay_epoch_outputs['out_hist_fig_result']\n",
    "\n",
    "\n",
    "custom_save_filenames\n",
    "custom_save_filepaths\n",
    "export_files_dict\n",
    "# print_keys_if_possible('callback_outputs', compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_output, max_depth=3)\n",
    "# a_replay_epoch_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d41b45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_strs = []\n",
    "for k, v in a_replay_epoch_outputs.items():\n",
    "    code_strs.append(f\"{k} = a_replay_epoch_outputs['{k}']\")\n",
    "\n",
    "print('\\n'.join(code_strs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6d6e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_output['export_files_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8beeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_epoch_outputs = deepcopy(compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_output['replay_epoch_outputs'])\n",
    "# replay_epoch_outputs\n",
    "\n",
    "normal_computed_replay_epoch_outputs = replay_epoch_outputs['normal_computed']\n",
    "normal_computed_replay_epoch_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a3bfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(replay_epoch_outputs.keys())\n",
    "\n",
    "export_files_dict = normal_computed_replay_epoch_outputs['export_files_dict']\n",
    "export_files_dict\n",
    "\n",
    "export_file_path_ripple_WCorrShuffle_df = export_files_dict['ripple_WCorrShuffle_df'] # 'W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-11-18_1020PM-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_1.0-(ripple_WCorrShuffle_df)_tbin-0.025.csv'\n",
    "export_file_path_ripple_WCorrShuffle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a46edd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_save_filepaths = normal_computed_replay_epoch_outputs['custom_save_filepaths'] ## these seem to be misnamed AND redundant\n",
    "custom_save_filepaths\n",
    "\n",
    "ripple_csv_out_path = custom_save_filepaths['ripple_csv_out_path'] # 'K:/scratch/collected_outputs/2024-11-18-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_1.0_withNormalComputedReplays-frateThresh_1.0-qclu_[1, 2, 4, 6, 7, 9]-(ripple_marginals_df).csv'\n",
    "ripple_csv_out_path\n",
    "\n",
    "ripple_csv_time_bin_marginals = custom_save_filepaths['ripple_csv_time_bin_marginals'] # 'K:/scratch/collected_outputs/2024-11-18-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_1.0_withNormalComputedReplays-frateThresh_1.0-qclu_[1, 2, 4, 6, 7, 9]-(ripple_time_bin_marginals_df).csv'\n",
    "ripple_csv_time_bin_marginals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3f496b",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_7_'></a>[Call `compute_and_export_session_trial_by_trial_performance_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be44b166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_session_trial_by_trial_performance_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "return_full_decoding_results: bool = True\n",
    "save_hdf: bool = True\n",
    "save_csvs:bool = True\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "additional_session_context = None\n",
    "try:\n",
    "    if custom_suffix is not None:\n",
    "        additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "        print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "except NameError as err:\n",
    "    additional_session_context = None\n",
    "    print(f'NO CUSTOM SUFFIX.')    \n",
    "    \n",
    "active_laps_decoding_time_bin_size: float = 0.025\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_session_trial_by_trial_performance_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict, active_laps_decoding_time_bin_size=active_laps_decoding_time_bin_size,\n",
    "                                                # # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None)\n",
    "                                                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e427751",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_outputs = _across_session_results_extended_dict['compute_and_export_session_trial_by_trial_performance_completion_function']\n",
    "a_trial_by_trial_result: TrialByTrialActivityResult = callback_outputs['a_trial_by_trial_result']\n",
    "subset_neuron_IDs_dict = callback_outputs['subset_neuron_IDs_dict']\n",
    "subset_decode_results_dict = callback_outputs['subset_decode_results_dict']\n",
    "subset_decode_results_track_id_correct_performance_dict = callback_outputs['subset_decode_results_track_id_correct_performance_dict']\n",
    "directional_active_lap_pf_results_dicts: Dict[types.DecoderName, TrialByTrialActivity] = a_trial_by_trial_result.directional_active_lap_pf_results_dicts\n",
    "_out_subset_decode_results_track_id_correct_performance_dict = callback_outputs['subset_decode_results_track_id_correct_performance_dict']\n",
    "_out_subset_decode_results_dict = callback_outputs['subset_decode_results_dict']\n",
    "(complete_decoded_context_correctness_tuple, laps_marginals_df, all_directional_pf1D_Decoder, all_test_epochs_df, test_all_directional_decoder_result, all_directional_laps_filter_epochs_decoder_result, _out_separate_decoder_results)  = _out_subset_decode_results_dict['any_decoder'] ## get the result for all cells\n",
    "filtered_laps_time_bin_marginals_df: pd.DataFrame = callback_outputs['subset_decode_results_time_bin_marginals_df_dict']['filtered_laps_time_bin_marginals_df']\n",
    "# active_results: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy({k:v.decoder_result for k, v in _out_separate_decoder_results[0].items()})\n",
    "active_results: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy({k:v for k, v in _out_separate_decoder_results[1].items()})\n",
    "filtered_laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276588e6",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_8_'></a>[Call `compute_and_export_cell_first_spikes_characteristics_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a69538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_cell_first_spikes_characteristics_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "try:\n",
    "    _across_session_results_extended_dict\n",
    "except NameError as e:\n",
    "    _across_session_results_extended_dict = {} # initialize\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_cell_first_spikes_characteristics_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                # # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None)\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855bd06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import figures_plot_cell_first_spikes_characteristics_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "try:\n",
    "    _across_session_results_extended_dict\n",
    "except NameError as e:\n",
    "    _across_session_results_extended_dict = {} # initialize\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | figures_plot_cell_first_spikes_characteristics_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                # # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None),\n",
    "                                                later_appearing_cell_lap_start_id=4,\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4624b606",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_9_'></a>[Call `kdiba_session_post_fixup_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef1b68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyphoplacecellanalysis.General.type_aliases as types\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import PostHocPipelineFixup, kdiba_session_post_fixup_completion_function, SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "# additional_session_context = None\n",
    "# try:\n",
    "#     if custom_suffix is not None:\n",
    "#         additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "#         print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "# except NameError as err:\n",
    "#     additional_session_context = None\n",
    "#     print(f'NO CUSTOM SUFFIX.')    \n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | kdiba_session_post_fixup_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                force_recompute=False, is_dry_run=False,\n",
    "                                                )\n",
    "\n",
    "\n",
    "# callback_outputs = _across_session_results_extended_dict['kdiba_session_post_fixup_completion_function'] # 'PostHocPipelineFixup'\n",
    "# loaded_track_limits = callback_outputs['loaded_track_limits']\n",
    "# a_config_dict = callback_outputs['a_config_dict']\n",
    "# print(f'loaded_track_limits: {loaded_track_limits}') \n",
    "    \n",
    "\n",
    "#  'computation_results[\"maze_any\"]': False, 'filtered_sessions[\"maze1_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze1_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze1_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze1_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze2_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze2_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze2_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze2_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze1_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_even\"].config.pix2cm': False, 'filtered_sessions[\"maze1_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.grid_bin': True, 'filtered_sessions[\"maze1_even\"].config.track_start_t': True, 'filtered_sessions[\"maze1_even\"].config.track_end_t': True, 'filtered_sessions[\"maze2_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_even\"].config.pix2cm': False, 'filtered_sessions[\"maze2_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.grid_bin': True, 'filtered_sessions[\"maze2_even\"].config.track_start_t': True, 'filtered_sessions[\"maze2_even\"].config.track_end_t': True, 'filtered_sessions[\"maze_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze_even\"].config.pix2cm': False, 'filtered_sessions[\"maze_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.grid_bin': True, 'filtered_sessions[\"maze_even\"].config.track_start_t': True, 'filtered_sessions[\"maze_even\"].config.track_end_t': True, 'filtered_sessions[\"maze1_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_any\"].config.pix2cm': False, 'filtered_sessions[\"maze1_any\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.grid_bin': True, 'filtered_sessions[\"maze1_any\"].config.track_start_t': True, 'filtered_sessions[\"maze1_any\"].config.track_end_t': True, 'filtered_sessions[\"maze2_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_any\"].config.pix2cm': False, 'filtered_sessions[\"maze2_any\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.grid_bin': True, 'filtered_sessions[\"maze2_any\"].config.track_start_t': True, 'filtered_sessions[\"maze2_any\"].config.track_end_t': True, 'filtered_sessions[\"maze_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze_any\"].config.pix2cm': False, 'filtered_sessions[\"maze_any\"].config.real_unit_grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.real_cm_grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.grid_bin': True, 'filtered_sessions[\"maze_any\"].config.track_start_t': False, 'filtered_sessions[\"maze_any\"].config.track_end_t': False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdfd908",
   "metadata": {},
   "outputs": [],
   "source": [
    "_across_session_results_extended_dict\n",
    "\n",
    "# 'filtered_sessions[\"maze1_odd\"].loaded_track_limits': False,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.pix2cm': False,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.real_unit_grid_bin_bounds': True,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.real_cm_grid_bin_bounds': True,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.grid_bin_bounds': True,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.grid_bin': True,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.track_start_t': True,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.track_end_t': True,\n",
    "\n",
    "['real_unit_grid_bin_bounds', 'real_cm_grid_bin_bounds', 'grid_bin_bounds', 'grid_bin', 'track_start_t', 'track_end_t']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c43d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.filtered_sessions[\"maze1_odd\"].config.real_unit_grid_bin_bounds\n",
    "curr_active_pipeline.filtered_sessions[\"maze_even\"].config.grid_bin_bounds\n",
    "curr_active_pipeline.filtered_sessions[\"maze1_odd\"].config.grid_bin_bounds\n",
    "curr_active_pipeline.filtered_sessions[\"maze1_odd\"].config.loaded_track_limits\n",
    "curr_active_pipeline.filtered_sessions[\"maze1_odd\"].config.track_start_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650ee1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.filtered_sessions['maze1_even'].config.real_unit_grid_bin_bounds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a3bd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# extended_computations_include_includelist=['ratemap_peaks_prominence2d', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring',] # do only specified\n",
    "computation_functions_name_includelist = ['_perform_baseline_placefield_computation', '_perform_time_dependent_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_time_dependent_pf_sequential_surprise_computation_perform_two_step_position_decoding_computation']\n",
    " #['rank_order_shuffle_analysis', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'ratemap_peaks_prominence2d', ] # do only specified\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=computation_functions_name_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=False, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=True)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963bf33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_include_function_names # {'_perform_pf_find_ratemap_peaks_computation': False, '_perform_time_dependent_pf_sequential_surprise_computation_perform_two_step_position_decoding_computation': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3d93e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=computation_functions_name_includelist, computation_kwargs_list=None, enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b70e5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# curr_active_pipeline.perform_computations(computation_functions_name_includelist=computation_functions_name_includelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2bc08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# curr_active_pipeline.active_configs # Dict[types.FilterContextName, InteractivePlaceCellConfig]\n",
    "# curr_active_pipeline.computation_results # Dict[types.FilterContextName, ComputationResult]\n",
    "\n",
    "# curr_active_pipeline.computation_results['maze1_odd'].computation_config # DynamicContainer\n",
    "# curr_active_pipeline.computation_results['maze1_odd'].computation_config.pf_params # PlacefieldComputationParameters\n",
    "\n",
    "\n",
    "grid_bin_bounds = deepcopy(curr_active_pipeline.computation_results['maze1_odd'].computation_config.pf_params.grid_bin_bounds) # ((0.0, 287.7697841726619), (115.10791366906477, 172.66187050359713))\n",
    "\n",
    "grid_bin = deepcopy(curr_active_pipeline.computation_results['maze1_odd'].computation_config.pf_params.grid_bin) # (3.8054171165052444, 1.4477079927649104)\n",
    "\n",
    "grid_bin_bounds\n",
    "# long_any_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1885e4bc",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_10_'></a>[Call `generalized_decode_epochs_dict_and_export_results_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2fb70e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of pyphoplacecellanalysis.Analysis.Decoder.context_dependent failed: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 274, in check\n",
      "    superreload(m, reload, self.old_objects, self.shell)\n",
      "  File \"c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 330, in update_class\n",
      "    old_obj = getattr(old, key)\n",
      "AttributeError: 'types.GenericAlias' object has no attribute '__copy__'\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "generalized_decode_epochs_dict_and_export_results_completion_function(curr_session_context: kdiba_gor01_one_2006-6-09_1-22-43, curr_session_basedir: W:\\Data\\KDIBA\\gor01\\one\\2006-6-09_1-22-43, ...)\n",
      "included includelist is specified: ['non_PBE_epochs_results'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze_any\"\n",
      "done with all batch_extended_computations(...).\n",
      "epochs_decoding_time_bin_size = 0.025, frame_divide_bin_size = 10.0\n",
      "IndexError: len(a_time_bin_edges): 33 != (num_time_bins+1): 2. Skipping .creating_new_spikes_per_t_bin_masked_variants(...) for a_context: laps_1_pseudo2D_0.025_pbe_ignore_per_time_bin.\n",
      "\tcomputed 1 new results\n",
      "\t creating new across_session_results_extended_dict['generalized_decode_epochs_dict_and_export_results_completion_function']['a_new_fully_generic_result'] result.\n",
      "csv_save_paths_dict: {'FAT': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2025-03-18_0620PM-kdiba_gor01_one_2006-6-09_1-22-43_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0-(FAT)_tbin-0.025.csv')}\n",
      "\n",
      "\t\tdone.\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GenericDecoderDictDecodedEpochsDictResult(\n",
       "    spikes_df_dict=<['format_name:kdiba|animal:gor01|exper_name:one|session_name:2006-6-09_1-22-43', '', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:nan_filled|data_grain:per_time_bin']>,\n",
       "    decoders=<['trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:long_LR|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:long_RL|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:short_LR|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:short_RL|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:long_LR|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:long_RL|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:short_LR|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:short_RL|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore']>,\n",
       "    filter_epochs_to_decode_dict=<['trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:laps', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:pbe', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:non_pbe', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore']>,\n",
       "    filter_epochs_specific_decoded_result=<['trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:laps', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:pbe', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:non_pbe', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:nan_filled|data_grain:per_time_bin']>,\n",
       "    filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict=<['trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:last_valid', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:nan_filled', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:last_valid', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:nan_filled', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:non_pbe|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:non_pbe|masked_time_bin_fill_type:last_valid', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:non_pbe|masked_time_bin_fill_type:nan_filled', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore|data_grain:per_time_bin', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore|data_grain:per_epoch', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore|data_grain:per_time_bin', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore|data_grain:per_epoch']>\n",
       ")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyphoplacecellanalysis.General.type_aliases as types\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import generalized_decode_epochs_dict_and_export_results_completion_function, SimpleBatchComputationDummy\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult #, KnownNamedDecoderTrainedComputeEpochsType, KnownNamedDecodingEpochsType, MaskedTimeBinFillType, DataTimeGrain, GenericResultTupleIndexType\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "\n",
    "## Settings:\n",
    "_across_session_results_extended_dict = {}\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | generalized_decode_epochs_dict_and_export_results_completion_function(a_dummy, None,\n",
    "                                                    curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                    across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tforce_recompute = False,\n",
    "                                                )\n",
    "\n",
    "callback_outputs = _across_session_results_extended_dict['generalized_decode_epochs_dict_and_export_results_completion_function'] # 'PostHocPipelineFixup'\n",
    "a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult = callback_outputs['a_new_fully_generic_result']\n",
    "csv_save_paths_dict: Dict[str, Path] = callback_outputs['csv_save_paths_dict']\n",
    "a_new_fully_generic_result\n",
    "# a_config_dict = callback_outputs['a_config_dict']\n",
    "# print(f'loaded_track_limits: {loaded_track_limits}') \n",
    " \n",
    "#  'computation_results[\"maze_any\"]': False, 'filtered_sessions[\"maze1_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze1_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze1_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze1_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze2_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze2_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze2_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze2_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze1_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_even\"].config.pix2cm': False, 'filtered_sessions[\"maze1_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.grid_bin': True, 'filtered_sessions[\"maze1_even\"].config.track_start_t': True, 'filtered_sessions[\"maze1_even\"].config.track_end_t': True, 'filtered_sessions[\"maze2_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_even\"].config.pix2cm': False, 'filtered_sessions[\"maze2_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.grid_bin': True, 'filtered_sessions[\"maze2_even\"].config.track_start_t': True, 'filtered_sessions[\"maze2_even\"].config.track_end_t': True, 'filtered_sessions[\"maze_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze_even\"].config.pix2cm': False, 'filtered_sessions[\"maze_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.grid_bin': True, 'filtered_sessions[\"maze_even\"].config.track_start_t': True, 'filtered_sessions[\"maze_even\"].config.track_end_t': True, 'filtered_sessions[\"maze1_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_any\"].config.pix2cm': False, 'filtered_sessions[\"maze1_any\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.grid_bin': True, 'filtered_sessions[\"maze1_any\"].config.track_start_t': True, 'filtered_sessions[\"maze1_any\"].config.track_end_t': True, 'filtered_sessions[\"maze2_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_any\"].config.pix2cm': False, 'filtered_sessions[\"maze2_any\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.grid_bin': True, 'filtered_sessions[\"maze2_any\"].config.track_start_t': True, 'filtered_sessions[\"maze2_any\"].config.track_end_t': True, 'filtered_sessions[\"maze_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze_any\"].config.pix2cm': False, 'filtered_sessions[\"maze_any\"].config.real_unit_grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.real_cm_grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.grid_bin': True, 'filtered_sessions[\"maze_any\"].config.track_start_t': False, 'filtered_sessions[\"maze_any\"].config.track_end_t': False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1269a3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found best match for a_result with 0 matching attributes:\tnon_pbe_laps\n",
      "\n",
      "Found best match for a_decoder with 0 matching attributes:\tlaps_1_pseudo2D_0.025_laps_ignore\n",
      "\n",
      "Found best match for a_decoded_marginal_posterior_df with 0 matching attributes:\tnon_pbe_laps_ignore\n",
      "\n",
      "Warning: Different contexts matched: result=non_pbe_laps, decoder=laps_1_pseudo2D_0.025_laps_ignore, posterior=non_pbe_laps_ignore\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore'),\n",
       " DecodedFilterEpochsResult(decoding_time_bin_size: float,\n",
       " \tfilter_epochs: pandas.core.frame.DataFrame,\n",
       " \tnum_filter_epochs: int,\n",
       " \tmost_likely_positions_list: list | shape (n_epochs),\n",
       " \tp_x_given_n_list: list | shape (n_epochs),\n",
       " \tmarginal_x_list: list | shape (n_epochs),\n",
       " \tmarginal_y_list: list | shape (n_epochs),\n",
       " \tmost_likely_position_indicies_list: list | shape (n_epochs),\n",
       " \tspkcount: list | shape (n_epochs),\n",
       " \tnbins: numpy.ndarray | shape (n_epochs),\n",
       " \ttime_bin_containers: list | shape (n_epochs),\n",
       " \ttime_bin_edges: list | shape (n_epochs),\n",
       " \tepoch_description_list: list | shape (n_epochs),\n",
       " \tpos_bin_edges: numpy.ndarray | shape (n_pos_bins+1)\n",
       " ),\n",
       " BasePositionDecoder(pf=PfND(config=<PlacefieldComputationParameters: {'speed_thresh': 10.0, 'grid_bin': (4.877453969028168, 1.0), 'grid_bin_bounds': ((0.0, 287.7697841726619), (0, 4)), 'smooth': (2.0, 0.0), 'frate_thresh': 0.0, 'is_directional': True};>, position_srate=29.969756198785802, setup_on_init=False, compute_on_init=False, _save_intermediate_spikes_maps=True, _included_thresh_neurons_indx=None, _peak_frate_filter_function=None, _ratemap=<Ratemap: {'_filename': None, '_metadata': None, 'spikes_maps': array([[[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]]]), 'tuning_curves': array([[[0, 0.00336505, 0, 0],\n",
       "         [0, 0.0136865, 0, 0],\n",
       "         [0, 0.0515681, 0, 0],\n",
       "         ...,\n",
       "         [0, 0.00976002, 0, 0],\n",
       "         [0, 0.00244404, 0, 0],\n",
       "         [0, 0.000548405, 0, 0]],\n",
       " \n",
       "        [[7.28252e-05, 0.00112981, 0, 0],\n",
       "         [0.000342897, 0.00406469, 0, 0],\n",
       "         [0.00143309, 0.0137708, 0, 0],\n",
       "         ...,\n",
       "         [0, 0.00145046, 0, 0],\n",
       "         [0, 0.000277146, 0, 0],\n",
       "         [0, 3.89411e-05, 0, 0]],\n",
       " \n",
       "        [[0.000186976, 0.00105986, 0, 0],\n",
       "         [0.000823288, 0.00352893, 0, 0],\n",
       "         [0.00325617, 0.0107875, 0, 0],\n",
       "         ...,\n",
       "         [9.30767e-05, 0.0102055, 0, 0],\n",
       "         [1.42738e-05, 0.00252494, 0, 0],\n",
       "         [0, 0.00055814, 0, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[5.24991e-06, 0, 0, 0],\n",
       "         [4.97799e-05, 0, 0, 0],\n",
       "         [0.000275227, 1.23035e-05, 0, 0],\n",
       "         ...,\n",
       "         [0.017319, 0.0160292, 0, 0],\n",
       "         [0.00332061, 0.00248601, 0, 0],\n",
       "         [0.000477492, 0.000262852, 0, 0]],\n",
       " \n",
       "        [[0.000129901, 6.99581e-05, 0, 0],\n",
       "         [0.000660823, 0.0004721, 0, 0],\n",
       "         [0.00288359, 0.00242048, 0, 0],\n",
       "         ...,\n",
       "         [9.30767e-05, 0.00949441, 0, 0],\n",
       "         [1.42738e-05, 0.00238927, 0, 0],\n",
       "         [0, 0.000538669, 0, 0]],\n",
       " \n",
       "        [[0.000535352, 0.0125701, 0, 0],\n",
       "         [0.00254389, 0.0376638, 0, 0],\n",
       "         [0.010722, 0.110875, 0, 0],\n",
       "         ...,\n",
       "         [0.084405, 0.00148831, 0, 0],\n",
       "         [0.0271325, 0.00028295, 0, 0],\n",
       "         [0.00804441, 3.89411e-05, 0, 0]]]), 'unsmoothed_tuning_maps': array([[[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0],\n",
       "         [0, 0, 0, 0]]]), '_neuron_ids': array([  2,   3,   4,   5,   6,   8,   9,  11,  12,  14,  15,  16,  18,  19,  20,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  38,  39,  40,  43,  44,  47,  48,  51,  52,  53,  55,  56,  57,  58,  59,  60,  61,  62,  63,  66,  67,  68,  69,  70,  71,  72,  75,  77,  79,  80,  81,  82,  83,  84,  85,  86,  87,  89,  90,  91,  92,  93,  95,  98, 101, 102, 103, 104]), '_neuron_extended_ids': [NeuronExtendedIdentity(shank=1, cluster=2, aclu=2, qclu=2), NeuronExtendedIdentity(shank=1, cluster=3, aclu=3, qclu=2), NeuronExtendedIdentity(shank=1, cluster=4, aclu=4, qclu=2), NeuronExtendedIdentity(shank=1, cluster=10, aclu=5, qclu=1), NeuronExtendedIdentity(shank=1, cluster=11, aclu=6, qclu=2), NeuronExtendedIdentity(shank=1, cluster=13, aclu=8, qclu=2), NeuronExtendedIdentity(shank=1, cluster=14, aclu=9, qclu=2), NeuronExtendedIdentity(shank=1, cluster=17, aclu=11, qclu=2), NeuronExtendedIdentity(shank=1, cluster=18, aclu=12, qclu=1), NeuronExtendedIdentity(shank=2, cluster=3, aclu=14, qclu=4), NeuronExtendedIdentity(shank=2, cluster=5, aclu=15, qclu=4), NeuronExtendedIdentity(shank=2, cluster=9, aclu=16, qclu=2), NeuronExtendedIdentity(shank=2, cluster=14, aclu=18, qclu=2), NeuronExtendedIdentity(shank=2, cluster=15, aclu=19, qclu=9), NeuronExtendedIdentity(shank=2, cluster=16, aclu=20, qclu=2), NeuronExtendedIdentity(shank=2, cluster=19, aclu=23, qclu=2), NeuronExtendedIdentity(shank=2, cluster=21, aclu=24, qclu=2), NeuronExtendedIdentity(shank=2, cluster=27, aclu=25, qclu=4), NeuronExtendedIdentity(shank=2, cluster=28, aclu=26, qclu=4), NeuronExtendedIdentity(shank=2, cluster=30, aclu=27, qclu=1), NeuronExtendedIdentity(shank=2, cluster=31, aclu=28, qclu=2), NeuronExtendedIdentity(shank=2, cluster=37, aclu=29, qclu=1), NeuronExtendedIdentity(shank=3, cluster=3, aclu=30, qclu=2), NeuronExtendedIdentity(shank=3, cluster=4, aclu=31, qclu=2), NeuronExtendedIdentity(shank=3, cluster=5, aclu=32, qclu=9), NeuronExtendedIdentity(shank=3, cluster=8, aclu=33, qclu=4), NeuronExtendedIdentity(shank=3, cluster=11, aclu=34, qclu=9), NeuronExtendedIdentity(shank=3, cluster=22, aclu=35, qclu=2), NeuronExtendedIdentity(shank=3, cluster=35, aclu=38, qclu=1), NeuronExtendedIdentity(shank=3, cluster=37, aclu=39, qclu=2), NeuronExtendedIdentity(shank=4, cluster=4, aclu=40, qclu=4), NeuronExtendedIdentity(shank=6, cluster=3, aclu=43, qclu=2), NeuronExtendedIdentity(shank=7, cluster=2, aclu=44, qclu=2), NeuronExtendedIdentity(shank=7, cluster=7, aclu=47, qclu=4), NeuronExtendedIdentity(shank=7, cluster=8, aclu=48, qclu=2), NeuronExtendedIdentity(shank=7, cluster=14, aclu=51, qclu=4), NeuronExtendedIdentity(shank=7, cluster=16, aclu=52, qclu=4), NeuronExtendedIdentity(shank=7, cluster=17, aclu=53, qclu=4), NeuronExtendedIdentity(shank=8, cluster=3, aclu=55, qclu=9), NeuronExtendedIdentity(shank=8, cluster=4, aclu=56, qclu=4), NeuronExtendedIdentity(shank=8, cluster=5, aclu=57, qclu=2), NeuronExtendedIdentity(shank=8, cluster=6, aclu=58, qclu=1), NeuronExtendedIdentity(shank=8, cluster=7, aclu=59, qclu=2), NeuronExtendedIdentity(shank=8, cluster=8, aclu=60, qclu=4), NeuronExtendedIdentity(shank=8, cluster=10, aclu=61, qclu=2), NeuronExtendedIdentity(shank=8, cluster=12, aclu=62, qclu=2), NeuronExtendedIdentity(shank=8, cluster=14, aclu=63, qclu=2), NeuronExtendedIdentity(shank=8, cluster=21, aclu=66, qclu=2), NeuronExtendedIdentity(shank=8, cluster=25, aclu=67, qclu=2), NeuronExtendedIdentity(shank=8, cluster=30, aclu=68, qclu=4), NeuronExtendedIdentity(shank=8, cluster=32, aclu=69, qclu=1), NeuronExtendedIdentity(shank=9, cluster=4, aclu=70, qclu=4), NeuronExtendedIdentity(shank=9, cluster=5, aclu=71, qclu=9), NeuronExtendedIdentity(shank=9, cluster=7, aclu=72, qclu=2), NeuronExtendedIdentity(shank=9, cluster=13, aclu=75, qclu=4), NeuronExtendedIdentity(shank=9, cluster=16, aclu=77, qclu=9), NeuronExtendedIdentity(shank=9, cluster=19, aclu=79, qclu=2), NeuronExtendedIdentity(shank=9, cluster=20, aclu=80, qclu=2), NeuronExtendedIdentity(shank=10, cluster=2, aclu=81, qclu=2), NeuronExtendedIdentity(shank=10, cluster=6, aclu=82, qclu=2), NeuronExtendedIdentity(shank=10, cluster=7, aclu=83, qclu=4), NeuronExtendedIdentity(shank=10, cluster=8, aclu=84, qclu=2), NeuronExtendedIdentity(shank=10, cluster=10, aclu=85, qclu=4), NeuronExtendedIdentity(shank=10, cluster=12, aclu=86, qclu=2), NeuronExtendedIdentity(shank=10, cluster=13, aclu=87, qclu=9), NeuronExtendedIdentity(shank=10, cluster=15, aclu=89, qclu=2), NeuronExtendedIdentity(shank=10, cluster=18, aclu=90, qclu=2), NeuronExtendedIdentity(shank=10, cluster=19, aclu=91, qclu=2), NeuronExtendedIdentity(shank=10, cluster=20, aclu=92, qclu=2), NeuronExtendedIdentity(shank=11, cluster=4, aclu=93, qclu=2), NeuronExtendedIdentity(shank=12, cluster=3, aclu=95, qclu=9), NeuronExtendedIdentity(shank=12, cluster=7, aclu=98, qclu=1), NeuronExtendedIdentity(shank=12, cluster=11, aclu=101, qclu=4), NeuronExtendedIdentity(shank=12, cluster=12, aclu=102, qclu=9), NeuronExtendedIdentity(shank=12, cluster=13, aclu=103, qclu=2), NeuronExtendedIdentity(shank=12, cluster=15, aclu=104, qclu=2)], 'xbin': array([0, 4.87745, 9.75491, 14.6324, 19.5098, 24.3873, 29.2647, 34.1422, 39.0196, 43.8971, 48.7745, 53.652, 58.5294, 63.4069, 68.2844, 73.1618, 78.0393, 82.9167, 87.7942, 92.6716, 97.5491, 102.427, 107.304, 112.181, 117.059, 121.936, 126.814, 131.691, 136.569, 141.446, 146.324, 151.201, 156.079, 160.956, 165.833, 170.711, 175.588, 180.466, 185.343, 190.221, 195.098, 199.976, 204.853, 209.731, 214.608, 219.485, 224.363, 229.24, 234.118, 238.995, 243.873, 248.75, 253.628, 258.505, 263.383, 268.26, 273.137, 278.015, 282.892, 287.77]), 'ybin': array([0, 1, 2, 3, 4]), 'occupancy': array([[0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0.100101, 0, 0],\n",
       "        [0, 1.46815, 0, 0],\n",
       "        [0, 2.50252, 0, 0],\n",
       "        [8.07481, 3.1365, 0, 0],\n",
       "        [12.7462, 2.86956, 0, 0],\n",
       "        [4.30434, 4.20424, 0, 0],\n",
       "        [4.17087, 5.43882, 0, 0],\n",
       "        [3.77047, 3.03639, 0, 0],\n",
       "        [0, 0.033367, 0, 0],\n",
       "        [0, 0.0667339, 0, 0],\n",
       "        [2.23559, 1.60161, 0, 0],\n",
       "        [2.36905, 2.03539, 0, 0.400405],\n",
       "        [4.0374, 2.13549, 22.8231, 8.04146],\n",
       "        [1.86855, 1.60161, 7.30739, 9.80992],\n",
       "        [2.63599, 2.20222, 4.47119, 3.40344],\n",
       "        [3.2366, 2.60262, 3.47017, 4.10415],\n",
       "        [1.50151, 2.06875, 2.10212, 3.43681],\n",
       "        [2.56926, 1.80182, 2.46916, 2.23559],\n",
       "        [1.33468, 1.80182, 1.86856, 2.00202],\n",
       "        [1.36805, 1.86855, 1.80182, 1.90192],\n",
       "        [1.66835, 1.63498, 1.73509, 1.43478],\n",
       "        [1.46815, 2.10212, 1.80182, 1.60162],\n",
       "        [1.33468, 1.80182, 1.66835, 1.20121],\n",
       "        [1.56825, 2.13549, 1.76845, 1.60162],\n",
       "        [1.76845, 2.10212, 1.66835, 1.26795],\n",
       "        [2.36905, 1.86855, 1.83519, 1.26795],\n",
       "        [2.43579, 1.46815, 1.86856, 1.16785],\n",
       "        [1.66835, 1.83518, 1.70172, 1.26795],\n",
       "        [2.00202, 1.53488, 1.96866, 1.23458],\n",
       "        [1.56825, 1.93528, 1.83519, 1.36805],\n",
       "        [1.56825, 1.93528, 1.53488, 1.30132],\n",
       "        [1.93528, 2.00202, 1.86856, 1.33468],\n",
       "        [2.43579, 1.73508, 2.10212, 1.16785],\n",
       "        [2.46916, 2.00202, 2.26896, 2.7361],\n",
       "        [2.03539, 1.13448, 3.70374, 1.86856],\n",
       "        [2.63599, 1.60161, 4.90496, 2.50253],\n",
       "        [1.83518, 1.90192, 8.5086, 2.9363],\n",
       "        [2.10212, 2.20222, 4.20425, 3.10314],\n",
       "        [2.20222, 2.13549, 3.16987, 3.33671],\n",
       "        [1.63498, 1.36805, 4.40445, 8.07483],\n",
       "        [3.16986, 2.86956, 2.30233, 11.2781],\n",
       "        [3.7371, 3.47017, 0.0333671, 0],\n",
       "        [8.17491, 3.70373, 0, 0],\n",
       "        [8.84225, 4.27097, 0, 0],\n",
       "        [9.37612, 7.04043, 0, 0],\n",
       "        [9.37612, 23.0566, 0, 0],\n",
       "        [0.700706, 6.8736, 0, 0],\n",
       "        [0.533872, 0.934275, 0, 0],\n",
       "        [0.33367, 0.467138, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0]])};>, _ratemap_spiketrains=None, _ratemap_spiketrains_pos=None, ndim=2, xbin=array([0, 4.87745, 9.75491, 14.6324, 19.5098, 24.3873, 29.2647, 34.1422, 39.0196, 43.8971, 48.7745, 53.652, 58.5294, 63.4069, 68.2844, 73.1618, 78.0393, 82.9167, 87.7942, 92.6716, 97.5491, 102.427, 107.304, 112.181, 117.059, 121.936, 126.814, 131.691, 136.569, 141.446, 146.324, 151.201, 156.079, 160.956, 165.833, 170.711, 175.588, 180.466, 185.343, 190.221, 195.098, 199.976, 204.853, 209.731, 214.608, 219.485, 224.363, 229.24, 234.118, 238.995, 243.873, 248.75, 253.628, 258.505, 263.383, 268.26, 273.137, 278.015, 282.892, 287.77]), ybin=array([0, 1, 2, 3, 4]), bin_info=None), neuron_IDXs=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75]), neuron_IDs=array([  2,   3,   4,   5,   6,   8,   9,  11,  12,  14,  15,  16,  18,  19,  20,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  38,  39,  40,  43,  44,  47,  48,  51,  52,  53,  55,  56,  57,  58,  59,  60,  61,  62,  63,  66,  67,  68,  69,  70,  71,  72,  75,  77,  79,  80,  81,  82,  83,  84,  85,  86,  87,  89,  90,  91,  92,  93,  95,  98, 101, 102, 103, 104]), setup_on_init=True, post_load_on_init=True, debug_print=False),\n",
       "                  t    P_Long   P_Short  epoch_id  sub_epoch_time_bin_index  delta_aligned_start_t       session_name  time_bin_size pre_post_delta_category\n",
       " 0         3.067274  0.875471  0.124529         0                         0           -1026.249335  2006-6-09_1-22-43          0.025               pre-delta\n",
       " 1         3.092274  0.860276  0.139724         0                         1           -1026.224335  2006-6-09_1-22-43          0.025               pre-delta\n",
       " 2         3.117274  0.305716  0.694284         0                         2           -1026.199335  2006-6-09_1-22-43          0.025               pre-delta\n",
       " 3         3.142274  0.305716  0.694284         0                         3           -1026.174335  2006-6-09_1-22-43          0.025               pre-delta\n",
       " 4         3.167274  0.834689  0.165311         0                         4           -1026.149335  2006-6-09_1-22-43          0.025               pre-delta\n",
       " 5         3.192274  0.609616  0.390384         0                         5           -1026.124335  2006-6-09_1-22-43          0.025               pre-delta\n",
       " ...            ...       ...       ...       ...                       ...                    ...                ...            ...                     ...\n",
       " 19096  1657.962730  0.469509  0.530491        83                       208             628.646121  2006-6-09_1-22-43          0.025              post-delta\n",
       " 19097  1657.987730  0.452922  0.547078        83                       209             628.671121  2006-6-09_1-22-43          0.025              post-delta\n",
       " 19098  1658.012730  0.491076  0.508924        83                       210             628.696121  2006-6-09_1-22-43          0.025              post-delta\n",
       " 19099  1658.037730  0.452922  0.547078        83                       211             628.721121  2006-6-09_1-22-43          0.025              post-delta\n",
       " 19100  1658.062730  0.144182  0.855818        83                       212             628.746121  2006-6-09_1-22-43          0.025              post-delta\n",
       " 19101  1658.087730  0.622638  0.377362        83                       213             628.771121  2006-6-09_1-22-43          0.025              post-delta\n",
       " \n",
       " [19102 rows x 9 columns])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_new_fully_generic_result.get_matching_contexts(IdentifyingContext())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dff79ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "\n",
    "curr_active_pipeline.reload_default_computation_functions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b59a6e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included includelist is specified: ['non_PBE_epochs_results'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze_any\"\n",
      "done with all batch_extended_computations(...).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## perform the computation either way:\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['non_PBE_epochs_results'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "\n",
    "curr_active_pipeline.batch_extended_computations(include_includelist=['non_PBE_epochs_results'], include_global_functions=True, included_computation_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a809a658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IndexError: len(a_time_bin_edges): 33 != (num_time_bins+1): 2. Skipping .creating_new_spikes_per_t_bin_masked_variants(...) for a_context: laps_1_pseudo2D_0.025_pbe_ignore_per_time_bin.\n",
      "\tcomputed 1 new results\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GenericDecoderDictDecodedEpochsDictResult(\n",
       "    spikes_df_dict=<['format_name:kdiba|animal:gor01|exper_name:one|session_name:2006-6-09_1-22-43', '', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:nan_filled|data_grain:per_time_bin']>,\n",
       "    decoders=<['trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:long_LR|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:long_RL|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:short_LR|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:short_RL|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:long_LR|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:long_RL|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:short_LR|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:short_RL|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore']>,\n",
       "    filter_epochs_to_decode_dict=<['trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:laps', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:pbe', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:non_pbe', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore']>,\n",
       "    filter_epochs_specific_decoded_result=<['trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:laps', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:pbe', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:non_pbe', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:nan_filled|data_grain:per_time_bin']>,\n",
       "    filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict=<['trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:last_valid', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:nan_filled', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:last_valid', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:nan_filled', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:non_pbe|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:non_pbe|masked_time_bin_fill_type:last_valid', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:non_pbe|masked_time_bin_fill_type:nan_filled', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore|data_grain:per_time_bin', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore|data_grain:per_epoch', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore|data_grain:per_time_bin', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore|data_grain:per_epoch']>\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "\n",
    "spikes_df = deepcopy(get_proper_global_spikes_df(curr_active_pipeline))\n",
    "a_new_fully_generic_result = a_new_fully_generic_result.creating_new_spikes_per_t_bin_masked_variants(spikes_df=spikes_df)\n",
    "a_new_fully_generic_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec89910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_new_fully_generic_result.get_matching_contexts(context_query=IdentifyingContext(), return_multiple_matches=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1beeb43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found best match for a_result with 3 matching attributes:\tlaps_1_pseudo2D_0.025_pbe_ignore\n",
      "\n",
      "Found best match for a_decoder with 3 matching attributes:\tlaps_1_pseudo2D_0.025_pbe_ignore\n",
      "\n",
      "Found best match for a_decoded_marginal_posterior_df with 3 matching attributes:\tlaps_1_pseudo2D_0.025_pbe_ignore_per_time_bin\n",
      "\n",
      "Warning: Different contexts matched: result=laps_1_pseudo2D_0.025_pbe_ignore, decoder=laps_1_pseudo2D_0.025_pbe_ignore, posterior=laps_1_pseudo2D_0.025_pbe_ignore_per_time_bin\n",
      "best_matching_context: laps_1_pseudo2D_0.025_pbe_ignore_per_time_bin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_LR</th>\n",
       "      <th>P_RL</th>\n",
       "      <th>P_Long</th>\n",
       "      <th>P_Short</th>\n",
       "      <th>long_LR</th>\n",
       "      <th>long_RL</th>\n",
       "      <th>short_LR</th>\n",
       "      <th>short_RL</th>\n",
       "      <th>result_t_bin_idx</th>\n",
       "      <th>epoch_df_idx</th>\n",
       "      <th>parent_epoch_label</th>\n",
       "      <th>label</th>\n",
       "      <th>start</th>\n",
       "      <th>t_bin_center</th>\n",
       "      <th>stop</th>\n",
       "      <th>delta_aligned_start_t</th>\n",
       "      <th>session_name</th>\n",
       "      <th>time_bin_size</th>\n",
       "      <th>pre_post_delta_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.157071</td>\n",
       "      <td>0.842929</td>\n",
       "      <td>0.063367</td>\n",
       "      <td>0.936633</td>\n",
       "      <td>0.003123</td>\n",
       "      <td>0.060244</td>\n",
       "      <td>0.153949</td>\n",
       "      <td>0.782684</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42.658077</td>\n",
       "      <td>42.658577</td>\n",
       "      <td>42.659077</td>\n",
       "      <td>-986.658031</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>0.025</td>\n",
       "      <td>pre-delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.768486</td>\n",
       "      <td>0.231514</td>\n",
       "      <td>0.768486</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.231514</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55.735809</td>\n",
       "      <td>55.736309</td>\n",
       "      <td>55.736809</td>\n",
       "      <td>-973.580300</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>0.025</td>\n",
       "      <td>pre-delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.436490</td>\n",
       "      <td>0.563510</td>\n",
       "      <td>0.436490</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.563510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>55.760809</td>\n",
       "      <td>55.761309</td>\n",
       "      <td>55.761809</td>\n",
       "      <td>-973.555300</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>0.025</td>\n",
       "      <td>pre-delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.396270</td>\n",
       "      <td>0.603730</td>\n",
       "      <td>0.396270</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.603730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>55.785809</td>\n",
       "      <td>55.786309</td>\n",
       "      <td>55.786809</td>\n",
       "      <td>-973.530300</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>0.025</td>\n",
       "      <td>pre-delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.730270</td>\n",
       "      <td>0.269730</td>\n",
       "      <td>0.576341</td>\n",
       "      <td>0.423659</td>\n",
       "      <td>0.390890</td>\n",
       "      <td>0.185451</td>\n",
       "      <td>0.339380</td>\n",
       "      <td>0.084278</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>55.810809</td>\n",
       "      <td>55.811309</td>\n",
       "      <td>55.811809</td>\n",
       "      <td>-973.505300</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>0.025</td>\n",
       "      <td>pre-delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.528182</td>\n",
       "      <td>0.471818</td>\n",
       "      <td>0.320130</td>\n",
       "      <td>0.679870</td>\n",
       "      <td>0.179607</td>\n",
       "      <td>0.140523</td>\n",
       "      <td>0.348575</td>\n",
       "      <td>0.331295</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>55.835809</td>\n",
       "      <td>55.836309</td>\n",
       "      <td>55.836809</td>\n",
       "      <td>-973.480300</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>0.025</td>\n",
       "      <td>pre-delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2884</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.301627</td>\n",
       "      <td>0.698373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.301627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.698373</td>\n",
       "      <td>409</td>\n",
       "      <td>409</td>\n",
       "      <td>420</td>\n",
       "      <td>2884</td>\n",
       "      <td>1733.816959</td>\n",
       "      <td>1733.817459</td>\n",
       "      <td>1733.817959</td>\n",
       "      <td>704.500850</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>0.025</td>\n",
       "      <td>post-delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2885</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.786629</td>\n",
       "      <td>0.213371</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.786629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.213371</td>\n",
       "      <td>409</td>\n",
       "      <td>409</td>\n",
       "      <td>420</td>\n",
       "      <td>2885</td>\n",
       "      <td>1733.841959</td>\n",
       "      <td>1733.842459</td>\n",
       "      <td>1733.842959</td>\n",
       "      <td>704.525850</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>0.025</td>\n",
       "      <td>post-delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>410</td>\n",
       "      <td>410</td>\n",
       "      <td>421</td>\n",
       "      <td>2886</td>\n",
       "      <td>1734.973032</td>\n",
       "      <td>1734.973532</td>\n",
       "      <td>1734.974032</td>\n",
       "      <td>705.656923</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>0.025</td>\n",
       "      <td>post-delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>410</td>\n",
       "      <td>410</td>\n",
       "      <td>421</td>\n",
       "      <td>2887</td>\n",
       "      <td>1734.998032</td>\n",
       "      <td>1734.998532</td>\n",
       "      <td>1734.999032</td>\n",
       "      <td>705.681923</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>0.025</td>\n",
       "      <td>post-delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.606841</td>\n",
       "      <td>0.393159</td>\n",
       "      <td>0.606841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.393159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>411</td>\n",
       "      <td>411</td>\n",
       "      <td>422</td>\n",
       "      <td>2888</td>\n",
       "      <td>1736.904796</td>\n",
       "      <td>1736.905296</td>\n",
       "      <td>1736.905796</td>\n",
       "      <td>707.588688</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>0.025</td>\n",
       "      <td>post-delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2889</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.873391</td>\n",
       "      <td>0.126609</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.873391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126609</td>\n",
       "      <td>411</td>\n",
       "      <td>411</td>\n",
       "      <td>422</td>\n",
       "      <td>2889</td>\n",
       "      <td>1736.929796</td>\n",
       "      <td>1736.930296</td>\n",
       "      <td>1736.930796</td>\n",
       "      <td>707.613688</td>\n",
       "      <td>2006-6-09_1-22-43</td>\n",
       "      <td>0.025</td>\n",
       "      <td>post-delta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2890 rows √ó 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          P_LR      P_RL    P_Long   P_Short   long_LR   long_RL  short_LR  short_RL  result_t_bin_idx  epoch_df_idx parent_epoch_label  label        start  t_bin_center         stop  delta_aligned_start_t       session_name  time_bin_size pre_post_delta_category\n",
       "0     0.157071  0.842929  0.063367  0.936633  0.003123  0.060244  0.153949  0.782684                 0             0                  0      0    42.658077     42.658577    42.659077            -986.658031  2006-6-09_1-22-43          0.025               pre-delta\n",
       "1     1.000000  0.000000  0.768486  0.231514  0.768486  0.000000  0.231514  0.000000                 1             1                  1      1    55.735809     55.736309    55.736809            -973.580300  2006-6-09_1-22-43          0.025               pre-delta\n",
       "2     1.000000  0.000000  0.436490  0.563510  0.436490  0.000000  0.563510  0.000000                 1             1                  1      2    55.760809     55.761309    55.761809            -973.555300  2006-6-09_1-22-43          0.025               pre-delta\n",
       "3     1.000000  0.000000  0.396270  0.603730  0.396270  0.000000  0.603730  0.000000                 1             1                  1      3    55.785809     55.786309    55.786809            -973.530300  2006-6-09_1-22-43          0.025               pre-delta\n",
       "4     0.730270  0.269730  0.576341  0.423659  0.390890  0.185451  0.339380  0.084278                 1             1                  1      4    55.810809     55.811309    55.811809            -973.505300  2006-6-09_1-22-43          0.025               pre-delta\n",
       "5     0.528182  0.471818  0.320130  0.679870  0.179607  0.140523  0.348575  0.331295                 1             1                  1      5    55.835809     55.836309    55.836809            -973.480300  2006-6-09_1-22-43          0.025               pre-delta\n",
       "...        ...       ...       ...       ...       ...       ...       ...       ...               ...           ...                ...    ...          ...           ...          ...                    ...                ...            ...                     ...\n",
       "2884  0.000000  1.000000  0.301627  0.698373  0.000000  0.301627  0.000000  0.698373               409           409                420   2884  1733.816959   1733.817459  1733.817959             704.500850  2006-6-09_1-22-43          0.025              post-delta\n",
       "2885  0.000000  1.000000  0.786629  0.213371  0.000000  0.786629  0.000000  0.213371               409           409                420   2885  1733.841959   1733.842459  1733.842959             704.525850  2006-6-09_1-22-43          0.025              post-delta\n",
       "2886       NaN       NaN       NaN       NaN       NaN       NaN       NaN       NaN               410           410                421   2886  1734.973032   1734.973532  1734.974032             705.656923  2006-6-09_1-22-43          0.025              post-delta\n",
       "2887       NaN       NaN       NaN       NaN       NaN       NaN       NaN       NaN               410           410                421   2887  1734.998032   1734.998532  1734.999032             705.681923  2006-6-09_1-22-43          0.025              post-delta\n",
       "2888  1.000000  0.000000  0.606841  0.393159  0.606841  0.000000  0.393159  0.000000               411           411                422   2888  1736.904796   1736.905296  1736.905796             707.588688  2006-6-09_1-22-43          0.025              post-delta\n",
       "2889  0.000000  1.000000  0.873391  0.126609  0.000000  0.873391  0.000000  0.126609               411           411                422   2889  1736.929796   1736.930296  1736.930796             707.613688  2006-6-09_1-22-43          0.025              post-delta\n",
       "\n",
       "[2890 rows x 19 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "# %aimport pyphoplacecellanalysis.Analysis.Decoder.context_dependent\n",
    "\n",
    "## Get a specific context to plot: \n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=2, decoder_identifier='long_LR', time_bin_size=0.025, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore')\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', time_bin_size=0.025, known_named_decoding_epochs_type='pbe') # , decoder_identifier='long_LR', masked_time_bin_fill_type='ignore', pfND_ndim=2\n",
    "\n",
    "best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_matching_contexts(context_query=a_target_context, debug_print=True)\n",
    "print(f'best_matching_context: {best_matching_context}')\n",
    "a_decoded_marginal_posterior_df\n",
    "## OUTPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ef17ee24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 matches for a_result\n",
      "Found 10 matches for a_decoder\n",
      "Found 4 matches for a_decoded_marginal_posterior_df\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'),\n",
       " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore', data_grain= 'per_epoch'),\n",
       " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'),\n",
       " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'ignore', data_grain= 'per_epoch')]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get a specific context to plot:\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='long_LR', time_bin_size=0.025, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore')\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore') # , decoder_identifier='long_LR'\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, known_named_decoding_epochs_type='laps') # , masked_time_bin_fill_type='ignore', decoder_identifier='long_LR'\n",
    "\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', time_bin_size=0.025) # , known_named_decoding_epochs_type='laps'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "flat_context_list\n",
    "## OUTPUTS: flat_context_list: List[IdentifyingContext], flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict\n",
    "## OUTPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0d8869ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "creating_new_spikes_per_t_bin_masked_variants() got an unexpected keyword argument 'a_target_context'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m spikes_df \u001b[38;5;241m=\u001b[39m deepcopy(get_proper_global_spikes_df(curr_active_pipeline))\n\u001b[1;32m----> 2\u001b[0m a_new_fully_generic_result \u001b[38;5;241m=\u001b[39m \u001b[43ma_new_fully_generic_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreating_new_spikes_per_t_bin_masked_variants\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspikes_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspikes_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_target_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mIdentifyingContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrained_compute_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlaps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpfND_ndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_identifier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpseudo2D\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_bin_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.025\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknown_named_decoding_epochs_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlaps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasked_time_bin_fill_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mignore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_grain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mper_time_bin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m a_new_fully_generic_result\n",
      "\u001b[1;31mTypeError\u001b[0m: creating_new_spikes_per_t_bin_masked_variants() got an unexpected keyword argument 'a_target_context'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "spikes_df = deepcopy(get_proper_global_spikes_df(curr_active_pipeline))\n",
    "a_new_fully_generic_result = a_new_fully_generic_result.creating_new_spikes_per_t_bin_masked_variants(spikes_df=spikes_df, a_target_context=IdentifyingContext(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'))\n",
    "a_new_fully_generic_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50efded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "\n",
    "## Export to CSVs:\n",
    "csv_save_paths = {}\n",
    "\n",
    "# parent_output_path = curr_active_pipeline.get_output_path().resolve() ## Session-specific folder:\n",
    "parent_output_path = collected_outputs_path.resolve() ## Session-specific folder:\n",
    "Assert.path_exists(parent_output_path)\n",
    "\n",
    "## INPUTS: collected_outputs_path\n",
    "decoding_time_bin_size: float = 0.025\n",
    "\n",
    "complete_session_context, (session_context, additional_session_context) = curr_active_pipeline.get_complete_session_context()\n",
    "active_context = complete_session_context\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "earliest_delta_aligned_t_start, t_delta, latest_delta_aligned_t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "tbin_values_dict={'laps': decoding_time_bin_size, 'pbe': decoding_time_bin_size, 'non_pbe': decoding_time_bin_size, 'FAT': decoding_time_bin_size}\n",
    "\n",
    "# csv_save_paths_dict = GenericDecoderDictDecodedEpochsDictResult._perform_export_dfs_dict_to_csvs(extracted_dfs_dict=a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict,\n",
    "csv_save_paths_dict = a_new_fully_generic_result.export_csvs(\n",
    "                                            parent_output_path=parent_output_path.resolve(),\n",
    "                                            active_context=active_context, session_name=session_name, #curr_active_pipeline=curr_active_pipeline,\n",
    "                                            decoding_time_bin_size=decoding_time_bin_size,\n",
    "\t\t\t\t\t\t\t\t\t\t\tcurr_session_t_delta=t_delta\n",
    "                                            )\n",
    "csv_save_paths_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accb2e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoding_time_bin_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce0a9b9",
   "metadata": {
    "tags": [
     "active-2025-03-12"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# INPUTS: a_new_fully_generic_result\n",
    "for ctx, a_df in a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict.items():\n",
    "    print(ctx.get_description(include_property_names=True, separator=\"|\", key_value_separator=':'))\n",
    "    \n",
    "    # a_df\n",
    "    \n",
    "    csv_output_path, out_path_filenname_str, out_path_basename_str = curr_active_pipeline.build_complete_session_identifier_filename_string(output_date_str=BATCH_DATE_TO_USE, data_identifier_str=\"(fucking_results)\", parent_output_path=collected_outputs_path.resolve(), out_extension='.csv')\n",
    "    print(f'\\tout_path_str: \"{out_path_filenname_str}\"')\n",
    "    print(f'\\tout_path: \"{csv_output_path}\"')\n",
    "    \n",
    "    # csv_output_path = Path(f'a_df_{ctx.get_description()}.csv')\n",
    "    a_df.to_csv(out_path)\n",
    "    csv_save_paths[ctx] = csv_output_path\n",
    "    \n",
    "csv_save_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f58ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoded_marginal_posterior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a69f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_man = UserAnnotationsManager()\n",
    "identifying_context_dict = annotations_man.get_hardcoded_specific_session_override_dict()\n",
    "\n",
    "relevant_entries = IdentifyingContext.matching(identifying_context_dict, criteria={'animal': 'vvp01'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022c0648",
   "metadata": {},
   "source": [
    "# <a id='toc22_'></a>[2025-01-09 - Playing with SpikeRaster2D Sort Order and Cell Emphasis](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38fec31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.SpikesRenderingBaseMixin import SpikeEmphasisState\n",
    "\n",
    "\n",
    "set(results1D.decoders['long'].neuron_IDs).difference(set(results1D.decoders['long'].pf.ratemap.neuron_ids))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2b3cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## Example 1: De-emphasize spikes excluded from the placefield calculations:\n",
    "# is_spike_included_in_pf = np.isin(spike_raster_window.spike_raster_plt_2d.spikes_df.index, active_pf_2D.filtered_spikes_df.index)\n",
    "# spike_raster_window.spike_raster_plt_2d.update_spike_emphasis(np.logical_not(is_spike_included_in_pf), SpikeEmphasisState.Deemphasized)\n",
    "\n",
    "\n",
    "## Example 2: De-emphasize spikes that don't have their 'aclu' from a given set of indicies:\n",
    "# is_spike_included = spike_raster_window.spike_raster_plt_2d.spikes_df.aclu.to_numpy() == 2\n",
    "# is_spike_included = np.isin(spike_raster_window.spike_raster_plt_2d.spikes_df.aclu.to_numpy(), track_templates.any_decoder_neuron_IDs)\n",
    "is_spike_included = np.isin(spike_raster_window.spike_raster_plt_2d.spikes_df.aclu.to_numpy(), results1D.decoders['long'].pf.ratemap.neuron_ids)\n",
    "# is_spike_included = np.isin(spike_raster_window.spike_raster_plt_2d.spikes_df.aclu.to_numpy(), [2, 4, 23])\n",
    "# spike_raster_window.spike_raster_plt_2d.update_spike_emphasis(np.logical_not(is_spike_included), SpikeEmphasisState.Deemphasized)\n",
    "spike_raster_window.spike_raster_plt_2d.update_spike_emphasis(np.logical_not(is_spike_included), SpikeEmphasisState.Hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07897ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_spike_included = np.isin(spike_raster_window.spike_raster_plt_2d.spikes_df.aclu.to_numpy(), results1D.decoders['long'].pf.ratemap.neuron_ids)\n",
    "# is_spike_included = np.isin(spike_raster_window.spike_raster_plt_2d.spikes_df.aclu.to_numpy(), [2, 4, 23])\n",
    "spike_raster_window.spike_raster_plt_2d.update_spike_emphasis(is_spike_included, SpikeEmphasisState.Emphasized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89941fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.spike_raster_plt_2d.reset_spike_emphasis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef18afb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import determine_long_short_pf1D_indicies_sort_by_peak\n",
    "\n",
    "## Get 2D or 3D Raster from spike_raster_window\n",
    "active_raster_plot = spike_raster_window.spike_raster_plt_2d # <pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster.Spike2DRaster at 0x196c7244280>\n",
    "if active_raster_plot is None:\n",
    "    active_raster_plot = spike_raster_window.spike_raster_plt_3d # <pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster.Spike2DRaster at 0x196c7244280>\n",
    "    assert active_raster_plot is not None\n",
    "\n",
    "# Sort the neurons by their peak on the long track AND on the short track:\n",
    "included_unit_neuron_IDs = active_raster_plot.neuron_ids\n",
    "new_active_2d_plotter_aclus_LONG_PEAK_sort_indicies = determine_long_short_pf1D_indicies_sort_by_peak(curr_active_pipeline=curr_active_pipeline, curr_any_context_neurons=included_unit_neuron_IDs, sortby=[\"long_pf_peak_x\", \"short_pf_peak_x\", 'neuron_IDX']) # get the neuron_ids to be sorted from the raster plot\n",
    "new_active_2d_plotter_aclus_SHORT_PEAK_sort_indicies = determine_long_short_pf1D_indicies_sort_by_peak(curr_active_pipeline=curr_active_pipeline, curr_any_context_neurons=included_unit_neuron_IDs, sortby=[\"short_pf_peak_x\", \"long_pf_peak_x\", 'neuron_IDX']) # get the neuron_ids to be sorted from the raster plot\n",
    "\n",
    "display(new_active_2d_plotter_aclus_LONG_PEAK_sort_indicies)\n",
    "display(new_active_2d_plotter_aclus_SHORT_PEAK_sort_indicies)\n",
    "# new_active_2d_plotter_aclus_sort_indicies # array([14,  3,  1,  2,  5,  9,  0, 20, 16, 24,  7, 19, 17, 21, 11, 10, 13, 12,  4, 18, 25,  6, 15, 23, 22,  8])\n",
    "\n",
    "# Update the sort order on the Spike2DPlotter to align with the LONG TRACK pf1D field peaks:\n",
    "# active_raster_plot.unit_sort_order = new_active_2d_plotter_aclus_LONG_PEAK_sort_indicies\n",
    "\n",
    "# # Update the sort order on the Spike2DPlotter to align with the SHORT TRACK pf1D field peaks:\n",
    "# active_raster_plot.unit_sort_order = new_active_2d_plotter_aclus_SHORT_PEAK_sort_indicies\n",
    "\n",
    "# # Restore the original sort order of Spike2DPlotter:\n",
    "original_neuron_plotter_aclus_sort_index = np.arange(len(new_active_2d_plotter_aclus_LONG_PEAK_sort_indicies))\n",
    "active_raster_plot.unit_sort_order = original_neuron_plotter_aclus_sort_index\n",
    "\n",
    "# active_2d_plot.unit_sort_order = new_active_2d_plotter_aclus_sort_indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfce17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_templates.any_decoder_neuron_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58b3e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_raster_plot = spike_raster_window.spike_raster_plt_2d # <pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster.Spike2DRaster at 0x196c7244280>\n",
    "\n",
    "spikes_window = active_raster_plot.spikes_window # SpikesDataframeWindow\n",
    "\n",
    "\n",
    "spikes_df: pd.DataFrame = spikes_window.df\n",
    "# spikes_df\n",
    "\n",
    "\n",
    "curr_spike_emphasis_state: SpikeEmphasisState = SpikeEmphasisState.Default\n",
    "# curr_state_pen_dict_map = {aclu:v[2] for aclu, v in active_raster_plot.params.config_items.items()}\n",
    "\n",
    "\n",
    "curr_state_color_map = {aclu:v[2][curr_spike_emphasis_state].color() for aclu, v in active_raster_plot.params.config_items.items()} # [2] is hardcoded and the only element of the tuple used, something legacy I guess\n",
    "# curr_state_color_map\n",
    "\n",
    "# curr_state_pen_dict_map\n",
    "\n",
    "\n",
    "# active_raster_plot.params.config_items[2] #[curr_neuron_id]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9709e487",
   "metadata": {},
   "outputs": [],
   "source": [
    "_raster_tracks_out_dict = active_2d_plot.prepare_pyqtgraph_rasterPlot_track(name_modifier_suffix='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bda3cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import RasterPlotSetupTuple\n",
    "\n",
    "name_modifier_suffix='test'\n",
    "_out = _raster_tracks_out_dict[f'rasters{name_modifier_suffix}']\n",
    "dock_config, time_sync_pyqtgraph_widget, raster_root_graphics_layout_widget, raster_plot_item, rasters_display_outputs_tuple = _out\n",
    "app, win, plots, plots_data = rasters_display_outputs_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a21efcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_plot_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60e1abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots_data.all_spots\n",
    "plots_data.data_keys\n",
    "plots_data.spikes_df['visualization_raster_y_location'].min(), plots_data.spikes_df['visualization_raster_y_location'].max()\n",
    "neuron_y_pos = np.array(list(deepcopy(plots_data.new_sorted_raster.neuron_y_pos).values()))\n",
    "np.min(neuron_y_pos), np.max(neuron_y_pos)\n",
    "\n",
    "# neuron_y_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96682f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup range for plot:\n",
    "# earliest_t, latest_t = active_2d_plot.spikes_window.total_df_start_end_times # global\n",
    "earliest_t, latest_t = active_2d_plot.spikes_window.active_time_window # current\n",
    "raster_plot_item.setXRange(earliest_t, latest_t, padding=0)\n",
    "neuron_y_pos = np.array(list(deepcopy(plots_data.new_sorted_raster.neuron_y_pos).values()))\n",
    "raster_plot_item.setYRange(np.nanmin(neuron_y_pos), np.nanmax(neuron_y_pos), padding=0)\n",
    "\n",
    "# plots.scatter_plot\n",
    "\n",
    "# list(_raster_tracks_out_dict.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2070a19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_sync_pyqtgraph_widget.plots_data\n",
    "\n",
    "np.array(list(deepcopy(time_sync_pyqtgraph_widget.plots_data.new_sorted_raster.neuron_y_pos).values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ebd466",
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_window = active_2d_plot.spikes_window # SpikesDataframeWindow\n",
    "spikes_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c281bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup range for plot:\n",
    "earliest_t, latest_t = active_2d_plot.spikes_window.total_df_start_end_times\n",
    "background_static_scroll_window_plot.setXRange(earliest_t, latest_t, padding=0)\n",
    "background_static_scroll_window_plot.setYRange(np.nanmin(curr_spike_y), np.nanmax(curr_spike_y), padding=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c018787",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spikes_dataSource = spikes_window.dataSource # SpikesDataframeDatasource\n",
    "spikes_dataSource.get_updated_data_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba2aed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import new_plot_raster_plot, NewSimpleRaster\n",
    "\n",
    "# an_included_unsorted_neuron_ids = deepcopy(included_any_context_neuron_ids_dict[a_decoder_name])\n",
    "an_included_unsorted_neuron_ids = deepcopy(unsorted_neuron_IDs_lists[i])\n",
    "a_sorted_neuron_ids = deepcopy(sorted_neuron_IDs_lists[i])\n",
    "\n",
    "unit_sort_order, desired_sort_arr = find_desired_sort_indicies(an_included_unsorted_neuron_ids, a_sorted_neuron_ids)\n",
    "print(f'unit_sort_order: {unit_sort_order}\\ndesired_sort_arr: {desired_sort_arr}')\n",
    "_out_data.unit_sort_orders_dict[a_decoder_name] = deepcopy(unit_sort_order)\n",
    "\n",
    "# Get only the spikes for the shared_aclus:\n",
    "a_spikes_df = deepcopy(spikes_df).spikes.sliced_by_neuron_id(an_included_unsorted_neuron_ids)\n",
    "a_spikes_df, neuron_id_to_new_IDX_map = a_spikes_df.spikes.rebuild_fragile_linear_neuron_IDXs() # rebuild the fragile indicies afterwards\n",
    "\n",
    "\n",
    "rasters_display_outputs = new_plot_raster_plot(a_spikes_df, an_included_unsorted_neuron_ids, unit_sort_order=unit_sort_order, unit_colors_list=deepcopy(unsorted_unit_colors_map), scatter_plot_kwargs=None, scatter_app_name=f'pho_directional_laps_rasters_{title_str}', defer_show=defer_show, active_context=None)\n",
    "# an_app, a_win, a_plots, a_plots_data, an_on_update_active_epoch, an_on_update_active_scatterplot_kwargs = _out_plots.rasters_display_outputs[a_decoder_name]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde920b5",
   "metadata": {},
   "source": [
    "### <a id='toc22_1_1_'></a>[Global Recompute:](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0aecf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# override_time_bin_size: float = 0.025\n",
    "override_time_bin_size: float = 0.058\n",
    "## INPUTS: override_time_bin_size\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "computation_functions_name_kwarg_dict = {\n",
    "'directional_decoders_decode_continuous': {'time_bin_size': override_time_bin_size, 'should_disable_cache': False},\n",
    "}\n",
    "\n",
    "computation_functions_name_includelist = list(computation_functions_name_kwarg_dict.keys())\n",
    "computation_kwargs_list = list(computation_functions_name_kwarg_dict.values())\n",
    "\n",
    "# requires_global_keys=['DirectionalLaps', 'DirectionalMergedDecoders'], provides_global_keys=['DirectionalDecodersDecoded']\n",
    "# ['DirectionalLaps', 'DirectionalMergedDecoders']\n",
    "\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=computation_functions_name_includelist, computation_kwargs_list=computation_kwargs_list, enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acffa8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "override_time_bin_size: float = 0.025\n",
    "# override_time_bin_size: float = 0.058\n",
    "## INPUTS: override_time_bin_size\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "time_bin_size: float = override_time_bin_size\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['merged_directional_placefields', 'directional_decoders_decode_continuous'], # , 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring'\n",
    "                                                   computation_kwargs_list=[{'ripple_decoding_time_bin_size': time_bin_size, 'laps_decoding_time_bin_size': time_bin_size}, {'time_bin_size': time_bin_size},\n",
    "                                                                            # {'should_skip_radon_transform': True},\n",
    "                                                                            # {'same_thresh_fraction_of_track': 0.05, 'max_ignore_bins': 2, 'use_bin_units_instead_of_realworld': False, 'max_jump_distance_cm': 60.0},\n",
    "                                                                             ], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec5e7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum ~10ms\n",
    "\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_evaluate_epochs'], computation_kwargs_list=[{'should_skip_radon_transform': True}], enabled_filter_names=None, fail_on_exception=True, debug_print=True)\n",
    "# ## produces: 'DirectionalDecodersEpochsEvaluations'\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_epoch_heuristic_scoring'], enabled_filter_names=None, fail_on_exception=True, debug_print=False) # OK FOR PICKLE\n",
    "\n",
    "time_bin_size: float = 0.050\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['merged_directional_placefields', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring'],\n",
    "                                                   computation_kwargs_list=[{'ripple_decoding_time_bin_size': time_bin_size, 'laps_decoding_time_bin_size': time_bin_size}, {'time_bin_size': time_bin_size}, {'should_skip_radon_transform': True},\n",
    "                                                                             {'same_thresh_fraction_of_track': 0.05, 'max_ignore_bins': 2, 'use_bin_units_instead_of_realworld': False, 'max_jump_distance_cm': 60.0}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449f099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['position_decoding_two_step'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7559fc34",
   "metadata": {},
   "source": [
    "# üü¢üü¢‚öìüü¢üü¢ <a id='toc23_'></a>[2025-01-27 - Include all activity except the detected PBEs as training data](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "059c3f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs_decoding_time_bin_size = 0.025, frame_divide_bin_size = 10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GeneralDecoderDictDecodedEpochsDictResult(is_global: bool,\n",
       "\tresult_version: str,\n",
       "\t_VersionedResultMixin_version: str,\n",
       "\tfilter_epochs_to_decode_dict: dict,\n",
       "\tfilter_epochs_pseudo2D_continuous_specific_decoded_result: dict,\n",
       "\tfilter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict: dict\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from neuropy.core.epoch import EpochsAccessor, Epoch, ensure_dataframe\n",
    "from pyphocorehelpers.indexing_helpers import partition_df_dict, partition_df        \n",
    "# from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _adding_global_non_PBE_epochs\n",
    "# from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import Compute_NonPBE_Epochs\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import EpochComputationFunctions, EpochComputationsComputationsContainer, DecodingResultND, Compute_NonPBE_Epochs, KnownFilterEpochs\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import EpochComputationsComputationsContainer, KnownNamedDecodingEpochsType\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalDecodersContinuouslyDecodedResult, DecodedFilterEpochsResult, DirectionalPseudo2DDecodersResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import SingleEpochDecodedResult, MaskedTimeBinFillType\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import GeneralDecoderDictDecodedEpochsDictResult\n",
    "from neuropy.core.epoch import Epoch, ensure_dataframe, ensure_Epoch\n",
    "from neuropy.analyses.placefields import PfND\n",
    "\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "\n",
    "## Unpack from pipeline:\n",
    "nonPBE_results: EpochComputationsComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['EpochComputations']\n",
    "a_new_NonPBE_Epochs_obj: Compute_NonPBE_Epochs = nonPBE_results.a_new_NonPBE_Epochs_obj\n",
    "results1D: DecodingResultND = nonPBE_results.results1D\n",
    "results2D: DecodingResultND = nonPBE_results.results2D\n",
    "\n",
    "epochs_decoding_time_bin_size = nonPBE_results.epochs_decoding_time_bin_size\n",
    "frame_divide_bin_size = nonPBE_results.frame_divide_bin_size\n",
    "\n",
    "print(f'{epochs_decoding_time_bin_size = }, {frame_divide_bin_size = }')\n",
    "\n",
    "assert (results1D is not None)\n",
    "assert (results2D is not None)\n",
    "\n",
    "## New computed properties:\n",
    "a_general_decoder_dict_decoded_epochs_dict_result: GeneralDecoderDictDecodedEpochsDictResult = nonPBE_results.a_general_decoder_dict_decoded_epochs_dict_result ## get the pre-decoded result\n",
    "a_general_decoder_dict_decoded_epochs_dict_result\n",
    "\n",
    "\n",
    "# # ==================================================================================================================== #\n",
    "# # 2025-02-20 20:06 New `nonPBE_results._build_merged_joint_placefields_and_decode` method                              #\n",
    "# # ==================================================================================================================== #\n",
    "# non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict, non_PBE_marginal_over_track_ID, (time_bin_containers, time_window_centers, track_marginal_posterior_df) = nonPBE_results._build_merged_joint_placefields_and_decode(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)))\n",
    "# masked_pseudo2D_continuous_specific_decoded_result, _mask_index_tuple = pseudo2D_continuous_specific_decoded_result.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)))\n",
    "# (all_time_bin_indicies, last_valid_indicies) = _mask_index_tuple\n",
    "# masked_pseudo2D_continuous_specific_decoded_result\n",
    "## OUTPUTS: pseudo2D_continuous_specific_decoded_result, non_PBE_marginal_over_track_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e2705a",
   "metadata": {},
   "source": [
    "# <a id='toc24_'></a>[2025-03-04 - Final Histogram](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7a94ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benedict import benedict\n",
    "filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict = benedict(a_general_decoder_dict_decoded_epochs_dict_result.filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict)\n",
    "filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict.keypaths() # ['laps', 'laps.ignore', 'laps.last_valid', 'laps.nan_filled', 'non_pbe', 'non_pbe.ignore', 'non_pbe.last_valid', 'non_pbe.nan_filled', 'pbe', 'pbe.ignore', 'pbe.last_valid', 'pbe.nan_filled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bbf54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "['ignore', 'nan_filled', 'last_valid']\n",
    "['ignore', 'nan_filled', 'last_valid']\n",
    "\n",
    "from attrs import make_class\n",
    "\n",
    "\n",
    "make_class("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cb49e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "template: str = 'plotly_dark' # set plotl template\n",
    "pio.templates.default = template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed73ff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_export_path = Path(r'K:\\scratch\\output').resolve()\n",
    "non_pbe_marginals_PKL_export_path: Path = non_pbe_marginals_export_basepath.with_suffix('.pkl').resolve()\n",
    "a_general_decoder_dict_decoded_epochs_dict_result.save(pkl_output_path=non_pbe_marginals_PKL_export_path)\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26590c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_a_general_decoder_dict_decoded_epochs_dict_result: GeneralDecoderDictDecodedEpochsDictResult =  GeneralDecoderDictDecodedEpochsDictResult.from_file(pkl_path=non_pbe_marginals_PKL_export_path)\n",
    "loaded_a_general_decoder_dict_decoded_epochs_dict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fde2b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_pbe_marginals_export_basepath = parent_export_path.joinpath(f'{BATCH_DATE_TO_USE}_non_pbe_marginals_export')\n",
    "non_pbe_marginals_HDF5_export_path: Path = non_pbe_marginals_export_basepath.with_suffix('.h5').resolve()\n",
    "a_general_decoder_dict_decoded_epochs_dict_result.to_hdf(file_path=non_pbe_marginals_HDF5_export_path, key='a_general_decoder_dict_decoded_epochs_dict_result', debug_print=True) # , OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02555045",
   "metadata": {},
   "outputs": [],
   "source": [
    "## OUTPUTS: flat_context_list: List[IdentifyingContext], flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict\n",
    "## OUTPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc27e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute and plot the new tracks:\n",
    "# non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict, non_PBE_marginal_over_track_ID, (time_bin_containers, time_window_centers) = nonPBE_results._build_merged_joint_placefields_and_decode(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)))\n",
    "unique_added_track_identifiers = nonPBE_results.add_to_SpikeRaster2D_tracks(active_2d_plot=active_2d_plot, non_PBE_all_directional_pf1D_Decoder=non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result=pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict=continuous_decoded_results_dict, non_PBE_marginal_over_track_ID=non_PBE_marginal_over_track_ID, time_window_centers=time_window_centers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8a218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.enable_interaction_events_debug_print = True\n",
    "spike_raster_window.enable_debug_print = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645e0aa6",
   "metadata": {
    "tags": [
     "active-2025-03-11"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import build_single_plotly_marginal_scatter_and_hist_over_time\n",
    "\n",
    "#INPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder\n",
    "_flat_out_figs_dict = {}\n",
    "a_fig, a_figure_context = build_single_plotly_marginal_scatter_and_hist_over_time(a_decoded_posterior_df=a_decoded_marginal_posterior_df, a_target_context=a_target_context)\n",
    "_flat_out_figs_dict[a_figure_context] = a_fig\n",
    "\n",
    "a_fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d39b4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoded_marginal_posterior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ab4b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if 'time_bin_size' not in a_decoded_posterior_df:\n",
    "\t## add the missing column from the context\n",
    "\tfound_time_bin_size: float = a_target_context.get('time_bin_size', None)\n",
    "\tassert found_time_bin_size is not None\n",
    "\ta_decoded_posterior_df['time_bin_size'] = float(found_time_bin_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69dd71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = a_general_decoder_dict_decoded_epochs_dict_result.build_plotly_marginal_scatter_and_hist_over_time()\n",
    "\n",
    "# _flat_out_figs_dict = a_general_decoder_dict_decoded_epochs_dict_result.build_plotly_marginal_scatter_and_hist_over_time(debug_print=False)\n",
    "\n",
    "# display(list(_flat_out_figs_dict.values())[0])\n",
    "\n",
    "# Display all figures in the dictionary\n",
    "for fig in _flat_out_figs_dict.values():\n",
    "    display(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33e4ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_pre_post_delta_scatter\n",
    "## INPUTS: a_general_decoder_dict_decoded_epochs_dict_result\n",
    "\n",
    "histogram_bins: int = 25\n",
    "debug_print = False\n",
    "# 'masked_laps': 'Laps (Masked)', 'masked_laps': 'Laps (Nan-masked)')\n",
    "# masked_bin_fill_modes: ['ignore', 'last_valid', 'nan_filled', 'dropped']\n",
    "\n",
    "_flat_out_figs_dict = {}\n",
    "\n",
    "for a_known_decoded_epochs_type, a_decoded_posterior_dfs_dict in a_general_decoder_dict_decoded_epochs_dict_result.filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict.items():\n",
    "    if debug_print:\n",
    "        print(f'a_known_decoded_epochs_type: \"{a_known_decoded_epochs_type}\"')\n",
    "    for masking_bin_fill_mode, a_decoded_posterior_df in a_decoded_posterior_dfs_dict.items():\n",
    "        if debug_print:\n",
    "            print(f'\\tmasking_bin_fill_mode: \"{masking_bin_fill_mode}\"')\n",
    "        plot_row_identifier: str = f'{a_known_decoded_epochs_type.capitalize()} - {masking_bin_fill_mode.capitalize()} decoder' # should be like 'Laps (Masked) from Non-PBE decoder'\n",
    "        \n",
    "        fig, figure_context = plotly_pre_post_delta_scatter(data_results_df=deepcopy(a_decoded_posterior_df), out_scatter_fig=None, \n",
    "                                        histogram_variable_name='P_Short', hist_kwargs=dict(), histogram_bins=histogram_bins,\n",
    "                                        common_plot_kwargs=dict(),\n",
    "                                        px_scatter_kwargs = dict(x='delta_aligned_start_t', y='P_Short', title=plot_row_identifier))\n",
    "        _flat_out_figs_dict[figure_context] = fig\n",
    "        \n",
    "# ['laps', 'non_PBE']\n",
    "# ['a', 'masked', 'dropping_masked']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b1d063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(list(_flat_out_figs_dict.values())[0])\n",
    "\n",
    "# # Display all figures in the dictionary\n",
    "# for fig in _flat_out_figs_dict.values():\n",
    "#     display(fig)\n",
    "\n",
    "from pyphoplacecellanalysis.External.pyqtgraph.Qt import QtWidgets\n",
    "from pyphoplacecellanalysis.External.pyqtgraph.dockarea import DockArea, Dock\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.PlotlyFigurePyQtWidget import PlotlyDockContainer, PlotlyWidget\n",
    "\n",
    "## INPUTS: _flat_out_figs_dict\n",
    "# Create the container\n",
    "container: PlotlyDockContainer = PlotlyDockContainer()\n",
    "# Display all figures in the dictionary\n",
    "for a_fig_context, fig in _flat_out_figs_dict.items():\n",
    "    container.add_figure(fig, name=f\"{a_fig_context}\", position='bottom')\n",
    "\n",
    "# Show the container\n",
    "container.resize(1200, 800)\n",
    "container.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2b07d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8877a367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7629aca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1406bcd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d06c39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bf036ef",
   "metadata": {},
   "source": [
    "### <a id='toc24_1_1_'></a>[Plotting Tracks on Spike2DRaster](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b821068",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Never used: all at once:\n",
    "a_dock_config = None\n",
    "_out_tuple = active_2d_plot.add_docked_decoded_posterior_track_from_result(name=f'laps_pseudo2D_continuous_specific_decoded_result', a_dock_config=a_dock_config, a_1D_decoded_result=laps_pseudo2D_continuous_specific_decoded_result,\n",
    "                                                                                xbin = deepcopy(non_PBE_all_directional_pf1D_Decoder.xbin), measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "                                                                                extended_dock_title_info='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb37b1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, DockDisplayColors\n",
    "\n",
    "active_time_bin_size: float = pseudo2D_continuous_specific_decoded_result.decoding_time_bin_size\n",
    "info_string: str = f'{active_time_bin_size:.3f}'\n",
    "dock_group_sep_character: str = '_'\n",
    "showCloseButton = True\n",
    "_common_dock_config_kwargs = {'dock_group_names': [dock_group_sep_character.join([f'LapsDecode', info_string])], 'showCloseButton': showCloseButton}\n",
    "dock_configs: Dict[str, CustomDockDisplayConfig] = dict(zip(unique_decoder_names,\n",
    "                        (CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_long_dock_colors, **_common_dock_config_kwargs),\n",
    "                        CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_short_dock_colors, **_common_dock_config_kwargs))))\n",
    "                        \n",
    "\n",
    "pf1D_Decoder_dict = {k:deepcopy(v) for k, v in results1D.decoders.items() if k in unique_decoder_names}\n",
    "\n",
    "output_dict = active_2d_plot.add_docked_decoded_results_dict_tracks(name=f'LapsDecode', a_decoded_result_dict=laps_pseudo2D_split_to_1D_continuous_results_dict, dock_configs=dock_configs, pf1D_Decoder_dict=pf1D_Decoder_dict,\n",
    "                                                                                            measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "                                                                                            extended_dock_title_info=info_string, dockSize=(10, 4))\n",
    "\n",
    "a_dock_config = CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_global_dock_colors, **_common_dock_config_kwargs)\n",
    "marginal_y_p_x_given_n_list = [deepcopy(v.p_x_given_n) for v in laps_pseudo2D_continuous_specific_decoded_result.marginal_y_list]\n",
    "_out_tuple = active_2d_plot.add_docked_decoded_posterior_slices_track(name=f'PBE_marginal_over_track_ID', a_dock_config=a_dock_config,\n",
    "                                                                                slices_time_window_centers=laps_pseudo2D_continuous_specific_decoded_result.time_window_centers, slices_posteriors=marginal_y_p_x_given_n_list,\n",
    "                                                                                xbin=None, xbin_labels=unique_decoder_names, measured_position_df=None, extended_dock_title_info=info_string, posterior_heatmap_imshow_kwargs=dict(), dockSize=(10, 1))\n",
    "output_dict['PBE_marginal_over_track_ID'] = _out_tuple\n",
    "# active_2d_plot.layout_dockGroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44547381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "\n",
    "## INPUTS: masked_laps_pseudo2D_split_to_1D_continuous_results_dict, masked_laps_pseudo2D_continuous_specific_decoded_result\n",
    "_common_dock_config_kwargs = {'dock_group_names': [dock_group_sep_character.join([f'MASKED_LapsDecode', info_string])], 'showCloseButton': showCloseButton}\n",
    "masked_dock_configs: Dict[str, CustomDockDisplayConfig] = dict(zip(unique_decoder_names,\n",
    "                        (CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_long_dock_colors, **_common_dock_config_kwargs),\n",
    "                        CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_short_dock_colors, **_common_dock_config_kwargs))))\n",
    "                        \n",
    "\n",
    "pf1D_Decoder_dict = {k:deepcopy(v) for k, v in results1D.decoders.items() if k in unique_decoder_names}\n",
    "\n",
    "MASKED_output_dict = active_2d_plot.add_docked_decoded_results_dict_tracks(name=f'MASKED_LapsDecode', a_decoded_result_dict=masked_laps_pseudo2D_split_to_1D_continuous_results_dict, dock_configs=masked_dock_configs, pf1D_Decoder_dict=pf1D_Decoder_dict,\n",
    "                                                                                            measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "                                                                                            extended_dock_title_info=info_string, dockSize=(10, 4))\n",
    "\n",
    "a_dock_config = CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_global_dock_colors, **_common_dock_config_kwargs)\n",
    "marginal_y_p_x_given_n_list = [deepcopy(v.p_x_given_n) for v in masked_laps_pseudo2D_continuous_specific_decoded_result.marginal_y_list]\n",
    "_masked_out_tuple = active_2d_plot.add_docked_decoded_posterior_slices_track(name=f'MASKED_PBE_marginal_over_track_ID', a_dock_config=a_dock_config,\n",
    "                                                                                slices_time_window_centers=masked_laps_pseudo2D_continuous_specific_decoded_result.time_window_centers, slices_posteriors=marginal_y_p_x_given_n_list,\n",
    "                                                                                xbin=None, xbin_labels=unique_decoder_names, measured_position_df=None, extended_dock_title_info=info_string, posterior_heatmap_imshow_kwargs=dict(), dockSize=(10, 1))\n",
    "MASKED_output_dict['MASKED_PBE_marginal_over_track_ID'] = _masked_out_tuple\n",
    "# active_2d_plot.layout_dockGroups()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7abd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flat_time_window_centers, flat_marginal_y_p_x_given_n = laps_pseudo2D_continuous_specific_decoded_result.get_pseudo2D_result_to_pseudo2D_marginalization_result(pseudo2D_decoder_names_list=unique_decoder_names) ## this is wrong\n",
    "time_bin_size = epochs_decoding_time_bin_size\n",
    "info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "# identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dock_item = active_2d_plot.add_docked_marginal_track(name='non-PBE_marginal_over_track_ID',\n",
    "#                                                                                         time_window_centers=flat_time_window_centers, a_1D_posterior=flat_marginal_y_p_x_given_n, extended_dock_title_info=info_string)\n",
    "\n",
    "marginal_y_p_x_given_n_list = [deepcopy(v.p_x_given_n) for v in laps_pseudo2D_continuous_specific_decoded_result.marginal_y_list]\n",
    "_out_tuple = active_2d_plot.add_docked_decoded_posterior_slices_track(name=f'PBE_marginal_over_track_ID', a_dock_config=None,\n",
    "                                                                                slices_time_window_centers=laps_pseudo2D_continuous_specific_decoded_result.time_window_centers, slices_posteriors=marginal_y_p_x_given_n_list,\n",
    "                                                                                xbin=None, measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "                                                                                extended_dock_title_info=info_string, posterior_heatmap_imshow_kwargs=dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05b98bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_pseudo2D_continuous_specific_decoded_result.p_x_given_n_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcb7eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timebins, flat_time_bin_containers, timebins_p_x_given_n = laps_pseudo2D_continuous_specific_decoded_result.flatten()\n",
    "\n",
    "desired_total_n_timebins, updated_is_masked_bin, updated_time_bin_containers, updated_timebins_p_x_given_n = laps_pseudo2D_continuous_specific_decoded_result.flatten_to_masked_values()\n",
    "\n",
    "# flat_time_bin_containers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e43cb3",
   "metadata": {},
   "source": [
    "### <a id='toc24_1_2_'></a>[Plotting Histograms Directly](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff6b535",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot: directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_pre_post_delta_scatter\n",
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import plot_histograms\n",
    "\n",
    "## INPUTS: masked_pseudo2D_continuous_specific_decoded_result\n",
    "masked_pseudo2D_continuous_specific_decoded_result = deepcopy(masked_pseudo2D_continuous_specific_decoded_result)\n",
    "ripple_weighted_corr_merged_df\n",
    "\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "## INPUTS: track_marginal_posterior_df\n",
    "\n",
    "# You can use it like this:\n",
    "_out0: \"MatplotlibRenderPlots\" = plot_histograms(data_type='Laps', session_spec='1 Session', data_results_df=track_marginal_posterior_df, time_bin_duration_str=\"25 ms\")\n",
    "# _out1: \"MatplotlibRenderPlots\" = plot_histograms(data_type='Ripples', session_spec='All Sessions', data_results_df=all_sessions_ripple_time_bin_df, time_bin_duration_str=\"75 ms\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20af0225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "\n",
    "if ('DirectionalDecodersEpochsEvaluations' in curr_active_pipeline.global_computation_results.computed_data) and (curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations'] is not None):\n",
    "    directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "    directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)\n",
    "\n",
    "    ## UNPACK HERE via direct property access:\n",
    "    pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "    ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "    laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "    print(f'{pos_bin_size = }, {ripple_decoding_time_bin_size = }, {laps_decoding_time_bin_size = }') # pos_bin_size = 3.8054171165052444, ripple_decoding_time_bin_size = 0.025, laps_decoding_time_bin_size = 0.2\n",
    "    decoder_laps_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict\n",
    "    decoder_ripple_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict\n",
    "    decoder_laps_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_df_dict\n",
    "    decoder_ripple_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_df_dict\n",
    "\n",
    "    # New items:\n",
    "    decoder_laps_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_extras_dict\n",
    "    decoder_ripple_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_extras_dict\n",
    "\n",
    "    # Weighted correlations:\n",
    "    laps_weighted_corr_merged_df = directional_decoders_epochs_decode_result.laps_weighted_corr_merged_df\n",
    "    ripple_weighted_corr_merged_df = directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "    decoder_laps_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_laps_weighted_corr_df_dict\n",
    "    decoder_ripple_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict\n",
    "\n",
    "    # Pearson's correlations:\n",
    "    laps_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.laps_simple_pf_pearson_merged_df\n",
    "    ripple_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603edd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_session_name: str = curr_active_pipeline.session_name # '2006-6-08_14-26-15'\n",
    "CURR_BATCH_OUTPUT_PREFIX: str = f\"{BATCH_DATE_TO_USE}-{curr_session_name}\"\n",
    "print(f'CURR_BATCH_OUTPUT_PREFIX: {CURR_BATCH_OUTPUT_PREFIX}')\n",
    "\n",
    "# active_context = curr_active_pipeline.get_session_context().adding_context_if_missing(custom_\n",
    "\n",
    "# session_name: str = curr_active_pipeline.session_name\n",
    "\n",
    "active_context = curr_active_pipeline.get_session_context()\n",
    "session_name: str = f\"{curr_active_pipeline.session_name}{custom_suffix}\" ## appending this here is a hack, but it makes the correct filename\n",
    "active_context = active_context.adding_context_if_missing(suffix=custom_suffix)\n",
    "session_ctxt_key:str = active_context.get_description(separator='|', subset_includelist=(IdentifyingContext._get_session_context_keys() + ['suffix']))\n",
    "\n",
    "earliest_delta_aligned_t_start, t_delta, latest_delta_aligned_t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "active_context\n",
    "session_ctxt_key\n",
    "# Shifts the absolute times to delta-relative values, as would be needed to draw on a 'delta_aligned_start_t' axis:\n",
    "delta_relative_t_start, delta_relative_t_delta, delta_relative_t_end = np.array([earliest_delta_aligned_t_start, t_delta, latest_delta_aligned_t_end]) - t_delta\n",
    "# decoder_user_selected_epoch_times_dict, any_good_selected_epoch_times = DecoderDecodedEpochsResult.load_user_selected_epoch_times(curr_active_pipeline)\n",
    "# any_good_selected_epoch_indicies = filtered_ripple_simple_pf_pearson_merged_df.epochs.matching_epoch_times_slice(any_good_selected_epoch_times)\n",
    "# df = filter_epochs_dfs_by_annotation_times(curr_active_pipeline, any_good_selected_epoch_times, ripple_decoding_time_bin_size=ripple_decoding_time_bin_size, filtered_ripple_simple_pf_pearson_merged_df, ripple_weighted_corr_merged_df)\n",
    "# df\n",
    "\n",
    "# collected_outputs_path = self.collected_outputs_path.resolve()\n",
    "\n",
    "collected_outputs_path = collected_outputs_path.resolve()\n",
    "\n",
    "## Export CSVs:\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d550bf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "def _update_ripple_df(a_ripple_df):\n",
    "    \"\"\" captures: session_name, t_start, t_delta, t_end, ripple_decoding_time_bin_size \"\"\"\n",
    "    if ('time_bin_size' not in a_ripple_df.columns) and (ripple_decoding_time_bin_size is not None):\n",
    "        ## add the column\n",
    "        a_ripple_df['time_bin_size'] = ripple_decoding_time_bin_size\n",
    "    # Add the maze_id to the active_filter_epochs so we can see how properties change as a function of which track the replay event occured on:\n",
    "    a_ripple_df = DecoderDecodedEpochsResult.add_session_df_columns(a_ripple_df, session_name=session_name, time_bin_size=None, t_start=t_start, curr_session_t_delta=t_delta, t_end=t_end, time_col='ripple_start_t')\n",
    "    return a_ripple_df\n",
    "\n",
    "directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df = _update_ripple_df(directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df)\n",
    "directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df = _update_ripple_df(directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df)\n",
    "    \n",
    "ripple_weighted_corr_merged_df = directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "ripple_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df\n",
    "\n",
    "## UPDATES: directional_decoders_epochs_decode_result\n",
    "## OUTPUTS: ripple_simple_pf_pearson_merged_df, ripple_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127cd14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_simple_pf_pearson_merged_df\n",
    "ripple_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec606dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "# directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict # vector for each decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161d321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_pseudo2D_continuous_specific_decoded_result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fa02d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot: directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_pre_post_delta_scatter\n",
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import plot_histograms\n",
    "\n",
    "## INPUTS: masked_pseudo2D_continuous_specific_decoded_result\n",
    "masked_pseudo2D_continuous_specific_decoded_result = deepcopy(masked_pseudo2D_continuous_specific_decoded_result)\n",
    "ripple_weighted_corr_merged_df\n",
    "\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "# You can use it like this:\n",
    "_out0: \"MatplotlibRenderPlots\" = plot_histograms(data_type='Continuous', session_spec='1 Session', data_results_df=masked_pseudo2D_continuous_specific_decoded_result, time_bin_duration_str=\"25 ms\")\n",
    "# _out1: \"MatplotlibRenderPlots\" = plot_histograms(data_type='Ripples', session_spec='All Sessions', data_results_df=all_sessions_ripple_time_bin_df, time_bin_duration_str=\"75 ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e17e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram_bins = 'auto'\n",
    "histogram_bins: int = 25\n",
    "\n",
    "# ripple_weighted_corr_merged_df = ripple_weighted_corr_merged_df[['P_Short','delta_aligned_start_t', 'time_bin_size']]\n",
    "ripple_weighted_corr_merged_df = ripple_weighted_corr_merged_df[['P_Short','delta_aligned_start_t', 'time_bin_size']]\n",
    "new_ripple_fig, new_ripple_fig_context = plotly_pre_post_delta_scatter(data_results_df=ripple_weighted_corr_merged_df, out_scatter_fig=None, histogram_bins=histogram_bins,\n",
    "                                                                        px_scatter_kwargs=dict(title='Ripple'), histogram_variable_name='P_Short')\n",
    "\n",
    "# new_laps_fig = new_laps_fig.update_layout(fig_size_kwargs, \n",
    "#     xaxis_title=\"X Axis Title\",\n",
    "#     yaxis_title=\"Y Axis Title\",\n",
    "#     legend_title=\"Legend Title\",\n",
    "#     font=dict(\n",
    "#         family=\"Courier New, monospace\",\n",
    "#         size=18,\n",
    "#         color=\"RebeccaPurple\"\n",
    "#     ),\n",
    "# )\n",
    "# Update x-axis labels\n",
    "# new_laps_fig.update_xaxes(title_text=\"Num Time Bins\", row=1, col=1)\n",
    "# new_laps_fig.update_xaxes(title_text=\"Delta-aligned Event Time (seconds)\", row=1, col=2)\n",
    "# new_laps_fig.update_xaxes(title_text=\"Num Time Bins\", row=1, col=3)\n",
    "\n",
    "\n",
    "_extras_output_dict = {}\n",
    "_extras_output_dict[\"y_mid_line\"] = new_ripple_fig.add_hline(y=0.5, line=dict(color=\"rgba(0.8,0.8,0.8,.75)\", width=2), row='all', col='all')\n",
    "\n",
    "new_ripple_fig\n",
    "\n",
    "\n",
    "\n",
    "# # Update layout to add a title to the legend\n",
    "# new_fig_ripples.update_layout(\n",
    "#     legend_title_text='Is User Selected'  # Add a title to the legend\n",
    "# )\n",
    "\n",
    "# fig_to_clipboard(new_fig_ripples, **fig_size_kwargs)\n",
    "\n",
    "# new_laps_fig_context: IdentifyingContext = new_laps_fig_context.adding_context_if_missing(epoch='withNewKamranExportedReplays', num_sessions=num_sessions, plot_type='scatter+hist', comparison='pre-post-delta', variable_name=variable_name)\n",
    "# figure_out_paths = save_plotly(a_fig=new_laps_fig, a_fig_context=new_laps_fig_context)\n",
    "# new_laps_fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dde0e0",
   "metadata": {},
   "source": [
    "We wanted to ensure that there waasn't significant bias in the decoder based on lack of training on the endcaps when the animal was not running, so we isolated all periods excluding those recgonized as PBEs, and built two more 1D decoders based on this information. Since running direction is not well-defined on the endcaps (where the rat is mostly stationary or moving slowly), this variant of our Pseudo2D decoder only considered the two trackID contexts (Long vs. Short)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59a55fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_PBE_marginal_over_track_ID # (2, 44887) - which track it's using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a48222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import find_epochs_overlapping_other_epochs\n",
    "\n",
    "# INPUTS: track_marginal_posterior_df\n",
    "\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "global_session = curr_active_pipeline.filtered_sessions[global_epoch_name]\n",
    "\n",
    "# global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps) # .trimmed_to_non_overlapping()\n",
    "global_laps_epochs_df = global_laps.to_dataframe()\n",
    "# active_test_epochs_df: pd.DataFrame = deepcopy(global_laps_epochs_df)\n",
    "global_laps_epochs_df\n",
    "\n",
    "\n",
    "# global_laps_epochs_df\n",
    "is_included: NDArray = find_epochs_overlapping_other_epochs(epochs_df=track_marginal_posterior_df, epochs_df_required_to_overlap=deepcopy(global_laps_epochs_df))\n",
    "track_marginal_posterior_df['is_in_laps'] = is_included\n",
    "track_marginal_posterior_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ad6c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_PBE_marginal_over_track_ID.shape # (2, 44887) - which track it's using\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01fe90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window_centers.shape # (44887,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9176dca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build into a marginal df like `all_sessions_laps_df`:\n",
    "track_marginal_posterior_df : pd.DataFrame = pd.DataFrame({'t':deepcopy(time_window_centers), 'P_Long': np.squeeze(non_PBE_marginal_over_track_ID[0, :]), 'P_Short': np.squeeze(non_PBE_marginal_over_track_ID[1, :]), 'time_bin_size': pseudo2D_continuous_specific_decoded_result.decoding_time_bin_size})\n",
    "track_marginal_posterior_df['delta_aligned_start_t'] = track_marginal_posterior_df['t'] - t_delta ## subtract off t_delta\n",
    "track_marginal_posterior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af44479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "template: str = 'plotly_dark' # set plotl template\n",
    "pio.templates.default = template\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_pre_post_delta_scatter\n",
    "\n",
    "\n",
    "histogram_bins: int = 25\n",
    "\n",
    "# new_laps_fig = plotly_pre_post_delta_scatter(data_results_df=deepcopy(all_sessions_laps_df), out_scatter_fig=fig_laps, histogram_bins=histogram_bins, px_scatter_kwargs = dict(title='Laps'))\n",
    "fig, figure_context = plotly_pre_post_delta_scatter(data_results_df=deepcopy(track_marginal_posterior_df)[['delta_aligned_start_t', 'P_Long', 'time_bin_size']], out_scatter_fig=None, histogram_bins=histogram_bins, px_scatter_kwargs = dict(title='Continuous'))\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bf545c",
   "metadata": {},
   "source": [
    "# <a id='toc25_'></a>[‚öìüü¢üéØ 2025-02-20 - Compute Merged Placefields for Non-PBE Epochs for Long/Short](#toc0_)\n",
    "[/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/DirectionalPlacefieldGlobalComputationFunctions.py:5680](vscode://file/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/DirectionalPlacefieldGlobalComputationFunctions.py:5680)\n",
    "```python\n",
    "# From `General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions._build_merged_directional_placefields`\n",
    "def _build_merged_directional_placefields(owning_pipeline_reference, global_computation_results, computation_results, active_configs, include_includelist=None, debug_print=False,\n",
    "                                                laps_decoding_time_bin_size: float = 0.250, # 250ms\n",
    "                                                ripple_decoding_time_bin_size: float = 0.025, # 25ms\n",
    "                                                should_validate_lap_decoding_performance: bool = False,\n",
    "                                            ):\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbab5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = Path(r\"K:/scratch/output/videos\").resolve()\n",
    "# out_path = Path(r\"output/videos/\").resolve()\n",
    "out_path.mkdir(exist_ok=True, parents=True)\n",
    "assert out_path.exists()\n",
    "out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0b1d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9abc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "track_suffix: int = 'long'\n",
    "a_decoder_continuously_decoded_result: DecodedFilterEpochsResult = continuous_decoded_results_dict.get(track_suffix, None)\n",
    "# a_decoder_continuously_decoded_result: DecodedFilterEpochsResult = continuous_decoded_results_dict.get('short', None)\n",
    "# PosteriorExporting.save_posterior_to_video(a_decoder_continuously_decoded_result=a_decoder_continuously_decoded_result, result_name='non_pbe_continuous_long')\n",
    "PosteriorExporting.save_posterior_to_video(a_decoder_continuously_decoded_result=pseudo2D_continuous_specific_decoded_result, result_name=f'non_pbe_continuous_pseudo2D_{track_suffix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3519fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a3b13c7",
   "metadata": {},
   "source": [
    "### <a id='toc25_1_1_'></a>[üößüîú 2025-02-26 -  Plot 1D pseudo2D Continuous Decodings and their marginals over TrackID on SpikeRaster2D track - uses `AddNewDecodedPosteriors_MatplotlibPlotCommand.prepare_and_perform_custom_decoder_decoded_epochs(...)`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9569f931",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_bin_size = epochs_decoding_time_bin_size\n",
    "info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dock_item = active_2d_plot.add_docked_marginal_track(name='non-PBE_marginal_over_track_ID',\n",
    "                                                                                        time_window_centers=time_window_centers, a_1D_posterior=non_PBE_marginal_over_track_ID, extended_dock_title_info=info_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfd6308",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_decoded_results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94401b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AddNewDecodedEpochMarginal_MatplotlibPlotCommand._perform_add_new_decoded_posterior_marginal_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4f1cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dock all Grouped results from `'DockedWidgets.Pseudo2DDecodedEpochsDockedMatplotlibView'`\n",
    "## INPUTS: active_2d_plot\n",
    "nested_dock_items, nested_dynamic_docked_widget_container_widgets = active_2d_plot.ui.dynamic_docked_widget_container.layout_dockGroups()\n",
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e99ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83e6f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "an_ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d58a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_ax.remove(line_measured_position)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e7c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_sess = curr_active_pipeline.sess\n",
    "active_sess = curr_active_pipeline.filtered_sessions[global_epoch_name]\n",
    "\n",
    "# active_sess.position\n",
    "\n",
    "a_pf2D = global_pf2D\n",
    "(a_pf2D.n_xbin_centers, a_pf2D.n_ybin_centers)\n",
    "a_pf2D.dims_coord_tuple\n",
    "a_pf2D.n_flattened_position_bins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a288f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_sess.neurons.n_neurons\n",
    "active_sess.neurons.t_start\n",
    "active_sess.neurons.t_stop\n",
    "active_sess.duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfef5a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['perform_compute_non_PBE_epochs'], computation_kwargs_list=[dict(epochs_decoding_time_bin_size=0.050, frame_divide_bin_size=0.250, compute_1D=True, compute_2D=False, drop_previous_result_and_compute_fresh=True)], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6931df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_results = curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['non_PBE_epochs_results'], computation_kwargs_list=[dict(epochs_decoding_time_bin_size=0.025, frame_divide_bin_size=5.0, compute_1D=True, compute_2D=False, drop_previous_result_and_compute_fresh=True, skip_training_test_split=False)],\n",
    "                                                                                                                                            enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3232a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['non_PBE_epochs_results'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb2b869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs_decoding_time_bin_size = 0.050\n",
    "# subdivide_bin_size = 0.250\n",
    "\n",
    "epochs_decoding_time_bin_size = 1.0\n",
    "subdivide_bin_size = 1.0\n",
    "\n",
    "_out_results = curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['non_PBE_epochs_results'], computation_kwargs_list=[dict(epochs_decoding_time_bin_size=epochs_decoding_time_bin_size, frame_divide_bin_size=subdivide_bin_size, compute_1D=True, compute_2D=True, drop_previous_result_and_compute_fresh=False)],\n",
    "                                                                                                                                            enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b0a25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_result = results2D.frame_divided_epochs_results['global'] \n",
    "# a_result.p_x_given_n_list\n",
    "a_result.n_pos_bins\n",
    "a_result.nbins\n",
    "a_result.pos_bin_edges\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b103e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [np.shape(v) for v in a_result.p_x_given_n_list]\n",
    "\n",
    "np.sum([np.prod(np.shape(v)) for v in a_result.p_x_given_n_list])\n",
    "\n",
    "# np.vstack([np.shape(v) for v in a_result.p_x_given_n_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464af0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData, loadData\n",
    "\n",
    "# output_save_parent_path: Path = Path(r\"C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\data\").resolve()\n",
    "output_save_parent_path: Path = curr_active_pipeline.get_output_path().resolve()\n",
    "# hdf5_output_path: Path = curr_active_pipeline.get_output_path().joinpath('2025-02-14_results_nonPBEDecoding_2D.h5')\n",
    "# pkl_output_path: Path = output_save_parent_path.joinpath('2025-02-18_results_EpochComputations_nonPBEDecoding.pkl')\n",
    "pkl_output_path: Path = output_save_parent_path.joinpath('2025-02-20_results_EpochComputations_nonPBEDecoding.pkl')\n",
    "print(f'pkl_output_path: \"{pkl_output_path}\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5d8014",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "saveData(pkl_output_path, nonPBE_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad5e355",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load from pickle:\n",
    "print(f'pkl_output_path: {pkl_output_path}')\n",
    "nonPBE_results = loadData(pkl_path=pkl_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a670f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "## usually you want to load it into the pipeline:\n",
    "curr_active_pipeline.global_computation_results.computed_data['EpochComputations'] = nonPBE_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed322671",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import SingleEpochDecodedResult\n",
    "\n",
    "## Extract the continuous decoding result:\n",
    "global_continuous_decoded_epochs_result2D: DecodedFilterEpochsResult = continuous_specific_decoded_results2D_dict['global']\n",
    "assert len(global_continuous_decoded_epochs_result2D.p_x_given_n_list) == 1\n",
    "a_continuous_decoded_result2D: SingleEpochDecodedResult = global_continuous_decoded_epochs_result2D.get_result_for_epoch(0)\n",
    "p_x_given_n2D = global_continuous_decoded_epochs_result2D.p_x_given_n_list[0]\n",
    "time_bin_containers = global_continuous_decoded_epochs_result2D.time_bin_containers[0]\n",
    "time_window_centers = time_bin_containers.centers\n",
    "# measured_positions_list = partition_df(global_pos_df, partitionColumn='global_subdivision_idx')\n",
    "# len(measured_positions_list)\n",
    "# measured_positions_list\n",
    "\n",
    "## OUTPUTS: global_continuous_decoded_epochs_result2D, a_continuous_decoded_result2D, p_x_given_n2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8177d4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_2d_plot.add_rendered_intervals(a_new_training_df, name=f'GlobalNonPBE_TRAIN')\n",
    "# active_2d_plot.add_rendered_intervals(a_new_test_df, name=f'GlobalNonPBE_TEST')\n",
    "\n",
    "# vis_column_kwarg_keys = ['y_location', 'height', 'pen_color', 'brush_color']\n",
    "\n",
    "# shared_kwargs = {'y_location': -5.0, 'height': 0.9}\n",
    "\n",
    "# active_2d_plot.update_rendered_intervals_visualization_properties({\n",
    "#     # 'GlobalNonPBE':dict(pen_color=inline_mkColor('green', 0.8), brush_color=inline_mkColor('green', 0.5), **shared_kwargs),\n",
    "# \t'GlobalNonPBE_TRAIN':dict(pen_color=inline_mkColor('purple', 0.8), brush_color=inline_mkColor('purple', 0.5), **shared_kwargs),\n",
    "# \t'GlobalNonPBE_TEST':dict(pen_color=inline_mkColor('pink', 0.8), brush_color=inline_mkColor('pink', 0.5), **shared_kwargs),\n",
    "# })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fd04bc",
   "metadata": {},
   "source": [
    "# <a id='toc26_'></a>[PyQtGraph rendering](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259294d2",
   "metadata": {},
   "source": [
    "### <a id='toc26_1_1_'></a>[BinByBinDecodingDebugger](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cb09bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.Extensions.pyqtgraph_helpers import LayoutScrollability\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.BinByBinDecodingDebugger import BinByBinDecodingDebugger \n",
    "from pyphoplacecellanalysis.General.Model.TimeWindow import TimeWindow, TimeWindowOwningMixin\n",
    "from pyphoplacecellanalysis.General.Model.SpikesDataframeWindow import SpikesDataframeWindow, SpikesWindowOwningMixin\n",
    "from pyphocorehelpers.DataStructure.general_parameter_containers import VisualizationParameters, RenderPlotsData, RenderPlots # PyqtgraphRenderPlots\n",
    "from pyphocorehelpers.DataStructure.RenderPlots.PyqtgraphRenderPlots import PyqtgraphRenderPlots\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.BinByBinDecodingDebugger import BinByBinDebuggingData\n",
    "\n",
    "# a_decoder_name = 'long'\n",
    "\n",
    "# ## 2D:\n",
    "# ## INPUTS: results2D\n",
    "# a_decoded_result: DecodedFilterEpochsResult = deepcopy(results2D.continuous_results[a_decoder_name])\n",
    "# a_decoder = deepcopy(results2D.decoders[a_decoder_name])\n",
    "\n",
    "# ## 1D: \n",
    "# ## INPUTS: results1D\n",
    "# a_decoded_result: DecodedFilterEpochsResult = deepcopy(results1D.continuous_results[a_decoder_name])\n",
    "# a_decoder = deepcopy(results1D.decoders[a_decoder_name])\n",
    "\n",
    "\n",
    "a_decoder_name: str = 'long_LR'\n",
    "# a_decoder_name: str = 'short_LR'\n",
    "## Uses the `global_computation_results.computed_data['DirectionalDecodersDecoded']`\n",
    "directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "pseudo2D_decoder: BasePositionDecoder = directional_decoders_decode_result.pseudo2D_decoder        \n",
    "# all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "# continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "continuously_decoded_dict = directional_decoders_decode_result.most_recent_continuously_decoded_dict\n",
    "pseudo2D_decoder_continuously_decoded_result: DecodedFilterEpochsResult = continuously_decoded_dict.get('pseudo2D', None)\n",
    "a_decoded_result: DecodedFilterEpochsResult = deepcopy(continuously_decoded_dict[a_decoder_name])\n",
    "a_decoder = deepcopy(directional_decoders_decode_result.pf1D_Decoder_dict[a_decoder_name])\n",
    "\n",
    "\n",
    "neuron_IDs = deepcopy(a_decoder.neuron_IDs)\n",
    "global_spikes_df = get_proper_global_spikes_df(curr_active_pipeline).spikes.sliced_by_neuron_id(neuron_IDs) ## only get the relevant spikes\n",
    "## OUTPUTS: neuron_IDs, global_spikes_df, active_window_time_bins\n",
    "\n",
    "active_spikes_window = active_2d_plot.spikes_window\n",
    "decoding_time_bin_size: float = a_decoded_result.decoding_time_bin_size\n",
    "single_continuous_result: SingleEpochDecodedResult = a_decoded_result.get_result_for_epoch(0) # SingleEpochDecodedResult\n",
    "decoding_bins_epochs_df: pd.DataFrame = single_continuous_result.build_pseudo_epochs_df_from_decoding_bins().epochs.get_valid_df()\n",
    "bin_by_bin_data: BinByBinDebuggingData = BinByBinDebuggingData.init_from_single_continuous_result(a_decoder=a_decoder, global_spikes_df=global_spikes_df, single_continuous_result=single_continuous_result, decoding_time_bin_size=decoding_time_bin_size, n_max_debugged_time_bins=25)\n",
    "## OUTPUTS: bin_by_bin_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54151396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_decoded_result\n",
    "# a_decoder.get_debug_binning_info()\n",
    "# len(a_decoder.pf.included_neuron_IDs[0])\n",
    "a_spkcount: NDArray = deepcopy(a_decoded_result.spkcount[0]) # (n_neurons, n_time_bins)\n",
    "\n",
    "n_active_aclus_per_t_bin = np.sum((a_spkcount > 0), axis=0)\n",
    "n_active_aclus_per_t_bin\n",
    "\n",
    "invalid_t_bin_mask = (n_active_aclus_per_t_bin < 1)\n",
    "invalid_t_bin_mask\n",
    "\n",
    "\n",
    "\n",
    "# a_spkcount.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269acb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_decoded_result\n",
    "a_decoder.num_neurons\n",
    "len(a_decoder.neuron_IDs)\n",
    "# a_decoder.ratemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99590724",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: active_spikes_window, global_spikes_df, decoding_bins_epochs_df\n",
    "## Slice to current window:\n",
    "active_window_t_start, active_window_t_end = active_spikes_window.active_time_window\n",
    "print(f'active_window_t_start: {active_window_t_start}, active_window_t_end: {active_window_t_end}')\n",
    "active_global_spikes_df, active_window_decoded_epochs_df, active_epoch_active_aclu_spike_counts_list, (active_window_slice_idxs, active_window_time_bin_edges, active_p_x_given_n) = bin_by_bin_data.sliced_to_current_window(active_window_t_start, active_window_t_end)\n",
    "\n",
    "## OUTPUTS: active_window_slice_idxs, active_window_time_bin_edges, active_p_x_given_n\n",
    "\n",
    "## OUTPUTS: active_global_spikes_df, active_window_decoded_epochs_df, active_epoch_active_aclu_spike_counts_list\n",
    "\n",
    "## INPUTS: neuron_IDs, (active_global_spikes_df, active_window_decoded_epochs_df, active_aclu_spike_counts_dict_list)\n",
    "## INPUTS: active_window_slice_idxs, active_window_time_bin_edges, active_p_x_given_n\n",
    "plots_container = PyqtgraphRenderPlots(name='PhoTest', root_plot=None) # Create a new one\n",
    "plots_data = RenderPlotsData(name=f'epoch[Test]', spikes_df=active_global_spikes_df, a_decoder=a_decoder, active_aclus=neuron_IDs, bin_by_bin_data=bin_by_bin_data)\n",
    "win, out_pf1D_decoder_template_objects, (plots_container, plots_data) = BinByBinDecodingDebugger._perform_build_time_binned_decoder_debug_plots(a_decoder=a_decoder, time_bin_edges=active_window_time_bin_edges, p_x_given_n=active_p_x_given_n, active_epoch_active_aclu_spike_counts_list=active_epoch_active_aclu_spike_counts_list,\n",
    "                                                                                                                            plots_data=plots_data, plots_container=plots_container,\n",
    "                                                                                                                            debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dab324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later when data changes:\n",
    "## INPUTS: active_spikes_window, global_spikes_df, decoding_bins_epochs_df\n",
    "## Slice to current window:\n",
    "active_window_t_start, active_window_t_end = active_spikes_window.active_time_window\n",
    "print(f'active_window_t_start: {active_window_t_start}, active_window_t_end: {active_window_t_end}')\n",
    "active_global_spikes_df, active_window_decoded_epochs_df, active_epoch_active_aclu_spike_counts_list, (active_window_slice_idxs, active_window_time_bin_edges, active_p_x_given_n) = bin_by_bin_data.sliced_to_current_window(active_window_t_start, active_window_t_end)\n",
    "\n",
    "\n",
    "win, template_objs, (plots_container, plots_data) = BinByBinDecodingDebugger.update_time_binned_decoder_debug_plots(win, out_pf1D_decoder_template_objects, plots_container, plots_data, new_time_bin_edges=active_window_time_bin_edges, new_p_x_given_n=active_p_x_given_n, new_active_aclu_spike_counts_list=active_epoch_active_aclu_spike_counts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfcfce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f9370c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# (_out_decoded_time_bin_edges, _out_decoded_unit_specific_time_binned_spike_counts, _out_decoded_active_unit_lists, _out_decoded_active_p_x_given_n, _out_decoded_active_plots_data) = BinByBinDecodingDebugger.build_spike_counts_and_decoder_outputs(a_decoder=a_decoder, epochs_df=active_window_decoded_epochs_df,\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   epoch_id_col_name='rel_epoch_idx', spikes_df=active_global_spikes_df,\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   time_bin_size=time_bin_size)\n",
    "\n",
    "\n",
    "## ~10 seconds\n",
    "## OUTPUTS: _out_decoded_time_bin_edges, _out_decoded_unit_specific_time_binned_spike_counts, _out_decoded_active_unit_lists, _out_decoded_active_p_x_given_n, _out_decoded_active_plots_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bf8214",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_decoded_active_unit_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344da9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.DataStructure.general_parameter_containers import VisualizationParameters, RenderPlotsData, RenderPlots # PyqtgraphRenderPlots\n",
    "from pyphocorehelpers.DataStructure.RenderPlots.PyqtgraphRenderPlots import PyqtgraphRenderPlots\n",
    "\n",
    "## INPUTS: _out_decoded_time_bin_edges, _out_decoded_unit_specific_time_binned_spike_counts, _out_decoded_active_unit_lists, _out_decoded_active_p_x_given_n, _out_decoded_active_plots_data\n",
    "an_epoch_id: int = 0\n",
    "active_epoch_active_aclu_spike_counts_list = _out_decoded_active_unit_lists[an_epoch_id]\n",
    "time_bin_edges = _out_decoded_time_bin_edges[an_epoch_id]\n",
    "most_likely_positions, p_x_given_n, most_likely_position_indicies, flat_outputs_container = _out_decoded_active_p_x_given_n[an_epoch_id]\n",
    "plots_data = _out_decoded_active_plots_data[an_epoch_id]\n",
    "plots_container = PyqtgraphRenderPlots(name=an_epoch_id, root_plot=None) # Create a new one\n",
    "# plots_data = RenderPlotsData(name=f'epoch[{an_epoch_id}]', spikes_df=epoch_specific_spikes_df, active_aclus=all_lap_active_units_list)\n",
    "win, out_pf1D_decoder_template_objects, (plots_container, plots_data) = BinByBinDecodingDebugger._perform_build_time_binned_decoder_debug_plots(a_decoder=a_decoder, time_bin_edges=time_bin_edges, p_x_given_n=p_x_given_n, active_epoch_active_aclu_spike_counts_list=active_epoch_active_aclu_spike_counts_list,\n",
    "                                                                                                                            plots_data=plots_data, plots_container=plots_container,\n",
    "                                                                                                                            debug_print=False)\n",
    "## Assign the outputs:\n",
    "# _out_decoded_active_plots[an_epoch_id] = plots_container\n",
    "# _out_decoded_active_plots_data[an_epoch_id] = plots_data\n",
    "\n",
    "\n",
    "## OUTPUTS: plots_container, plots_data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# win.nextRow()\n",
    "win.setWindowTitle('BinByBinDecodingDebugger')\n",
    "win.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da806e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_epoch_active_aclu_spike_counts_list = _out_decoded_active_unit_lists[an_epoch_id]\n",
    "time_bin_edges = _out_decoded_time_bin_edges[an_epoch_id]\n",
    "most_likely_positions, p_x_given_n, most_likely_position_indicies, flat_outputs_container = _out_decoded_active_p_x_given_n[an_epoch_id]\n",
    "plots_data = _out_decoded_active_plots_data[an_epoch_id]\n",
    "plots_container = PyqtgraphRenderPlots(name=an_epoch_id, root_plot=None) # Create a new one\n",
    "# plots_data = RenderPlotsData(name=f'epoch[{an_epoch_id}]', spikes_df=epoch_specific_spikes_df, active_aclus=all_lap_active_units_list)\n",
    "win, out_pf1D_decoder_template_objects, (plots_container, plots_data) = BinByBinDecodingDebugger._perform_build_time_binned_decoder_debug_plots(a_decoder=a_decoder, time_bin_edges=time_bin_edges, p_x_given_n=p_x_given_n, active_epoch_active_aclu_spike_counts_list=active_epoch_active_aclu_spike_counts_list,\n",
    "                                                                                                                            plots_data=plots_data, plots_container=plots_container,\n",
    "                                                                                                                            debug_print=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7593e49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "win, out_pf1D_decoder_template_objects, (_out_decoded_active_plots, _out_decoded_active_plots_data) = BinByBinDecodingDebugger.build_time_binned_decoder_debug_plots(a_decoder=a_decoder, an_epoch_id=an_epoch_id, _out_decoded_time_bin_edges=_out_decoded_time_bin_edges,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  _out_decoded_active_p_x_given_n=_out_decoded_active_p_x_given_n, _out_decoded_active_unit_lists=_out_decoded_active_unit_lists, _out_decoded_active_plots_data=_out_decoded_active_plots_data,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  debug_print=True)\n",
    "\n",
    "## All-in-one mode:\n",
    "# win, out_pf1D_decoder_template_objects, (_out_decoded_active_plots, _out_decoded_active_plots_data) = BinByBinDecodingDebugger.plot_bin_by_bin_decoding_example(curr_active_pipeline=curr_active_pipeline, a_decoder=a_decoder, time_bin_size=time_bin_size, an_epoch_id=an_epoch_id)\n",
    "\n",
    "print(f\"Returned window: {win}\")\n",
    "print(f\"Returned decoder objects: {out_pf1D_decoder_template_objects}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54af217",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage:\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "global_spikes_df = get_proper_global_spikes_df(curr_active_pipeline)\n",
    "\n",
    "# global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "# global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps).trimmed_to_non_overlapping() \n",
    "# global_laps_epochs_df = global_laps.to_dataframe()\n",
    "# an_epochs_df = deepcopy(global_laps_epochs_df)\n",
    "\n",
    "## INPUTS: \n",
    "# time_bin_size: float = 0.250\n",
    "# an_epoch_id: int = 9\n",
    "# a_decoder_name = 'long_LR'\n",
    "\n",
    "# time_bin_size: float = 0.025 # 25ms\n",
    "# an_epochs_df = deepcopy(global_laps_epochs_df)\n",
    "an_epochs_df = deepcopy(decoding_bins_epochs_df)\n",
    "## COMPUTED: \n",
    "# a_decoder_idx: int = track_templates.get_decoder_names().index(a_decoder_name)\n",
    "# a_decoder = deepcopy(track_templates.long_LR_decoder)\n",
    "\n",
    "# a_decoder_idx: int = list(results2D.decoders.keys()).index(a_decoder_name)\n",
    "# a_decoder = deepcopy(results2D.decoders[a_decoder_name])\n",
    "\n",
    "# (_out_decoded_time_bin_edges, _out_decoded_unit_specific_time_binned_spike_counts, _out_decoded_active_unit_lists, _out_decoded_active_p_x_given_n, _out_decoded_active_plots_data) = BinByBinDecodingDebugger.build_spike_counts_and_decoder_outputs(a_decoder=a_decoder, epochs_df=global_laps_epochs_df, epoch_id_col_name='lap_id', spikes_df=global_spikes_df, time_bin_size=time_bin_size)\n",
    "(_out_decoded_time_bin_edges, _out_decoded_unit_specific_time_binned_spike_counts, _out_decoded_active_unit_lists, _out_decoded_active_p_x_given_n, _out_decoded_active_plots_data) = BinByBinDecodingDebugger.build_spike_counts_and_decoder_outputs(a_decoder=a_decoder, epochs_df=an_epochs_df, epoch_id_col_name='label', spikes_df=global_spikes_df, time_bin_size=time_bin_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b145c4d0",
   "metadata": {},
   "source": [
    "### <a id='toc26_1_2_'></a>[`DataSlicingVisualizer` - 2D Decoded Posterior Visualizer](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13e42e8",
   "metadata": {
    "tags": [
     "2025-03-09_time_bin_masking"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import DataSlicingVisualizer\n",
    "\n",
    "## INPUTS: results2D\n",
    "a_decoder_name = 'long'\n",
    "\n",
    "## 2D:\n",
    "## INPUTS: results2D\n",
    "a_decoded_result: DecodedFilterEpochsResult = deepcopy(results2D.continuous_results[a_decoder_name])\n",
    "a_decoder = deepcopy(results2D.decoders[a_decoder_name])\n",
    "\n",
    "# ## 1D: \n",
    "# ## INPUTS: results1D\n",
    "# a_decoded_result: DecodedFilterEpochsResult = deepcopy(results1D.continuous_results[a_decoder_name])\n",
    "# a_decoder = deepcopy(results1D.decoders[a_decoder_name])\n",
    "\n",
    "decoding_time_bin_size: float = a_decoded_result.decoding_time_bin_size\n",
    "\n",
    "## get masked result using last-good-fill method:\n",
    "a_decoded_result\n",
    "## INPUTS: a_decoded_result\n",
    "type(a_decoded_result)\n",
    "\n",
    "## Testing masking with last-good-bin-fill:\n",
    "spikes_df: pd.DataFrame = deepcopy(get_proper_global_spikes_df(curr_active_pipeline))\n",
    "a_maksed_decoded_result, a_mask_index_tuple = a_decoded_result.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)))\n",
    "# (is_time_bin_active_list, inactive_mask_list, all_time_bin_indicies_list, last_valid_indices_list) = mask_index_tuple\n",
    "a_maksed_decoded_result\n",
    "\n",
    "# active_decoded_result = deepcopy(a_decoded_result)\n",
    "active_decoded_result = deepcopy(a_maksed_decoded_result)\n",
    "\n",
    "single_continuous_result: SingleEpochDecodedResult = active_decoded_result.get_result_for_epoch(0) # SingleEpochDecodedResult\n",
    "decoding_bins_epochs_df: pd.DataFrame = single_continuous_result.build_pseudo_epochs_df_from_decoding_bins().epochs.get_valid_df()\n",
    "time_bin_edges = deepcopy(single_continuous_result.time_bin_edges)\n",
    "p_x_given_n: NDArray = deepcopy(single_continuous_result.p_x_given_n)\n",
    "\n",
    "print(f'p_x_given_n.shape: {np.shape(p_x_given_n)}')\n",
    "# active_decoded_result.filter_epochs\n",
    "# active_decoded_result.spkcount\n",
    "\n",
    "## OUTPUTS: decoding_bins_epochs_df, time_bin_edges, p_x_given_n, decoding_time_bin_size\n",
    "\n",
    "## INPUTS: time_bin_edges, p_x_given_n\n",
    "measured_pos_df: pd.DataFrame = deepcopy(curr_active_pipeline.sess.position.to_dataframe())\n",
    "# p_x_given_n.shape # (59, 8, 103512)\n",
    "visualizer: DataSlicingVisualizer = DataSlicingVisualizer(time_bin_edges=time_bin_edges, data=p_x_given_n, measured_df=measured_pos_df, x_bin_edges=a_decoder.xbin, y_bin_edges=a_decoder.ybin)\n",
    "visualizer.set_data(time_bin_edges=time_bin_edges, new_data=p_x_given_n)\n",
    "visualizer.show()\n",
    "\n",
    "# connect_controlled_time_synchronized_plotter\n",
    "\n",
    "\n",
    "# _connection = active_2d_plot.sigWindowChanged.connect(visualizer.on_window_changed)\n",
    "\n",
    "# spike_raster_window.connection_man\n",
    "# controlled_plt = visualizer\n",
    "# _out_conn = spike_raster_window.connection_man.connect_drivable_to_driver(drivable=controlled_plt, driver=spike_raster_window.spike_raster_plt_2d,\n",
    "#                                                         custom_connect_function=(lambda driver, drivable: pg.SignalProxy(driver.window_scrolled, delay=0.2, rateLimit=30, slot=drivable.on_window_changed)))\n",
    "_out_conn = spike_raster_window.spike_raster_plt_2d.window_scrolled.connect(lambda start_t, end_t: visualizer.on_window_changed(start_t=start_t, end_t=end_t))\n",
    "# connect_drivable_to_driver(drivable=controlled_plt, driver=spike_raster_window.spike_raster_plt_2d,\n",
    "#                                                         custom_connect_function=(lambda driver, drivable: pg.SignalProxy(driver.window_scrolled, delay=0.2, rateLimit=30, slot=drivable.on_window_changed)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959af32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.spike_raster_plt_2d.window_scrolled.disconnect(_out_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779a1b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizer.imv.autoLevels()\n",
    "# visualizer.imv.autoRange()\n",
    "# visualizer.imv.setImage(\n",
    "\n",
    "visualizer.test_image_display()  # Test the ImageView\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf92416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standalone_pyqtgraph_test():\n",
    "    \"\"\"Test PyQtGraph image display completely independently\"\"\"\n",
    "    # Create a simple app and window\n",
    "    app = pg.mkQApp(\"Test App\")\n",
    "    win = pg.GraphicsWindow(title=\"Basic Image Test\")\n",
    "    win.resize(500, 500)\n",
    "    \n",
    "    # Add a ViewBox and ImageItem\n",
    "    view = win.addViewBox()\n",
    "    view.setAspectLocked(True)\n",
    "    \n",
    "    # Create a simple test image\n",
    "    img_data = np.random.normal(size=(100, 100))\n",
    "    img = pg.ImageItem(img_data)\n",
    "    view.addItem(img)\n",
    "    \n",
    "    win.show()\n",
    "    return win, app  # Return to prevent garbage collection\n",
    "\n",
    "# Run the standalone test\n",
    "test_win, test_app = standalone_pyqtgraph_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a098967",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"PyQtGraph is using: {pg.Qt.QT_LIB}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c59106f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "from pyphoplacecellanalysis.External.pyqtgraph.Qt import QtWidgets\n",
    "\n",
    "# Interpret image data as row-major instead of col-major\n",
    "pg.setConfigOptions(imageAxisOrder='row-major')\n",
    "\n",
    "app = pg.mkQApp(\"ImageView Example\")\n",
    "\n",
    "## Create window with ImageView widget\n",
    "win = QtWidgets.QMainWindow()\n",
    "win.resize(800,800)\n",
    "imv = pg.ImageView()\n",
    "win.setCentralWidget(imv)\n",
    "win.show()\n",
    "win.setWindowTitle('pyqtgraph example: ImageView')\n",
    "\n",
    "## Create random 3D data set with time varying signals\n",
    "dataRed = np.ones((100, 200, 200)) * np.linspace(90, 150, 100)[:, np.newaxis, np.newaxis]\n",
    "dataRed += pg.gaussianFilter(np.random.normal(size=(200, 200)), (5, 5)) * 100\n",
    "dataGrn = np.ones((100, 200, 200)) * np.linspace(90, 180, 100)[:, np.newaxis, np.newaxis]\n",
    "dataGrn += pg.gaussianFilter(np.random.normal(size=(200, 200)), (5, 5)) * 100\n",
    "dataBlu = np.ones((100, 200, 200)) * np.linspace(180, 90, 100)[:, np.newaxis, np.newaxis]\n",
    "dataBlu += pg.gaussianFilter(np.random.normal(size=(200, 200)), (5, 5)) * 100\n",
    "\n",
    "data = np.concatenate(\n",
    "    (dataRed[:, :, :, np.newaxis], dataGrn[:, :, :, np.newaxis], dataBlu[:, :, :, np.newaxis]), axis=3\n",
    ")\n",
    "\n",
    "\n",
    "## Display the data and assign each frame a time value from 1.0 to 3.0\n",
    "imv.setImage(data, xvals=np.linspace(1., 3., data.shape[0]))\n",
    "\n",
    "## Set a custom color map\n",
    "colors = [\n",
    "    (0, 0, 0),\n",
    "    (45, 5, 61),\n",
    "    (84, 42, 55),\n",
    "    (150, 87, 60),\n",
    "    (208, 171, 141),\n",
    "    (255, 255, 255)\n",
    "]\n",
    "cmap = pg.ColorMap(pos=np.linspace(0.0, 1.0, 6), color=colors)\n",
    "imv.setColorMap(cmap)\n",
    "\n",
    "# Start up with an ROI\n",
    "imv.ui.roiBtn.setChecked(True)\n",
    "imv.roiClicked()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f5ca22",
   "metadata": {},
   "source": [
    "### <a id='toc26_1_3_'></a>[Old Stuff](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2323020",
   "metadata": {},
   "outputs": [],
   "source": [
    "## sync up the widgets\n",
    "active_2d_plot.sync_matplotlib_render_plot_widget(identifier=name, sync_mode=SynchronizedPlotMode.TO_WINDOW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c38dd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.TimelinePlotterBase import TimelinePlotterBase\n",
    "import pyqtgraph as pg\n",
    "from qtpy import QtCore\n",
    "\n",
    "class SynchronizedHeatmapPlotter(TimelinePlotterBase):\n",
    "    def __init__(self, results2D, parent=None):\n",
    "        super().__init__(parent=parent)\n",
    "        self._results2D = results2D\n",
    "        a_result: SingleEpochDecodedResult = results2D.a_result2D.get_result_for_epoch(0)\n",
    "        self.a_result =  a_result\n",
    "        self.data_t_bins = self.a_result.time_bin_container.centers\n",
    "        \n",
    "        self.data = self.a_result.p_x_given_n\n",
    "        \n",
    "        # Setup PyQtGraph components\n",
    "        self.plot_widget = pg.PlotWidget()\n",
    "        self.img_item = pg.ImageItem()\n",
    "        self.plot_widget.addItem(self.img_item)\n",
    "        \n",
    "        # Add to layout\n",
    "        self.layout().addWidget(self.plot_widget)\n",
    "        \n",
    "    def update_time_window(self, new_start_time, new_end_time):\n",
    "        # Called when time window changes\n",
    "        # time_mask = (self.data_times >= new_start_time) & (self.data_times <= new_end_time)\n",
    "        nearest_idx = np.searchsorted(self.data_t_bins, new_start_time)\n",
    "        \n",
    "        visible_data = self.a_result.p_x_given_n[:, :, nearest_idx] # [n_x_bins, n_y_bins]\n",
    "        self.img_item.setImage(visible_data)\n",
    "        \n",
    "    def set_data(self, data, times):\n",
    "        # Store data and times\n",
    "        self.data = data\n",
    "        self.data_t_bins = times\n",
    "\n",
    "\n",
    "# Create and setup\n",
    "heatmap_plotter = SynchronizedHeatmapPlotter(results2D=results2D)\n",
    "heatmap_plotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d16b16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster.sigTimeWindowChanged.connect(heatmap_plotter.on_window_changed)\n",
    "\n",
    "# Add to layout\n",
    "spike_raster.layout().addWidget(heatmap_plotter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff6b0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = BasicBinnedImageRenderingWindow(active_eloy_analysis.avg_2D_speed_per_pos, results2D.a_new_global2D_decoder.xbin_labels, results2D.a_new_global2D_decoder.ybin_labels, name='avg_velocity', title=\"Avg Velocity per Pos (X, Y)\", variable_label='Avg Velocity', scrollability_mode=LayoutScrollability.SCROLLABLE)\n",
    "out.add_data(row=1, col=0, matrix=active_eloy_analysis.pf_overlapDensity_2D, xbins=results2D.a_new_global2D_decoder.xbin_labels, ybins=results2D.a_new_global2D_decoder.ybin_labels, name='pf_overlapDensity', title='pf overlapDensity metric', variable_label='pf overlapDensity')\n",
    "# out.add_data(row=2, col=0, matrix=active_pf_2D.ratemap.occupancy, xbins=active_pf_2D.xbin, ybins=active_pf_2D.ybin, name='occupancy_seconds', title='Seconds Occupancy', variable_label='seconds')\n",
    "# out.add_data(row=3, col=0, matrix=active_simpler_pf_densities_analysis.n_neurons_meeting_firing_critiera_by_position_bins_2D, xbins=active_pf_2D.xbin, ybins=active_pf_2D.ybin, name='n_neurons_meeting_firing_critiera_by_position_bins_2D', title='# neurons > 1Hz per Pos (X, Y)', variable_label='# neurons')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d93374",
   "metadata": {},
   "source": [
    "#### <a id='toc26_1_3_1_'></a>[üñºÔ∏è Test Single Epoch/Axes `DecodedTrajectoryMatplotlibPlotter` with slider to choose epoch](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34deb831",
   "metadata": {
    "tags": [
     "2025-02-13_broken"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.mixins.decoder_plotting_mixins import DecodedTrajectoryMatplotlibPlotter\n",
    "\n",
    "a_result2D: DecodedFilterEpochsResult = results2D.frame_divided_epochs_results['global']\n",
    "a_new_global_decoder2D = results2D.decoders['global']\n",
    "# a_result2D = results2D.a_result2D\n",
    "# a_new_global_decoder2D = results2D.a_new_global_decoder2D\n",
    "## INPUTS: directional_laps_results, decoder_ripple_filter_epochs_decoder_result_dict\n",
    "xbin = deepcopy(a_new_global_decoder2D.xbin)\n",
    "xbin_centers = deepcopy(a_new_global_decoder2D.xbin_centers)\n",
    "ybin_centers = deepcopy(a_new_global_decoder2D.ybin_centers)\n",
    "ybin = deepcopy(a_new_global_decoder2D.ybin)\n",
    "num_filter_epochs: int = a_result2D.num_filter_epochs\n",
    "a_decoded_traj_plotter = DecodedTrajectoryMatplotlibPlotter(a_result=a_result2D, xbin=xbin, xbin_centers=xbin_centers, ybin=ybin, ybin_centers=ybin_centers, rotate_to_vertical=True)\n",
    "fig, axs, decoded_epochs_pages = a_decoded_traj_plotter.plot_decoded_trajectories_2d(global_session, curr_num_subplots=1, active_page_index=0, plot_actual_lap_lines=False, use_theoretical_tracks_instead=True, fixed_columns=1)\n",
    "\n",
    "ax = axs[0][0]\n",
    "ax.set_aspect('auto')  # Adjust automatically based on data limits\n",
    "ax.set_adjustable('datalim')  # Ensure the aspect ratio respects the data limits\n",
    "ax.autoscale()  # Autoscale the view to fit data\n",
    "\n",
    "# axs[0][0].set_aspect(1)\n",
    "# axs[0][0].set_aspect('equal')  # Preserve aspect ratio\n",
    "integer_slider = a_decoded_traj_plotter.plot_epoch_with_slider_widget(an_epoch_idx=0, include_most_likely_pos_line=False)\n",
    "integer_slider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d21822",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoded_traj_plotter.num_filter_epochs\n",
    "an_epoch_idx = 125\n",
    "a_decoded_traj_plotter.plot_epoch(an_epoch_idx=an_epoch_idx, include_most_likely_pos_line=None, time_bin_index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caffcb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.laps import plot_lap_trajectories_2d\n",
    "# Complete Version:\n",
    "fig, axs, laps_pages = plot_lap_trajectories_2d(curr_active_pipeline.sess, curr_num_subplots=len(curr_active_pipeline.sess.laps.lap_id), active_page_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453aa237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "## INPUTS: results2D\n",
    "\n",
    "a_decoder_name: str = 'long'\n",
    "a_full_decoded_2D_posterior_result: SingleEpochDecodedResult = results2D.continuous_results[a_decoder_name].get_result_for_epoch(0)\n",
    "a_full_decoded_2D_posterior_result.marginal_x\n",
    "a_full_decoded_2D_posterior_result.marginal_y\n",
    "a_save_path = Path('data/a_full_decoded_2D_posterior_result.pkl').resolve()\n",
    "if not a_save_path.parent.exists():\n",
    "\tprint(f'creating \"{a_save_path.parent}\"...')\n",
    "\ta_save_path.parent.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "with h5py.File(a_save_path, 'w') as f:\n",
    "    a_full_decoded_2D_posterior_result.to_hdf(f, 'a_full_decoded_2D_posterior_result')\n",
    "    print(f'\\tsaved \"{a_save_path}\".')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e251f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(a_full_decoded_2D_posterior_result.p_x_given_n) # (59, 8, 69487)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bf9547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.laps import plot_lap_trajectories_3d\n",
    "## single_combined_plot == True mode (mode 1.):\n",
    "p, laps_pages = plot_lap_trajectories_3d(curr_active_pipeline.sess, single_combined_plot=True)\n",
    "p.show()\n",
    "\n",
    "## single_combined_plot == False mode (mode 2.):        \n",
    "p, laps_pages = plot_lap_trajectories_3d(curr_active_pipeline.sess, single_combined_plot=False, curr_num_subplots=len(curr_active_pipeline.sess.laps.lap_id), active_page_index=1)\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468fcd8a",
   "metadata": {},
   "source": [
    "# <a id='toc27_'></a>[3D PyVista Plotter](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881e2aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "import pyvistaqt\n",
    "from pyvistaqt import BackgroundPlotter\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.mixins.decoder_plotting_mixins import DecodedTrajectoryPyVistaPlotter, DecodedTrajectoryPlotter, DecoderRenderingPyVistaMixin, DecodedTrajectoryMatplotlibPlotter\n",
    "from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.InteractiveCustomDataExplorer import InteractiveCustomDataExplorer\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.Testing.EpochRenderTimebinSelectorWidget.EpochRenderTimebinSelectorWidget import EpochRenderTimebinSelectorWidget, EpochTimebinningIndexingDatasource, ConcreteEpochTimebinningIndexingDatasource\n",
    "\n",
    "a_result2D: DecodedFilterEpochsResult = results2D.frame_divided_epochs_results['global']\n",
    "a_new_global_decoder2D = results2D.decoders['global']\n",
    "\n",
    "curr_active_pipeline.prepare_for_display()\n",
    "_out = curr_active_pipeline.display(display_function='_display_3d_interactive_custom_data_explorer', active_session_configuration_context=global_epoch_context,\n",
    "                                params_kwargs=dict(should_use_linear_track_geometry=True, **{'t_start': t_start, 't_delta': t_delta, 't_end': t_end}),\n",
    "                                )\n",
    "iplapsDataExplorer: InteractiveCustomDataExplorer = _out['iplapsDataExplorer']\n",
    "pActiveInteractiveLapsPlotter = _out['plotter']\n",
    "a_decoded_trajectory_pyvista_plotter: DecodedTrajectoryPyVistaPlotter = DecodedTrajectoryPyVistaPlotter(a_result=a_result2D, xbin=a_new_global_decoder2D.xbin, xbin_centers=a_new_global_decoder2D.xbin_centers, ybin=a_new_global_decoder2D.ybin, ybin_centers=a_new_global_decoder2D.ybin_centers, p=iplapsDataExplorer.p)\n",
    "\n",
    "plotter: BackgroundPlotter = iplapsDataExplorer.p\n",
    "app_window: pyvistaqt.window.MainWindow = plotter.app_window\n",
    "# editor: pyvistaqt.editor.Editor = plotter.editor\n",
    "root_layout: pg.QtWidgets.QVBoxLayout = app_window.centralWidget().layout() # root_layout\n",
    "\n",
    "# a_decoded_trajectory_pyvista_plotter.build_ui()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ff8ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de377c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = dict()\n",
    "_out['_display_3d_interactive_spike_and_behavior_browser'] = curr_active_pipeline.display(display_function='_display_3d_interactive_spike_and_behavior_browser', active_session_configuration_context=IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43',filter_name='maze1_odd',lap_dir='odd')) # _display_3d_interactive_spike_and_behavior_browser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b275e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_out = dict()\n",
    "_out['_display_3d_interactive_tuning_curves_plotter'] = curr_active_pipeline.display(display_function='_display_3d_interactive_tuning_curves_plotter', active_session_configuration_context=IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43',filter_name='maze1_odd',lap_dir='odd')) # _display_3d_interactive_tuning_curves_plotter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b4be48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.laps import plot_lap_trajectories_3d\n",
    "\n",
    "## single_combined_plot == True mode (mode 1.):\n",
    "p, laps_pages = plot_lap_trajectories_3d(curr_active_pipeline.sess, single_combined_plot=True)\n",
    "p.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bb85fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## single_combined_plot == False mode (mode 2.):        \n",
    "p, laps_pages = plot_lap_trajectories_3d(curr_active_pipeline.sess, single_combined_plot=False, curr_num_subplots=len(curr_active_pipeline.sess.laps.lap_id), active_page_index=1)\n",
    "p.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79177032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_decoded_trajectory_pyvista_plotter.enable_plot_all_time_bins_in_epoch_mode = wants_use_all_bins\n",
    "\n",
    "a_decoded_trajectory_pyvista_plotter.on_update_slider_epoch_idx(5)\n",
    "a_decoded_trajectory_pyvista_plotter.on_update_slider_epoch_time_bin(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969c89e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoded_trajectory_pyvista_plotter.curr_epoch_idx\n",
    "a_decoded_trajectory_pyvista_plotter.curr_time_bin_index\n",
    "# a_decoded_trajectory_pyvista_plotter.curr_n_time_bins\n",
    "a_decoded_trajectory_pyvista_plotter.enable_plot_all_time_bins_in_epoch_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ce2377",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoded_trajectory_pyvista_plotter.enable_plot_all_time_bins_in_epoch_mode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93125fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.Testing.EpochRenderTimebinSelectorWidget.EpochRenderTimebinSelectorWidget import EpochRenderTimebinSelectorWidget, EpochTimebinningIndexingDatasource, ConcreteEpochTimebinningIndexingDatasource\n",
    "\n",
    "# Create and add the custom widget\n",
    "custom_widget = EpochRenderTimebinSelectorWidget(epoch_ds=a_decoded_trajectory_pyvista_plotter, enable_plot_all_time_bins_in_epoch_mode=a_decoded_trajectory_pyvista_plotter.enable_plot_all_time_bins_in_epoch_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7decbe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter: BackgroundPlotter = iplapsDataExplorer.p\n",
    "app_window: pyvistaqt.window.MainWindow = plotter.app_window\n",
    "root_layout: pg.QtWidgets.QVBoxLayout = app_window.centralWidget().layout()\n",
    "\n",
    "# Create and add the custom widget\n",
    "custom_widget = EpochRenderTimebinSelectorWidget(epoch_ds=a_decoded_trajectory_pyvista_plotter)\n",
    "# layout = plotter.central_widget.layout()\n",
    "root_layout.insertWidget(0, custom_widget)  # Insert at the top (index 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e702724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _helper_on_update_slider_epoch_idx(self, value: int):\n",
    "    \"\"\" called when the epoch_idx slider changes. \n",
    "    \"\"\"\n",
    "    print(f'._helper_on_update_slider_epoch_idx(self: {self}, value: {value})')\n",
    "    a_decoded_trajectory_pyvista_plotter.on_update_slider_epoch_idx(int(value))\n",
    "    # self.on_update_slider_epoch_idx(int(value))\n",
    "\n",
    "def _helper_on_update_slider_time_bin_idx(self, value: int):\n",
    "    \"\"\" called when the epoch_time_bin within a given epoch_idx slider changes \n",
    "    \"\"\"\n",
    "    print(f'._helper_on_update_slider_time_bin_idx(self: {self}, value: {value})')\n",
    "    # self.on_update_slider_epoch_time_bin(int(value))\n",
    "    a_decoded_trajectory_pyvista_plotter.on_update_slider_epoch_time_bin(int(value))\n",
    "    \n",
    "def _helper_on_update_wants_use_all_time_bins(self, wants_use_all_bins: bool):\n",
    "    \"\"\" called when the epoch_time_bin within a given epoch_idx slider changes \n",
    "    \"\"\"\n",
    "    print(f'._helper_on_update_wants_use_all_time_bins(self: {self}, wants_use_all_bins: {wants_use_all_bins})')\n",
    "    # self.on_update_slider_epoch_time_bin(value=value)\n",
    "    will_change: bool = (a_decoded_trajectory_pyvista_plotter.enable_plot_all_time_bins_in_epoch_mode != wants_use_all_bins)\n",
    "    if (not will_change):\n",
    "        print(f'\\tno change.')\n",
    "        return\n",
    "    else:\n",
    "        ## update:\n",
    "        a_decoded_trajectory_pyvista_plotter.enable_plot_all_time_bins_in_epoch_mode = wants_use_all_bins\n",
    "    # a_decoded_trajectory_pyvista_plotter.on_update_slider_epoch_idx(int(value))\n",
    "\n",
    "\n",
    "## connect the signals\n",
    "_out_connections = {}\n",
    "_out_connections['sigEpochIndexChanged'] = custom_widget.sigEpochIndexChanged.connect(lambda selected_idx: _helper_on_update_slider_epoch_idx(custom_widget, selected_idx))\n",
    "_out_connections['sigTimeBinIndexChanged'] = custom_widget.sigTimeBinIndexChanged.connect(lambda selected_idx: _helper_on_update_slider_time_bin_idx(custom_widget, selected_idx))\n",
    "_out_connections['sigUseAllTimeBinsToggled'] = custom_widget.sigUseAllTimeBinsToggled.connect(lambda wants_use_all_bins: _helper_on_update_wants_use_all_time_bins(custom_widget, wants_use_all_bins))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44644cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_keys_if_possible('iplapsDataExplorer', iplapsDataExplorer, max_depth=1)\n",
    "# print_keys_if_possible('BackgroundPlotter', iplapsDataExplorer.p, max_depth=1)\n",
    "print_keys_if_possible('pyvistaqt.window.MainWindow', app_window, max_depth=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0df8a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# .app_window, \n",
    ".app_window\n",
    ".main_menu # PyQt5.QtWidgets.QMenuBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24239540",
   "metadata": {},
   "outputs": [],
   "source": [
    "iplapsDataExplorer.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958c0e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "iplapsDataExplorer.enable_plot_all_time_bins_in_epoch_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcb5832",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoded_trajectory_pyvista_plotter.enable_plot_all_time_bins_in_epoch_mode = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9627cdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoded_trajectory_pyvista_plotter.perform_clear_existing_decoded_trajectory_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de87906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import AddNewDecodedPosteriors_MatplotlibPlotCommand\n",
    "\n",
    "display_output = {}\n",
    "AddNewDecodedPosteriors_MatplotlibPlotCommand(spike_raster_window, curr_active_pipeline, active_config_name=active_config_name, active_context=active_context, display_output=display_output, action_identifier='actionPseudo2DDecodedEpochsDockedMatplotlibView')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ace0b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "dock_tree_list, group_meta_item_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_tree_dict()\n",
    "dock_tree_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee32b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.ui.dynamic_docked_widget_container.dynamic_display_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912f6e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.build_dock_area_managing_tree_widget()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2925ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_epoch_name: str = 'long'\n",
    "# an_epoch_name: str = 'short'\n",
    "\n",
    "an_epoch_period_description = f'{an_epoch_name}_train'\n",
    "# an_epoch_period_description = 'short_train'\n",
    "test_epochs_decoder_result: DecodedFilterEpochsResult = split_train_test_epoch_specific_decoded_results_dict[an_epoch_period_description]\n",
    "a_sliced_pf1D_Decoder: BasePositionDecoder = split_train_test_epoch_specific_pfND_Decoder_dict[an_epoch_period_description]\n",
    "pos_df: pd.DataFrame = original_pos_dfs_dict[an_epoch_name]\n",
    "# filtered_pos_df = deepcopy(a_sliced_pf1D_Decoder.pf.filtered_pos_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334a30b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kwargs = dict()\n",
    "\n",
    "## Build the new dock track:\n",
    "dock_identifier: str = 'New non-PBE Decoding Performance'\n",
    "ts_widget, fig, ax_list = active_2d_plot.add_new_matplotlib_render_plot_widget(name=dock_identifier)\n",
    "ax = ax_list[0]\n",
    "\n",
    "## Get the needed data:\n",
    "# directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "# all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "# continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "# previously_decoded_keys: List[float] = list(continuously_decoded_result_cache_dict.keys()) # [0.03333]\n",
    "# print(F'previously_decoded time_bin_sizes: {previously_decoded_keys}')\n",
    "\n",
    "# time_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\n",
    "# print(f'time_bin_size: {time_bin_size}')\n",
    "# continuously_decoded_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_decode_result.most_recent_continuously_decoded_dict\n",
    "# all_directional_continuously_decoded_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = {k:v for k, v in (continuously_decoded_dict or {}).items() if k in TrackTemplates.get_decoder_names()} ## what is plotted in the `f'{a_decoder_name}_ContinuousDecode'` rows by `AddNewDirectionalDecodedEpochs_MatplotlibPlotCommand`\n",
    "## OUT: all_directional_continuously_decoded_dict\n",
    "## Draw the position meas/decoded on the plot widget\n",
    "## INPUT: fig, ax_list, all_directional_continuously_decoded_dict, track_templates\n",
    "\n",
    "# _out_artists =  _perform_plot_multi_decoder_meas_pred_position_track(curr_active_pipeline, fig, ax_list, desired_time_bin_size=1.0, enable_flat_line_drawing=True)\n",
    "# pos_df = pos_df.position.add_binned_time_column(time_window_edges=time_bin_containers.edges, time_window_edges_binning_info=time_bin_containers.edge_info) # 'binned_time' refers to which time bins these are\n",
    "# Plot the measured position X:\n",
    "# _, ax = plot_1D_most_likely_position_comparsions(pos_df, variable_name='x', time_window_centers=None, xbin=None, posterior=None, active_most_likely_positions_1D=None, ax=ax_list[0], enable_flat_line_drawing=False, debug_print=debug_print, **kwargs)\n",
    "\n",
    "## sync up the widgets\n",
    "active_2d_plot.sync_matplotlib_render_plot_widget(dock_identifier, sync_mode=SynchronizedPlotMode.TO_WINDOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b70236",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_epochs_decoder_result.most_likely_positions_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68797b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.matplotlib_helpers import get_heatmap_cmap\n",
    "\n",
    "posterior_heatmap_imshow_kwargs = dict()\n",
    "\n",
    "\n",
    "# an_epoch_name: str = 'long'\n",
    "# an_epoch_name: str = 'short'\n",
    "\n",
    "for an_epoch_name, an_epoch_measured_pos_df in original_pos_dfs_dict.items():\n",
    "\n",
    "    an_epoch_period_description = f'{an_epoch_name}_train'\n",
    "    # an_epoch_period_description = 'short_train'\n",
    "    test_epochs_decoder_result: DecodedFilterEpochsResult = split_train_test_epoch_specific_decoded_results_dict[an_epoch_period_description]\n",
    "    a_sliced_pf1D_Decoder: BasePositionDecoder = split_train_test_epoch_specific_pf1D_Decoder_dict[an_epoch_period_description]\n",
    "    # pos_df: pd.DataFrame = original_pos_dfs_dict[an_epoch_name]\n",
    "\n",
    "\n",
    "    # # Get the colormap to use and set the bad color\n",
    "    # cmap = mpl.colormaps.get_cmap('viridis')  # viridis is the default colormap for imshow\n",
    "    # cmap.set_bad(color='black')\n",
    "\n",
    "    ## OLD:\n",
    "    # main_plot_kwargs = {'origin': 'lower', 'vmin': 0, 'vmax': 1, 'cmap': cmap, 'interpolation':'nearest', 'aspect':'auto'}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Plot the measured position X:\n",
    "    _, ax = plot_1D_most_likely_position_comparsions(an_epoch_measured_pos_df, variable_name='x', time_window_centers=None, xbin=None, posterior=None, active_most_likely_positions_1D=None, ax=ax, enable_flat_line_drawing=True, debug_print=debug_print, **kwargs)\n",
    "\n",
    "    assert ax is not None\n",
    "\n",
    "    if posterior_heatmap_imshow_kwargs is None:\n",
    "        posterior_heatmap_imshow_kwargs = {}\n",
    "    ## END if posterior_heatmap_imshow_kwargs is None...\n",
    "\n",
    "\n",
    "    # Get the colormap to use and set the bad color\n",
    "    # cmap = get_heatmap_cmap(cmap='viridis', bad_color='black', under_color='white', over_color='red')\n",
    "    # active_cmap = posterior_heatmap_imshow_kwargs.get('cmap', get_heatmap_cmap(cmap='Oranges', bad_color='black', under_color='white', over_color='red'))\n",
    "    active_cmap = posterior_heatmap_imshow_kwargs.get('cmap', get_heatmap_cmap(cmap='viridis', bad_color='black', under_color='white', over_color='red'))\n",
    "\n",
    "    fig, ax, out_img_list = plot_slices_1D_most_likely_position_comparsions(pos_df, slices_time_window_centers=[v.centers for v in test_epochs_decoder_result.time_bin_containers], xbin=a_sliced_pf1D_Decoder.xbin,\n",
    "                                                    slices_posteriors=test_epochs_decoder_result.p_x_given_n_list,\n",
    "                                                    slices_active_most_likely_positions_1D=test_epochs_decoder_result.most_likely_positions_list,\n",
    "                                                    enable_flat_line_drawing=False, debug_print=False, ax=ax,\n",
    "                                                    posterior_heatmap_imshow_kwargs=dict(cmap=active_cmap),)\n",
    "                                                    \n",
    "    # num_filter_epochs = test_epochs_decoder_result.num_filter_epochs\n",
    "    # time_window_centers = [v.centers for v in test_epochs_decoder_result.time_bin_containers]\n",
    "\n",
    "# fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b30d2ec",
   "metadata": {},
   "source": [
    "From [/c:/Users/pho/repos/Spike3DWorkEnv/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/DirectionalPlacefieldGlobalComputationFunctions.py:3996](vscode://file/c:/Users/pho/repos/Spike3DWorkEnv/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Pipeline/Stages/ComputationFunctions/MultiContextComputationFunctions/DirectionalPlacefieldGlobalComputationFunctions.py:3996)\n",
    "```python\n",
    "compute_train_test_split_laps_decoders\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3eb111",
   "metadata": {},
   "source": [
    "# <a id='toc28_'></a>[2025-02-18 - Napari](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df7e12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: batch_plot_helper: SingleArtistMultiEpochBatchHelpers\n",
    "napari_batch_plot_helper: SingleArtistMultiEpochBatchHelpers = deepcopy(batch_plot_helper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951131b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "napari_batch_plot_helper.stacked_p_x_given_n.shape # (1, 59, 528104)\n",
    "\n",
    "# napari_batch_plot_helper.a_result2D.p_x_given_n_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c3a950",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Napari.napari_helpers import napari_from_layers_dict\n",
    "\n",
    "custom_direction_split_layers_dict = {}\n",
    "layers_list_sort_order = ['long_LR_z_scored_tuning_maps', 'long_LR_C_trial_by_trial_correlation_matrix', 'long_RL_z_scored_tuning_maps', 'long_RL_C_trial_by_trial_correlation_matrix', 'short_LR_z_scored_tuning_maps', 'short_LR_C_trial_by_trial_correlation_matrix', 'short_RL_z_scored_tuning_maps', 'short_RL_C_trial_by_trial_correlation_matrix']\n",
    "\n",
    "\n",
    "# INPUTS: results2D\n",
    "n_timebins, flat_time_bin_containers, flat_timebins_p_x_given_n = napari_batch_plot_helper.a_result2D.flatten()\n",
    "flat_time_bin_containers = flat_time_bin_containers.tolist()\n",
    "flat_time_bin_centers: NDArray = np.hstack([v.centers for v in flat_time_bin_containers])\n",
    "\n",
    "# np.shape(flat_time_bin_containers) # (1738,)\n",
    "timebins_p_x_given_n_shape = np.shape(flat_timebins_p_x_given_n) # (76, 40, 29532)\n",
    "n_xbins, n_ybins, n_tbins = timebins_p_x_given_n_shape\n",
    "# (n_xbins, n_ybins, n_tbins)\n",
    "# np.shape(flat_time_bin_centers) # (29532,)\n",
    "\n",
    "flattened_timebins_p_x_given_n_shape = np.shape(flat_timebins_p_x_given_n) # (76, 40, 29532)\n",
    "n_xbins, n_ybins, n_tbins = flattened_timebins_p_x_given_n_shape ## MUST BE UPDATED POST SLICE\n",
    "\n",
    "print(f'flattened_timebins_p_x_given_n_shape: {flattened_timebins_p_x_given_n_shape}') # (59, 8, 66013)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2438d56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Build the image data layers for each\n",
    "# for an_epoch_name, (active_laps_df, C_trial_by_trial_correlation_matrix, z_scored_tuning_map_matrix, aclu_to_matrix_IDX_map, neuron_ids) in directional_active_lap_pf_results_dicts.items():\n",
    "# for an_epoch_name, active_trial_by_trial_activity_obj in directional_active_lap_pf_results_dicts.items():\n",
    "#     # (active_laps_df, C_trial_by_trial_correlation_matrix, z_scored_tuning_map_matrix, aclu_to_matrix_IDX_map, neuron_ids)\n",
    "#     z_scored_tuning_map_matrix = active_trial_by_trial_activity_obj.z_scored_tuning_map_matrix\n",
    "#     custom_direction_split_layers_dict[f'{an_epoch_name}_z_scored_tuning_maps'] = dict(blending='translucent', colormap='viridis', name=f'{an_epoch_name}_z_scored_tuning_maps', img_data=z_scored_tuning_map_matrix.transpose(1, 0, 2)) # reshape to be compatibile with C_i's dimensions\n",
    "#     if include_trial_by_trial_correlation_matrix:\n",
    "#         C_trial_by_trial_correlation_matrix = active_trial_by_trial_activity_obj.C_trial_by_trial_correlation_matrix\n",
    "#         custom_direction_split_layers_dict[f'{an_epoch_name}_C_trial_by_trial_correlation_matrix'] = dict(blending='translucent', colormap='viridis', name=f'{an_epoch_name}_C_trial_by_trial_correlation_matrix', img_data=C_trial_by_trial_correlation_matrix)\n",
    "\n",
    "\n",
    "# custom_direction_split_layers_dict[f'stacked_p_x_given_n'] = dict(blending='translucent', colormap='viridis', name=f'{an_epoch_name}_z_scored_tuning_maps', img_data=napari_batch_plot_helper.stacked_p_x_given_n) # reshape to be compatibile with C_i's dimensions .transpose(1, 0, 2)\n",
    "\n",
    "custom_direction_split_layers_dict[f'flat_timebins_p_x_given_n'] = dict(blending='translucent', colormap='viridis', name=f'flat_timebins_p_x_given_n', img_data=flat_timebins_p_x_given_n) # reshape to be compatibile with C_i's dimensions .transpose(1, 0, 2)\n",
    "\n",
    "\n",
    "# directional_viewer, directional_image_layer_dict = napari_trial_by_trial_activity_viz(None, None, layers_dict=custom_direction_split_layers_dict)\n",
    "\n",
    "## sort the layers dict:\n",
    "# custom_direction_split_layers_dict = {k:custom_direction_split_layers_dict[k] for k in reversed(layers_list_sort_order) if k in custom_direction_split_layers_dict}\n",
    "\n",
    "directional_viewer, directional_image_layer_dict = napari_from_layers_dict(layers_dict=custom_direction_split_layers_dict, title='Non-PBE 2D Decoding', axis_labels=('xbin', 'ybin', 'subdiv_epoch'))\n",
    "# if include_trial_by_trial_correlation_matrix:\n",
    "#     directional_viewer.grid.shape = (-1, 4)\n",
    "# else:\n",
    "#     directional_viewer.grid.shape = (2, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270c611c",
   "metadata": {},
   "source": [
    "# <a id='toc29_'></a>[2025-01-30 - Rat Heading-Angle from Position Change Derivation](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9910622",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_pos_obj: Position = deepcopy(global_session.position)\n",
    "# global_pos_df: pd.DataFrame = global_pos_obj.compute_higher_order_derivatives().position.compute_smoothed_position_info(N=15)\n",
    "global_pos_df: pd.DataFrame = global_pos_obj.adding_approx_head_dir_columns(N=15)\n",
    "# global_pos_df = global_pos_df.dropna(axis='index', subset=['approx_head_dir_degrees'])\n",
    "global_pos_df\n",
    "# Convert angles to radians\n",
    "angles = np.deg2rad(global_pos_df['approx_head_dir_degrees'])\n",
    "\n",
    "# Create circular histogram\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\n",
    "ax.hist(angles, bins=36, density=True, alpha=0.70)\n",
    "\n",
    "# Set labels\n",
    "ax.set_title(\"Circular Histogram of Head Direction\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36db1348",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Given a pd.DataFrame with columns ['x', 'y', 'approx_head_dir_degrees'], compute binned versions of these variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6862634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = deepcopy(global_pos_df)\n",
    "\n",
    "# Normalize time to use as radius\n",
    "radii = (df['t'] - df['t'].min()) / (df['t'].max() - df['t'].min())\n",
    "\n",
    "# Create circular scatter plot\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\n",
    "ax.scatter(angles, radii, alpha=0.20, s=1)\n",
    "# ax.plot(angles, radii, alpha=0.20, s=1)\n",
    "# Set labels\n",
    "ax.set_title(\"Circular Scatter Plot of Head Direction Over Time\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a744785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create circular scatter plot with line connecting points\n",
    "fig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\n",
    "\n",
    "# Plot points\n",
    "ax.scatter(angles, radii, alpha=0.75, s=5)  # Smaller point size\n",
    "\n",
    "# Connect points with a line\n",
    "ax.plot(angles, radii, alpha=0.5, linewidth=1)\n",
    "\n",
    "# Set labels\n",
    "ax.set_title(\"Circular Scatter Plot of Head Direction Over Time\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48003e72",
   "metadata": {},
   "source": [
    "## <a id='toc29_1_'></a>[Binning Position, Angle](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5139dcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "xbin_edges = global_pf2D.xbin\n",
    "ybin_edges = global_pf2D.ybin\n",
    "# Create evenly spaced bin edges from 0 to 360\n",
    "n_dir_bins: int = 8\n",
    "angle_dir_bin_edges = np.linspace(0, 360, n_dir_bins + 1)\n",
    "\n",
    "n_xbins: int = len(xbin_edges) - 1\n",
    "n_ybins: int = len(ybin_edges) - 1\n",
    "n_dir_bins: int = len(angle_dir_bin_edges) - 1\n",
    "\n",
    "print(f'n_xbins: {n_xbins}, n_ybins: {n_ybins}, n_dir_bins: {n_dir_bins}')\n",
    "\n",
    "# Use pd.cut with the explicit bin edges\n",
    "global_pos_df['head_dir_angle_binned'] = pd.cut(global_pos_df['approx_head_dir_degrees'], bins=angle_dir_bin_edges, labels=False, include_lowest=True)\n",
    "global_pos_df = global_pos_df.position.adding_binned_position_columns(xbin_edges=xbin_edges, ybin_edges=ybin_edges)\n",
    "global_pos_df = global_pos_df.dropna(axis='index', subset=['binned_x', 'binned_y', 'head_dir_angle_binned'])\n",
    "global_pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18aa91b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_attributes(short_name=None, tags=['working', 'angular'], input_requires=[], output_provides=[], uses=[], used_by=[], creation_date='2025-02-21 00:48', related_items=[])\n",
    "def compute_3d_occupancy_map(df, n_x_bins=50, n_y_bins=50, n_dir_bins=8):\n",
    "    \"\"\"Creates a 3D occupancy map with fixed dimensions regardless of observed data\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with binned columns\n",
    "        n_x_bins (int): Number of x position bins\n",
    "        n_y_bins (int): Number of y position bins\n",
    "        n_dir_bins (int): Number of head direction bins\n",
    "    \"\"\"\n",
    "    # Create all possible combinations\n",
    "    x_bins = range(n_x_bins)\n",
    "    y_bins = range(n_y_bins)\n",
    "    dir_bins = range(n_dir_bins)\n",
    "    \n",
    "    # Use crosstab with specific bins to force output size\n",
    "    occupancy_map = pd.crosstab(\n",
    "        index=[df['binned_x'], df['binned_y']], \n",
    "        columns=df['head_dir_angle_binned'],\n",
    "        dropna=False  # Keep all combinations\n",
    "    ).reindex(\n",
    "        index=pd.MultiIndex.from_product([x_bins, y_bins]),\n",
    "        columns=dir_bins,\n",
    "        fill_value=0  # Fill missing combinations with 0\n",
    "    ).values.reshape(n_x_bins, n_y_bins, n_dir_bins)\n",
    "    \n",
    "    return occupancy_map, {'x': n_x_bins, 'y': n_y_bins, 'dir': n_dir_bins}\n",
    "\n",
    "\n",
    "# 1. Compute the 3D occupancy map\n",
    "# occupancy_map, bin_counts = compute_3d_occupancy_map(global_pos_df)\n",
    "\n",
    "occupancy_map, bin_counts = compute_3d_occupancy_map(global_pos_df, n_x_bins=n_xbins, n_y_bins=n_ybins, n_dir_bins=n_dir_bins)\n",
    "\n",
    "# Print the shape and counts\n",
    "print(f\"Occupancy map shape: {occupancy_map.shape}\")\n",
    "print(f\"Unique bins per dimension: {bin_counts}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa65c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "from pyphoplacecellanalysis.External.pyqtgraph.Qt import QtCore, QtGui\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow\n",
    "\n",
    "class CircularBinnedImageRenderingWindow(BasicBinnedImageRenderingWindow):\n",
    "    \"\"\"Renders circular/angular heatmaps within each spatial bin\"\"\"\n",
    "    \n",
    "    def __init__(self, angular_matrix, xbins=None, ybins=None, n_angle_bins: int=None, **kwargs):\n",
    "        \"\"\"\n",
    "        angular_matrix: shape (n_x_bins, n_y_bins, n_angle_bins) containing angular distribution data\n",
    "        \"\"\"\n",
    "        assert n_angle_bins is not None\n",
    "        pos_only_mat = np.sum(deepcopy(angular_matrix), axis=-1)\n",
    "        super().__init__(matrix=pos_only_mat, xbins=xbins, ybins=ybins, **kwargs)\n",
    "        self.n_angle_bins = n_angle_bins\n",
    "        self.angular_data = deepcopy(angular_matrix)\n",
    "        \n",
    "    def add_circular_heatmap(self, bin_x: int, bin_y: int, angular_data: np.ndarray) -> None:\n",
    "        \"\"\"Adds a circular heatmap to a specific spatial bin\"\"\"\n",
    "        # Create circular representation\n",
    "        theta = np.linspace(0, 2*np.pi, self.n_angle_bins+1)[:-1]  # Angular positions\n",
    "        r = angular_data  # Radial values from angular distribution\n",
    "        \n",
    "        # Convert to cartesian coordinates\n",
    "        x = r * np.cos(theta)\n",
    "        y = r * np.sin(theta)\n",
    "        \n",
    "        # Create polygon for the circular heatmap\n",
    "        polygon = QtGui.QPolygonF()\n",
    "        for px, py in zip(x, y):\n",
    "            polygon.append(QtCore.QPointF(px + bin_x + 0.5, py + bin_y + 0.5))\n",
    "            \n",
    "        # Create path for smooth rendering\n",
    "        path = QtGui.QPainterPath()\n",
    "        path.addPolygon(polygon)\n",
    "        path.closeSubpath()\n",
    "        \n",
    "        # Create graphics item\n",
    "        item = pg.QtGui.QGraphicsPathItem(path)\n",
    "        \n",
    "        # Set color based on distribution intensity\n",
    "        color = pg.mkColor('w')  # Base color\n",
    "        color.setAlphaF(0.7)     # Semi-transparent\n",
    "        item.setBrush(pg.mkBrush(color))\n",
    "        item.setPen(pg.mkPen(None))  # No border\n",
    "        \n",
    "        # Add to plot\n",
    "        assert len(window.plot_names) > 0 is not None # 'angular_distribution'\n",
    "        plot_name: str = window.plot_names[0]\n",
    "        assert plot_name in self.plots, f\"plot_name: {plot_name} not in self.plots\"\n",
    "        self.plots[plot_name].mainPlotItem.addItem(item)\n",
    "        \n",
    "\n",
    "    def render_all_circular_heatmaps(self):\n",
    "        \"\"\"Renders circular heatmaps for all spatial bins\"\"\"\n",
    "        n_x, n_y, _ = self.angular_data.shape\n",
    "        \n",
    "        for x in range(n_x):\n",
    "            for y in range(n_y):\n",
    "                angular_dist = self.angular_data[x, y]\n",
    "                # Normalize the distribution\n",
    "                if np.sum(angular_dist) > 0:\n",
    "                    angular_dist = angular_dist / np.max(angular_dist)\n",
    "                    self.add_circular_heatmap(x, y, angular_dist)\n",
    "\n",
    "    def init_UI(self):\n",
    "        \"\"\"Initialize the UI and render circular heatmaps\"\"\"\n",
    "        super().init_UI()\n",
    "        # self.render_all_circular_heatmaps()\n",
    "\n",
    "\n",
    "\n",
    "# ## INPUTS: occupancy_map, n_xbins, n_ybins n_x_bins=n_xbins, n_y_bins=n_ybins, n_dir_bins=n_dir_bins\n",
    "# Create sample angular distribution data\n",
    "# n_x_bins, n_y_bins = 10, 10\n",
    "# n_angle_bins = 36\n",
    "# angular_matrix = np.random.rand(n_x_bins, n_y_bins, n_angle_bins)\n",
    "angular_matrix = deepcopy(occupancy_map)\n",
    "\n",
    "# Create window\n",
    "window = CircularBinnedImageRenderingWindow(\n",
    "    angular_matrix=angular_matrix,\n",
    "    xbins=np.arange(n_xbins),\n",
    "    ybins=np.arange(n_ybins),\n",
    "    n_angle_bins=n_dir_bins,\n",
    "    name='angular_distribution',\n",
    "    title='Angular Distribution per Position Bin'\n",
    ")\n",
    "\n",
    "window.render_all_circular_heatmaps()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8868fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spatial_angular_distributions(occupancy_map, subsample_factor=5):\n",
    "    \"\"\"Plot radar charts of angular distributions across spatial positions\n",
    "    \n",
    "    Args:\n",
    "        occupancy_map (np.ndarray): 3D array (x_bins, y_bins, direction_bins)\n",
    "        subsample_factor (int): Plot every Nth spatial bin to avoid overcrowding\n",
    "\n",
    "\n",
    "    Usage:    \n",
    "        fig, ax = plot_spatial_angular_distributions(occupancy_map, subsample_factor=4)\n",
    "        plt.show()\n",
    "\n",
    "    \"\"\"\n",
    "    n_x, n_y, n_angles = occupancy_map.shape\n",
    "    \n",
    "    # Create main figure\n",
    "    fig, ax = plt.subplots(figsize=(25, 15), clear=True, num='test')\n",
    "    \n",
    "    # Calculate angles for radar plot (in radians)\n",
    "    # theta = np.linspace(0, 2*np.pi, n_angles, endpoint=False)\n",
    "    # Calculate bin edges for rose plot\n",
    "    bins = np.linspace(0, 2*np.pi, n_angles+1)    \n",
    "\n",
    "    \n",
    "    # Plot radar at each subsampled position\n",
    "    for i in range(0, n_x, subsample_factor):\n",
    "        for j in range(0, n_y, subsample_factor):\n",
    "            # Get angular distribution at this position\n",
    "            values = occupancy_map[i,j,:]\n",
    "            \n",
    "            # Create small axes for this position\n",
    "            # radar_ax = fig.add_axes([i/n_x, j/n_y, 1/n_x, 1/n_y], projection='polar')\n",
    "            # radar_ax.plot(theta, values)\n",
    "            # radar_ax.fill(theta, values, alpha=0.25)\n",
    "            \n",
    "            # Create small axes for this position\n",
    "            _new_radial_ax = fig.add_axes([i/n_x, j/n_y, 1/n_x, 1/n_y], projection='polar')\n",
    "            \n",
    "            # Create rose plot using hist\n",
    "            _new_radial_ax.hist(bins[:-1], bins=bins, weights=values, density=False, histtype='stepfilled')\n",
    "\n",
    "            # pc = _new_radial_ax.pcolormesh(A, R, hist.T, cmap=\"magma_r\")\n",
    "            # fig.colorbar(pc)\n",
    "            # _new_radial_ax.grid(True)\n",
    "\n",
    "            _new_radial_ax.set_xticks([])\n",
    "            _new_radial_ax.set_yticks([])\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "# angles = np.deg2rad(global_pos_df['approx_head_dir_degrees'])\n",
    "# # Create circular histogram\n",
    "# fig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\n",
    "# ax.hist(angles, bins=36, density=True, alpha=0.70)\n",
    "# # Set labels\n",
    "# ax.set_title(\"Circular Histogram of Head Direction\")\n",
    "\n",
    "\n",
    "fig, ax = plot_spatial_angular_distributions(occupancy_map, subsample_factor=4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcf5050",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def radial_histogram(data, bins=12, ax=None):\n",
    "    if ax is None:\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='polar')\n",
    "    counts, edges = np.histogram(data, bins=bins, range=(0, 2*np.pi))\n",
    "    widths = np.diff(edges)\n",
    "    ax.bar(edges[:-1], counts, width=widths, bottom=0, align='edge', color='blue', alpha=0.5)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    return ax\n",
    "\n",
    "def plot_spatial_angular_distributions(occupancy_map, subsample_factor=5):\n",
    "    n_x, n_y, n_angles = occupancy_map.shape\n",
    "    fig, ax = plt.subplots(figsize=(25, 15), clear=True, num='test')\n",
    "\n",
    "    # Draw grid boxes for each x/y bin\n",
    "    for i in range(n_x):\n",
    "        for j in range(n_y):\n",
    "            x0 = i / n_x\n",
    "            y0 = j / n_y\n",
    "            w_ = 1 / n_x\n",
    "            h_ = 1 / n_y\n",
    "            rect = plt.Rectangle((x0, y0), w_, h_, fill=False, color='black', lw=1, transform=fig.transFigure)\n",
    "            fig.add_artist(rect)\n",
    "\n",
    "    # Size of each small polar subplot\n",
    "    w = 0.6 * (subsample_factor / n_x)\n",
    "    h = 0.6 * (subsample_factor / n_y)\n",
    "\n",
    "    for i in range(0, n_x, subsample_factor):\n",
    "        for j in range(0, n_y, subsample_factor):\n",
    "            counts = occupancy_map[i, j, :]\n",
    "            angles = np.hstack([np.full(int(counts[k]), (2*np.pi*(k + 0.5)) / n_angles) for k in range(n_angles)])\n",
    "            pos_x = i / n_x\n",
    "            pos_y = j / n_y\n",
    "            ax_sub = fig.add_axes([pos_x, pos_y, w, h], projection='polar')\n",
    "            radial_histogram(angles, bins=n_angles, ax=ax_sub)\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "fig, ax = plot_spatial_angular_distributions(occupancy_map, subsample_factor=2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba48de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_radial_lines(rect_width, rect_height, n_bins):\n",
    "    \"\"\"Draws lines from rectangle center to perimeter, creating equal angular divisions\n",
    "    \n",
    "    Args:\n",
    "        rect_width (float): Width of rectangle\n",
    "        rect_height (float): Height of rectangle\n",
    "        n_bins (int): Number of angular divisions desired\n",
    "    \n",
    "    Returns:\n",
    "        list of tuples: [(x1,y1,x2,y2)] coordinates for each line\n",
    "    \"\"\"\n",
    "    # Calculate center point\n",
    "    center_x = rect_width / 2\n",
    "    center_y = rect_height / 2\n",
    "    \n",
    "    # Calculate angles for each division\n",
    "    angles = np.linspace(0, 2*np.pi, n_bins, endpoint=False)\n",
    "    \n",
    "    lines = []\n",
    "    for angle in angles:\n",
    "        # Calculate direction vector\n",
    "        dx = np.cos(angle)\n",
    "        dy = np.sin(angle)\n",
    "        \n",
    "        # Find intersection with rectangle boundary\n",
    "        # Scale factor t = min positive value that hits boundary\n",
    "        t_values = []\n",
    "        \n",
    "        # Check horizontal boundaries\n",
    "        if dx != 0:\n",
    "            t_values.extend([\n",
    "                (0 - center_x) / dx,  # Left boundary\n",
    "                (rect_width - center_x) / dx  # Right boundary\n",
    "            ])\n",
    "            \n",
    "        # Check vertical boundaries\n",
    "        if dy != 0:\n",
    "            t_values.extend([\n",
    "                (0 - center_y) / dy,  # Bottom boundary\n",
    "                (rect_height - center_y) / dy  # Top boundary\n",
    "            ])\n",
    "            \n",
    "        # Get smallest positive t value\n",
    "        t = min(t for t in t_values if t > 0)\n",
    "        \n",
    "        # Calculate endpoint\n",
    "        end_x = center_x + t * dx\n",
    "        end_y = center_y + t * dy\n",
    "        \n",
    "        lines.append((center_x, center_y, end_x, end_y))\n",
    "    \n",
    "    return lines\n",
    "\n",
    "plt.figure(num='box_line_test',clear=True)\n",
    "# Draw 8 radial divisions in a 100x80 rectangle\n",
    "lines = draw_radial_lines(100, 80, 8)\n",
    "\n",
    "# Plot the lines\n",
    "for x1,y1,x2,y2 in lines:\n",
    "    plt.plot([x1,x2], [y1,y2], 'k-')\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43816b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_directional_occupancy(occupancy_map, direction_bin):\n",
    "    \"\"\"Plot 2D heatmap for a specific head direction bin\"\"\"\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.imshow(occupancy_map[:,:,direction_bin], origin='lower')\n",
    "    plt.colorbar(label='Count')\n",
    "    plt.title(f'Occupancy for Direction Bin {direction_bin}')\n",
    "    plt.xlabel('X bin')\n",
    "    plt.ylabel('Y bin')\n",
    "\n",
    "\n",
    "# 2. Visualize a single direction slice\n",
    "direction_bin = 1  # Example: looking at 180 degrees if using 36 bins\n",
    "plot_directional_occupancy(occupancy_map, direction_bin)\n",
    "\n",
    "# 3. Get total occupancy across all directions\n",
    "total_spatial_occupancy = np.sum(occupancy_map, axis=2)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(total_spatial_occupancy, origin='lower')\n",
    "plt.colorbar(label='Total Count')\n",
    "plt.title('Total Spatial Occupancy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b283b133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spatial_angular_distributions(occupancy_map, subsample_factor=5):\n",
    "    \"\"\"Plot radar charts of angular distributions across spatial positions\n",
    "    \n",
    "    Args:\n",
    "        occupancy_map (np.ndarray): 3D array (x_bins, y_bins, direction_bins)\n",
    "        subsample_factor (int): Plot every Nth spatial bin to avoid overcrowding\n",
    "    \"\"\"\n",
    "    n_x, n_y, n_angles = occupancy_map.shape\n",
    "    \n",
    "    # Create main figure\n",
    "    fig, ax = plt.subplots(figsize=(25, 15), clear=True, num='test')\n",
    "    \n",
    "    # Calculate angles for radar plot (in radians)\n",
    "    # theta = np.linspace(0, 2*np.pi, n_angles, endpoint=False)\n",
    "    # Calculate bin edges for rose plot\n",
    "    bins = np.linspace(0, 2*np.pi, n_angles+1)    \n",
    "\n",
    "    \n",
    "    # Plot radar at each subsampled position\n",
    "    for i in range(0, n_x, subsample_factor):\n",
    "        for j in range(0, n_y, subsample_factor):\n",
    "            # Get angular distribution at this position\n",
    "            values = occupancy_map[i,j,:]\n",
    "            \n",
    "            # Create small axes for this position\n",
    "            # radar_ax = fig.add_axes([i/n_x, j/n_y, 1/n_x, 1/n_y], projection='polar')\n",
    "            # radar_ax.plot(theta, values)\n",
    "            # radar_ax.fill(theta, values, alpha=0.25)\n",
    "            \n",
    "            # Create small axes for this position\n",
    "            _new_radial_ax = fig.add_axes([i/n_x, j/n_y, 1/n_x, 1/n_y], projection='polar')\n",
    "            \n",
    "            # Create rose plot using hist\n",
    "            _new_radial_ax.hist(bins[:-1], bins=bins, weights=values, density=False, histtype='stepfilled')\n",
    "\n",
    "            # pc = _new_radial_ax.pcolormesh(A, R, hist.T, cmap=\"magma_r\")\n",
    "            # fig.colorbar(pc)\n",
    "            # _new_radial_ax.grid(True)\n",
    "\n",
    "            _new_radial_ax.set_xticks([])\n",
    "            _new_radial_ax.set_yticks([])\n",
    "    \n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "# angles = np.deg2rad(global_pos_df['approx_head_dir_degrees'])\n",
    "# # Create circular histogram\n",
    "# fig, ax = plt.subplots(subplot_kw={'projection': 'polar'})\n",
    "# ax.hist(angles, bins=36, density=True, alpha=0.70)\n",
    "# # Set labels\n",
    "# ax.set_title(\"Circular Histogram of Head Direction\")\n",
    "\n",
    "\n",
    "fig, ax = plot_spatial_angular_distributions(occupancy_map, subsample_factor=4)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0dcb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "50*5*8\n",
    "\n",
    "# 135/5 -> 27\n",
    "# 472/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf7581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xbin_edges = global_pf2D.xbin\n",
    "ybin_edges = global_pf2D.ybin\n",
    "# Create evenly spaced bin edges from 0 to 360\n",
    "n_dir_bins: int = 8\n",
    "angle_dir_bin_edges = np.linspace(0, 360, n_dir_bins + 1)\n",
    "\n",
    "# Use pd.cut with the explicit bin edges\n",
    "global_pos_df['head_dir_angle_binned'] = pd.cut(global_pos_df['approx_head_dir_degrees'], bins=angle_dir_bin_edges, labels=False, include_lowest=True)\n",
    "global_pos_df = global_pos_df.position.adding_binned_position_columns(xbin_edges=xbin_edges, ybin_edges=ybin_edges)\n",
    "global_pos_df = global_pos_df.dropna(axis='index', subset=['binned_x', 'binned_y', 'head_dir_angle_binned'])\n",
    "global_pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f301f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xbin_edges = global_pf2D.xbin\n",
    "ybin_edges = global_pf2D.ybin\n",
    "# Create evenly spaced bin edges from 0 to 360\n",
    "n_dir_bins: int = 8\n",
    "angle_dir_bin_edges = np.linspace(0, 360, n_dir_bins + 1)\n",
    "\n",
    "# Use pd.cut with the explicit bin edges\n",
    "global_pos_df['head_dir_angle_binned'] = pd.cut(global_pos_df['approx_head_dir_degrees'], bins=angle_dir_bin_edges, labels=False, include_lowest=True)\n",
    "global_pos_df = global_pos_df.position.adding_binned_position_columns(xbin_edges=xbin_edges, ybin_edges=ybin_edges)\n",
    "global_pos_df = global_pos_df.dropna(axis='index', subset=['binned_x', 'binned_y', 'head_dir_angle_binned'])\n",
    "global_pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2e9051",
   "metadata": {},
   "outputs": [],
   "source": [
    "xbin_edges = global_pf2D.xbin\n",
    "ybin_edges = global_pf2D.ybin\n",
    "# Create evenly spaced bin edges from 0 to 360\n",
    "n_dir_bins: int = 8\n",
    "angle_dir_bin_edges = np.linspace(0, 360, n_dir_bins + 1)\n",
    "\n",
    "# Use pd.cut with the explicit bin edges\n",
    "global_pos_df['head_dir_angle_binned'] = pd.cut(global_pos_df['approx_head_dir_degrees'], bins=angle_dir_bin_edges, labels=False, include_lowest=True)\n",
    "global_pos_df = global_pos_df.position.adding_binned_position_columns(xbin_edges=xbin_edges, ybin_edges=ybin_edges)\n",
    "global_pos_df = global_pos_df.dropna(axis='index', subset=['binned_x', 'binned_y', 'head_dir_angle_binned'])\n",
    "global_pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44522f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now I have the columns `global_pos_df[['binned_x', 'binned_y', 'head_dir_angle_binned']]` and I'd like to visualize a heatmap showing:\n",
    "1. and "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd768a42",
   "metadata": {},
   "source": [
    "# <a id='toc30_'></a>[2025-02-10 - Proper Timeline Slider Widget](#toc0_)\n",
    "Should show a 2D raster of all firing, potentially downsampled to minimize the number of points that have to be drawn and the crowding.\n",
    "HOLDUP #TODO 2025-02-10 09:05: - [ ] Currently `Render2DScrollWindowPlotMixin` manages much of this functionality, but `Spike2DRaster` extends it because it includes the ability to add Epochs (and perhaps more) in addition to spikes.\n",
    "\n",
    "Has two modes: TimelineModePoint, TimelineModeRange\n",
    "\n",
    "Provides two corresponding callback signals: sigTimePointUpdated: float, sigTimeRangeUpdated: (float, float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9039aed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.enum_helpers import StringLiteralComparableEnum\n",
    "\n",
    "# Define your custom enum type:\n",
    "class TimelineSelectMode(StringLiteralComparableEnum):\n",
    "    \"\"\" \n",
    "    Has two modes: TimelineModePoint, TimelineModeRange\n",
    "\n",
    "    Provides two corresponding callback signals: sigTimePointUpdated: float, sigTimeRangeUpdated: (float, float)\n",
    "    \"\"\"\n",
    "    POINT = \"point\"\n",
    "    RANGE = \"range\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e932fb",
   "metadata": {},
   "source": [
    "# <a id='toc31_'></a>[2025-02-10 - Final Filtering by qclu/neuron_IDs/etc](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f9f8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "global_computation_results = curr_active_pipeline.global_computation_results\n",
    "\n",
    "rank_order_results = curr_active_pipeline.global_computation_results.computed_data.get('RankOrder', None) # : \"RankOrderComputationsContainer\"\n",
    "if rank_order_results is not None:\n",
    "    minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "else:        \n",
    "    ## get from parameters:\n",
    "    minimum_inclusion_fr_Hz: float = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.included_qclu_values\n",
    "\n",
    "\n",
    "directional_laps_results: DirectionalLapsResult = global_computation_results.computed_data['DirectionalLaps']\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\n",
    "print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "print(f'included_qclu_values: {included_qclu_values}')\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "ripple_decoding_time_bin_size: float = directional_merged_decoders_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_merged_decoders_result.laps_decoding_time_bin_size\n",
    "# pos_bin_size = _recover_position_bin_size(track_templates.get_decoders()[0]) # 3.793023081021702\n",
    "# print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}, ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}, pos_bin_size: {pos_bin_size}')\n",
    "# pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e86b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult, DirectionalLapsResult, DirectionalDecodersContinuouslyDecodedResult\n",
    "\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']   \n",
    "rank_order_results: RankOrderComputationsContainer = curr_active_pipeline.global_computation_results.computed_data.get('RankOrder', None)\n",
    "if rank_order_results is not None:\n",
    "    minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "else:        \n",
    "    ## get from parameters:\n",
    "    minimum_inclusion_fr_Hz: float = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.included_qclu_values\n",
    "\n",
    "print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "print(f'included_qclu_values: {included_qclu_values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a05f85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9b9689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses.placefields import PfND\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BasePositionDecoder\n",
    "\n",
    "# Set your thresholds\n",
    "minimum_inclusion_fr_Hz = 5.0  # Only include neurons with peak FR >= 5Hz\n",
    "included_qclu_values = [2, 3]  # Only include neurons with qclu values 2 or 3\n",
    "\n",
    "# Get filtered PFs and filtered neuron IDs\n",
    "filtered_pf_dict, filtered_direction_shared_aclus_list = PfND.determine_pf_aclus_filtered_by_frate_and_qclu(\n",
    "    pf_dict=results1D.pfs,\n",
    "    minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz,\n",
    "    included_qclu_values=included_qclu_values\n",
    ")\n",
    "\n",
    "filtered_direction_shared_aclus_list\n",
    "filtered_decoders = {k:v.get_by_id(an_included_neuron_IDs) for an_included_neuron_IDs, (k, v) in zip(filtered_direction_shared_aclus_list, results1D.decoders.items())}\n",
    "filtered_decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7960bfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(active_2d_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84867b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a01546",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: all_time_bin_sizes_output_dict\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, DockDisplayColors\n",
    "\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import AddNewDecodedPosteriors_MatplotlibPlotCommand\n",
    "## plot only a single time bin for now:\n",
    "cached_decoded_time_bin_size_list = list(all_time_bin_sizes_output_dict.keys())\n",
    "assert len(cached_decoded_time_bin_size_list) > 0\n",
    "active_time_bin_size: float = cached_decoded_time_bin_size_list[0]\n",
    "info_string: str = f'{active_time_bin_size:.2f}'\n",
    "## one for each of the four decoders:\n",
    "a_split_pseudo2D_continuous_result_to_1D_continuous_result_dict: Dict[types.DecoderName, SingleEpochDecodedResult] = all_time_bin_sizes_output_dict[active_time_bin_size]\n",
    "dock_group_sep_character: str = '_'\n",
    "showCloseButton = True\n",
    "_common_dock_config_kwargs = {'dock_group_names': [dock_group_sep_character.join([f'ContinuousDecode', info_string])], 'showCloseButton': showCloseButton}\n",
    "dock_configs = dict(zip(('long_LR', 'long_RL', 'short_LR', 'short_RL'),\n",
    "\t\t\t\t\t\t(CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Laps.get_LR_dock_colors, **_common_dock_config_kwargs),\n",
    "                        CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Laps.get_RL_dock_colors, **_common_dock_config_kwargs),\n",
    "                        CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Laps.get_LR_dock_colors, **_common_dock_config_kwargs),\n",
    "                        CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Laps.get_RL_dock_colors, **_common_dock_config_kwargs))))\n",
    "\n",
    "\n",
    "# Need all_directional_pf1D_Decoder_dict\n",
    "output_dict = {}\n",
    "a_dock_config = dock_configs[a_decoder_name]\n",
    "a_1D_decoder: BasePositionDecoder = all_directional_pf1D_Decoder_dict[a_decoder_name]\n",
    "\n",
    "active_2d_plot.add_\n",
    "_out_tuple = AddNewDecodedPosteriors_MatplotlibPlotCommand._perform_add_new_decoded_posterior_row(curr_active_pipeline=curr_active_pipeline, active_2d_plot=active_2d_plot, a_dock_config=a_dock_config, a_decoder_name=a_decoder_name, a_position_decoder=a_1D_decoder,\n",
    "                                                            time_window_centers=a_1D_continuous_decoded_result.time_bin_container.centers, a_1D_posterior=a_1D_continuous_decoded_result.p_x_given_n, extended_dock_title_info=info_string)\n",
    "identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = _out_tuple\n",
    "## Add `a_decoded_result` to the plots_data\n",
    "widget.plots_data.a_decoded_result = a_1D_continuous_decoded_result\n",
    "\n",
    "output_dict[a_decoder_name] = _out_tuple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb1b75c",
   "metadata": {},
   "source": [
    "# <a id='toc32_'></a>[2025-02-20 - `Pseudo-PosByContextDecoder`](#toc0_)\n",
    "## <a id='toc32_1_'></a>[In general, the requirement for building a Pseudo2D (or more general a Pseudo-PosByContextDecoder) is that all bins are mutually exclusive](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe538ae",
   "metadata": {},
   "source": [
    "#TODO 2025-02-25 13:54: - [ ] `plot_attached_BinByBinDecodingDebugger`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3af425b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import plot_attached_BinByBinDecodingDebugger\n",
    "\n",
    "## INPUTS: a_decoder, a_decoded_result\n",
    "win, out_pf1D_decoder_template_objects, (plots_container, plots_data), _on_update_fcn = plot_attached_BinByBinDecodingDebugger(spike_raster_window, curr_active_pipeline, a_decoder=a_decoder, a_decoded_result=a_decoded_result)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e39f9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import SingleEpochDecodedResult\n",
    "from neuropy.utils.mixins.indexing_helpers import UnpackableMixin, get_dict_subset\n",
    "from neuropy.utils.indexing_helpers import PandasHelpers, flatten, ListHelpers, NumpyHelpers\n",
    "\n",
    "flat_widgets_list = active_2d_plot.get_flat_widgets_list()\n",
    "# flat_plots_data_list = active_2d_plot.get_flat_widgets_list()\n",
    "desired_plots_data_key_names = ['a_decoder', 'matrix', 'time_window_centers']\n",
    "\n",
    "plots_data_dict = {}\n",
    "plots_data_dict = {}\n",
    "for a_widget in flat_widgets_list:\n",
    "    if hasattr(a_widget, 'plots_data'):\n",
    "        a_plots_data = a_widget.plots_data\n",
    "        # a_plots_data\n",
    "        has_all_attrs: bool = np.all([a_plots_data.has_attr(key_name) for key_name in desired_plots_data_key_names])\n",
    "        if has_all_attrs:\n",
    "            # if hasattr(a_plots_data, 'a_decoder'):\n",
    "            ## get the decoder\n",
    "            # getattr(a_plots_data, 'a_decoder')\n",
    "            a_decoded_posterior_plots_data_dict = get_dict_subset(a_plots_data.to_dict(), desired_plots_data_key_names)\n",
    "            single_epoch_result: SingleEpochDecodedResult = SingleEpochDecodedResult(p_x_given_n=a_plots_data.matrix, time_bin **a_decoded_posterior_plots_data_dict)\n",
    "            a_plots_data.single_epoch_result = single_epoch_result\n",
    "            plots_data_dict[a_widget.params.name] = a_plots_data\n",
    "\n",
    "# plots_data_dict\n",
    "\n",
    "# desired_plots_data_key_names\n",
    "\n",
    "a_plots_data\n",
    "# SingleEpochDecodedResult\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b617c11",
   "metadata": {},
   "source": [
    "## <a id='toc32_2_'></a>[Get 1D representations of the Pseudo2D track (4 decoders) so they can be plotted on seperate tracks and bin-debugged independently.](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd94fd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = active_2d_plot.compute_if_needed_and_add_continuous_decoded_posterior(curr_active_pipeline=curr_active_pipeline, desired_time_bin_size=0.05, debug_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b821104",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = active_2d_plot.compute_if_needed_and_add_continuous_decoded_posterior(curr_active_pipeline=curr_active_pipeline, desired_time_bin_size=0.025, debug_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2e7918",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3c784d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.indexing_helpers import get_dict_subset\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalDecodersContinuouslyDecodedResult, DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import SingleEpochDecodedResult\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, DockDisplayColors\n",
    "\n",
    "debug_print = True\n",
    "\n",
    "## Uses the `global_computation_results.computed_data['DirectionalDecodersDecoded']`\n",
    "directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "pseudo2D_decoder: BasePositionDecoder = directional_decoders_decode_result.pseudo2D_decoder  # merged pseudo2D decoder\n",
    "all_directional_pf1D_Decoder_dict: Dict[types.DecoderName, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict ## separate 1D decoders\n",
    "\n",
    "continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "\n",
    "\n",
    "all_time_bin_sizes_output_dict: Dict[float, Dict[types.DecoderName, SingleEpochDecodedResult]] = directional_decoders_decode_result.split_pseudo2D_continuous_result_to_1D_continuous_result()\n",
    "## OUTPUTS: all_directional_pf1D_Decoder_dict, all_time_bin_sizes_output_dict, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9335f589",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Common/shared for all decoded epochs:\n",
    "unique_decoder_names = ['long', 'short']\n",
    "non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict, non_PBE_marginal_over_track_ID, (time_bin_containers, time_window_centers, track_marginal_posterior_df) = nonPBE_results._build_merged_joint_placefields_and_decode(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline))) # , filter_epochs=deepcopy(global_any_laps_epochs_obj)\n",
    "\n",
    "## from dict of filter_epochs to decode:\n",
    "global_replays_df: pd.DataFrame = TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].replay))\n",
    "filter_epochs_to_decode_dict: Dict[KnownNamedDecodingEpochsType, Epoch] = {'laps': ensure_Epoch(deepcopy(global_any_laps_epochs_obj)),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   'pbe': ensure_Epoch(deepcopy(global_session.pbe.get_non_overlapping())),\n",
    "\t\t\t\t\t\t\t\t#  'ripple': ensure_Epoch(deepcopy(global_session.ripple)),\n",
    "\t\t\t\t\t\t\t\t#   'replay': ensure_Epoch(deepcopy(global_replays_df)),\n",
    "\t\t\t\t\t\t\t\t  'non_pbe': ensure_Epoch(deepcopy(global_session.non_pbe)),\n",
    "\t\t\t\t\t\t\t\t  }\n",
    "# filter_epochs_to_decode_dict\n",
    "\n",
    "## Perform the decoding and masking as needed for invalid bins:\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "a_general_decoder_dict_decoded_epochs_dict_result: GeneralDecoderDictDecodedEpochsDictResult = EpochComputationsComputationsContainer._build_output_decoded_posteriors(non_PBE_all_directional_pf1D_Decoder=non_PBE_all_directional_pf1D_Decoder, # pseudo2D_continuous_specific_decoded_result=pseudo2D_continuous_specific_decoded_result,\n",
    "    filter_epochs_to_decode_dict=filter_epochs_to_decode_dict,\n",
    "    unique_decoder_names=unique_decoder_names, spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), epochs_decoding_time_bin_size=epochs_decoding_time_bin_size,\n",
    "    session_name=session_name, t_start=t_start, t_delta=t_delta, t_end=t_end,\n",
    ")\n",
    "\n",
    "\n",
    "## OUTPUTS: filter_epochs_pseudo2D_continuous_specific_decoded_result, filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict\n",
    "# 58sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81706b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(continuously_decoded_result_cache_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50c1170",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uses `AddNewDecodedPosteriors_MatplotlibPlotCommand._perform_add_new_decoded_posterior_row(...)` to build the 4 tracks from the split result:\n",
    "# active_2d_plot.add_new_embedded_pyqtgraph_render_plot_widget(\n",
    "\"\"\"\n",
    "add_new_matplotlib_render_plot_widget\n",
    "add_new_matplotlib_render_plot_widget\n",
    "add_new_embedded_pyqtgraph_render_plot_widget\n",
    "\"\"\"\n",
    "## INPUTS: all_time_bin_sizes_output_dict\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import AddNewDecodedPosteriors_MatplotlibPlotCommand\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, DockDisplayColors\n",
    "\n",
    "## plot only a single time bin for now:\n",
    "cached_decoded_time_bin_size_list = list(all_time_bin_sizes_output_dict.keys())\n",
    "assert len(cached_decoded_time_bin_size_list) > 0\n",
    "active_time_bin_size: float = cached_decoded_time_bin_size_list[0]\n",
    "info_string: str = f'{active_time_bin_size:.2f}'\n",
    "## one for each of the four decoders:\n",
    "a_split_pseudo2D_continuous_result_to_1D_continuous_result_dict: Dict[types.DecoderName, SingleEpochDecodedResult] = all_time_bin_sizes_output_dict[active_time_bin_size]\n",
    "dock_group_sep_character: str = '_'\n",
    "showCloseButton = True\n",
    "_common_dock_config_kwargs = {'dock_group_names': [dock_group_sep_character.join([f'ContinuousDecode', info_string])], 'showCloseButton': showCloseButton}\n",
    "dock_configs = dict(zip(('long_LR', 'long_RL', 'short_LR', 'short_RL'),\n",
    "\t\t\t\t\t\t(CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Laps.get_LR_dock_colors, **_common_dock_config_kwargs),\n",
    "                        CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Laps.get_RL_dock_colors, **_common_dock_config_kwargs),\n",
    "                        CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Laps.get_LR_dock_colors, **_common_dock_config_kwargs),\n",
    "                        CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Laps.get_RL_dock_colors, **_common_dock_config_kwargs))))\n",
    "\n",
    "\n",
    "## all at once:\n",
    "output_dict = active_2d_plot.add_docked_decoded_results_dict_tracks(name=f'DirectionalDecodersDecoded', a_decoded_result_dict=a_split_pseudo2D_continuous_result_to_1D_continuous_result_dict, dock_configs=dock_configs, pf1D_Decoder_dict=all_directional_pf1D_Decoder_dict,\n",
    "                                                                                            measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "                                                                                            extended_dock_title_info=info_string)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6828e1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Need all_directional_pf1D_Decoder_dict\n",
    "output_dict = {}\n",
    "for a_decoder_name, a_1D_continuous_decoded_result in a_split_pseudo2D_continuous_result_to_1D_continuous_result_dict.items():\n",
    "    ## a_1D_continuous_decoded_result: SingleEpochDecodedResult\n",
    "    a_dock_config = dock_configs[a_decoder_name]\n",
    "    a_1D_decoder: BasePositionDecoder = all_directional_pf1D_Decoder_dict[a_decoder_name]\n",
    "    # _out_tuple = AddNewDecodedPosteriors_MatplotlibPlotCommand._perform_add_new_decoded_posterior_row(curr_active_pipeline=curr_active_pipeline, active_2d_plot=active_2d_plot, a_dock_config=a_dock_config, a_decoder_name=a_decoder_name, a_position_decoder=a_1D_decoder,\n",
    "    #                                                             time_window_centers=a_1D_continuous_decoded_result.time_bin_container.centers, a_1D_posterior=a_1D_continuous_decoded_result.p_x_given_n, extended_dock_title_info=info_string)\n",
    "    _out_tuple = active_2d_plot.add_docked_decoded_posterior_track(name=f'DirectionalDecodersDecoded[{a_decoder_name}]', a_dock_config=a_dock_config,\n",
    "                                                                                            time_window_centers=a_1D_continuous_decoded_result.time_bin_container.centers, a_1D_posterior=a_1D_continuous_decoded_result.p_x_given_n,\n",
    "                                                                                            xbin = deepcopy(a_1D_decoder.xbin), measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "                                                                                            extended_dock_title_info=info_string)\n",
    "\n",
    "    identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = _out_tuple\n",
    "    ## Add `a_decoded_result` to the plots_data\n",
    "    widget.plots_data.a_decoded_result = a_1D_continuous_decoded_result\n",
    "    widget.plots_data.a_decoder = deepcopy(a_1D_decoder)\n",
    "    output_dict[a_decoder_name] = _out_tuple\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56538c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_decoder_name, an_out_tuple in output_dict.items():\n",
    "    identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = an_out_tuple\n",
    "    print(f'a_decoder_name: {a_decoder_name} -- identifier_name: \"{identifier_name}\"')\n",
    "\n",
    "    # dDisplayItem.orientation\n",
    "    dDisplayItem.autoOrient = False\n",
    "    # dDisplayItem.setOrientation('horizontal', force=True)\n",
    "    dDisplayItem.setOrientation('vertical', force=True)\n",
    "    dDisplayItem.label.relayout_text()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f833550",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_decoder_name, an_out_tuple in output_dict.items():\n",
    "    identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = an_out_tuple\n",
    "    print(f'a_decoder_name: {a_decoder_name} -- identifier_name: \"{identifier_name}\"')\n",
    "    # widget.plots_data.data_keys\n",
    "    widget.plots_data.a_decoded_result = a_1D_continuous_decoded_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450d37f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import plot_attached_BinByBinDecodingDebugger\n",
    "\n",
    "a_decoder_name: types.DecoderName = 'long_LR'\n",
    "identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = output_dict[a_decoder_name]\n",
    "a_1D_continuous_decoded_result = widget.plots_data.a_decoded_result\n",
    "a_decoder = widget.plots_data.a_decoder\n",
    "## INPUTS: a_decoder, a_decoded_result\n",
    "win, out_pf1D_decoder_template_objects, (plots_container, plots_data), _on_update_fcn = plot_attached_BinByBinDecodingDebugger(spike_raster_window, curr_active_pipeline, a_decoder=a_decoder, a_decoded_result=a_1D_continuous_decoded_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b217f221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_1D_continuous_decoded_result.epoch_info_tuple\n",
    "a_1D_continuous_decoded_result.time_bin_container.center_info.step\n",
    "a_1D_continuous_decoded_result.time_bin_container.edge_info.step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c4a72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, CustomCyclicColorsDockDisplayConfig, NamedColorScheme\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import new_plot_raster_plot #, NewSimpleRaster, paired_separately_sort_neurons\n",
    "\n",
    "_raster_tracks_out_dict = {}\n",
    "## Enables creating a new pyqtgraph-based track to display the intervals/epochs\n",
    "dock_config = CustomCyclicColorsDockDisplayConfig(named_color_scheme=NamedColorScheme.grey, showCloseButton=True, showCollapseButton=False, showGroupButton=False, corner_radius=\"0px\", hideTitleBar=True)\n",
    "name = f'rasters[{name_modifier_suffix}]'\n",
    "time_sync_pyqtgraph_widget, raster_root_graphics_layout_widget, raster_plot_item, raster_dock = self.add_new_embedded_pyqtgraph_render_plot_widget(name=name, dockSize=(500, 120), display_config=dock_config)\n",
    "\n",
    "if raster_plot_item not in self.params.custom_interval_rendering_plots:\n",
    "    self.params.custom_interval_rendering_plots.append(raster_plot_item) ## this signals that it should recieve updates for its intervals somewhere else\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15a97f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# all_time_bin_sizes_output_dict = {'non_marginalized_raw_result': [], 'marginal_over_direction': [], 'marginal_over_track_ID': []}\n",
    "# flat_all_time_bin_sizes_output_tuples_list: List[Tuple] = []\n",
    "\n",
    "for time_bin_size, a_continuously_decoded_dict in continuously_decoded_result_cache_dict.items():\n",
    "    ## Each iteration here adds 4 more tracks -- one for each decoding context\n",
    "    \n",
    "    # a_continuously_decoded_dict: Dict[str, DecodedFilterEpochsResult]\n",
    "    if debug_print:\n",
    "        print(f'time_bin_size: {time_bin_size}')\n",
    "\n",
    "    info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "    \n",
    "    ## Uses the `global_computation_results.computed_data['DirectionalDecodersDecoded']`\n",
    "    # all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "    # continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "\n",
    "    continuously_decoded_dict = a_continuously_decoded_dict\n",
    "    \n",
    "\n",
    "    # continuously_decoded_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(directional_decoders_decode_result.most_recent_continuously_decoded_dict)\n",
    "    assert continuously_decoded_dict is not None\n",
    "\n",
    "    ## Get the separate 1D results, these are ready-to-go:\n",
    "    all_directional_pf1D_Decoder_continuous_results_dict: Dict[types.DecoderName, SingleEpochDecodedResult] = {k:v.get_result_for_epoch(0) for k, v in get_dict_subset(continuously_decoded_dict, subset_includelist=None, subset_excludelist=['pseudo2D']).items()}\n",
    "    \n",
    "\n",
    "    ## Extract the Pseudo2D results as separate 1D tracks\n",
    "    ## INPUTS: most_recent_continuously_decoded_dict: Dict[str, DecodedFilterEpochsResult], info_string\n",
    "    \n",
    "    # all_directional_continuously_decoded_dict = most_recent_continuously_decoded_dict or {}\n",
    "    pseudo2D_decoder_continuously_decoded_result: DecodedFilterEpochsResult = continuously_decoded_dict.get('pseudo2D', None)\n",
    "    assert len(pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list) == 1\n",
    "    single_pseudo2D_decoder_continuously_decoded_result: SingleEpochDecodedResult = pseudo2D_decoder_continuously_decoded_result.get_result_for_epoch(0)\n",
    "    \n",
    "\n",
    "    p_x_given_n = single_pseudo2D_decoder_continuously_decoded_result.p_x_given_n ## continuous -- meaning single epoch\n",
    "    # p_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0]['p_x_given_n']\n",
    "    time_bin_container = single_pseudo2D_decoder_continuously_decoded_result.time_bin_container\n",
    "    time_window_centers = time_bin_container.centers\n",
    "    \n",
    "\n",
    "    # p_x_given_n.shape # (62, 4, 209389)\n",
    "\n",
    "    ## Split across the 2nd axis to make 1D posteriors that can be displayed in separate dock rows:\n",
    "    assert p_x_given_n.shape[1] == 4, f\"expected the 4 pseudo-y bins for the decoder in p_x_given_n.shape[1]. but found p_x_given_n.shape: {p_x_given_n.shape}\"\n",
    "    split_pseudo2D_posteriors_dict = {k:np.squeeze(p_x_given_n[:, i, :]) for i, k in enumerate(('long_LR', 'long_RL', 'short_LR', 'short_RL'))}\n",
    "\n",
    "    # Need all_directional_pf1D_Decoder_dict\n",
    "    output_dict = {}\n",
    "    output_pseudo2D_split_to_1D_continuous_results_dict: Dict[types.DecoderName, SingleEpochDecodedResult] = {}\n",
    "\n",
    "    # for a_decoder_name, a_1D_posterior in split_pseudo2D_posteriors_dict.items():\n",
    "    for i, a_decoder_name in enumerate(('long_LR', 'long_RL', 'short_LR', 'short_RL')):\n",
    "        ## make separate `SingleEpochDecodedResult` objects\n",
    "        \n",
    "        # all_directional_pf1D_Decoder_continuous_results_dict\n",
    "        output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name] = deepcopy(single_pseudo2D_decoder_continuously_decoded_result) ## copy the whole pseudo2D result\n",
    "        # output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].p_x_given_n = a_1D_posterior ## or could squish them here\n",
    "        output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].p_x_given_n = np.squeeze(output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].p_x_given_n[:, i, :]) ## or could squish them here\n",
    "        \n",
    "        # _out_tuple = dict(a_decoder_name=a_decoder_name, a_position_decoder=pseudo2D_decoder, time_window_centers=time_window_centers, a_1D_posterior=a_1D_posterior)\n",
    "        # identifier_name, widget, matplotlib_fig, matplotlib_fig_axes = _out_tuple\n",
    "        # output_dict[a_decoder_name] = _out_tuple\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## OUTPUTS: all_directional_pf1D_Decoder_dict: Dict[types.DecoderName, BasePositionDecoder], all_directional_pf1D_Decoder_continuous_results_dict: Dict[types.DecoderName, SingleEpochDecodedResult]\n",
    "## OUTPUTS: pseudo2D_decoder: BasePositionDecoder, single_pseudo2D_decoder_continuously_decoded_result: SingleEpochDecodedResult, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea54c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].p_x_given_n.shape\n",
    "# output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].most_likely_positions\n",
    "\n",
    "# output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name]._test_find_fields_by_shape_metadata()\n",
    "\n",
    "## Marginals are wrong afterwards, and most-likely positions have too many dimensions\n",
    "\n",
    "\n",
    "# pseudo2D_decoder_continuously_decoded_result.perform_compute_marginals\n",
    "output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].most_likely_positions\n",
    "output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].marginal_x\n",
    "\n",
    "output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].marginal_x['p_x_given_n'].shape ## these are okay, (n_x_bins, n_t_bins)\n",
    "output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].marginal_y['p_x_given_n'].shape ## these are bad, (n_decoder_names, n_t_bins)\n",
    "\n",
    "\n",
    "output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].most_likely_positions["
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522aab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo2D_decoder_continuously_decoded_result.pos_bin_edges\n",
    "pseudo2D_decoder_continuously_decoded_result.n_pos_bins\n",
    "continuously_decoded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566c4c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_bin_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1687f8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_pseudo2D_decoder_continuously_decoded_result.to_hdf(\n",
    "import h5py\n",
    "\n",
    "hdf5_output_path: Path = curr_active_pipeline.get_output_path().joinpath('test_data.h5')\n",
    "with h5py.File(hdf5_output_path, 'w') as f: ## open the path as a HDF5 file handle:\n",
    "    single_pseudo2D_decoder_continuously_decoded_result.to_hdf(f, key='single_pseudo2D_decoder_continuously_decoded_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5b63de",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_pseudo2D_decoder_continuously_decoded_result\n",
    "single_pseudo2D_decoder_continuously_decoded_result.marginal_y['p_x_given_n'].shape\n",
    "single_pseudo2D_decoder_continuously_decoded_result.marginal_x['p_x_given_n'].shape\n",
    "\n",
    "\n",
    "\n",
    "# single_pseudo2D_decoder_continuously_decoded_result.epoch_info_tuple\n",
    "single_pseudo2D_decoder_continuously_decoded_result.p_x_given_n.shape # (59, 4, 69487)\n",
    "# single_pseudo2D_decoder_continuously_decoded_result.get_posterior_as_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0a366c",
   "metadata": {},
   "source": [
    "# <a id='toc33_'></a>[Mice, Mark 1](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9251c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the time bins with insufficient spikes in them.\n",
    "\n",
    "## Darken them by overlaying something\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ff7444",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import compute_unit_time_binned_spike_counts_and_mask, _plot_low_firing_time_bins_overlay_image\n",
    "\n",
    "\n",
    "# results1D.decoders['global'] #.unit_specific_time_binned_spike_counts  #.shape\n",
    "# results2D.a_result2D.spkcount\n",
    "\n",
    "# time_bin_edges: NDArray = deepcopy(results1D.continuous_results['global'].time_bin_edges[0])\n",
    "# spikes_df: pd.DataFrame = deepcopy(get_proper_global_spikes_df(curr_active_pipeline))\n",
    "# unit_specific_time_binned_spike_counts, (is_time_bin_active, inactive_mask, mask_rgba) = compute_unit_time_binned_spike_counts_and_mask(spikes_df=spikes_df, time_bin_edges=time_bin_edges)\n",
    "\n",
    "\n",
    "for a_decoder_name, a_1D_continuous_decoded_result in a_split_pseudo2D_continuous_result_to_1D_continuous_result_dict.items():\n",
    "    ## a_1D_continuous_decoded_result: SingleEpochDecodedResult\n",
    "    a_1D_decoder: BasePositionDecoder = all_directional_pf1D_Decoder_dict[a_decoder_name]\n",
    "    _out_tuple = output_dict[a_decoder_name]\n",
    "    identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = _out_tuple\n",
    "    ## add num spikes per time bin masking:    \n",
    "    time_bin_edges: NDArray = deepcopy(a_1D_continuous_decoded_result.time_bin_edges)\n",
    "    spikes_df: pd.DataFrame = deepcopy(get_proper_global_spikes_df(curr_active_pipeline))\n",
    "    unit_specific_time_binned_spike_counts, (is_time_bin_active, inactive_mask, mask_rgba) = compute_unit_time_binned_spike_counts_and_mask(spikes_df=spikes_df, time_bin_edges=time_bin_edges)\n",
    "\n",
    "    ## add data to plots_data:\n",
    "    widget.plots_data.time_bin_edges = time_bin_edges\n",
    "    widget.plots_data.spikes_df = spikes_df\n",
    "    widget.plots_data.unit_specific_time_binned_spike_counts = unit_specific_time_binned_spike_counts\n",
    "    widget.plots_data.is_time_bin_active = is_time_bin_active\n",
    "    widget.plots_data.mask_rgba = mask_rgba\n",
    "    \n",
    "    ## Add overlay plot to hide bins that don't meet the firing criteria:\n",
    "    _plot_low_firing_time_bins_overlay_image(widget=widget, time_bin_edges=time_bin_edges, mask_rgba=mask_rgba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd2108b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _plot_low_firing_time_bins_overlay_image, add_unit_spike_count_visualization\n",
    "\n",
    "# time_window_centers = deepcopy(results1D.continuous_results['global'].time_bin_containers[0].centers)\n",
    "## INPUTS: unique_units, time_bin_edges, unit_specific_time_binned_spike_counts\n",
    "time_bin_edges: NDArray = deepcopy(results1D.continuous_results['global'].time_bin_edges[0])\n",
    "spikes_df: pd.DataFrame = deepcopy(get_proper_global_spikes_df(curr_active_pipeline))\n",
    "# unique_units = np.unique(spikes_df['aclu']) # sorted\n",
    "unit_specific_time_binned_spike_counts, unique_units, (is_time_bin_active, inactive_mask, mask_rgba) = spikes_df.spikes.compute_unit_time_binned_spike_counts_and_mask(time_bin_edges=time_bin_edges)\n",
    "widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = add_unit_spike_count_visualization(active_2d_plot, neuron_ids=unique_units, time_bin_edges=time_bin_edges, unit_specific_time_binned_spike_counts=unit_specific_time_binned_spike_counts, a_dock_config=None, extended_dock_title_info=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da04fee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import Epoch\n",
    "\n",
    "_starts = deepcopy(results1D.continuous_results['global'].time_bin_containers[0].left_edges)\n",
    "_stops = deepcopy(results1D.continuous_results['global'].time_bin_containers[0].right_edges)\n",
    "all_decoding_time_bin_epochs: Epoch = Epoch.from_starts_stops_arrays(starts=_starts, stops=_stops)\n",
    "active_time_bin_epochs: Epoch = all_decoding_time_bin_epochs.boolean_indicies_slice(is_time_bin_active)\n",
    "inactive_time_bin_epochs: Epoch = all_decoding_time_bin_epochs.boolean_indicies_slice(inactive_mask)\n",
    "\n",
    "## OUTPUTS: active_time_bin_epochs, inactive_time_bin_epochs\n",
    "\n",
    "active_time_bin_epochs_df: pd.DataFrame = active_time_bin_epochs.epochs.get_valid_df().epochs.get_non_overlapping_df().epochs.get_valid_df()\n",
    "active_time_bin_epochs_df['label'] = active_time_bin_epochs_df['label'].astype(int) \n",
    "active_time_bin_epochs_df\n",
    "\n",
    "## OUTPUTS: active_time_bin_epochs_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b1a2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from neuropy.core.epoch import find_data_indicies_from_epoch_times, ensure_Epoch, ensure_dataframe\n",
    "from neuropy.utils.mixins.time_slicing import add_epochs_id_identity\n",
    "from pyphoplacecellanalysis.General.Mixins.SpikesRenderingBaseMixin import SpikeEmphasisState\n",
    "\n",
    "spikes_df: pd.DataFrame = spike_raster_window.spike_raster_plt_2d.spikes_df\n",
    "\n",
    "# spikes_df.spikes.time_sliced(active_time_bin_epochs)\n",
    "\n",
    "# Convert the Epoch object to a numpy array of start/stop times\n",
    "# epoch_times = active_time_bin_epochs.to_dataframe()[['start', 'stop']].to_numpy()\n",
    "\n",
    "# # Find indices\n",
    "# spike_indices = find_data_indicies_from_epoch_times(spikes_df, epoch_times=epoch_times, atol=1e-3)\n",
    "# spike_indices\n",
    "\n",
    "# Add epoch IDs to spikes_df\n",
    "spikes_df = add_epochs_id_identity(spikes_df, active_time_bin_epochs_df, epoch_id_key_name='active_time_bin_epoch_id', epoch_label_column_name='label')\n",
    "# spikes_df\n",
    "\n",
    "# Then filter for spikes within any epoch (not NaN)\n",
    "active_time_bin_spike_indices = spikes_df[~np.isnan(spikes_df['active_time_bin_epoch_id'])].index.values\n",
    "active_time_bin_spike_indices\n",
    "\n",
    "is_spike_included_in_active_time_bin_epoch = ~np.isnan(spikes_df['active_time_bin_epoch_id'])\n",
    "is_spike_excluded_from_active_time_bin_epoch = np.isnan(spikes_df['active_time_bin_epoch_id'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c669c8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.spike_raster_plt_2d.update_spike_emphasis(is_spike_excluded_from_active_time_bin_epoch, SpikeEmphasisState.Deemphasized)\n",
    "# spike_raster_window.spike_raster_plt_2d.update_spike_emphasis(is_spike_excluded_from_active_time_bin_epoch, SpikeEmphasisState.Hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97af5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import find_data_indicies_from_epoch_times, ensure_Epoch, ensure_dataframe\n",
    "from neuropy.utils.mixins.time_slicing import add_epochs_id_identity\n",
    "\n",
    "\n",
    "spikes_df: pd.DataFrame = spike_raster_window.spike_raster_plt_2d.spikes_df\n",
    "\n",
    "# spikes_df.spikes.time_sliced(active_time_bin_epochs)\n",
    "\n",
    "# Convert the Epoch object to a numpy array of start/stop times\n",
    "# epoch_times = active_time_bin_epochs.to_dataframe()[['start', 'stop']].to_numpy()\n",
    "\n",
    "# # Find indices\n",
    "# spike_indices = find_data_indicies_from_epoch_times(spikes_df, epoch_times=epoch_times, atol=1e-3)\n",
    "# spike_indices\n",
    "\n",
    "# Add epoch IDs to spikes_df\n",
    "spikes_df = add_epochs_id_identity(spikes_df, active_time_bin_epochs_df, epoch_id_key_name='active_time_bin_epoch_id', epoch_label_column_name='label')\n",
    "# spikes_df\n",
    "\n",
    "# Then filter for spikes within any epoch (not NaN)\n",
    "active_time_bin_spike_indices = spikes_df[~np.isnan(spikes_df['active_time_bin_epoch_id'])].index.values\n",
    "active_time_bin_spike_indices\n",
    "\n",
    "is_spike_included_in_active_time_bin_epoch = ~np.isnan(spikes_df['active_time_bin_epoch_id'])\n",
    "is_spike_excluded_from_active_time_bin_epoch = np.isnan(spikes_df['active_time_bin_epoch_id'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4307f0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example 1: De-emphasize spikes excluded from the placefield calculations:\n",
    "is_spike_included_in_pf = np.isin(spike_raster_window.spike_raster_plt_2d.spikes_df.index, active_pf_2D.filtered_spikes_df.index)\n",
    "spike_raster_window.spike_raster_plt_2d.update_spike_emphasis(np.logical_not(is_spike_included_in_pf), SpikeEmphasisState.Deemphasized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c011fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_ax = matplotlib_fig_axes[0]\n",
    "an_ax.get_ylim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f86be67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _plot_low_firing_time_bins_overlay_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2eb3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get other tracks, add the mask to the axes\n",
    "widget, matplotlib_fig, matplotlib_fig_axes = active_2d_plot.find_matplotlib_render_plot_widget(\"ContinuousDecode_long_LR - t_bin_size: 0.025\")\n",
    "_plot_low_firing_time_bins_overlay_image(widget=widget, time_bin_edges=time_bin_edges, mask_rgba=mask_rgba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaa78e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "widget, matplotlib_fig, matplotlib_fig_axes = active_2d_plot.find_matplotlib_render_plot_widget(\"ContinuousDecode_long_RL - t_bin_size: 0.025\")\n",
    "_plot_low_firing_time_bins_overlay_image(widget=widget, time_bin_edges=time_bin_edges, mask_rgba=mask_rgba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc1c5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "widget, matplotlib_fig, matplotlib_fig_axes = active_2d_plot.find_matplotlib_render_plot_widget(\"ContinuousDecode_short_LR - t_bin_size: 0.025\")\n",
    "_plot_low_firing_time_bins_overlay_image(widget=widget, time_bin_edges=time_bin_edges, mask_rgba=mask_rgba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8bdaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "widget, matplotlib_fig, matplotlib_fig_axes = active_2d_plot.find_matplotlib_render_plot_widget(\"ContinuousDecode_short_RL - t_bin_size: 0.025\")\n",
    "_plot_low_firing_time_bins_overlay_image(widget=widget, time_bin_edges=time_bin_edges, mask_rgba=mask_rgba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d3d140",
   "metadata": {},
   "outputs": [],
   "source": [
    "widget, matplotlib_fig, matplotlib_fig_axes = active_2d_plot.find_matplotlib_render_plot_widget(\"ContinuousDecode_short_RL - t_bin_size: 0.025\")\n",
    "_plot_low_firing_time_bins_overlay_image(widget=widget, time_bin_edges=time_bin_edges, mask_rgba=mask_rgba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e4af49",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.get_leaf_only_flat_dock_identifiers_list()\n",
    "\n",
    "['ContinuousDecode_long_LR - t_bin_size: 0.025', 'ContinuousDecode_long_RL - t_bin_size: 0.025', 'ContinuousDecode_short_LR - t_bin_size: 0.025', 'ContinuousDecode_short_RL - t_bin_size: 0.025']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd481163",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_item_identifiers_list = ['ContinuousDecode_long_LR - t_bin_size: 0.025', 'ContinuousDecode_long_RL - t_bin_size: 0.025', 'ContinuousDecode_short_LR - t_bin_size: 0.025', 'ContinuousDecode_short_RL - t_bin_size: 0.025', 'ContinuousDecode_longnon-PBE-pseudo2D marginals', 'ContinuousDecode_shortnon-PBE-pseudo2D marginals', 'non-PBE_marginal_over_track_ID_ContinuousDecode - t_bin_size: 0.05', 'Masked Non-PBE Pseudo2D']\n",
    "for an_identifier in target_item_identifiers_list:\n",
    "    widget, matplotlib_fig, matplotlib_fig_axes = active_2d_plot.find_matplotlib_render_plot_widget(an_identifier)\n",
    "    if widget is not None:\n",
    "        _plot_low_firing_time_bins_overlay_image(widget=widget, time_bin_edges=time_bin_edges, mask_rgba=mask_rgba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66ce480",
   "metadata": {},
   "source": [
    "# <a id='toc34_'></a>[General Decoding Record with Frozen Decoding Parameters Tuples](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0889b292",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dict of decoding results, where the decoders used for decoding are built from: nonPBE_Long, nonPBE_Short, Laps_LongLR, Laps_LongRL, Laps_ShortLR, Laps_ShortRL\n",
    "## qclu, frHz\n",
    "# All Decoders should be continuous (decoding the entire session as a single epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e6797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import EpochsAccessor, Epoch, ensure_dataframe, ensure_Epoch\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import EpochComputationFunctions, EpochComputationsComputationsContainer, DecodingResultND, Compute_NonPBE_Epochs, KnownFilterEpochs\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import GeneralDecoderDictDecodedEpochsDictResult, GenericResultTupleIndexType, KnownNamedDecodingEpochsType, MaskedTimeBinFillType\n",
    "\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "\n",
    "## Unpack from pipeline:\n",
    "nonPBE_results: EpochComputationsComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['EpochComputations']\n",
    "a_new_NonPBE_Epochs_obj: Compute_NonPBE_Epochs = nonPBE_results.a_new_NonPBE_Epochs_obj\n",
    "results1D: DecodingResultND = nonPBE_results.results1D\n",
    "results2D: DecodingResultND = nonPBE_results.results2D\n",
    "\n",
    "epochs_decoding_time_bin_size = nonPBE_results.epochs_decoding_time_bin_size\n",
    "frame_divide_bin_size = nonPBE_results.frame_divide_bin_size\n",
    "\n",
    "print(f'{epochs_decoding_time_bin_size = }, {frame_divide_bin_size = }')\n",
    "\n",
    "assert (results1D is not None)\n",
    "assert (results2D is not None)\n",
    "\n",
    "## New computed properties:\n",
    "a_general_decoder_dict_decoded_epochs_dict_result: GeneralDecoderDictDecodedEpochsDictResult = nonPBE_results.a_general_decoder_dict_decoded_epochs_dict_result ## get the pre-decoded result\n",
    "a_general_decoder_dict_decoded_epochs_dict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098dbf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# 2025-02-20 20:06 New `nonPBE_results._build_merged_joint_placefields_and_decode` method                              #\n",
    "# ==================================================================================================================== #\n",
    "non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict, non_PBE_marginal_over_track_ID, (time_bin_containers, time_window_centers, track_marginal_posterior_df) = nonPBE_results._build_merged_joint_placefields_and_decode(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)))\n",
    "masked_pseudo2D_continuous_specific_decoded_result, _mask_index_tuple = pseudo2D_continuous_specific_decoded_result.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)))\n",
    "## OUTPUTS: pseudo2D_continuous_specific_decoded_result, non_PBE_marginal_over_track_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1ffbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'DirectionalMergedDecoders' in curr_active_pipeline.global_computation_results.computed_data:\n",
    "    # DirectionalMergedDecoders: Get the result after computation:\n",
    "    directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "    a_new_fully_generic_result = a_new_fully_generic_result.adding_directional_pseudo2D_decoder_results_filtered_by_spikes_per_t_bin_masked(directional_merged_decoders_result=directional_merged_decoders_result)\n",
    "else:\n",
    "    print('WARN: missing \"DirectionalMergedDecoders\" global result. Skipping.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f11aef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.get_complete_session_context()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37a4b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict, non_PBE_marginal_over_track_ID, (time_bin_containers, time_window_centers, track_marginal_posterior_df), masked_pseudo2D_continuous_specific_decoded_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf7487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_attributes(short_name=None, tags=['WORKING'], input_requires=[], output_provides=[], uses=[], used_by=[], creation_date='2025-03-04 11:36', related_items=[])\n",
    "def add_decoded_posterior_row(active_2d_plot, identifier_name: str, a_decoder: BasePositionDecoder, a_decoded_result: DecodedFilterEpochsResult, extended_dock_title_info: Optional[str]=None):\n",
    "    \"\"\" adds a new decoder track to the active_2d_plot \n",
    "    \"\"\"\n",
    "    from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import SynchronizedPlotMode\n",
    "    from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_1D_most_likely_position_comparsions\n",
    "    from neuropy.utils.matplotlib_helpers import get_heatmap_cmap\n",
    "    from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import FixedCustomColormaps\n",
    "    from pyphocorehelpers.gui.Qt.color_helpers import ColormapHelpers\n",
    "\n",
    "    ## ‚úÖ Add a new row for each of the four 1D directional decoders:\n",
    "    # identifier_name: str = f'ContinuousDecode_{a_decoder_name}'\n",
    "    if extended_dock_title_info is not None:\n",
    "        identifier_name += extended_dock_title_info ## add extra info like the time_bin_size in ms\n",
    "    # print(f'identifier_name: {identifier_name}')\n",
    "\n",
    "    # print(f'identifier_name: {identifier_name}')\n",
    "    widget, matplotlib_fig, matplotlib_fig_axes, dock_item = active_2d_plot.add_new_matplotlib_render_plot_widget(name=identifier_name, dockSize=(65, 200), display_config=None, sync_mode=SynchronizedPlotMode.TO_WINDOW)\n",
    "    an_ax = matplotlib_fig_axes[0]\n",
    "\n",
    "    active_decoder = deepcopy(a_decoder)\n",
    "    assert a_decoded_result is not None, f\"a_decoded_result should not be None anymore.\"\n",
    "\n",
    "    if a_decoded_result is not None:\n",
    "        active_result = deepcopy(a_decoded_result) # already decoded\n",
    "        assert (active_result.num_filter_epochs == 1), f\"currently only supports decoded results (DecodedFilterEpochsResult) computed with a single epoch for all time bins, but active_result.num_filter_epochs: {active_result.num_filter_epochs}\"\n",
    "        active_marginals = active_result.marginal_x_list[0]\n",
    "    else:\n",
    "        # no previously decoded result, fallback to the decoder's internal properties        \n",
    "        active_marginals = active_decoder.marginal.x\n",
    "        \n",
    "\n",
    "    variable_name='x'\n",
    "    active_bins = deepcopy(active_decoder.xbin)\n",
    "    time_window_centers = deepcopy(active_result.time_bin_containers[0].centers)\n",
    "    # active_most_likely_positions = active_marginals.most_likely_positions_1D # Raw decoded positions\n",
    "    active_most_likely_positions = None\n",
    "    active_posterior = active_marginals.p_x_given_n\n",
    "\n",
    "    # active_posterior = deepcopy(a_1D_posterior)\n",
    "    \n",
    "    # most_likely_positions_mode: 'standard'|'corrected'\n",
    "    # fig, curr_ax = curr_active_pipeline.display('_display_plot_marginal_1D_most_likely_position_comparisons', _active_config_name, variable_name='x', most_likely_positions_mode='corrected', ax=an_ax) # ax=active_2d_plot.ui.matplotlib_view_widget.ax\n",
    "    posterior_heatmap_imshow_kwargs = dict(\n",
    "        cmap = get_heatmap_cmap(cmap='viridis', bad_color='black', under_color='white', over_color='red'),\n",
    "    )\n",
    "\n",
    "    measured_position_df = None # Note: for some reason setting `measured_position_df` to anything other than None here messes up the plotting entirely. Set it to None now, and if we want measured positions plot them after\n",
    "    ## Actual plotting portion:\n",
    "    fig, an_ax = plot_1D_most_likely_position_comparsions(measured_position_df=None, time_window_centers=time_window_centers, xbin=active_bins,\n",
    "                                                            posterior=active_posterior,\n",
    "                                                            active_most_likely_positions_1D=active_most_likely_positions,\n",
    "                                                            ax=an_ax, variable_name=variable_name, debug_print=True, enable_flat_line_drawing=False,\n",
    "                                                            posterior_heatmap_imshow_kwargs=posterior_heatmap_imshow_kwargs)\n",
    "\n",
    "\n",
    "\n",
    "    widget.plots_data.active_decoder = active_decoder\n",
    "    widget.plots_data.a_decoded_result = a_decoded_result\n",
    "\n",
    "    # active_bins = active_decoder.xbin\n",
    "\n",
    "    # # active_most_likely_positions = active_marginals.most_likely_positions_1D # Raw decoded positions\n",
    "    # active_most_likely_positions = None\n",
    "    # active_posterior = active_marginals.p_x_given_n\n",
    "    return widget, matplotlib_fig, an_ax, dock_item\n",
    "\n",
    "\n",
    "add_decoded_posterior_row(active_2d_plot, identifier_name=f'Masked Non-PBE Pseudo2D', a_decoder=deepcopy(non_PBE_all_directional_pf1D_Decoder), a_decoded_result=masked_pseudo2D_continuous_specific_decoded_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91d6d4b",
   "metadata": {},
   "source": [
    "### <a id='toc34_1_1_'></a>[üößüîú 2025-02-26 -  Plot 1D pseudo2D Continuous Decodings and their marginals over TrackID on SpikeRaster2D track - uses `AddNewDecodedPosteriors_MatplotlibPlotCommand.prepare_and_perform_custom_decoder_decoded_epochs(...)`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4299cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import AddNewDecodedPosteriors_MatplotlibPlotCommand, AddNewDecodedEpochMarginal_MatplotlibPlotCommand\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, CustomCyclicColorsDockDisplayConfig, NamedColorScheme\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalDecodersContinuouslyDecodedResult\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import PlottingHelpers\n",
    "\n",
    "## Main INPUT: continuous_specific_decoded_results_dict\n",
    "display_output = {}\n",
    "\n",
    "\n",
    "AddNewDecodedPosteriors_MatplotlibPlotCommand._build_dock_group_id(extended_dock_title_info='non-PBE-pseudo2D marginals')\n",
    "## INPUTS: pseudo2D_continuous_specific_decoded_result, non_PBE_marginal_over_track_ID\n",
    "\n",
    "# override_dock_group_name: str = 'non_pbe_continuous_decoding_plot_group'\n",
    "override_dock_group_name: str = None ## this feature doesn't work\n",
    "_cont_posteriors_output_dict = AddNewDecodedPosteriors_MatplotlibPlotCommand.prepare_and_perform_custom_decoder_decoded_epochs(curr_active_pipeline=curr_active_pipeline, active_2d_plot=active_2d_plot,\n",
    "                                                                                                                continuously_decoded_dict=continuous_decoded_results_dict, info_string='non-PBE-pseudo2D marginals', # results1D.continuous_results\n",
    "                                                                                                                xbin=deepcopy(results1D.decoders['global'].xbin), skip_plotting_measured_positions=False, debug_print=False,\n",
    "                                                                                                                dock_group_name=override_dock_group_name)\n",
    "\n",
    "\n",
    "display_output.update(_cont_posteriors_output_dict)\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Plot the Decodings and their Marginals over TrackID as new Tracks                                                    #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "## INPUTS: non_PBE_marginal_over_track_ID\n",
    "\n",
    "## Manually call `AddNewDecodedEpochMarginal_MatplotlibPlotCommand` to add the custom marginals track to the active SpikeRaster3DWindow\n",
    "time_bin_size = epochs_decoding_time_bin_size\n",
    "info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "\n",
    "dock_config = CustomCyclicColorsDockDisplayConfig(showCloseButton=True, named_color_scheme=NamedColorScheme.grey)\n",
    "dock_config.dock_group_names = [override_dock_group_name] # , 'non-PBE Continuous Decoding'\n",
    "\n",
    "_marginalized_post_output_dict = {}\n",
    "a_posterior_name: str = 'non-PBE_marginal_over_track_ID'\n",
    "assert non_PBE_marginal_over_track_ID.shape[0] == 2, f\"expected the 2 marginalized pseudo-y bins for the decoder in non_PBE_marginal_over_track_ID.shape[1]. but found non_PBE_marginal_over_track_ID.shape: {non_PBE_marginal_over_track_ID.shape}\"\n",
    "_marginalized_post_output_dict[a_posterior_name] = AddNewDecodedEpochMarginal_MatplotlibPlotCommand._perform_add_new_decoded_posterior_marginal_row(curr_active_pipeline=curr_active_pipeline, active_2d_plot=active_2d_plot, a_dock_config=dock_config,\n",
    "                                                                                    a_variable_name=a_posterior_name, xbin=np.arange(2), time_window_centers=time_window_centers, a_1D_posterior=non_PBE_marginal_over_track_ID, extended_dock_title_info=info_string)\n",
    "display_output.update({'a_posterior_name': _marginalized_post_output_dict[a_posterior_name]})\n",
    "\n",
    "## Draw the \"Long\", \"Short\" labels\n",
    "identifier_name, widget, matplotlib_fig, matplotlib_fig_axes = _marginalized_post_output_dict[a_posterior_name]\n",
    "label_artists_dict = {}\n",
    "for i, ax in enumerate(matplotlib_fig_axes):\n",
    "    label_artists_dict[ax] = PlottingHelpers.helper_matplotlib_add_pseudo2D_marginal_labels(ax, y_bin_labels=['short','long'], enable_draw_decoder_colored_lines=False)\n",
    "_marginalized_post_output_dict[a_posterior_name] = (identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, label_artists_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b067fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_pseudo2D_continuous_specific_decoded_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149fcf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dock all Grouped results from `'DockedWidgets.Pseudo2DDecodedEpochsDockedMatplotlibView'`\n",
    "## INPUTS: active_2d_plot\n",
    "nested_dock_items, nested_dynamic_docked_widget_container_widgets = active_2d_plot.ui.dynamic_docked_widget_container.layout_dockGroups()\n",
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4dd842",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Manually draw the red \"current position\" lines:\n",
    "## extracted from `plot_1D_most_likely_position_comparsions`\n",
    "\n",
    "measured_position_df: pd.DataFrame = deepcopy(results1D.pos_df)\n",
    "\n",
    "identifier_names = ['ContinuousDecode_longnon-PBE-pseudo2D marginals', 'ContinuousDecode_shortnon-PBE-pseudo2D marginals']\n",
    "out_artists = {}\n",
    "out_artists['measured_pos_artists'] = {}\n",
    "for an_identifier in identifier_names:\n",
    "    widget, matplotlib_fig, matplotlib_fig_axes = active_2d_plot.find_matplotlib_render_plot_widget(an_identifier)\n",
    "    an_ax = matplotlib_fig_axes[0]\n",
    "    ## INPUTS: measured_position_df, an_ax\n",
    "    # Actual Position Plots (red line):\n",
    "    # actual_postion_plot_kwargs = {'color': '#ff000066', 'alpha': 0.6, 'marker': '+', 'markersize': 4, 'animated': False}\n",
    "    # actual_postion_plot_kwargs = {'color': '#ff000066', 'alpha': 0.6, 'marker': 'none', 'animated': False}\n",
    "    actual_postion_plot_kwargs = {'color': '#ff000066', 'alpha': 0.35, 'marker': 'none', 'animated': False}\n",
    "    variable_name = 'x'\n",
    "    a_line_measured_position = an_ax.plot(measured_position_df['t'].to_numpy(), measured_position_df[variable_name].to_numpy(), label=f'measured {variable_name}', **actual_postion_plot_kwargs) # Opaque RED # , linestyle='dashed', linewidth=2, color='#ff0000ff'\n",
    "    out_artists['measured_pos_artists'] = a_line_measured_position\n",
    "\n",
    "    ## draw when done:\n",
    "    an_ax.get_figure().canvas.draw_idle()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c6d576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.Menus.BaseMenuProviderMixin import BaseMenuCommand\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import AddNewDecodedPosteriors_MatplotlibPlotCommand\n",
    "\n",
    "\n",
    "@define(slots=False)\n",
    "class TimelineTrack:\n",
    "    dock: Dock = field()\n",
    "    widget: TimelinePlotterBase = field()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6376f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = curr_active_pipeline.sess.epochs.to_dataframe() #.to_clipboard()\n",
    "print(df.to_dict('list'))\n",
    "# \tstart\tstop\tlabel\tduration\n",
    "# 0\t0.0\t1029.316608761903\tmaze1\t1029.316608761903\n",
    "# 1\t1029.316608761903\t1737.1968310000375\tmaze2\t707.8802222381346\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e3d821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nptyping as ND\n",
    "from nptyping import NDArray\n",
    "from neuropy.core.epoch import EpochsAccessor, Epoch\n",
    "from neuropy.core.flattened_spiketrains import SpikesAccessor\n",
    "\n",
    "test_epochs_df: pd.DataFrame = pd.DataFrame({'start': [0.0, 1029.316608761903], 'stop': [1029.316608761903, 1737.1968310000375], 'label': ['maze1', 'maze2'], 'duration': [1029.316608761903, 707.8802222381346]})\n",
    "epochs: Epoch = Epoch(test_epochs_df) # Epoch(...) # Create an Epoch object as needed\n",
    "\n",
    "test_epochs_df.epochs.is_gapless_overlap_df()\n",
    "\n",
    "# test_epochs_df.epochs.get_non_overlapping_df(debug_print=True)\n",
    "\n",
    "time_bin_edges: NDArray = deepcopy(results1D.continuous_results['global'].time_bin_edges[0])\n",
    "spikes_df: pd.DataFrame = deepcopy(get_proper_global_spikes_df(curr_active_pipeline))\n",
    "# unit_specific_time_binned_spike_counts, included_neuron_ids = spikes_df.spikes.compute_unit_time_binned_spike_counts(time_bin_edges=time_bin_edges)\n",
    "\n",
    "unit_specific_time_binned_spike_counts: NDArray[ND.Shape[\"N_ACLUS, N_TIME_BINS\"], ND.Int] = spikes_df.spikes.compute_unit_time_binned_spike_counts(time_bin_edges=time_bin_edges)[0]\n",
    "included_neuron_ids: NDArray[ND.Shape[\"N_ACLUS\"], ND.Int] = spikes_df.spikes.compute_unit_time_binned_spike_counts(time_bin_edges=time_bin_edges)[1]\n",
    "unit_specific_time_binned_spike_counts\n",
    "\n",
    "# isinstance(unit_specific_time_binned_spike_counts, NDArray[ND.Shape[\"n_aclus, n_time_bins\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f89c52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(spikes_df.spikes.get_split_by_unit()[0])\n",
    "spikes_df.slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b01cb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nptyping as ND\n",
    "from nptyping import NDArray\n",
    "\n",
    "## Note: in the following test code I prefer to use `import nptyping as ND` instead of `from nptyping import Shape` because I have other `Shape` classes.\n",
    "isinstance(np.random.randn(2, 2), NDArray[ND.Shape[\"Size, Size\"], Any])\n",
    "isinstance(np.random.randn(100, 100), NDArray[ND.Shape[\"Size, Size\"], Any])\n",
    "isinstance(np.random.randn(42, 52), NDArray[ND.Shape[\"N_ACLUS, N_TIME_BINS\"], Any])\n",
    "# isinstance(np.random.randn(42, 43), NDArray[ND.Shape[\"N_ACLUS, N_TIME_BINS\"]])\n",
    "\n",
    "arr: NDArray[ND.Shape[\"Size, Size\"], Any] = np.random.randn(2, 2)\n",
    "arr: NDArray[ND.Shape[\"Size1, Size2\"], Any] = np.random.randn(2, 2)\n",
    "arr: NDArray[ND.Shape[\"Size1, Size2\"], Any] = np.random.randn(2, 2) # Case-sensitivity: valid\n",
    "# arr: NDArray[ND.Shape[\"Size1, size2\"], Any] =  np.random.randn(2, 2) # Case-sensitivity: InvalidShapeError: 'Size1, size2' is not a valid shape expression.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23add0e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "acd7bf14",
   "metadata": {},
   "source": [
    "# <a id='toc35_'></a>[2025-03-10 Evaluate the differences between `epochs_spkcount` and `_OLD_epochs_spkcount`](#toc0_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc083c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import subdivide_epochs, ensure_dataframe, Epoch\n",
    "from neuropy.analyses.decoders import epochs_spkcount, _OLD_epochs_spkcount\n",
    "from neuropy.utils.mixins.binning_helpers import BinningInfo, BinningContainer\n",
    "\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "global_session = curr_active_pipeline.filtered_sessions[global_epoch_name]\n",
    "\n",
    "spikes_df = get_proper_global_spikes_df(curr_active_pipeline)\n",
    "# filter_epochs: pd.DataFrame = global_session.laps.to_dataframe()\n",
    "\n",
    "filter_epochs: pd.DataFrame = ensure_dataframe(global_session.replay) #.epochs.get_non_overlapping()\n",
    "filter_epochs\n",
    "\n",
    "# spikes_df.spikes.sliced_by_neuron_id\n",
    "use_single_time_bin_per_epoch: bool = False\n",
    "decoding_time_bin_size = 0.025\n",
    "\n",
    "debug_print: bool = False\n",
    "included_neuron_ids: NDArray[ND.Shape[\"N_ACLUS\"], ND.Int] = np.unique(spikes_df['aclu']) # sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780dbe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## Evaluate the differences between `epochs_spkcount` and `_OLD_epochs_spkcount`\n",
    "spkcount, included_neuron_ids, nbins, time_bin_containers_list = epochs_spkcount(spikes_df, epochs=filter_epochs, bin_size=decoding_time_bin_size, export_time_bins=True, included_neuron_ids=included_neuron_ids, use_single_time_bin_per_epoch=use_single_time_bin_per_epoch, debug_print=debug_print) ## Modern Method\n",
    "\n",
    "spkcount_OLD, included_neuron_ids_OLD, nbins_OLD, time_bin_containers_list_OLD = _OLD_epochs_spkcount(spikes_df, epochs=filter_epochs, bin_size=decoding_time_bin_size, slideby=decoding_time_bin_size, export_time_bins=True, included_neuron_ids=included_neuron_ids, use_single_time_bin_per_epoch=use_single_time_bin_per_epoch, debug_print=debug_print) ## Modern Method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fefeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses.decoders import compare_epochs_spkcount_implementations, print_detailed_epoch_differences\n",
    "\n",
    "# Run the comparison\n",
    "results, (new_spkcount, new_included_neuron_ids, new_nbins, new_time_bin_containers_list), (old_spkcount, old_included_neuron_ids, old_nbins, old_time_bin_containers_list) = compare_epochs_spkcount_implementations(\n",
    "    spikes_df=spikes_df,\n",
    "    epochs=filter_epochs,\n",
    "    bin_size=decoding_time_bin_size,\n",
    "    export_time_bins=True,\n",
    "    included_neuron_ids=included_neuron_ids,\n",
    "    use_single_time_bin_per_epoch=use_single_time_bin_per_epoch,\n",
    "    debug_print=False\n",
    ")\n",
    "\n",
    "# old_outputs\n",
    "\n",
    "# BIN COUNT DIFFERENCES:\n",
    "# Epoch 1: New: 103, Old: 102, Diff: 1\n",
    "# Epoch 2: New: 227, Old: 226, Diff: 1\n",
    "\n",
    "# SHAPE DIFFERENCES:\n",
    "# Epoch 1: New shape: (67, 103), Old shape: (67, 102)\n",
    "#   Total spike counts - New: 87, Old: 86, Diff: 1\n",
    "# Epoch 2: New shape: (67, 227), Old shape: (67, 226)\n",
    "#   Total spike counts - New: 555, Old: 554, Diff: 1\n",
    "\n",
    "# Print detailed information about differences\n",
    "print_detailed_epoch_differences(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7becec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_new_binning_container: BinningContainer = new_time_bin_containers_list[0]\n",
    "a_new_binning_container\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c107436",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_nbins\n",
    "new_nbins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b5c88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_n_bins_from_spkcount = np.array([np.shape(v)[1] for v in new_spkcount]) # new is always 1 less bin\n",
    "old_n_bins_from_spkcount = np.array([np.shape(v)[1] for v in old_spkcount])\n",
    "\n",
    "new_n_bins_from_spkcount\n",
    "old_n_bins_from_spkcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b55ded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_thing = np.array([v.centers for v in new_time_bin_containers_list])\n",
    "# new_thing = [v.edges for v in new_time_bin_containers_list]\n",
    "# new_thing\n",
    "\n",
    "n_epochs: int = len(old_nbins)\n",
    "\n",
    "# new_n_bins_from_spkcount = np.array([np.shape(v)[1] for v in new_spkcount]) # new is always 1 less bin\n",
    "# old_n_bins_from_spkcount = np.array([np.shape(v)[1] for v in old_spkcount])\n",
    "\n",
    "for i, an_new_spkcount, an_new_included_neuron_ids, an_new_nbins, new_time_bin_containers, an_old_spkcount, an_old_included_neuron_ids, an_old_nbins, old_time_bin_containers in zip(np.arange(n_epochs), new_spkcount, new_included_neuron_ids, new_nbins, new_time_bin_containers_list, old_spkcount, old_included_neuron_ids, old_nbins, old_time_bin_containers_list):\n",
    "\n",
    "    print(f'====> Epoch[{i}]:')\n",
    "\n",
    "    an_new_n_bins_from_spkcount = np.shape(an_new_spkcount)[1]\n",
    "    an_old_n_bins_from_spkcount = np.shape(an_old_spkcount)[1]\n",
    "   \n",
    "    print(f'nbins (new, old): {(an_new_nbins, an_old_nbins)}')\n",
    "    print(f'bins from spkcount (new, old): {(an_new_n_bins_from_spkcount, an_old_n_bins_from_spkcount)}')\n",
    "   \n",
    "    print(f'new centers: {np.array2string(new_time_bin_containers.centers, separator=\", \")}')\n",
    "    print(f'old centers: {np.array2string(old_time_bin_containers.centers, separator=\", \")}')\n",
    "    print(f'new edges: {np.array2string(new_time_bin_containers.edges, separator=\", \")}')\n",
    "    print(f'old edges: {np.array2string(old_time_bin_containers.edges, separator=\", \")}')\n",
    "    \n",
    "    # _ = [print(v) for v in (new_time_bin_containers.centers, old_time_bin_containers.centers)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374a8fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_thing = np.array([v.centers for v in new_time_bin_containers_list])\n",
    "new_thing = [v.edges for v in new_time_bin_containers_list]\n",
    "# new_thing\n",
    "\n",
    "n_epochs: int = len(old_nbins)\n",
    "# new_n_bins_from_spkcount = np.array([np.shape(v)[1] for v in new_spkcount]) # new is always 1 less bin\n",
    "# old_n_bins_from_spkcount = np.array([np.shape(v)[1] for v in old_spkcount])\n",
    "\n",
    "for i, an_new_spkcount, an_new_included_neuron_ids, an_new_nbins, new_time_bin_containers, an_old_spkcount, an_old_included_neuron_ids, an_old_nbins, old_time_bin_containers in zip(np.arange(n_epochs), new_spkcount, new_included_neuron_ids, new_nbins, new_time_bin_containers_list, old_spkcount, old_included_neuron_ids, old_nbins, old_time_bin_containers_list):\n",
    "    print(f'====> Epoch[{i}]:')\n",
    "    an_new_n_bins_from_spkcount = np.shape(an_new_spkcount)[1]\n",
    "    an_old_n_bins_from_spkcount = np.shape(an_old_spkcount)[1]\n",
    "    \n",
    "    print(f'new: {(an_new_nbins, an_old_nbins)}')\n",
    "    print(f'new: {(an_new_n_bins_from_spkcount, an_old_n_bins_from_spkcount)}')\n",
    "    \n",
    "    _ = [print(f'new: {np.array2string(v, separator=\", \")}') for v in (new_time_bin_containers.centers, old_time_bin_containers.centers)]\n",
    "    _ = [print(f'old: {np.array2string(v, separator=\", \")}') for v in (new_time_bin_containers.edges, old_time_bin_containers.edges)]\n",
    "    # _ = [print(v) for v in (new_time_bin_containers.centers, old_time_bin_containers.centers)]\n",
    "\n",
    "\n",
    "    # _ = [print(v) for v in (new_time_bin_containers.centers, old_time_bin_containers.centers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7adcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "[new_time_bin_containers_list, old_time_bin_containers_list]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a9f1cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb796232",
   "metadata": {},
   "source": [
    "# <a id='toc36_'></a>[2025-03-11 Apply the masking strategy introduced with the non-PBE epoch analyses on the other `DecodedFilterEpochsResult`s produced by the lap-constructed decoders (TrackTemplates)](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342da66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from neuropy.core.epoch import ensure_dataframe\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring\n",
    "from neuropy.utils.result_context import DisplaySpecifyingIdentifyingContext\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import EpochFilteringMode, _compute_proper_filter_epochs\n",
    "\n",
    "KnownNamedDecoderTrainedComputeEpochsType = Literal['laps', 'non_pbe']\n",
    "\n",
    "filtered_epochs_df = None\n",
    "\n",
    "## INPUTS: curr_active_pipeline, track_templates, a_decoded_filter_epochs_decoder_result_dict\n",
    "\n",
    "## INPUTS: directional_decoders_epochs_decode_result, filtered_epochs_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "# directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = deepcopy(curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']) ## GENERAL\n",
    "# a_new_fully_generic_result = _subfn_add_spikes_per_t_bin_masked_variants(a_new_fully_generic_result, directional_decoders_epochs_decode_result=directional_decoders_epochs_decode_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c365edda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directional_decoders_epochs_decode_result\n",
    "decoder_filter_epochs_result_dict_dict['laps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b02280",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_filter_epochs_result_dict_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ba386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict, non_PBE_marginal_over_track_ID, (time_bin_containers, time_window_centers, track_marginal_posterior_df) = nonPBE_results._build_merged_joint_placefields_and_decode(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)))\n",
    "masked_pseudo2D_continuous_specific_decoded_result, _mask_index_tuple = pseudo2D_continuous_specific_decoded_result.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)))\n",
    "# (all_time_bin_indicies, last_valid_indicies) = _mask_index_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5739b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from typing import Literal\n",
    "# Define a type that can only be one of these specific strings\n",
    "KnownNamedDecodingEpochsType = Literal['laps', 'replay', 'ripple', 'pbe', 'non_pbe']\n",
    "# Define a type that can only be one of these specific strings\n",
    "MaskedTimeBinFillType = Literal['ignore', 'last_valid', 'nan_filled', 'dropped'] ## used in `DecodedFilterEpochsResult.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(...)` to specify how invalid bins (due to too few spikes) are treated.\n",
    "\n",
    "GenericResultTupleIndexType: TypeAlias = IdentifyingContext # an template/stand-in variable that aims to abstract away the unique-hashable index of a single result computed with a given set of parameters. Not yet fully implemented 2025-03-09 17:50 \n",
    "\n",
    "\n",
    "test_identifier: IdentifyingContext = IdentifyingContext(known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='last_valid')\n",
    "\n",
    "test_identifier.get_description(include_property_names=True, separator=\"|\", key_value_separator=':') # , replace_separator_in_property_names='|'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf59afa",
   "metadata": {
    "tags": [
     "active-2025-03-11"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "from pyphoplacecellanalysis.General.type_aliases import GenericResultTupleIndexType, KnownNamedDecodingEpochsType, MaskedTimeBinFillType\n",
    "\n",
    "# a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult = GenericDecoderDictDecodedEpochsDictResult.init_from_old_GeneralDecoderDictDecodedEpochsDictResult(a_general_decoder_dict_decoded_epochs_dict_result)\n",
    "\n",
    "a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult = GenericDecoderDictDecodedEpochsDictResult()  # start empty\n",
    "\n",
    "a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult = a_new_fully_generic_result.adding_from_old_GeneralDecoderDictDecodedEpochsDictResult(a_general_decoder_dict_decoded_epochs_dict_result=a_general_decoder_dict_decoded_epochs_dict_result)\n",
    "\n",
    "# a_new_fully_generic_result = GenericDecoderDictDecodedEpochsDictResult() # start empty\n",
    "\n",
    "# for a_known_epoch_name, an_epoch in a_general_decoder_dict_decoded_epochs_dict_result.filter_epochs_to_decode_dict.items():\n",
    "#     a_new_identifier = IdentifyingContext(known_named_decoding_epochs_type=a_known_epoch_name)\n",
    "#     a_new_fully_generic_result.filter_epochs_to_decode_dict[a_new_identifier] = deepcopy(an_epoch)\n",
    "    \n",
    "#     a_new_fully_generic_result.filter_epochs_pseudo2D_continuous_specific_decoded_result[a_new_identifier] = deepcopy(a_general_decoder_dict_decoded_epochs_dict_result.filter_epochs_pseudo2D_continuous_specific_decoded_result[a_known_epoch_name])\n",
    "#     for a_known_t_bin_fill_type, a_posterior_df in a_general_decoder_dict_decoded_epochs_dict_result.filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict[a_known_epoch_name].items():\n",
    "#         a_new_joint_identifier = IdentifyingContext(known_named_decoding_epochs_type=a_known_epoch_name, masked_time_bin_fill_type=a_known_t_bin_fill_type)\n",
    "#         a_new_fully_generic_result.filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict[a_new_joint_identifier] = deepcopy(a_posterior_df)\n",
    "\n",
    "# a_new_fully_generic_result\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = deepcopy(curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']) ## GENERAL\n",
    "a_new_fully_generic_result = a_new_fully_generic_result.adding_directional_decoder_results_filtered_by_spikes_per_t_bin_masked(directional_decoders_epochs_decode_result=directional_decoders_epochs_decode_result)\n",
    "\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "a_new_fully_generic_result = a_new_fully_generic_result.adding_directional_pseudo2D_decoder_results_filtered_by_spikes_per_t_bin_masked(directional_merged_decoders_result=directional_merged_decoders_result)\n",
    "\n",
    "spikes_df = deepcopy(get_proper_global_spikes_df(curr_active_pipeline))\n",
    "a_new_fully_generic_result = a_new_fully_generic_result.creating_new_spikes_per_t_bin_masked_variants(spikes_df=spikes_df)\n",
    "\n",
    "a_new_fully_generic_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90229d86",
   "metadata": {
    "tags": [
     "active-2025-03-11"
    ]
   },
   "outputs": [],
   "source": [
    "a_new_fully_generic_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828384eb",
   "metadata": {
    "tags": [
     "active-2025-03-11"
    ]
   },
   "outputs": [],
   "source": [
    "## OUTPUTS:\n",
    "# a_new_fully_generic_result\n",
    "\n",
    "for a_context, a_marginal_df in a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict.items():\n",
    "    param_sep_str: str = '¬¶'\n",
    "    # param_sep_str: str = ''\n",
    "    # param_sep_str: str = ' ‚Åñ'\n",
    "    key_val_sep_str: str = ':'\n",
    "    a_ctxt_str: str = a_context.get_description(separator=param_sep_str, replace_separator_in_property_names='_', include_property_names=True, key_value_separator=key_val_sep_str)\n",
    "    # a_ctxt_str: str = a_context.get_initialization_code_string()\n",
    "    print(f'a_context: \"<{a_ctxt_str}>\" - np.shape(a_marginal_df): {np.shape(a_marginal_df)}')\n",
    "    \n",
    "\n",
    "# a_context: \"trained_compute_epochs:non_pbe¬¶known_named_decoding_epochs_type:laps¬¶masked_time_bin_fill_type:ignore\" - np.shape(a_marginal_df): (14350, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¬¶known_named_decoding_epochs_type:laps¬¶masked_time_bin_fill_type:last_valid\" - np.shape(a_marginal_df): (14350, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¬¶known_named_decoding_epochs_type:laps¬¶masked_time_bin_fill_type:nan_filled\" - np.shape(a_marginal_df): (14350, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¬¶known_named_decoding_epochs_type:pbe¬¶masked_time_bin_fill_type:ignore\" - np.shape(a_marginal_df): (1569, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¬¶known_named_decoding_epochs_type:pbe¬¶masked_time_bin_fill_type:last_valid\" - np.shape(a_marginal_df): (1569, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¬¶known_named_decoding_epochs_type:pbe¬¶masked_time_bin_fill_type:nan_filled\" - np.shape(a_marginal_df): (1569, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¬¶known_named_decoding_epochs_type:non_pbe¬¶masked_time_bin_fill_type:ignore\" - np.shape(a_marginal_df): (43377, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¬¶known_named_decoding_epochs_type:non_pbe¬¶masked_time_bin_fill_type:last_valid\" - np.shape(a_marginal_df): (43377, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¬¶known_named_decoding_epochs_type:non_pbe¬¶masked_time_bin_fill_type:nan_filled\" - np.shape(a_marginal_df): (43377, 9)\n",
    "# a_context: \"trained_compute_epochs:laps¬¶pfND_ndim:1¬¶decoder_identifier:pseudo2D¬¶time_bin_size:0.025¬¶known_named_decoding_epochs_type:laps¬¶masked_time_bin_fill_type:ignore¬¶data_grain:per_time_bin\" - np.shape(a_marginal_df): (14350, 15)\n",
    "# a_context: \"trained_compute_epochs:laps¬¶pfND_ndim:1¬¶decoder_identifier:pseudo2D¬¶time_bin_size:0.025¬¶known_named_decoding_epochs_type:laps¬¶masked_time_bin_fill_type:ignore¬¶data_grain:per_epoch\" - np.shape(a_marginal_df): (74, 6)\n",
    "# a_context: \"trained_compute_epochs:laps¬¶pfND_ndim:1¬¶decoder_identifier:pseudo2D¬¶time_bin_size:0.025¬¶known_named_decoding_epochs_type:pbe¬¶masked_time_bin_fill_type:ignore¬¶data_grain:per_time_bin\" - np.shape(a_marginal_df): (1165, 15)\n",
    "# a_context: \"trained_compute_epochs:laps¬¶pfND_ndim:1¬¶decoder_identifier:pseudo2D¬¶time_bin_size:0.025¬¶known_named_decoding_epochs_type:pbe¬¶masked_time_bin_fill_type:ignore¬¶data_grain:per_epoch\" - np.shape(a_marginal_df): (133, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188ef752",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a_new_fully_generic_result.filter_epochs_pseudo2D_continuous_specific_decoded_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38476959",
   "metadata": {},
   "source": [
    "##### <a id='toc36_1_1_1_1_'></a>[2025-03-11 11:13 not sure if this is the old version or if it adds something to the `a_new_fully_generic_result`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f9ccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Common/shared for all decoded epochs:\n",
    "unique_decoder_names = ['long', 'short']\n",
    "non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict, non_PBE_marginal_over_track_ID, (time_bin_containers, time_window_centers, track_marginal_posterior_df) = nonPBE_results._build_merged_joint_placefields_and_decode(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline))) # , filter_epochs=deepcopy(global_any_laps_epochs_obj)\n",
    "\n",
    "## from dict of filter_epochs to decode:\n",
    "global_replays_df: pd.DataFrame = TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].replay))\n",
    "filter_epochs_to_decode_dict: Dict[KnownNamedDecodingEpochsType, Epoch] = {'laps': ensure_Epoch(deepcopy(global_any_laps_epochs_obj)),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   'pbe': ensure_Epoch(deepcopy(global_session.pbe.get_non_overlapping())),\n",
    "\t\t\t\t\t\t\t\t#  'ripple': ensure_Epoch(deepcopy(global_session.ripple)),\n",
    "\t\t\t\t\t\t\t\t#   'replay': ensure_Epoch(deepcopy(global_replays_df)),\n",
    "\t\t\t\t\t\t\t\t  'non_pbe': ensure_Epoch(deepcopy(global_session.non_pbe)),\n",
    "\t\t\t\t\t\t\t\t  }\n",
    "# filter_epochs_to_decode_dict\n",
    "\n",
    "## Perform the decoding and masking as needed for invalid bins:\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "a_general_decoder_dict_decoded_epochs_dict_result: GeneralDecoderDictDecodedEpochsDictResult = EpochComputationsComputationsContainer._build_output_decoded_posteriors(non_PBE_all_directional_pf1D_Decoder=non_PBE_all_directional_pf1D_Decoder, # pseudo2D_continuous_specific_decoded_result=pseudo2D_continuous_specific_decoded_result,\n",
    "    filter_epochs_to_decode_dict=filter_epochs_to_decode_dict,\n",
    "    unique_decoder_names=unique_decoder_names, spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), epochs_decoding_time_bin_size=epochs_decoding_time_bin_size,\n",
    "    session_name=session_name, t_start=t_start, t_delta=t_delta, t_end=t_end,\n",
    ")\n",
    "\n",
    "\n",
    "## OUTPUTS: filter_epochs_pseudo2D_continuous_specific_decoded_result, filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict\n",
    "# 58sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d05ac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# filter_epochs_pseudo2D_continuous_specific_decoded_result, filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict\n",
    "retro_general_decoder_dict_decoded_epochs_dict_result: GeneralDecoderDictDecodedEpochsDictResult = EpochComputationsComputationsContainer._build_output_decoded_posteriors(non_PBE_all_directional_pf1D_Decoder=non_PBE_all_directional_pf1D_Decoder, # pseudo2D_continuous_specific_decoded_result=pseudo2D_continuous_specific_decoded_result,\n",
    "    filter_epochs_to_decode_dict=filter_epochs_to_decode_dict,\n",
    "    unique_decoder_names=unique_decoder_names, spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), epochs_decoding_time_bin_size=epochs_decoding_time_bin_size,\n",
    "    session_name=session_name, t_start=t_start, t_delta=t_delta, t_end=t_end,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021b0ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try fresh 2025-03-11-style decoding of the TrackTemplates:\n",
    "global_session = curr_active_pipeline.filtered_sessions[global_epoch_name]\n",
    "\n",
    "## from dict of filter_epochs to decode:\n",
    "global_replays_df: pd.DataFrame = TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(deepcopy(global_session.replay))\n",
    "global_any_laps_epochs_obj = curr_active_pipeline.computation_results[global_epoch_name].computation_config.pf_params.computation_epochs # global_session.get\n",
    "filter_epochs_to_decode_dict: Dict[KnownNamedDecodingEpochsType, Epoch] = {'laps': ensure_Epoch(deepcopy(global_any_laps_epochs_obj)),\n",
    "                                                                        'pbe': ensure_Epoch(deepcopy(global_session.pbe.get_non_overlapping())),\n",
    "                                #  'ripple': ensure_Epoch(deepcopy(global_session.ripple)),\n",
    "                                #   'replay': ensure_Epoch(deepcopy(global_replays_df)),\n",
    "                                'non_pbe': ensure_Epoch(deepcopy(global_session.non_pbe)),\n",
    "                                }\n",
    "# filter_epochs_to_decode_dict\n",
    "\n",
    "## constrain all epochs to be at least two decoding time bins long, or drop them entirely:\n",
    "filter_epochs_to_decode_dict = {k:_compute_proper_filter_epochs(epochs_df=v, desired_decoding_time_bin_size=epochs_decoding_time_bin_size, minimum_event_duration=(2.0 * epochs_decoding_time_bin_size), mode=EpochFilteringMode.DropShorter)[0] for k, v in filter_epochs_to_decode_dict.items()} # `[0]` gets just the dataframe, as in DropShorter mode the time_bin_size is unchanged\n",
    "\n",
    "## Perform the decoding and masking as needed for invalid bins:\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6a401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_decoders_epochs_decode_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
