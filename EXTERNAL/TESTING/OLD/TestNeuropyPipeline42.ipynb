{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b911237-bf80-4a81-936c-b3f3891f9481",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls.length === 0 && js_modules.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    var skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n",
       "      \n",
       "      root._bokeh_is_loading = css_urls.length + 0;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length;\n",
       "    }\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      if (skip.indexOf(url) >= 0) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (var i = 0; i < js_modules.length; i++) {\n",
       "      var url = js_modules[i];\n",
       "      if (skip.indexOf(url) >= 0) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/panel.min.js\"];\n",
       "  var js_modules = [];\n",
       "  var css_urls = [\"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/alerts.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/card.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/dataframe.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/json.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/loading.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/markdown.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/widgets.css\"];\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      inject_raw_css(\"\\n    .bk.pn-loading.arcs:before {\\n      background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiBzdHlsZT0ibWFyZ2luOiBhdXRvOyBiYWNrZ3JvdW5kOiBub25lOyBkaXNwbGF5OiBibG9jazsgc2hhcGUtcmVuZGVyaW5nOiBhdXRvOyIgdmlld0JveD0iMCAwIDEwMCAxMDAiIHByZXNlcnZlQXNwZWN0UmF0aW89InhNaWRZTWlkIj4gIDxjaXJjbGUgY3g9IjUwIiBjeT0iNTAiIHI9IjMyIiBzdHJva2Utd2lkdGg9IjgiIHN0cm9rZT0iI2MzYzNjMyIgc3Ryb2tlLWRhc2hhcnJheT0iNTAuMjY1NDgyNDU3NDM2NjkgNTAuMjY1NDgyNDU3NDM2NjkiIGZpbGw9Im5vbmUiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCI+ICAgIDxhbmltYXRlVHJhbnNmb3JtIGF0dHJpYnV0ZU5hbWU9InRyYW5zZm9ybSIgdHlwZT0icm90YXRlIiByZXBlYXRDb3VudD0iaW5kZWZpbml0ZSIgZHVyPSIxcyIga2V5VGltZXM9IjA7MSIgdmFsdWVzPSIwIDUwIDUwOzM2MCA1MCA1MCI+PC9hbmltYXRlVHJhbnNmb3JtPiAgPC9jaXJjbGU+PC9zdmc+\\\");\\n      max-height: 400px;\\n    }\\n    \");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, js_modules, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      \n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length;\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) >= 0) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) >= 0) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.2.min.js\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/panel.min.js\"];\n  var js_modules = [];\n  var css_urls = [\"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/alerts.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/card.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/dataframe.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/json.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/loading.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/markdown.css\", \"https://unpkg.com/@holoviz/panel@0.12.6/dist/css/widgets.css\"];\n  var inline_js = [\n    function(Bokeh) {\n      inject_raw_css(\"\\n    .bk.pn-loading.arcs:before {\\n      background-image: url(\\\"data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiBzdHlsZT0ibWFyZ2luOiBhdXRvOyBiYWNrZ3JvdW5kOiBub25lOyBkaXNwbGF5OiBibG9jazsgc2hhcGUtcmVuZGVyaW5nOiBhdXRvOyIgdmlld0JveD0iMCAwIDEwMCAxMDAiIHByZXNlcnZlQXNwZWN0UmF0aW89InhNaWRZTWlkIj4gIDxjaXJjbGUgY3g9IjUwIiBjeT0iNTAiIHI9IjMyIiBzdHJva2Utd2lkdGg9IjgiIHN0cm9rZT0iI2MzYzNjMyIgc3Ryb2tlLWRhc2hhcnJheT0iNTAuMjY1NDgyNDU3NDM2NjkgNTAuMjY1NDgyNDU3NDM2NjkiIGZpbGw9Im5vbmUiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCI+ICAgIDxhbmltYXRlVHJhbnNmb3JtIGF0dHJpYnV0ZU5hbWU9InRyYW5zZm9ybSIgdHlwZT0icm90YXRlIiByZXBlYXRDb3VudD0iaW5kZWZpbml0ZSIgZHVyPSIxcyIga2V5VGltZXM9IjA7MSIgdmFsdWVzPSIwIDUwIDUwOzM2MCA1MCA1MCI+PC9hbmltYXRlVHJhbnNmb3JtPiAgPC9jaXJjbGU+PC9zdmc+\\\");\\n      max-height: 400px;\\n    }\\n    \");\n    },\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, js_modules, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "@author: pho\n",
    "\"\"\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import time\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "# %gui qt\n",
    "# $env:QT_API=\"pyqt6\"\n",
    "%gui qt5\n",
    "# from PyQt5.Qt import QApplication\n",
    "# # start qt event loop\n",
    "# _instance = QApplication.instance()\n",
    "# if not _instance:\n",
    "#     _instance = QApplication([])\n",
    "# app = _instance\n",
    "import pyqtgraph as pg\n",
    "from pyqtgraph.Qt import QtCore, QtGui\n",
    "\n",
    "# ## Panel:\n",
    "# import param\n",
    "import panel as pn\n",
    "# from panel.interact import interact, interactive, fixed, interact_manual\n",
    "# from panel.viewable import Viewer\n",
    "\n",
    "pn.extension()\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.general_helpers import get_arguments_as_optional_dict, inspect_callable_arguments\n",
    "from pyphocorehelpers.function_helpers import compose_functions\n",
    "from pyphocorehelpers.indexing_helpers import partition, build_spanning_bins, compute_spanning_bins, compute_position_grid_size, compute_paginated_grid_config\n",
    "from pyphocorehelpers.print_helpers import PrettyPrintable, WrappingMessagePrinter\n",
    "from pyphocorehelpers.geometry_helpers import compute_data_extent, compute_data_aspect_ratio, corner_points_from_extents\n",
    "from pyphocorehelpers.DataStructure.dynamic_parameters import DynamicParameters\n",
    "from pyphocorehelpers.performance_timing_helpers import WrappingPerformanceTimer\n",
    "from pyphocorehelpers.gui.interaction_helpers import CallbackWrapper\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.SessionSelectionAndFiltering import batch_filter_session, build_custom_epochs_filters\n",
    "from pyphoplacecellanalysis.General.ComputationResults import ComputationResult\n",
    "from pyphoplacecellanalysis.General.KnownDataSessionTypeProperties import KnownDataSessionTypeProperties\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Display import DefaultDisplayFunctions\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.Ratemaps import DefaultRatemapDisplayFunctions\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import DefaultDecoderDisplayFunctions\n",
    "\n",
    "\n",
    "\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.pyqtplot_RasterPlot import plot_raster_plot, _display_pyqtgraph_raster_plot, plot_3d_raster_plot\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "try:\n",
    "    from neuropy import core\n",
    "\n",
    "    importlib.reload(core)\n",
    "except ImportError:\n",
    "    sys.path.append(r\"C:\\Users\\Pho\\repos\\NeuroPy\")  # Windows\n",
    "    # sys.path.append('/home/pho/repo/BapunAnalysis2021/NeuroPy') # Linux\n",
    "    # sys.path.append(r'/Users/pho/repo/Python Projects/NeuroPy') # MacOS\n",
    "    print(\"neuropy module not found, adding directory to sys.path. \\n >> Updated sys.path.\")\n",
    "    from neuropy import core\n",
    "\n",
    "# Neuropy:\n",
    "from neuropy.core.session.data_session_loader import DataSessionLoader\n",
    "from neuropy.core.session.dataSession import DataSession\n",
    "from neuropy.core.laps import Laps\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters, perform_compute_placefields\n",
    "from neuropy.analyses.laps import estimation_session_laps\n",
    "from neuropy.core.epoch import NamedTimerange\n",
    "\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters, perform_compute_placefields\n",
    "from neuropy.core.neuron_identities import NeuronIdentity, build_units_colormap, PlotStringBrevityModeEnum\n",
    "from neuropy.utils.debug_helpers import debug_print_placefield, debug_print_spike_counts, debug_print_subsession_neuron_differences\n",
    "from neuropy.plotting.ratemaps import enumTuningMap2DPlotVariables\n",
    "# from neuropy.utils.mixins.time_slicing import verify_non_overlapping, add_PBE_identity\n",
    "from neuropy.utils.efficient_interval_search import get_non_overlapping_epochs, drop_overlapping\n",
    "\n",
    "known_data_session_type_dict = {'kdiba':KnownDataSessionTypeProperties(load_function=(lambda a_base_dir: DataSessionLoader.kdiba_old_format_session(a_base_dir)),\n",
    "                               basedir=Path(r'R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53')),\n",
    "                'bapun':KnownDataSessionTypeProperties(load_function=(lambda a_base_dir: DataSessionLoader.bapun_data_session(a_base_dir)),\n",
    "                               basedir=Path('R:\\data\\Bapun\\Day5TwoNovel'))\n",
    "               }\n",
    "known_data_session_type_dict['kdiba'].post_load_functions = [lambda a_loaded_sess: estimation_session_laps(a_loaded_sess)]\n",
    "\n",
    "# known_data_session_type_dict['kdiba'].name\n",
    "# from matplotlib.figure import Figure\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib qt\n",
    "# from matplotlib.transforms import IdentityTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28884090-444c-4c0a-a0a1-c7d5d09bf195",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "enable_saving_to_disk = False\n",
    "# common_parent_foldername = Path(r'R:\\Dropbox (Personal)\\Active\\Kamran Diba Lib\\Pho-Kamran-Meetings\\Final Placemaps 2021-01-14')\n",
    "common_parent_foldername = Path(r'R:\\Dropbox (Personal)\\Active\\Kamran Diba Lib\\Pho-Kamran-Meetings\\2022-01-16')\n",
    "\n",
    "def compute_position_grid_bin_size(x, y, num_bins=(64,64), debug_print=False):\n",
    "    \"\"\" Compute Required Bin size given a desired number of bins in each dimension\n",
    "    Usage:\n",
    "        active_grid_bin = compute_position_grid_bin_size(curr_kdiba_pipeline.sess.position.x, curr_kdiba_pipeline.sess.position.y, num_bins=(64, 64)\n",
    "    \"\"\"\n",
    "    out_grid_bin_size, out_bins, out_bins_infos = compute_position_grid_size(x, y, num_bins=num_bins)\n",
    "    active_grid_bin = tuple(out_grid_bin_size)\n",
    "    if debug_print:\n",
    "        print(f'active_grid_bin: {active_grid_bin}') # (3.776841861770752, 1.043326930905373)\n",
    "    return active_grid_bin\n",
    "\n",
    "# WARNING! TODO: Changing the smooth values from (1.5, 1.5) to (0.5, 0.5) was the difference between successful running and a syntax error!\n",
    "# try:\n",
    "#     active_grid_bin\n",
    "# except NameError as e:\n",
    "#     print('setting active_grid_bin = None')\n",
    "#     active_grid_bin = None\n",
    "# finally:\n",
    "#     # active_session_computation_config = PlacefieldComputationParameters(speed_thresh=10.0, grid_bin=active_grid_bin, smooth=(1.0, 1.0), frate_thresh=0.2, time_bin_size=0.5) # if active_grid_bin is missing, figure out the name\n",
    "#     active_session_computation_config = PlacefieldComputationParameters(speed_thresh=10.0, grid_bin=active_grid_bin, smooth=(1.0, 1.0), frate_thresh=0.2, time_bin_size=0.5) # if active_grid_bin is missing, figure out the name\n",
    "\n",
    "## Dynamic mode:\n",
    "def _build_active_computation_configs(sess):\n",
    "    \"\"\" _get_computation_configs(curr_kdiba_pipeline.sess)\n",
    "        # From Diba:\n",
    "        # (3.777, 1.043) # for (64, 64) bins\n",
    "        # (1.874, 0.518) # for (128, 128) bins\n",
    "\n",
    "    \"\"\"\n",
    "    # active_grid_bin = compute_position_grid_bin_size(sess.position.x, sess.position.y, num_bins=(64, 64))\n",
    "    # active_session_computation_config.computation_epochs = None # set the placefield computation epochs to None, using all epochs.\n",
    "    # return [PlacefieldComputationParameters(speed_thresh=10.0, grid_bin=compute_position_grid_bin_size(sess.position.x, sess.position.y, num_bins=(64, 64)), smooth=(1.0, 1.0), frate_thresh=0.2, time_bin_size=0.5, computation_epochs = None)]\n",
    "    # return [PlacefieldComputationParameters(speed_thresh=10.0, grid_bin=compute_position_grid_bin_size(sess.position.x, sess.position.y, num_bins=(128, 128)), smooth=(2.0, 2.0), frate_thresh=0.2, time_bin_size=0.5, computation_epochs = None)]\n",
    "    return [PlacefieldComputationParameters(speed_thresh=10.0, grid_bin=compute_position_grid_bin_size(sess.position.x, sess.position.y, num_bins=(64, 64)), smooth=(2.0, 2.0), frate_thresh=0.2, time_bin_size=1.0, computation_epochs = None)]\n",
    "    # return [PlacefieldComputationParameters(speed_thresh=10.0, grid_bin=(3.777, 1.043), smooth=(1.0, 1.0), frate_thresh=0.2, time_bin_size=0.5, computation_epochs = None)]\n",
    "\n",
    "    # return [PlacefieldComputationParameters(speed_thresh=10.0, grid_bin=compute_position_grid_bin_size(sess.position.x, sess.position.y, num_bins=(32, 32)), smooth=(1.0, 1.0), frate_thresh=0.2, time_bin_size=0.5, computation_epochs = None),\n",
    "    #         PlacefieldComputationParameters(speed_thresh=10.0, grid_bin=compute_position_grid_bin_size(sess.position.x, sess.position.y, num_bins=(64, 64)), smooth=(1.0, 1.0), frate_thresh=0.2, time_bin_size=0.5, computation_epochs = None),\n",
    "    #         PlacefieldComputationParameters(speed_thresh=10.0, grid_bin=compute_position_grid_bin_size(sess.position.x, sess.position.y, num_bins=(128, 128)), smooth=(1.0, 1.0), frate_thresh=0.2, time_bin_size=0.5, computation_epochs = None),\n",
    "    #        ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eceb354-7fa7-4064-ba26-4e989b9f3354",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bapun Format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20843de4-9a94-42f7-80a9-f2c8d5704b62",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# curr_bapun_pipeline = NeuropyPipeline(name='bapun_pipeline', session_data_type='bapun', basedir=known_data_session_type_dict['bapun'].basedir, load_function=known_data_session_type_dict['bapun'].load_function)\n",
    "curr_bapun_pipeline = NeuropyPipeline.init_from_known_data_session_type('bapun', known_data_session_type_dict['bapun'])\n",
    "active_session_computation_configs = _build_active_computation_configs(curr_bapun_pipeline.sess)\n",
    "# active_session_computation_config.grid_bin = compute_position_grid_bin_size(curr_bapun_pipeline.sess.position.x, curr_bapun_pipeline.sess.position.y, num_bins=(64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e0cc6c-4c19-4670-b685-bba16553e82c",
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bapun/DataFrame style session filter functions:\n",
    "def build_bapun_any_epochs_filters(sess):\n",
    "    return build_custom_epochs_filters(sess)\n",
    "    \n",
    "def build_bapun_any_maze_epochs_filters(sess):\n",
    "    # all_filters = build_custom_epochs_filters(sess)\n",
    "    # # print(f'all_filters: {all_filters}')\n",
    "    # maze_only_filters = dict()\n",
    "    # for (name, filter_fcn) in all_filters.items():\n",
    "    #     if 'maze' in name:\n",
    "    #         maze_only_filters[name] = filter_fcn\n",
    "    # maze_only_filters = build_custom_epochs_filters(sess, included_epoch_labels=['maze1','maze2'])\n",
    "    # { key:value for (key,value) in dictOfNames.items() if key % 2 == 0}\n",
    "    # dict(filter(lambda elem: len(elem[1]) == 6,dictOfNames.items()))\n",
    "    # maze_only_name_filter_fn = lambda dict: dict(filter(lambda elem: 'maze' in elem[0], dict.items()))\n",
    "    maze_only_name_filter_fn = lambda names: list(filter(lambda elem: elem.startswith('maze'), names))\n",
    "    # print(f'callable(maze_only_name_filter_fn): {callable(maze_only_name_filter_fn)}')\n",
    "    # print(maze_only_name_filter_fn(['pre', 'maze1', 'post1', 'maze2', 'post2']))\n",
    "    # lambda elem: elem[0] % 2 == 0\n",
    "    maze_only_filters = build_custom_epochs_filters(sess, included_epoch_labels=maze_only_name_filter_fn)\n",
    "    # print(f'maze_only_filters: {maze_only_filters}')\n",
    "    return maze_only_filters\n",
    "\n",
    "# active_session_filter_configurations = build_bapun_any_epochs_filters(curr_bapun_pipeline.sess)\n",
    "active_session_filter_configurations = build_bapun_any_maze_epochs_filters(curr_bapun_pipeline.sess)\n",
    "# print(f'active_session_filter_configurations: {active_session_filter_configurations}')\n",
    "curr_bapun_pipeline.filter_sessions(active_session_filter_configurations)\n",
    "for i in np.arange(len(active_session_computation_configs)):\n",
    "    active_session_computation_configs[i].computation_epochs = None  # set the placefield computation epochs to None, using all epochs.\n",
    "curr_bapun_pipeline.perform_computations(active_session_computation_configs[0])\n",
    "curr_bapun_pipeline.prepare_for_display() # TODO: pass a display config\n",
    "# Set curr_active_pipeline for testing:\n",
    "curr_active_pipeline = curr_bapun_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4940269-23e4-46dc-a4ae-61d512ac5e41",
   "metadata": {
    "tags": []
   },
   "source": [
    "## KDiba Format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "506398f3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basedir is already Path object.\n",
      "\t basepath: R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\n",
      "\t session_name: 2006-6-07_11-26-53\n",
      "Loading matlab import file results to R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.epochs_info.mat... done.\n",
      "Loading matlab import file results to R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.position_info.mat... done.\n",
      "Loading matlab import file results to R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.spikes.mat... done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Computing linear positions for all active epochs for session... Saving updated position results results to R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.position.npy... 2006-6-07_11-26-53.position.npy saved\n",
      "done.\n",
      "\t Failure loading .interpolated_spike_positions.npy. Must recompute.\n",
      "\n",
      "\t Saving updated interpolated spike position results results to R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.interpolated_spike_positions.npy... 2006-6-07_11-26-53.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results to R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53\\2006-6-07_11-26-53.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "Loading success: .ripple.npy.\n",
      "Loading success: .mua.npy.\n",
      "Loading success: .pbe.npy.\n",
      "desc_crossings_x: (24,), asc_crossings_x: (24,)\n"
     ]
    }
   ],
   "source": [
    "## Data must be pre-processed using the MATLAB script located here: \n",
    "# R:\\data\\KDIBA\\gor01\\one\\IIDataMat_Export_ToPython_2021_11_23.m\n",
    "# From pre-computed .mat files:\n",
    "## 07: \n",
    "# basedir = r'R:\\data\\KDIBA\\gor01\\one\\2006-6-07_11-26-53'\n",
    "# # ## 08:\n",
    "# basedir = r'R:\\data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15'\n",
    "# curr_kdiba_pipeline = NeuropyPipeline(name='kdiba_pipeline', session_data_type='kdiba', basedir=known_data_session_type_dict['kdiba'].basedir, load_function=known_data_session_type_dict['kdiba'].load_function)\n",
    "curr_kdiba_pipeline = NeuropyPipeline.init_from_known_data_session_type('kdiba', known_data_session_type_dict['kdiba'])\n",
    "# active_grid_bin = compute_position_grid_bin_size(curr_kdiba_pipeline.sess.position.x, curr_kdiba_pipeline.sess.position.y, num_bins=(64, 64))\n",
    "# active_session_computation_config.grid_bin = active_grid_bin\n",
    "active_session_computation_configs = _build_active_computation_configs(curr_kdiba_pipeline.sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22f03a92-1685-41a6-b10c-88ea7dc55ad9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying session filter named \"maze1\"...\n",
      "Constraining to epoch with times (start: 22.26, end: 1739.1533641185379)\n",
      "computing neurons mua for session...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df[['lap_id']] = laps_df[['lap_id']].astype('int')\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df[['start_spike_index', 'end_spike_index']] = laps_df[['start_spike_index', 'end_spike_index']].astype('int')\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['num_spikes'] = laps_df['end_spike_index'] - laps_df['start_spike_index']\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:73: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['lap_dir'] = laps_df['lap_dir'].astype('int')\n",
      "c:\\users\\pho\\repos\\neuropy\\neuropy\\core\\laps.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  laps_df['label'] = laps_df['lap_id'].astype('str') # add the string \"label\" column\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing single_computation on filtered_session with filter named \"maze1\"...\n",
      "Recomputing active_epoch_placefields... pre speed filtering: 819159 spikes.\n",
      "post speed filtering: 193520 spikes.\n",
      "\t done.\n",
      "Recomputing active_epoch_placefields2D... pre speed filtering: 819159 spikes.\n",
      "post speed filtering: 226415 spikes.\n",
      "\t done.\n",
      "Performing perform_registered_computations(...) with 5 registered_computation_functions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pho\\repos\\pyphoplacecellanalysis\\src\\pyphoplacecellanalysis\\Analysis\\reconstruction.py:177: RuntimeWarning: overflow encountered in double_scalars\n",
      "  C_tau_n = 1.0 / np.sum(un_normalized_result) # normalize the result\n",
      "c:\\users\\pho\\repos\\pyphoplacecellanalysis\\src\\pyphoplacecellanalysis\\Analysis\\reconstruction.py:178: RuntimeWarning: invalid value encountered in multiply\n",
      "  result = C_tau_n * un_normalized_result\n",
      "c:\\users\\pho\\repos\\pyphoplacecellanalysis\\src\\pyphoplacecellanalysis\\Analysis\\reconstruction.py:177: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  C_tau_n = 1.0 / np.sum(un_normalized_result) # normalize the result\n",
      "c:\\users\\pho\\repos\\pyphoplacecellanalysis\\src\\pyphoplacecellanalysis\\Analysis\\reconstruction.py:217: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return C * np.exp(numerator/denominator)\n",
      "c:\\users\\pho\\repos\\pyphoplacecellanalysis\\src\\pyphoplacecellanalysis\\Analysis\\reconstruction.py:232: RuntimeWarning: invalid value encountered in multiply\n",
      "  return k * one_step_p_x_given_n * cls.compute_conditional_probability_x_prev_given_x_t(x_prev, all_x, sigma_t, C)\n"
     ]
    }
   ],
   "source": [
    "def build_any_maze_epochs_filters(sess):\n",
    "    sess.epochs.t_start = 22.26 # exclude the first short period where the animal isn't on the maze yet\n",
    "    active_session_filter_configurations = {'maze1': lambda x: (x.filtered_by_epoch(x.epochs.get_named_timerange('maze1')), x.epochs.get_named_timerange('maze1')) } # just maze 1\n",
    "    # active_session_filter_configurations = {'maze1': lambda x: (x.filtered_by_epoch(x.epochs.get_named_timerange('maze1')), x.epochs.get_named_timerange('maze1')),\n",
    "    #                                     'maze2': lambda x: (x.filtered_by_epoch(x.epochs.get_named_timerange('maze2')), x.epochs.get_named_timerange('maze2')),\n",
    "    #                                     'maze': lambda x: (x.filtered_by_epoch(NamedTimerange(name='maze', start_end_times=[x.epochs['maze1'][0], x.epochs['maze2'][1]])), NamedTimerange(name='maze', start_end_times=[x.epochs['maze1'][0], x.epochs['maze2'][1]]))\n",
    "    #                                    }\n",
    "    return active_session_filter_configurations\n",
    "\n",
    "active_session_filter_configurations = build_any_maze_epochs_filters(curr_kdiba_pipeline.sess)\n",
    "curr_kdiba_pipeline.filter_sessions(active_session_filter_configurations)\n",
    "for i in np.arange(len(active_session_computation_configs)):\n",
    "    active_session_computation_configs[i].computation_epochs = None # add the laps epochs to all of the computation configs.\n",
    "\n",
    "curr_kdiba_pipeline.perform_computations(active_session_computation_configs[0])\n",
    "curr_kdiba_pipeline.prepare_for_display() # TODO: pass a display config\n",
    "# set curr_active_pipeline for testing:\n",
    "curr_active_pipeline = curr_kdiba_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee23920e-5d46-4258-8a99-bb40056913f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pyramidal_epochs_filters(sess):\n",
    "    sess.epochs.t_start = 22.26 # exclude the first short period where the animal isn't on the maze yet\n",
    "    active_session_filter_configurations = {'maze1': lambda x: (x.filtered_by_neuron_type('pyramidal').filtered_by_epoch(x.epochs.get_named_timerange('maze1')), x.epochs.get_named_timerange('maze1')),\n",
    "                                        'maze2': lambda x: (x.filtered_by_neuron_type('pyramidal').filtered_by_epoch(x.epochs.get_named_timerange('maze2')), x.epochs.get_named_timerange('maze2')),\n",
    "                                        'maze': lambda x: (x.filtered_by_neuron_type('pyramidal').filtered_by_epoch(NamedTimerange(name='maze', start_end_times=[x.epochs['maze1'][0], x.epochs['maze2'][1]])), NamedTimerange(name='maze', start_end_times=[x.epochs['maze1'][0], x.epochs['maze2'][1]]))\n",
    "                                       }\n",
    "    return active_session_filter_configurations\n",
    "\n",
    "active_session_filter_configurations = build_pyramidal_epochs_filters(curr_kdiba_pipeline.sess)\n",
    "\n",
    "\n",
    "is_non_overlapping_lap = get_non_overlapping_epochs(curr_kdiba_pipeline.sess.laps.to_dataframe()[['start','stop']].to_numpy())\n",
    "only_good_laps_df = curr_kdiba_pipeline.sess.laps.to_dataframe()[is_non_overlapping_lap]\n",
    "curr_kdiba_pipeline.sess.laps = Laps(only_good_laps_df) # replace the laps object with the filtered one\n",
    "\n",
    "\n",
    "lap_specific_epochs = curr_kdiba_pipeline.sess.laps.as_epoch_obj()\n",
    "any_lap_specific_epochs = lap_specific_epochs.label_slice(lap_specific_epochs.labels[np.arange(len(curr_kdiba_pipeline.sess.laps.lap_id))])\n",
    "even_lap_specific_epochs = lap_specific_epochs.label_slice(lap_specific_epochs.labels[np.arange(0, len(curr_kdiba_pipeline.sess.laps.lap_id), 2)])\n",
    "odd_lap_specific_epochs = lap_specific_epochs.label_slice(lap_specific_epochs.labels[np.arange(1, len(curr_kdiba_pipeline.sess.laps.lap_id), 2)])\n",
    "\n",
    "\n",
    "# Copy the active session_computation_config:\n",
    "for i in np.arange(len(active_session_computation_configs)):\n",
    "    active_session_computation_configs[i].computation_epochs = any_lap_specific_epochs # add the laps epochs to all of the computation configs.\n",
    "\n",
    "curr_kdiba_pipeline.filter_sessions(active_session_filter_configurations)\n",
    "curr_kdiba_pipeline.perform_computations(active_session_computation_configs[0]) # Causes \"IndexError: index 59 is out of bounds for axis 0 with size 59\"\n",
    "curr_kdiba_pipeline.prepare_for_display() # TODO: pass a display config\n",
    "# set curr_active_pipeline for testing:\n",
    "curr_active_pipeline = curr_kdiba_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3136f4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Common: Optional Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7d9acd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from pyphocorehelpers.print_helpers import debug_dump_object_member_shapes\n",
    "\n",
    "curr_active_pipeline\n",
    "# debug_dump_object_member_shapes(curr_active_pipeline)\n",
    "# curr_active_pipeline.__dict__\n",
    "# debug_dump_object_member_shapes(curr_active_pipeline.computation_results)\n",
    "\n",
    "# curr_active_pipeline.filtered_sessions\n",
    "# curr_active_pipeline.computation_results\n",
    "\n",
    "# debug_dump_object_member_shapes(active_session_computation_configs.st)\n",
    "# curr_active_pipeline.computation_results.to_pickle('R:\\completed_pipeline.pkl', protocol=5)\n",
    "\n",
    "# pickle.dump(curr_active_pipeline.computation_results, open(\"R:\\completed_pipeline.pkl\", 'wb'), protocol=5)\n",
    "\n",
    "# pickle.dump(curr_active_pipeline.filtered_sessions, open(\"R:\\completed_pipeline_kdiba_sessions.pkl\", 'wb'), protocol=5)\n",
    "# pickle.dump(curr_active_pipeline.computation_results, open(\"R:\\completed_pipeline_kdiba.pkl\", 'wb'), protocol=5)\n",
    "\n",
    "# np.savez_compressed('completed_pipeline', curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd6649",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "curr_epoch_labels = list(curr_active_pipeline.sess.epochs.labels) # ['pre', 'maze1', 'post1', 'maze2', 'post2']\n",
    "curr_named_timeranges = [curr_active_pipeline.sess.epochs.get_named_timerange(a_label) for a_label in curr_epoch_labels]\n",
    "\n",
    "curr_named_timeranges\n",
    "\n",
    "all_filters_list = list(curr_active_pipeline.filtered_sessions.keys())\n",
    "all_filters_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d57f5d",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Analyze PBEs by looping through the filtered epochs:\n",
    "\n",
    "\n",
    "# curr_kdiba_pipeline.sess.spikes_df.spikes.time_variable_name # 't_rel_seconds' \n",
    "# active_timestamps = curr_kdiba_pipeline.sess.spikes_df[curr_kdiba_pipeline.sess.spikes_df.spikes.time_variable_name].copy().to_numpy() # get the timestamps column using the time_variable_name property. It's 't_rel_seconds' for kdiba-format data for example\n",
    "# active_timestamps\n",
    "\n",
    "curr_kdiba_pipeline.sess.spikes_df[curr_kdiba_pipeline.sess.spikes_df['PBE_id'] > -1]\n",
    "\n",
    "# curr_epoch_duration\n",
    "# determine_event_interval_is_included(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b44895",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#TODO: Works, but need to convert into the computation function format or find a new place to put it. It operates on the entire pipeline while currently computation functions are limited to operating on one stage at a time.\n",
    "def _perform_PBE_stats(active_pipeline, debug_print = False):\n",
    "    \"\"\" # Analyze PBEs by looping through the filtered epochs:\n",
    "        This whole implementation seems silly and inefficient        \n",
    "        Can't I use .agg(['count', 'mean']) or something? \n",
    "    \"\"\"\n",
    "    all_epochs_labels = []\n",
    "    all_epochs_total_durations = []\n",
    "    all_epochs_n_pbes = []\n",
    "    all_epochs_pbe_duration_lists = []\n",
    "    all_epochs_cummulative_pbe_durations = []\n",
    "    all_epochs_mean_pbe_durations = []\n",
    "    all_epochs_full_pbe_spiketrain_lists = []\n",
    "    all_epochs_pbe_num_spikes_lists = []\n",
    "    all_epochs_intra_pbe_interval_lists = []\n",
    "    \n",
    "    for (name, filtered_sess) in active_pipeline.filtered_sessions.items():\n",
    "        # interested in analyzing both the filtered_sess.pbe and the filtered_sess.spikes_df (as they relate to the PBEs)\n",
    "        all_epochs_labels.append(name)\n",
    "        curr_named_time_range = active_pipeline.sess.epochs.get_named_timerange(name) # for 'maze' key, the total duration is being set to array([], dtype=float64) for some reason. all_epochs_total_durations: [1716.8933641185379, 193.26664069312392, array([], dtype=float64)]\n",
    "        \n",
    "        if not np.isscalar(curr_named_time_range.duration):\n",
    "            # for 'maze' key, the total duration is being set to array([], dtype=float64) for some reason. all_epochs_total_durations: [1716.8933641185379, 193.26664069312392, array([], dtype=float64)]\n",
    "            curr_named_time_range = NamedTimerange(name='maze', start_end_times=[active_pipeline.sess.epochs['maze1'][0], active_pipeline.sess.epochs['maze2'][1]])\n",
    "        \n",
    "        curr_epoch_duration = curr_named_time_range.duration\n",
    "        all_epochs_total_durations.append(curr_epoch_duration) # TODO: this should be in seconds (or at least the same units as the PBE durations)... actually this might be right.\n",
    "        # Computes the intervals between each PBE:\n",
    "        curr_intra_pbe_intervals = filtered_sess.pbe.starts[1:] - filtered_sess.pbe.stops[:-1]\n",
    "        all_epochs_intra_pbe_interval_lists.append(curr_intra_pbe_intervals)\n",
    "        all_epochs_n_pbes.append(filtered_sess.pbe.n_epochs)\n",
    "        all_epochs_pbe_duration_lists.append(filtered_sess.pbe.durations)\n",
    "        all_epochs_cummulative_pbe_durations.append(np.sum(filtered_sess.pbe.durations))\n",
    "        all_epochs_mean_pbe_durations.append(np.nanmean(filtered_sess.pbe.durations))\n",
    "        # filtered_sess.spikes_df.PBE_id\n",
    "        curr_pbe_only_spikes_df = filtered_sess.spikes_df[filtered_sess.spikes_df.PBE_id > -1].copy()\n",
    "        unique_PBE_ids = np.unique(curr_pbe_only_spikes_df['PBE_id'])\n",
    "        flat_PBE_ids = [int(id) for id in unique_PBE_ids]\n",
    "        num_unique_PBE_ids = len(flat_PBE_ids)\n",
    "        # groups the spikes_df by PBEs:\n",
    "        curr_pbe_grouped_spikes_df = curr_pbe_only_spikes_df.groupby(['PBE_id'])\n",
    "        curr_spiketrains = list()\n",
    "        curr_PBE_spiketrain_num_spikes = list()\n",
    "        for i in np.arange(num_unique_PBE_ids):\n",
    "            curr_PBE_id = flat_PBE_ids[i] # actual cell ID\n",
    "            #curr_flat_cell_indicies = (flat_spikes_out_dict['aclu'] == curr_cell_id) # the indicies where the cell_id matches the current one\n",
    "            curr_PBE_dataframe = curr_pbe_grouped_spikes_df.get_group(curr_PBE_id)\n",
    "            curr_PBE_num_spikes = np.shape(curr_PBE_dataframe)[0] # the number of spikes in this PBE\n",
    "            curr_PBE_spiketrain_num_spikes.append(curr_PBE_num_spikes)\n",
    "            curr_spiketrains.append(curr_PBE_dataframe['t'].to_numpy())\n",
    "\n",
    "        curr_PBE_spiketrain_num_spikes = np.array(curr_PBE_spiketrain_num_spikes)\n",
    "        all_epochs_pbe_num_spikes_lists.append(curr_PBE_spiketrain_num_spikes)\n",
    "        curr_spiketrains = np.array(curr_spiketrains, dtype='object')\n",
    "        all_epochs_full_pbe_spiketrain_lists.append(curr_spiketrains)\n",
    "        if debug_print:\n",
    "            print(f'name: {name}, filtered_sess.pbe: {filtered_sess.pbe}')\n",
    "\n",
    "    if debug_print:\n",
    "        print(f'all_epochs_n_pbes: {all_epochs_n_pbes}, all_epochs_mean_pbe_durations: {all_epochs_mean_pbe_durations}, all_epochs_cummulative_pbe_durations: {all_epochs_cummulative_pbe_durations}, all_epochs_total_durations: {all_epochs_total_durations}')\n",
    "        # all_epochs_n_pbes: [3152, 561, 1847, 832, 4566], all_epochs_mean_pbe_durations: [0.19560881979695527, 0.22129233511594312, 0.19185056848946497, 0.2333112980769119, 0.1987152869032212]\n",
    "\n",
    "    all_epochs_pbe_occurance_rate = [(float(all_epochs_total_durations[i]) / float(all_epochs_n_pbes[i])) for i in np.arange(len(all_epochs_n_pbes))]\n",
    "    all_epochs_pbe_percent_duration = [(float(all_epochs_total_durations[i]) / float(all_epochs_cummulative_pbe_durations[i])) for i in np.arange(len(all_epochs_n_pbes))]    \n",
    "    all_epoch_mean_num_pbe_spikes = [np.nanmean(pbe_spike_counts) for pbe_spike_counts in all_epochs_pbe_num_spikes_lists] # [3151, 561, 1847, 831, 4563]\n",
    "    all_epoch_std_num_pbe_spikes = [np.nanstd(pbe_spike_counts) for pbe_spike_counts in all_epochs_pbe_num_spikes_lists] # [11.638970035733648, 15.013817202645336, 15.5123897729991, 15.113395025612247, 11.473087401691878]\n",
    "    # [20.429704855601397, 27.338680926916222, 23.748781808337846, 25.673886883273166, 20.38614946307254]\n",
    "    # Build the final output result dataframe:\n",
    "    pbe_analyses_result_df = pd.DataFrame({'n_pbes':all_epochs_n_pbes, 'mean_pbe_durations': all_epochs_mean_pbe_durations, 'cummulative_pbe_durations':all_epochs_cummulative_pbe_durations, 'epoch_total_duration':all_epochs_total_durations,\n",
    "                'pbe_occurance_rate':all_epochs_pbe_occurance_rate, 'pbe_percent_duration':all_epochs_pbe_percent_duration,\n",
    "                'mean_num_pbe_spikes':all_epoch_mean_num_pbe_spikes, 'stddev_num_pbe_spikes':all_epoch_std_num_pbe_spikes}, index=all_epochs_labels)\n",
    "    # temporary: this isn't how the returns work for other computation functions:\n",
    "    all_epochs_info = [all_epochs_full_pbe_spiketrain_lists, all_epochs_pbe_num_spikes_lists, all_epochs_intra_pbe_interval_lists] # list version\n",
    "    # all_epochs_info = {'all_epochs_full_pbe_spiketrain_lists':all_epochs_full_pbe_spiketrain_lists, 'all_epochs_pbe_num_spikes_lists':all_epochs_pbe_num_spikes_lists, 'all_epochs_intra_pbe_interval_lists':all_epochs_intra_pbe_interval_lists} # dict version\n",
    "    return pbe_analyses_result_df, all_epochs_info\n",
    "\n",
    "pbe_analyses_result_df, [all_epochs_full_pbe_spiketrain_lists, all_epochs_pbe_num_spikes_lists, all_epochs_intra_pbe_interval_lists] = _perform_PBE_stats(curr_active_pipeline, debug_print=False) # all_epochs_n_pbes: [206, 31, 237], all_epochs_mean_pbe_durations: [0.2209951456310722, 0.23900000000001073, 0.22335021097046923], all_epochs_cummulative_pbe_durations: [45.52500000000087, 7.409000000000333, 52.934000000001205], all_epochs_total_durations: [1716.8933641185379, 193.26664069312392, 1910.1600048116618]\n",
    "\n",
    "pbe_analyses_result_df\n",
    "# pbe_analyses_result_df.to_clipboard(sep=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee40f53-70cd-4b54-8fa1-71117a9a200c",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.pyqtplot_SimplePlot import plot_simple_graph\n",
    "\n",
    "[p1], win, app = plot_simple_graph(all_epochs_intra_pbe_interval_lists[0])\n",
    "\n",
    "for (idx, named_range) in enumerate(curr_named_timeranges):\n",
    "    # interested in analyzing both the filtered_sess.pbe and the filtered_sess.spikes_df (as they relate to the PBEs)\n",
    "    p1.plot(all_epochs_intra_pbe_interval_lists[idx] + (300 * idx), pen=(255,0,0), name=named_range.name)\n",
    "\n",
    "# p1.plot(np.random.normal(size=100), pen=(255,0,0), name=\"Red curve\")\n",
    "# p1.plot(np.random.normal(size=110)+5, pen=(0,255,0), name=\"Green curve\")\n",
    "# p1.plot(np.random.normal(size=120)+10, pen=(0,0,255), name=\"Blue curve\")\n",
    "\n",
    "# def plot_simple_graph(y=np.random.normal(size=100))\n",
    "#     app = pg.mkQApp(\"Plotting Example\")\n",
    "#     #mw = QtGui.QMainWindow()\n",
    "#     #mw.resize(800,800)\n",
    "#     \n",
    "#     win = pg.GraphicsLayoutWidget(show=True, title=\"Basic plotting examples\")\n",
    "#     win.resize(1000,600)\n",
    "#     win.setWindowTitle('pyqtgraph example: Plotting')\n",
    "#     \n",
    "#     # Enable antialiasing for prettier plots\n",
    "#     pg.setConfigOptions(antialias=True)\n",
    "#     \n",
    "#     p1 = win.addPlot(title=\"Basic array plotting\", y=y)\n",
    "#     \n",
    "#     return app, win, [p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9795cd4-6968-4458-9442-3e38701ad1e8",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Find all spikes that occur during both a PBE & a lap on the track:\n",
    "\n",
    "# curr_active_pipeline.sess.spikes_df[(curr_active_pipeline.sess.spikes_df['PBE_id'] > -1)] # & (curr_active_pipeline.sess.spikes_df['lap'] != -1)\n",
    "during_lap_and_PBE_spikes_df = curr_active_pipeline.sess.spikes_df[(curr_active_pipeline.sess.spikes_df['PBE_id'] > -1) & (curr_active_pipeline.sess.spikes_df['lap'] != -1)]\n",
    "# curr_active_pipeline.sess.spikes_df[(curr_active_pipeline.sess.spikes_df['lap'] > -1)]\n",
    "during_lap_and_PBE_spikes_df\n",
    "\n",
    "# updated_spikes_df = curr_active_pipeline.sess.compute_PBEs_spikes_df(curr_active_pipeline.sess.spikes_df, curr_active_pipeline.sess.pbe.to_dataframe())\n",
    "# updated_spikes_df[(updated_spikes_df['PBE_id'] > -1)]\n",
    "# curr_active_pipeline.sess.spikes_df[(curr_active_pipeline.sess.spikes_df['PBE_id'] > -1)]\n",
    "# curr_active_pipeline.sess.spikes_df\n",
    "\n",
    "# group by Team, get mean, min, and max value of Age for each value of Team.\n",
    "grouped_single = during_lap_and_PBE_spikes_df.groupby('lap').agg({'PBE_id': ['mean', 'min', 'max']})\n",
    "grouped_single = grouped_single.reset_index()\n",
    "print(grouped_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "10d8670b-8cae-458e-9a39-de7a223a55d2",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>t_seconds</th>\n",
       "      <th>t_rel_seconds</th>\n",
       "      <th>shank</th>\n",
       "      <th>cluster</th>\n",
       "      <th>aclu</th>\n",
       "      <th>qclu</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>speed</th>\n",
       "      <th>...</th>\n",
       "      <th>lap</th>\n",
       "      <th>maze_relative_lap</th>\n",
       "      <th>maze_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>flat_spike_idx</th>\n",
       "      <th>x_loaded</th>\n",
       "      <th>y_loaded</th>\n",
       "      <th>lin_pos</th>\n",
       "      <th>unit_id</th>\n",
       "      <th>PBE_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12501</th>\n",
       "      <td>724640.0</td>\n",
       "      <td>506939.896978</td>\n",
       "      <td>22.260929</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>228.516743</td>\n",
       "      <td>145.440319</td>\n",
       "      <td>4.527835</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>NeuronType.CONTAMINATED</td>\n",
       "      <td>12501</td>\n",
       "      <td>0.793607</td>\n",
       "      <td>0.499042</td>\n",
       "      <td>-46.102852</td>\n",
       "      <td>54</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12502</th>\n",
       "      <td>724774.0</td>\n",
       "      <td>506939.901095</td>\n",
       "      <td>22.265046</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>228.508952</td>\n",
       "      <td>145.457226</td>\n",
       "      <td>4.527785</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>NeuronType.CONTAMINATED</td>\n",
       "      <td>12502</td>\n",
       "      <td>0.793590</td>\n",
       "      <td>0.499036</td>\n",
       "      <td>-46.095137</td>\n",
       "      <td>38</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12503</th>\n",
       "      <td>724887.0</td>\n",
       "      <td>506939.904566</td>\n",
       "      <td>22.268517</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>228.502387</td>\n",
       "      <td>145.471474</td>\n",
       "      <td>4.527580</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>NeuronType.CONTAMINATED</td>\n",
       "      <td>12503</td>\n",
       "      <td>0.793580</td>\n",
       "      <td>0.499029</td>\n",
       "      <td>-46.088634</td>\n",
       "      <td>54</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12504</th>\n",
       "      <td>725305.0</td>\n",
       "      <td>506939.917407</td>\n",
       "      <td>22.281358</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>228.478172</td>\n",
       "      <td>145.524024</td>\n",
       "      <td>4.524279</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>NeuronType.CONTAMINATED</td>\n",
       "      <td>12504</td>\n",
       "      <td>0.793634</td>\n",
       "      <td>0.498939</td>\n",
       "      <td>-46.064611</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12505</th>\n",
       "      <td>725313.0</td>\n",
       "      <td>506939.917653</td>\n",
       "      <td>22.281604</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>228.477709</td>\n",
       "      <td>145.525029</td>\n",
       "      <td>4.524216</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>NeuronType.CONTAMINATED</td>\n",
       "      <td>12505</td>\n",
       "      <td>0.793635</td>\n",
       "      <td>0.498937</td>\n",
       "      <td>-46.064152</td>\n",
       "      <td>14</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32202</th>\n",
       "      <td>1952611.0</td>\n",
       "      <td>506977.620228</td>\n",
       "      <td>59.984179</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>63.338414</td>\n",
       "      <td>142.357789</td>\n",
       "      <td>6.651623</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NeuronType.CONTAMINATED</td>\n",
       "      <td>32202</td>\n",
       "      <td>0.224061</td>\n",
       "      <td>0.493588</td>\n",
       "      <td>119.046292</td>\n",
       "      <td>54</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32203</th>\n",
       "      <td>1952670.0</td>\n",
       "      <td>506977.622041</td>\n",
       "      <td>59.985992</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>63.345572</td>\n",
       "      <td>142.368181</td>\n",
       "      <td>6.665776</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NeuronType.CONTAMINATED</td>\n",
       "      <td>32203</td>\n",
       "      <td>0.223938</td>\n",
       "      <td>0.493560</td>\n",
       "      <td>119.040813</td>\n",
       "      <td>33</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32204</th>\n",
       "      <td>1952671.0</td>\n",
       "      <td>506977.622071</td>\n",
       "      <td>59.986022</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>63.345693</td>\n",
       "      <td>142.368357</td>\n",
       "      <td>6.666015</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NeuronType.CONTAMINATED</td>\n",
       "      <td>32204</td>\n",
       "      <td>0.223936</td>\n",
       "      <td>0.493560</td>\n",
       "      <td>119.040720</td>\n",
       "      <td>38</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32205</th>\n",
       "      <td>1952761.0</td>\n",
       "      <td>506977.624836</td>\n",
       "      <td>59.988787</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>63.356612</td>\n",
       "      <td>142.384208</td>\n",
       "      <td>6.687603</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NeuronType.CONTAMINATED</td>\n",
       "      <td>32205</td>\n",
       "      <td>0.223748</td>\n",
       "      <td>0.493517</td>\n",
       "      <td>119.032362</td>\n",
       "      <td>58</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32206</th>\n",
       "      <td>1952998.0</td>\n",
       "      <td>506977.632117</td>\n",
       "      <td>59.996068</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>63.385365</td>\n",
       "      <td>142.425949</td>\n",
       "      <td>6.744451</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NeuronType.CONTAMINATED</td>\n",
       "      <td>32206</td>\n",
       "      <td>0.223255</td>\n",
       "      <td>0.493406</td>\n",
       "      <td>119.010353</td>\n",
       "      <td>11</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19706 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               t      t_seconds  t_rel_seconds  shank  cluster  aclu  qclu  \\\n",
       "12501   724640.0  506939.896978      22.260929      9        3    56     5   \n",
       "12502   724774.0  506939.901095      22.265046      7        4    40     5   \n",
       "12503   724887.0  506939.904566      22.268517      9        3    56     5   \n",
       "12504   725305.0  506939.917407      22.281358      1        9     6     5   \n",
       "12505   725313.0  506939.917653      22.281604      2        8    16     5   \n",
       "...          ...            ...            ...    ...      ...   ...   ...   \n",
       "32202  1952611.0  506977.620228      59.984179      9        3    56     5   \n",
       "32203  1952670.0  506977.622041      59.985992      4        4    35     5   \n",
       "32204  1952671.0  506977.622071      59.986022      7        4    40     5   \n",
       "32205  1952761.0  506977.624836      59.988787     11        6    60     5   \n",
       "32206  1952998.0  506977.632117      59.996068      2        4    13     5   \n",
       "\n",
       "                x           y     speed  ...  lap  maze_relative_lap  maze_id  \\\n",
       "12501  228.516743  145.440319  4.527835  ...   -1                 -1        1   \n",
       "12502  228.508952  145.457226  4.527785  ...   -1                 -1        1   \n",
       "12503  228.502387  145.471474  4.527580  ...   -1                 -1        1   \n",
       "12504  228.478172  145.524024  4.524279  ...   -1                 -1        1   \n",
       "12505  228.477709  145.525029  4.524216  ...   -1                 -1        1   \n",
       "...           ...         ...       ...  ...  ...                ...      ...   \n",
       "32202   63.338414  142.357789  6.651623  ...    2                  2        1   \n",
       "32203   63.345572  142.368181  6.665776  ...    2                  2        1   \n",
       "32204   63.345693  142.368357  6.666015  ...    2                  2        1   \n",
       "32205   63.356612  142.384208  6.687603  ...    2                  2        1   \n",
       "32206   63.385365  142.425949  6.744451  ...    2                  2        1   \n",
       "\n",
       "                     cell_type flat_spike_idx  x_loaded  y_loaded     lin_pos  \\\n",
       "12501  NeuronType.CONTAMINATED          12501  0.793607  0.499042  -46.102852   \n",
       "12502  NeuronType.CONTAMINATED          12502  0.793590  0.499036  -46.095137   \n",
       "12503  NeuronType.CONTAMINATED          12503  0.793580  0.499029  -46.088634   \n",
       "12504  NeuronType.CONTAMINATED          12504  0.793634  0.498939  -46.064611   \n",
       "12505  NeuronType.CONTAMINATED          12505  0.793635  0.498937  -46.064152   \n",
       "...                        ...            ...       ...       ...         ...   \n",
       "32202  NeuronType.CONTAMINATED          32202  0.224061  0.493588  119.046292   \n",
       "32203  NeuronType.CONTAMINATED          32203  0.223938  0.493560  119.040813   \n",
       "32204  NeuronType.CONTAMINATED          32204  0.223936  0.493560  119.040720   \n",
       "32205  NeuronType.CONTAMINATED          32205  0.223748  0.493517  119.032362   \n",
       "32206  NeuronType.CONTAMINATED          32206  0.223255  0.493406  119.010353   \n",
       "\n",
       "       unit_id  PBE_id  \n",
       "12501       54      -1  \n",
       "12502       38      -1  \n",
       "12503       54      -1  \n",
       "12504        4      -1  \n",
       "12505       14      -1  \n",
       "...        ...     ...  \n",
       "32202       54      -1  \n",
       "32203       33      -1  \n",
       "32204       38      -1  \n",
       "32205       58      -1  \n",
       "32206       11      -1  \n",
       "\n",
       "[19706 rows x 21 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 3D Spike Train Visualization\n",
    "import pyqtgraph.opengl as gl # for 3D raster plot\n",
    "from numpy import interp\n",
    "from pyphocorehelpers.indexing_helpers import interleave_elements\n",
    "\n",
    "curr_epoch_name = 'maze1'\n",
    "curr_epoch = curr_active_pipeline.filtered_epochs[curr_epoch_name] # <NamedTimerange: {'name': 'maze1', 'start_end_times': array([  22.26      , 1739.15336412])};>\n",
    "curr_sess = curr_active_pipeline.filtered_sessions[curr_epoch_name]\n",
    "curr_spikes_df = curr_sess.spikes_df\n",
    "\n",
    "\n",
    "# test windowing:\n",
    "render_window_duration = 60.0\n",
    "curr_time_windowed_spikes_df = curr_spikes_df[curr_spikes_df[curr_spikes_df.spikes.time_variable_name].between(0, render_window_duration)]\n",
    "curr_time_windowed_spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3bc8dd5e-cb98-497d-b069-6bdc8bf4fd8c",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plot_3d_raster_plot(...): unit_ids: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63], n: 64\n",
      "cell_id: 0, curr_color: 128\n",
      "cell_id: 1, curr_color: 128\n",
      "cell_id: 2, curr_color: 128\n",
      "cell_id: 3, curr_color: 128\n",
      "cell_id: 4, curr_color: 128\n",
      "cell_id: 5, curr_color: 128\n",
      "cell_id: 6, curr_color: 128\n",
      "cell_id: 7, curr_color: 128\n",
      "cell_id: 8, curr_color: 128\n",
      "cell_id: 9, curr_color: 128\n",
      "cell_id: 10, curr_color: 128\n",
      "cell_id: 11, curr_color: 128\n",
      "cell_id: 12, curr_color: 128\n",
      "cell_id: 13, curr_color: 128\n",
      "cell_id: 14, curr_color: 128\n",
      "cell_id: 15, curr_color: 128\n",
      "cell_id: 16, curr_color: 128\n",
      "cell_id: 17, curr_color: 128\n",
      "cell_id: 18, curr_color: 128\n",
      "cell_id: 19, curr_color: 128\n",
      "cell_id: 20, curr_color: 128\n",
      "cell_id: 21, curr_color: 128\n",
      "cell_id: 22, curr_color: 128\n",
      "cell_id: 23, curr_color: 128\n",
      "cell_id: 24, curr_color: 128\n",
      "cell_id: 25, curr_color: 128\n",
      "cell_id: 26, curr_color: 128\n",
      "cell_id: 27, curr_color: 128\n",
      "cell_id: 28, curr_color: 128\n",
      "cell_id: 29, curr_color: 128\n",
      "cell_id: 30, curr_color: 128\n",
      "cell_id: 31, curr_color: 128\n",
      "cell_id: 32, curr_color: 128\n",
      "cell_id: 33, curr_color: 128\n",
      "cell_id: 34, curr_color: 128\n",
      "cell_id: 35, curr_color: 128\n",
      "cell_id: 36, curr_color: 128\n",
      "cell_id: 37, curr_color: 128\n",
      "cell_id: 38, curr_color: 128\n",
      "cell_id: 39, curr_color: 128\n",
      "cell_id: 40, curr_color: 128\n",
      "cell_id: 41, curr_color: 128\n",
      "cell_id: 42, curr_color: 128\n",
      "cell_id: 43, curr_color: 128\n",
      "cell_id: 44, curr_color: 128\n",
      "cell_id: 45, curr_color: 128\n",
      "cell_id: 46, curr_color: 128\n",
      "cell_id: 47, curr_color: 128\n",
      "cell_id: 48, curr_color: 128\n",
      "cell_id: 49, curr_color: 128\n",
      "cell_id: 50, curr_color: 128\n",
      "cell_id: 51, curr_color: 128\n",
      "cell_id: 52, curr_color: 128\n",
      "cell_id: 53, curr_color: 128\n",
      "cell_id: 54, curr_color: 128\n",
      "cell_id: 55, curr_color: 128\n",
      "cell_id: 56, curr_color: 128\n",
      "cell_id: 57, curr_color: 128\n",
      "cell_id: 58, curr_color: 128\n",
      "cell_id: 59, curr_color: 128\n",
      "cell_id: 60, curr_color: 128\n",
      "cell_id: 61, curr_color: 128\n",
      "cell_id: 62, curr_color: 128\n",
      "cell_id: 63, curr_color: 128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<pyqtgraph.opengl.GLViewWidget.GLViewWidget at 0x2cea2216700>,\n",
       " <PyQt5.QtWidgets.QApplication at 0x2cdd3f88af0>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Used to figure out the transform we want:\n",
    "# curr_unit_ids = np.unique(curr_spikes_df['unit_id']) # this will map to the y position\n",
    "# normalized_unit_ids = curr_unit_ids / np.max(curr_unit_ids)\n",
    "# upper_unit_bounds = (np.unique(normalized_unit_ids)*0.9) + 0.05 # 0.05 to 0.95\n",
    "# lower_unit_bounds = upper_unit_bounds - 0.05 # 0.00 to 0.90\n",
    "\n",
    "# print(f'curr_unit_ids: {curr_unit_ids}')\n",
    "# normalized_unit_ids\n",
    "# lower_unit_bounds\n",
    "# upper_unit_bounds\n",
    "# plot_raster_plot(\n",
    "\n",
    "\n",
    "# def _test_display_pyqtgraph_raster_plot(curr_spikes_df):    \n",
    "#     curr_unit_id = curr_spikes_df['unit_id'].to_numpy() # this will map to the y position\n",
    "#     curr_spike_t = curr_spikes_df[curr_spikes_df.spikes.time_variable_name].to_numpy() # this will map to the depth dimension in 3D or x-pos in 2D\n",
    "\n",
    "#     print(f'_test_display_pyqtgraph_raster_plot(np.shape(curr_unit_id): {np.shape(curr_unit_id)}, np.shape(curr_spike_t): {np.shape(curr_spike_t)})')\n",
    "#     # print(f'\\t curr_unit_id: {curr_unit_id}\\n curr_spike_t: {curr_spike_t}')\n",
    "    \n",
    "#     # For the unit Ids, perform a transformation:\n",
    "#     normalized_unit_ids = curr_unit_id / np.max(curr_unit_id)\n",
    "#     upper_unit_bounds = (normalized_unit_ids*0.9) + 0.05 # 0.05 to 0.95\n",
    "#     lower_unit_bounds = upper_unit_bounds - 0.05 # 0.00 to 0.90\n",
    "\n",
    "#     # curr_unit_id_repeats = curr_unit_id.copy()\n",
    "#     curr_spike_t_repeats = curr_spike_t.copy()\n",
    "\n",
    "#     curr_spike_t_repeats = np.atleast_2d(curr_spike_t.copy())\n",
    "    \n",
    "#     lower_unit_bounds = np.atleast_2d(lower_unit_bounds)\n",
    "#     upper_unit_bounds = np.atleast_2d(upper_unit_bounds)\n",
    "#     print(f'np.atleast_2d(lower_unit_bounds): {np.shape(np.atleast_2d(lower_unit_bounds))}') # (1, 819170)\n",
    "#     # end_points = np.atleast_2d(end_points)\n",
    "    \n",
    "#     # the paired arrays should be twice as long as the original arrays and are to be used with the connected='pair' argument\n",
    "#     # curr_paired_unit_id = interleave_elements(curr_unit_id, curr_unit_id_repeats)\n",
    "#     curr_paired_unit_id = np.squeeze(interleave_elements(lower_unit_bounds.T, upper_unit_bounds.T)) # use the computed ranges instead\n",
    "#     curr_paired_spike_t = np.squeeze(interleave_elements(curr_spike_t_repeats.T, curr_spike_t_repeats.T))\n",
    "    \n",
    "#     print(f'curr_paired_unit_id: {np.shape(curr_paired_unit_id)}, curr_paired_spike_t: {np.shape(curr_paired_spike_t)}')\n",
    "#     # out_q_path = pg.arrayToQPath(curr_paired_spike_t, curr_paired_unit_id, connect='pairs', finiteCheck=True) # connect='pairs' details how to connect points in the path\n",
    "    \n",
    "#     return plot_raster_plot(x=curr_paired_spike_t, y=curr_paired_unit_id)    \n",
    "    \n",
    "\n",
    "# _display_pyqtgraph_raster_plot(curr_spikes_df)\n",
    "\n",
    "# _test_display_pyqtgraph_raster_plot(curr_spikes_df)\n",
    "\n",
    "\n",
    "# def _test_display_pyqtgraph_3D_raster_plot(curr_spikes_df):    \n",
    "#     curr_unit_id = curr_spikes_df['unit_id'].to_numpy() # this will map to the y position\n",
    "#     curr_spike_t = curr_spikes_df[curr_spikes_df.spikes.time_variable_name].to_numpy() # this will map to the depth dimension in 3D or x-pos in 2D\n",
    "#     print(f'_test_display_pyqtgraph_3D_raster_plot(np.shape(curr_unit_id): {np.shape(curr_unit_id)}, np.shape(curr_spike_t): {np.shape(curr_spike_t)})')\n",
    "#     # print(f'\\t curr_unit_id: {curr_unit_id}\\n curr_spike_t: {curr_spike_t}')\n",
    "    \n",
    "#     unit_ids = np.unique(curr_unit_id)\n",
    "#     for cell_id in unit_ids:\n",
    "#         # Filter the dataframe using that column and value from the list\n",
    "#         df[df['unit_id']==cell_id].to_csv()\n",
    "    \n",
    "    \n",
    "#     # For the unit Ids, perform a transformation:\n",
    "#     normalized_unit_ids = curr_unit_id / np.max(curr_unit_id)\n",
    "#     upper_unit_bounds = (normalized_unit_ids*0.9) + 0.05 # 0.05 to 0.95\n",
    "#     lower_unit_bounds = upper_unit_bounds - 0.05 # 0.00 to 0.90\n",
    "\n",
    "#     # curr_unit_id_repeats = curr_unit_id.copy()\n",
    "#     curr_spike_t_repeats = curr_spike_t.copy()\n",
    "\n",
    "#     curr_spike_t_repeats = np.atleast_2d(curr_spike_t.copy())\n",
    "    \n",
    "#     lower_unit_bounds = np.atleast_2d(lower_unit_bounds)\n",
    "#     upper_unit_bounds = np.atleast_2d(upper_unit_bounds)\n",
    "#     print(f'np.atleast_2d(lower_unit_bounds): {np.shape(np.atleast_2d(lower_unit_bounds))}') # (1, 819170)\n",
    "#     # end_points = np.atleast_2d(end_points)\n",
    "    \n",
    "#     # the paired arrays should be twice as long as the original arrays and are to be used with the connected='pair' argument\n",
    "#     # curr_paired_unit_id = interleave_elements(curr_unit_id, curr_unit_id_repeats)\n",
    "#     curr_paired_unit_id = np.squeeze(interleave_elements(lower_unit_bounds.T, upper_unit_bounds.T)) # use the computed ranges instead\n",
    "#     curr_paired_spike_t = np.squeeze(interleave_elements(curr_spike_t_repeats.T, curr_spike_t_repeats.T))\n",
    "    \n",
    "#     print(f'curr_paired_unit_id: {np.shape(curr_paired_unit_id)}, curr_paired_spike_t: {np.shape(curr_paired_spike_t)}')\n",
    "#     # out_q_path = pg.arrayToQPath(curr_paired_spike_t, curr_paired_unit_id, connect='pairs', finiteCheck=True) # connect='pairs' details how to connect points in the path\n",
    "    \n",
    "#     return plot_3d_raster_plot(x=curr_paired_spike_t, y=curr_paired_unit_id)    \n",
    "    \n",
    "    \n",
    "# _test_display_pyqtgraph_3D_raster_plot(curr_spikes_df)\n",
    "# def _test_plot_3d_raster_plot(curr_spikes_df):\n",
    "# # def plot_3d_raster_plot(x=np.linspace(-10,10,100), y=np.random.normal(size=100), z=None):\n",
    "#     # curr_unit_id = curr_spikes_df['unit_id'].to_numpy() # this will map to the y position\n",
    "#     # curr_spike_t = curr_spikes_df[curr_spikes_df.spikes.time_variable_name].to_numpy() # this will map to the depth dimension in 3D or x-pos in 2D\n",
    "#     unit_ids = np.unique(curr_spikes_df['unit_id'].to_numpy())\n",
    "#     n = len(unit_ids)\n",
    "#     render_window_duration = 60.0 # in seconds, 1minute by default\n",
    "#     spike_start_z = -10.0\n",
    "#     spike_end_z = 0.1\n",
    "    \n",
    "#     n_half_cells = np.ceil(float(n)/2.0)\n",
    "#     n_full_cell_grid = 2.0 * n_half_cells # could be one more than n\n",
    "#     half_render_window_duration = np.ceil(float(render_window_duration)/2.0) # 10 by default\n",
    "    \n",
    "    \n",
    "    \n",
    "#     print(f'_test_plot_3d_raster_plot(...): unit_ids: {unit_ids}, n: {n}')\n",
    "#     # print(f'plot_3d_raster_plot(np.shape(x): {np.shape(x)}, np.shape(y): {np.shape(y)})')\n",
    "#     # print(f'\\t x: {x}\\n y: {y}')\n",
    "    \n",
    "#     app = pg.mkQApp(\"Pyqtgraph 3D Raster Plot\")\n",
    "#     #mw = QtGui.QMainWindow()\n",
    "#     #mw.resize(800,800)\n",
    "#     w = gl.GLViewWidget()\n",
    "#     w.show()\n",
    "#     w.resize(1000,600)\n",
    "#     w.setWindowTitle('pyqtgraph: 3D Raster Spikes Plotting')\n",
    "#     w.setCameraPosition(distance=40)\n",
    "    \n",
    "    \n",
    "#     # Add axes planes:\n",
    "    \n",
    "#     # X-plane:\n",
    "#     gx = gl.GLGridItem(color=(255, 155, 155, 76.5))\n",
    "#     gx.rotate(90, 0, 1, 0)\n",
    "#     gx.translate(-half_render_window_duration, 0, 0) # shift backwards\n",
    "#     gx.setSize(20, n_full_cell_grid) # std size in z-dir, n_cell size across\n",
    "#     gx.setSpacing(10.0, 1) \n",
    "#     w.addItem(gx)\n",
    "    \n",
    "#     # Y-plane:\n",
    "#     gy = gl.GLGridItem(color=(155, 255, 155, 76.5))\n",
    "#     gy.rotate(90, 1, 0, 0)\n",
    "#     # gy.translate(0, -10, 0)\n",
    "#     gy.translate(0, -n_half_cells, 0) # offset by half the number of units in the -y direction\n",
    "#     gy.setSize(render_window_duration, 20)\n",
    "#     # gy.setSpacing(1, 1)\n",
    "#     w.addItem(gy)\n",
    "    \n",
    "#     # XY-plane (with normal in z-dir):\n",
    "#     gz = gl.GLGridItem(color=(155, 155, 255, 76.5))\n",
    "#     gz.translate(0, 0, -10) # Shift down by 10 units in the z-dir\n",
    "#     gz.setSize(render_window_duration, n_full_cell_grid)\n",
    "#     gz.setSpacing(20.0, 1)\n",
    "#     # gz.setSize(n_full_cell_grid, n_full_cell_grid)\n",
    "#     w.addItem(gz)\n",
    "\n",
    "    \n",
    "#     pos = np.empty((53, 3))\n",
    "#     size = np.empty((53))\n",
    "#     color = np.empty((53, 4))\n",
    "#     pos[0] = (1,0,0); size[0] = 0.5;   color[0] = (1.0, 0.0, 0.0, 0.5)\n",
    "\n",
    "\n",
    "#     # Custom 3D raster plot:\n",
    "#     # y = np.linspace(-10,10,n) # the line location I think\n",
    "#     # # x = np.linspace(-10,10,100) # the temporal location, size 100 by default\n",
    "#     # x = np.linspace(-10, 25, 100) # the temporal location, size 100 by default\n",
    "#     # # x = np.linspace(0.0, render_window_duration, 100) # the temporal location, size 100 by default\n",
    "    \n",
    "#     # New attempt\n",
    "#     y = np.linspace(-n_half_cells, n_half_cells, n) + 0.5 # add 0.5 so they're centered\n",
    "#     # x = np.linspace(-half_render_window_duration, half_render_window_duration, 100)\n",
    "    \n",
    "#     # Filter based on the current spikes window to show:\n",
    "    \n",
    "#     curr_render_window_start_time = 0.0\n",
    "#     curr_render_window_end_time = curr_render_window_start_time + render_window_duration\n",
    "#     curr_time_windowed_spikes_df = curr_spikes_df[curr_spikes_df[curr_spikes_df.spikes.time_variable_name].between(curr_render_window_start_time, curr_render_window_end_time)]\n",
    "    \n",
    "    \n",
    "#     # np.interp(a, (a.min(), a.max()), (-1, +1))\n",
    "    \n",
    "#     for cell_id in unit_ids:\n",
    "#         # Filter the dataframe using that column and value from the list\n",
    "#         curr_cell_df = curr_time_windowed_spikes_df[curr_time_windowed_spikes_df['unit_id']==cell_id].copy()\n",
    "#         curr_unit_id = curr_cell_df['unit_id'].to_numpy() # this will map to the y position\n",
    "#         curr_spike_t = curr_cell_df[curr_cell_df.spikes.time_variable_name].to_numpy() # this will map \n",
    "#         yi = y[cell_id] # get the correct y-position for all spikes of this cell\n",
    "#         print(f'cell_id: {cell_id}, yi: {yi}')\n",
    "#         # map the current spike times back onto the range of the window's (-half_render_window_duration, +half_render_window_duration) so they represent the x coordinate\n",
    "#         curr_x = np.interp(curr_spike_t, (curr_render_window_start_time, curr_render_window_end_time), (-half_render_window_duration, +half_render_window_duration))\n",
    "#         curr_paired_x = np.squeeze(interleave_elements(np.atleast_2d(curr_x).T, np.atleast_2d(curr_x).T))        \n",
    "        \n",
    "#         # Z-positions:\n",
    "#         # z = curr_spike_t[np.arange(100)] # get the first 20 spikes for each\n",
    "#         spike_bottom_zs = np.full_like(curr_x, spike_start_z)\n",
    "#         spike_top_zs = np.full_like(curr_x, spike_end_z)\n",
    "#         curr_paired_spike_zs = np.squeeze(interleave_elements(np.atleast_2d(spike_bottom_zs).T, np.atleast_2d(spike_top_zs).T)) # alternating top and bottom z-positions\n",
    "     \n",
    "#         # sp1 = gl.GLScatterPlotItem(pos=pos, size=size, color=color, pxMode=False)\n",
    "#         # sp1.translate(5,5,0)\n",
    "#         # w.addItem(sp1)\n",
    "        \n",
    "#         # Build lines:\n",
    "#         pts = np.column_stack([curr_paired_x, np.full_like(curr_paired_x, yi), curr_paired_spike_zs]) # the middle coordinate is the size of the x array with the value given by yi. yi must be the scalar for this cell.\n",
    "#         # pts = np.column_stack([x, np.full_like(x, yi), z]) # the middle coordinate is the size of the x array with the value given by yi. yi must be the scalar for this cell.\n",
    "#         # plt = gl.GLLinePlotItem(pos=pts, color=pg.mkColor((cell_id,n*1.3)), width=(cell_id+1)/10., antialias=True)\n",
    "#         plt = gl.GLLinePlotItem(pos=pts, color=pg.mkColor((cell_id, n*1.3)), width=1.0, antialias=True, mode='lines') # mode='lines' means that each pair of vertexes draws a single line segement\n",
    "#         w.addItem(plt)\n",
    "\n",
    "#         # # Adds a helper widget that displays the x/y/z vector at the origin:\n",
    "#         # ref_axes_indicator = gl.GLAxisItem()\n",
    "#         # ref_axes_indicator.setSize(x=10.0, y=10.0, z=5.0)\n",
    "#         # w.addItem(ref_axes_indicator)\n",
    "    \n",
    "#     # # Example 3D wave plot made of lines:\n",
    "#     # n = 51\n",
    "#     # y = np.linspace(-10,10,n) # the line location I think\n",
    "#     # x = np.linspace(-10,10,100) # the temporal location\n",
    "#     # for i in range(n):\n",
    "#     #     yi = y[i]\n",
    "#     #     if z is None:\n",
    "#     #         d = np.hypot(x, yi)\n",
    "#     #         z = 10 * np.cos(d) / (d+1)\n",
    "#     #     pts = np.column_stack([x, np.full_like(x, yi), z])\n",
    "#     #     plt = gl.GLLinePlotItem(pos=pts, color=pg.mkColor((i,n*1.3)), width=(i+1)/10., antialias=True)\n",
    "#     #     w.addItem(plt)\n",
    "\n",
    "#     return w, app\n",
    "\n",
    "\n",
    "plot_3d_raster_plot(curr_spikes_df)\n",
    "# _test_plot_3d_raster_plot(curr_spikes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2ccfbc",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_computation_function_names\n",
    "# ['_perform_placefield_overlap_computation',\n",
    "#  '_perform_firing_rate_trends_computation',\n",
    "#  '_perform_extended_statistics_computation',\n",
    "#  '_perform_two_step_position_decoding_computation',\n",
    "#  '_perform_position_decoding_computation']\n",
    "\n",
    "\n",
    "curr_active_pipeline.registered_display_function_names\n",
    "# ['_display_1d_placefield_validations',\n",
    "#  '_display_2d_placefield_result_plot_ratemaps_2D',\n",
    "#  '_display_2d_placefield_result_plot_raw',\n",
    "#  '_display_3d_image_plotter',\n",
    "#  '_display_3d_interactive_custom_data_explorer',\n",
    "#  '_display_3d_interactive_spike_and_behavior_browser',\n",
    "#  '_display_3d_interactive_tuning_curves_plotter',\n",
    "#  '_display_normal',\n",
    "#  '_display_placemaps_pyqtplot_2D',\n",
    "#  '_display_decoder_result',\n",
    "#  '_display_plot_most_likely_position_comparisons',\n",
    "#  '_display_two_step_decoder_prediction_error_2D',\n",
    "#  '_display_two_step_decoder_prediction_error_animated_2D']\n",
    "\n",
    "\n",
    "# all_fcn_tuples[0]\n",
    "# [a_name for (a_name, a_fn) in all_fcn_tuples]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cbbfa0",
   "metadata": {},
   "source": [
    "# Common: Display\n",
    "Common visualization and display functions for both forms of data/pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28864994-db95-4b51-8c68-092828a42ce9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "list(curr_active_pipeline.computation_results.keys()) # ['maze1', 'maze2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4917da1-a0b3-4b77-a34e-73f87c41a1ef",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "active_config_name = 'maze1'\n",
    "# active_config_name = 'maze'\n",
    "\n",
    "# Get relevant variables:\n",
    "# curr_active_pipeline is set above, and usable here\n",
    "sess: DataSession = curr_active_pipeline.filtered_sessions[active_config_name]\n",
    "pf = curr_active_pipeline.computation_results[active_config_name].computed_data['pf1D']\n",
    "active_one_step_decoder = curr_active_pipeline.computation_results[active_config_name].computed_data['pf2D_Decoder']\n",
    "active_two_step_decoder = curr_active_pipeline.computation_results[active_config_name].computed_data.get('pf2D_TwoStepDecoder', None)\n",
    "active_measured_positions = curr_active_pipeline.computation_results[active_config_name].sess.position.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd23e683-c624-4726-8d09-bdd92331e0bf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Compare curr_active_pipeline.filtered_sessions[active_config_name] and \n",
    "# from pyphoplacecellanalysis.GUI.PyQtPlot.pyqtplot_DataTreeWidget import plot_dataTreeWidget\n",
    "#\n",
    "# print(f'curr_active_pipeline.filtered_sessions[active_config_name]: {curr_active_pipeline.filtered_sessions[active_config_name]}')\n",
    "# print(f'curr_active_pipeline.computation_results[active_config_name].sess: {curr_active_pipeline.computation_results[active_config_name].sess}')\n",
    "#\n",
    "# filtered_sessions_tree, filtered_sessions_app = plot_dataTreeWidget(data={'filtered_sessions[active_config_name]':curr_active_pipeline.filtered_sessions[active_config_name].to_dict()}, title='PhoOutputDataTreeApp - filtered_sessions[active_config_name]')\n",
    "# tree, app = plot_dataTreeWidget(data={'computation_results[active_config_name].sess':curr_active_pipeline.computation_results[active_config_name].sess.to_dict()}, title='PhoOutputDataTreeApp- curr_active_pipeline.computation_results[active_config_name].sess')\n",
    "\n",
    "# pg.exec()\n",
    "\n",
    "# sess.ripple\n",
    "# sess.mua\n",
    "if sess.pbe is None:\n",
    "    sess.pbe = DataSession.compute_pbe_epochs(sess, save_on_compute=False)\n",
    "    \n",
    "sess.pbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2a3b3c-999e-486c-8e48-0e16096a0419",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "if curr_active_pipeline.filtered_sessions['maze2'].pbe is None:\n",
    "    curr_active_pipeline.filtered_sessions['maze2'].pbe = DataSession.compute_pbe_epochs(curr_active_pipeline.filtered_sessions['maze2'], save_on_compute=False)\n",
    "    \n",
    "curr_active_pipeline.filtered_sessions['maze2'].pbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3df1291",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_output = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1535f17-a388-4bd3-aece-bd5e7ca856c9",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pActiveTuningCurvesPlotter = None\n",
    "display_output = curr_active_pipeline.display(DefaultDisplayFunctions._display_3d_interactive_tuning_curves_plotter, active_config_name, extant_plotter=display_output.get('plotter', None)) # Works now!\n",
    "# display_output = curr_active_pipeline.display(DefaultDisplayFunctions._display_3d_interactive_tuning_curves_plotter, active_config_name, extant_plotter=pActiveTuningCurvesPlotter) # Works now!\n",
    "# pActiveTuningCurvesPlotter = display_output['plotter']\n",
    "display_output['pane'] # doesn't seem to work to control the output anymore!\n",
    "# display_output['ipcDataExplorer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b3d24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_output = curr_active_pipeline.display(DefaultDisplayFunctions._display_3d_interactive_tuning_curves_plotter, active_config_name, extant_plotter=display_output.get('pActiveTuningCurvesPlotter', None)) # Works now!\n",
    "\n",
    "pActiveTuningCurvesPlotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40404570",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.display(DefaultDisplayFunctions._display_3d_interactive_spike_and_behavior_browser, active_config_name) # this works now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0073ab-9e27-45e8-b3a0-ff5e34b4cd11",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.display(DefaultDisplayFunctions._display_3d_interactive_custom_data_explorer, active_config_name) # does not work, missing color info?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f6497b-f442-4096-afe0-12ce9b41612b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plots = curr_active_pipeline.display(DefaultDisplayFunctions._display_1d_placefield_validations, active_config_name) # works, but generates a TON of plots!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fab03e-809e-441c-a235-7469147604cb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(plots) # 39\n",
    "type(plots[0]) # matplotlib.figure.Figure\n",
    "\n",
    "fig = plt.figure(constrained_layout=True, figsize=(10, 4))\n",
    "subfigs = fig.subfigures(1, 2, wspace=0.07)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb4c7d3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb39bbd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Here we look at the population burst events for each epoch ('maze1' vs. 'maze2')\n",
    "# curr_active_pipeline.sess.\n",
    "\n",
    "# get only the spikes that occur during PBEs:\n",
    "pbe_only_spikes_df = sess.spikes_df[(sess.spikes_df.PBE_id > -1)]\n",
    "pbe_only_spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37e889d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.pbe #[10960 rows x 4 columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14b1549-6a5f-493f-98f2-3b3f367cc43b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.display(DefaultDecoderDisplayFunctions._display_two_step_decoder_prediction_error_2D, active_config_name, variable_name='p_x_given_n') # works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5d1ff7-73fa-44b3-a351-6ce01510320b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.display(DefaultDecoderDisplayFunctions._display_two_step_decoder_prediction_error_2D, active_config_name, variable_name='p_x_given_n_and_x_prev') # works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c49ccf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.display(DefaultDecoderDisplayFunctions._display_two_step_decoder_prediction_error_animated_2D, active_config_name, variable_name='p_x_given_n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16de2901-e7ea-40fe-8807-d5bfb57b01bd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "app, win, w = curr_active_pipeline.display(DefaultRatemapDisplayFunctions._display_placemaps_pyqtplot_2D, active_config_name)\n",
    "win.show(); pg.exec()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abc004f-a5d9-4979-8cde-f202597ba1ba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "source": [
    "### Old Individual Plotting Functions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5422763d-b961-4dab-810d-8e27b091dffe",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "filter_name = 'maze1'\n",
    "# curr_bapun_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, filter_name, subplots=(20, 8), max_screen_figure_size=(2256, 2048), enable_spike_overlay=False, plot_variable=enumTuningMap2DPlotVariables.FIRING_MAPS, fignum=0) # works!\n",
    "curr_active_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, filter_name, subplots=(20, 8), max_screen_figure_size=(2256, 2048), enable_spike_overlay=False, plot_variable=enumTuningMap2DPlotVariables.TUNING_MAPS, fignum=10) # works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca71727-a5cc-48df-88e7-782bbccdef39",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_name = 'maze2'\n",
    "# curr_bapun_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, filter_name, subplots=(20, 8), max_screen_figure_size=(2256, 2048), enable_spike_overlay=False, plot_variable=enumTuningMap2DPlotVariables.FIRING_MAPS, fignum=0) # works!\n",
    "curr_active_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, filter_name, subplots=(20, 8), max_screen_figure_size=(2256, 2048), enable_spike_overlay=False, plot_variable=enumTuningMap2DPlotVariables.TUNING_MAPS, fignum=11) # works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9c4f39-412d-42e7-9b3d-8417993ee562",
   "metadata": {},
   "outputs": [],
   "source": [
    "_display_result(curr_active_pipeline.computation_results['maze1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62c4907-c242-4908-80dd-0c7d49e89b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "_display_result(curr_active_pipeline.computation_results['maze2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c3eb8a-d963-4d60-ab39-721de81a34fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_name = 'maze1'\n",
    "# curr_kdiba_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, filter_name, enable_spike_overlay=False, plot_variable=enumTuningMap2DPlotVariables.FIRING_MAPS, fignum=0, max_screen_figure_size=(None, 1868), debug_print=False, enable_saving_to_disk=enable_saving_to_disk) # works!\n",
    "curr_active_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, filter_name, enable_spike_overlay=False, plot_variable=enumTuningMap2DPlotVariables.TUNING_MAPS, fignum=1, max_screen_figure_size=(None, 1868), debug_print=False, enable_saving_to_disk=enable_saving_to_disk) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794ad5c3-328d-41a9-b7c2-2bc6f7aaf2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_name = 'maze2'\n",
    "# curr_kdiba_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, filter_name, enable_spike_overlay=False, plot_variable=enumTuningMap2DPlotVariables.FIRING_MAPS, fignum=0, max_screen_figure_size=(None, 1868), debug_print=False, enable_saving_to_disk=enable_saving_to_disk) # works!\n",
    "curr_active_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, filter_name, enable_spike_overlay=False, plot_variable=enumTuningMap2DPlotVariables.TUNING_MAPS, fignum=1, max_screen_figure_size=(None, 1868), debug_print=False, enable_saving_to_disk=enable_saving_to_disk) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c849eb9-e7c4-476d-b17c-d197d2f80983",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_name = 'maze'\n",
    "# curr_kdiba_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, filter_name, enable_spike_overlay=False, plot_variable=enumTuningMap2DPlotVariables.FIRING_MAPS, fignum=0, max_screen_figure_size=(None, 1868), debug_print=False, enable_saving_to_disk=enable_saving_to_disk) # works!\n",
    "curr_active_pipeline.display(DefaultDisplayFunctions._display_2d_placefield_result_plot_ratemaps_2D, filter_name, enable_spike_overlay=False, plot_variable=enumTuningMap2DPlotVariables.TUNING_MAPS, fignum=1, max_screen_figure_size=(None, 1868), debug_print=False, enable_saving_to_disk=enable_saving_to_disk) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701c4ecf-15c2-4197-927f-8f1a63c7ac20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_kdiba_pipeline.display(DefaultDisplayFunctions._display_3d_interactive_custom_data_explorer, 'maze1') # works!\n",
    "curr_active_pipeline.display(DefaultDisplayFunctions._display_3d_interactive_tuning_curves_plotter, 'maze1') # works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd2f3bb-49a9-4053-9fd4-03c8796e7bf2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.display(DefaultDisplayFunctions._display_1d_placefield_validations, 'maze1') # works!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469c4171-ea23-4f0f-bcc0-a7ab3544dfbe",
   "metadata": {},
   "source": [
    "\n",
    "# Testing: Position Decoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b04bc40",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# win.close()\n",
    "app.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37445b3-c614-4b68-b6ab-ee7a26c29af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stock Decoder:\n",
    "from neuropy.analyses.decoders import Decode1d\n",
    "\n",
    "def stock_1d_decoder(sess, pf, curr_result_label):\n",
    "    maze1 = sess.paradigm[curr_result_label]\n",
    "    # rpls = sess.ripple.time_slice(maze1[0], maze1[1])\n",
    "    rpls = None\n",
    "    pf_neurons = sess.neurons.get_by_id(pf.ratemap.neuron_ids)\n",
    "    decode = Decode1d(neurons=pf_neurons, ratemap = pf.ratemap, epochs=rpls, bin_size=0.02)\n",
    "    return decode\n",
    "\n",
    "def validate_stock_1d_decoder(sess, decode):\n",
    "    # Plot to validate decoder:\n",
    "    np.shape(decode.decoded_position) # (85845,)\n",
    "    plt.plot(decode.decoded_position)\n",
    "    ax = plt.gca()\n",
    "    # ax.xlim() # (-4292.2, 90136.2)\n",
    "    ax.set_xlim(10000, 12000)\n",
    "\n",
    "np.shape(decode.posterior) # (48, 85845)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c545afc1-63d6-4f45-a186-5acae5b2dab3",
   "metadata": {
    "tags": []
   },
   "source": [
    "<!-- % $$\\int_{a}^b f(x)dx$$ -->\n",
    "<!-- Euler's identity: $ e^{i \\pi} + 1 = 0 $ -->\n",
    "\n",
    "## One-step Bayesian Decoder:\n",
    "$$P(\\overrightarrow{x}_{t}|\\overrightarrow{n}_{t})$$\n",
    "\n",
    "$$P(\\overrightarrow{n}|\\overrightarrow{x})$$ : probability for the numbers of spikes $\\overrightarrow{n}$ to occur given we know the animal is at location $\\overrightarrow{x}$\n",
    "\n",
    "## Two-step Bayesian Decoder:\n",
    "$$P(\\overrightarrow{x}_{t}|\\overrightarrow{n}_{t}, \\overrightarrow{x}_{t-1}) = k P(\\overrightarrow{x}_{t}|\\overrightarrow{n}_{t}) P(\\overrightarrow{x}_{t-1}|\\overrightarrow{x}_{t})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0b8e04-3f5d-49e9-af1b-786326567330",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# active_two_step_decoder['most_likely_positions'].shape # (2, 1717)\n",
    "\n",
    "active_two_step_decoder['most_likely_position_indicies'].shape # (2, 1717)\n",
    "np.max(active_two_step_decoder['most_likely_position_indicies'], axis=1) # array([0, 1])\n",
    "active_two_step_decoder['most_likely_position_indicies']\n",
    "# active_two_step_decoder['p_x_given_n_and_x_prev'].shape # (59, 21, 1717)\n",
    "\n",
    "# np.nanmax(active_two_step_decoder['p_x_given_n_and_x_prev'], axis=(1, 2)) # (59,)\n",
    "# np.nanmax(active_two_step_decoder['p_x_given_n_and_x_prev'], axis=-1).shape # (59, 21)\n",
    "\n",
    "# np.nanmax(active_two_step_decoder['p_x_given_n_and_x_prev'], axis=-1)\n",
    "# np.max(active_two_step_decoder['most_likely_positions'], axis=1) # array([ 36.30101033, 128.49991842])\n",
    "\n",
    "\n",
    "# np.max(active_one_step_decoder.most_likely_positions, axis=0) # array([244.02731273, 148.3231301 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93be34e2-9062-4e08-bedb-0d7ec4ceca9c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PyQtPlot Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d4e875-52e9-4bf4-b742-db1bfaab77d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.plot_placefields import pyqtplot_plot_image_array, pyqtplot_plot_image\n",
    "\n",
    "# test single image plot:\n",
    "curr_im = np.squeeze(active_one_step_decoder.ratemap.normalized_tuning_curves[0,:,:]) # (43, 63, 63)\n",
    "app, win, imv = pyqtplot_plot_image(active_one_step_decoder.xbin, active_one_step_decoder.ybin, curr_im)\n",
    "win.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1263931-3967-4eff-a766-2be9b275566d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DataTree Widget that displays a nested hierarchy of data:\n",
    "d = {\n",
    "    'active_sess_config':curr_active_pipeline.active_sess_config.__dict__,\n",
    "    'active_configs':curr_active_pipeline.active_configs,\n",
    "    'active_session_computation_configs':active_session_computation_configs[0].__dict__\n",
    "}\n",
    "# d = {\n",
    "#     'active_two_step_decoder': active_two_step_decoder,\n",
    "#     'active_extended_stats': active_extended_stats\n",
    "# }\n",
    "# d = {\n",
    "#     'active_session_computation_configs':active_session_computation_configs,\n",
    "#     'active_two_step_decoder': active_two_step_decoder,\n",
    "#     'active_extended_stats': active_extended_stats\n",
    "# }\n",
    "\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.pyqtplot_DataTreeWidget import plot_dataTreeWidget\n",
    "tree, app = plot_dataTreeWidget(data=d, title='PhoOutputDataTreeApp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6943e136",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Params.pyqtplot_ParamTreeWidget import plot_paramTreeWidget\n",
    "param_tree, param_tree_app = plot_paramTreeWidget(title='PhoMainParamTreeApp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827ddf63",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Flowchart.pyqtplot_Flowchart import plot_flowchartWidget\n",
    "pipeline_flowchart_window, pipeline_flowchart_app = plot_flowchartWidget(title='PhoMainPipelineFlowchartApp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f8f405-a15b-4e58-a281-c56fc6cb9c93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pg.mkQApp()\n",
    "# Create ScatterPlotWidget and configure its fields\n",
    "spw = pg.ScatterPlotWidget()\n",
    "# spw.setFields([\n",
    "    # ('x_pos', {'units': 'm'}),\n",
    "#     ('y_pos', {'units': 'm'}),\n",
    "#     ('count', {}),\n",
    "#     ('amplitude', {'units': 'V'}),\n",
    "#     ('decay', {'units': 's'}),    \n",
    "#     ('type', {'mode': 'enum', 'values': strings}),\n",
    "#     ])\n",
    "\n",
    "spw.setFields([\n",
    "    ('x', {'units': 'm'}),\n",
    "    ('y', {'units': 'm'}),\n",
    "    ('lin_pos', {'units': 'm'}),\n",
    "    ('speed', {'units': 'm/s'}),\n",
    "    ('binned_x', {}),\n",
    "    ('binned_y', {}),\n",
    "    # ('type', {'mode': 'enum', 'values': strings}),\n",
    "])\n",
    "    \n",
    "spw.setData(time_binned_pos_df)\n",
    "spw.show()\n",
    "\n",
    "\n",
    "# ## Multiple Line Plots:\n",
    "# plotWidget = pg.plot(title='PhoTest PyQtPlot Widget')\n",
    "# for i in range(3):\n",
    "#     plotWidget.plot(x, y[i], pen=(i,3))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6710ea4d-d80b-4e39-ba21-a3f9a3466ee2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Check Placefield Normalizations:\n",
    "Conclusion: neither the normalized_tuning_curves nor tuning_curves are normalized in any way! They give different firing rates across time.\n",
    "NOTE: For the pyramidal-only and lap-epoch filtered Diba data, the np.nanmax of normalized_tuning_curves actually does appear to be scaled to a maximum of 1.0 across all units, meaning only the relative difference between units in firing rate is preserved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0938f2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad417c9-8b38-4a08-a8f1-6ca254064f55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.sum(active_one_step_decoder.pf.ratemap.normalized_tuning_curves, axis=(1,2)) # ERROR: the normalized_tuning_curves are NOT normalized in any way!\n",
    "np.nanmax(active_one_step_decoder.pf.ratemap.normalized_tuning_curves, axis=(1,2)) # Not even by having their maximum value scaled to one!\n",
    "\n",
    "# np.sum(active_one_step_decoder.pf.ratemap.tuning_curves, axis=(1,2))\n",
    "# np.nanmax(active_one_step_decoder.pf.ratemap.tuning_curves, axis=(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb1fd1f-9bff-42b3-a3c5-5dfbd56ede80",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Placefield Firing Rate Tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18873548-010d-44fd-808f-f6c5dabdd545",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# debug_dump_object_member_shapes(active_one_step_decoder)\n",
    "# computation_result.computed_data['pf2D_Decoder']\n",
    "# active_one_step_decoder.time_window_edges\n",
    "\n",
    "def _display_firing_rate_trends(cell_firing_rate_samples):    \n",
    "    # Incoming data is (C,N): where C is the number of cells and N is the number of datapoints.\n",
    "    num_cells = np.shape(cell_firing_rate_samples)[0]\n",
    "    num_samples = np.shape(cell_firing_rate_samples)[1]\n",
    "    assert (num_samples >= num_cells), f'num_samples should be greater than num_cells, but num_samples: {num_samples} and num_cells: {num_cells}! You probably meant the transpose of the data you passed in.'\n",
    "    \n",
    "    win = pg.plot()\n",
    "    win.setWindowTitle('pyqtgraph beeswarm: Firing Rate Trends')\n",
    "\n",
    "    print(f'np.shape(cell_firing_rate_samples): {np.shape(cell_firing_rate_samples)}, num_cells: {num_cells}, num_samples: {num_samples}')\n",
    "    # data = np.random.normal(size=(4,20))\n",
    "    # data[0] += 5\n",
    "    # data[1] += 7\n",
    "    # data[2] += 5\n",
    "    # data[3] = 10 + data[3] * 2\n",
    "\n",
    "    ## Make bar graph\n",
    "    #bar = pg.BarGraphItem(x=range(4), height=data.mean(axis=1), width=0.5, brush=0.4)\n",
    "    #win.addItem(bar)\n",
    "\n",
    "    ## add scatter plots on top\n",
    "    for i in np.arange(num_cells):\n",
    "        curr_cell_samples = cell_firing_rate_samples.loc[i,:].to_numpy()\n",
    "        print(f'i: {i} - np.shape(curr_cell_samples): {np.shape(curr_cell_samples)}')\n",
    "        xvals = pg.pseudoScatter(curr_cell_samples, spacing=0.4, bidir=True) * 0.2\n",
    "        win.plot(x=xvals+i, y=curr_cell_samples, pen=None, symbol='o', symbolBrush=pg.intColor(i,6,maxValue=128))\n",
    "\n",
    "    ## Make error bars\n",
    "    err = pg.ErrorBarItem(x=np.arange(num_cells), y=cell_firing_rate_samples.mean(axis=1), height=cell_firing_rate_samples.std(axis=1), beam=0.5, pen={'color':'w', 'width':2})\n",
    "    win.addItem(err)\n",
    "    return err, win\n",
    "\n",
    "\n",
    "# active_one_step_decoder.time_window_center_binning_info\n",
    "# position_time_delta = pd.to_timedelta(active_pos_df[active_pos_df.position.time_variable_name], unit=\"sec\")\n",
    "# active_pos_df['time_delta_sec'] = position_time_delta\n",
    "# active_pos_df = active_pos_df.set_index('time_delta_sec')\n",
    "# window_resampled_pos_df = active_pos_df.resample(f'{time_bin_size}S', base=0)#.nearest() # '0.02S' 0.02 second bins\n",
    "\n",
    "# np.shape(active_one_step_decoder.active_time_windows) # (2892, 2)\n",
    "\n",
    "active_firing_rate_trends = curr_active_pipeline.computation_results[active_config_name].computed_data['firing_rate_trends']\n",
    "\n",
    "active_rolling_window_times = active_firing_rate_trends['active_rolling_window_times']\n",
    "mean_firing_rates = active_firing_rate_trends['mean_firing_rates']\n",
    "moving_mean_firing_rates_df = active_firing_rate_trends['moving_mean_firing_rates_df']\n",
    "moving_mean_firing_rates_df # 3969 rows x 43 columns\n",
    "\n",
    "# mean_firing_rates\n",
    "# pg.plot(mean_firing_rates)\n",
    "\n",
    "np.shape(moving_mean_firing_rates_df) # (3969, 43)\n",
    "good_only_moving_mean_firing_rates_df = moving_mean_firing_rates_df.dropna() # 3910 rows x 43 columns\n",
    "good_only_moving_mean_firing_rates_df.T\n",
    "err, win = _display_firing_rate_trends(good_only_moving_mean_firing_rates_df.T)\n",
    "win.show()\n",
    "\n",
    "# active_rolling_window_times # dtype='timedelta64[ns]', name='time_delta_sec', length=2900, freq='S'\n",
    "# pg.plot(moving_mean_firing_rates_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94ac6af-9c53-4d2d-9b3e-32a939acb346",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Placefield Overlap Detection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b9150b-f478-4a56-b645-73eaa9c9def0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test Placefield Overlap Detection:\n",
    "def compute_placefield_overlap(pf):\n",
    "    return np.squeeze(np.prod(pf, axis=0))\n",
    "\n",
    "\n",
    "active_pf_overlap_results = curr_active_pipeline.computation_results[active_config_name].computed_data['placefield_overlap']\n",
    "all_pairwise_neuron_IDs_combinations = active_pf_overlap_results['all_pairwise_neuron_IDs_combinations']\n",
    "total_pairwise_overlaps = active_pf_overlap_results['total_pairwise_overlaps']\n",
    "all_pairwise_overlaps = active_pf_overlap_results['all_pairwise_overlaps']\n",
    "\n",
    "active_placefield_overlap\n",
    "total_pairwise_overlaps\n",
    "all_pairwise_overlaps\n",
    "\n",
    "\n",
    "# top_pairwise_overlaps = all_pairwise_overlaps[0:9,:,:]\n",
    "\n",
    "top_pairwise_overlaps = np.squeeze(all_pairwise_overlaps[2,:,:])\n",
    "\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.pyqtplot_Matrix import MatrixRenderingWindow\n",
    "print(f'np.shape(top_pairwise_overlaps): {np.shape(top_pairwise_overlaps)}')\n",
    "pg.mkQApp(\"Correlation matrix display\")\n",
    "main_window = MatrixRenderingWindow(matrix=top_pairwise_overlaps, columns=[f'{i}' for i in np.arange(np.shape(top_pairwise_overlaps)[-1])])\n",
    "\n",
    "# compute_placefield_overlap(active_one_step_decoder.pf.ratemap.normalized_tuning_curves)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7357706-f14c-413b-9020-496db9ed63cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Position Dataframe Binning in Time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0e39c8-6842-4ac4-8711-3fff06436690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aligned_active_pos_df = active_pos_df.copy()\n",
    "\n",
    "time_window_edges_time_delta = pd.to_timedelta(active_one_step_decoder.time_window_edges, unit=\"sec\") # convert the windows to timedeltas as well to allow efficient comparison\n",
    "time_window_edges_time_delta # length=1718\n",
    "\n",
    "# aligned_active_pos_df.between_time\n",
    "\n",
    "# aligned_active_pos_df.at_time(pho_custom_decoder.time_window_edges)\n",
    "\n",
    "# pho_custom_decoder.time_window_edges\n",
    "# aligned_active_pos_df.align(time_window_edges_time_delta, fill_value=np.nan)\n",
    "\n",
    "# build_position_df_time_window_idx(active_pos_df, pho_custom_decoder.active_time_window_centers)\n",
    "\n",
    "# pho_custom_decoder.active_time_window_centers\n",
    "# pho_custom_decoder.time_window_edges\n",
    "\n",
    "# s21, s22 = ts_2.align(ts_1, fill_value=0)\n",
    "\n",
    "# active_sess.position.df\n",
    "# aligned_active_pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d0c686-f861-4f42-9897-d4344ed691c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pho_custom_decoder = curr_kdiba_pipeline.computation_results['maze1'].computed_data['pf2D_Decoder']\n",
    "enable_plots = True\n",
    "\n",
    "print(f'most_likely_positions: {np.shape(pho_custom_decoder.most_likely_positions)}') # most_likely_positions: (3434, 2)\n",
    "\n",
    "\n",
    "def spike_count_and_firing_rate_normalizations(pho_custom_decoder, enable_plots=True):\n",
    "    \"\"\" Computes several different normalizations of binned firing rate and spike counts, optionally plotting them. \n",
    "    \n",
    "    Usage:\n",
    "        pho_custom_decoder = curr_kdiba_pipeline.computation_results['maze1'].computed_data['pf2D_Decoder']\n",
    "        enable_plots = True\n",
    "        unit_specific_time_binned_outputs = spike_count_and_firing_rate_normalizations(pho_custom_decoder, enable_plots=enable_plots)\n",
    "        spike_proportion_global_fr_normalized, firing_rate, firing_rate_global_fr_normalized = unit_specific_time_binned_outputs # unwrap the output tuple:\n",
    "    \"\"\"\n",
    "    # produces a fraction which indicates which proportion of the window's firing belonged to each unit (accounts for global changes in firing rate (each window is scaled by the toial spikes of all cells in that window)\n",
    "    unit_specific_time_binned_spike_proportion_global_fr_normalized = pho_custom_decoder.unit_specific_time_binned_spike_counts / pho_custom_decoder.total_spike_counts_per_window\n",
    "    if enable_plots:\n",
    "        plt.figure(num=5)\n",
    "        plt.imshow(unit_specific_time_binned_spike_proportion_global_fr_normalized, cmap='turbo', aspect='auto')\n",
    "        plt.title('Unit Specific Proportion of Window Spikes')\n",
    "        plt.xlabel('Binned Time Window')\n",
    "        plt.ylabel('Neuron Proportion Activity')\n",
    "\n",
    "    # print(pho_custom_decoder.time_window_edges_binning_info.step)\n",
    "    # print(f'pho_custom_decoder: {pho_custom_decoder}')\n",
    "    # np.shape(pho_custom_decoder.F) # (1856, 64)\n",
    "\n",
    "    unit_specific_time_binned_firing_rate = pho_custom_decoder.unit_specific_time_binned_spike_counts / pho_custom_decoder.time_window_edges_binning_info.step\n",
    "    # print(unit_specific_time_binned_firing_rate)\n",
    "    if enable_plots:\n",
    "        plt.figure(num=6)\n",
    "        plt.imshow(unit_specific_time_binned_firing_rate, cmap='turbo', aspect='auto')\n",
    "        plt.title('Unit Specific Binned Firing Rates')\n",
    "        plt.xlabel('Binned Time Window')\n",
    "        plt.ylabel('Neuron Firing Rate')\n",
    "\n",
    "\n",
    "    # produces a unit firing rate for each window that accounts for global changes in firing rate (each window is scaled by the firing rate of all cells in that window\n",
    "    unit_specific_time_binned_firing_rate_global_fr_normalized = unit_specific_time_binned_spike_proportion_global_fr_normalized / pho_custom_decoder.time_window_edges_binning_info.step\n",
    "    if enable_plots:\n",
    "        plt.figure(num=7)\n",
    "        plt.imshow(unit_specific_time_binned_firing_rate_global_fr_normalized, cmap='turbo', aspect='auto')\n",
    "        plt.title('Unit Specific Binned Firing Rates (Global Normalized)')\n",
    "        plt.xlabel('Binned Time Window')\n",
    "        plt.ylabel('Neuron Proportion Firing Rate')\n",
    "        \n",
    "        \n",
    "    # Special:\n",
    "    # pho_custom_decoder.unit_specific_time_binned_spike_counts\n",
    "    # unit_specific_binned_spike_count_mean = np.nanmean(pho_custom_decoder.unit_specific_time_binned_spike_counts, axis=1)\n",
    "    \n",
    "\n",
    "    # Return the computed values, leaving the original data unchanged.\n",
    "    return unit_specific_time_binned_spike_proportion_global_fr_normalized, unit_specific_time_binned_firing_rate, unit_specific_time_binned_firing_rate_global_fr_normalized\n",
    "\n",
    "\n",
    "unit_specific_time_binned_outputs = spike_count_and_firing_rate_normalizations(pho_custom_decoder, enable_plots=enable_plots)\n",
    "spike_proportion_global_fr_normalized, firing_rate, firing_rate_global_fr_normalized = unit_specific_time_binned_outputs # unwrap the output tuple:\n",
    "\n",
    "# pho_custom_decoder.unit_specific_time_binned_spike_counts.shape # (64, 1717)\n",
    "unit_specific_binned_spike_count_mean = np.nanmean(pho_custom_decoder.unit_specific_time_binned_spike_counts, axis=1)\n",
    "unit_specific_binned_spike_count_var = np.nanvar(pho_custom_decoder.unit_specific_time_binned_spike_counts, axis=1)\n",
    "unit_specific_binned_spike_count_median = np.nanmedian(pho_custom_decoder.unit_specific_time_binned_spike_counts, axis=1)\n",
    "\n",
    "unit_specific_binned_spike_count_mean\n",
    "unit_specific_binned_spike_count_median\n",
    "# unit_specific_binned_spike_count_mean.shape # (64, )\n",
    "\n",
    "\n",
    "# pho_custom_decoder.unit_specific_time_binned_spike_counts\n",
    "# pho_custom_decoder.time_window_edges\n",
    "# pho_custom_decoder.time_window_edges_binning_info\n",
    "# pho_custom_decoder.total_spike_counts_per_window\n",
    "# curr_kdiba_pipeline.pf.xbin\n",
    "\n",
    "\n",
    "# active_pos_df = curr_kdiba_pipeline.filtered_sessions['maze1'].position.to_dataframe()\n",
    "# time_window_edges, time_window_edges_binning_info = compute_spanning_bins(active_pos_df['x'].to_numpy(), bin_size=max_time_bin_size) # np.shape(out_digitized_variable_bins)[0] == np.shape(spikes_df)[0]\n",
    "# assert np.shape(time_window_edges)[0] < np.shape(spikes_df)[0], f'spikes_df[time_variable_name]: {np.shape(spikes_df[time_variable_name])} should be less than time_window_edges: {np.shape(time_window_edges)}!'\n",
    "\n",
    "# active_sess.position.df\n",
    "\n",
    "# active_aligned_pos_df = align_data(pho_custom_decoder.active_time_window_centers, active_pos_df['t'].to_numpy(), active_pos_df[['x','y']].to_numpy())\n",
    "# active_aligned_pos_df = align_data(pho_custom_decoder.active_time_window_centers, active_pos_df.index, active_pos_df['x'])\n",
    "# active_aligned_pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8fa335-d725-41ba-a8cd-2921eb85de71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from pyphoplacecellanalysis.General.Decoder.decoder_result import DecoderResultDisplayingPlot2D\n",
    "# def _display_decoder_result():\n",
    "#     renderer = DecoderResultDisplayingPlot2D(pho_custom_decoder, active_pos_df)\n",
    "#     def animate(i):\n",
    "#         # print(f'animate({i})')\n",
    "#         return renderer.display(i)\n",
    "#     interact(animate, i=(0, pho_custom_decoder.num_time_windows, 10))\n",
    "\n",
    "curr_kdiba_pipeline.display(DefaultDisplayFunctions._display_decoder_result, 'maze1', show_posterior=True) # works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12b6e96-0231-4829-a895-bfd14249b4fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @pn.interact(i=(0,pho_custom_decoder.num_time_windows,1,0))\n",
    "# @interact(i=pn.widgets.IntSlider(start=0,end=pho_custom_decoder.num_time_windows,step=1,value=0))\n",
    "\n",
    "# ani = FuncAnimation(renderer.fig, animate, interval=300)\n",
    "# interact(animate, i=(0, pho_custom_decoder.num_time_windows, 10))\n",
    "\n",
    "# pn.Column('**A custom interact layout**', pn.Row(layout[0], layout[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47c981e-7259-4a8e-acfd-5d9146e6b3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_kdiba_pipeline.computation_results['maze2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc9a4b0-0474-4f57-a5bb-e76a1fdee8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "_display_result(curr_kdiba_pipeline.computation_results['maze1'])\n",
    "_display_result(curr_kdiba_pipeline.computation_results['maze2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58555225-e9c9-45b2-afb5-d303cabb9118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from neuropy.utils.misc import is_iterable\n",
    "from neuropy.plotting.figure import pretty_plot\n",
    "from scipy.ndimage import gaussian_filter, gaussian_filter1d, interpolation\n",
    "\n",
    "from pyphoplacecellanalysis.Analysis.reliability import compute_lap_to_lap_reliability\n",
    "\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.laps import plot_laps_2d\n",
    "\n",
    "\n",
    "def _test_plotRaw_v_time(active_pf, cellind, speed_thresh=False, alpha=0.5, ax=None):\n",
    "        \"\"\" Builds one subplot for each dimension of the position data\n",
    "        \n",
    "        Updated to work with both 1D and 2D Placefields \"\"\"   \n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots(active_pf.ndim, 1, sharex=True)\n",
    "            fig.set_size_inches([23, 9.7])\n",
    "        \n",
    "        if not is_iterable(ax):\n",
    "            ax = [ax]\n",
    "            \n",
    "        # plot trajectories\n",
    "        if active_pf.ndim < 2:\n",
    "            variable_array = [active_pf.x]\n",
    "            label_array = [\"X position (cm)\"]\n",
    "        else:\n",
    "            variable_array = [active_pf.x, active_pf.y]\n",
    "            label_array = [\"X position (cm)\", \"Y position (cm)\"]\n",
    "            \n",
    "        for a, pos, ylabel in zip(ax, variable_array, label_array):\n",
    "            a.plot(active_pf.t, pos)\n",
    "            a.set_xlabel(\"Time (seconds)\")\n",
    "            a.set_ylabel(ylabel)\n",
    "            pretty_plot(a)\n",
    "\n",
    "        # Grab correct spike times/positions\n",
    "        if speed_thresh:\n",
    "            spk_pos_, spk_t_ = active_pf.run_spk_pos, active_pf.run_spk_t\n",
    "        else:\n",
    "            spk_pos_, spk_t_ = active_pf.spk_pos, active_pf.spk_t\n",
    "\n",
    "        # plot spikes on trajectory\n",
    "        for a, pos in zip(ax, spk_pos_[cellind]):\n",
    "            a.plot(spk_t_[cellind], pos, \".\", color=[0, 0, 0.8, alpha])\n",
    "\n",
    "        # Put info on title\n",
    "        ax[0].set_title(\n",
    "            \"Cell \"\n",
    "            + str(active_pf.cell_ids[cellind])\n",
    "            + \":, speed_thresh=\"\n",
    "            + str(active_pf.speed_thresh)\n",
    "        )\n",
    "        return ax\n",
    "\n",
    "\n",
    "def compute_reliability_metrics(out_indicies, out_digitized_position_bins, out_within_lap_spikes_overlap, debug_print=False, plot_results=False):\n",
    "    \"\"\" Takes input from compute_lap_to_lap_reliability(...) to build the actual reliability metrics \"\"\"\n",
    "    # Actual Computations of Reliability:\n",
    "    out_pairwise_pair_results = np.zeros_like(out_within_lap_spikes_overlap)\n",
    "    \n",
    "    # do simple diff:\n",
    "    laps_spikes_overlap_diff = np.diff(out_within_lap_spikes_overlap, axis=1) # the element-wise diff of the overlap. Shows changes.\n",
    "    out_pairwise_pair_results[:, 1:] = laps_spikes_overlap_diff\n",
    "    # out_pairwise_pair_results[:, -1] = np.zeros_like(out_within_lap_spikes_overlap[:,0])\n",
    "    \n",
    "    # do custom pairwise operation:\n",
    "#     for first_item_lap_idx, next_item_lap_idx in list(out_pairwise_flat_lap_indicies):\n",
    "#         first_item = out_within_lap_spikes_overlap[:, first_item_lap_idx]\n",
    "#         next_item = out_within_lap_spikes_overlap[:, next_item_lap_idx]\n",
    "#         out_pairwise_pair_results[:, next_item_lap_idx] = (first_item * next_item) # the result should be stored in the index of the second item, if we're doing the typical backwards style differences.\n",
    "#         # print(f'np.max(out_pairwise_pair_results[:, next_item_lap_idx]): {np.max(out_pairwise_pair_results[:, next_item_lap_idx])}')\n",
    "\n",
    "    if debug_print: \n",
    "        print(f'max out: {np.max(out_pairwise_pair_results)}')\n",
    "        \n",
    "    lap_ids \n",
    "    flat_lap_idxs = np.arange(len(lap_ids))\n",
    "    \n",
    "    \n",
    "    # add to the extant plot as a new color:\n",
    "    if plot_results:\n",
    "        for lap_idx, lap_ID in zip(flat_lap_idxs, lap_ids):\n",
    "            # curr_lap_alt_ax = axs[lap_idx]\n",
    "            if plot_horizontal:\n",
    "                curr_lap_alt_ax = axs[lap_idx].twiny()\n",
    "                curr_lap_alt_ax.plot(out_pairwise_pair_results[:, lap_idx], out_digitized_position_bins, '--r')\n",
    "            else:\n",
    "                # vertical\n",
    "                curr_lap_alt_ax = axs[lap_idx].twinx()\n",
    "                curr_lap_alt_ax.plot(out_digitized_position_bins, out_pairwise_pair_results[:, lap_idx], '--r')\n",
    "            \n",
    "    cum_laps_reliability = np.cumprod(out_within_lap_spikes_overlap, axis=1)\n",
    "    all_laps_reliability = np.prod(out_within_lap_spikes_overlap, axis=1, keepdims=True)\n",
    "    \n",
    "    if plot_results:\n",
    "        fig_result, axs_result = plt.subplots(2, 1, sharex=True, sharey=True, figsize=(24, 40))\n",
    "        axs_result[0].plot(out_digitized_position_bins, all_laps_reliability, 'r')\n",
    "        axs_result[1].plot(out_digitized_position_bins, cum_laps_reliability, 'r')\n",
    "\n",
    "curr_result_label = 'maze1'\n",
    "sess = curr_kdiba_pipeline.filtered_sessions[curr_result_label]\n",
    "sess = curr_kdiba_pipeline.sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b340e1ae-1165-4a55-b35a-73de562df226",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_laps_df = sess.laps.to_dataframe()\n",
    "curr_laps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00bc5e4-11cc-456f-994e-d4ae3ece2298",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = sess.compute_position_laps() # ensures the laps are computed if they need to be:\n",
    "position_obj = sess.position\n",
    "position_obj.compute_higher_order_derivatives()\n",
    "pos_df = position_obj.compute_smoothed_position_info(N=20) ## Smooth the velocity curve to apply meaningful logic to it\n",
    "pos_df = position_obj.to_dataframe()\n",
    "pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58644ddd-6efe-40b7-a9c5-5971a1bc1bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, out_axes_list = plot_laps_2d(sess, legacy_plotting_mode=True)\n",
    "fig, out_axes_list = plot_laps_2d(sess, legacy_plotting_mode=False)\n",
    "out_axes_list[0].set_title('New Pho Position Thresholding Estimated Laps')\n",
    "\n",
    "curr_cell_idx = 2 \n",
    "# curr_cell_idx = 3 # good for end platform analysis\n",
    "curr_cell_ID = sess.spikes_df.spikes.neuron_ids[curr_cell_idx]\n",
    "print(f'curr_cell_idx: {curr_cell_idx}, curr_cell_ID: {curr_cell_ID}')\n",
    "\n",
    "# pre-filter by spikes that occur in one of the included laps for the filtered_spikes_df\n",
    "filtered_spikes_df = sess.spikes_df.copy()\n",
    "time_variable_name = filtered_spikes_df.spikes.time_variable_name # 't_rel_seconds'\n",
    "\n",
    "lap_ids = sess.laps.lap_id\n",
    "# lap_flat_idxs = sess.laps.get_lap_flat_indicies(lap_ids)\n",
    "\n",
    "out_indicies, out_digitized_position_bins, out_within_lap_spikes_overlap = compute_lap_to_lap_reliability(curr_kdiba_pipeline.computation_results[curr_result_label].computed_data['pf2D'], filtered_spikes_df, lap_ids, curr_cell_idx, debug_print=False, plot_results=True);\n",
    "\n",
    "# compute_reliability_metrics(out_indicies, out_digitized_position_bins, out_within_lap_spikes_overlap, debug_print=False, plot_results=False)\n",
    "\n",
    "# # curr_kdiba_pipeline.computation_results['maze1'].computed_data['pf2D'].plotRaw_v_time(curr_cell_idx)\n",
    "# _test_plotRaw_v_time(curr_kdiba_pipeline.computation_results[curr_result_label].computed_data['pf2D'], curr_cell_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e8e317-9b3c-4895-ac55-13600e8ccc47",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3D Lap Plotting Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b752016f-67d4-4351-a61d-defc8a1bff41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice # for Pagination class\n",
    "import pyvista as pv\n",
    "import pyvistaqt as pvqt\n",
    "from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.LapsVisualizationMixin import LapsVisualizationMixin\n",
    "from pyphocorehelpers.gui.PyVista.PhoCustomVtkWidgets import PhoWidgetHelper\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.spikeAndPositions import perform_plot_flat_arena, _build_flat_arena_data\n",
    "\n",
    "\"\"\" Test Drawing Spike Lines \"\"\"\n",
    "# from pyphoplacecellanalysis.Pho3D.spikes import draw_line_spike, lines_from_points\n",
    "from pyphoplacecellanalysis.Pho3D.points import interlieve_points\n",
    "\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.spikeAndPositions import build_active_spikes_plot_pointdata_df\n",
    "\n",
    "def _plot_all_lap_spikes(p, sess, included_cell_IDXs, included_lap_IDXs, debug_print=True, lap_start_z=0.0, lap_id_dependent_z_offset=10.0):\n",
    "    should_reinterpolate_spike_positions = False\n",
    "        \n",
    "    def _plot_single_spikes(p, cell_specific_spikes_dfs, placefield_cell_index):\n",
    "        curr_cell_spike_df = cell_specific_spikes_dfs[placefield_cell_index]\n",
    "        # curr_cell_spike_df['z_fixed'] = np.full_like(active_flat_df['x'].values, 1.1)\n",
    "        pdata = build_active_spikes_plot_pointdata_df(curr_cell_spike_df)\n",
    "\n",
    "        # curr_cell_spike_times = curr_cell_spike_df[curr_cell_spike_df.spikes.time_variable_name].to_numpy()  # (271,)\n",
    "        # curr_cell_spike_positions = curr_cell_spike_df['x','y'].to_numpy()  # (271,)\n",
    "\n",
    "        # lines_from_points(\n",
    "        # p[0,0].add_points(pdata, name='plot_single_spikes_points', render_points_as_spheres=True, point_size=5.0)\n",
    "\n",
    "        # Build offset points and spike data:\n",
    "        spike_height = max((lap_id_dependent_z_offset * 0.6), 0.5) # half the line height\n",
    "\n",
    "        # start_points = pdata.points.copy()\n",
    "        # end_points = start_points.copy()\n",
    "        # # end_points[:,2] # get z values\n",
    "        # end_points[:,2] = end_points[:,2] + spike_height\n",
    "        # all_points = interlieve_points(start_points, end_points)\n",
    "        # lines_poly_data = pv.PolyData()\n",
    "        # lines_poly_data.points = all_points\n",
    "        # # cells = np.hstack(([2, 0, 1],[2, 1, 2]))\n",
    "        # num_lines = np.shape(start_points)[0]\n",
    "        # cells = [[2, 2*i, 2*i+1] for i in np.arange(num_lines)]\n",
    "        # lines_poly_data.lines = cells\n",
    "        \n",
    "        p[0,0].add_mesh(pdata, name=f'plot_single_spikes_points[{placefield_cell_index}]', render_points_as_spheres=True, point_size=5.0, color='white')        \n",
    "        \n",
    "        # p[0,0].add_points(pdata, name=f'plot_single_spikes_points[{placefield_cell_index}]', render_points_as_spheres=True, point_size=5.0)\n",
    "        # p[0,0].add_mesh(lines_poly_data, name=f'plot_single_spikes_lines[{placefield_cell_index}]', render_points_as_spheres=False, point_size=5.0)\n",
    "        # return {'pdata':pdata, 'lines_poly_data':lines_poly_data}\n",
    "        \n",
    "        return {'pdata':pdata}\n",
    "    \n",
    "    time_variable_name = sess.spikes_df.spikes.time_variable_name # 't_rel_seconds'\n",
    "    # sets the 'z_fixed' value for all spikes in sess.spikes_df, which will be used to plot them as points\n",
    "    sess.spikes_df['z'] = lap_start_z + (lap_id_dependent_z_offset * sess.spikes_df.lap.to_numpy())\n",
    "\n",
    "    if debug_print:\n",
    "        print(f'sess.laps.lap_id: {sess.laps.lap_id}')\n",
    "        \n",
    "    included_cell_IDXs = np.array(included_cell_IDXs)\n",
    "    included_lap_IDXs = np.array(included_lap_IDXs)\n",
    "    \n",
    "    # ensure that only lap_ids included in this session are used:\n",
    "    included_lap_ids = sess.laps.lap_id[included_lap_IDXs]\n",
    "    possible_included_lap_ids = np.unique(sess.spikes_df.lap.values)\n",
    "    if debug_print:\n",
    "        print(f'np.unique(sess.spikes_df.lap.values): {np.unique(sess.spikes_df.lap.values)}')\n",
    "    included_lap_ids = included_lap_ids[np.isin(included_lap_ids, possible_included_lap_ids)]\n",
    "    if debug_print:\n",
    "        print(f'included_lap_ids: {included_lap_ids}')\n",
    "    \n",
    "    # get the included cell IDs\n",
    "    included_cell_IDs = np.array(sess.spikes_df.spikes.neuron_ids)[included_cell_IDXs]\n",
    "        \n",
    "    # print(np.isin(['R','G','B','render_opacity'], sess.spikes_df.columns).all())\n",
    "\n",
    "    # POSITIONS:\n",
    "    curr_position_df, lap_specific_position_dfs, lap_specific_time_ranges, lap_specific_position_traces = LapsVisualizationMixin._compute_laps_position_data(sess)\n",
    "    \n",
    "    # SPIKES:\n",
    "    # # grouped by lap\n",
    "    # lap_grouped_spikes_df = sess.spikes_df.groupby('lap')\n",
    "    # lap_specific_spikes_dfs = [lap_grouped_spikes_df.get_group(i)[[time_variable_name,'aclu','lap','flat_spike_idx','cell_type','x','y','lin_pos','z']] for i in included_lap_ids] # dataframes split for each ID:\n",
    "\n",
    "    # grouped by cell:\n",
    "    # pre-filter by spikes that occur in one of the included laps for the filtered_spikes_df\n",
    "    filtered_spikes_df = sess.spikes_df.copy()\n",
    "    filtered_spikes_df = filtered_spikes_df[np.isin(filtered_spikes_df['lap'], included_lap_ids)] # get only the spikes that occur in one of the included laps for the filtered_spikes_df\n",
    "    \n",
    "    \n",
    "    # Interpolate the spikes positions again:\n",
    "    if should_reinterpolate_spike_positions:\n",
    "        print('Re-interpolating spike positions...')\n",
    "        filtered_spikes_df = filtered_spikes_df.spikes.interpolate_spike_positions(curr_position_df['t'].to_numpy(), curr_position_df['x'].to_numpy(), curr_position_df['y'].to_numpy())\n",
    "        # filtered_spikes_df = FlattenedSpiketrains.interpolate_spike_positions(filtered_spikes_df, session.position.time, session.position.x, session.position.y, spike_timestamp_column_name=time_variable_name)\n",
    "    \n",
    "    cell_grouped_spikes_df = filtered_spikes_df.groupby('aclu')\n",
    "    cell_specific_spikes_dfs = [cell_grouped_spikes_df.get_group(i)[[time_variable_name,'aclu','lap','flat_spike_idx','cell_type','x','y','lin_pos','z']] for i in included_cell_IDs] # dataframes split for each ID:\n",
    "\n",
    "    # lap_specific_position_dfs = _compute_laps_position_data(sess)\n",
    "\n",
    "    # # Positions:\n",
    "    # curr_position_df = sess.compute_position_laps()\n",
    "    # included_pos_lap_ids = np.unique(curr_position_df.lap.values)\n",
    "    # print(f'np.unique(curr_position_df.lap.values): {np.unique(curr_position_df.lap.values)}')\n",
    "    # included_pos_lap_ids = included_pos_lap_ids[np.isin(included_pos_lap_ids, sess.laps.lap_id)]\n",
    "    # included_pos_lap_ids\n",
    "\n",
    "    # print(f'included_pos_lap_ids: {included_pos_lap_ids}')\n",
    "\n",
    "    # lap_grouped_position_df = curr_position_df.groupby('lap')\n",
    "    # lap_specific_position_dfs = [lap_grouped_position_df.get_group(i)[['t','aclu','x','y','lin_pos']] for i in included_lap_ids] # dataframes split for each ID:\n",
    "\n",
    "    for i, curr_cell_ID in enumerate(included_cell_IDs):\n",
    "        plot_data_dict = _plot_single_spikes(p, cell_specific_spikes_dfs, i)\n",
    "\n",
    "\n",
    "# sess = curr_kdiba_pipeline.filtered_sessions['maze']\n",
    "# included_cell_IDXs = [6]\n",
    "# included_lap_IDXs = [2, 3]\n",
    "# _plot_all_lap_spikes(pActiveInteractiveLapsPlotter, sess, included_cell_IDXs, included_lap_IDXs)\n",
    "\n",
    "from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.InteractiveCustomDataExplorer import InteractiveCustomDataExplorer\n",
    "\n",
    "lap_start_z = 0.0\n",
    "# lap_id_dependent_z_offset = 0.0\n",
    "lap_id_dependent_z_offset = 3.0\n",
    "# curr_kdiba_pipeline.active_configs['maze1'].lap_id_dependent_z_offset = 3.0\n",
    "\n",
    "def _display_testing(sess, computation_result, active_config, extant_plotter=None):\n",
    "    \"\"\" Testing of plot_lap_trajectories_2d \"\"\"\n",
    "    print(f'active_config.plotting_config: {active_config.plotting_config}')\n",
    "    single_combined_plot=True\n",
    "    if single_combined_plot:\n",
    "        default_plotting = True\n",
    "    else:\n",
    "        default_plotting = False\n",
    "    active_config.plotting_config.plotter_type = 'MultiPlotter'\n",
    "    print(f'active_config.plotting_config: {active_config.plotting_config}')\n",
    "    iplapsDataExplorer = InteractiveCustomDataExplorer(active_config, sess, extant_plotter=extant_plotter)\n",
    "    pActiveInteractiveLapsPlotter = iplapsDataExplorer.plot(pActivePlotter=extant_plotter, default_plotting=default_plotting)\n",
    "    # included_cell_idxs = None\n",
    "    included_cell_idxs = [0, 1]\n",
    "    # included_lap_idxs = [2, 5, 9, 12]\n",
    "    included_lap_idxs = [2]\n",
    "    # All\n",
    "    # included_cell_idxs = np.arange(len(sess.spikes_df.spikes.neuron_ids))\n",
    "    # included_lap_idxs = np.arange(len(sess.laps.lap_id))\n",
    "    from pyphoplacecellanalysis.PhoPositionalData.plotting.laps import plot_lap_trajectories_3d\n",
    "    pActiveInteractiveLapsPlotter, laps_pages = plot_lap_trajectories_3d(sess, curr_num_subplots=5, active_page_index=0, included_lap_idxs=included_lap_idxs, single_combined_plot=single_combined_plot, \n",
    "                                                                         lap_start_z = lap_start_z, lap_id_dependent_z_offset = lap_id_dependent_z_offset,\n",
    "                                                                         existing_plotter=pActiveInteractiveLapsPlotter)\n",
    "\n",
    "    # add the spikes for the curves:\n",
    "    _plot_all_lap_spikes(pActiveInteractiveLapsPlotter, sess, included_cell_idxs, included_lap_idxs, lap_start_z=lap_start_z, lap_id_dependent_z_offset=lap_id_dependent_z_offset)\n",
    "    return iplapsDataExplorer, pActiveInteractiveLapsPlotter\n",
    "\n",
    "\n",
    "# curr_kdiba_pipeline.computation_results['maze1'].computation_config\n",
    "# curr_kdiba_pipeline.computation_results['maze1'].sess.config\n",
    "# curr_kdiba_pipeline.active_configs['maze1']\n",
    "\n",
    "curr_result_label = 'maze1'\n",
    "sess = curr_active_pipeline.filtered_sessions[curr_result_label]\n",
    "sess = curr_active_pipeline.sess\n",
    "\n",
    "pActiveInteractiveLapsPlotter = None\n",
    "try: pActiveInteractiveLapsPlotter\n",
    "except NameError: pActiveInteractiveLapsPlotter = None # Checks variable p's existance, and sets its value to None if it doesn't exist so it can be checked in the next step\n",
    "iplapsDataExplorer, pActiveInteractiveLapsPlotter = _display_testing(sess, curr_active_pipeline.computation_results[curr_result_label], curr_active_pipeline.active_configs[curr_result_label],\n",
    "                                                                     extant_plotter=pActiveInteractiveLapsPlotter)\n",
    "pActiveInteractiveLapsPlotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e5881e-3e37-4d8b-b5c3-0c8837cbd1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lines_from_points(pdata.points)\n",
    "\n",
    "np.shape(all_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c580c6e6-38b1-4d6e-bf09-6b60842a922a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3a0d93-16ac-4240-a373-7bd9f337f6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "p, laps_pages = _plot_lap_trajectories_combined_plot_3d(curr_kdiba_pipeline.sess, curr_num_subplots=5, single_combined_plot=False)\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86802581-69ea-4aca-a673-e4e306d6e17b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phoviz_ultimate]",
   "language": "python",
   "name": "conda-env-phoviz_ultimate-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
