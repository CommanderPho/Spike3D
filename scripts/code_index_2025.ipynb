{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "020aa596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import inspect\n",
    "import importlib.util\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any, Optional\n",
    "import sys\n",
    "\n",
    "def extract_function_attributes_metadata(func_obj) -> Dict[str, Any]:\n",
    "    \"\"\"Extract function_attributes metadata from a function object\"\"\"\n",
    "    from pyphocorehelpers.function_helpers import get_decorated_function_attributes, is_decorated_with_function_attributes\n",
    "    \n",
    "    metadata = {}\n",
    "    if is_decorated_with_function_attributes(func_obj):\n",
    "        metadata = get_decorated_function_attributes(func_obj)\n",
    "    return metadata\n",
    "\n",
    "def extract_metadata_attributes_metadata(obj) -> Dict[str, Any]:\n",
    "    \"\"\"Extract metadata_attributes metadata from a function, method, or class object\"\"\"\n",
    "    from pyphocorehelpers.programming_helpers import get_decorated_metadata_attributes, is_decorated_with_metadata_attributes\n",
    "    \n",
    "    metadata = {}\n",
    "    if is_decorated_with_metadata_attributes(obj):\n",
    "        metadata = get_decorated_metadata_attributes(obj)\n",
    "    return metadata\n",
    "\n",
    "def parse_ast_node(node: ast.AST, module_path: str, module_name: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Parse AST node and extract function/class information\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    if isinstance(node, ast.FunctionDef):\n",
    "        # Extract function signature\n",
    "        args = [arg.arg for arg in node.args.args]\n",
    "        defaults = [ast.unparse(d) if hasattr(ast, 'unparse') else 'N/A' \n",
    "                   for d in node.args.defaults] if node.args.defaults else []\n",
    "        \n",
    "        # Get decorators\n",
    "        decorators = [ast.unparse(d) if hasattr(ast, 'unparse') else d.id \n",
    "                     for d in node.decorator_list if isinstance(d, (ast.Name, ast.Call))]\n",
    "        \n",
    "        results.append({\n",
    "            'type': 'function',\n",
    "            'name': node.name,\n",
    "            'module': module_name,\n",
    "            'file_path': module_path,\n",
    "            'line_number': node.lineno,\n",
    "            'args': args,\n",
    "            'defaults': defaults,\n",
    "            'decorators': decorators,\n",
    "            'docstring': ast.get_docstring(node),\n",
    "            'is_async': isinstance(node, ast.AsyncFunctionDef),\n",
    "        })\n",
    "    \n",
    "    elif isinstance(node, ast.ClassDef):\n",
    "        # Extract class information\n",
    "        decorators = [ast.unparse(d) if hasattr(ast, 'unparse') else d.id \n",
    "                     for d in node.decorator_list if isinstance(d, (ast.Name, ast.Call))]\n",
    "        \n",
    "        bases = [ast.unparse(b) if hasattr(ast, 'unparse') else b.id \n",
    "                for b in node.bases if isinstance(b, (ast.Name, ast.Call))]\n",
    "        \n",
    "        results.append({\n",
    "            'type': 'class',\n",
    "            'name': node.name,\n",
    "            'module': module_name,\n",
    "            'file_path': module_path,\n",
    "            'line_number': node.lineno,\n",
    "            'bases': bases,\n",
    "            'decorators': decorators,\n",
    "            'docstring': ast.get_docstring(node),\n",
    "        })\n",
    "        \n",
    "        # Parse methods within the class\n",
    "        for item in node.body:\n",
    "            if isinstance(item, (ast.FunctionDef, ast.AsyncFunctionDef)):\n",
    "                args = [arg.arg for arg in item.args.args if arg.arg != 'self']\n",
    "                defaults = [ast.unparse(d) if hasattr(ast, 'unparse') else 'N/A' \n",
    "                           for d in item.args.defaults] if item.args.defaults else []\n",
    "                \n",
    "                method_decorators = [ast.unparse(d) if hasattr(ast, 'unparse') else d.id \n",
    "                                   for d in item.decorator_list if isinstance(d, (ast.Name, ast.Call))]\n",
    "                \n",
    "                results.append({\n",
    "                    'type': 'method',\n",
    "                    'name': f\"{node.name}.{item.name}\",\n",
    "                    'class_name': node.name,\n",
    "                    'module': module_name,\n",
    "                    'file_path': module_path,\n",
    "                    'line_number': item.lineno,\n",
    "                    'args': args,\n",
    "                    'defaults': defaults,\n",
    "                    'decorators': method_decorators,\n",
    "                    'docstring': ast.get_docstring(item),\n",
    "                    'is_async': isinstance(item, ast.AsyncFunctionDef),\n",
    "                })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def parse_python_file(file_path: Path, library_root: Path) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Parse a single Python file using AST\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        tree = ast.parse(content, filename=str(file_path))\n",
    "        \n",
    "        # Construct module name\n",
    "        rel_path = file_path.relative_to(library_root)\n",
    "        module_name = '.'.join(rel_path.parts[:-1] + (rel_path.stem,))\n",
    "        \n",
    "        results = []\n",
    "        for node in ast.walk(tree):\n",
    "            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n",
    "                # Only process top-level definitions\n",
    "                if node.lineno and isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):\n",
    "                    node_results = parse_ast_node(node, str(file_path), module_name)\n",
    "                    results.extend(node_results)\n",
    "        \n",
    "        # Remove duplicates and keep only top-level items\n",
    "        seen = set()\n",
    "        unique_results = []\n",
    "        for item in results:\n",
    "            key = (item['type'], item['name'], item['line_number'])\n",
    "            if key not in seen:\n",
    "                seen.add(key)\n",
    "                unique_results.append(item)\n",
    "        \n",
    "        return unique_results\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing {file_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "def enrich_with_runtime_metadata(df: pd.DataFrame, library_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Enrich AST-parsed data with runtime metadata (function_attributes, metadata_attributes, signatures, etc.)\"\"\"\n",
    "    # Start with a copy of the original dataframe to preserve all columns\n",
    "    enriched_df = df.copy()\n",
    "    \n",
    "    # Initialize all possible metadata columns with None\n",
    "    # Known function_attributes keys\n",
    "    func_attr_keys = ['short_name', 'tags', 'creation_date', 'input_requires', 'output_provides', \n",
    "                      'uses', 'used_by', 'related_items', 'conforms_to', 'is_global', \n",
    "                      'validate_computation_test', 'requires_global_keys', 'provides_global_keys']\n",
    "    # Known metadata_attributes keys\n",
    "    meta_attr_keys = ['short_name', 'tags', 'creation_date', 'input_requires', 'output_provides',\n",
    "                      'uses', 'used_by', 'related_items', 'pyqt_signals_emitted']\n",
    "    \n",
    "    # Initialize columns\n",
    "    for key in func_attr_keys:\n",
    "        enriched_df[f'func_attr_{key}'] = None\n",
    "    for key in meta_attr_keys:\n",
    "        enriched_df[f'meta_attr_{key}'] = None\n",
    "    enriched_df['signature'] = None\n",
    "    \n",
    "    # Process each row\n",
    "    for idx, row in df.iterrows():\n",
    "        # Try to import and get runtime metadata\n",
    "        try:\n",
    "            module = importlib.import_module(row['module'])\n",
    "            obj_type = row['type']\n",
    "            obj_name = row['name']\n",
    "            \n",
    "            obj = None\n",
    "            if obj_type == 'method':\n",
    "                # For methods, parse ClassName.method_name format\n",
    "                if '.' in obj_name:\n",
    "                    class_name, method_name = obj_name.split('.', 1)\n",
    "                    class_obj = getattr(module, class_name, None)\n",
    "                    if class_obj is not None and inspect.isclass(class_obj):\n",
    "                        # Get the method from the class\n",
    "                        obj = getattr(class_obj, method_name, None)\n",
    "            elif obj_type == 'class':\n",
    "                # For classes, get the class object directly\n",
    "                obj = getattr(module, obj_name, None)\n",
    "            else:\n",
    "                # For functions, get the function object\n",
    "                obj = getattr(module, obj_name, None)\n",
    "            \n",
    "            if obj is not None:\n",
    "                # Extract function_attributes metadata\n",
    "                func_attr_metadata = extract_function_attributes_metadata(obj)\n",
    "                for key, value in func_attr_metadata.items():\n",
    "                    enriched_df.at[idx, f'func_attr_{key}'] = value\n",
    "                \n",
    "                # Extract metadata_attributes metadata\n",
    "                meta_attr_metadata = extract_metadata_attributes_metadata(obj)\n",
    "                for key, value in meta_attr_metadata.items():\n",
    "                    enriched_df.at[idx, f'meta_attr_{key}'] = value\n",
    "                \n",
    "                # Get signature if available (for callable objects)\n",
    "                if callable(obj):\n",
    "                    try:\n",
    "                        sig = inspect.signature(obj)\n",
    "                        enriched_df.at[idx, 'signature'] = str(sig)\n",
    "                    except:\n",
    "                        enriched_df.at[idx, 'signature'] = None\n",
    "        except Exception as e:\n",
    "            # Module might not be importable, that's okay\n",
    "            pass\n",
    "    \n",
    "    return enriched_df\n",
    "\n",
    "def parse_python_library(library_path: str, enrich_with_runtime: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"Parse entire Python library and return DataFrame\"\"\"\n",
    "    library_path = Path(library_path)\n",
    "    all_results = []\n",
    "    \n",
    "    # Walk through all Python files\n",
    "    for py_file in library_path.rglob('*.py'):\n",
    "        # Skip __pycache__ and test files if desired\n",
    "        if '__pycache__' in str(py_file) or py_file.name.startswith('test_'):\n",
    "            continue\n",
    "        \n",
    "        results = parse_python_file(py_file, library_path)\n",
    "        all_results.extend(results)\n",
    "    \n",
    "    df = pd.DataFrame(all_results)\n",
    "    \n",
    "    if enrich_with_runtime and len(df) > 0:\n",
    "        # Add library path to sys.path temporarily\n",
    "        library_parent = str(library_path.parent)\n",
    "        if library_parent not in sys.path:\n",
    "            sys.path.insert(0, library_parent)\n",
    "        \n",
    "        try:\n",
    "            df = enrich_with_runtime_metadata(df, library_path)\n",
    "        finally:\n",
    "            if library_parent in sys.path:\n",
    "                sys.path.remove(library_parent)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36e107de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing library...\n",
      "Error parsing h:\\TEMP\\Spike3DEnv_ExploreUpgrade\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\External\\burst-detection-master\\lib_final_cma.py: Missing parentheses in call to 'print'. Did you mean print(\"\\nRUNNING CUMULATIVE MOVING AVERAGE ANALYSIS\\n\")? (lib_final_cma.py, line 15)\n",
      "Error parsing h:\\TEMP\\Spike3DEnv_ExploreUpgrade\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\External\\burst-detection-master\\lib_final_ehv.py: Missing parentheses in call to 'print'. Did you mean print(\"\\n\\nGenerating basis functions...\")? (lib_final_ehv.py, line 162)\n",
      "Error parsing h:\\TEMP\\Spike3DEnv_ExploreUpgrade\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\External\\burst-detection-master\\lib_final_poisson.py: Missing parentheses in call to 'print'. Did you mean print(\"\\n\\n===== ===== ===== ===== =====\")? (lib_final_poisson.py, line 66)\n",
      "Error parsing h:\\TEMP\\Spike3DEnv_ExploreUpgrade\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\External\\burst-detection-master\\_do_analysis.py: Missing parentheses in call to 'print'. Did you mean print(\"Making raster plot...\")? (_do_analysis.py, line 100)\n",
      "Error parsing h:\\TEMP\\Spike3DEnv_ExploreUpgrade\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\PhoPositionalData\\plotting\\mixins\\decoder_plotting_mixins.py: EOL while scanning string literal (decoder_plotting_mixins.py, line 3027)\n",
      "\n",
      "Found 18971 items:\n",
      "function    9850\n",
      "method      8015\n",
      "class       1106\n",
      "Name: type, dtype: int64\n",
      "\n",
      "First few rows:\n",
      "       type                                            name  \\\n",
      "0  function                robust_velocity_and_acceleration   \n",
      "1  function                             _compute_pos_derivs   \n",
      "2  function  debug_plot_helper_add_position_and_derivatives   \n",
      "3  function      debug_plot_position_and_derivatives_figure   \n",
      "4  function           debug_plot_position_derivatives_stack   \n",
      "\n",
      "                          module  \\\n",
      "0  Analysis.position_derivatives   \n",
      "1  Analysis.position_derivatives   \n",
      "2  Analysis.position_derivatives   \n",
      "3  Analysis.position_derivatives   \n",
      "4  Analysis.position_derivatives   \n",
      "\n",
      "                                           file_path  line_number  \\\n",
      "0  h:\\TEMP\\Spike3DEnv_ExploreUpgrade\\Spike3DWorkE...           22   \n",
      "1  h:\\TEMP\\Spike3DEnv_ExploreUpgrade\\Spike3DWorkE...           85   \n",
      "2  h:\\TEMP\\Spike3DEnv_ExploreUpgrade\\Spike3DWorkE...          124   \n",
      "3  h:\\TEMP\\Spike3DEnv_ExploreUpgrade\\Spike3DWorkE...          200   \n",
      "4  h:\\TEMP\\Spike3DEnv_ExploreUpgrade\\Spike3DWorkE...          247   \n",
      "\n",
      "                                                args            defaults  \\\n",
      "0                                             [t, x]                  []   \n",
      "1  [time_window_centers, position, decoding_time_...       [None, False]   \n",
      "2  [time_window_centers, position, velocity, acce...  [None, None, None]   \n",
      "3  [new_measured_pos_df, all_epochs_position_deri...  [None, None, True]   \n",
      "4  [new_measured_pos_df, all_epochs_position_deri...  [False, 300, 1900]   \n",
      "\n",
      "                                          decorators  \\\n",
      "0  [function_attributes(short_name=None, tags=['p...   \n",
      "1  [function_attributes(short_name=None, tags=['d...   \n",
      "2  [function_attributes(short_name=None, tags=['h...   \n",
      "3  [function_attributes(short_name=None, tags=['m...   \n",
      "4  [function_attributes(short_name=None, tags=['p...   \n",
      "\n",
      "                                           docstring is_async  ...  \\\n",
      "0  a much improved computation for velocity and a...    False  ...   \n",
      "1  try recomputing velocties/accelerations\\n\\nfro...    False  ...   \n",
      "2  HELPER to `debug_plot_position_and_derivatives...    False  ...   \n",
      "3  Renders a single matplotlib figure with a stac...    False  ...   \n",
      "4  Renders a stack of 3 subplots: [position, velo...    False  ...   \n",
      "\n",
      "  meta_attr_short_name meta_attr_tags meta_attr_creation_date  \\\n",
      "0                 None           None                    None   \n",
      "1                 None           None                    None   \n",
      "2                 None           None                    None   \n",
      "3                 None           None                    None   \n",
      "4                 None           None                    None   \n",
      "\n",
      "  meta_attr_input_requires meta_attr_output_provides meta_attr_uses  \\\n",
      "0                     None                      None           None   \n",
      "1                     None                      None           None   \n",
      "2                     None                      None           None   \n",
      "3                     None                      None           None   \n",
      "4                     None                      None           None   \n",
      "\n",
      "  meta_attr_used_by meta_attr_related_items meta_attr_pyqt_signals_emitted  \\\n",
      "0              None                    None                           None   \n",
      "1              None                    None                           None   \n",
      "2              None                    None                           None   \n",
      "3              None                    None                           None   \n",
      "4              None                    None                           None   \n",
      "\n",
      "  signature  \n",
      "0      None  \n",
      "1      None  \n",
      "2      None  \n",
      "3      None  \n",
      "4      None  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Usage\n",
    "# if __name__ == '__main__':\n",
    "library_path = r'h:\\TEMP\\Spike3DEnv_ExploreUpgrade\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis'\n",
    "\n",
    "print(\"Parsing library...\")\n",
    "df = parse_python_library(library_path, enrich_with_runtime=True)\n",
    "\n",
    "print(f\"\\nFound {len(df)} items:\")\n",
    "print(df['type'].value_counts())\n",
    "\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Save to CSV\n",
    "# df.to_csv('library_analysis.csv', index=False)\n",
    "# print(\"\\nSaved to library_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "320a3672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['type',\n",
       " 'name',\n",
       " 'module',\n",
       " 'file_path',\n",
       " 'line_number',\n",
       " 'args',\n",
       " 'defaults',\n",
       " 'decorators',\n",
       " 'docstring',\n",
       " 'is_async',\n",
       " 'bases',\n",
       " 'class_name',\n",
       " 'func_attr_short_name',\n",
       " 'func_attr_tags',\n",
       " 'func_attr_creation_date',\n",
       " 'func_attr_input_requires',\n",
       " 'func_attr_output_provides',\n",
       " 'func_attr_uses',\n",
       " 'func_attr_used_by',\n",
       " 'func_attr_related_items',\n",
       " 'func_attr_conforms_to',\n",
       " 'func_attr_is_global',\n",
       " 'func_attr_validate_computation_test',\n",
       " 'func_attr_requires_global_keys',\n",
       " 'func_attr_provides_global_keys',\n",
       " 'meta_attr_short_name',\n",
       " 'meta_attr_tags',\n",
       " 'meta_attr_creation_date',\n",
       " 'meta_attr_input_requires',\n",
       " 'meta_attr_output_provides',\n",
       " 'meta_attr_uses',\n",
       " 'meta_attr_used_by',\n",
       " 'meta_attr_related_items',\n",
       " 'meta_attr_pyqt_signals_emitted',\n",
       " 'signature']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
