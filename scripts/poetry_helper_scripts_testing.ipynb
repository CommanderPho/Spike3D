{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "module_path: c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from typing import Dict, List, Tuple, Optional, Callable, Union, Any\n",
    "\n",
    "import subprocess\n",
    "import shutil\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from pyphocorehelpers.Filesystem.source_code_helpers import find_py_files\n",
    "# from pyphocorehelpers.Filesystem.poetry_helpers import get_current_poetry_env, copy_recursive\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "print(f'module_path: {module_path}')\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    print(f'appending to module_path...')\n",
    "    sys.path.append(module_path)\n",
    "    # sys.path.append(module_path+\"\\\\scripts\")\n",
    "    # sys.path.append(module_path+\"\\\\scripts\"+\"\\\\helpers\")\n",
    "    # sys.path.append(module_path+\"\\\\scripts\"+\"\\\\helpers\"+\"\\\\export_subrepos\")\n",
    "    \n",
    "# \\helpers\n",
    "\n",
    "# from .scripts.helpers.export_subrepos import export_poetry_repo\n",
    "# import scripts\n",
    "# import scripts.helpers.export_subrepos\n",
    "# from scripts.helpers.export_subrepos import export_poetry_repo # scripts.helpers.export_subrepos import export_poetry_repo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Spike3D'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mSpike3D\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscripts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhelpers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexport_subrepos\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m export_poetry_repo\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Spike3D'"
     ]
    }
   ],
   "source": [
    "from Spike3D.scripts.helpers.export_subrepos import export_poetry_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_project_path = pathlib.Path(\"C:/Users/pho/repos/Spike3DWorkEnv/\")\n",
    "assert root_project_path.exists()\n",
    "# repos_source_paths = [\"C:/Users/pho/repos/Spike3DWorkEnv/NeuroPy/neuropy\", \"C:/Users/pho/repos/Spike3DWorkEnv/pyPhoCoreHelpers/src\", \"C:/Users/pho/repos/Spike3DWorkEnv/pyPhoPlaceCellAnalysis/src\"]\n",
    "# repos_exclude_dir_lists = [None, None, [\"pyphoplacecellanalysis/External\"]]\n",
    "\n",
    "# all_found_files = []\n",
    "# for a_src_path, exclude_dirs in zip(repos_source_paths, repos_exclude_dir_lists):\n",
    "#     all_found_files.extend(find_py_files(a_src_path, exclude_dirs = exclude_dirs))\n",
    "\n",
    "\n",
    "spike3D_path = pathlib.Path(\"C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\").resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.devcontainer', '.git', '.idea', '.mypy_cache', '.vscode', 'backups', 'exports', 'flexitext', 'matlab-to-neuropy-exporter', 'maxlikespy', 'napari-spike3d', 'NeuroPy', 'pho_jupyter_preview_widget', 'portion', 'proplot', 'PyCanvas', 'pycscope', 'pylustrator', 'pyPhoCoreHelpers', 'pyPhoPlaceCellAnalysis', 'pyqode.core', 'pyqode.python', 'PyQtInspect-Open', 'PyQtWebEngine-5.15.7', 'SCRIPTS', 'silx', 'Spike3D', 'tests', 'TrajSeg']\n",
      "{'matlab-to-neuropy-exporter': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/matlab-to-neuropy-exporter'), 'NeuroPy': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/NeuroPy'), 'pyPhoCoreHelpers': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/pyPhoCoreHelpers'), 'pyPhoPlaceCellAnalysis': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/pyPhoPlaceCellAnalysis'), 'pyqode.core': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/pyqode.core'), 'pyqode.python': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/pyqode.python'), 'Spike3D': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D')}\n"
     ]
    }
   ],
   "source": [
    "root_project_path: Path\n",
    "# Get full directory paths\n",
    "directory_paths = [str(item.name) for item in root_project_path.iterdir() if item.is_dir()]\n",
    "print(directory_paths)\n",
    "\n",
    "\n",
    "_default_child_repo_dir_names = ['matlab-to-neuropy-exporter', 'NeuroPy', 'pyPhoCoreHelpers', 'pyPhoPlaceCellAnalysis', 'pyqode.core', 'pyqode.python', 'Spike3D']\n",
    "\n",
    "child_repo_dir_names = deepcopy(_default_child_repo_dir_names)\n",
    "# child_repo_dir_names = ['flexitext', 'maxlikespy', 'napari-spike3d', 'pho_jupyter_preview_widget', 'portion', 'proplot', 'pylustrator', 'PyQtInspect-Open', 'PyQtWebEngine-5.15.7', 'silx', 'TrajSeg']\n",
    "\n",
    "child_repo_dir_paths = [item for item in root_project_path.iterdir() if (item.is_dir() and str(item.name) in child_repo_dir_names)]\n",
    "# print(child_repo_dir_paths)\n",
    "\n",
    "child_repo_dir_path_dict: Dict[str, Path] = dict(zip(child_repo_dir_names, child_repo_dir_paths))\n",
    "print(child_repo_dir_path_dict)\n",
    "## OUTPUTS: child_repo_dir_path_dict, child_repo_dir_names, child_repo_dir_paths\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating zip archive for matlab-to-neuropy-exporter...\n",
      "Created C:\\Users\\pho\\repos\\Spike3DWorkEnv\\backups\\matlab-to-neuropy-exporter.zip\n",
      "Creating zip archive for NeuroPy...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_exclude(file_path):\n\u001b[0;32m     46\u001b[0m                 \u001b[38;5;66;03m# Get relative path\u001b[39;00m\n\u001b[0;32m     47\u001b[0m                 rel_path \u001b[38;5;241m=\u001b[39m file_path\u001b[38;5;241m.\u001b[39mrelative_to(root_project_path)\n\u001b[1;32m---> 48\u001b[0m                 \u001b[43mzipf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreated \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\zipfile.py:1771\u001b[0m, in \u001b[0;36mZipFile.write\u001b[1;34m(self, filename, arcname, compress_type, compresslevel)\u001b[0m\n\u001b[0;32m   1769\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1770\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m src, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopen(zinfo, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m dest:\n\u001b[1;32m-> 1771\u001b[0m         \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopyfileobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\shutil.py:208\u001b[0m, in \u001b[0;36mcopyfileobj\u001b[1;34m(fsrc, fdst, length)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m buf:\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m \u001b[43mfdst_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\zipfile.py:1136\u001b[0m, in \u001b[0;36m_ZipWriteFile.write\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_crc \u001b[38;5;241m=\u001b[39m crc32(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_crc)\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compressor:\n\u001b[1;32m-> 1136\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compress_size \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data)\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fileobj\u001b[38;5;241m.\u001b[39mwrite(data)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# First, get all the child repository directories\n",
    "# child_repo_dir_paths = [item for item in root_project_path.iterdir() if item.is_dir()]\n",
    "## OUTPUTS: child_repo_dir_path_dict, child_repo_dir_names, child_repo_dir_paths\n",
    "\n",
    "# Define what to exclude when zipping\n",
    "def should_exclude(path):\n",
    "    exclude_patterns = [\n",
    "        '.git', '__pycache__', '.pytest_cache', '.vscode',\n",
    "        'node_modules', '.ipynb_checkpoints', '.egg-info'\n",
    "    ]\n",
    "    return any(pattern in str(path) for pattern in exclude_patterns)\n",
    "\n",
    "# Create timestamp for zip filenames\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Create a zip for each repository\n",
    "# for a_child_path in child_repo_dir_paths:\n",
    "for a_child_name, a_child_path in child_repo_dir_path_dict.items():\n",
    "    # Create zip filename with timestamp\n",
    "    # zip_filename = f\"{a_child_path.name}_{timestamp}.zip\"\n",
    "    zip_filename = f\"{a_child_path.name}.zip\"\n",
    "    zip_path = root_project_path / \"backups\" / zip_filename\n",
    "    \n",
    "    # Create backups directory if it doesn't exist\n",
    "    (root_project_path / \"backups\").mkdir(exist_ok=True)\n",
    "    \n",
    "    print(f\"Creating zip archive for {a_child_path.name}...\")\n",
    "    \n",
    "    # Create the zip file\n",
    "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        # Walk through directory and add files\n",
    "        for root, dirs, files in os.walk(a_child_path):\n",
    "            root_path = pathlib.Path(root)\n",
    "            \n",
    "            # Skip excluded directories\n",
    "            dirs[:] = [d for d in dirs if not should_exclude(root_path / d)]\n",
    "            \n",
    "            # Add files to zip\n",
    "            for file in files:\n",
    "                file_path = root_path / file\n",
    "                if not should_exclude(file_path):\n",
    "                    # Get relative path\n",
    "                    rel_path = file_path.relative_to(root_project_path)\n",
    "                    zipf.write(file_path, rel_path)\n",
    "    \n",
    "    print(f\"Created {zip_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository: matlab-to-neuropy-exporter\n",
      "Remote URL: https://github.com/CommanderPho/matlab-to-neuropy-exporter.git\n",
      "--------------------------------------------------\n",
      "Repository: NeuroPy\n",
      "Remote URL: https://github.com/CommanderPho/NeuroPy.git\n",
      "--------------------------------------------------\n",
      "Repository: pyPhoCoreHelpers\n",
      "Remote URL: https://github.com/CommanderPho/pyPhoCoreHelpers.git\n",
      "--------------------------------------------------\n",
      "Repository: pyPhoPlaceCellAnalysis\n",
      "Remote URL: https://github.com/CommanderPho/pyPhoPlaceCellAnalysis.git\n",
      "--------------------------------------------------\n",
      "Repository: pyqode.core\n",
      "Remote URL: https://github.com/CommanderPho/pyqode.core.git\n",
      "--------------------------------------------------\n",
      "Repository: pyqode.python\n",
      "Remote URL: https://github.com/CommanderPho/pyqode.python.git\n",
      "--------------------------------------------------\n",
      "Repository: Spike3D\n",
      "Remote URL: https://github.com/CommanderPho/Spike3D.git\n",
      "--------------------------------------------------\n",
      "\n",
      "Summary of repositories and their remote URLs:\n",
      "matlab-to-neuropy-exporter: https://github.com/CommanderPho/matlab-to-neuropy-exporter.git\n",
      "NeuroPy: https://github.com/CommanderPho/NeuroPy.git\n",
      "pyPhoCoreHelpers: https://github.com/CommanderPho/pyPhoCoreHelpers.git\n",
      "pyPhoPlaceCellAnalysis: https://github.com/CommanderPho/pyPhoPlaceCellAnalysis.git\n",
      "pyqode.core: https://github.com/CommanderPho/pyqode.core.git\n",
      "pyqode.python: https://github.com/CommanderPho/pyqode.python.git\n",
      "Spike3D: https://github.com/CommanderPho/Spike3D.git\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store repo names and their remote URLs\n",
    "repo_remote_urls = {}\n",
    "\n",
    "## INPUTS: child_repo_dir_path_dict\n",
    "\n",
    "# for a_child_path in child_repo_dir_paths:\n",
    "for a_child_name, a_child_path in child_repo_dir_path_dict.items():\n",
    "    try:\n",
    "        # Run git command to get the remote URL\n",
    "        result = subprocess.run(\n",
    "            ['git', '-C', str(a_child_path), 'remote', 'get-url', 'origin'],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=False  # Don't raise exception for non-zero return codes\n",
    "        )\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            remote_url = result.stdout.strip()\n",
    "            repo_remote_urls[a_child_path.name] = remote_url\n",
    "            print(f\"Repository: {a_child_path.name}\")\n",
    "            print(f\"Remote URL: {remote_url}\")\n",
    "            print(\"-\" * 50)\n",
    "        else:\n",
    "            print(f\"Warning: {a_child_path.name} might not be a git repository or doesn't have a remote named 'origin'\")\n",
    "            print(f\"Error: {result.stderr.strip()}\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {a_child_path.name}: {str(e)}\")\n",
    "\n",
    "# Now repo_remote_urls contains the mapping of repo names to their remote URLs\n",
    "print(\"\\nSummary of repositories and their remote URLs:\")\n",
    "for repo_name, url in repo_remote_urls.items():\n",
    "    print(f\"{repo_name}: {url}\")\n",
    "\n",
    "## OUTPUTS: repo_remote_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of repositories and their remote URLs:\n",
      "\"https://github.com/CommanderPho/matlab-to-neuropy-exporter\",\n",
      "\"https://github.com/CommanderPho/NeuroPy\",\n",
      "\"https://github.com/CommanderPho/pyPhoCoreHelpers\",\n",
      "\"https://github.com/CommanderPho/pyPhoPlaceCellAnalysis\",\n",
      "\"https://github.com/CommanderPho/pyqode.core\",\n",
      "\"https://github.com/CommanderPho/pyqode.python\",\n",
      "\"https://github.com/CommanderPho/Spike3D\",\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSummary of repositories and their remote URLs:\")\n",
    "for repo_name, url in repo_remote_urls.items():\n",
    "    # print(f\"{repo_name}: {url.strip('.git')}\")\n",
    "    print(f'\"{url.strip(\".git\")}\",')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'child_repo_dir_path_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 24\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m## INPUTS: child_repo_dir_path_dict, repo_remote_urls\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# for a_child_path in child_repo_dir_paths:\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# for a_child_name, a_child_path in child_repo_dir_path_dict.items():\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Usage example\u001b[39;00m\n\u001b[0;32m     23\u001b[0m repo_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnapari-spike3d\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 24\u001b[0m repo_disk_path: Path \u001b[38;5;241m=\u001b[39m \u001b[43mchild_repo_dir_path_dict\u001b[49m[repo_name]\n\u001b[0;32m     25\u001b[0m url \u001b[38;5;241m=\u001b[39m repo_remote_urls[repo_name]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'child_repo_dir_path_dict' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "## remove the flat repo and add it as a subrepo\n",
    "def convert_to_submodule(local_path: Path, remote_url: str):\n",
    "    \"\"\" remove the flat repo and add it as a subrepo \n",
    "    \"\"\"\n",
    "    # Ensure the directory exists\n",
    "    if not local_path.is_dir():\n",
    "        raise FileNotFoundError(f\"{local_path} is not a valid directory\")\n",
    "    \n",
    "    # Go to the parent directory\n",
    "    parent_dir = local_path.parent\n",
    "    \n",
    "    # Run git commands to remove the directory from tracking and add it as a submodule\n",
    "    subprocess.run(['git', 'rm', '-r', '--cached', str(local_path)], cwd=parent_dir, check=True)\n",
    "    subprocess.run(['git', 'submodule', 'add', remote_url, str(local_path)], cwd=parent_dir, check=True)\n",
    "    subprocess.run(['git', 'commit', '-m', f'Convert {local_path} to submodule'], cwd=parent_dir, check=True)\n",
    "\n",
    "## INPUTS: child_repo_dir_path_dict, repo_remote_urls\n",
    "\n",
    "# for a_child_path in child_repo_dir_paths:\n",
    "# for a_child_name, a_child_path in child_repo_dir_path_dict.items():\n",
    "\n",
    "# Usage example\n",
    "repo_name = 'napari-spike3d'\n",
    "repo_disk_path: Path = child_repo_dir_path_dict[repo_name]\n",
    "url = repo_remote_urls[repo_name]\n",
    "print(f'repo_name: {repo_name}')\n",
    "print(f'\\trepo_disk_path: {repo_disk_path}')\n",
    "print(f'\\turl: {url}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "convert_to_submodule(local_path=repo_disk_path, remote_url=url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_current_poetry_env()\n",
    "def get_current_poetry_env(working_dir=None) -> str:\n",
    "    if working_dir is not None:\n",
    "        curr_env_path = subprocess.check_output([f'poetry env list --full-path --directory={working_dir}'], shell=True)\n",
    "    else:\n",
    "        curr_env_path = subprocess.check_output(['poetry env list --full-path'], shell=True) # use the current working directory\n",
    "    return curr_env_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['poetry env list --full-path --directory=C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# curr_env_path = subprocess.check_output(['poetry env list --full-path'], shell=True)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m working_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(spike3D_path)\n\u001b[1;32m----> 3\u001b[0m curr_env_path \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpoetry env list --full-path --directory=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mworking_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m curr_env_path\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\subprocess.py:424\u001b[0m, in \u001b[0;36mcheck_output\u001b[1;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    421\u001b[0m         empty \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    422\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m empty\n\u001b[1;32m--> 424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m run(\u001b[38;5;241m*\u001b[39mpopenargs, stdout\u001b[38;5;241m=\u001b[39mPIPE, timeout\u001b[38;5;241m=\u001b[39mtimeout, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    425\u001b[0m            \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mstdout\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\subprocess.py:528\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    526\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mpoll()\n\u001b[0;32m    527\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[1;32m--> 528\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[0;32m    529\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[1;31mCalledProcessError\u001b[0m: Command '['poetry env list --full-path --directory=C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "# curr_env_path = subprocess.check_output(['poetry env list --full-path'], shell=True)\n",
    "working_dir = str(spike3D_path)\n",
    "curr_env_path = subprocess.check_output([f'poetry env list --full-path --directory={working_dir}'], shell=True)\n",
    "curr_env_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(spike3d-py3.9) C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D>poetry env list --full-path --directory=C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\n",
    "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv (Activated)\n",
    "W:\\FastSwap\\pypoetry_CACHE\\virtualenvs\\spike3d-UP7QTzFM-py3.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poetry_venv_path = Path('C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\.venv').resolve()\n",
    "assert poetry_venv_path.exists()\n",
    "assert poetry_venv_path.is_dir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "poetry_destination_venv = poetry_venv_path.parent.joinpath('.altvenv').resolve()\n",
    "print(f'poetry_destination_venv: {poetry_destination_venv}')\n",
    "assert not poetry_destination_venv.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_recursive(poetry_venv_path, poetry_destination_venv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the file paths to cscope.files\n",
    "with open(cscope_files, \"w\") as f:\n",
    "\tprint(f'writing to {cscope_files}...')\n",
    "\tfor file_path in all_found_files:\n",
    "\t\tf.write(str(file_path) + \"\\n\")\n",
    "\tprint('\\tdone.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_code_index(project_path, exclude_dirs=[]):\n",
    "    project_path = pathlib.Path(project_path)\n",
    "    cscope_files = project_path / \"cscope.files\"\n",
    "    cscope_out = project_path / \"cscope.out\"\n",
    "    tags = project_path / \"tags\"\n",
    "    db_path = project_path / \"myproject.db\"\n",
    "\n",
    "    # Find all .py files in the project directory and its subdirectories\n",
    "    py_files = project_path.glob(\"**/*.py\")\n",
    "    py_files = [file_path for file_path in py_files] # to list\n",
    "\n",
    "    excluded_py_files = []\n",
    "    if exclude_dirs is not None:\n",
    "        # Find all .py files in the project directory and its subdirectories, excluding the 'my_exclude_dir' directory\n",
    "        exclude_paths = [project_path.joinpath(a_dir) for a_dir in exclude_dirs]\n",
    "        for an_exclude_path in exclude_paths:\n",
    "            excluded_py_files.extend([file_path for file_path in an_exclude_path.glob(\"**/*.py\")])\n",
    "\n",
    "    included_py_files = [x for x in py_files if x not in excluded_py_files]\n",
    "\n",
    "    # Write the file paths to cscope.files\n",
    "    with open(project_path / \"cscope.files\", \"w\") as f:\n",
    "        for file_path in included_py_files:\n",
    "            f.write(str(file_path) + \"\\n\")\n",
    "\n",
    "    # Generate the cscope index\n",
    "    subprocess.run([\"pycscope\", \"-i\", str(cscope_files)], cwd=str(project_path), check=True)\n",
    "    \n",
    "    # Generate the ctags index\n",
    "    subprocess.run([\"ctags\", \"--fields=+i\", \"-n\", \"-L\", str(cscope_files)], cwd=str(project_path), check=True)\n",
    "    \n",
    "    # Generate the CodeQL database\n",
    "    subprocess.run([\"cqmakedb\", \"-s\", str(db_path), \"-c\", str(cscope_out), \"-t\", str(tags), \"-p\"], cwd=str(project_path), check=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_code_index(\"C:/Users/pho/repos/Spike3DWorkEnv/NeuroPy/neuropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_code_index(\"C:/Users/pho/repos/Spike3DWorkEnv/pyPhoCoreHelpers/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_code_index(\"C:/Users/pho/repos/Spike3DWorkEnv/pyPhoPlaceCellAnalysis/src\", exclude_dirs = [\"pyphoplacecellanalysis/External\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'src'\n",
    "'src'\n",
    "\n",
    "\n",
    "\"C:/Users/pho/repos/Spike3DWorkEnv/pyPhoPlaceCellAnalysis/src\", exclude_dirs = [\"pyphoplacecellanalysis/External\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open(this_file).read(), {'__file__': this_file})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_UV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
