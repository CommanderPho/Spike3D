{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "module_path: c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from typing import Dict, List, Tuple, Optional, Callable, Union, Any\n",
    "\n",
    "import subprocess\n",
    "import shutil\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from pyphocorehelpers.Filesystem.source_code_helpers import find_py_files\n",
    "# from pyphocorehelpers.Filesystem.poetry_helpers import get_current_poetry_env, copy_recursive\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "print(f'module_path: {module_path}')\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    print(f'appending to module_path...')\n",
    "    sys.path.append(module_path)\n",
    "    # sys.path.append(module_path+\"\\\\scripts\")\n",
    "    # sys.path.append(module_path+\"\\\\scripts\"+\"\\\\helpers\")\n",
    "    # sys.path.append(module_path+\"\\\\scripts\"+\"\\\\helpers\"+\"\\\\export_subrepos\")\n",
    "    \n",
    "# \\helpers\n",
    "\n",
    "# from .scripts.helpers.export_subrepos import export_poetry_repo\n",
    "# import scripts\n",
    "# import scripts.helpers.export_subrepos\n",
    "# from scripts.helpers.export_subrepos import export_poetry_repo # scripts.helpers.export_subrepos import export_poetry_repo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Spike3D.scripts.helpers.export_subrepos import export_poetry_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_project_path = pathlib.Path(\"C:/Users/pho/repos/Spike3DWorkEnv/\")\n",
    "assert root_project_path.exists()\n",
    "# repos_source_paths = [\"C:/Users/pho/repos/Spike3DWorkEnv/NeuroPy/neuropy\", \"C:/Users/pho/repos/Spike3DWorkEnv/pyPhoCoreHelpers/src\", \"C:/Users/pho/repos/Spike3DWorkEnv/pyPhoPlaceCellAnalysis/src\"]\n",
    "# repos_exclude_dir_lists = [None, None, [\"pyphoplacecellanalysis/External\"]]\n",
    "\n",
    "# all_found_files = []\n",
    "# for a_src_path, exclude_dirs in zip(repos_source_paths, repos_exclude_dir_lists):\n",
    "#     all_found_files.extend(find_py_files(a_src_path, exclude_dirs = exclude_dirs))\n",
    "\n",
    "\n",
    "spike3D_path = pathlib.Path(\"C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\").resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.devcontainer', '.git', '.idea', '.mypy_cache', '.vscode', 'backups', 'exports', 'flexitext', 'matlab-to-neuropy-exporter', 'maxlikespy', 'napari-spike3d', 'NeuroPy', 'pho_jupyter_preview_widget', 'portion', 'proplot', 'pylustrator', 'pyPhoCoreHelpers', 'pyPhoPlaceCellAnalysis', 'pyqode.core', 'pyqode.python', 'PyQtInspect-Open', 'PyQtWebEngine-5.15.7', 'SCRIPTS', 'silx', 'Spike3D', 'tests', 'TrajSeg']\n",
      "{'flexitext': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/flexitext'), 'maxlikespy': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/maxlikespy'), 'napari-spike3d': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/napari-spike3d'), 'pho_jupyter_preview_widget': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/pho_jupyter_preview_widget'), 'portion': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/portion'), 'proplot': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/proplot'), 'pylustrator': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/pylustrator'), 'PyQtInspect-Open': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/PyQtInspect-Open'), 'PyQtWebEngine-5.15.7': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/PyQtWebEngine-5.15.7'), 'silx': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/silx'), 'TrajSeg': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/TrajSeg')}\n"
     ]
    }
   ],
   "source": [
    "root_project_path: Path\n",
    "# Get full directory paths\n",
    "directory_paths = [str(item.name) for item in root_project_path.iterdir() if item.is_dir()]\n",
    "print(directory_paths)\n",
    "\n",
    "\n",
    "_default_child_repo_dir_names = ['matlab-to-neuropy-exporter', 'NeuroPy', 'pyPhoCoreHelpers', 'pyPhoPlaceCellAnalysis', 'pyqode.core', 'pyqode.python', 'Spike3D']\n",
    "\n",
    "child_repo_dir_names = ['flexitext', 'maxlikespy', 'napari-spike3d', 'pho_jupyter_preview_widget', 'portion', 'proplot', 'pylustrator', 'PyQtInspect-Open', 'PyQtWebEngine-5.15.7', 'silx', 'TrajSeg']\n",
    "\n",
    "child_repo_dir_paths = [item for item in root_project_path.iterdir() if (item.is_dir() and str(item.name) in child_repo_dir_names)]\n",
    "# print(child_repo_dir_paths)\n",
    "\n",
    "child_repo_dir_path_dict: Dict[str, Path] = dict(zip(child_repo_dir_names, child_repo_dir_paths))\n",
    "print(child_repo_dir_path_dict)\n",
    "## OUTPUTS: child_repo_dir_path_dict, child_repo_dir_names, child_repo_dir_paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating zip archive for flexitext...\n",
      "Created C:\\Users\\pho\\repos\\Spike3DWorkEnv\\backups\\flexitext.zip\n",
      "Creating zip archive for maxlikespy...\n",
      "Created C:\\Users\\pho\\repos\\Spike3DWorkEnv\\backups\\maxlikespy.zip\n",
      "Creating zip archive for napari-spike3d...\n",
      "Created C:\\Users\\pho\\repos\\Spike3DWorkEnv\\backups\\napari-spike3d.zip\n",
      "Creating zip archive for pho_jupyter_preview_widget...\n",
      "Created C:\\Users\\pho\\repos\\Spike3DWorkEnv\\backups\\pho_jupyter_preview_widget.zip\n",
      "Creating zip archive for portion...\n",
      "Created C:\\Users\\pho\\repos\\Spike3DWorkEnv\\backups\\portion.zip\n",
      "Creating zip archive for proplot...\n",
      "Created C:\\Users\\pho\\repos\\Spike3DWorkEnv\\backups\\proplot.zip\n",
      "Creating zip archive for pylustrator...\n",
      "Created C:\\Users\\pho\\repos\\Spike3DWorkEnv\\backups\\pylustrator.zip\n",
      "Creating zip archive for PyQtInspect-Open...\n",
      "Created C:\\Users\\pho\\repos\\Spike3DWorkEnv\\backups\\PyQtInspect-Open.zip\n",
      "Creating zip archive for PyQtWebEngine-5.15.7...\n",
      "Created C:\\Users\\pho\\repos\\Spike3DWorkEnv\\backups\\PyQtWebEngine-5.15.7.zip\n",
      "Creating zip archive for silx...\n",
      "Created C:\\Users\\pho\\repos\\Spike3DWorkEnv\\backups\\silx.zip\n",
      "Creating zip archive for TrajSeg...\n",
      "Created C:\\Users\\pho\\repos\\Spike3DWorkEnv\\backups\\TrajSeg.zip\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# First, get all the child repository directories\n",
    "# child_repo_dir_paths = [item for item in root_project_path.iterdir() if item.is_dir()]\n",
    "## OUTPUTS: child_repo_dir_path_dict, child_repo_dir_names, child_repo_dir_paths\n",
    "\n",
    "# Define what to exclude when zipping\n",
    "def should_exclude(path):\n",
    "    exclude_patterns = [\n",
    "        '.git', '__pycache__', '.pytest_cache', '.vscode',\n",
    "        'node_modules', '.ipynb_checkpoints', '.egg-info'\n",
    "    ]\n",
    "    return any(pattern in str(path) for pattern in exclude_patterns)\n",
    "\n",
    "# Create timestamp for zip filenames\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Create a zip for each repository\n",
    "# for a_child_path in child_repo_dir_paths:\n",
    "for a_child_name, a_child_path in child_repo_dir_path_dict.items():\n",
    "    # Create zip filename with timestamp\n",
    "    # zip_filename = f\"{a_child_path.name}_{timestamp}.zip\"\n",
    "    zip_filename = f\"{a_child_path.name}.zip\"\n",
    "    zip_path = root_project_path / \"backups\" / zip_filename\n",
    "    \n",
    "    # Create backups directory if it doesn't exist\n",
    "    (root_project_path / \"backups\").mkdir(exist_ok=True)\n",
    "    \n",
    "    print(f\"Creating zip archive for {a_child_path.name}...\")\n",
    "    \n",
    "    # Create the zip file\n",
    "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        # Walk through directory and add files\n",
    "        for root, dirs, files in os.walk(a_child_path):\n",
    "            root_path = pathlib.Path(root)\n",
    "            \n",
    "            # Skip excluded directories\n",
    "            dirs[:] = [d for d in dirs if not should_exclude(root_path / d)]\n",
    "            \n",
    "            # Add files to zip\n",
    "            for file in files:\n",
    "                file_path = root_path / file\n",
    "                if not should_exclude(file_path):\n",
    "                    # Get relative path\n",
    "                    rel_path = file_path.relative_to(root_project_path)\n",
    "                    zipf.write(file_path, rel_path)\n",
    "    \n",
    "    print(f\"Created {zip_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository: flexitext\n",
      "Remote URL: https://github.com/CommanderPho/flexitext.git\n",
      "--------------------------------------------------\n",
      "Repository: maxlikespy\n",
      "Remote URL: https://github.com/CommanderPho/maxlikespy.git\n",
      "--------------------------------------------------\n",
      "Repository: napari-spike3d\n",
      "Remote URL: https://github.com/CommanderPho/napari-spike3d.git\n",
      "--------------------------------------------------\n",
      "Repository: pho_jupyter_preview_widget\n",
      "Remote URL: https://github.com/CommanderPho/pho_jupyter_preview_widget.git\n",
      "--------------------------------------------------\n",
      "Repository: portion\n",
      "Remote URL: https://github.com/CommanderPho/portion.git\n",
      "--------------------------------------------------\n",
      "Repository: proplot\n",
      "Remote URL: https://github.com/CommanderPho/proplot.git\n",
      "--------------------------------------------------\n",
      "Repository: pylustrator\n",
      "Remote URL: https://github.com/CommanderPho/pylustrator.git\n",
      "--------------------------------------------------\n",
      "Repository: PyQtInspect-Open\n",
      "Remote URL: https://github.com/CommanderPho/PyQtInspect-Open.git\n",
      "--------------------------------------------------\n",
      "Repository: PyQtWebEngine-5.15.7\n",
      "Remote URL: https://github.com/CommanderPho/Spike3DWorkEnv.git\n",
      "--------------------------------------------------\n",
      "Repository: silx\n",
      "Remote URL: https://github.com/CommanderPho/silx.git\n",
      "--------------------------------------------------\n",
      "Repository: TrajSeg\n",
      "Remote URL: https://github.com/CommanderPho/TrajSeg.git\n",
      "--------------------------------------------------\n",
      "\n",
      "Summary of repositories and their remote URLs:\n",
      "flexitext: https://github.com/CommanderPho/flexitext.git\n",
      "maxlikespy: https://github.com/CommanderPho/maxlikespy.git\n",
      "napari-spike3d: https://github.com/CommanderPho/napari-spike3d.git\n",
      "pho_jupyter_preview_widget: https://github.com/CommanderPho/pho_jupyter_preview_widget.git\n",
      "portion: https://github.com/CommanderPho/portion.git\n",
      "proplot: https://github.com/CommanderPho/proplot.git\n",
      "pylustrator: https://github.com/CommanderPho/pylustrator.git\n",
      "PyQtInspect-Open: https://github.com/CommanderPho/PyQtInspect-Open.git\n",
      "PyQtWebEngine-5.15.7: https://github.com/CommanderPho/Spike3DWorkEnv.git\n",
      "silx: https://github.com/CommanderPho/silx.git\n",
      "TrajSeg: https://github.com/CommanderPho/TrajSeg.git\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store repo names and their remote URLs\n",
    "repo_remote_urls = {}\n",
    "\n",
    "## INPUTS: child_repo_dir_path_dict\n",
    "\n",
    "# for a_child_path in child_repo_dir_paths:\n",
    "for a_child_name, a_child_path in child_repo_dir_path_dict.items():\n",
    "    try:\n",
    "        # Run git command to get the remote URL\n",
    "        result = subprocess.run(\n",
    "            ['git', '-C', str(a_child_path), 'remote', 'get-url', 'origin'],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            check=False  # Don't raise exception for non-zero return codes\n",
    "        )\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            remote_url = result.stdout.strip()\n",
    "            repo_remote_urls[a_child_path.name] = remote_url\n",
    "            print(f\"Repository: {a_child_path.name}\")\n",
    "            print(f\"Remote URL: {remote_url}\")\n",
    "            print(\"-\" * 50)\n",
    "        else:\n",
    "            print(f\"Warning: {a_child_path.name} might not be a git repository or doesn't have a remote named 'origin'\")\n",
    "            print(f\"Error: {result.stderr.strip()}\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {a_child_path.name}: {str(e)}\")\n",
    "\n",
    "# Now repo_remote_urls contains the mapping of repo names to their remote URLs\n",
    "print(\"\\nSummary of repositories and their remote URLs:\")\n",
    "for repo_name, url in repo_remote_urls.items():\n",
    "    print(f\"{repo_name}: {url}\")\n",
    "\n",
    "## OUTPUTS: repo_remote_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repo_name: napari-spike3d\n",
      "\trepo_disk_path: C:\\Users\\pho\\repos\\Spike3DWorkEnv\\napari-spike3d\n",
      "\turl: https://github.com/CommanderPho/napari-spike3d.git\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## remove the flat repo and add it as a subrepo\n",
    "def convert_to_submodule(local_path: Path, remote_url: str):\n",
    "    \"\"\" remove the flat repo and add it as a subrepo \n",
    "    \"\"\"\n",
    "    # Ensure the directory exists\n",
    "    if not local_path.is_dir():\n",
    "        raise FileNotFoundError(f\"{local_path} is not a valid directory\")\n",
    "    \n",
    "    # Go to the parent directory\n",
    "    parent_dir = local_path.parent\n",
    "    \n",
    "    # Run git commands to remove the directory from tracking and add it as a submodule\n",
    "    subprocess.run(['git', 'rm', '-r', '--cached', str(local_path)], cwd=parent_dir, check=True)\n",
    "    subprocess.run(['git', 'submodule', 'add', remote_url, str(local_path)], cwd=parent_dir, check=True)\n",
    "    subprocess.run(['git', 'commit', '-m', f'Convert {local_path} to submodule'], cwd=parent_dir, check=True)\n",
    "\n",
    "## INPUTS: child_repo_dir_path_dict, repo_remote_urls\n",
    "\n",
    "# for a_child_path in child_repo_dir_paths:\n",
    "# for a_child_name, a_child_path in child_repo_dir_path_dict.items():\n",
    "\n",
    "# Usage example\n",
    "repo_name = 'napari-spike3d'\n",
    "repo_disk_path: Path = child_repo_dir_path_dict[repo_name]\n",
    "url = repo_remote_urls[repo_name]\n",
    "print(f'repo_name: {repo_name}')\n",
    "print(f'\\trepo_disk_path: {repo_disk_path}')\n",
    "print(f'\\turl: {url}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "convert_to_submodule(local_path=repo_disk_path, remote_url=url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_current_poetry_env()\n",
    "def get_current_poetry_env(working_dir=None) -> str:\n",
    "    if working_dir is not None:\n",
    "        curr_env_path = subprocess.check_output([f'poetry env list --full-path --directory={working_dir}'], shell=True)\n",
    "    else:\n",
    "        curr_env_path = subprocess.check_output(['poetry env list --full-path'], shell=True) # use the current working directory\n",
    "    return curr_env_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['poetry env list --full-path --directory=C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# curr_env_path = subprocess.check_output(['poetry env list --full-path'], shell=True)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m working_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(spike3D_path)\n\u001b[1;32m----> 3\u001b[0m curr_env_path \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpoetry env list --full-path --directory=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mworking_dir\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m curr_env_path\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\subprocess.py:424\u001b[0m, in \u001b[0;36mcheck_output\u001b[1;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    421\u001b[0m         empty \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    422\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m empty\n\u001b[1;32m--> 424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m run(\u001b[38;5;241m*\u001b[39mpopenargs, stdout\u001b[38;5;241m=\u001b[39mPIPE, timeout\u001b[38;5;241m=\u001b[39mtimeout, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    425\u001b[0m            \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mstdout\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\subprocess.py:528\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    526\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mpoll()\n\u001b[0;32m    527\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[1;32m--> 528\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[0;32m    529\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[1;31mCalledProcessError\u001b[0m: Command '['poetry env list --full-path --directory=C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "# curr_env_path = subprocess.check_output(['poetry env list --full-path'], shell=True)\n",
    "working_dir = str(spike3D_path)\n",
    "curr_env_path = subprocess.check_output([f'poetry env list --full-path --directory={working_dir}'], shell=True)\n",
    "curr_env_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(spike3d-py3.9) C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D>poetry env list --full-path --directory=C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\n",
    "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv (Activated)\n",
    "W:\\FastSwap\\pypoetry_CACHE\\virtualenvs\\spike3d-UP7QTzFM-py3.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poetry_venv_path = Path('C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\.venv').resolve()\n",
    "assert poetry_venv_path.exists()\n",
    "assert poetry_venv_path.is_dir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "poetry_destination_venv = poetry_venv_path.parent.joinpath('.altvenv').resolve()\n",
    "print(f'poetry_destination_venv: {poetry_destination_venv}')\n",
    "assert not poetry_destination_venv.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_recursive(poetry_venv_path, poetry_destination_venv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the file paths to cscope.files\n",
    "with open(cscope_files, \"w\") as f:\n",
    "\tprint(f'writing to {cscope_files}...')\n",
    "\tfor file_path in all_found_files:\n",
    "\t\tf.write(str(file_path) + \"\\n\")\n",
    "\tprint('\\tdone.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_code_index(project_path, exclude_dirs=[]):\n",
    "    project_path = pathlib.Path(project_path)\n",
    "    cscope_files = project_path / \"cscope.files\"\n",
    "    cscope_out = project_path / \"cscope.out\"\n",
    "    tags = project_path / \"tags\"\n",
    "    db_path = project_path / \"myproject.db\"\n",
    "\n",
    "    # Find all .py files in the project directory and its subdirectories\n",
    "    py_files = project_path.glob(\"**/*.py\")\n",
    "    py_files = [file_path for file_path in py_files] # to list\n",
    "\n",
    "    excluded_py_files = []\n",
    "    if exclude_dirs is not None:\n",
    "        # Find all .py files in the project directory and its subdirectories, excluding the 'my_exclude_dir' directory\n",
    "        exclude_paths = [project_path.joinpath(a_dir) for a_dir in exclude_dirs]\n",
    "        for an_exclude_path in exclude_paths:\n",
    "            excluded_py_files.extend([file_path for file_path in an_exclude_path.glob(\"**/*.py\")])\n",
    "\n",
    "    included_py_files = [x for x in py_files if x not in excluded_py_files]\n",
    "\n",
    "    # Write the file paths to cscope.files\n",
    "    with open(project_path / \"cscope.files\", \"w\") as f:\n",
    "        for file_path in included_py_files:\n",
    "            f.write(str(file_path) + \"\\n\")\n",
    "\n",
    "    # Generate the cscope index\n",
    "    subprocess.run([\"pycscope\", \"-i\", str(cscope_files)], cwd=str(project_path), check=True)\n",
    "    \n",
    "    # Generate the ctags index\n",
    "    subprocess.run([\"ctags\", \"--fields=+i\", \"-n\", \"-L\", str(cscope_files)], cwd=str(project_path), check=True)\n",
    "    \n",
    "    # Generate the CodeQL database\n",
    "    subprocess.run([\"cqmakedb\", \"-s\", str(db_path), \"-c\", str(cscope_out), \"-t\", str(tags), \"-p\"], cwd=str(project_path), check=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_code_index(\"C:/Users/pho/repos/Spike3DWorkEnv/NeuroPy/neuropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_code_index(\"C:/Users/pho/repos/Spike3DWorkEnv/pyPhoCoreHelpers/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_code_index(\"C:/Users/pho/repos/Spike3DWorkEnv/pyPhoPlaceCellAnalysis/src\", exclude_dirs = [\"pyphoplacecellanalysis/External\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'src'\n",
    "'src'\n",
    "\n",
    "\n",
    "\"C:/Users/pho/repos/Spike3DWorkEnv/pyPhoPlaceCellAnalysis/src\", exclude_dirs = [\"pyphoplacecellanalysis/External\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open(this_file).read(), {'__file__': this_file})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spike3d-global-poetry",
   "language": "python",
   "name": "spike3d-global-poetry"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
