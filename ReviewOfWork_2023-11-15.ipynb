{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "# %load_ext viztracer\n",
    "# from viztracer import VizTracer\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "from copy import deepcopy\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "# pd.options.mode.dtype_backend = 'pyarrow' # use new pyarrow backend instead of numpy\n",
    "from attrs import define, field, fields, Factory\n",
    "import tables as tb\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Pho's Formatting Preferences\n",
    "from pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\n",
    "set_pho_preferences_concise()\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "# from neuropy import core\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.core.epoch import NamedTimerange, Epoch\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.utils.matplotlib_helpers import matplotlib_file_only, matplotlib_configuration, matplotlib_configuration_update\n",
    "from neuropy.core.neuron_identities import NeuronIdentityTable, neuronTypesList, neuronTypesEnum\n",
    "from neuropy.utils.mixins.AttrsClassHelpers import AttrsBasedClassHelperMixin, serialized_field, serialized_attribute_field, non_serialized_field, custom_define\n",
    "from neuropy.utils.mixins.HDF5_representable import HDF_DeserializationMixin, post_deserialize, HDF_SerializationMixin, HDFMixin, HDF_Converter\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "from neuropy.core.neurons import NeuronType\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from neuropy.core.position import Position\n",
    "from neuropy.core.session.dataSession import DataSession\n",
    "from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent, PlacefieldSnapshot\n",
    "from neuropy.utils.debug_helpers import debug_print_placefield, debug_print_subsession_neuron_differences, debug_print_ratemap, debug_print_spike_counts, debug_plot_2d_binning, print_aligned_columns\n",
    "from neuropy.utils.debug_helpers import parameter_sweeps, _plot_parameter_sweep, compare_placefields_info\n",
    "\n",
    "from pyphocorehelpers.print_helpers import print_object_memory_usage, print_dataframe_memory_usage, print_value_overview_only, DocumentationFilePrinter, print_keys_if_possible, generate_html_string, CapturedException, document_active_variables\n",
    "from pyphocorehelpers.general_helpers import GeneratedClassDefinitionType, CodeConversion, inspect_callable_arguments\n",
    "\n",
    "## Pho Programming Helpers:\n",
    "import inspect\n",
    "from pyphocorehelpers.general_helpers import inspect_callable_arguments, get_arguments_as_optional_dict, GeneratedClassDefinitionType, CodeConversion\n",
    "from pyphocorehelpers.print_helpers import DocumentationFilePrinter, TypePrintMode, print_keys_if_possible, debug_dump_object_member_shapes, print_value_overview_only, document_active_variables, CapturedException\n",
    "from pyphocorehelpers.programming_helpers import IPythonHelpers, PythonDictionaryDefinitionFormat, MemoryManagement\n",
    "from pyphocorehelpers.gui.Qt.TopLevelWindowHelper import TopLevelWindowHelper, print_widget_hierarchy\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_load_session, batch_extended_computations, batch_extended_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import _find_any_context_neurons\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchSessionCompletionHandler # for `post_compute_validate(...)`\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BasePositionDecoder\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsResults\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends # for `_perform_long_short_instantaneous_spike_rate_groups_analysis`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import SingleBarResult, InstantaneousSpikeRateGroupsComputation, TruncationCheckingResults # for `BatchSessionCompletionHandler`, `AcrossSessionsAggregator`\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import SplitPartitionMembership\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalComputationFunctions\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderGlobalComputationFunctions\n",
    "\n",
    "\n",
    "# Plotting\n",
    "# import pylustrator # customization of figures\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "# import pylustrator # call `pylustrator.start()` before creating your first figure in code.\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap_pyqtgraph # used in `plot_kourosh_activity_style_figure`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot, plot_raster_plot\n",
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import DataSeriesColorHelpers\n",
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import UnitColoringMode, DataSeriesColorHelpers\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import _build_default_tick, build_scatter_plot_kwargs\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.Render2DScrollWindowPlot import Render2DScrollWindowPlotMixin, ScatterItemData\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_extended_programmatic_figures, batch_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PAPER_FIGURE_figure_1_add_replay_epoch_rasters, PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_3, main_complete_figure_generations\n",
    "from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import *\n",
    "\n",
    "# Jupyter Widget Interactive\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import interactive_pipeline_widget, fullwidth_path_widget, interactive_pipeline_files\n",
    "from pyphocorehelpers.gui.Jupyter.simple_widgets import render_colors\n",
    "\n",
    "global_data_root_parent_path = find_first_extant_path([Path(r'W:\\Data'), Path(r'/media/MAX/Data'), Path(r'/home/halechr/FastData'), Path(r'/Volumes/MoverNew/data'), Path(r'/home/halechr/turbo/Data'), Path(r'/home/halechr/cloud/turbo/Data')])\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30db844b",
   "metadata": {},
   "source": [
    "# Load Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "233d2b8a",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basedir: W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\n",
      "Loading loaded session pickle file results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\loadedSessPickle.pkl... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:NeuropyPipeline.__setstate__(state=\"{'pipeline_name': 'kdiba_pipeline', 'session_data_type': 'kdiba', '_stage': <pyphoplacecellanalysis.General.Pipeline.Stages.Display.DisplayPipelineStage object at 0x00000184EEE3D4C0>}\")\n",
      "INFO:com.PhoHale.Spike3D.pipeline:select_filters(...) with: []\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_even\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_even\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_even\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_any\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_any\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_any\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing global computations...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:select_filters(...) with: []\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_even\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_even\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_even\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_any\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_any\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_any\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing global computations...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:select_filters(...) with: []\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Loading pickled pipeline success: W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['pf_computation', 'firing_rate_trends', 'position_decoding']\n",
      "curr_active_computation_params.pf_params.computation_epochs: 20 epochs\n",
      "array([[31.8625, 39.7703],\n",
      "       [161.459, 167.332],\n",
      "       [255.121, 262.696],\n",
      "       [314.047, 319.385],\n",
      "       [511.579, 518.353],\n",
      "       [558.36, 565.501],\n",
      "       [599.268, 604.74],\n",
      "       [645.747, 655.19],\n",
      "       [692.428, 697.566],\n",
      "       [734.337, 741.178],\n",
      "       [763.133, 768.971],\n",
      "       [804.742, 812.149],\n",
      "       [848.687, 853.692],\n",
      "       [941.846, 951.456],\n",
      "       [997.202, 1002.31],\n",
      "       [1035.51, 1040.75],\n",
      "       [1068.04, 1074.35],\n",
      "       [1104.61, 1110.12],\n",
      "       [1163.44, 1167.77],\n",
      "       [1195.03, 1203.64]])\n",
      "\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "curr_active_computation_params.pf_params.computation_epochs: 20 epochs\n",
      "array([[1258.37, 1265.44],\n",
      "       [1342.82, 1346.29],\n",
      "       [1380.25, 1383.93],\n",
      "       [1405.61, 1409.85],\n",
      "       [1431.51, 1436.01],\n",
      "       [1561.97, 1566.98],\n",
      "       [1588.53, 1591.87],\n",
      "       [1610.79, 1617.49],\n",
      "       [1637.85, 1643.72],\n",
      "       [1665.08, 1669.51],\n",
      "       [1692.64, 1697.44],\n",
      "       [1714.82, 1721.4],\n",
      "       [1752, 1756.37],\n",
      "       [1901.38, 1907.05],\n",
      "       [1928.87, 1933.58],\n",
      "       [1953.17, 1964.44],\n",
      "       [1979.19, 1990.7],\n",
      "       [2002.88, 2008.29],\n",
      "       [2026.01, 2031.38],\n",
      "       [2057.64, 2068.85]])\n",
      "\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "curr_active_computation_params.pf_params.computation_epochs: 40 epochs\n",
      "array([[31.8625, 39.7703],\n",
      "       [161.459, 167.332],\n",
      "       [255.121, 262.696],\n",
      "       [314.047, 319.385],\n",
      "       [511.579, 518.353],\n",
      "       [558.36, 565.501],\n",
      "       [599.268, 604.74],\n",
      "       [645.747, 655.19],\n",
      "       [692.428, 697.566],\n",
      "       [734.337, 741.178],\n",
      "       [763.133, 768.971],\n",
      "       [804.742, 812.149],\n",
      "       [848.687, 853.692],\n",
      "       [941.846, 951.456],\n",
      "       [997.202, 1002.31],\n",
      "       [1035.51, 1040.75],\n",
      "       [1068.04, 1074.35],\n",
      "       [1104.61, 1110.12],\n",
      "       [1163.44, 1167.77],\n",
      "       [1195.03, 1203.64],\n",
      "       [1258.37, 1265.44],\n",
      "       [1342.82, 1346.29],\n",
      "       [1380.25, 1383.93],\n",
      "       [1405.61, 1409.85],\n",
      "       [1431.51, 1436.01],\n",
      "       [1561.97, 1566.98],\n",
      "       [1588.53, 1591.87],\n",
      "       [1610.79, 1617.49],\n",
      "       [1637.85, 1643.72],\n",
      "       [1665.08, 1669.51],\n",
      "       [1692.64, 1697.44],\n",
      "       [1714.82, 1721.4],\n",
      "       [1752, 1756.37],\n",
      "       [1901.38, 1907.05],\n",
      "       [1928.87, 1933.58],\n",
      "       [1953.17, 1964.44],\n",
      "       [1979.19, 1990.7],\n",
      "       [2002.88, 2008.29],\n",
      "       [2026.01, 2031.38],\n",
      "       [2057.64, 2068.85]])\n",
      "\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "curr_active_computation_params.pf_params.computation_epochs: 20 epochs\n",
      "array([[31.8625, 39.7703],\n",
      "       [161.459, 167.332],\n",
      "       [255.121, 262.696],\n",
      "       [314.047, 319.385],\n",
      "       [511.579, 518.353],\n",
      "       [558.36, 565.501],\n",
      "       [599.268, 604.74],\n",
      "       [645.747, 655.19],\n",
      "       [692.428, 697.566],\n",
      "       [734.337, 741.178],\n",
      "       [763.133, 768.971],\n",
      "       [804.742, 812.149],\n",
      "       [848.687, 853.692],\n",
      "       [941.846, 951.456],\n",
      "       [997.202, 1002.31],\n",
      "       [1035.51, 1040.75],\n",
      "       [1068.04, 1074.35],\n",
      "       [1104.61, 1110.12],\n",
      "       [1163.44, 1167.77],\n",
      "       [1195.03, 1203.64]])\n",
      "\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "curr_active_computation_params.pf_params.computation_epochs: 20 epochs\n",
      "array([[1258.37, 1265.44],\n",
      "       [1342.82, 1346.29],\n",
      "       [1380.25, 1383.93],\n",
      "       [1405.61, 1409.85],\n",
      "       [1431.51, 1436.01],\n",
      "       [1561.97, 1566.98],\n",
      "       [1588.53, 1591.87],\n",
      "       [1610.79, 1617.49],\n",
      "       [1637.85, 1643.72],\n",
      "       [1665.08, 1669.51],\n",
      "       [1692.64, 1697.44],\n",
      "       [1714.82, 1721.4],\n",
      "       [1752, 1756.37],\n",
      "       [1901.38, 1907.05],\n",
      "       [1928.87, 1933.58],\n",
      "       [1953.17, 1964.44],\n",
      "       [1979.19, 1990.7],\n",
      "       [2002.88, 2008.29],\n",
      "       [2026.01, 2031.38],\n",
      "       [2057.64, 2068.85]])\n",
      "\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "curr_active_computation_params.pf_params.computation_epochs: 40 epochs\n",
      "array([[31.8625, 39.7703],\n",
      "       [161.459, 167.332],\n",
      "       [255.121, 262.696],\n",
      "       [314.047, 319.385],\n",
      "       [511.579, 518.353],\n",
      "       [558.36, 565.501],\n",
      "       [599.268, 604.74],\n",
      "       [645.747, 655.19],\n",
      "       [692.428, 697.566],\n",
      "       [734.337, 741.178],\n",
      "       [763.133, 768.971],\n",
      "       [804.742, 812.149],\n",
      "       [848.687, 853.692],\n",
      "       [941.846, 951.456],\n",
      "       [997.202, 1002.31],\n",
      "       [1035.51, 1040.75],\n",
      "       [1068.04, 1074.35],\n",
      "       [1104.61, 1110.12],\n",
      "       [1163.44, 1167.77],\n",
      "       [1195.03, 1203.64],\n",
      "       [1258.37, 1265.44],\n",
      "       [1342.82, 1346.29],\n",
      "       [1380.25, 1383.93],\n",
      "       [1405.61, 1409.85],\n",
      "       [1431.51, 1436.01],\n",
      "       [1561.97, 1566.98],\n",
      "       [1588.53, 1591.87],\n",
      "       [1610.79, 1617.49],\n",
      "       [1637.85, 1643.72],\n",
      "       [1665.08, 1669.51],\n",
      "       [1692.64, 1697.44],\n",
      "       [1714.82, 1721.4],\n",
      "       [1752, 1756.37],\n",
      "       [1901.38, 1907.05],\n",
      "       [1928.87, 1933.58],\n",
      "       [1953.17, 1964.44],\n",
      "       [1979.19, 1990.7],\n",
      "       [2002.88, 2008.29],\n",
      "       [2026.01, 2031.38],\n",
      "       [2057.64, 2068.85]])\n",
      "\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "curr_active_computation_params.pf_params.computation_epochs: 20 epochs\n",
      "array([[31.8625, 39.7703],\n",
      "       [161.459, 167.332],\n",
      "       [255.121, 262.696],\n",
      "       [314.047, 319.385],\n",
      "       [511.579, 518.353],\n",
      "       [558.36, 565.501],\n",
      "       [599.268, 604.74],\n",
      "       [645.747, 655.19],\n",
      "       [692.428, 697.566],\n",
      "       [734.337, 741.178],\n",
      "       [763.133, 768.971],\n",
      "       [804.742, 812.149],\n",
      "       [848.687, 853.692],\n",
      "       [941.846, 951.456],\n",
      "       [997.202, 1002.31],\n",
      "       [1035.51, 1040.75],\n",
      "       [1068.04, 1074.35],\n",
      "       [1104.61, 1110.12],\n",
      "       [1163.44, 1167.77],\n",
      "       [1195.03, 1203.64]])\n",
      "\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "curr_active_computation_params.pf_params.computation_epochs: 20 epochs\n",
      "array([[1258.37, 1265.44],\n",
      "       [1342.82, 1346.29],\n",
      "       [1380.25, 1383.93],\n",
      "       [1405.61, 1409.85],\n",
      "       [1431.51, 1436.01],\n",
      "       [1561.97, 1566.98],\n",
      "       [1588.53, 1591.87],\n",
      "       [1610.79, 1617.49],\n",
      "       [1637.85, 1643.72],\n",
      "       [1665.08, 1669.51],\n",
      "       [1692.64, 1697.44],\n",
      "       [1714.82, 1721.4],\n",
      "       [1752, 1756.37],\n",
      "       [1901.38, 1907.05],\n",
      "       [1928.87, 1933.58],\n",
      "       [1953.17, 1964.44],\n",
      "       [1979.19, 1990.7],\n",
      "       [2002.88, 2008.29],\n",
      "       [2026.01, 2031.38],\n",
      "       [2057.64, 2068.85]])\n",
      "\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "curr_active_computation_params.pf_params.computation_epochs: 40 epochs\n",
      "array([[31.8625, 39.7703],\n",
      "       [161.459, 167.332],\n",
      "       [255.121, 262.696],\n",
      "       [314.047, 319.385],\n",
      "       [511.579, 518.353],\n",
      "       [558.36, 565.501],\n",
      "       [599.268, 604.74],\n",
      "       [645.747, 655.19],\n",
      "       [692.428, 697.566],\n",
      "       [734.337, 741.178],\n",
      "       [763.133, 768.971],\n",
      "       [804.742, 812.149],\n",
      "       [848.687, 853.692],\n",
      "       [941.846, 951.456],\n",
      "       [997.202, 1002.31],\n",
      "       [1035.51, 1040.75],\n",
      "       [1068.04, 1074.35],\n",
      "       [1104.61, 1110.12],\n",
      "       [1163.44, 1167.77],\n",
      "       [1195.03, 1203.64],\n",
      "       [1258.37, 1265.44],\n",
      "       [1342.82, 1346.29],\n",
      "       [1380.25, 1383.93],\n",
      "       [1405.61, 1409.85],\n",
      "       [1431.51, 1436.01],\n",
      "       [1561.97, 1566.98],\n",
      "       [1588.53, 1591.87],\n",
      "       [1610.79, 1617.49],\n",
      "       [1637.85, 1643.72],\n",
      "       [1665.08, 1669.51],\n",
      "       [1692.64, 1697.44],\n",
      "       [1714.82, 1721.4],\n",
      "       [1752, 1756.37],\n",
      "       [1901.38, 1907.05],\n",
      "       [1928.87, 1933.58],\n",
      "       [1953.17, 1964.44],\n",
      "       [1979.19, 1990.7],\n",
      "       [2002.88, 2008.29],\n",
      "       [2026.01, 2031.38],\n",
      "       [2057.64, 2068.85]])\n",
      "\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "curr_active_computation_params.pf_params.computation_epochs: 20 epochs\n",
      "array([[5.63587, 17.4478],\n",
      "       [135.802, 144.176],\n",
      "       [234.466, 239.807],\n",
      "       [294.026, 299.8],\n",
      "       [499.299, 504.806],\n",
      "       [530.199, 540.641],\n",
      "       [584.353, 591.26],\n",
      "       [616.819, 625.728],\n",
      "       [678.314, 684.688],\n",
      "       [712.482, 721.725],\n",
      "       [750.488, 755.224],\n",
      "       [782.252, 788.224],\n",
      "       [825.695, 832.236],\n",
      "       [923.895, 933.705],\n",
      "       [971.844, 983.954],\n",
      "       [1010.48, 1024.66],\n",
      "       [1052.42, 1059.73],\n",
      "       [1086.99, 1093.57],\n",
      "       [1123.53, 1130.4],\n",
      "       [1179.02, 1187.23]])\n",
      "\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "curr_active_computation_params.pf_params.computation_epochs: 20 epochs\n",
      "array([[1237.71, 1244.52],\n",
      "       [1330.54, 1336.31],\n",
      "       [1362.87, 1367.01],\n",
      "       [1394.34, 1400.44],\n",
      "       [1413.86, 1422.26],\n",
      "       [1551.66, 1559],\n",
      "       [1574.65, 1583.26],\n",
      "       [1603.68, 1610.32],\n",
      "       [1627.47, 1633.01],\n",
      "       [1649.83, 1655.67],\n",
      "       [1678.89, 1683.29],\n",
      "       [1706.95, 1711.12],\n",
      "       [1743.69, 1748.76],\n",
      "       [1894.74, 1901.35],\n",
      "       [1917.86, 1923.4],\n",
      "       [1939.69, 1948.33],\n",
      "       [1971.98, 1977.46],\n",
      "       [1998.98, 2002.85],\n",
      "       [2019.13, 2024.91],\n",
      "       [2037.62, 2042.29]])\n",
      "\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "curr_active_computation_params.pf_params.computation_epochs: 40 epochs\n",
      "array([[5.63587, 17.4478],\n",
      "       [135.802, 144.176],\n",
      "       [234.466, 239.807],\n",
      "       [294.026, 299.8],\n",
      "       [499.299, 504.806],\n",
      "       [530.199, 540.641],\n",
      "       [584.353, 591.26],\n",
      "       [616.819, 625.728],\n",
      "       [678.314, 684.688],\n",
      "       [712.482, 721.725],\n",
      "       [750.488, 755.224],\n",
      "       [782.252, 788.224],\n",
      "       [825.695, 832.236],\n",
      "       [923.895, 933.705],\n",
      "       [971.844, 983.954],\n",
      "       [1010.48, 1024.66],\n",
      "       [1052.42, 1059.73],\n",
      "       [1086.99, 1093.57],\n",
      "       [1123.53, 1130.4],\n",
      "       [1179.02, 1187.23],\n",
      "       [1237.71, 1244.52],\n",
      "       [1330.54, 1336.31],\n",
      "       [1362.87, 1367.01],\n",
      "       [1394.34, 1400.44],\n",
      "       [1413.86, 1422.26],\n",
      "       [1551.66, 1559],\n",
      "       [1574.65, 1583.26],\n",
      "       [1603.68, 1610.32],\n",
      "       [1627.47, 1633.01],\n",
      "       [1649.83, 1655.67],\n",
      "       [1678.89, 1683.29],\n",
      "       [1706.95, 1711.12],\n",
      "       [1743.69, 1748.76],\n",
      "       [1894.74, 1901.35],\n",
      "       [1917.86, 1923.4],\n",
      "       [1939.69, 1948.33],\n",
      "       [1971.98, 1977.46],\n",
      "       [1998.98, 2002.85],\n",
      "       [2019.13, 2024.91],\n",
      "       [2037.62, 2042.29]])\n",
      "\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "curr_active_computation_params.pf_params.computation_epochs: 20 epochs\n",
      "array([[5.63587, 17.4478],\n",
      "       [135.802, 144.176],\n",
      "       [234.466, 239.807],\n",
      "       [294.026, 299.8],\n",
      "       [499.299, 504.806],\n",
      "       [530.199, 540.641],\n",
      "       [584.353, 591.26],\n",
      "       [616.819, 625.728],\n",
      "       [678.314, 684.688],\n",
      "       [712.482, 721.725],\n",
      "       [750.488, 755.224],\n",
      "       [782.252, 788.224],\n",
      "       [825.695, 832.236],\n",
      "       [923.895, 933.705],\n",
      "       [971.844, 983.954],\n",
      "       [1010.48, 1024.66],\n",
      "       [1052.42, 1059.73],\n",
      "       [1086.99, 1093.57],\n",
      "       [1123.53, 1130.4],\n",
      "       [1179.02, 1187.23]])\n",
      "\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "curr_active_computation_params.pf_params.computation_epochs: 20 epochs\n",
      "array([[1237.71, 1244.52],\n",
      "       [1330.54, 1336.31],\n",
      "       [1362.87, 1367.01],\n",
      "       [1394.34, 1400.44],\n",
      "       [1413.86, 1422.26],\n",
      "       [1551.66, 1559],\n",
      "       [1574.65, 1583.26],\n",
      "       [1603.68, 1610.32],\n",
      "       [1627.47, 1633.01],\n",
      "       [1649.83, 1655.67],\n",
      "       [1678.89, 1683.29],\n",
      "       [1706.95, 1711.12],\n",
      "       [1743.69, 1748.76],\n",
      "       [1894.74, 1901.35],\n",
      "       [1917.86, 1923.4],\n",
      "       [1939.69, 1948.33],\n",
      "       [1971.98, 1977.46],\n",
      "       [1998.98, 2002.85],\n",
      "       [2019.13, 2024.91],\n",
      "       [2037.62, 2042.29]])\n",
      "\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "curr_active_computation_params.pf_params.computation_epochs: 40 epochs\n",
      "array([[5.63587, 17.4478],\n",
      "       [135.802, 144.176],\n",
      "       [234.466, 239.807],\n",
      "       [294.026, 299.8],\n",
      "       [499.299, 504.806],\n",
      "       [530.199, 540.641],\n",
      "       [584.353, 591.26],\n",
      "       [616.819, 625.728],\n",
      "       [678.314, 684.688],\n",
      "       [712.482, 721.725],\n",
      "       [750.488, 755.224],\n",
      "       [782.252, 788.224],\n",
      "       [825.695, 832.236],\n",
      "       [923.895, 933.705],\n",
      "       [971.844, 983.954],\n",
      "       [1010.48, 1024.66],\n",
      "       [1052.42, 1059.73],\n",
      "       [1086.99, 1093.57],\n",
      "       [1123.53, 1130.4],\n",
      "       [1179.02, 1187.23],\n",
      "       [1237.71, 1244.52],\n",
      "       [1330.54, 1336.31],\n",
      "       [1362.87, 1367.01],\n",
      "       [1394.34, 1400.44],\n",
      "       [1413.86, 1422.26],\n",
      "       [1551.66, 1559],\n",
      "       [1574.65, 1583.26],\n",
      "       [1603.68, 1610.32],\n",
      "       [1627.47, 1633.01],\n",
      "       [1649.83, 1655.67],\n",
      "       [1678.89, 1683.29],\n",
      "       [1706.95, 1711.12],\n",
      "       [1743.69, 1748.76],\n",
      "       [1894.74, 1901.35],\n",
      "       [1917.86, 1923.4],\n",
      "       [1939.69, 1948.33],\n",
      "       [1971.98, 1977.46],\n",
      "       [1998.98, 2002.85],\n",
      "       [2019.13, 2024.91],\n",
      "       [2037.62, 2042.29]])\n",
      "\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "curr_active_computation_params.pf_params.computation_epochs: 20 epochs\n",
      "array([[5.63587, 17.4478],\n",
      "       [135.802, 144.176],\n",
      "       [234.466, 239.807],\n",
      "       [294.026, 299.8],\n",
      "       [499.299, 504.806],\n",
      "       [530.199, 540.641],\n",
      "       [584.353, 591.26],\n",
      "       [616.819, 625.728],\n",
      "       [678.314, 684.688],\n",
      "       [712.482, 721.725],\n",
      "       [750.488, 755.224],\n",
      "       [782.252, 788.224],\n",
      "       [825.695, 832.236],\n",
      "       [923.895, 933.705],\n",
      "       [971.844, 983.954],\n",
      "       [1010.48, 1024.66],\n",
      "       [1052.42, 1059.73],\n",
      "       [1086.99, 1093.57],\n",
      "       [1123.53, 1130.4],\n",
      "       [1179.02, 1187.23]])\n",
      "\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "curr_active_computation_params.pf_params.computation_epochs: 20 epochs\n",
      "array([[1237.71, 1244.52],\n",
      "       [1330.54, 1336.31],\n",
      "       [1362.87, 1367.01],\n",
      "       [1394.34, 1400.44],\n",
      "       [1413.86, 1422.26],\n",
      "       [1551.66, 1559],\n",
      "       [1574.65, 1583.26],\n",
      "       [1603.68, 1610.32],\n",
      "       [1627.47, 1633.01],\n",
      "       [1649.83, 1655.67],\n",
      "       [1678.89, 1683.29],\n",
      "       [1706.95, 1711.12],\n",
      "       [1743.69, 1748.76],\n",
      "       [1894.74, 1901.35],\n",
      "       [1917.86, 1923.4],\n",
      "       [1939.69, 1948.33],\n",
      "       [1971.98, 1977.46],\n",
      "       [1998.98, 2002.85],\n",
      "       [2019.13, 2024.91],\n",
      "       [2037.62, 2042.29]])\n",
      "\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "curr_active_computation_params.pf_params.computation_epochs: 40 epochs\n",
      "array([[5.63587, 17.4478],\n",
      "       [135.802, 144.176],\n",
      "       [234.466, 239.807],\n",
      "       [294.026, 299.8],\n",
      "       [499.299, 504.806],\n",
      "       [530.199, 540.641],\n",
      "       [584.353, 591.26],\n",
      "       [616.819, 625.728],\n",
      "       [678.314, 684.688],\n",
      "       [712.482, 721.725],\n",
      "       [750.488, 755.224],\n",
      "       [782.252, 788.224],\n",
      "       [825.695, 832.236],\n",
      "       [923.895, 933.705],\n",
      "       [971.844, 983.954],\n",
      "       [1010.48, 1024.66],\n",
      "       [1052.42, 1059.73],\n",
      "       [1086.99, 1093.57],\n",
      "       [1123.53, 1130.4],\n",
      "       [1179.02, 1187.23],\n",
      "       [1237.71, 1244.52],\n",
      "       [1330.54, 1336.31],\n",
      "       [1362.87, 1367.01],\n",
      "       [1394.34, 1400.44],\n",
      "       [1413.86, 1422.26],\n",
      "       [1551.66, 1559],\n",
      "       [1574.65, 1583.26],\n",
      "       [1603.68, 1610.32],\n",
      "       [1627.47, 1633.01],\n",
      "       [1649.83, 1655.67],\n",
      "       [1678.89, 1683.29],\n",
      "       [1706.95, 1711.12],\n",
      "       [1743.69, 1748.76],\n",
      "       [1894.74, 1901.35],\n",
      "       [1917.86, 1923.4],\n",
      "       [1939.69, 1948.33],\n",
      "       [1971.98, 1977.46],\n",
      "       [1998.98, 2002.85],\n",
      "       [2019.13, 2024.91],\n",
      "       [2037.62, 2042.29]])\n",
      "\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "curr_active_computation_params.pf_params.computation_epochs: 40 epochs\n",
      "array([[5.63587, 17.4478],\n",
      "       [31.8625, 39.7703],\n",
      "       [135.802, 144.176],\n",
      "       [161.459, 167.332],\n",
      "       [234.466, 239.807],\n",
      "       [255.121, 262.696],\n",
      "       [294.026, 299.8],\n",
      "       [314.047, 319.385],\n",
      "       [499.299, 504.806],\n",
      "       [511.579, 518.353],\n",
      "       [530.199, 540.641],\n",
      "       [558.36, 565.501],\n",
      "       [584.353, 591.26],\n",
      "       [599.268, 604.74],\n",
      "       [616.819, 625.728],\n",
      "       [645.747, 655.19],\n",
      "       [678.314, 684.688],\n",
      "       [692.428, 697.566],\n",
      "       [712.482, 721.725],\n",
      "       [734.337, 741.178],\n",
      "       [750.488, 755.224],\n",
      "       [763.133, 768.971],\n",
      "       [782.252, 788.224],\n",
      "       [804.742, 812.149],\n",
      "       [825.695, 832.236],\n",
      "       [848.687, 853.692],\n",
      "       [923.895, 933.705],\n",
      "       [941.846, 951.456],\n",
      "       [971.844, 983.954],\n",
      "       [997.202, 1002.31],\n",
      "       [1010.48, 1024.66],\n",
      "       [1035.51, 1040.75],\n",
      "       [1052.42, 1059.73],\n",
      "       [1068.04, 1074.35],\n",
      "       [1086.99, 1093.57],\n",
      "       [1104.61, 1110.12],\n",
      "       [1123.53, 1130.4],\n",
      "       [1163.44, 1167.77],\n",
      "       [1179.02, 1187.23],\n",
      "       [1195.03, 1203.64]])\n",
      "\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "curr_active_computation_params.pf_params.computation_epochs: 40 epochs\n",
      "array([[1237.71, 1244.52],\n",
      "       [1258.37, 1265.44],\n",
      "       [1330.54, 1336.31],\n",
      "       [1342.82, 1346.29],\n",
      "       [1362.87, 1367.01],\n",
      "       [1380.25, 1383.93],\n",
      "       [1394.34, 1400.44],\n",
      "       [1405.61, 1409.85],\n",
      "       [1413.86, 1422.26],\n",
      "       [1431.51, 1436.01],\n",
      "       [1551.66, 1559],\n",
      "       [1561.97, 1566.98],\n",
      "       [1574.65, 1583.26],\n",
      "       [1588.53, 1591.87],\n",
      "       [1603.68, 1610.32],\n",
      "       [1610.79, 1617.49],\n",
      "       [1627.47, 1633.01],\n",
      "       [1637.85, 1643.72],\n",
      "       [1649.83, 1655.67],\n",
      "       [1665.08, 1669.51],\n",
      "       [1678.89, 1683.29],\n",
      "       [1692.64, 1697.44],\n",
      "       [1706.95, 1711.12],\n",
      "       [1714.82, 1721.4],\n",
      "       [1743.69, 1748.76],\n",
      "       [1752, 1756.37],\n",
      "       [1894.74, 1901.35],\n",
      "       [1901.38, 1907.05],\n",
      "       [1917.86, 1923.4],\n",
      "       [1928.87, 1933.58],\n",
      "       [1939.69, 1948.33],\n",
      "       [1953.17, 1964.44],\n",
      "       [1971.98, 1977.46],\n",
      "       [1979.19, 1990.7],\n",
      "       [1998.98, 2002.85],\n",
      "       [2002.88, 2008.29],\n",
      "       [2019.13, 2024.91],\n",
      "       [2026.01, 2031.38],\n",
      "       [2037.62, 2042.29],\n",
      "       [2057.64, 2068.85]])\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_odd\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_even\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_even\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_even\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1_any\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2_any\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze_any\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing global computations...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:NeuropyPipeline.on_stage_changed(new_stage=\"PipelineStage.Displayed\")\n",
      "WARNING:com.PhoHale.Spike3D.pipeline:WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "curr_active_computation_params.pf_params.computation_epochs: 80 epochs\n",
      "array([[5.63587, 17.4478],\n",
      "       [31.8625, 39.7703],\n",
      "       [135.802, 144.176],\n",
      "       [161.459, 167.332],\n",
      "       [234.466, 239.807],\n",
      "       [255.121, 262.696],\n",
      "       [294.026, 299.8],\n",
      "       [314.047, 319.385],\n",
      "       [499.299, 504.806],\n",
      "       [511.579, 518.353],\n",
      "       [530.199, 540.641],\n",
      "       [558.36, 565.501],\n",
      "       [584.353, 591.26],\n",
      "       [599.268, 604.74],\n",
      "       [616.819, 625.728],\n",
      "       [645.747, 655.19],\n",
      "       [678.314, 684.688],\n",
      "       [692.428, 697.566],\n",
      "       [712.482, 721.725],\n",
      "       [734.337, 741.178],\n",
      "       [750.488, 755.224],\n",
      "       [763.133, 768.971],\n",
      "       [782.252, 788.224],\n",
      "       [804.742, 812.149],\n",
      "       [825.695, 832.236],\n",
      "       [848.687, 853.692],\n",
      "       [923.895, 933.705],\n",
      "       [941.846, 951.456],\n",
      "       [971.844, 983.954],\n",
      "       [997.202, 1002.31],\n",
      "       [1010.48, 1024.66],\n",
      "       [1035.51, 1040.75],\n",
      "       [1052.42, 1059.73],\n",
      "       [1068.04, 1074.35],\n",
      "       [1086.99, 1093.57],\n",
      "       [1104.61, 1110.12],\n",
      "       [1123.53, 1130.4],\n",
      "       [1163.44, 1167.77],\n",
      "       [1179.02, 1187.23],\n",
      "       [1195.03, 1203.64],\n",
      "       [1237.71, 1244.52],\n",
      "       [1258.37, 1265.44],\n",
      "       [1330.54, 1336.31],\n",
      "       [1342.82, 1346.29],\n",
      "       [1362.87, 1367.01],\n",
      "       [1380.25, 1383.93],\n",
      "       [1394.34, 1400.44],\n",
      "       [1405.61, 1409.85],\n",
      "       [1413.86, 1422.26],\n",
      "       [1431.51, 1436.01],\n",
      "       [1551.66, 1559],\n",
      "       [1561.97, 1566.98],\n",
      "       [1574.65, 1583.26],\n",
      "       [1588.53, 1591.87],\n",
      "       [1603.68, 1610.32],\n",
      "       [1610.79, 1617.49],\n",
      "       [1627.47, 1633.01],\n",
      "       [1637.85, 1643.72],\n",
      "       [1649.83, 1655.67],\n",
      "       [1665.08, 1669.51],\n",
      "       [1678.89, 1683.29],\n",
      "       [1692.64, 1697.44],\n",
      "       [1706.95, 1711.12],\n",
      "       [1714.82, 1721.4],\n",
      "       [1743.69, 1748.76],\n",
      "       [1752, 1756.37],\n",
      "       [1894.74, 1901.35],\n",
      "       [1901.38, 1907.05],\n",
      "       [1917.86, 1923.4],\n",
      "       [1928.87, 1933.58],\n",
      "       [1939.69, 1948.33],\n",
      "       [1953.17, 1964.44],\n",
      "       [1971.98, 1977.46],\n",
      "       [1979.19, 1990.7],\n",
      "       [1998.98, 2002.85],\n",
      "       [2002.88, 2008.29],\n",
      "       [2019.13, 2024.91],\n",
      "       [2026.01, 2031.38],\n",
      "       [2037.62, 2042.29],\n",
      "       [2057.64, 2068.85]])\n",
      "\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_odd] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "curr_active_computation_params.pf_params.computation_epochs: 40 epochs\n",
      "array([[5.63587, 17.4478],\n",
      "       [31.8625, 39.7703],\n",
      "       [135.802, 144.176],\n",
      "       [161.459, 167.332],\n",
      "       [234.466, 239.807],\n",
      "       [255.121, 262.696],\n",
      "       [294.026, 299.8],\n",
      "       [314.047, 319.385],\n",
      "       [499.299, 504.806],\n",
      "       [511.579, 518.353],\n",
      "       [530.199, 540.641],\n",
      "       [558.36, 565.501],\n",
      "       [584.353, 591.26],\n",
      "       [599.268, 604.74],\n",
      "       [616.819, 625.728],\n",
      "       [645.747, 655.19],\n",
      "       [678.314, 684.688],\n",
      "       [692.428, 697.566],\n",
      "       [712.482, 721.725],\n",
      "       [734.337, 741.178],\n",
      "       [750.488, 755.224],\n",
      "       [763.133, 768.971],\n",
      "       [782.252, 788.224],\n",
      "       [804.742, 812.149],\n",
      "       [825.695, 832.236],\n",
      "       [848.687, 853.692],\n",
      "       [923.895, 933.705],\n",
      "       [941.846, 951.456],\n",
      "       [971.844, 983.954],\n",
      "       [997.202, 1002.31],\n",
      "       [1010.48, 1024.66],\n",
      "       [1035.51, 1040.75],\n",
      "       [1052.42, 1059.73],\n",
      "       [1068.04, 1074.35],\n",
      "       [1086.99, 1093.57],\n",
      "       [1104.61, 1110.12],\n",
      "       [1123.53, 1130.4],\n",
      "       [1163.44, 1167.77],\n",
      "       [1179.02, 1187.23],\n",
      "       [1195.03, 1203.64]])\n",
      "\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "curr_active_computation_params.pf_params.computation_epochs: 40 epochs\n",
      "array([[1237.71, 1244.52],\n",
      "       [1258.37, 1265.44],\n",
      "       [1330.54, 1336.31],\n",
      "       [1342.82, 1346.29],\n",
      "       [1362.87, 1367.01],\n",
      "       [1380.25, 1383.93],\n",
      "       [1394.34, 1400.44],\n",
      "       [1405.61, 1409.85],\n",
      "       [1413.86, 1422.26],\n",
      "       [1431.51, 1436.01],\n",
      "       [1551.66, 1559],\n",
      "       [1561.97, 1566.98],\n",
      "       [1574.65, 1583.26],\n",
      "       [1588.53, 1591.87],\n",
      "       [1603.68, 1610.32],\n",
      "       [1610.79, 1617.49],\n",
      "       [1627.47, 1633.01],\n",
      "       [1637.85, 1643.72],\n",
      "       [1649.83, 1655.67],\n",
      "       [1665.08, 1669.51],\n",
      "       [1678.89, 1683.29],\n",
      "       [1692.64, 1697.44],\n",
      "       [1706.95, 1711.12],\n",
      "       [1714.82, 1721.4],\n",
      "       [1743.69, 1748.76],\n",
      "       [1752, 1756.37],\n",
      "       [1894.74, 1901.35],\n",
      "       [1901.38, 1907.05],\n",
      "       [1917.86, 1923.4],\n",
      "       [1928.87, 1933.58],\n",
      "       [1939.69, 1948.33],\n",
      "       [1953.17, 1964.44],\n",
      "       [1971.98, 1977.46],\n",
      "       [1979.19, 1990.7],\n",
      "       [1998.98, 2002.85],\n",
      "       [2002.88, 2008.29],\n",
      "       [2019.13, 2024.91],\n",
      "       [2026.01, 2031.38],\n",
      "       [2037.62, 2042.29],\n",
      "       [2057.64, 2068.85]])\n",
      "\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "curr_active_computation_params.pf_params.computation_epochs: 80 epochs\n",
      "array([[5.63587, 17.4478],\n",
      "       [31.8625, 39.7703],\n",
      "       [135.802, 144.176],\n",
      "       [161.459, 167.332],\n",
      "       [234.466, 239.807],\n",
      "       [255.121, 262.696],\n",
      "       [294.026, 299.8],\n",
      "       [314.047, 319.385],\n",
      "       [499.299, 504.806],\n",
      "       [511.579, 518.353],\n",
      "       [530.199, 540.641],\n",
      "       [558.36, 565.501],\n",
      "       [584.353, 591.26],\n",
      "       [599.268, 604.74],\n",
      "       [616.819, 625.728],\n",
      "       [645.747, 655.19],\n",
      "       [678.314, 684.688],\n",
      "       [692.428, 697.566],\n",
      "       [712.482, 721.725],\n",
      "       [734.337, 741.178],\n",
      "       [750.488, 755.224],\n",
      "       [763.133, 768.971],\n",
      "       [782.252, 788.224],\n",
      "       [804.742, 812.149],\n",
      "       [825.695, 832.236],\n",
      "       [848.687, 853.692],\n",
      "       [923.895, 933.705],\n",
      "       [941.846, 951.456],\n",
      "       [971.844, 983.954],\n",
      "       [997.202, 1002.31],\n",
      "       [1010.48, 1024.66],\n",
      "       [1035.51, 1040.75],\n",
      "       [1052.42, 1059.73],\n",
      "       [1068.04, 1074.35],\n",
      "       [1086.99, 1093.57],\n",
      "       [1104.61, 1110.12],\n",
      "       [1123.53, 1130.4],\n",
      "       [1163.44, 1167.77],\n",
      "       [1179.02, 1187.23],\n",
      "       [1195.03, 1203.64],\n",
      "       [1237.71, 1244.52],\n",
      "       [1258.37, 1265.44],\n",
      "       [1330.54, 1336.31],\n",
      "       [1342.82, 1346.29],\n",
      "       [1362.87, 1367.01],\n",
      "       [1380.25, 1383.93],\n",
      "       [1394.34, 1400.44],\n",
      "       [1405.61, 1409.85],\n",
      "       [1413.86, 1422.26],\n",
      "       [1431.51, 1436.01],\n",
      "       [1551.66, 1559],\n",
      "       [1561.97, 1566.98],\n",
      "       [1574.65, 1583.26],\n",
      "       [1588.53, 1591.87],\n",
      "       [1603.68, 1610.32],\n",
      "       [1610.79, 1617.49],\n",
      "       [1627.47, 1633.01],\n",
      "       [1637.85, 1643.72],\n",
      "       [1649.83, 1655.67],\n",
      "       [1665.08, 1669.51],\n",
      "       [1678.89, 1683.29],\n",
      "       [1692.64, 1697.44],\n",
      "       [1706.95, 1711.12],\n",
      "       [1714.82, 1721.4],\n",
      "       [1743.69, 1748.76],\n",
      "       [1752, 1756.37],\n",
      "       [1894.74, 1901.35],\n",
      "       [1901.38, 1907.05],\n",
      "       [1917.86, 1923.4],\n",
      "       [1928.87, 1933.58],\n",
      "       [1939.69, 1948.33],\n",
      "       [1953.17, 1964.44],\n",
      "       [1971.98, 1977.46],\n",
      "       [1979.19, 1990.7],\n",
      "       [1998.98, 2002.85],\n",
      "       [2002.88, 2008.29],\n",
      "       [2019.13, 2024.91],\n",
      "       [2026.01, 2031.38],\n",
      "       [2037.62, 2042.29],\n",
      "       [2057.64, 2068.85]])\n",
      "\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_even] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "curr_active_computation_params.pf_params.computation_epochs: 40 epochs\n",
      "array([[5.63587, 17.4478],\n",
      "       [31.8625, 39.7703],\n",
      "       [135.802, 144.176],\n",
      "       [161.459, 167.332],\n",
      "       [234.466, 239.807],\n",
      "       [255.121, 262.696],\n",
      "       [294.026, 299.8],\n",
      "       [314.047, 319.385],\n",
      "       [499.299, 504.806],\n",
      "       [511.579, 518.353],\n",
      "       [530.199, 540.641],\n",
      "       [558.36, 565.501],\n",
      "       [584.353, 591.26],\n",
      "       [599.268, 604.74],\n",
      "       [616.819, 625.728],\n",
      "       [645.747, 655.19],\n",
      "       [678.314, 684.688],\n",
      "       [692.428, 697.566],\n",
      "       [712.482, 721.725],\n",
      "       [734.337, 741.178],\n",
      "       [750.488, 755.224],\n",
      "       [763.133, 768.971],\n",
      "       [782.252, 788.224],\n",
      "       [804.742, 812.149],\n",
      "       [825.695, 832.236],\n",
      "       [848.687, 853.692],\n",
      "       [923.895, 933.705],\n",
      "       [941.846, 951.456],\n",
      "       [971.844, 983.954],\n",
      "       [997.202, 1002.31],\n",
      "       [1010.48, 1024.66],\n",
      "       [1035.51, 1040.75],\n",
      "       [1052.42, 1059.73],\n",
      "       [1068.04, 1074.35],\n",
      "       [1086.99, 1093.57],\n",
      "       [1104.61, 1110.12],\n",
      "       [1123.53, 1130.4],\n",
      "       [1163.44, 1167.77],\n",
      "       [1179.02, 1187.23],\n",
      "       [1195.03, 1203.64]])\n",
      "\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "curr_active_computation_params.pf_params.computation_epochs: 40 epochs\n",
      "array([[1237.71, 1244.52],\n",
      "       [1258.37, 1265.44],\n",
      "       [1330.54, 1336.31],\n",
      "       [1342.82, 1346.29],\n",
      "       [1362.87, 1367.01],\n",
      "       [1380.25, 1383.93],\n",
      "       [1394.34, 1400.44],\n",
      "       [1405.61, 1409.85],\n",
      "       [1413.86, 1422.26],\n",
      "       [1431.51, 1436.01],\n",
      "       [1551.66, 1559],\n",
      "       [1561.97, 1566.98],\n",
      "       [1574.65, 1583.26],\n",
      "       [1588.53, 1591.87],\n",
      "       [1603.68, 1610.32],\n",
      "       [1610.79, 1617.49],\n",
      "       [1627.47, 1633.01],\n",
      "       [1637.85, 1643.72],\n",
      "       [1649.83, 1655.67],\n",
      "       [1665.08, 1669.51],\n",
      "       [1678.89, 1683.29],\n",
      "       [1692.64, 1697.44],\n",
      "       [1706.95, 1711.12],\n",
      "       [1714.82, 1721.4],\n",
      "       [1743.69, 1748.76],\n",
      "       [1752, 1756.37],\n",
      "       [1894.74, 1901.35],\n",
      "       [1901.38, 1907.05],\n",
      "       [1917.86, 1923.4],\n",
      "       [1928.87, 1933.58],\n",
      "       [1939.69, 1948.33],\n",
      "       [1953.17, 1964.44],\n",
      "       [1971.98, 1977.46],\n",
      "       [1979.19, 1990.7],\n",
      "       [1998.98, 2002.85],\n",
      "       [2002.88, 2008.29],\n",
      "       [2019.13, 2024.91],\n",
      "       [2026.01, 2031.38],\n",
      "       [2037.62, 2042.29],\n",
      "       [2057.64, 2068.85]])\n",
      "\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "curr_active_computation_params.pf_params.computation_epochs: 80 epochs\n",
      "array([[5.63587, 17.4478],\n",
      "       [31.8625, 39.7703],\n",
      "       [135.802, 144.176],\n",
      "       [161.459, 167.332],\n",
      "       [234.466, 239.807],\n",
      "       [255.121, 262.696],\n",
      "       [294.026, 299.8],\n",
      "       [314.047, 319.385],\n",
      "       [499.299, 504.806],\n",
      "       [511.579, 518.353],\n",
      "       [530.199, 540.641],\n",
      "       [558.36, 565.501],\n",
      "       [584.353, 591.26],\n",
      "       [599.268, 604.74],\n",
      "       [616.819, 625.728],\n",
      "       [645.747, 655.19],\n",
      "       [678.314, 684.688],\n",
      "       [692.428, 697.566],\n",
      "       [712.482, 721.725],\n",
      "       [734.337, 741.178],\n",
      "       [750.488, 755.224],\n",
      "       [763.133, 768.971],\n",
      "       [782.252, 788.224],\n",
      "       [804.742, 812.149],\n",
      "       [825.695, 832.236],\n",
      "       [848.687, 853.692],\n",
      "       [923.895, 933.705],\n",
      "       [941.846, 951.456],\n",
      "       [971.844, 983.954],\n",
      "       [997.202, 1002.31],\n",
      "       [1010.48, 1024.66],\n",
      "       [1035.51, 1040.75],\n",
      "       [1052.42, 1059.73],\n",
      "       [1068.04, 1074.35],\n",
      "       [1086.99, 1093.57],\n",
      "       [1104.61, 1110.12],\n",
      "       [1123.53, 1130.4],\n",
      "       [1163.44, 1167.77],\n",
      "       [1179.02, 1187.23],\n",
      "       [1195.03, 1203.64],\n",
      "       [1237.71, 1244.52],\n",
      "       [1258.37, 1265.44],\n",
      "       [1330.54, 1336.31],\n",
      "       [1342.82, 1346.29],\n",
      "       [1362.87, 1367.01],\n",
      "       [1380.25, 1383.93],\n",
      "       [1394.34, 1400.44],\n",
      "       [1405.61, 1409.85],\n",
      "       [1413.86, 1422.26],\n",
      "       [1431.51, 1436.01],\n",
      "       [1551.66, 1559],\n",
      "       [1561.97, 1566.98],\n",
      "       [1574.65, 1583.26],\n",
      "       [1588.53, 1591.87],\n",
      "       [1603.68, 1610.32],\n",
      "       [1610.79, 1617.49],\n",
      "       [1627.47, 1633.01],\n",
      "       [1637.85, 1643.72],\n",
      "       [1649.83, 1655.67],\n",
      "       [1665.08, 1669.51],\n",
      "       [1678.89, 1683.29],\n",
      "       [1692.64, 1697.44],\n",
      "       [1706.95, 1711.12],\n",
      "       [1714.82, 1721.4],\n",
      "       [1743.69, 1748.76],\n",
      "       [1752, 1756.37],\n",
      "       [1894.74, 1901.35],\n",
      "       [1901.38, 1907.05],\n",
      "       [1917.86, 1923.4],\n",
      "       [1928.87, 1933.58],\n",
      "       [1939.69, 1948.33],\n",
      "       [1953.17, 1964.44],\n",
      "       [1971.98, 1977.46],\n",
      "       [1979.19, 1990.7],\n",
      "       [1998.98, 2002.85],\n",
      "       [2002.88, 2008.29],\n",
      "       [2019.13, 2024.91],\n",
      "       [2026.01, 2031.38],\n",
      "       [2037.62, 2042.29],\n",
      "       [2057.64, 2068.85]])\n",
      "\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze_any] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n"
     ]
    }
   ],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Load Data                                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "active_data_mode_name = 'kdiba'\n",
    "local_session_root_parent_context = IdentifyingContext(format_name=active_data_mode_name) # , animal_name='', configuration_name='one', session_name=a_sess.session_name\n",
    "local_session_root_parent_path = global_data_root_parent_path.joinpath('KDIBA')\n",
    "\n",
    "# [*] - indicates bad or session with a problem\n",
    "# 0, 1, 2, 3, 4, 5, 6, 7, [8], [9], 10, 11, [12], 13, 14, [15], [16], 17, \n",
    "# curr_context: IdentifyingContext = good_contexts_list[1] # select the session from all of the good sessions here.\n",
    "curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15') # DONE. Very good. Many good Pfs, many good replays.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43') # DONE, might be the BEST SESSION, good example session with lots of place cells, clean replays, and clear bar graphs.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31') # DONE, Good Pfs but no good replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-13_14-42-6') # BAD, 2023-07-14, unsure why still.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19') # DONE, GREAT, both good Pfs and replays!\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25') # DONE, Added replay selections. Very \"jumpy\" between the starts and ends of the track.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40') # DONE, Added replay selections. A TON of putative replays in general, most bad, but some good.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46') # DONE, added replay selections. Very few (like 12) replays each.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-13_15-22-3') # DONE, Good Pfs, no good epochs.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30') # DONE, okay replays (selected)\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50') # DONE, very few replays (selected)\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-19_13-34-40') # BAD\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54') # DONE, one replay each (selected)\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3') # BAD, Good Pfs strangely despite horrible map, no good epochs\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-12_15-25-59') # BAD, No Epochs\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-16_18-47-52')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-17_12-52-15')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-25_13-20-55')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-28_12-38-13')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44') # DONE, good. Many good pfs, many good replays. Noticed very strange jumping off the track in the 3D behavior/spikes viewer. Is there something wrong with this session?\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0') # DONE, good?, replays selected, few\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25') # DONE, very few replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_12-15-3')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_22-4-5')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54') # DONE, replays selected, quite a few replays but few are very good.\n",
    "\n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25')\n",
    "\n",
    "local_session_parent_path: Path = local_session_root_parent_path.joinpath(curr_context.animal, curr_context.exper_name) # 'gor01', 'one' - probably not needed anymore\n",
    "basedir: Path = local_session_parent_path.joinpath(curr_context.session_name).resolve()\n",
    "print(f'basedir: {str(basedir)}')\n",
    "\n",
    "# Read if possible:\n",
    "saving_mode = PipelineSavingScheme.SKIP_SAVING\n",
    "force_reload = False\n",
    "\n",
    "# # Force write:\n",
    "# saving_mode = PipelineSavingScheme.TEMP_THEN_OVERWRITE\n",
    "# saving_mode = PipelineSavingScheme.OVERWRITE_IN_PLACE\n",
    "# force_reload = True\n",
    "\n",
    "## TODO: if loading is not possible, we need to change the `saving_mode` so that the new results are properly saved.\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-full_session_LOO_decoding_analysis.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "# epoch_name_includelist = ['maze']\n",
    "epoch_name_includelist = None\n",
    "active_computation_functions_name_includelist=['pf_computation',\n",
    "                                            #    'pfdt_computation',\n",
    "                                                'firing_rate_trends',\n",
    "                                                # 'pf_dt_sequential_surprise', \n",
    "                                            #    'ratemap_peaks_prominence2d',\n",
    "                                                'position_decoding', \n",
    "                                                # 'position_decoding_two_step', \n",
    "                                            #    'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping',\n",
    "                                            #     'long_short_inst_spike_rate_groups',\n",
    "                                            #     'long_short_endcap_analysis',\n",
    "                                            # 'split_to_directional_laps',\n",
    "]\n",
    "\n",
    "curr_active_pipeline: NeuropyPipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_includelist=epoch_name_includelist,\n",
    "                                        computation_functions_name_includelist=active_computation_functions_name_includelist,\n",
    "                                        saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                        skip_extended_batch_computations=True, debug_print=False, fail_on_exception=True) # , active_pickle_filename = 'loadedSessPickle_withParameters.pkl'\n",
    "\n",
    "\n",
    "\n",
    "## Post Compute Validate 2023-05-16:\n",
    "was_updated = BatchSessionCompletionHandler.post_compute_validate(curr_active_pipeline) ## TODO: need to potentially re-save if was_updated. This will fail because constained versions not ran yet.\n",
    "if was_updated:\n",
    "    print(f'was_updated: {was_updated}')\n",
    "    try:\n",
    "        curr_active_pipeline.save_pipeline(saving_mode=saving_mode)\n",
    "    except Exception as e:\n",
    "        ## TODO: catch/log saving error and indicate that it isn't saved.\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'ERROR RE-SAVING PIPELINE after update. error: {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acba46b6",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading loaded session pickle file results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\output\\global_computation_results.pkl... done.\n",
      "included includelist is specified: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'ratemap_peaks_prominence2d', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_endcap_analysis', 'spike_burst_detection', 'split_to_directional_laps', 'rank_order_shuffle_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze_any\"\n",
      "pf_computation, maze_any already computed.\n",
      "pfdt_computation, maze_any already computed.\n",
      "ratemap_peaks_prominence2d, maze_any already computed.\n",
      "spike_burst_detection, maze_any already computed.\n",
      "firing_rate_trends, maze_any already computed.\n",
      "split_to_directional_laps missing.\n",
      "\t Recomputing split_to_directional_laps...\n",
      "WARN: _split_to_directional_laps(...): include_includelist: ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any'] is specified but include_includelist is currently ignored! Continuing with defaults.\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "long_epoch_obj: 1 epochs\n",
      "array([[0, 1211.56]])\n",
      ", short_epoch_obj: 1 epochs\n",
      "array([[1211.56, 2093.9]])\n",
      "\n",
      "original_num_epochs: [20 20 20 20]\n",
      "modified_num_epochs: [20 20 20 20]\n",
      "odd_n_neurons: 52, odd_shared_aclus: [  5   7   9  17  22  24  25  26  31  32  34  38  39  41  45  46  48  50  51  53  55  56  59  61  62  64  66  68  69  72  75  76  78  79  81  82  83  84  86  87  88  89  90  91  92  93  95  96  99 100 101 108]\n",
      "even_n_neurons: 54, even_shared_aclus: [  3   5   7   9  10  11  14  15  16  31  32  33  35  36  37  39  41  45  46  48  49  50  52  55  57  60  61  62  64  69  70  71  72  75  76  78  79  83  84  85  86  88  90  91  92  93  95  98  99 100 101 102 107 108]\n",
      "\t done.\n",
      "rank_order_shuffle_analysis missing.\n",
      "\t Recomputing rank_order_shuffle_analysis...\n",
      "WARN: perform_rank_order_shuffle_analysis(...): include_includelist: ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any'] is specified but include_includelist is currently ignored! Continuing with defaults.\n",
      "perform_rank_order_shuffle_analysis(..., num_shuffles=1000)\n",
      "\tcomputing Laps rank-order shuffles:\n",
      "WARN: .trim_overlapping_laps(...): need to recompute  ['start_position_index', 'end_position_index', 'start_spike_index', 'end_spike_index', 'num_spikes'] for the laps after calling self.trim_overlapping_laps()!\n",
      "laps_paired_tests: [TtestResult(statistic=10.103138874198912, pvalue=6.969080991653421e-16, df=79), TtestResult(statistic=13.59085052909697, pvalue=2.23097973879169e-22, df=79)]\n",
      "\tcomputing Ripple rank-order shuffles:\n",
      "ripple_evts_paired_tests: [TtestResult(statistic=1.32082213796101, pvalue=0.18704407964200723, df=625), TtestResult(statistic=-0.48471373069967666, pvalue=0.6280492532891311, df=625)]\n",
      "\tdone. building global result.\n",
      "\t done.\n",
      "long_short_decoding_analyses missing.\n",
      "\t Recomputing long_short_decoding_analyses...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "`is_certain_properly_constrained`: True - Correctly initialized pipelines (pfs limited to laps, decoders already long/short constrainted by default, replays already the estimated versions\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\scipy\\spatial\\distance.py:1259: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(js / 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(n_neurons = 62, n_all_epoch_timebins = 2237)\n",
      "reusing extant decoder.\n",
      "USING EXISTING original_1D_decoder.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\scipy\\spatial\\distance.py:1259: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return np.sqrt(js / 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(n_neurons = 62, n_all_epoch_timebins = 2237)\n",
      "\t done.\n",
      "short_long_pf_overlap_analyses missing.\n",
      "\t Recomputing short_long_pf_overlap_analyses...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t done.\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "have an existing `global_computation_results.computation_config`: DynamicContainer({'instantaneous_time_bin_size_seconds': 0.01})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\MultiContextComputationFunctions\\LongShortTrackComputations.py:2558: RuntimeWarning: invalid value encountered in divide\n",
      "  normalized_convolved_result_subset = convolved_result_subset / convolved_result_subset_area\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\utils\\efficient_interval_search.py:650: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  epoch_split_spike_dfs_aclu_firingrates_Hz = [{an_aclu:(float(a_count)/trimmed_epoch_duration) for an_aclu, a_count in a_spike_count_dict.items()} for trimmed_epoch_duration, a_spike_count_dict in zip(spike_trimmed_active_epochs.durations, epoch_split_spike_dfs_aclu_spikecounts)] # just the non-zero aclus values: e.g. {108: 16.582832394938322, 36: 16.582832394938322, 34: 16.582832394938322, 66: 16.582832394938322, 58: 12.437124296203741, 74: 12.437124296203741, 51: 12.437124296203741, 23: 8.291416197469161, 57: 8.291416197469161, 32: 8.291416197469161, 63: 8.291416197469161, 11: 8.291416197469161, 73: 8.291416197469161, 88: 8.291416197469161, 16: 8.291416197469161, 31: 8.291416197469161, 13: 4.1457080987345805, 27: 4.1457080987345805, 10: 4.1457080987345805, 19: 4.1457080987345805, 25: 4.1457080987345805, 62: 4.1457080987345805, 59: 4.1457080987345805, 21: 4.1457080987345805, 98: 4.1457080987345805, 14: 4.1457080987345805}\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\utils\\efficient_interval_search.py:650: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  epoch_split_spike_dfs_aclu_firingrates_Hz = [{an_aclu:(float(a_count)/trimmed_epoch_duration) for an_aclu, a_count in a_spike_count_dict.items()} for trimmed_epoch_duration, a_spike_count_dict in zip(spike_trimmed_active_epochs.durations, epoch_split_spike_dfs_aclu_spikecounts)] # just the non-zero aclus values: e.g. {108: 16.582832394938322, 36: 16.582832394938322, 34: 16.582832394938322, 66: 16.582832394938322, 58: 12.437124296203741, 74: 12.437124296203741, 51: 12.437124296203741, 23: 8.291416197469161, 57: 8.291416197469161, 32: 8.291416197469161, 63: 8.291416197469161, 11: 8.291416197469161, 73: 8.291416197469161, 88: 8.291416197469161, 16: 8.291416197469161, 31: 8.291416197469161, 13: 4.1457080987345805, 27: 4.1457080987345805, 10: 4.1457080987345805, 19: 4.1457080987345805, 25: 4.1457080987345805, 62: 4.1457080987345805, 59: 4.1457080987345805, 21: 4.1457080987345805, 98: 4.1457080987345805, 14: 4.1457080987345805}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_generalized_compute_long_short_firing_rate_indicies(...): processing key: \"laps\"\n",
      "_generalized_compute_long_short_firing_rate_indicies(...): processing key: \"replays\"\n",
      "_generalized_compute_long_short_firing_rate_indicies(...): processing key: \"non_replays\"\n",
      "\t done.\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "WARN: 2023-09-28 16:15: - [ ] fix the combination properties. Would work if we directly used the computed _is_L_only and _is_S_only above\n",
      "\t done.\n",
      "long_short_post_decoding missing.\n",
      "\t Recomputing long_short_post_decoding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t done.\n",
      "long_short_endcap_analysis missing.\n",
      "\t Recomputing long_short_endcap_analysis...\n",
      "num_disappearing_endcap_cells/num_total_endcap_cells: 6/28\n",
      "num_non_disappearing_endcap_cells/num_total_endcap_cells: 22/28\n",
      "num_significant_position_remappping_endcap_cells/num_non_disappearing_endcap_cells: 10/22\n",
      "\t done.\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: [('split_to_directional_laps', 'maze_any'), ('rank_order_shuffle_analysis', 'maze_any'), ('long_short_decoding_analyses', 'maze_any'), ('short_long_pf_overlap_analyses', 'maze_any'), ('long_short_fr_indicies_analyses', 'maze_any'), ('jonathan_firing_rate_analysis', 'maze_any'), ('long_short_post_decoding', 'maze_any'), ('long_short_endcap_analysis', 'maze_any')].\n",
      "\n",
      "\n",
      "!!WARNING!!: changes to global results have been made but they will not be saved since saving_mode.value == \"skip_saving\"\n",
      "\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df9198a0bc2458b839f446532a4a101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Box(children=(Label(value='session path:', layout=Layout(width='auto')), Label(value='W:\\\\Data\\"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:save_pipeline(): Attempting to save pipeline to disk...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\tfinalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\loadedSessPickle.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\loadedSessPickle.pkl\n",
      "Saving (file mode 'None') saved session pickle file results : None... pickling exception occured while using safeSaveData(pkl_path: None, ..., , should_append=False) but original file was NOT overwritten!\n",
      "Exception: Can't pickle <function make_set_closure_cell.<locals>.set_closure_cell at 0x00000184B4FCA790>: it's not found as attr._compat.make_set_closure_cell.<locals>.set_closure_cell\n",
      "done.\n",
      "ERROR RE-SAVING PIPELINE after update. error: !! Can't pickle <function make_set_closure_cell.<locals>.set_closure_cell at 0x00000184B4FCA790>: it's not found as attr._compat.make_set_closure_cell.<locals>.set_closure_cell ::::: (<class '_pickle.PicklingError'>, PicklingError(\"Can't pickle <function make_set_closure_cell.<locals>.set_closure_cell at 0x00000184B4FCA790>: it's not found as attr._compat.make_set_closure_cell.<locals>.set_closure_cell\"), <traceback object at 0x000001848B64DA40>)\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "### GLOBAL COMPUTATIONS:\n",
    "if not force_reload: # not just force_reload, needs to recompute whenever the computation fails.\n",
    "    try:\n",
    "        curr_active_pipeline.load_pickled_global_computation_results()\n",
    "    except Exception as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'cannot load global results: {e}')\n",
    "        raise\n",
    "\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "\n",
    "extended_computations_include_includelist=['pf_computation', 'pfdt_computation', 'firing_rate_trends',\n",
    "    # 'pf_dt_sequential_surprise',\n",
    "     'ratemap_peaks_prominence2d',\n",
    "    'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding',\n",
    "    # 'long_short_rate_remapping',\n",
    "    # 'long_short_inst_spike_rate_groups',\n",
    "    'long_short_endcap_analysis',\n",
    "    'spike_burst_detection',\n",
    "    'split_to_directional_laps',\n",
    "    'rank_order_shuffle_analysis'\n",
    "] # do only specified\n",
    "\n",
    "force_recompute_global = force_reload\n",
    "# force_recompute_global = True\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True, force_recompute=force_recompute_global, debug_print=False)\n",
    "if (len(newly_computed_values) > 0):\n",
    "    print(f'newly_computed_values: {newly_computed_values}.')\n",
    "    if (saving_mode.value != 'skip_saving'):\n",
    "        print(f'Saving global results...')\n",
    "        try:\n",
    "            # curr_active_pipeline.global_computation_results.persist_time = datetime.now()\n",
    "            # Try to write out the global computation function results:\n",
    "            curr_active_pipeline.save_global_computation_results()\n",
    "        except Exception as e:\n",
    "            exception_info = sys.exc_info()\n",
    "            e = CapturedException(e, exception_info)\n",
    "            print(f'\\n\\n!!WARNING!!: saving the global results threw the exception: {e}')\n",
    "            print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "    else:\n",
    "        print(f'\\n\\n!!WARNING!!: changes to global results have been made but they will not be saved since saving_mode.value == \"skip_saving\"')\n",
    "        print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "else:\n",
    "    print(f'no changes in global results.')\n",
    "\n",
    "# except Exception as e:\n",
    "#     exception_info = sys.exc_info()\n",
    "#     e = CapturedException(e, exception_info)\n",
    "#     print(f'second half threw: {e}')\n",
    "\n",
    "\n",
    "# 4m 5.2s for inst fr computations\n",
    "# Jupyter Widget Interactive\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import interactive_pipeline_widget, fullwidth_path_widget, interactive_pipeline_files\n",
    "\n",
    "_pipeline_jupyter_widget = interactive_pipeline_widget(curr_active_pipeline=curr_active_pipeline)\n",
    "# display(_pipeline_jupyter_widget)\n",
    "_pipeline_jupyter_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2334afa3",
   "metadata": {},
   "source": [
    "newly_computed_values: [('long_short_decoding_analyses', 'maze_any'), ('short_long_pf_overlap_analyses', 'maze_any'), ('long_short_fr_indicies_analyses', 'maze_any'), ('jonathan_firing_rate_analysis', 'maze_any'), ('long_short_post_decoding', 'maze_any'), ('long_short_endcap_analysis', 'maze_any')].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee3d4f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_computation_results_pickle_path: W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\output\\global_computation_results.pkl\n",
      "Saving (file mode 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\output\\global_computation_results.pkl') saved session pickle file results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\output\\global_computation_results.pkl... pickling exception occured while using safeSaveData(pkl_path: W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\output\\global_computation_results.pkl, ..., , should_append=False) but original file was NOT overwritten!\n",
      "Exception: Can't pickle <function make_set_closure_cell.<locals>.set_closure_cell at 0x00000184B4FCA790>: it's not found as attr._compat.make_set_closure_cell.<locals>.set_closure_cell\n",
      "done.\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <function make_set_closure_cell.<locals>.set_closure_cell at 0x00000184B4FCA790>: it's not found as attr._compat.make_set_closure_cell.<locals>.set_closure_cell",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\ReviewOfWork_2023-11-15.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/pho/repos/Spike3DWorkEnv/Spike3D/ReviewOfWork_2023-11-15.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m curr_active_pipeline\u001b[39m.\u001b[39;49msave_global_computation_results()\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1232\u001b[0m, in \u001b[0;36mPipelineWithComputedPipelineStageMixin.save_global_computation_results\u001b[1;34m(self, override_global_pickle_path, override_global_pickle_filename)\u001b[0m\n\u001b[0;32m   1229\u001b[0m         global_computation_results_pickle_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_output_path()\u001b[39m.\u001b[39mjoinpath(override_global_pickle_filename)\u001b[39m.\u001b[39mresolve() \n\u001b[0;32m   1231\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mglobal_computation_results_pickle_path: \u001b[39m\u001b[39m{\u001b[39;00mglobal_computation_results_pickle_path\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1232\u001b[0m saveData(global_computation_results_pickle_path, (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mglobal_computation_results\u001b[39m.\u001b[39;49mto_dict()))\n\u001b[0;32m   1233\u001b[0m \u001b[39mreturn\u001b[39;00m global_computation_results_pickle_path\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Loading.py:104\u001b[0m, in \u001b[0;36msaveData\u001b[1;34m(pkl_path, db, should_append, safe_save)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" \u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[39m\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[39msafe_save: If True, a temporary extension is added to the save path if the file already exists and the file is only overwritten if pickling doesn't throw an exception.\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[39m    This temporarily requires double the disk space.\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[39m    \u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[39mif\u001b[39;00m safe_save:\n\u001b[1;32m--> 104\u001b[0m     safeSaveData(pkl_path, db\u001b[39m=\u001b[39;49mdb, should_append\u001b[39m=\u001b[39;49mshould_append)\n\u001b[0;32m    105\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    106\u001b[0m     \u001b[39mif\u001b[39;00m should_append:\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Loading.py:90\u001b[0m, in \u001b[0;36msafeSaveData\u001b[1;34m(pkl_path, db, should_append, backup_file_if_smaller_than_original, backup_minimum_difference_MB)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[39mif\u001b[39;00m is_temporary_file_used:\n\u001b[0;32m     89\u001b[0m     pkl_path\u001b[39m.\u001b[39munlink(missing_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m# removes the incomplete file. The user's file located at _desired_final_pickle_path is still intact.\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Loading.py:66\u001b[0m, in \u001b[0;36msafeSaveData\u001b[1;34m(pkl_path, db, should_append, backup_file_if_smaller_than_original, backup_minimum_difference_MB)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(pkl_path, file_mode) \u001b[39mas\u001b[39;00m dbfile: \n\u001b[0;32m     65\u001b[0m         \u001b[39m# source, destination\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m         pickle\u001b[39m.\u001b[39;49mdump(db, dbfile)\n\u001b[0;32m     67\u001b[0m         dbfile\u001b[39m.\u001b[39mclose()\n\u001b[0;32m     68\u001b[0m     \u001b[39m# Pickling succeeded\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \n\u001b[0;32m     70\u001b[0m     \u001b[39m# If we saved to a temporary name, now see if we should overwrite or backup and then replace:\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\dill\\_dill.py:336\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol, byref, fmode, recurse, **kwds)\u001b[0m\n\u001b[0;32m    334\u001b[0m _kwds \u001b[39m=\u001b[39m kwds\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m    335\u001b[0m _kwds\u001b[39m.\u001b[39mupdate(\u001b[39mdict\u001b[39m(byref\u001b[39m=\u001b[39mbyref, fmode\u001b[39m=\u001b[39mfmode, recurse\u001b[39m=\u001b[39mrecurse))\n\u001b[1;32m--> 336\u001b[0m Pickler(file, protocol, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_kwds)\u001b[39m.\u001b[39;49mdump(obj)\n\u001b[0;32m    337\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\dill\\_dill.py:620\u001b[0m, in \u001b[0;36mPickler.dump\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    618\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(msg)\n\u001b[0;32m    619\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 620\u001b[0m     StockPickler\u001b[39m.\u001b[39;49mdump(\u001b[39mself\u001b[39;49m, obj)\n\u001b[0;32m    621\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:487\u001b[0m, in \u001b[0;36m_Pickler.dump\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproto \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m4\u001b[39m:\n\u001b[0;32m    486\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframer\u001b[39m.\u001b[39mstart_framing()\n\u001b[1;32m--> 487\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave(obj)\n\u001b[0;32m    488\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(STOP)\n\u001b[0;32m    489\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframer\u001b[39m.\u001b[39mend_framing()\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\dill\\_dill.py:1251\u001b[0m, in \u001b[0;36msave_module_dict\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[0;32m   1249\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1251\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[0;32m   1252\u001b[0m     log\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1253\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[0;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[1;32m--> 971\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[0;32m    996\u001b[0m         save(k)\n\u001b[1;32m--> 997\u001b[0m         save(v)\n\u001b[0;32m    998\u001b[0m     write(SETITEMS)\n\u001b[0;32m    999\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(\u001b[39m\"\u001b[39m\u001b[39mTuple returned by \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m must have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    600\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mtwo to six elements\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m reduce)\n\u001b[0;32m    602\u001b[0m \u001b[39m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[1;32m--> 603\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_reduce(obj\u001b[39m=\u001b[39;49mobj, \u001b[39m*\u001b[39;49mrv)\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:717\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     \u001b[39mif\u001b[39;00m state_setter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 717\u001b[0m         save(state)\n\u001b[0;32m    718\u001b[0m         write(BUILD)\n\u001b[0;32m    719\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    720\u001b[0m         \u001b[39m# If a state_setter is specified, call it instead of load_build\u001b[39;00m\n\u001b[0;32m    721\u001b[0m         \u001b[39m# to update obj's with its previous state.\u001b[39;00m\n\u001b[0;32m    722\u001b[0m         \u001b[39m# First, push state_setter and its tuple of expected arguments\u001b[39;00m\n\u001b[0;32m    723\u001b[0m         \u001b[39m# (obj, state) onto the stack.\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\dill\\_dill.py:1251\u001b[0m, in \u001b[0;36msave_module_dict\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[0;32m   1249\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1251\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[0;32m   1252\u001b[0m     log\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1253\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[0;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[1;32m--> 971\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[0;32m    996\u001b[0m         save(k)\n\u001b[1;32m--> 997\u001b[0m         save(v)\n\u001b[0;32m    998\u001b[0m     write(SETITEMS)\n\u001b[0;32m    999\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\dill\\_dill.py:1251\u001b[0m, in \u001b[0;36msave_module_dict\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[0;32m   1249\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1251\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[0;32m   1252\u001b[0m     log\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1253\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[0;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[1;32m--> 971\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[0;32m    996\u001b[0m         save(k)\n\u001b[1;32m--> 997\u001b[0m         save(v)\n\u001b[0;32m    998\u001b[0m     write(SETITEMS)\n\u001b[0;32m    999\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(\u001b[39m\"\u001b[39m\u001b[39mTuple returned by \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m must have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    600\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mtwo to six elements\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m reduce)\n\u001b[0;32m    602\u001b[0m \u001b[39m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[1;32m--> 603\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_reduce(obj\u001b[39m=\u001b[39;49mobj, \u001b[39m*\u001b[39;49mrv)\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:687\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    684\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(\n\u001b[0;32m    685\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39margs[0] from __newobj__ args has the wrong class\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    686\u001b[0m args \u001b[39m=\u001b[39m args[\u001b[39m1\u001b[39m:]\n\u001b[1;32m--> 687\u001b[0m save(\u001b[39mcls\u001b[39;49m)\n\u001b[0;32m    688\u001b[0m save(args)\n\u001b[0;32m    689\u001b[0m write(NEWOBJ)\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\dill\\_dill.py:1838\u001b[0m, in \u001b[0;36msave_type\u001b[1;34m(pickler, obj, postproc_list)\u001b[0m\n\u001b[0;32m   1836\u001b[0m             postproc_list \u001b[39m=\u001b[39m []\n\u001b[0;32m   1837\u001b[0m         postproc_list\u001b[39m.\u001b[39mappend((\u001b[39msetattr\u001b[39m, (obj, \u001b[39m'\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m'\u001b[39m, obj_name)))\n\u001b[1;32m-> 1838\u001b[0m     _save_with_postproc(pickler, (_create_type, (\n\u001b[0;32m   1839\u001b[0m         \u001b[39mtype\u001b[39;49m(obj), obj\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m, obj\u001b[39m.\u001b[39;49m\u001b[39m__bases__\u001b[39;49m, _dict\n\u001b[0;32m   1840\u001b[0m     )), obj\u001b[39m=\u001b[39;49mobj, postproc_list\u001b[39m=\u001b[39;49mpostproc_list)\n\u001b[0;32m   1841\u001b[0m     log\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39m# \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m _t)\n\u001b[0;32m   1842\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\dill\\_dill.py:1140\u001b[0m, in \u001b[0;36m_save_with_postproc\u001b[1;34m(pickler, reduction, is_pickler_dill, obj, postproc_list)\u001b[0m\n\u001b[0;32m   1137\u001b[0m     pickler\u001b[39m.\u001b[39m_postproc[\u001b[39mid\u001b[39m(obj)] \u001b[39m=\u001b[39m postproc_list\n\u001b[0;32m   1139\u001b[0m \u001b[39m# TODO: Use state_setter in Python 3.8 to allow for faster cPickle implementations\u001b[39;00m\n\u001b[1;32m-> 1140\u001b[0m pickler\u001b[39m.\u001b[39;49msave_reduce(\u001b[39m*\u001b[39;49mreduction, obj\u001b[39m=\u001b[39;49mobj)\n\u001b[0;32m   1142\u001b[0m \u001b[39mif\u001b[39;00m is_pickler_dill:\n\u001b[0;32m   1143\u001b[0m     \u001b[39m# pickler.x -= 1\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m     \u001b[39m# print(pickler.x*' ', 'pop', obj, id(obj))\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m     postproc \u001b[39m=\u001b[39m pickler\u001b[39m.\u001b[39m_postproc\u001b[39m.\u001b[39mpop(\u001b[39mid\u001b[39m(obj))\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:692\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    691\u001b[0m     save(func)\n\u001b[1;32m--> 692\u001b[0m     save(args)\n\u001b[0;32m    693\u001b[0m     write(REDUCE)\n\u001b[0;32m    695\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    696\u001b[0m     \u001b[39m# If the object is already in the memo, this means it is\u001b[39;00m\n\u001b[0;32m    697\u001b[0m     \u001b[39m# recursive. In this case, throw away everything we put on the\u001b[39;00m\n\u001b[0;32m    698\u001b[0m     \u001b[39m# stack, and fetch the object back from the memo.\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:901\u001b[0m, in \u001b[0;36m_Pickler.save_tuple\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    899\u001b[0m write(MARK)\n\u001b[0;32m    900\u001b[0m \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m obj:\n\u001b[1;32m--> 901\u001b[0m     save(element)\n\u001b[0;32m    903\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mid\u001b[39m(obj) \u001b[39min\u001b[39;00m memo:\n\u001b[0;32m    904\u001b[0m     \u001b[39m# Subtle.  d was not in memo when we entered save_tuple(), so\u001b[39;00m\n\u001b[0;32m    905\u001b[0m     \u001b[39m# the process of saving the tuple's elements must have saved\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    909\u001b[0m     \u001b[39m# could have been done in the \"for element\" loop instead, but\u001b[39;00m\n\u001b[0;32m    910\u001b[0m     \u001b[39m# recursive tuples are a rare thing.\u001b[39;00m\n\u001b[0;32m    911\u001b[0m     get \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget(memo[\u001b[39mid\u001b[39m(obj)][\u001b[39m0\u001b[39m])\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\dill\\_dill.py:1251\u001b[0m, in \u001b[0;36msave_module_dict\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[0;32m   1249\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1251\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[0;32m   1252\u001b[0m     log\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1253\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[0;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[1;32m--> 971\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[0;32m    996\u001b[0m         save(k)\n\u001b[1;32m--> 997\u001b[0m         save(v)\n\u001b[0;32m    998\u001b[0m     write(SETITEMS)\n\u001b[0;32m    999\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\dill\\_dill.py:1963\u001b[0m, in \u001b[0;36msave_function\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   1960\u001b[0m     \u001b[39mif\u001b[39;00m state_dict:\n\u001b[0;32m   1961\u001b[0m         state \u001b[39m=\u001b[39m state, state_dict\n\u001b[1;32m-> 1963\u001b[0m     _save_with_postproc(pickler, (_create_function, (\n\u001b[0;32m   1964\u001b[0m           obj\u001b[39m.\u001b[39;49m\u001b[39m__code__\u001b[39;49m, globs, obj\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m, obj\u001b[39m.\u001b[39;49m\u001b[39m__defaults__\u001b[39;49m,\n\u001b[0;32m   1965\u001b[0m           closure\n\u001b[0;32m   1966\u001b[0m     ), state), obj\u001b[39m=\u001b[39;49mobj, postproc_list\u001b[39m=\u001b[39;49mpostproc_list)\n\u001b[0;32m   1967\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1968\u001b[0m     closure \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mfunc_closure\n",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\dill\\_dill.py:1154\u001b[0m, in \u001b[0;36m_save_with_postproc\u001b[1;34m(pickler, reduction, is_pickler_dill, obj, postproc_list)\u001b[0m\n\u001b[0;32m   1152\u001b[0m \u001b[39mif\u001b[39;00m source:\n\u001b[0;32m   1153\u001b[0m     pickler\u001b[39m.\u001b[39mwrite(pickler\u001b[39m.\u001b[39mget(pickler\u001b[39m.\u001b[39mmemo[\u001b[39mid\u001b[39m(dest)][\u001b[39m0\u001b[39m]))\n\u001b[1;32m-> 1154\u001b[0m     pickler\u001b[39m.\u001b[39;49m_batch_setitems(\u001b[39miter\u001b[39;49m(source\u001b[39m.\u001b[39;49mitems()))\n\u001b[0;32m   1155\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1156\u001b[0m     \u001b[39m# Updating with an empty dictionary. Same as doing nothing.\u001b[39;00m\n\u001b[0;32m   1157\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[0;32m    996\u001b[0m         save(k)\n\u001b[1;32m--> 997\u001b[0m         save(v)\n\u001b[0;32m    998\u001b[0m     write(SETITEMS)\n\u001b[0;32m    999\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\dill\\_dill.py:2004\u001b[0m, in \u001b[0;36msave_function\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   2002\u001b[0m     log\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mF2: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m obj)\n\u001b[0;32m   2003\u001b[0m     name \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(obj, \u001b[39m'\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mgetattr\u001b[39m(obj, \u001b[39m'\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m-> 2004\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_global(pickler, obj, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   2005\u001b[0m     log\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39m# F2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2006\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:1070\u001b[0m, in \u001b[0;36m_Pickler.save_global\u001b[1;34m(self, obj, name)\u001b[0m\n\u001b[0;32m   1068\u001b[0m     obj2, parent \u001b[39m=\u001b[39m _getattribute(module, name)\n\u001b[0;32m   1069\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mImportError\u001b[39;00m, \u001b[39mKeyError\u001b[39;00m, \u001b[39mAttributeError\u001b[39;00m):\n\u001b[1;32m-> 1070\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(\n\u001b[0;32m   1071\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt pickle \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m: it\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms not found as \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1072\u001b[0m         (obj, module_name, name)) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1073\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1074\u001b[0m     \u001b[39mif\u001b[39;00m obj2 \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m obj:\n",
      "\u001b[1;31mPicklingError\u001b[0m: Can't pickle <function make_set_closure_cell.<locals>.set_closure_cell at 0x00000184B4FCA790>: it's not found as attr._compat.make_set_closure_cell.<locals>.set_closure_cell"
     ]
    }
   ],
   "source": [
    "curr_active_pipeline.save_global_computation_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7283980b",
   "metadata": {},
   "source": [
    "## 2023-09-21 - `dill` Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47b74354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving session to C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\output\\test_pickled_session_2023-11-15.pkl\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <built-in function input>: it's not the same object as builtins.input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\ReviewOfWork_2023-11-15.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pho/repos/Spike3DWorkEnv/Spike3D/ReviewOfWork_2023-11-15.ipynb#Y154sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m test_session_file \u001b[39m=\u001b[39m Path(\u001b[39m'\u001b[39m\u001b[39moutput/test_pickled_session_2023-11-15.pkl\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mresolve()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pho/repos/Spike3DWorkEnv/Spike3D/ReviewOfWork_2023-11-15.ipynb#Y154sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39msaving session to \u001b[39m\u001b[39m{\u001b[39;00mtest_session_file\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/pho/repos/Spike3DWorkEnv/Spike3D/ReviewOfWork_2023-11-15.ipynb#Y154sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m dump_session(test_session_file)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pho/repos/Spike3DWorkEnv/Spike3D/ReviewOfWork_2023-11-15.ipynb#Y154sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# dill.detect.trace(True)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pho/repos/Spike3DWorkEnv/Spike3D/ReviewOfWork_2023-11-15.ipynb#Y154sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# dill.dump_session(test_session_file) # PicklingError: Can't pickle : it's not the same object as builtins.input\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pho/repos/Spike3DWorkEnv/Spike3D/ReviewOfWork_2023-11-15.ipynb#Y154sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# PicklingError: Can't pickle .NewCol'>: it's not found as tables.description.Col._subclass_from_prefix..NewCol\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pho/repos/Spike3DWorkEnv/Spike3D/ReviewOfWork_2023-11-15.ipynb#Y154sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m#     # log(\"> D = %r\", D)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pho/repos/Spike3DWorkEnv/Spike3D/ReviewOfWork_2023-11-15.ipynb#Y154sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39m#     dill.dump_session(test_session_file)\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\ReviewOfWork_2023-11-15.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pho/repos/Spike3DWorkEnv/Spike3D/ReviewOfWork_2023-11-15.ipynb#Y154sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump_session\u001b[39m(file_path):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pho/repos/Spike3DWorkEnv/Spike3D/ReviewOfWork_2023-11-15.ipynb#Y154sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Pickle the current python session to be used in the worker.\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/pho/repos/Spike3DWorkEnv/Spike3D/ReviewOfWork_2023-11-15.ipynb#Y154sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pho/repos/Spike3DWorkEnv/Spike3D/ReviewOfWork_2023-11-15.ipynb#Y154sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m  Note: Due to the inconsistency in the first dump of dill dump_session we\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pho/repos/Spike3DWorkEnv/Spike3D/ReviewOfWork_2023-11-15.ipynb#Y154sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m  create and load the dump twice to have consistent results in the worker and\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pho/repos/Spike3DWorkEnv/Spike3D/ReviewOfWork_2023-11-15.ipynb#Y154sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m  the running session. Check: https://github.com/uqfoundation/dill/issues/195\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pho/repos/Spike3DWorkEnv/Spike3D/ReviewOfWork_2023-11-15.ipynb#Y154sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/pho/repos/Spike3DWorkEnv/Spike3D/ReviewOfWork_2023-11-15.ipynb#Y154sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m   dill\u001b[39m.\u001b[39;49mdump_session(file_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pho/repos/Spike3DWorkEnv/Spike3D/ReviewOfWork_2023-11-15.ipynb#Y154sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m   dill\u001b[39m.\u001b[39mload_session(file_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pho/repos/Spike3DWorkEnv/Spike3D/ReviewOfWork_2023-11-15.ipynb#Y154sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m dill\u001b[39m.\u001b[39mdump_session(file_path)\n",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\dill\\_dill.py:503\u001b[0m, in \u001b[0;36mdump_session\u001b[1;34m(filename, main, byref, **kwds)\u001b[0m\n\u001b[0;32m    501\u001b[0m     pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    502\u001b[0m     pickler\u001b[39m.\u001b[39m_main_modified \u001b[39m=\u001b[39m main \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m pickler\u001b[39m.\u001b[39m_original_main\n\u001b[1;32m--> 503\u001b[0m     pickler\u001b[39m.\u001b[39;49mdump(main)\n\u001b[0;32m    504\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    505\u001b[0m     \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m filename:  \u001b[39m# If newly opened file\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\dill\\_dill.py:620\u001b[0m, in \u001b[0;36mPickler.dump\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    618\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(msg)\n\u001b[0;32m    619\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 620\u001b[0m     StockPickler\u001b[39m.\u001b[39;49mdump(\u001b[39mself\u001b[39;49m, obj)\n\u001b[0;32m    621\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:487\u001b[0m, in \u001b[0;36m_Pickler.dump\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproto \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m4\u001b[39m:\n\u001b[0;32m    486\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframer\u001b[39m.\u001b[39mstart_framing()\n\u001b[1;32m--> 487\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave(obj)\n\u001b[0;32m    488\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(STOP)\n\u001b[0;32m    489\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframer\u001b[39m.\u001b[39mend_framing()\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\dill\\_dill.py:1765\u001b[0m, in \u001b[0;36msave_module\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   1762\u001b[0m     _main_dict \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m\u001b[39m.\u001b[39mcopy() \u001b[39m#XXX: better no copy? option to copy?\u001b[39;00m\n\u001b[0;32m   1763\u001b[0m     [_main_dict\u001b[39m.\u001b[39mpop(item, \u001b[39mNone\u001b[39;00m) \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m singletontypes\n\u001b[0;32m   1764\u001b[0m         \u001b[39m+\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39m__builtins__\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m__loader__\u001b[39m\u001b[39m\"\u001b[39m]]\n\u001b[1;32m-> 1765\u001b[0m     pickler\u001b[39m.\u001b[39;49msave_reduce(_import_module, (obj\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m,), obj\u001b[39m=\u001b[39;49mobj,\n\u001b[0;32m   1766\u001b[0m                         state\u001b[39m=\u001b[39;49m_main_dict)\n\u001b[0;32m   1767\u001b[0m     log\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39m# M1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1768\u001b[0m \u001b[39melif\u001b[39;00m PY3 \u001b[39mand\u001b[39;00m obj\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdill._dill\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:717\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     \u001b[39mif\u001b[39;00m state_setter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 717\u001b[0m         save(state)\n\u001b[0;32m    718\u001b[0m         write(BUILD)\n\u001b[0;32m    719\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    720\u001b[0m         \u001b[39m# If a state_setter is specified, call it instead of load_build\u001b[39;00m\n\u001b[0;32m    721\u001b[0m         \u001b[39m# to update obj's with its previous state.\u001b[39;00m\n\u001b[0;32m    722\u001b[0m         \u001b[39m# First, push state_setter and its tuple of expected arguments\u001b[39;00m\n\u001b[0;32m    723\u001b[0m         \u001b[39m# (obj, state) onto the stack.\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\dill\\_dill.py:1251\u001b[0m, in \u001b[0;36msave_module_dict\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[0;32m   1249\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1251\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[0;32m   1252\u001b[0m     log\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1253\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[0;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[1;32m--> 971\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[0;32m    996\u001b[0m         save(k)\n\u001b[1;32m--> 997\u001b[0m         save(v)\n\u001b[0;32m    998\u001b[0m     write(SETITEMS)\n\u001b[0;32m    999\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\dill\\_dill.py:1251\u001b[0m, in \u001b[0;36msave_module_dict\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[0;32m   1249\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1251\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[0;32m   1252\u001b[0m     log\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1253\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[0;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[1;32m--> 971\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:1002\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m   1000\u001b[0m     k, v \u001b[39m=\u001b[39m tmp[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1001\u001b[0m     save(k)\n\u001b[1;32m-> 1002\u001b[0m     save(v)\n\u001b[0;32m   1003\u001b[0m     write(SETITEM)\n\u001b[0;32m   1004\u001b[0m \u001b[39m# else tmp is empty, and we're done\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(\u001b[39m\"\u001b[39m\u001b[39mTuple returned by \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m must have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    600\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mtwo to six elements\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m reduce)\n\u001b[0;32m    602\u001b[0m \u001b[39m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[1;32m--> 603\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_reduce(obj\u001b[39m=\u001b[39;49mobj, \u001b[39m*\u001b[39;49mrv)\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:717\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     \u001b[39mif\u001b[39;00m state_setter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 717\u001b[0m         save(state)\n\u001b[0;32m    718\u001b[0m         write(BUILD)\n\u001b[0;32m    719\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    720\u001b[0m         \u001b[39m# If a state_setter is specified, call it instead of load_build\u001b[39;00m\n\u001b[0;32m    721\u001b[0m         \u001b[39m# to update obj's with its previous state.\u001b[39;00m\n\u001b[0;32m    722\u001b[0m         \u001b[39m# First, push state_setter and its tuple of expected arguments\u001b[39;00m\n\u001b[0;32m    723\u001b[0m         \u001b[39m# (obj, state) onto the stack.\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\dill\\_dill.py:1251\u001b[0m, in \u001b[0;36msave_module_dict\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[0;32m   1249\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1251\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[0;32m   1252\u001b[0m     log\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1253\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[0;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[1;32m--> 971\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[0;32m    996\u001b[0m         save(k)\n\u001b[1;32m--> 997\u001b[0m         save(v)\n\u001b[0;32m    998\u001b[0m     write(SETITEMS)\n\u001b[0;32m    999\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\dill\\_dill.py:1251\u001b[0m, in \u001b[0;36msave_module_dict\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[0;32m   1249\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1251\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[0;32m   1252\u001b[0m     log\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1253\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[0;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[1;32m--> 971\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[0;32m    996\u001b[0m         save(k)\n\u001b[1;32m--> 997\u001b[0m         save(v)\n\u001b[0;32m    998\u001b[0m     write(SETITEMS)\n\u001b[0;32m    999\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(\u001b[39m\"\u001b[39m\u001b[39mTuple returned by \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m must have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    600\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mtwo to six elements\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m reduce)\n\u001b[0;32m    602\u001b[0m \u001b[39m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[1;32m--> 603\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_reduce(obj\u001b[39m=\u001b[39;49mobj, \u001b[39m*\u001b[39;49mrv)\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:717\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     \u001b[39mif\u001b[39;00m state_setter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 717\u001b[0m         save(state)\n\u001b[0;32m    718\u001b[0m         write(BUILD)\n\u001b[0;32m    719\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    720\u001b[0m         \u001b[39m# If a state_setter is specified, call it instead of load_build\u001b[39;00m\n\u001b[0;32m    721\u001b[0m         \u001b[39m# to update obj's with its previous state.\u001b[39;00m\n\u001b[0;32m    722\u001b[0m         \u001b[39m# First, push state_setter and its tuple of expected arguments\u001b[39;00m\n\u001b[0;32m    723\u001b[0m         \u001b[39m# (obj, state) onto the stack.\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\dill\\_dill.py:1251\u001b[0m, in \u001b[0;36msave_module_dict\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[0;32m   1249\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1251\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[0;32m   1252\u001b[0m     log\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1253\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[0;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[1;32m--> 971\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[0;32m    996\u001b[0m         save(k)\n\u001b[1;32m--> 997\u001b[0m         save(v)\n\u001b[0;32m    998\u001b[0m     write(SETITEMS)\n\u001b[0;32m    999\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(\u001b[39m\"\u001b[39m\u001b[39mTuple returned by \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m must have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    600\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mtwo to six elements\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m reduce)\n\u001b[0;32m    602\u001b[0m \u001b[39m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[1;32m--> 603\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_reduce(obj\u001b[39m=\u001b[39;49mobj, \u001b[39m*\u001b[39;49mrv)\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:717\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     \u001b[39mif\u001b[39;00m state_setter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 717\u001b[0m         save(state)\n\u001b[0;32m    718\u001b[0m         write(BUILD)\n\u001b[0;32m    719\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    720\u001b[0m         \u001b[39m# If a state_setter is specified, call it instead of load_build\u001b[39;00m\n\u001b[0;32m    721\u001b[0m         \u001b[39m# to update obj's with its previous state.\u001b[39;00m\n\u001b[0;32m    722\u001b[0m         \u001b[39m# First, push state_setter and its tuple of expected arguments\u001b[39;00m\n\u001b[0;32m    723\u001b[0m         \u001b[39m# (obj, state) onto the stack.\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\dill\\_dill.py:1251\u001b[0m, in \u001b[0;36msave_module_dict\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[0;32m   1249\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1251\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[0;32m   1252\u001b[0m     log\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1253\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[0;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[1;32m--> 971\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[0;32m    996\u001b[0m         save(k)\n\u001b[1;32m--> 997\u001b[0m         save(v)\n\u001b[0;32m    998\u001b[0m     write(SETITEMS)\n\u001b[0;32m    999\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\dill\\_dill.py:1251\u001b[0m, in \u001b[0;36msave_module_dict\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   1248\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[0;32m   1249\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[0;32m   1250\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1251\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[0;32m   1252\u001b[0m     log\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1253\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[0;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[1;32m--> 971\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[0;32m    996\u001b[0m         save(k)\n\u001b[1;32m--> 997\u001b[0m         save(v)\n\u001b[0;32m    998\u001b[0m     write(SETITEMS)\n\u001b[0;32m    999\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:589\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    587\u001b[0m \u001b[39m# Check for string returned by reduce(), meaning \"save as global\"\u001b[39;00m\n\u001b[0;32m    588\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(rv, \u001b[39mstr\u001b[39m):\n\u001b[1;32m--> 589\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_global(obj, rv)\n\u001b[0;32m    590\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    592\u001b[0m \u001b[39m# Assert that reduce() returned a tuple\u001b[39;00m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\pickle.py:1075\u001b[0m, in \u001b[0;36m_Pickler.save_global\u001b[1;34m(self, obj, name)\u001b[0m\n\u001b[0;32m   1073\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1074\u001b[0m     \u001b[39mif\u001b[39;00m obj2 \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m obj:\n\u001b[1;32m-> 1075\u001b[0m         \u001b[39mraise\u001b[39;00m PicklingError(\n\u001b[0;32m   1076\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt pickle \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m: it\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms not the same object as \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1077\u001b[0m             (obj, module_name, name))\n\u001b[0;32m   1079\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproto \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m   1080\u001b[0m     code \u001b[39m=\u001b[39m _extension_registry\u001b[39m.\u001b[39mget((module_name, name))\n",
      "\u001b[1;31mPicklingError\u001b[0m: Can't pickle <built-in function input>: it's not the same object as builtins.input"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "\n",
    "# dill.errors(obj, depth=0, exact=False, safe=False) # get errors for objects that fail to pickle\n",
    "# dill.pickles(obj, exact=False, safe=False, **kwds) # Quick check if object pickles with dill.\n",
    "# dill.get_objgraph\n",
    "\n",
    "def dump_session(file_path):\n",
    "  \"\"\"Pickle the current python session to be used in the worker.\n",
    "\n",
    "  Note: Due to the inconsistency in the first dump of dill dump_session we\n",
    "  create and load the dump twice to have consistent results in the worker and\n",
    "  the running session. Check: https://github.com/uqfoundation/dill/issues/195\n",
    "  \"\"\"\n",
    "  dill.dump_session(file_path)\n",
    "  dill.load_session(file_path)\n",
    "  return dill.dump_session(file_path)\n",
    "\n",
    "test_session_file = Path('output/test_pickled_session_2023-11-15.pkl').resolve()\n",
    "print(f'saving session to {test_session_file}')\n",
    "dump_session(test_session_file)\n",
    "\n",
    "# dill.detect.trace(True)\n",
    "# dill.dump_session(test_session_file) # PicklingError: Can't pickle : it's not the same object as builtins.input\n",
    "# PicklingError: Can't pickle .NewCol'>: it's not found as tables.description.Col._subclass_from_prefix..NewCol\n",
    "\n",
    "# with detect.trace('output/dill_trace_2023-09-21.log', mode='w') as log:\n",
    "#     # log(\"> D = %r\", D)\n",
    "#     dill.dump_session(test_session_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e635746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fe54599",
   "metadata": {},
   "source": [
    "# End Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a533ba8",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions failed: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 274, in check\n",
      "    superreload(m, reload, self.old_objects, self.shell)\n",
      "  File \"c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 365, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 323, in update_instances\n",
      "    object.__setattr__(ref, \"__class__\", new)\n",
      "TypeError: can't apply this __setattr__ to ComputationFunctionRegistryHolder object\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations failed: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 274, in check\n",
      "    superreload(m, reload, self.old_objects, self.shell)\n",
      "  File \"c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 365, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 323, in update_instances\n",
      "    object.__setattr__(ref, \"__class__\", new)\n",
      "TypeError: __class__ assignment only supported for heap types or ModuleType subclasses\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# (long_one_step_decoder_1D, short_one_step_decoder_1D), (long_one_step_decoder_2D, short_one_step_decoder_2D) = compute_short_long_constrained_decoders(curr_active_pipeline, recalculate_anyway=True)\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_epoch_context, short_epoch_context, global_epoch_context = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_epoch_name, short_epoch_name, global_epoch_name)]\n",
    "long_epoch_obj, short_epoch_obj = [Epoch(curr_active_pipeline.sess.epochs.to_dataframe().epochs.label_slice(an_epoch_name.removesuffix('_any'))) for an_epoch_name in [long_epoch_name, short_epoch_name]] #TODO 2023-11-10 20:41: - [ ] Issue with getting actual Epochs from sess.epochs for directional laps: emerges because long_epoch_name: 'maze1_any' and the actual epoch label in curr_active_pipeline.sess.epochs is 'maze1' without the '_any' part.\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_computation_config, short_computation_config, global_computation_config = [curr_active_pipeline.computation_results[an_epoch_name]['computation_config'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "long_pf2D, short_pf2D, global_pf2D = long_results.pf2D, short_results.pf2D, global_results.pf2D\n",
    "\n",
    "assert short_epoch_obj.n_epochs > 0, f'long_epoch_obj: {long_epoch_obj}, short_epoch_obj: {short_epoch_obj}'\n",
    "assert long_epoch_obj.n_epochs > 0, f'long_epoch_obj: {long_epoch_obj}, short_epoch_obj: {short_epoch_obj}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9071e94f",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: 2023-09-28 16:15: - [ ] fix the combination properties. Would work if we directly used the computed _is_L_only and _is_S_only above\n",
      "WARNING: PAPER_FIGURE_figure_1_add_replay_epoch_rasters(...): no user-assigned manually labeled replay epochs. Reeturning all epochs.\n",
      "WARN: 2023-09-28 16:15: - [ ] fix the combination properties. Would work if we directly used the computed _is_L_only and _is_S_only above\n"
     ]
    }
   ],
   "source": [
    "## long_short_decoding_analyses:\n",
    "curr_long_short_decoding_analyses = curr_active_pipeline.global_computation_results.computed_data['long_short_leave_one_out_decoding_analysis']\n",
    "long_one_step_decoder_1D, short_one_step_decoder_1D, long_replays, short_replays, global_replays, long_shared_aclus_only_decoder, short_shared_aclus_only_decoder, shared_aclus, long_short_pf_neurons_diff, n_neurons, long_results_obj, short_results_obj, is_global = curr_long_short_decoding_analyses.long_decoder, curr_long_short_decoding_analyses.short_decoder, curr_long_short_decoding_analyses.long_replays, curr_long_short_decoding_analyses.short_replays, curr_long_short_decoding_analyses.global_replays, curr_long_short_decoding_analyses.long_shared_aclus_only_decoder, curr_long_short_decoding_analyses.short_shared_aclus_only_decoder, curr_long_short_decoding_analyses.shared_aclus, curr_long_short_decoding_analyses.long_short_pf_neurons_diff, curr_long_short_decoding_analyses.n_neurons, curr_long_short_decoding_analyses.long_results_obj, curr_long_short_decoding_analyses.short_results_obj, curr_long_short_decoding_analyses.is_global \n",
    "decoding_time_bin_size = long_one_step_decoder_1D.time_bin_size # 1.0/30.0 # 0.03333333333333333\n",
    "\n",
    "## Get global `long_short_fr_indicies_analysis`:\n",
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "long_laps, long_replays, short_laps, short_replays, global_laps, global_replays = [long_short_fr_indicies_analysis_results[k] for k in ['long_laps', 'long_replays', 'short_laps', 'short_replays', 'global_laps', 'global_replays']]\n",
    "long_short_fr_indicies_df = long_short_fr_indicies_analysis_results['long_short_fr_indicies_df']\n",
    "\n",
    "## Get global 'long_short_post_decoding' results:\n",
    "curr_long_short_post_decoding = curr_active_pipeline.global_computation_results.computed_data['long_short_post_decoding']\n",
    "expected_v_observed_result, curr_long_short_rr = curr_long_short_post_decoding.expected_v_observed_result, curr_long_short_post_decoding.rate_remapping\n",
    "rate_remapping_df, high_remapping_cells_only = curr_long_short_rr.rr_df, curr_long_short_rr.high_only_rr_df\n",
    "Flat_epoch_time_bins_mean, Flat_decoder_time_bin_centers, num_neurons, num_timebins_in_epoch, num_total_flat_timebins, is_short_track_epoch, is_long_track_epoch, short_short_diff, long_long_diff = expected_v_observed_result.Flat_epoch_time_bins_mean, expected_v_observed_result.Flat_decoder_time_bin_centers, expected_v_observed_result.num_neurons, expected_v_observed_result.num_timebins_in_epoch, expected_v_observed_result.num_total_flat_timebins, expected_v_observed_result.is_short_track_epoch, expected_v_observed_result.is_long_track_epoch, expected_v_observed_result.short_short_diff, expected_v_observed_result.long_long_diff\n",
    "\n",
    "jonathan_firing_rate_analysis_result: JonathanFiringRateAnalysisResult = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis\n",
    "(epochs_df_L, epochs_df_S), (filter_epoch_spikes_df_L, filter_epoch_spikes_df_S), (good_example_epoch_indicies_L, good_example_epoch_indicies_S), (short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset), new_all_aclus_sort_indicies, assigning_epochs_obj = PAPER_FIGURE_figure_1_add_replay_epoch_rasters(curr_active_pipeline)\n",
    "neuron_replay_stats_df, short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset = jonathan_firing_rate_analysis_result.get_cell_track_partitions(frs_index_inclusion_magnitude=0.05)\n",
    "\n",
    "## Update long_exclusive/short_exclusive properties with `long_short_fr_indicies_df`\n",
    "# long_exclusive.refine_exclusivity_by_inst_frs_index(long_short_fr_indicies_df, frs_index_inclusion_magnitude=0.5)\n",
    "# short_exclusive.refine_exclusivity_by_inst_frs_index(long_short_fr_indicies_df, frs_index_inclusion_magnitude=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5be7a929",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n"
     ]
    }
   ],
   "source": [
    "# Unpack all directional variables:\n",
    "## {\"even\": \"RL\", \"odd\": \"LR\"}\n",
    "long_LR_name, short_LR_name, global_LR_name, long_RL_name, short_RL_name, global_RL_name, long_any_name, short_any_name, global_any_name = ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "\n",
    "# Most popular\n",
    "# long_LR_name, short_LR_name, long_RL_name, short_RL_name, global_any_name\n",
    "\n",
    "# Unpacking for `(long_LR_name, long_RL_name, short_LR_name, short_RL_name)`\n",
    "(long_LR_context, long_RL_context, short_LR_context, short_RL_context) = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj, global_any_laps_epochs_obj = [curr_active_pipeline.computation_results[an_epoch_name]['computation_config'].pf_params.computation_epochs for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name, global_any_name)] # note has global also\n",
    "(long_LR_session, long_RL_session, short_LR_session, short_RL_session) = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)] # sessions are correct at least, seems like just the computation parameters are messed up\n",
    "(long_LR_results, long_RL_results, short_LR_results, short_RL_results) = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_computation_config, long_RL_computation_config, short_LR_computation_config, short_RL_computation_config) = [curr_active_pipeline.computation_results[an_epoch_name]['computation_config'] for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_pf1D, long_RL_pf1D, short_LR_pf1D, short_RL_pf1D) = (long_LR_results.pf1D, long_RL_results.pf1D, short_LR_results.pf1D, short_RL_results.pf1D)\n",
    "(long_LR_pf2D, long_RL_pf2D, short_LR_pf2D, short_RL_pf2D) = (long_LR_results.pf2D, long_RL_results.pf2D, short_LR_results.pf2D, short_RL_results.pf2D)\n",
    "(long_LR_pf1D_Decoder, long_RL_pf1D_Decoder, short_LR_pf1D_Decoder, short_RL_pf1D_Decoder) = (long_LR_results.pf1D_Decoder, long_RL_results.pf1D_Decoder, short_LR_results.pf1D_Decoder, short_RL_results.pf1D_Decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84669e5c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "LR_ripple_rank_order_result, RL_ripple_rank_order_result, LR_laps_rank_order_result, RL_laps_rank_order_result = curr_active_pipeline.global_computation_results.computed_data['RankOrder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7c43b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover from the saved global result:\n",
    "# Unpacking:\n",
    "directional_laps_results = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "# directional_lap_specific_configs, split_directional_laps_dict, split_directional_laps_config_names, computed_base_epoch_names = [directional_laps_results[k] for k in ['directional_lap_specific_configs', 'split_directional_laps_dict', 'split_directional_laps_names', 'computed_base_epoch_names']]\n",
    "directional_lap_specific_configs, split_directional_laps_dict, split_directional_laps_contexts_dict, split_directional_laps_config_names, computed_base_epoch_names = [directional_laps_results.__dict__[k] for k in ['directional_lap_specific_configs', 'split_directional_laps_dict', 'split_directional_laps_contexts_dict', 'split_directional_laps_config_names', 'computed_base_epoch_names']]\n",
    "long_odd_shared_aclus_only_one_step_decoder_1D, long_even_shared_aclus_only_one_step_decoder_1D, short_odd_shared_aclus_only_one_step_decoder_1D, short_even_shared_aclus_only_one_step_decoder_1D = [directional_laps_results.__dict__[k] for k in ['long_odd_shared_aclus_only_one_step_decoder_1D', 'long_even_shared_aclus_only_one_step_decoder_1D', 'short_odd_shared_aclus_only_one_step_decoder_1D', 'short_even_shared_aclus_only_one_step_decoder_1D']]\n",
    "long_odd_laps_obj, long_even_laps_obj, short_odd_laps_obj, short_even_laps_obj = list(directional_laps_results.split_directional_laps_dict.values())\n",
    "\n",
    "# print(list(directional_laps_results.__dict__.keys()))\n",
    "# ['directional_lap_specific_configs', 'split_directional_laps_dict', 'split_directional_laps_contexts_dict', 'split_directional_laps_config_names', 'computed_base_epoch_names', 'long_odd_shared_aclus_only_one_step_decoder_1D', 'long_even_shared_aclus_only_one_step_decoder_1D', 'short_odd_shared_aclus_only_one_step_decoder_1D', 'short_even_shared_aclus_only_one_step_decoder_1D']\n",
    "\n",
    "split_directional_laps_config_names\n",
    "# split_directional_laps_config_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabbbaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display('_display_1d_placefields', 'maze1_odd')\n",
    "curr_active_pipeline.display('_display_1d_placefields', 'maze1_even')\n",
    "curr_active_pipeline.display('_display_1d_placefields', 'maze2_even')\n",
    "curr_active_pipeline.display('_display_1d_placefields', 'maze2_odd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beafdd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalDisplayFunctions\n",
    "_out = curr_active_pipeline.display(DirectionalPlacefieldGlobalDisplayFunctions._display_directional_laps_overview)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6beb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "win = _out['win']\n",
    "win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d50287",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_widget_hierarchy(win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bc7366",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = _out['app']\n",
    "app\n",
    "# TopLevelWindowHelper.top_level_windows(app)\n",
    "\n",
    "found_children = TopLevelWindowHelper.find_all_children_of_type(app, pg.PlotWidget)\n",
    "found_children\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be492440",
   "metadata": {},
   "outputs": [],
   "source": [
    "widget_classes = (pg.PlotWidget, pg.PlotItem, pg.ScatterPlotItem)\n",
    "found_widgets = win.findChildren(widget_classes)\n",
    "found_widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904e3fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_widgets = win.findChildren(widget_classes)\n",
    "found_widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226a7ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d12351",
   "metadata": {},
   "outputs": [],
   "source": [
    "win.findChildren(pg.QtWidgets.QWidget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84d613a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_widgets = win.findChildren(pg.PlotItem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48c07f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecb728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_pyqtgraph_plot(win)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafef423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8f24e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "area: pg.DockArea  = win.area\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca1456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "win.ui.area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c5e8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(_out.keys())\n",
    "_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a498473b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all exportable items:\n",
    "_out.plots["
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877e2806",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out['plots']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdcb379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import attr\n",
    "import attrs\n",
    "from attrs import define, field, Factory\n",
    "\n",
    "def create_class_from_dict(class_name, input_dict):\n",
    "    attributes = {}\n",
    "    for key, value in input_dict.items():\n",
    "        attributes[key] = attr.ib(type=type(value), default=value) # , repr=False\n",
    "\n",
    "    return attrs.make_class(class_name, attributes)\n",
    "\n",
    "TempGraphicsOutput = create_class_from_dict('TempGraphicsOutput', _out)\n",
    "TempGraphicsOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc77c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = TempGraphicsOutput()\n",
    "print(instance)\n",
    "\n",
    "grl = instance.plots\n",
    "grl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa36e31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyqtgraph.exporters\n",
    "\n",
    "exporter = pg.exporters.ImageExporter( grl.scene() ) # graphics layout widget (grl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d38dcc",
   "metadata": {},
   "source": [
    "## 2023-10-19 - Test Instantaneous Spike Rates and their visualizations during the Replay Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3b28c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.indexing_helpers import BinningContainer\n",
    "\n",
    "\n",
    "replay_instantaneous_time_bin_size_seconds = 0.01\n",
    "inst_replay_frs: SpikeRateTrends = SpikeRateTrends.init_from_spikes_and_epochs(spikes_df=global_session.spikes_df, filter_epochs=global_replays, included_neuron_ids=EITHER_subset.track_exclusive_aclus.copy(), instantaneous_time_bin_size_seconds=replay_instantaneous_time_bin_size_seconds)\n",
    "neuron_labels = [str(aclu) for aclu in inst_replay_frs.included_neuron_ids] # labels for plotting the epochs using `BasicBinnedImageRenderingWindow`\n",
    "# 26 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ea72d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_idx = 1\n",
    "a_replay_inst_frs = inst_replay_frs.inst_fr_df_list[epoch_idx].to_numpy() # (n_epoch_time_bins, n_cells)   ## OLD: #.T # (n_cells, n_epoch_time_bins)\n",
    "display(a_replay_inst_frs.shape)\n",
    "a_epoch_timebin_labels = [str(v) for v in np.arange(np.shape(a_replay_inst_frs)[0])]\n",
    "assert len(a_epoch_timebin_labels) == np.shape(a_replay_inst_frs)[0]\n",
    "assert len(neuron_labels) == np.shape(a_replay_inst_frs)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80f3926",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow, LayoutScrollability\n",
    "out = BasicBinnedImageRenderingWindow(a_replay_inst_frs, None, None, name='a_replay_inst_frs', title=\"Inst Fr for Replay Epoch\", variable_label='Inst FR', scrollability_mode=LayoutScrollability.NON_SCROLLABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e058584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_burst_intervals = curr_active_pipeline.computation_results[global_epoch_name].computed_data['burst_detection']['burst_intervals']\n",
    "active_burst_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fd793b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative Entropy/Surprise Results:\n",
    "active_extended_stats = global_results['extended_stats']\n",
    "active_relative_entropy_results = active_extended_stats['pf_dt_sequential_surprise'] # DynamicParameters\n",
    "historical_snapshots = active_relative_entropy_results['historical_snapshots']\n",
    "post_update_times: np.ndarray = active_relative_entropy_results['post_update_times'] # (4152,) = (n_post_update_times,)\n",
    "snapshot_differences_result_dict = active_relative_entropy_results['snapshot_differences_result_dict']\n",
    "time_intervals: np.ndarray = active_relative_entropy_results['time_intervals']\n",
    "surprise_time_bin_duration = (post_update_times[2]-post_update_times[1])\n",
    "long_short_rel_entr_curves_frames: np.ndarray = active_relative_entropy_results['long_short_rel_entr_curves_frames'] # (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "short_long_rel_entr_curves_frames: np.ndarray = active_relative_entropy_results['short_long_rel_entr_curves_frames'] # (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "flat_relative_entropy_results: np.ndarray = active_relative_entropy_results['flat_relative_entropy_results'] # (149, 63) - (nSnapshots, nXbins)\n",
    "flat_jensen_shannon_distance_results: np.ndarray = active_relative_entropy_results['flat_jensen_shannon_distance_results'] # (149, 63) - (nSnapshots, nXbins)\n",
    "flat_jensen_shannon_distance_across_all_positions: np.ndarray = np.sum(np.abs(flat_jensen_shannon_distance_results), axis=1) # sum across all position bins # (4152,) - (nSnapshots)\n",
    "flat_surprise_across_all_positions: np.ndarray = np.sum(np.abs(flat_relative_entropy_results), axis=1) # sum across all position bins # (4152,) - (nSnapshots)\n",
    "\n",
    "## Get the placefield dt matrix:\n",
    "if 'snapshot_occupancy_weighted_tuning_maps' not in active_relative_entropy_results:\n",
    "\t## Compute it if missing:\n",
    "\toccupancy_weighted_tuning_maps_over_time = np.stack([placefield_snapshot.occupancy_weighted_tuning_maps_matrix for placefield_snapshot in historical_snapshots.values()])\n",
    "\tactive_relative_entropy_results['snapshot_occupancy_weighted_tuning_maps'] = occupancy_weighted_tuning_maps_over_time\n",
    "else:\n",
    "\toccupancy_weighted_tuning_maps_over_time = active_relative_entropy_results['snapshot_occupancy_weighted_tuning_maps'] # (n_post_update_times, n_neurons, n_xbins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5597bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-dependent\n",
    "long_pf1D_dt, short_pf1D_dt, global_pf1D_dt = long_results.pf1D_dt, short_results.pf1D_dt, global_results.pf1D_dt\n",
    "long_pf2D_dt, short_pf2D_dt, global_pf2D_dt = long_results.pf2D_dt, short_results.pf2D_dt, global_results.pf2D_dt\n",
    "global_pf1D_dt: PfND_TimeDependent = global_results.pf1D_dt\n",
    "global_pf2D_dt: PfND_TimeDependent = global_results.pf2D_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483230a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## long_short_endcap_analysis: checks for cells localized to the endcaps that have their placefields truncated after shortening the track\n",
    "truncation_checking_result: TruncationCheckingResults = curr_active_pipeline.global_computation_results.computed_data.long_short_endcap\n",
    "disappearing_endcap_aclus = truncation_checking_result.disappearing_endcap_aclus\n",
    "# disappearing_endcap_aclus\n",
    "trivially_remapping_endcap_aclus = truncation_checking_result.minor_remapping_endcap_aclus\n",
    "# trivially_remapping_endcap_aclus\n",
    "significant_distant_remapping_endcap_aclus = truncation_checking_result.significant_distant_remapping_endcap_aclus\n",
    "# significant_distant_remapping_endcap_aclus\n",
    "appearing_aclus = jonathan_firing_rate_analysis_result.neuron_replay_stats_df[jonathan_firing_rate_analysis_result.neuron_replay_stats_df['track_membership'] == SplitPartitionMembership.RIGHT_ONLY].index\n",
    "# appearing_aclus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc4bbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_distant_remapping_endcap_aclus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aba9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import fig_remapping_cells\n",
    "\n",
    "graphics_output_dict = fig_remapping_cells(curr_active_pipeline=curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32b2281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023-11-10 - Adds \"LxC_PBEsDeltaMinus\" for PBEs \n",
    "\n",
    "\n",
    "temp = add_extra_spike_rate_trends(curr_active_pipeline)\n",
    "temp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac0ef2b",
   "metadata": {},
   "source": [
    "#  2023-10-20 - Z-Score Comparisons with Neuron_ID Shuffled templates\n",
    "1. Take the intersection of the long and short templates to get only the common cells\n",
    "2. Determine the long and short \"tempaltes\": this is done by ranking the aclus for each by their placefields' center of mass. `compute_placefield_center_of_masses`\n",
    "\t2a. `long_pf_peak_ranks`, `short_pf_peak_ranks` - there are one of each of these for each shared aclu.\n",
    "3. Generate the unit_id shuffled (`shuffled_aclus`, `shuffle_IDXs`) ahead of time to use to shuffle the two templates during the epochs.\n",
    "4. For each replay event, take each shuffled template\n",
    "\t4a. Iterate through each shuffle and obtain the shuffled templates like `long_pf_peak_ranks[epoch_specific_shuffled_indicies]`, `short_pf_peak_ranks[epoch_specific_shuffled_indicies]`\n",
    "\t4b. compute the spearman rank-order of the event and each shuffled template, and accumulate the results in `long_spearmanr_rank_stats_results`, `short_spearmanr_rank_stats_results`\n",
    "\n",
    "5. After we're done with the shuffle loop, accumulate the results and convert to the right output format.\n",
    "\n",
    "6. When all epochs are done, loop through the results (the epochs again) and compute the z-scores for each epoch so they can be compared to each other. Keep track of the means and std_dev for comparisons later, and subtract the two sets of z-scores (long/short) to get the delta_Z for each template.\n",
    "\n",
    "7. TODO: Next figure out what to do with the array of z-scores and delta_Z. We have:\n",
    "\tn_epochs sets of results\n",
    "\t\tn_shuffles scores of delta_Z\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fd9d61",
   "metadata": {},
   "source": [
    "## Convo with Kamran 2023-10-23:\n",
    "- Use directional templates **\n",
    "- No need to worry about re-ranking\n",
    "[X] Plot the long and short separately in addition to the difference, so we show significant reqplay on each as a sanity check\n",
    "[X] Absolute value difference?\n",
    "[X] Fisher transform the correlation values (check if there is a difference) because correlation coefficients aren't going to be normally distributed.\n",
    "\t[ ] Then Z-score releative to fisher.\n",
    "\n",
    "- T-test to compare to mean of zero (if looking at the difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419ffd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concerns:\n",
    "# 1. Permutation recommended over shuffling for small numbers of ids\n",
    "# 2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd86cb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nptyping import NDArray\n",
    "from attrs import define, field, Factory, astuple\n",
    "import scipy.stats\n",
    "from scipy import ndimage\n",
    "from neuropy.utils.misc import build_shuffled_ids # used in _SHELL_analyze_leave_one_out_decoding_results\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import pho_stats_paired_t_test\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import compute_shuffled_rankorder_analyses, build_track_templates_for_shuffle, compute_shuffled_rankorder_analyses\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import TrackTemplates, RankOrderAnalyses, ShuffleHelper, Zscorer\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.Extensions.pyqtgraph_helpers import build_pyqtgraph_epoch_indicator_regions\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import _helper_add_long_short_session_indicator_regions\n",
    "from pyphocorehelpers.DataStructure.general_parameter_containers import VisualizationParameters, RenderPlotsData, RenderPlots # PyqtgraphRenderPlots\n",
    "from pyphocorehelpers.gui.PhoUIContainer import PhoUIContainer\n",
    "from pyphocorehelpers.DataStructure.RenderPlots.PyqtgraphRenderPlots import PyqtgraphRenderPlots\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.RankOrderDebugger import GenericPyQtGraphContainer\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.RankOrderDebugger import GenericPyQtGraphScatterClicker\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.DockAreaWrapper import DockAreaWrapper, PhoDockAreaContainingWindow\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderComputationsContainer, RankOrderResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17402af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover from the saved global result:\n",
    "directional_laps_results = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "long_odd_shared_aclus_only_one_step_decoder_1D, long_even_shared_aclus_only_one_step_decoder_1D, short_odd_shared_aclus_only_one_step_decoder_1D, short_even_shared_aclus_only_one_step_decoder_1D = [directional_laps_results.__dict__[k] for k in ['long_odd_shared_aclus_only_one_step_decoder_1D', 'long_even_shared_aclus_only_one_step_decoder_1D', 'short_odd_shared_aclus_only_one_step_decoder_1D', 'short_even_shared_aclus_only_one_step_decoder_1D']]\n",
    "track_templates: TrackTemplates = TrackTemplates.init_from_paired_decoders(LR_decoder_pair=(long_odd_shared_aclus_only_one_step_decoder_1D, short_odd_shared_aclus_only_one_step_decoder_1D), RL_decoder_pair=(long_even_shared_aclus_only_one_step_decoder_1D, short_even_shared_aclus_only_one_step_decoder_1D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd9d83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack all directional variables:\n",
    "## {\"even\": \"RL\", \"odd\": \"LR\"}\n",
    "long_LR_name, short_LR_name, global_LR_name, long_RL_name, short_RL_name, global_RL_name, long_any_name, short_any_name, global_any_name = ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "\n",
    "# Most popular\n",
    "# long_LR_name, short_LR_name, long_RL_name, short_RL_name, global_any_name\n",
    "\n",
    "# Unpacking for `(long_LR_name, long_RL_name, short_LR_name, short_RL_name)`\n",
    "(long_LR_context, long_RL_context, short_LR_context, short_RL_context) = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj, global_any_laps_epochs_obj = [curr_active_pipeline.computation_results[an_epoch_name]['computation_config'].pf_params.computation_epochs for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name, global_any_name)] # note has global also\n",
    "(long_LR_session, long_RL_session, short_LR_session, short_RL_session) = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)] # sessions are correct at least, seems like just the computation parameters are messed up\n",
    "(long_LR_results, long_RL_results, short_LR_results, short_RL_results) = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_computation_config, long_RL_computation_config, short_LR_computation_config, short_RL_computation_config) = [curr_active_pipeline.computation_results[an_epoch_name]['computation_config'] for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_pf1D, long_RL_pf1D, short_LR_pf1D, short_RL_pf1D) = (long_LR_results.pf1D, long_RL_results.pf1D, short_LR_results.pf1D, short_RL_results.pf1D)\n",
    "(long_LR_pf2D, long_RL_pf2D, short_LR_pf2D, short_RL_pf2D) = (long_LR_results.pf2D, long_RL_results.pf2D, short_LR_results.pf2D, short_RL_results.pf2D)\n",
    "(long_LR_pf1D_Decoder, long_RL_pf1D_Decoder, short_LR_pf1D_Decoder, short_RL_pf1D_Decoder) = (long_LR_results.pf1D_Decoder, long_RL_results.pf1D_Decoder, short_LR_results.pf1D_Decoder, short_RL_results.pf1D_Decoder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3131a972",
   "metadata": {},
   "source": [
    "#  READY/NEXT: 2023-11-10 - All directional pf1D works for merging all four 1D templates!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ea4651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses.placefields import PfND\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BasePositionDecoder\n",
    "from neuropy.utils.mixins.time_slicing import TimeColumnAliasesProtocol\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "\n",
    "# Use the four epochs to make to a pseudo-y:\n",
    "all_directional_decoder_names = ['long_LR', 'long_RL', 'short_LR', 'short_RL']\n",
    "all_directional_pf1D = PfND.build_merged_directional_placefields(deepcopy(long_LR_pf1D), deepcopy(long_RL_pf1D), deepcopy(short_LR_pf1D), deepcopy(short_RL_pf1D), debug_print=False)\n",
    "all_directional_pf1D_Decoder = BasePositionDecoder(all_directional_pf1D, setup_on_init=True, post_load_on_init=True, debug_print=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6a5960",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Combine the non-directional PDFs and renormalize to get the directional PDF:\n",
    "# Inputs: long_LR_pf1D, long_RL_pf1D\n",
    "all_directional_decoder_names = ['long_LR', 'long_RL']\n",
    "long_directional_pf1D = PfND.build_merged_directional_placefields(deepcopy(long_LR_pf1D), deepcopy(long_RL_pf1D), debug_print=False)\n",
    "long_directional_pf1D_Decoder = BasePositionDecoder(long_directional_pf1D, setup_on_init=True, post_load_on_init=True, debug_print=False)\n",
    "# takes 6.3 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c649977",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_directional_pf1D_Decoder.ratemap.dims_coord_tuple \n",
    "all_directional_pf1D_Decoder.ratemap.ndim\n",
    "all_directional_pf1D_Decoder.ratemap.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f959b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed18d778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ad03a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should easily be able to plot the placefields, the occupancy:\n",
    "\n",
    "all_directional_pf1D_Decoder.ratemap\n",
    "\n",
    "np.print_options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9c0a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.DockAreaWrapper import DockAreaWrapper, PhoDockAreaContainingWindow\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum, LongShortDisplayConfigManager\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsWidgets.EpochsEditorItem import EpochsEditor # perform_plot_laps_diagnoser\n",
    "from pyphoplacecellanalysis.External.pyqtgraph.dockarea.Dock import Dock, DockDisplayConfig\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap_pyqtgraph # used in `plot_kourosh_activity_style_figure`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import TrackTemplates # _display_directional_laps_overview\n",
    "\n",
    "# uses `global_session`\n",
    "epochs_editor = EpochsEditor.init_from_session(global_session, include_velocity=False, include_accel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea764a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization:\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap, visualize_heatmap_pyqtgraph\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.plot_placefields import pyqtplot_plot_image_array, display_all_pf_2D_pyqtgraph_binned_image_rendering\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow, LayoutScrollability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901dd63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _display_fn_BasePositionDecoder_visualize_heatmap_pyqtgraph(a_decoder: BasePositionDecoder, a_decoder_name:Optional[str]=None):\n",
    "\tdef _get_decoder_sorted_pfs(a_decoder):\n",
    "\t\tratemap = a_decoder.pf.ratemap\n",
    "\t\tCoM_sort_indicies = np.argsort(ratemap.peak_tuning_curve_center_of_masses) # get the indicies to sort the placefields by their center-of-mass (CoM) location\n",
    "\t\t# CoM_sort_indicies.shape # (n_neurons,)\n",
    "\t\treturn ratemap.pdf_normalized_tuning_curves[CoM_sort_indicies, :]\n",
    "\ta_decoder_name = a_decoder_name or 'new'\n",
    "\treturn visualize_heatmap_pyqtgraph(_get_decoder_sorted_pfs(a_decoder), title=f'{a_decoder_name}_pf1Ds', show_value_labels=False, show_xticks=False, show_yticks=False, show_colorbar=False, win=None, defer_show=True)\n",
    "\n",
    "\n",
    "_display_fn_BasePositionDecoder_visualize_heatmap_pyqtgraph(all_directional_pf1D_Decoder, a_decoder_name='all_directional_pf1D_Decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa7d28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode using long_directional_decoder\n",
    "global_spikes_df, (odd_shuffle_helper, even_shuffle_helper) = RankOrderAnalyses.common_analysis_helper(curr_active_pipeline=curr_active_pipeline, num_shuffles=1000)\n",
    "spikes_df = deepcopy(global_spikes_df) #.spikes.sliced_by_neuron_id(track_templates.shared_aclus_only_neuron_IDs)\n",
    "global_replays = TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].replay))\n",
    "# long_directional_decoding_result: DecodedFilterEpochsResult = long_directional_pf1D_Decoder.decode_specific_epochs(spikes_df, global_replays, decoding_time_bin_size=0.01)\n",
    "all_directional_decoding_result: DecodedFilterEpochsResult = all_directional_pf1D_Decoder.decode_specific_epochs(spikes_df, global_replays, decoding_time_bin_size=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8702b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_directional_decoding_result.marginal_y_list.p_x_given_n_list\n",
    "list(all_directional_decoding_result.marginal_y_list[0].keys()) # ['p_x_given_n', 'most_likely_positions_1D']\n",
    "\n",
    "\n",
    "_out_marginal_y_p_x_given_n = [all_directional_decoding_result.marginal_y_list[i]['p_x_given_n'] for i in np.arange(len(all_directional_decoding_result.marginal_y_list))]\n",
    "_out_marginal_y_p_x_given_n[0].shape # (4, 26)\n",
    "\n",
    "\n",
    "_out_marginal_y_p_x_given_n_arr = np.stack(_out_marginal_y_p_x_given_n, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c414a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out = BasicBinnedImageRenderingWindow(a_replay_inst_frs, None, None, name='a_replay_inst_frs', title=\"Inst Fr for Replay Epoch\", variable_label='Inst FR', scrollability_mode=LayoutScrollability.NON_SCROLLABLE)\n",
    "# out.add_data(row=1, col=0, matrix=binned_x_transition_matrix_higher_order_list[1], xbins=pf1D.xbin_labels, ybins=pf1D.ybin_labels, name='binned_x_transition_matrix^2', title='2nd Order Transition Matrix for binned x (from, to)', variable_label='2nd Order Transition Matrix') # , scrollability_mode=LayoutScrollability.NON_SCROLLABLE\n",
    "# out.add_data(row=2, col=0, matrix=binned_x_transition_matrix_higher_order_list[2], xbins=pf1D.xbin_labels, ybins=pf1D.ybin_labels, name='binned_x_transition_matrix^3', title='3rd Order Transition Matrix for binned x (from, to)', variable_label='3rd Order Transition Matrix') # , scrollability_mode=LayoutScrollability.NON_SCROLLABLE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca5910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_decoding_result = long_directional_decoding_result\n",
    "active_decoding_result = all_directional_decoding_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cbfad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_decoding_result.p_x_given_n_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fc6181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# marginalize over the direction to find which direction is most likely\n",
    "epoch_idx = 0\n",
    "\n",
    "# long_directional_marginalized\n",
    "active_decoding_result.marginal_y_list[epoch_idx].p_x_given_n\n",
    "\n",
    "# np.sum(long_directional_decoding_result.marginal_y_list[epoch_idx].p_x_given_n, axis=0)\n",
    "\n",
    "time_bins = active_decoding_result.time_bin_containers[epoch_idx]\n",
    "len(time_bins.centers)\n",
    "time_bins.num_bins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150a1763",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_decoding_result.nbins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd47fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.sum(active_decoding_result.marginal_y_list[epoch_idx].p_x_given_n, axis=1)/active_decoding_result.time_bin_containers[epoch_idx].num_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5a94ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    " #.shape # (2, n_bins)\n",
    "\n",
    "# sum across timebins to get total likelihood for each of the two directions\n",
    "long_relative_direction_likelihoods = np.vstack([(np.sum(active_decoding_result.marginal_y_list[epoch_idx].p_x_given_n, axis=1)/active_decoding_result.time_bin_containers[epoch_idx].num_bins) for epoch_idx in np.arange(active_decoding_result.num_filter_epochs)]) # should get 2 values\n",
    "display(long_relative_direction_likelihoods.shape) # (n_epochs, 2)\n",
    "long_relative_direction_likelihoods\n",
    "\n",
    "# np.all(np.sum(long_relative_direction_likelihoods, axis=1) == 1)\n",
    "np.sum(long_relative_direction_likelihoods, axis=1) # not sure why some NaN values are getting in there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4f94bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_good_epoch = np.isfinite(np.sum(long_relative_direction_likelihoods, axis=1))\n",
    "is_good_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe2e7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = BasicBinnedImageRenderingWindow(long_relative_direction_likelihoods, None, None, name='long_relative_direction_likelihoods', title=\"Directional Decoder Prob for Replay Epochs\", variable_label='P_x_given_n', scrollability_mode=LayoutScrollability.NON_SCROLLABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232f7465",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_relative_direction_likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192e4879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68de0826",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_relative_direction_likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a424f450",
   "metadata": {},
   "outputs": [],
   "source": [
    "win = pg.GraphicsWindow()\n",
    "win.setWindowTitle('DOTS')\n",
    "# pg.plot(long_relative_direction_likelihoods.T[0], pen=None, symbol='o', symbolPen=None, symbolSize=4, symbolBrush=('b'), name='LR', win=win)\n",
    "# pg.plot(long_relative_direction_likelihoods.T[1], pen=None, symbol='o', symbolPen=None, symbolSize=4, symbolBrush=('r'), name='RL', win=win)\n",
    "p1 = win.addPlot() \n",
    "curve1 = p1.plot()\n",
    "curve2 = p1.plot()\n",
    "\n",
    "#Blue Dots\n",
    "curve1.setData(long_relative_direction_likelihoods.T[0], pen=None, symbol='o', symbolPen=None, symbolSize=4, symbolBrush=('b'), name='LR')\n",
    "#Red Dots\n",
    "curve2.setData(long_relative_direction_likelihoods.T[1], pen=None, symbol='o', symbolPen=None, symbolSize=4, symbolBrush=('r'), name='RL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784c4158",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Blue Dots\n",
    "curve1.setData(long_relative_direction_likelihoods.T[0], pen=None, symbol='o', symbolPen=None, symbolSize=4, symbolBrush=('b'), name='LR')\n",
    "#Red Dots\n",
    "curve2.setData(long_relative_direction_likelihoods.T[1], pen=None, symbol='o', symbolPen=None, symbolSize=4, symbolBrush=('r'), name='RL')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea2f309",
   "metadata": {},
   "source": [
    "# PhoKamran2023Paper Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162d813d",
   "metadata": {},
   "source": [
    "## Figure 1) pf1D Ratemaps, Active set, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273696fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot, plot_raster_plot\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap_pyqtgraph # used in `plot_kourosh_activity_style_figure`\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_1_add_replay_epoch_rasters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27e037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "pf1d_compare_graphics, (example_epoch_rasters_L, example_epoch_rasters_S), example_stacked_epoch_graphics, fig_1c_figures_out_dict = PAPER_FIGURE_figure_1_full(curr_active_pipeline) # did not display the pf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fa9acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = jonathan_firing_rate_analysis_result.rdf.rdf\n",
    "rdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cba3c7a",
   "metadata": {},
   "source": [
    "## Figure 2) `PaperFigureTwo`: LxC/SxC Analyses\n",
    "Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d3e1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PaperFigureTwo\n",
    "\n",
    "_out_fig_2 = PaperFigureTwo(instantaneous_time_bin_size_seconds=0.01) # 10ms\n",
    "_out_fig_2.compute(curr_active_pipeline=curr_active_pipeline)\n",
    "_out_fig_2.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a52142",
   "metadata": {},
   "source": [
    "## Figure 3) `PAPER_FIGURE_figure_3`: Firing Rate Index and Long/Short Firing Rate Replays v. Laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f765ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.matplotlib_helpers import FormattedFigureText\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import _plot_long_short_firing_rate_indicies\n",
    "# curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "_out, _out2 = PAPER_FIGURE_figure_3(curr_active_pipeline, defer_render=False, save_figure=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a3a1eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
