{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0056bc66-7629-4ef7-8c87-f28f8fcd9dc8",
   "metadata": {
    "autorun": true,
    "tags": [
     "imports",
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "build_module_logger(module_name=\"Spike3D.pipeline\"):\n",
      "\t Module logger com.PhoHale.Spike3D.pipeline has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.Spike3D.pipeline.log\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "# %load_ext viztracer\n",
    "# from viztracer import VizTracer\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from benedict import benedict\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "from copy import deepcopy\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from benedict import benedict # https://github.com/fabiocaccamo/python-benedict#usage\n",
    "\n",
    "# Pho's Formatting Preferences\n",
    "# from pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\n",
    "# set_pho_preferences_concise()\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.general_helpers import CodeConversion\n",
    "from pyphocorehelpers.function_helpers import function_attributes\n",
    "from pyphocorehelpers.print_helpers import print_keys_if_possible, print_value_overview_only, document_active_variables, objsize, print_object_memory_usage, debug_dump_object_member_shapes, TypePrintMode\n",
    "from pyphocorehelpers.print_helpers import get_now_day_str, get_now_time_str, get_now_time_precise_str\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "# from neuropy import core\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.core.epoch import NamedTimerange\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.BapunDataSessionFormat import BapunDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.RachelDataSessionFormat import RachelDataSessionFormat\n",
    "from neuropy.core.session.Formats.Specific.HiroDataSessionFormat import HiroDataSessionFormatRegisteredClass\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveWrapper import batch_load_session, batch_extended_computations, SessionBatchProgress, batch_programmatic_figures, batch_extended_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap\n",
    "\n",
    "# from PendingNotebookCode import _perform_batch_plot, _build_batch_plot_kwargs\n",
    "\n",
    "session_batch_status = {}\n",
    "session_batch_errors = {}\n",
    "enable_saving_to_disk = False\n",
    "\n",
    "global_data_root_parent_path = find_first_extant_path([Path(r'W:\\Data'), Path(r'/media/MAX/Data'), Path(r'/Volumes/MoverNew/data')])\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1538e2a-4e39-4d11-90b5-a9fef9258058",
   "metadata": {
    "tags": [
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "source": [
    "# Load Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f917bad9-8fe7-4882-b83b-71cf878fffd2",
   "metadata": {
    "tags": [
     "load",
     "REQUIRED"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_session_names_list: ['2006-6-07_16-40-19', '2006-6-12_16-53-46', '2006-6-09_22-24-40', '2006-6-13_15-22-3', '2006-6-08_21-16-25', '2006-6-08_15-46-47']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{PosixPath('/media/MAX/Data/KDIBA/gor01/two/2006-6-07_16-40-19'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " PosixPath('/media/MAX/Data/KDIBA/gor01/two/2006-6-12_16-53-46'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " PosixPath('/media/MAX/Data/KDIBA/gor01/two/2006-6-09_22-24-40'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " PosixPath('/media/MAX/Data/KDIBA/gor01/two/2006-6-13_15-22-3'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " PosixPath('/media/MAX/Data/KDIBA/gor01/two/2006-6-08_21-16-25'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " PosixPath('/media/MAX/Data/KDIBA/gor01/two/2006-6-08_15-46-47'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Load Data                                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "active_data_mode_name = 'kdiba'\n",
    "\n",
    "## Data must be pre-processed using the MATLAB script located here: \n",
    "#     neuropy/data_session_pre_processing_scripts/KDIBA/IIDataMat_Export_ToPython_2022_08_01.m\n",
    "# From pre-computed .mat files:\n",
    "\n",
    "local_session_root_parent_context = IdentifyingContext(format_name=active_data_mode_name) # , animal_name='', configuration_name='one', session_name=self.session_name\n",
    "local_session_root_parent_path = global_data_root_parent_path.joinpath('KDIBA')\n",
    "\n",
    "# Animal `gor01`:\n",
    "# local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='gor01', exper_name='one') # IdentifyingContext<('kdiba', 'gor01', 'one')>\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name) # 'gor01', 'one'\n",
    "# local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=['PhoHelpers', 'Spike3D-Minimal-Test', 'Unused'])\n",
    "\n",
    "local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='gor01', exper_name='two')\n",
    "local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name)\n",
    "local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=[])\n",
    "\n",
    "# ## Animal `vvp01`:\n",
    "# local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='vvp01', exper_name='one')\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name)\n",
    "# local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=[])\n",
    "\n",
    "# local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='vvp01', exper_name='two')\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name)\n",
    "# local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=[])\n",
    "\n",
    "# ### Animal `pin01`:\n",
    "# local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='pin01', exper_name='one')\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name) # no exper_name ('one' or 'two') folders for this animal.\n",
    "# local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=['redundant','showclus','sleep','tmaze'])\n",
    "\n",
    "## Build session contexts list:\n",
    "local_session_contexts_list = [local_session_parent_context.adding_context(collision_prefix='sess', session_name=a_name) for a_name in local_session_names_list] # [IdentifyingContext<('kdiba', 'gor01', 'one', '2006-6-07_11-26-53')>, ..., IdentifyingContext<('kdiba', 'gor01', 'one', '2006-6-13_14-42-6')>]\n",
    "\n",
    "## Initialize `session_batch_status` with the NOT_STARTED status if it doesn't already have a different status\n",
    "for curr_session_basedir in local_session_paths_list:\n",
    "    curr_session_status = session_batch_status.get(curr_session_basedir, None)\n",
    "    if curr_session_status is None:\n",
    "        session_batch_status[curr_session_basedir] = SessionBatchProgress.NOT_STARTED # set to not started if not present\n",
    "        # session_batch_status[curr_session_basedir] = SessionBatchProgress.COMPLETED # set to not started if not present\n",
    "\n",
    "session_batch_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d13e68b4-03e0-4388-a35c-87a352a6e6b3",
   "metadata": {
    "tags": [
     "load",
     "single_session",
     "REQUIRED"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "basedir: /media/MAX/Data/KDIBA/gor01/two/2006-6-07_16-40-19\n",
      "Loading loaded session pickle file results : /media/MAX/Data/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle.pkl... done.\n",
      "Loading pickled pipeline success: /media/MAX/Data/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle.pkl.\n",
      "property already present in pickled version. No need to save.\n",
      "using provided computation_functions_name_whitelist: ['_perform_baseline_placefield_computation', '_perform_time_dependent_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_time_dependent_pf_sequential_surprise_computation_perform_two_step_position_decoding_computation']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the blacklist/whitelist or computation function definitions change. Rework so that this is smarter.\n",
      "updating computation_results...\n",
      "done.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the blacklist/whitelist or computation function definitions change. Rework so that this is smarter.\n",
      "updating computation_results...\n",
      "done.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the blacklist/whitelist or computation function definitions change. Rework so that this is smarter.\n",
      "updating computation_results...\n",
      "done.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n"
     ]
    }
   ],
   "source": [
    "%pdb off\n",
    "# %%viztracer\n",
    "basedir = local_session_paths_list[0] # NOT 3\n",
    "print(f'basedir: {str(basedir)}')\n",
    "\n",
    "## Read if possible:\n",
    "saving_mode = PipelineSavingScheme.SKIP_SAVING\n",
    "force_reload = False\n",
    "\n",
    "# # Force write:\n",
    "# saving_mode = PipelineSavingScheme.OVERWRITE_IN_PLACE\n",
    "# force_reload = True\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "# epoch_name_whitelist = ['maze']\n",
    "epoch_name_whitelist = None\n",
    "active_computation_functions_name_whitelist=['_perform_baseline_placefield_computation', '_perform_time_dependent_placefield_computation', '_perform_extended_statistics_computation',\n",
    "                                        '_perform_position_decoding_computation', \n",
    "                                        '_perform_firing_rate_trends_computation',\n",
    "                                        # '_perform_pf_find_ratemap_peaks_computation',\n",
    "                                        '_perform_time_dependent_pf_sequential_surprise_computation'\n",
    "                                        '_perform_two_step_position_decoding_computation',\n",
    "                                        # '_perform_recursive_latent_placefield_decoding'\n",
    "                                    ]\n",
    "curr_active_pipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_whitelist=epoch_name_whitelist,\n",
    "                                          computation_functions_name_whitelist=active_computation_functions_name_whitelist,\n",
    "                                          saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                          skip_extended_batch_computations=True, debug_print=False, fail_on_exception=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e403d1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sane_midpoint_x: 118.93433364528494, hardcoded_track_midpoint_x: 150.0, track_min_max_x: (18.67140495721134, 256.5400722477812)\n",
      "desc_crossings_x: (20,), asc_crossings_x: (20,)\n"
     ]
    }
   ],
   "source": [
    "from neuropy.analyses.placefields import PfND\n",
    "from neuropy.analyses.laps import estimate_session_laps\n",
    "\n",
    "## 2023-04-07 - Builds the laps using estimation_session_laps(...) if needed for each epoch, and then sets the decoder's .epochs property to the laps object so the occupancy is correct.\n",
    "def constrain_to_laps(curr_active_pipeline):\n",
    "\t\"\"\" 2023-04-07 - Constrains the placefields to just the laps, computing the laps if needed.\n",
    "\tOther laps-related things?\n",
    "\t\t# ??? pos_df = sess.compute_position_laps() # ensures the laps are computed if they need to be:\n",
    "\t\t# DataSession.compute_position_laps(self)\n",
    "\t\t# DataSession.compute_laps_position_df(position_df, laps_df)\n",
    "\t\"\"\"\n",
    "\tlong_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "\tlong_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "\tlong_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "\n",
    "\tfor a_name, a_sess, a_result in zip((long_epoch_name, short_epoch_name, global_epoch_name), (long_session, short_session, global_session), (long_results, short_results, global_results)):\n",
    "\t\ta_sess = estimate_session_laps(a_sess, should_plot_laps_2d=False)\n",
    "\t\tcurr_laps_obj = a_sess.laps.as_epoch_obj() # set this to the laps object\n",
    "\t\tcurr_laps_obj = curr_laps_obj.get_non_overlapping()\n",
    "\t\tcurr_laps_obj = curr_laps_obj.filtered_by_duration(1.0, 10.0) # the lap must be at least 1 second long and at most 10 seconds long\n",
    "\t\t# curr_laps_obj = a_sess.estimate_laps().as_epoch_obj()\n",
    "\t\tcurr_active_pipeline.active_configs[a_name].computation_config.pf_params.computation_epochs = curr_laps_obj\n",
    "\t\tcurr_pf1D, curr_pf2D = a_result.pf1D, a_result.pf2D\n",
    "\n",
    "\t\tlap_filtered_curr_pf1D = deepcopy(curr_pf1D)\n",
    "\t\tlap_filtered_curr_pf1D = PfND(spikes_df=lap_filtered_curr_pf1D.spikes_df, position=lap_filtered_curr_pf1D.position, epochs=deepcopy(curr_laps_obj), config=lap_filtered_curr_pf1D.config, compute_on_init=True)\n",
    "\t\tlap_filtered_curr_pf2D = deepcopy(curr_pf2D)\n",
    "\t\tlap_filtered_curr_pf2D = PfND(spikes_df=lap_filtered_curr_pf2D.spikes_df, position=lap_filtered_curr_pf2D.position, epochs=deepcopy(curr_laps_obj), config=lap_filtered_curr_pf2D.config, compute_on_init=True)\n",
    "\t\ta_result.pf1D = lap_filtered_curr_pf1D\n",
    "\t\ta_result.pf2D = lap_filtered_curr_pf2D\n",
    "\t\treturn curr_active_pipeline\n",
    "\n",
    "curr_active_pipeline = constrain_to_laps(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02f14325",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "long_one_step_decoder_1D, short_one_step_decoder_1D  = [results_data.get('pf1D_Decoder', None) for results_data in (long_results, short_results)]\n",
    "recalculate_anyway = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f54a9300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (13754,) should be less than time_window_edges: (35786,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (13754,) should be less than time_window_edges: (35786,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (18163,) should be less than time_window_edges: (40455,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (18163,) should be less than time_window_edges: (40455,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "self will be re-binned to match target_pf...\n",
      "done.\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (18163,) should be less than time_window_edges: (40455,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (18163,) should be less than time_window_edges: (40455,)!\n",
      "decoding_time_bin_size: 0.03333\n"
     ]
    }
   ],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_position_decoding_computation'], computation_kwargs_list=[dict(ndim=1)], enabled_filter_names=[long_epoch_name, short_epoch_name], fail_on_exception=True, debug_print=True)\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "# long_one_step_decoder_1D, short_one_step_decoder_1D  = [results_data.get('pf1D_Decoder', None) for results_data in (long_results, short_results)]\n",
    "long_one_step_decoder_1D, short_one_step_decoder_1D  = [deepcopy(results_data.get('pf1D_Decoder', None)) for results_data in (long_results, short_results)]\n",
    "# ds and Decoders conform between the long and the short epochs:\n",
    "short_one_step_decoder_1D, did_recompute = short_one_step_decoder_1D.conform_to_position_bins(long_one_step_decoder_1D, force_recompute=True)\n",
    "\n",
    "# ## Build or get the two-step decoders for both the long and short:\n",
    "# long_two_step_decoder_1D, short_two_step_decoder_1D  = [results_data.get('pf1D_TwoStepDecoder', None) for results_data in (long_results, short_results)]\n",
    "# if recalculate_anyway or did_recompute or (long_two_step_decoder_1D is None) or (short_two_step_decoder_1D is None):\n",
    "#     curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_two_step_position_decoding_computation'], computation_kwargs_list=[dict(ndim=1)], enabled_filter_names=[long_epoch_name, short_epoch_name], fail_on_exception=True, debug_print=True)\n",
    "#     long_two_step_decoder_1D, short_two_step_decoder_1D  = [results_data.get('pf1D_TwoStepDecoder', None) for results_data in (long_results, short_results)]\n",
    "#     assert (long_two_step_decoder_1D is not None and short_two_step_decoder_1D is not None)\n",
    "\n",
    "decoding_time_bin_size = long_one_step_decoder_1D.time_bin_size # 1.0/30.0 # 0.03333333333333333\n",
    "# decoding_time_bin_size = 0.03 # 0.03333333333333333\n",
    "print(f'decoding_time_bin_size: {decoding_time_bin_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e20ceb",
   "metadata": {},
   "source": [
    "#### Get 2D Decoders for validation and comparisons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26c39017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (13754,) should be less than time_window_edges: (35786,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (13754,) should be less than time_window_edges: (35786,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (18163,) should be less than time_window_edges: (40455,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (18163,) should be less than time_window_edges: (40455,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (18163,) should be less than time_window_edges: (40455,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (18163,) should be less than time_window_edges: (40455,)!\n",
      "np.sum(long_one_step_decoder_2D.marginal.x.p_x_given_n) =36142.00000000002,\t np.sum(long_one_step_decoder_1D.p_x_given_n) = 36142.0\n"
     ]
    }
   ],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_position_decoding_computation'], computation_kwargs_list=[dict(ndim=2)], enabled_filter_names=[long_epoch_name, short_epoch_name], fail_on_exception=True, debug_print=True)\n",
    "# Make the 2D Placefields and Decoders conform between the long and the short epochs:\n",
    "long_pf2D, short_pf2D, global_pf2D = long_results.pf2D, short_results.pf2D, global_results.pf2D\n",
    "long_one_step_decoder_2D, short_one_step_decoder_2D  = [results_data.get('pf2D_Decoder', None) for results_data in (long_results, short_results)]\n",
    "short_one_step_decoder_2D, did_recompute = short_one_step_decoder_2D.conform_to_position_bins(long_one_step_decoder_2D)\n",
    "\n",
    "# ## Build or get the two-step decoders for both the long and short:\n",
    "# long_two_step_decoder_2D, short_two_step_decoder_2D  = [results_data.get('pf2D_TwoStepDecoder', None) for results_data in (long_results, short_results)]\n",
    "# if recalculate_anyway or did_recompute or (long_two_step_decoder_2D is None) or (short_two_step_decoder_2D is None):\n",
    "#     curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_two_step_position_decoding_computation'], computation_kwargs_list=[dict(ndim=2)], enabled_filter_names=[long_epoch_name, short_epoch_name], fail_on_exception=True, debug_print=True)\n",
    "#     long_two_step_decoder_2D, short_two_step_decoder_2D  = [results_data.get('pf2D_TwoStepDecoder', None) for results_data in (long_results, short_results)]\n",
    "#     assert (long_two_step_decoder_2D is not None and short_two_step_decoder_2D is not None)\n",
    "# Sums are similar:\n",
    "print(f'{np.sum(long_one_step_decoder_2D.marginal.x.p_x_given_n) =},\\t {np.sum(long_one_step_decoder_1D.p_x_given_n) = }') # 31181.999999999996 vs 31181.99999999999\n",
    "\n",
    "## Validate:\n",
    "assert long_one_step_decoder_2D.marginal.x.p_x_given_n.shape == long_one_step_decoder_1D.p_x_given_n.shape, f\"Must equal but: {long_one_step_decoder_2D.marginal.x.p_x_given_n.shape =} and {long_one_step_decoder_1D.p_x_given_n.shape =}\"\n",
    "assert long_one_step_decoder_2D.marginal.x.most_likely_positions_1D.shape == long_one_step_decoder_1D.most_likely_positions.shape, f\"Must equal but: {long_one_step_decoder_2D.marginal.x.most_likely_positions_1D.shape =} and {long_one_step_decoder_1D.most_likely_positions.shape =}\"\n",
    "\n",
    "## validate values:\n",
    "# assert np.allclose(long_one_step_decoder_2D.marginal.x.p_x_given_n, long_one_step_decoder_1D.p_x_given_n), f\"1D Decoder should have an x-posterior equal to its own posterior\"\n",
    "# assert np.allclose(curr_epoch_result['marginal_x']['most_likely_positions_1D'], curr_epoch_result['most_likely_positions']), f\"1D Decoder should have an x-posterior with most_likely_positions_1D equal to its own most_likely_positions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cee514",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent\n",
    "\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_time_dependent_placefield_computation'], enabled_filter_names=[long_epoch_name, short_epoch_name, global_epoch_name], fail_on_exception=True, debug_print=True)\n",
    "\n",
    "# long_results.pf1D_dt.reset()\n",
    "# long_results.pf1D_dt._included_thresh_neurons_indx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a896c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE)\n",
    "\n",
    "# TypeError: cannot pickle 'MplMultiTab' object\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea54a0e7",
   "metadata": {},
   "source": [
    "#### 2023-04-13 - Clear Display Outputs from pipeline so it can be saved\n",
    "##### TODO: Ignore `curr_active_pipeline.display_output_history_list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef7370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(curr_active_pipeline.display_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0615279",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display_output_history_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f9eb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clear any hanging display outputs:\n",
    "# do I need to close them before I just remove them?\n",
    "for a_display_output_key in curr_active_pipeline.display_output_history_list:\n",
    "\t# a_display_output.close()\n",
    "\tdel curr_active_pipeline.display_output[a_display_output_key]\n",
    "\n",
    "curr_active_pipeline.display_output_history_list.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a3c3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get all matplotlib figures?\n",
    "from pyphocorehelpers.plotting.figure_management import PhoActiveFigureManager2D, capture_new_figures_decorator\n",
    "fig_man = PhoActiveFigureManager2D(name=f'fig_man') # Initialize a new figure manager\n",
    "fig_man.close_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2798ab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.print_helpers import print_object_memory_usage\n",
    "print_object_memory_usage(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee4e035",
   "metadata": {},
   "outputs": [],
   "source": [
    "%help %whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc727de",
   "metadata": {},
   "outputs": [],
   "source": [
    "%lsmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a116ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%who_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6048000a",
   "metadata": {},
   "source": [
    "# 2023-04-11 - Review of Year's Progress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50c94a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5356d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for interactive\n",
    "curr_active_pipeline.registered_display_function_docs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9c437e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd3bbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter = curr_active_pipeline.plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b7199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dfc5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter._display_normal(active_session_configuration_context=long_epoch_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d48a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.plot._display_short_long_firing_rate_index_comparison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0431c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.plot.display_short_long_firing_rate_index_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb313f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included whitelist is specified: ['jonathan_firing_rate_analysis', 'short_long_pf_overlap_analyses', 'long_short_fr_indicies_analyses'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t encountered error: 'jonathan_firing_rate_analysis'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Batch/NonInteractiveWrapper.py\", line 423, in batch_extended_computations\n",
      "    curr_jonathan_firing_rate_analysis = curr_active_pipeline.global_computation_results.computed_data['jonathan_firing_rate_analysis']\n",
      "  File \"/home/halechr/repos/pyPhoCoreHelpers/src/pyphocorehelpers/DataStructure/dynamic_parameters.py\", line 34, in __getitem__\n",
      "    return self._mapping[key]\n",
      "KeyError: 'jonathan_firing_rate_analysis'\n",
      "\n",
      ".\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n",
      "Time window 13 has no spikes.\n",
      "Time window 898 has no spikes.\n",
      "\t done.\n",
      "short_long_pf_overlap_analyses missing.\n",
      "\t encountered error: 'short_long_pf_overlap_analyses'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Batch/NonInteractiveWrapper.py\", line 447, in batch_extended_computations\n",
      "    short_long_pf_overlap_analyses = curr_active_pipeline.global_computation_results.computed_data.short_long_pf_overlap_analyses\n",
      "  File \"/home/halechr/repos/pyPhoCoreHelpers/src/pyphocorehelpers/DataStructure/dynamic_parameters.py\", line 96, in __getattr__\n",
      "    return self[item]\n",
      "  File \"/home/halechr/repos/pyPhoCoreHelpers/src/pyphocorehelpers/DataStructure/dynamic_parameters.py\", line 34, in __getitem__\n",
      "    return self._mapping[key]\n",
      "KeyError: 'short_long_pf_overlap_analyses'\n",
      "\n",
      ".\n",
      "\t Recomputing short_long_pf_overlap_analyses...\n",
      "\t done.\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t encountered error: 'long_short_fr_indicies_analysis'\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/halechr/repos/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Batch/NonInteractiveWrapper.py\", line 494, in batch_extended_computations\n",
      "    long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
      "  File \"/home/halechr/repos/pyPhoCoreHelpers/src/pyphocorehelpers/DataStructure/dynamic_parameters.py\", line 34, in __getitem__\n",
      "    return self._mapping[key]\n",
      "KeyError: 'long_short_fr_indicies_analysis'\n",
      "\n",
      ".\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "\t done.\n",
      "done with all batch_extended_computations(...).\n"
     ]
    }
   ],
   "source": [
    "# extended_computations_include_whitelist=None # do all\n",
    "extended_computations_include_whitelist=['jonathan_firing_rate_analysis', 'short_long_pf_overlap_analyses', 'long_short_fr_indicies_analyses'] # do only specifiedl\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_whitelist=extended_computations_include_whitelist, include_global_functions=True, fail_on_exception=True, progress_print=True, debug_print=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9eac66a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t done.\n"
     ]
    }
   ],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_short_long_firing_rate_analyses'], fail_on_exception=True, debug_print=False) # fail_on_exception MUST be True or error handling is all messed up \n",
    "print(f'\\t done.')\n",
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "x_frs_index, y_frs_index = long_short_fr_indicies_analysis_results['x_frs_index'], long_short_fr_indicies_analysis_results['y_frs_index'] # use the all_results_dict as the computed data value\n",
    "active_context = long_short_fr_indicies_analysis_results['active_context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c367e7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_jonathan_firing_rate_analysis = curr_active_pipeline.global_computation_results.computed_data['jonathan_firing_rate_analysis']\n",
    "neuron_replay_stats_df, rdf, aclu_to_idx, irdf = curr_jonathan_firing_rate_analysis['neuron_replay_stats_df'], curr_jonathan_firing_rate_analysis['rdf']['rdf'], curr_jonathan_firing_rate_analysis['rdf']['aclu_to_idx'], curr_jonathan_firing_rate_analysis['irdf']['irdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24b27a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_long_pf_overlap_analyses = curr_active_pipeline.global_computation_results.computed_data.short_long_pf_overlap_analyses\n",
    "conv_overlap_dict = short_long_pf_overlap_analyses['conv_overlap_dict']\n",
    "conv_overlap_scalars_df = short_long_pf_overlap_analyses['conv_overlap_scalars_df']\n",
    "prod_overlap_dict = short_long_pf_overlap_analyses['product_overlap_dict']\n",
    "relative_entropy_overlap_dict = short_long_pf_overlap_analyses['relative_entropy_overlap_dict']\n",
    "relative_entropy_overlap_scalars_df = short_long_pf_overlap_analyses['relative_entropy_overlap_scalars_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3640e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "x_frs_index, y_frs_index = long_short_fr_indicies_analysis_results['x_frs_index'], long_short_fr_indicies_analysis_results['y_frs_index'] # use the all_results_dict as the computed data value\n",
    "active_context = long_short_fr_indicies_analysis_results['active_context']\n",
    "# long_short_fr_indicies_analysis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fe59c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "\n",
    "graphics_output_dict = curr_active_pipeline.display('_display_batch_pho_jonathan_replay_firing_rate_comparison', active_identifying_session_ctx)\n",
    "fig, axs, plot_data = graphics_output_dict['fig'], graphics_output_dict['axs'], graphics_output_dict['plot_data']\n",
    "neuron_df, rdf, aclu_to_idx, irdf = plot_data['df'], plot_data['rdf'], plot_data['aclu_to_idx'], plot_data['irdf']\n",
    "# Grab the output axes:\n",
    "curr_axs_dict = axs[0]\n",
    "curr_firing_rate_ax, curr_lap_spikes_ax, curr_placefield_ax = curr_axs_dict['firing_rate'], curr_axs_dict['lap_spikes'], curr_axs_dict['placefield'] # Extract variables from the `curr_axs_dict` dictionary to the local workspace\n",
    "## TODO 2023-04-11 - Set Window Title for '_display_batch_pho_jonathan_replay_firing_rate_comparison'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc63487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot long|short firing rate index:\n",
    "fig_save_parent_path = Path(r'E:\\Dropbox (Personal)\\Active\\Kamran Diba Lab\\Pho-Kamran-Meetings\\Results from 2023-04-11')\n",
    "curr_active_pipeline.display('_display_short_long_firing_rate_index_comparison', curr_active_pipeline.sess.get_context(), fig_save_parent_path=fig_save_parent_path)\n",
    "# plt.close() # closes the current figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf9b670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023-04-11 - Debug why `_display_short_long_firing_rate_index_comparison` is empty\n",
    "# Plot long|short firing rate index:\n",
    "\n",
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "x_frs_index, y_frs_index = long_short_fr_indicies_analysis_results['x_frs_index'], long_short_fr_indicies_analysis_results['y_frs_index'] # use the all_results_dict as the computed data value\n",
    "active_context = long_short_fr_indicies_analysis_results['active_context']\n",
    "long_short_fr_indicies_analysis_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0826d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display('_display_short_long_firing_rate_index_comparison', curr_active_pipeline.sess.get_context(), fig_save_parent_path=fig_save_parent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c230041",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_identifying_session_ctx, active_session_figures_out_path, active_out_figures_list = batch_programmatic_figures(curr_active_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc56f996",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_extended_programmatic_figures(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb79a73",
   "metadata": {},
   "source": [
    "## Explore display function documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4c4d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_display_function_docs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276eeb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# func.short_name, func.tags, func.creation_date, func.input_requires, func.output_provides, func.uses, func.used_by\n",
    "{a_fn_name:getattr(a_fn, 'tags', None) for a_fn_name, a_fn in curr_active_pipeline.registered_display_function_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6899c012",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_display_function_dict['_display_2d_placefield_result_plot_ratemaps_2D'].tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03a92c8",
   "metadata": {},
   "source": [
    "# 2023-03-16 - Explore passing in long/short decoders specifically to `perform_full_session_leave_one_out_decoding_analysis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1f22b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get existing long/short decoders from the cell under \"# 2023-02-24 Decoders\"\n",
    "long_decoder, short_decoder = deepcopy(long_one_step_decoder_1D), deepcopy(short_one_step_decoder_1D)\n",
    "assert np.all(long_decoder.xbin == short_decoder.xbin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5408614",
   "metadata": {},
   "outputs": [],
   "source": [
    "## backup existing replay objects\n",
    "# long_session.replay_backup, short_session.replay_backup, global_session.replay_backup = [deepcopy(a_session.replay) for a_session in [long_session, short_session, global_session]]\n",
    "# null-out the replay objects\n",
    "# long_session.replay, short_session.replay, global_session.replay = [None, None, None]\n",
    "\n",
    "# Compute/estimate replays if missing from session:\n",
    "if not global_session.has_replays:\n",
    "    print(f'Replays missing from sessions. Computing replays...')\n",
    "    long_session.replay, short_session.replay, global_session.replay = [a_session.estimate_replay_epochs(min_epoch_included_duration=0.06, max_epoch_included_duration=None, maximum_speed_thresh=None, min_inclusion_fr_active_thresh=0.01, min_num_unique_aclu_inclusions=3).to_dataframe() for a_session in [long_session, short_session, global_session]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4944f1fd",
   "metadata": {},
   "source": [
    "### Need to prune to only the cells active in both epochs ahead of time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f62debbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neurons = 37, neurons_colors_array.shape =(4, 37)\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BasePositionDecoder, BayesianPlacemapPositionDecoder\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import perform_full_session_leave_one_out_decoding_analysis\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import SurpriseAnalysisResult\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import build_neurons_color_map # for plot_short_v_long_pf1D_comparison\n",
    "\n",
    "# Prune to the shared aclus in both epochs (short/long):\n",
    "long_shared_aclus_only_decoder, short_shared_aclus_only_decoder = [BasePositionDecoder.init_from_stateful_decoder(a_decoder) for a_decoder in (long_decoder, short_decoder)]\n",
    "shared_aclus, (long_shared_aclus_only_decoder, short_shared_aclus_only_decoder), long_short_pf_neurons_diff = BasePositionDecoder.prune_to_shared_aclus_only(long_shared_aclus_only_decoder, short_shared_aclus_only_decoder)\n",
    "n_neurons = len(shared_aclus)\n",
    "# for plotting purposes, build colors only for the common (present in both, the intersection) neurons:\n",
    "neurons_colors_array = build_neurons_color_map(n_neurons, sortby=None, cmap=None)\n",
    "print(f'{n_neurons = }, {neurons_colors_array.shape =}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b360bc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-full_session_LOO_decoding_analysis.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "long_results_obj = perform_full_session_leave_one_out_decoding_analysis(global_session, original_1D_decoder=long_shared_aclus_only_decoder, decoding_time_bin_size = 0.025, cache_suffix = '_long', perform_cache_load=True) # , perform_cache_load=False\n",
    "short_results_obj = perform_full_session_leave_one_out_decoding_analysis(global_session, original_1D_decoder=short_shared_aclus_only_decoder, decoding_time_bin_size = 0.025, cache_suffix = '_short', perform_cache_load=True) # , perform_cache_load=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69eed8a",
   "metadata": {},
   "source": [
    "## 2023-04-13 - Shuffled Surprise\n",
    "\"\"\" \n",
    "Relevant Functions:\n",
    "`perform_full_session_leave_one_out_decoding_analysis`:\n",
    "\t`perform_leave_one_aclu_out_decoding_analysis`:\tfrom pyphoplacecellanalysis.Analysis.Decoder.decoder_result import perform_leave_one_aclu_out_decoding_analysis\n",
    "\t`_analyze_leave_one_out_decoding_results`: from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.DefaultComputationFunctions import _analyze_leave_one_out_decoding_results\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff984d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## for each cell:\n",
    "# for i, left_out_aclu in enumerate(original_1D_decoder.neuron_IDs):\n",
    "# \t# aclu = original_1D_decoder.neuron_IDs[i]\n",
    "# \tleft_out_neuron_IDX = original_1D_decoder.neuron_IDXs[i] # should just be i, but just to be safe\n",
    "# \t## TODO: only look at bins where the cell fires (is_cell_firing_time_bin[i])\n",
    "# \tcurr_cell_pf_curve = original_1D_decoder.pf.ratemap.tuning_curves[left_out_neuron_IDX]\n",
    "# \t# curr_cell_spike_curve = original_1D_decoder.pf.ratemap.spikes_maps[unit_IDX] ## not occupancy weighted... is this the right one to use for computing the expected spike rate? NO... doesn't seem like it\n",
    "\n",
    "# \tshuffled_cell_pf_curve = original_1D_decoder.pf.ratemap.tuning_curves[shuffle_IDXs[i]]\n",
    "\n",
    "# \tleft_out_decoder_result = one_left_out_filter_epochs_decoder_result_dict[left_out_aclu]\n",
    "\n",
    "# active_epoch = results_obj.active_filter_epochs[epoch_idx]\n",
    "# # Get a conversion between the epoch indicies and the flat indicies\n",
    "# flat_bin_indicies = results_obj.split_by_epoch_reverse_flattened_time_bin_indicies[epoch_idx]\n",
    "\n",
    "\n",
    "# for decoded_epoch_idx in np.arange(n_epochs):\n",
    "# \tnum_curr_epoch_time_bins = [len(self.result.one_left_out_posterior_to_pf_surprises[aclu][decoded_epoch_idx]) for aclu in self.original_1D_decoder.neuron_IDs] # get the number of time bins in this epoch to build the reverse indexing array\n",
    "\n",
    "# for decoded_epoch_idx in np.arange(left_out_decoder_result.num_filter_epochs):\n",
    "# \tlong_results_obj.active_filter_epochs\n",
    "\n",
    "\n",
    "for decoded_epoch_idx in np.arange(left_out_decoder_result.num_filter_epochs):\n",
    "\tlong_results_obj.active_filter_epochs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05bd78c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_obj = deepcopy(long_results_obj)\n",
    "results_obj.all_included_filter_epochs_decoder_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c380066d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4834"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract important things from the decoded data, like the time bins which are the same for all:\n",
    "n_epochs = results_obj.all_included_filter_epochs_decoder_result.num_filter_epochs\n",
    "n_timebins = np.sum(results_obj.all_included_filter_epochs_decoder_result.nbins)\n",
    "shared_timebin_containers = results_obj.all_included_filter_epochs_decoder_result.time_bin_containers\n",
    "# shared_timebin_\n",
    "n_timebins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "18c1c5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attrs import define\n",
    "## 0. Precompute the active neurons in each timebin, and the epoch-timebin-flattened decoded posteriors makes it easier to compute for a given time bin:\n",
    "@define(slots=False, repr=False)\n",
    "class TimebinnedNeuronActivity:\n",
    "\t\"\"\" keeps track of which neurons are active and inactive in each decoded timebin \"\"\"\n",
    "\tn_timebins: int\n",
    "\tactive_IDXs: np.ndarray\n",
    "\tactive_aclus: np.ndarray\n",
    "\tinactive_IDXs: np.ndarray\n",
    "\tinactive_aclus: np.ndarray\n",
    "\n",
    "\t@classmethod\n",
    "\tdef init_from_results_obj(cls, results_obj: SurpriseAnalysisResult):\n",
    "\t\tn_timebins = np.sum(results_obj.all_included_filter_epochs_decoder_result.nbins)\n",
    "\t\t# a list of lists where each list contains the aclus that are active during that timebin:\n",
    "\t\ttimebins_active_neuron_IDXs = [np.array(results_obj.original_1D_decoder.neuron_IDXs)[a_timebin_is_cell_firing] for a_timebin_is_cell_firing in np.logical_not(results_obj.is_non_firing_time_bin).T]\n",
    "\t\ttimebins_active_aclus = [np.array(results_obj.original_1D_decoder.neuron_IDs)[an_IDX] for an_IDX in timebins_active_neuron_IDXs]\n",
    "\n",
    "\t\ttimebins_inactive_neuron_IDXs = [np.array(results_obj.original_1D_decoder.neuron_IDXs)[a_timebin_is_cell_firing] for a_timebin_is_cell_firing in results_obj.is_non_firing_time_bin.T]\n",
    "\t\ttimebins_inactive_aclus = [np.array(results_obj.original_1D_decoder.neuron_IDs)[an_IDX] for an_IDX in timebins_inactive_neuron_IDXs]\n",
    "\t\t# timebins_p_x_given_n = np.hstack(results_obj.all_included_filter_epochs_decoder_result.p_x_given_n_list) # # .shape: (239, 5) - (n_x_bins, n_epoch_time_bins)  --TO-->  .shape: (63, 4146) - (n_x_bins, n_flattened_all_epoch_time_bins)\n",
    "\t\treturn cls(n_timebins=n_timebins, active_IDXs=timebins_active_neuron_IDXs, active_aclus=timebins_active_aclus, inactive_IDXs=timebins_inactive_neuron_IDXs, inactive_aclus=timebins_inactive_aclus)\n",
    "\n",
    "long_results_obj.timebinned_neuron_info = TimebinnedNeuronActivity.init_from_results_obj(long_results_obj)\n",
    "short_results_obj.timebinned_neuron_info = TimebinnedNeuronActivity.init_from_results_obj(short_results_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a90a4d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert long_results_obj.timebinned_neuron_info.n_timebins == short_results_obj.timebinned_neuron_info.n_timebins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e500fab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_bin_indices</th>\n",
       "      <th>posterior_to_pf_mean_surprise</th>\n",
       "      <th>posterior_to_scrambled_pf_mean_surprise</th>\n",
       "      <th>surprise_diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch_IDX</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.750000</td>\n",
       "      <td>1.089702</td>\n",
       "      <td>1.064788</td>\n",
       "      <td>-0.024914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.714286</td>\n",
       "      <td>0.869224</td>\n",
       "      <td>0.969990</td>\n",
       "      <td>0.100766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.833333</td>\n",
       "      <td>0.676741</td>\n",
       "      <td>0.961945</td>\n",
       "      <td>0.285204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.500000</td>\n",
       "      <td>1.079248</td>\n",
       "      <td>0.766917</td>\n",
       "      <td>-0.312331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.500000</td>\n",
       "      <td>1.156842</td>\n",
       "      <td>1.185924</td>\n",
       "      <td>0.029082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>4799.000000</td>\n",
       "      <td>0.743693</td>\n",
       "      <td>1.047981</td>\n",
       "      <td>0.304288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>4807.000000</td>\n",
       "      <td>0.982098</td>\n",
       "      <td>1.080911</td>\n",
       "      <td>0.098813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>4816.888889</td>\n",
       "      <td>0.807060</td>\n",
       "      <td>0.950911</td>\n",
       "      <td>0.143851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>4824.500000</td>\n",
       "      <td>1.066510</td>\n",
       "      <td>0.860651</td>\n",
       "      <td>-0.205859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>4831.000000</td>\n",
       "      <td>0.914619</td>\n",
       "      <td>0.890204</td>\n",
       "      <td>-0.024415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           time_bin_indices  posterior_to_pf_mean_surprise  \\\n",
       "epoch_IDX                                                    \n",
       "0                  3.750000                       1.089702   \n",
       "1                 13.714286                       0.869224   \n",
       "2                 21.833333                       0.676741   \n",
       "3                 29.500000                       1.079248   \n",
       "4                 36.500000                       1.156842   \n",
       "...                     ...                            ...   \n",
       "595             4799.000000                       0.743693   \n",
       "596             4807.000000                       0.982098   \n",
       "597             4816.888889                       0.807060   \n",
       "598             4824.500000                       1.066510   \n",
       "599             4831.000000                       0.914619   \n",
       "\n",
       "           posterior_to_scrambled_pf_mean_surprise  surprise_diff  \n",
       "epoch_IDX                                                          \n",
       "0                                         1.064788      -0.024914  \n",
       "1                                         0.969990       0.100766  \n",
       "2                                         0.961945       0.285204  \n",
       "3                                         0.766917      -0.312331  \n",
       "4                                         1.185924       0.029082  \n",
       "...                                            ...            ...  \n",
       "595                                       1.047981       0.304288  \n",
       "596                                       1.080911       0.098813  \n",
       "597                                       0.950911       0.143851  \n",
       "598                                       0.860651      -0.205859  \n",
       "599                                       0.890204      -0.024415  \n",
       "\n",
       "[600 rows x 4 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.DefaultComputationFunctions import LeaveOneOutDecodingResult\n",
    "from scipy.spatial import distance # for Jensen-Shannon distance in `_subfn_compute_leave_one_out_analysis`\n",
    "import random # for random.choice(mylist)\n",
    "from PendingNotebookCode import _scramble_curve\n",
    "\n",
    "# @define(slots=False, repr=False)\n",
    "# class PlacefieldPosteriorComputationHelper:\n",
    "\n",
    "# \tdef compute(self, curr_cell_pf_curve, curr_timebin_p_x_given_n):\n",
    "# \t\tresult.one_left_out_posterior_to_pf_surprises[timebin_IDX].append(distance.jensenshannon(curr_cell_pf_curve, curr_timebin_p_x_given_n))\n",
    "# \t\tresult.one_left_out_posterior_to_pf_correlations[timebin_IDX].append(distance.correlation(curr_cell_pf_curve, curr_timebin_p_x_given_n))\n",
    "\n",
    "\n",
    "# active_surprise_metric_fn = lambda pf, p_x_given_n: distance.jensenshannon(pf, p_x_given_n)\n",
    "active_surprise_metric_fn = lambda pf, p_x_given_n: distance.correlation(pf, p_x_given_n)\n",
    "\n",
    "#p_x_given_n_list\n",
    "#DecodedFilterEpochsResult\n",
    "timebinned_neuron_info = long_results_obj.timebinned_neuron_info\n",
    "result = LeaveOneOutDecodingResult(shuffle_IDXs=None)\n",
    "\n",
    "for timebin_IDX in np.arange(timebinned_neuron_info.n_timebins):\n",
    "\t# iterate through timebins\n",
    "\tif timebin_IDX not in result.one_left_out_posterior_to_pf_surprises:\n",
    "\t\tresult.one_left_out_posterior_to_pf_surprises[timebin_IDX] = []\n",
    "\tif timebin_IDX not in result.one_left_out_posterior_to_scrambled_pf_surprises:\n",
    "\t\tresult.one_left_out_posterior_to_scrambled_pf_surprises[timebin_IDX] = []\n",
    "\n",
    "\t## Pre loop: add empty array for accumulation\n",
    "\n",
    "\tfor neuron_IDX, aclu in zip(timebinned_neuron_info.active_IDXs[timebin_IDX], timebinned_neuron_info.active_aclus[timebin_IDX]):\n",
    "\t\t# iterate through only the active cells\n",
    "\t\t# 1. Get set of cells active in a given time bin, for each compute the surprise of its placefield with the leave-one-out decoded posterior.\n",
    "\t\tleft_out_decoder_result = long_results_obj.one_left_out_filter_epochs_decoder_result_dict[aclu]\n",
    "\t\tcurr_cell_pf_curve = long_results_obj.original_1D_decoder.pf.ratemap.tuning_curves[neuron_IDX]\n",
    "\t\t# curr_cell_spike_curve = original_1D_decoder.pf.ratemap.spikes_maps[unit_IDX] ## not occupancy weighted... is this the right one to use for computing the expected spike rate? NO... doesn't seem like it\n",
    "\n",
    "\n",
    "\t\tcurr_cell_pf_curve = long_results_obj.original_1D_decoder.pf.ratemap.normalized_tuning_curves[neuron_IDX]\n",
    "\n",
    "\t\t_, _, curr_timebins_p_x_given_n = left_out_decoder_result.flatten()\n",
    "\t\tcurr_timebin_p_x_given_n = curr_timebins_p_x_given_n[:, timebin_IDX] # .shape: (239, 5) - (n_x_bins, n_epoch_time_bins)\n",
    "\t\tassert curr_timebin_p_x_given_n.shape[0] == curr_cell_pf_curve.shape[0], f\"{curr_timebin_p_x_given_n.shape = } == {curr_cell_pf_curve.shape = }\"\n",
    "\t\t\n",
    "\t\t# if aclu not in result.one_left_out_posterior_to_pf_surprises:\n",
    "\t\t# \tresult.one_left_out_posterior_to_pf_surprises[aclu] = []\n",
    "\t\t# result.one_left_out_posterior_to_pf_surprises[aclu].append(distance.jensenshannon(curr_cell_pf_curve, curr_timebin_p_x_given_n))\n",
    "\n",
    "\t\tresult.one_left_out_posterior_to_pf_surprises[timebin_IDX].append(active_surprise_metric_fn(curr_cell_pf_curve, curr_timebin_p_x_given_n))\n",
    "\t\t# result.one_left_out_posterior_to_pf_correlations[timebin_IDX].append(distance.correlation(curr_cell_pf_curve, curr_timebin_p_x_given_n))\n",
    "\n",
    "\t\t\n",
    "\n",
    "\t\t# 2. From the remainder of cells (those not active), randomly choose one to grab the placefield of and compute the surprise with that and the same posterior.\n",
    "\t\t# shuffled_cell_pf_curve = long_results_obj.original_1D_decoder.pf.ratemap.tuning_curves[shuffle_IDXs[i]]\n",
    "\n",
    "\t\t# # a) Use a random non-firing cell's placefield:\n",
    "\t\t# random_not_firing_neuron_IDX = random.choice(timebinned_neuron_info.inactive_IDXs[timebin_IDX])\n",
    "\t\t# # random_not_firing_aclu = random.choice(timebinned_neuron_info.inactive_aclus[i])\n",
    "\t\t# curr_random_not_firing_cell_pf_curve = long_results_obj.original_1D_decoder.pf.ratemap.tuning_curves[random_not_firing_neuron_IDX]\n",
    "\n",
    "\t\t# b) Use a scrambled version of the real curve:\n",
    "\t\tcurr_random_not_firing_cell_pf_curve = _scramble_curve(curr_cell_pf_curve)\n",
    "\t\t# if aclu not in result.one_left_out_posterior_to_scrambled_pf_surprises:\n",
    "\t\t# \tresult.one_left_out_posterior_to_scrambled_pf_surprises[aclu] = []\n",
    "\t\t# # The shuffled cell's placefield and the posterior from leaving a cell out:\n",
    "\t\t# result.one_left_out_posterior_to_scrambled_pf_surprises[aclu].append(distance.jensenshannon(curr_random_not_firing_cell_pf_curve, curr_timebin_p_x_given_n))\n",
    "\t\t\n",
    "\t\t# The shuffled cell's placefield and the posterior from leaving a cell out:\n",
    "\t\tresult.one_left_out_posterior_to_scrambled_pf_surprises[timebin_IDX].append(active_surprise_metric_fn(curr_random_not_firing_cell_pf_curve, curr_timebin_p_x_given_n))\n",
    "\t\t# result.one_left_out_posterior_to_scrambled_pf_correlations[timebin_IDX].append(distance.correlation(curr_random_not_firing_cell_pf_curve, curr_timebin_p_x_given_n))\n",
    "\n",
    "\t# END Neuron Loop\n",
    "\t## Post neuron loops: convert lists to np.arrays\n",
    "\tresult.one_left_out_posterior_to_pf_surprises[timebin_IDX] = np.array(result.one_left_out_posterior_to_pf_surprises[timebin_IDX])\n",
    "\tresult.one_left_out_posterior_to_scrambled_pf_surprises[timebin_IDX] = np.array(result.one_left_out_posterior_to_scrambled_pf_surprises[timebin_IDX])\n",
    "\n",
    "# End Timebin Loop\n",
    "## Post timebin loops compute mean variables:\n",
    "result.one_left_out_posterior_to_pf_surprises_mean = {k:np.mean(v) for k, v in result.one_left_out_posterior_to_pf_surprises.items() if np.size(v) > 0}\n",
    "result.one_left_out_posterior_to_scrambled_pf_surprises_mean = {k:np.mean(v) for k, v in result.one_left_out_posterior_to_scrambled_pf_surprises.items() if np.size(v) > 0}\n",
    "assert len(result.one_left_out_posterior_to_scrambled_pf_surprises_mean) == len(result.one_left_out_posterior_to_pf_surprises_mean)\n",
    "assert list(result.one_left_out_posterior_to_scrambled_pf_surprises_mean.keys()) == list(result.one_left_out_posterior_to_pf_surprises_mean.keys())\n",
    "\n",
    "valid_time_bin_indicies = np.array(list(result.one_left_out_posterior_to_pf_surprises_mean.keys()))\n",
    "one_left_out_posterior_to_pf_surprises_mean = np.array(list(result.one_left_out_posterior_to_pf_surprises_mean.values()))\n",
    "one_left_out_posterior_to_scrambled_pf_surprises_mean = np.array(list(result.one_left_out_posterior_to_scrambled_pf_surprises_mean.values()))\n",
    "\n",
    "long_results_obj.all_epochs_reverse_flat_epoch_indicies_array\n",
    "\n",
    "# one_left_out_posterior_to_scrambled_pf_surprises_mean\n",
    "\n",
    "result_df = pd.DataFrame({'time_bin_indices': valid_time_bin_indicies, 'epoch_IDX': long_results_obj.all_epochs_reverse_flat_epoch_indicies_array[valid_time_bin_indicies], 'posterior_to_pf_mean_surprise': one_left_out_posterior_to_pf_surprises_mean, 'posterior_to_scrambled_pf_mean_surprise': one_left_out_posterior_to_scrambled_pf_surprises_mean})\n",
    "result_df['surprise_diff'] = result_df['posterior_to_scrambled_pf_mean_surprise'] - result_df['posterior_to_pf_mean_surprise']\n",
    "result_df\n",
    "\n",
    "# 24.9 seconds to compute\n",
    "\n",
    "## Compute Aggregate Dataframe for Epoch means:\n",
    "# Group by 'epoch_IDX' and compute means of all columns\n",
    "result_df_grouped = result_df.groupby('epoch_IDX').mean()\n",
    "result_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c107570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Get set of cells active in a given time bin, for each compute the surprise of its placefield with the leave-one-out decoded posterior.\n",
    "\n",
    "# 2. From the remainder of cells (those not active), randomly choose one to grab the placefield of and compute the surprise with that and the same posterior.\n",
    "\n",
    "\n",
    "# Expectation: The cells that are included in the time bin are expected to have a lower surprise (be less correlated with) the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da23db45",
   "metadata": {
    "tags": [
     "notes"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Relevant Functions:\n",
    "`perform_full_session_leave_one_out_decoding_analysis`:\n",
    "\t`perform_leave_one_aclu_out_decoding_analysis`:\tfrom pyphoplacecellanalysis.Analysis.Decoder.decoder_result import perform_leave_one_aclu_out_decoding_analysis\n",
    "\t`_analyze_leave_one_out_decoding_results`: from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.DefaultComputationFunctions import _analyze_leave_one_out_decoding_results\n",
    "\"\"\"\n",
    "\n",
    "# ## for each cell:\n",
    "# for i, left_out_aclu in enumerate(original_1D_decoder.neuron_IDs):\n",
    "# \t# aclu = original_1D_decoder.neuron_IDs[i]\n",
    "# \tleft_out_neuron_IDX = original_1D_decoder.neuron_IDXs[i] # should just be i, but just to be safe\n",
    "# \t## TODO: only look at bins where the cell fires (is_cell_firing_time_bin[i])\n",
    "# \tcurr_cell_pf_curve = original_1D_decoder.pf.ratemap.tuning_curves[left_out_neuron_IDX]\n",
    "# \t# curr_cell_spike_curve = original_1D_decoder.pf.ratemap.spikes_maps[unit_IDX] ## not occupancy weighted... is this the right one to use for computing the expected spike rate? NO... doesn't seem like it\n",
    "\n",
    "# \tshuffled_cell_pf_curve = original_1D_decoder.pf.ratemap.tuning_curves[shuffle_IDXs[i]]\n",
    "\n",
    "# \tleft_out_decoder_result = one_left_out_filter_epochs_decoder_result_dict[left_out_aclu]\n",
    "\n",
    "# active_epoch = results_obj.active_filter_epochs[epoch_idx]\n",
    "# # Get a conversion between the epoch indicies and the flat indicies\n",
    "# flat_bin_indicies = results_obj.split_by_epoch_reverse_flattened_time_bin_indicies[epoch_idx]\n",
    "\n",
    "\n",
    "# for decoded_epoch_idx in np.arange(n_epochs):\n",
    "# \tnum_curr_epoch_time_bins = [len(self.result.one_left_out_posterior_to_pf_surprises[aclu][decoded_epoch_idx]) for aclu in self.original_1D_decoder.neuron_IDs] # get the number of time bins in this epoch to build the reverse indexing array\n",
    "\n",
    "# for decoded_epoch_idx in np.arange(left_out_decoder_result.num_filter_epochs):\n",
    "# \tlong_results_obj.active_filter_epochs\n",
    "\n",
    "\n",
    "for decoded_epoch_idx in np.arange(left_out_decoder_result.num_filter_epochs):\n",
    "\tlong_results_obj.active_filter_epochs\n",
    "\n",
    "\n",
    "# 1. Get set of cells active in a given time bin, for each compute the surprise of its placefield with the leave-one-out decoded posterior.\n",
    "\n",
    "# 2. From the remainder of cells (those not active), randomly choose one to grab the placefield of and compute the surprise with that and the same posterior.\n",
    "\n",
    "\n",
    "# Expectation: The cells that are included in the time bin are expected to have a lower surprise (be less correlated with) the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e8ff50bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "# 'time_bin_indices': valid_time_bin_indicies, 'posterior_to_pf_mean_surprise': one_left_out_posterior_to_pf_surprises_mean, 'posterior_to_scrambled_pf_mean_surprise': one_left_out_posterior_to_scrambled_pf_surprises_mean}\n",
    "\n",
    "# make a separate symbol_brush color for each cell:\n",
    "# cell_color_symbol_brush = [pg.intColor(i,hues=9, values=3, alpha=180) for i, aclu in enumerate(long_results_obj.original_1D_decoder.neuron_IDs)] # maxValue=128\n",
    "# All properties in common:\n",
    "win = pg.plot()\n",
    "win.setWindowTitle('Long Sanity Check - Leave-one-out Custom Surprise Plot')\n",
    "# legend_size = (80,60) # fixed size legend\n",
    "legend_size = None # auto-sizing legend to contents\n",
    "legend = pg.LegendItem(legend_size, offset=(-1,0)) # do this instead of # .addLegend\n",
    "legend.setParentItem(win.graphicsItem())\n",
    "\n",
    "plots = {}\n",
    "label_prefix_list = ['normal', 'scrambled']\n",
    "long_short_symbol_list = ['t', 'o'] # note: 's' is a square. 'o', 't1': triangle pointing upwards0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Use mean time_bin and surprise for each epoch\n",
    "# plots['normal'] = win.plot(x=valid_time_bin_indicies, y=one_left_out_posterior_to_pf_surprises_mean, pen=None, symbol='t', symbolBrush=pg.intColor(1,6,maxValue=128), name=f'normal', alpha=0.5) #  symbolBrush=pg.intColor(i,6,maxValue=128) , symbol=curr_symbol, symbolBrush=cell_color_symbol_brush[unit_IDX]\n",
    "# plots['scrambled'] = win.plot(x=valid_time_bin_indicies, y=one_left_out_posterior_to_scrambled_pf_surprises_mean, pen=None, symbol='t', symbolBrush=pg.intColor(2,6,maxValue=128), name=f'scrambled', alpha=0.5) #  symbolBrush=pg.intColor(i,6,maxValue=128) , symbol=curr_symbol, symbolBrush=cell_color_symbol_brush[unit_IDX]\n",
    "\n",
    "curr_surprise_difference = one_left_out_posterior_to_scrambled_pf_surprises_mean - one_left_out_posterior_to_pf_surprises_mean\n",
    "\n",
    "\n",
    "# x=valid_time_bin_indicies\n",
    "# y=curr_surprise_difference\n",
    "x=result_df_grouped.time_bin_indices.to_numpy()\n",
    "y=result_df_grouped['surprise_diff'].to_numpy()\n",
    "\n",
    "plots['difference'] = win.plot(x=x, y=y, pen=None, symbol='t', symbolBrush=pg.intColor(2,6,maxValue=128), name=f'difference', alpha=0.5) #  symbolBrush=pg.intColor(i,6,maxValue=128) , symbol=curr_symbol, symbolBrush=cell_color_symbol_brush[unit_IDX]\n",
    "\n",
    "\n",
    "\n",
    "for k, v in plots.items():\n",
    "\tlegend.addItem(v, f'{k}')\n",
    "\n",
    "win.graphicsItem().setLabel(axis='left', text='Normal v. Random - Surprise (Custom)')\n",
    "win.graphicsItem().setLabel(axis='bottom', text='time')\n",
    "# return win, plots_tuple, legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0111cb1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(dict_keys([1, 3, 5, 6, 9, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 24, 25, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 42, 43, 44, 46, 48, 49, 50, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75, 78, 79, 80, 81, 82, 84, 85, 86, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 154, 155, 156, 157, 158, 159, 160, 161, 164, 165, 166, 167, 169, 171, 173, 174, 175, 176, 177, 178, 179, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 215, 216, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 249, 250, 252, 253, 256, 258, 259, 261, 262, 263, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 285, 286, 287, 288, 289, 290, 291, 293, 296, 297, 298, 299, 300, 301, 302, 303, 304, 306, 307, 309, 310, 311, 312, 315, 316, 317, 318, 319, 322, 323, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 345, 346, 347, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 376, 377, 379, 380, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 400, 401, 403, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 430, 431, 432, 434, 435, 436, 437, 438, 439, 440, 441, 442, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 472, 473, 475, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 491, 496, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 520, 521, 522, 524, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 590, 591, 592, 593, 594, 595, 596, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 627, 629, 630, 631, 632, 633, 634, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 648, 649, 650, 651, 653, 654, 655, 657, 658, 660, 661, 662, 664, 665, 666, 667, 672, 674, 675, 676, 679, 680, 681, 683, 685, 686, 687, 688, 689, 690, 691, 696, 697, 698, 699, 700, 703, 704, 705, 706, 709, 710, 711, 712, 719, 720, 721, 722, 723, 724, 725, 726, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 756, 757, 758, 759, 761, 762, 763, 764, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 780, 782, 783, 787, 788, 790, 791, 794, 798, 799, 800, 801, 802, 803, 804, 805, 809, 810, 811, 812, 813, 814, 816, 817, 818, 819, 820, 821, 822, 823, 825, 826, 827, 829, 830, 831, 832, 833, 834, 835, 836, 837, 843, 844, 845, 847, 848, 849, 850, 851, 852, 853, 856, 858, 859, 860, 861, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 880, 885, 886, 887, 888, 889, 890, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 929, 931, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 976, 978, 979, 980, 981, 982, 983, 985, 986, 988, 989, 991, 995, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1116, 1119, 1120, 1121, 1123, 1124, 1125, 1129, 1130, 1131, 1134, 1135, 1136, 1137, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1149, 1151, 1152, 1153, 1154, 1155, 1156, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1352, 1353, 1354, 1355, 1357, 1358, 1359, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1388, 1389, 1390, 1391, 1392, 1394, 1395, 1396, 1397, 1398, 1400, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1415, 1416, 1417, 1418, 1419, 1422, 1424, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1474, 1478, 1479, 1480, 1481, 1486, 1487, 1489, 1492, 1493, 1496, 1497, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1520, 1523, 1524, 1527, 1528, 1529, 1530, 1531, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1578, 1579, 1580, 1581, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1623, 1624, 1625, 1626, 1627, 1628, 1630, 1631, 1634, 1635, 1636, 1638, 1639, 1640, 1641, 1644, 1645, 1647, 1649, 1650, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1664, 1665, 1666, 1667, 1668, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1693, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1714, 1718, 1719, 1720, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1752, 1753, 1754, 1755, 1757, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1775, 1776, 1777, 1778, 1779, 1781, 1782, 1783, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1830, 1831, 1832, 1834, 1835, 1838, 1839, 1840, 1847, 1848, 1849, 1851, 1853, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1879, 1880, 1881, 1882, 1883, 1884, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1903, 1904, 1905, 1906, 1907, 1908, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1921, 1922, 1924, 1925, 1926, 1927, 1928, 1929, 1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1956, 1957, 1958, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1974, 1975, 1976, 1977, 1978, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1988, 1989, 1990, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2032, 2033, 2034, 2035, 2036, 2037, 2038, 2039, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2048, 2049, 2050, 2051, 2052, 2053, 2054, 2056, 2057, 2058, 2059, 2060, 2061, 2062, 2063, 2064, 2065, 2066, 2067, 2068, 2070, 2071, 2072, 2073, 2074, 2075, 2076, 2077, 2082, 2083, 2084, 2085, 2086, 2087, 2089, 2090, 2092, 2093, 2094, 2095, 2098, 2099, 2100, 2101, 2102, 2103, 2104, 2107, 2108, 2109, 2110, 2111, 2112, 2113, 2114, 2115, 2116, 2117, 2118, 2119, 2120, 2121, 2122, 2123, 2124, 2125, 2126, 2127, 2128, 2129, 2130, 2131, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2140, 2141, 2142, 2143, 2145, 2146, 2147, 2148, 2149, 2150, 2151, 2152, 2153, 2155, 2160, 2161, 2163, 2164, 2165, 2168, 2170, 2174, 2175, 2176, 2177, 2178, 2179, 2180, 2181, 2182, 2183, 2184, 2185, 2186, 2187, 2188, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2198, 2199, 2200, 2201, 2202, 2203, 2204, 2205, 2206, 2207, 2209, 2210, 2211, 2212, 2213, 2214, 2215, 2216, 2217, 2220, 2226, 2228, 2234, 2235, 2236, 2238, 2239, 2240, 2241, 2242, 2243, 2244, 2245, 2246, 2247, 2248, 2249, 2250, 2251, 2252, 2253, 2254, 2255, 2256, 2257, 2258, 2259, 2260, 2261, 2262, 2263, 2264, 2265, 2266, 2267, 2268, 2270, 2271, 2272, 2273, 2274, 2275, 2276, 2277, 2278, 2279, 2280, 2281, 2282, 2283, 2284, 2287, 2288, 2289, 2292, 2293, 2294, 2295, 2296, 2297, 2298, 2299, 2300, 2301, 2302, 2303, 2304, 2305, 2306, 2307, 2308, 2309, 2311, 2312, 2313, 2314, 2315, 2316, 2317, 2318, 2319, 2320, 2321, 2322, 2323, 2324, 2325, 2326, 2327, 2328, 2329, 2330, 2331, 2332, 2333, 2334, 2335, 2336, 2337, 2338, 2339, 2341, 2342, 2343, 2344, 2345, 2346, 2347, 2348, 2350, 2351, 2352, 2354, 2355, 2356, 2357, 2358, 2359, 2360, 2363, 2364, 2365, 2367, 2368, 2369, 2370, 2374, 2375, 2376, 2377, 2378, 2380, 2382, 2383, 2384, 2385, 2386, 2387, 2388, 2389, 2390, 2391, 2392, 2393, 2394, 2395, 2397, 2398, 2399, 2400, 2401, 2402, 2403, 2404, 2405, 2406, 2407, 2408, 2409, 2410, 2411, 2412, 2413, 2414, 2416, 2417, 2418, 2419, 2420, 2421, 2422, 2423, 2424, 2425, 2426, 2427, 2428, 2429, 2430, 2431, 2433, 2435, 2436, 2437, 2438, 2439, 2440, 2442, 2443, 2444, 2445, 2446, 2447, 2448, 2449, 2450, 2451, 2455, 2457, 2458, 2459, 2460, 2462, 2463, 2464, 2465, 2466, 2467, 2468, 2470, 2471, 2472, 2473, 2475, 2476, 2478, 2479, 2480, 2482, 2483, 2484, 2486, 2488, 2490, 2491, 2492, 2493, 2494, 2495, 2497, 2498, 2499, 2500, 2501, 2502, 2503, 2505, 2506, 2508, 2509, 2510, 2511, 2513, 2514, 2515, 2516, 2519, 2520, 2521, 2522, 2523, 2524, 2526, 2527, 2528, 2529, 2532, 2533, 2534, 2537, 2538, 2539, 2540, 2541, 2542, 2543, 2544, 2545, 2546, 2547, 2550, 2551, 2552, 2553, 2555, 2556, 2558, 2560, 2561, 2562, 2563, 2566, 2567, 2568, 2570, 2571, 2572, 2575, 2576, 2579, 2580, 2581, 2583, 2584, 2586, 2587, 2588, 2590, 2591, 2593, 2596, 2597, 2598, 2599, 2602, 2603, 2604, 2605, 2606, 2607, 2608, 2609, 2610, 2612, 2613, 2614, 2615, 2616, 2617, 2618, 2619, 2621, 2622, 2623, 2626, 2627, 2628, 2629, 2630, 2632, 2633, 2634, 2635, 2636, 2637, 2638, 2639, 2640, 2642, 2643, 2644, 2645, 2646, 2647, 2648, 2649, 2650, 2651, 2653, 2656, 2657, 2658, 2661, 2662, 2663, 2665, 2666, 2667, 2671, 2672, 2673, 2674, 2675, 2676, 2677, 2679, 2680, 2684, 2685, 2692, 2693, 2694, 2695, 2696, 2697, 2698, 2699, 2700, 2705, 2707, 2708, 2709, 2710, 2714, 2716, 2718, 2719, 2720, 2721, 2722, 2724, 2725, 2726, 2727, 2728, 2729, 2730, 2731, 2732, 2733, 2734, 2735, 2737, 2738, 2739, 2740, 2741, 2742, 2743, 2744, 2746, 2747, 2748, 2750, 2751, 2752, 2753, 2754, 2755, 2756, 2757, 2758, 2759, 2760, 2761, 2762, 2763, 2764, 2765, 2766, 2767, 2773, 2774, 2775, 2777, 2778, 2780, 2781, 2782, 2783, 2784, 2785, 2786, 2787, 2788, 2791, 2792, 2793, 2794, 2795, 2798, 2799, 2800, 2801, 2802, 2804, 2806, 2807, 2808, 2809, 2810, 2811, 2812, 2813, 2814, 2816, 2817, 2818, 2819, 2820, 2821, 2822, 2823, 2824, 2825, 2826, 2827, 2828, 2829, 2830, 2831, 2832, 2834, 2835, 2836, 2837, 2838, 2839, 2840, 2841, 2842, 2844, 2845, 2846, 2847, 2848, 2849, 2852, 2854, 2855, 2856, 2857, 2858, 2860, 2861, 2862, 2864, 2865, 2866, 2867, 2868, 2869, 2870, 2871, 2873, 2877, 2878, 2879, 2880, 2881, 2882, 2883, 2884, 2885, 2886, 2890, 2891, 2892, 2893, 2894, 2895, 2896, 2897, 2898, 2904, 2905, 2906, 2907, 2908, 2909, 2910, 2911, 2912, 2913, 2914, 2915, 2917, 2918, 2919, 2920, 2921, 2922, 2923, 2925, 2926, 2928, 2929, 2930, 2931, 2932, 2934, 2935, 2936, 2937, 2938, 2939, 2940, 2941, 2942, 2943, 2945, 2946, 2947, 2948, 2949, 2950, 2951, 2952, 2953, 2954, 2955, 2956, 2957, 2958, 2961, 2962, 2963, 2965, 2966, 2975, 2976, 2981, 2982, 2987, 2988, 2991, 2992, 2993, 2994, 2995, 2996, 2997, 2999, 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, 3009, 3010, 3011, 3012, 3013, 3014, 3015, 3016, 3017, 3018, 3019, 3024, 3025, 3027, 3028, 3032, 3033, 3034, 3035, 3036, 3037, 3038, 3039, 3040, 3041, 3042, 3043, 3044, 3045, 3046, 3047, 3050, 3051, 3052, 3053, 3055, 3056, 3057, 3058, 3059, 3061, 3062, 3063, 3064, 3065, 3066, 3067, 3068, 3069, 3070, 3071, 3072, 3075, 3076, 3077, 3078, 3079, 3080, 3081, 3082, 3085, 3086, 3087, 3088, 3090, 3091, 3092, 3093, 3094, 3095, 3096, 3097, 3098, 3099, 3100, 3101, 3102, 3103, 3104, 3105, 3106, 3108, 3110, 3111, 3112, 3113, 3114, 3115, 3117, 3119, 3120, 3121, 3122, 3123, 3124, 3125, 3126, 3127, 3128, 3129, 3130, 3131, 3132, 3133, 3134, 3135, 3143, 3144, 3145, 3146, 3147, 3148, 3149, 3150, 3151, 3153, 3154, 3155, 3156, 3157, 3158, 3159, 3161, 3162, 3163, 3164, 3165, 3166, 3169, 3170, 3171, 3172, 3174, 3175, 3177, 3178, 3180, 3181, 3182, 3186, 3187, 3188, 3189, 3190, 3191, 3192, 3194, 3196, 3197, 3198, 3199, 3200, 3201, 3202, 3203, 3204, 3205, 3206, 3207, 3208, 3209, 3210, 3211, 3212, 3213, 3214, 3216, 3217, 3218, 3219, 3221, 3222, 3223, 3224, 3225, 3226, 3227, 3228, 3229, 3231, 3232, 3233, 3234, 3235, 3236, 3237, 3238, 3239, 3240, 3241, 3242, 3243, 3245, 3246, 3247, 3248, 3249, 3250, 3251, 3252, 3253, 3254, 3255, 3256, 3257, 3258, 3259, 3260, 3261, 3262, 3263, 3264, 3265, 3266, 3267, 3268, 3269, 3270, 3271, 3272, 3273, 3274, 3275, 3276, 3277, 3278, 3279, 3280, 3281, 3283, 3284, 3285, 3286, 3287, 3288, 3289, 3290, 3291, 3292, 3293, 3294, 3295, 3296, 3297, 3298, 3299, 3301, 3302, 3303, 3304, 3306, 3307, 3308, 3309, 3310, 3311, 3312, 3313, 3314, 3315, 3316, 3317, 3318, 3319, 3324, 3325, 3326, 3327, 3329, 3330, 3331, 3332, 3333, 3334, 3335, 3336, 3337, 3338, 3342, 3343, 3344, 3346, 3347, 3348, 3350, 3352, 3353, 3354, 3355, 3356, 3357, 3358, 3359, 3360, 3361, 3362, 3363, 3364, 3365, 3366, 3367, 3368, 3369, 3370, 3371, 3372, 3373, 3374, 3375, 3376, 3377, 3378, 3379, 3380, 3381, 3382, 3383, 3384, 3386, 3388, 3389, 3390, 3391, 3392, 3395, 3396, 3397, 3398, 3399, 3400, 3401, 3402, 3403, 3404, 3405, 3406, 3409, 3410, 3411, 3412, 3413, 3414, 3415, 3416, 3417, 3418, 3419, 3420, 3423, 3424, 3425, 3426, 3427, 3428, 3429, 3430, 3431, 3432, 3433, 3434, 3435, 3443, 3444, 3445, 3448, 3449, 3450, 3451, 3452, 3455, 3456, 3457, 3458, 3459, 3462, 3464, 3467, 3468, 3471, 3472, 3473, 3474, 3476, 3478, 3479, 3480, 3485, 3486, 3488, 3489, 3490, 3491, 3492, 3493, 3496, 3497, 3498, 3499, 3500, 3501, 3502, 3503, 3504, 3505, 3506, 3507, 3508, 3509, 3510, 3511, 3512, 3513, 3514, 3515, 3516, 3518, 3519, 3520, 3521, 3522, 3523, 3524, 3525, 3526, 3528, 3529, 3530, 3531, 3532, 3533, 3534, 3535, 3536, 3537, 3538, 3539, 3540, 3541, 3543, 3544, 3545, 3546, 3547, 3548, 3549, 3550, 3551, 3552, 3553, 3555, 3556, 3557, 3558, 3559, 3560, 3561, 3562, 3563, 3564, 3565, 3566, 3567, 3568, 3569, 3570, 3572, 3573, 3574, 3575, 3576, 3577, 3578, 3579, 3580, 3581, 3583, 3585, 3586, 3587, 3588, 3589, 3590, 3591, 3592, 3593, 3594, 3595, 3596, 3600, 3602, 3603, 3604, 3605, 3606, 3607, 3608, 3609, 3610, 3611, 3612, 3613, 3614, 3615, 3616, 3617, 3618, 3619, 3620, 3622, 3623, 3624, 3625, 3626, 3627, 3628, 3629, 3630, 3631, 3632, 3633, 3634, 3635, 3636, 3637, 3638, 3639, 3640, 3641, 3643, 3644, 3645, 3646, 3647, 3648, 3649, 3650, 3651, 3652, 3653, 3654, 3655, 3656, 3657, 3658, 3659, 3660, 3661, 3662, 3663, 3664, 3665, 3666, 3667, 3668, 3669, 3670, 3671, 3672, 3673, 3674, 3675, 3676, 3677, 3678, 3680, 3681, 3682, 3683, 3684, 3685, 3686, 3687, 3688, 3689, 3690, 3692, 3694, 3695, 3696, 3697, 3698, 3699, 3700, 3701, 3702, 3703, 3704, 3705, 3706, 3707, 3708, 3709, 3710, 3712, 3713, 3714, 3715, 3716, 3718, 3719, 3720, 3721, 3722, 3723, 3724, 3725, 3726, 3727, 3728, 3729, 3730, 3731, 3733, 3734, 3735, 3736, 3737, 3738, 3739, 3740, 3741, 3742, 3743, 3744, 3745, 3746, 3747, 3752, 3753, 3755, 3757, 3759, 3760, 3761, 3762, 3763, 3764, 3766, 3767, 3768, 3769, 3770, 3771, 3772, 3773, 3775, 3776, 3777, 3778, 3780, 3781, 3783, 3784, 3785, 3786, 3787, 3788, 3789, 3790, 3791, 3792, 3796, 3797, 3798, 3799, 3800, 3801, 3802, 3803, 3804, 3806, 3809, 3810, 3811, 3812, 3813, 3814, 3815, 3816, 3818, 3819, 3820, 3821, 3822, 3823, 3824, 3825, 3826, 3827, 3828, 3829, 3830, 3833, 3834, 3835, 3836, 3838, 3839, 3840, 3841, 3842, 3843, 3844, 3846, 3847, 3848, 3849, 3851, 3855, 3862, 3863, 3864, 3865, 3866, 3868, 3869, 3870, 3871, 3872, 3873, 3874, 3875, 3876, 3877, 3878, 3879, 3880, 3881, 3882, 3883, 3884, 3886, 3887, 3888, 3889, 3890, 3893, 3894, 3895, 3896, 3897, 3898, 3899, 3900, 3901, 3902, 3903, 3904, 3905, 3906, 3907, 3908, 3909, 3910, 3911, 3912, 3915, 3916, 3917, 3918, 3920, 3921, 3922, 3923, 3925, 3926, 3927, 3929, 3930, 3931, 3932, 3935, 3936, 3937, 3938, 3939, 3940, 3941, 3942, 3943, 3944, 3945, 3946, 3947, 3948, 3949, 3950, 3951, 3952, 3953, 3954, 3955, 3956, 3957, 3958, 3959, 3960, 3961, 3962, 3963, 3965, 3966, 3967, 3968, 3969, 3970, 3974, 3975, 3976, 3977, 3978, 3979, 3981, 3982, 3983, 3984, 3985, 3986, 3987, 3988, 3990, 3991, 3993, 3994, 3995, 3997, 3998, 3999, 4000, 4001, 4002, 4003, 4004, 4005, 4006, 4007, 4008, 4009, 4010, 4011, 4012, 4013, 4014, 4015, 4016, 4018, 4019, 4020, 4021, 4022, 4023, 4024, 4025, 4026, 4027, 4028, 4029, 4030, 4031, 4032, 4033, 4034, 4035, 4036, 4037, 4038, 4039, 4040, 4041, 4042, 4043, 4044, 4045, 4046, 4047, 4048, 4049, 4050, 4051, 4052, 4054, 4056, 4057, 4058, 4059, 4060, 4061, 4062, 4063, 4064, 4065, 4066, 4067, 4068, 4069, 4070, 4071, 4072, 4073, 4074, 4075, 4076, 4077, 4078, 4079, 4080, 4081, 4082, 4083, 4084, 4085, 4086, 4087, 4088, 4089, 4090, 4091, 4092, 4093, 4094, 4095, 4097, 4098, 4099, 4101, 4102, 4103, 4104, 4105, 4106, 4107, 4108, 4109, 4110, 4111, 4112, 4113, 4114, 4115, 4116, 4117, 4118, 4119, 4120, 4121, 4122, 4123, 4124, 4125, 4126, 4127, 4128, 4129, 4130, 4131, 4132, 4133, 4134, 4135, 4136, 4137, 4138, 4139, 4141, 4142, 4144, 4145, 4146, 4147, 4148, 4149, 4150, 4151, 4153, 4154, 4155, 4157, 4158, 4159, 4160, 4161, 4163, 4164, 4165, 4167, 4168, 4169, 4171, 4175, 4176, 4177, 4178, 4179, 4180, 4181, 4182, 4183, 4184, 4185, 4186, 4187, 4189, 4190, 4191, 4192, 4193, 4194, 4195, 4196, 4197, 4198, 4199, 4200, 4201, 4202, 4203, 4204, 4205, 4206, 4207, 4208, 4209, 4210, 4211, 4212, 4213, 4214, 4216, 4217, 4218, 4221, 4223, 4224, 4226, 4227, 4228, 4229, 4230, 4231, 4232, 4233, 4234, 4235, 4236, 4237, 4238, 4239, 4240, 4241, 4242, 4246, 4247, 4248, 4249, 4250, 4251, 4252, 4253, 4254, 4255, 4256, 4257, 4260, 4261, 4262, 4263, 4264, 4265, 4266, 4267, 4268, 4269, 4270, 4271, 4272, 4273, 4274, 4275, 4276, 4277, 4278, 4279, 4280, 4281, 4282, 4283, 4284, 4285, 4286, 4287, 4288, 4289, 4290, 4291, 4292, 4293, 4294, 4295, 4296, 4297, 4299, 4300, 4301, 4303, 4305, 4306, 4307, 4308, 4309, 4310, 4311, 4312, 4313, 4314, 4315, 4316, 4317, 4318, 4320, 4321, 4322, 4323, 4324, 4325, 4326, 4327, 4328, 4329, 4330, 4332, 4334, 4335, 4336, 4337, 4338, 4339, 4340, 4341, 4342, 4343, 4344, 4345, 4346, 4348, 4350, 4351, 4353, 4354, 4355, 4356, 4358, 4359, 4360, 4361, 4363, 4364, 4365, 4366, 4367, 4368, 4369, 4370, 4372, 4373, 4374, 4375, 4376, 4379, 4380, 4381, 4382, 4383, 4384, 4385, 4386, 4387, 4388, 4389, 4390, 4391, 4393, 4394, 4395, 4397, 4398, 4399, 4400, 4401, 4402, 4403, 4404, 4405, 4406, 4408, 4409, 4410, 4411, 4412, 4413, 4414, 4415, 4416, 4417, 4419, 4421, 4422, 4423, 4424, 4425, 4426, 4427, 4428, 4429, 4430, 4434, 4437, 4438, 4440, 4443, 4445, 4446, 4449, 4450, 4451, 4452, 4453, 4454, 4455, 4456, 4457, 4458, 4459, 4460, 4462, 4463, 4464, 4465, 4466, 4467, 4468, 4469, 4470, 4471, 4472, 4473, 4474, 4475, 4476, 4477, 4478, 4479, 4480, 4481, 4482, 4483, 4484, 4486, 4487, 4488, 4489, 4491, 4492, 4493, 4494, 4495, 4496, 4497, 4499, 4500, 4501, 4503, 4504, 4505, 4506, 4507, 4508, 4509, 4510, 4511, 4513, 4514, 4516, 4517, 4519, 4520, 4521, 4522, 4524, 4525, 4526, 4527, 4528, 4532, 4533, 4536, 4537, 4538, 4539, 4540, 4541, 4542, 4544, 4545, 4546, 4547, 4548, 4550, 4551, 4552, 4553, 4554, 4555, 4556, 4557, 4558, 4559, 4560, 4561, 4562, 4563, 4564, 4565, 4566, 4567, 4568, 4569, 4570, 4571, 4572, 4573, 4574, 4575, 4578, 4579, 4580, 4583, 4584, 4585, 4586, 4587, 4588, 4589, 4590, 4591, 4592, 4593, 4594, 4595, 4599, 4600, 4602, 4603, 4604, 4605, 4606, 4607, 4608, 4609, 4614, 4615, 4616, 4617, 4620, 4621, 4622, 4623, 4624, 4625, 4626, 4627, 4628, 4629, 4630, 4634, 4635, 4636, 4637, 4639, 4640, 4641, 4642, 4644, 4645, 4646, 4647, 4648, 4649, 4651, 4652, 4653, 4654, 4656, 4657, 4658, 4659, 4660, 4662, 4663, 4664, 4666, 4667, 4670, 4671, 4672, 4673, 4674, 4679, 4683, 4689, 4690, 4691, 4692, 4693, 4694, 4695, 4696, 4697, 4698, 4704, 4705, 4706, 4707, 4708, 4710, 4711, 4712, 4713, 4715, 4716, 4717, 4718, 4719, 4720, 4721, 4722, 4723, 4725, 4726, 4727, 4728, 4729, 4730, 4731, 4732, 4733, 4734, 4735, 4736, 4737, 4739, 4740, 4741, 4742, 4743, 4744, 4745, 4746, 4747, 4748, 4749, 4750, 4751, 4752, 4753, 4754, 4755, 4756, 4757, 4758, 4759, 4760, 4761, 4762, 4763, 4764, 4765, 4766, 4767, 4768, 4769, 4770, 4771, 4772, 4773, 4774, 4776, 4777, 4779, 4780, 4781, 4782, 4783, 4785, 4786, 4787, 4788, 4789, 4790, 4791, 4792, 4793, 4794, 4795, 4796, 4797, 4798, 4799, 4800, 4801, 4802, 4803, 4804, 4805, 4806, 4807, 4808, 4809, 4810, 4811, 4812, 4814, 4815, 4816, 4817, 4818, 4819, 4820, 4821, 4822, 4823, 4824, 4825, 4826, 4827, 4829, 4830, 4831, 4832, 4833]),\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_time_bin_indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5f539736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49063225, 0.49612201, 0.61265914, ..., 0.50782605, 0.55819562,\n",
       "       0.66971   ])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_left_out_posterior_to_pf_surprises_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f996fd9",
   "metadata": {},
   "source": [
    "## Pre 2023-04-13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ea08f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute Fresh (don't load from cache)\n",
    "long_results_obj = perform_full_session_leave_one_out_decoding_analysis(global_session, original_1D_decoder=long_shared_aclus_only_decoder, decoding_time_bin_size = 0.025, cache_suffix = '_long', perform_cache_load=False, skip_cache_save=False)\n",
    "short_results_obj = perform_full_session_leave_one_out_decoding_analysis(global_session, original_1D_decoder=short_shared_aclus_only_decoder, decoding_time_bin_size = 0.025, cache_suffix = '_short', perform_cache_load=False, skip_cache_save=False)\n",
    "# # (time_bins, neurons), (epochs, neurons), (epochs)\n",
    "# all_epochs_computed_one_left_out_posterior_to_pf_surprises, all_epochs_computed_cell_one_left_out_posterior_to_pf_surprises_mean, all_epochs_all_cells_one_left_out_posterior_to_pf_surprises_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33b6ac25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num pyramidal_only_all_aclus: 40\n",
      "pyramidal_only_all_aclus: [ 5  6  7  8 10 11 12 15 17 18 19 20 21 24 25 26 27 28 31 34 35 39 40 41\n",
      " 43 44 45 48 49 50 51 52 53 55 56 60 62 63 64 65]\n",
      "active_epoch_n_timebins = 7\n",
      "len(shared_aclus) = 40\n",
      "callout_flat_timebin_IDXs = array([28, 30, 32])\n",
      "plots_data.callout_time_bins: [array([66.669, 66.719, 66.769]), array([66.694, 66.744, 66.794])]\n",
      "start_ts: [66.669 66.719 66.769], end_ts: [66.694 66.744 66.794]\n",
      "setting region[28]: 66.66900000000024, 66.69400000000036 :: end_t - start_t = 0.02500000000011937\n",
      "setting region[30]: 66.71900000000048, 66.7440000000006 :: end_t - start_t = 0.02500000000011937\n",
      "setting region[32]: 66.76900000000072, 66.79400000000084 :: end_t - start_t = 0.02500000000011937\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import plot_kourosh_activity_style_figure\n",
    "\n",
    "from neuropy.core.neurons import NeuronType\n",
    "# # Include only pyramidal aclus:\n",
    "# print(f'all shared_aclus: {len(shared_aclus)}\\nshared_aclus: {shared_aclus}')\n",
    "# shared_aclu_neuron_type = long_session.neurons.neuron_type[np.isin(long_session.neurons.neuron_ids, shared_aclus)]\n",
    "# assert len(shared_aclu_neuron_type) == len(shared_aclus)\n",
    "# # Find only the aclus that are pyramidal:\n",
    "# is_shared_aclu_pyramidal = (shared_aclu_neuron_type == NeuronType.PYRAMIDAL)\n",
    "# pyramidal_only_shared_aclus = shared_aclus[is_shared_aclu_pyramidal]\n",
    "# print(f'num pyramidal_only_shared_aclus: {len(pyramidal_only_shared_aclus)}\\npyramidal_only_shared_aclus: {pyramidal_only_shared_aclus}')\n",
    "\n",
    "\n",
    "## Drop Pyramidal but don't use only shared aclus:\n",
    "all_aclus = deepcopy(long_session.neurons.neuron_ids)\n",
    "neuron_type = long_session.neurons.neuron_type\n",
    "assert len(neuron_type) == len(all_aclus)\n",
    "# Find only the aclus that are pyramidal:\n",
    "is_aclu_pyramidal = (neuron_type == NeuronType.PYRAMIDAL)\n",
    "pyramidal_only_all_aclus = all_aclus[is_aclu_pyramidal]\n",
    "print(f'num pyramidal_only_all_aclus: {len(pyramidal_only_all_aclus)}\\npyramidal_only_all_aclus: {pyramidal_only_all_aclus}')\n",
    "\n",
    "# app, win, plots, plots_data = plot_kourosh_activity_style_figure(long_results_obj, long_session, shared_aclus, epoch_idx=5, callout_epoch_IDXs=[0,1,2,3], skip_rendering_callouts=True)\n",
    "# app, win, plots, plots_data = plot_kourosh_activity_style_figure(long_results_obj, long_session, pyramidal_only_shared_aclus, epoch_idx=2, callout_epoch_IDXs=[0,4], skip_rendering_callouts=False)\n",
    "app, win, plots, plots_data = plot_kourosh_activity_style_figure(long_results_obj, long_session, pyramidal_only_all_aclus, epoch_idx=3, callout_epoch_IDXs=[2,4,6], skip_rendering_callouts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea983fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "app, win, plots, plots_data = plot_kourosh_activity_style_figure(long_results_obj, long_session, pyramidal_only_all_aclus, epoch_idx=11, callout_epoch_IDXs=[0,1,2, 3, 4, 5], skip_rendering_callouts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3584cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f519e392",
   "metadata": {},
   "source": [
    "# 2023-04-13 Show Surprise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b417bb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "from PendingNotebookCode import plot_long_short, plot_long_short_any_values, plot_long_short_expected_vs_observed_firing_rates\n",
    "\n",
    "# plot_long_short(long_results_obj, short_results_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fbd6593",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "plot_long_short_any_values() missing 2 required positional arguments: 'x' and 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plot_long_short_any_values(long_results_obj\u001b[39m=\u001b[39;49mlong_results_obj, short_results_obj\u001b[39m=\u001b[39;49mshort_results_obj)\n",
      "\u001b[0;31mTypeError\u001b[0m: plot_long_short_any_values() missing 2 required positional arguments: 'x' and 'y'"
     ]
    }
   ],
   "source": [
    "plot_long_short_any_values(long_results_obj=long_results_obj, short_results_obj=short_results_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6b8a7ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<pyphoplacecellanalysis.External.pyqtgraph.widgets.PlotWidget.PlotWidget at 0x7f9fbaabfb80>,\n",
       " ({5: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaabe160>,\n",
       "   6: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaabf040>,\n",
       "   7: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaabf700>,\n",
       "   8: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaabfa60>,\n",
       "   10: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaabe5e0>,\n",
       "   11: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaabe940>,\n",
       "   12: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaabeca0>,\n",
       "   15: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaab0040>,\n",
       "   17: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaab03a0>,\n",
       "   18: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaab0700>,\n",
       "   20: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaab0a60>,\n",
       "   24: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaab0dc0>,\n",
       "   25: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaad7160>,\n",
       "   26: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaad74c0>,\n",
       "   27: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaad7820>,\n",
       "   28: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaad7b80>,\n",
       "   31: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaad7ee0>,\n",
       "   34: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaadb280>,\n",
       "   35: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaabfca0>,\n",
       "   39: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaaca5e0>,\n",
       "   40: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaadb550>,\n",
       "   41: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaadb8b0>,\n",
       "   43: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaadbc10>,\n",
       "   44: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaadbf70>,\n",
       "   45: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaad5310>,\n",
       "   49: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaad5670>,\n",
       "   50: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaad59d0>,\n",
       "   51: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaad5d30>,\n",
       "   52: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa6f0d0>,\n",
       "   53: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa6f4c0>,\n",
       "   55: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa6f820>,\n",
       "   56: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa6fb80>,\n",
       "   60: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa6fee0>,\n",
       "   62: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa72280>,\n",
       "   63: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa725e0>,\n",
       "   64: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa72940>,\n",
       "   65: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa72ca0>},\n",
       "  {5: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa7a040>,\n",
       "   6: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa7a3a0>,\n",
       "   7: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa7a700>,\n",
       "   8: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa7aa60>,\n",
       "   10: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa7adc0>,\n",
       "   11: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa8c160>,\n",
       "   12: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa8c4c0>,\n",
       "   15: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa8c820>,\n",
       "   17: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa8cb80>,\n",
       "   18: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa8cee0>,\n",
       "   20: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa93280>,\n",
       "   24: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa935e0>,\n",
       "   25: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa93940>,\n",
       "   26: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa93ca0>,\n",
       "   27: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa99040>,\n",
       "   28: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa993a0>,\n",
       "   31: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa99700>,\n",
       "   34: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa99a60>,\n",
       "   35: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa99dc0>,\n",
       "   39: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa31160>,\n",
       "   40: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa314c0>,\n",
       "   41: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa31820>,\n",
       "   43: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa31b80>,\n",
       "   44: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa31ee0>,\n",
       "   45: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa3b280>,\n",
       "   49: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa3b5e0>,\n",
       "   50: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa3b940>,\n",
       "   51: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa3bca0>,\n",
       "   52: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa42040>,\n",
       "   53: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa423a0>,\n",
       "   55: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa42700>,\n",
       "   56: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa42a60>,\n",
       "   60: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa42dc0>,\n",
       "   62: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa49160>,\n",
       "   63: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa494c0>,\n",
       "   64: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa49820>,\n",
       "   65: <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.PlotDataItem.PlotDataItem at 0x7f9fbaa49b80>}),\n",
       " <pyphoplacecellanalysis.External.pyqtgraph.graphicsItems.LegendItem.LegendItem at 0x7f9fbaac6b80>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_long_short_expected_vs_observed_firing_rates(long_results_obj=long_results_obj, short_results_obj=short_results_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1bdf68bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curr_epoch_time_bins.shape: (432,)\n",
      "np.shape(curr_epoch_data): (600,)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 8\u001b[0m\n\u001b[1;32m      3\u001b[0m y_fn \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m a_results_obj: a_results_obj\u001b[39m.\u001b[39mall_epochs_all_cells_one_left_out_posterior_to_pf_surprises_mean\n\u001b[1;32m      4\u001b[0m \u001b[39m# y_fn = lambda a_results_obj: a_results_obj.all_epochs_computed_one_left_out_posterior_to_pf_surprises\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[39m# (time_bins, neurons), (epochs, neurons), (epochs)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m# all_epochs_computed_one_left_out_posterior_to_pf_surprises, all_epochs_computed_cell_one_left_out_posterior_to_pf_surprises_mean, all_epochs_all_cells_one_left_out_posterior_to_pf_surprises_mean\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m win, plots_tuple, legend \u001b[39m=\u001b[39m plot_long_short_any_values(long_results_obj, short_results_obj, x\u001b[39m=\u001b[39;49mx_fn, y\u001b[39m=\u001b[39;49my_fn, limit_aclus\u001b[39m=\u001b[39;49m[\u001b[39m20\u001b[39;49m])\n",
      "File \u001b[0;32m~/repos/Spike3D/PendingNotebookCode.py:146\u001b[0m, in \u001b[0;36mplot_long_short_any_values\u001b[0;34m(long_results_obj, short_results_obj, x, y, limit_aclus)\u001b[0m\n\u001b[1;32m    144\u001b[0m curr_epoch_data \u001b[39m=\u001b[39m y(a_results_obj) \u001b[39m# [unit_IDX, curr_epoch_is_cell_active]\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnp.shape(curr_epoch_data): \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mshape(curr_epoch_data)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 146\u001b[0m curr_epoch_data \u001b[39m=\u001b[39m curr_epoch_data[unit_IDX, curr_epoch_is_cell_active]\n\u001b[1;32m    147\u001b[0m plots[aclu] \u001b[39m=\u001b[39m win\u001b[39m.\u001b[39mplot(x\u001b[39m=\u001b[39mcurr_epoch_time_bins, y\u001b[39m=\u001b[39mcurr_epoch_data, pen\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, symbol\u001b[39m=\u001b[39mcurr_symbol, symbolBrush\u001b[39m=\u001b[39mcell_color_symbol_brush[unit_IDX], name\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mlabel_prefix\u001b[39m}\u001b[39;00m\u001b[39m[\u001b[39m\u001b[39m{\u001b[39;00maclu\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m, alpha\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m) \u001b[39m#  symbolBrush=pg.intColor(i,6,maxValue=128)\u001b[39;00m\n\u001b[1;32m    148\u001b[0m legend\u001b[39m.\u001b[39maddItem(plots[aclu], \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mlabel_prefix\u001b[39m}\u001b[39;00m\u001b[39m[\u001b[39m\u001b[39m{\u001b[39;00maclu\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/spike3d-xhKu_1Lg-py3.9/lib64/python3.9/site-packages/numpy/ma/core.py:3222\u001b[0m, in \u001b[0;36mMaskedArray.__getitem__\u001b[0;34m(self, indx)\u001b[0m\n\u001b[1;32m   3212\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3213\u001b[0m \u001b[39mx.__getitem__(y) <==> x[y]\u001b[39;00m\n\u001b[1;32m   3214\u001b[0m \n\u001b[1;32m   3215\u001b[0m \u001b[39mReturn the item described by i, as a masked array.\u001b[39;00m\n\u001b[1;32m   3216\u001b[0m \n\u001b[1;32m   3217\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3218\u001b[0m \u001b[39m# We could directly use ndarray.__getitem__ on self.\u001b[39;00m\n\u001b[1;32m   3219\u001b[0m \u001b[39m# But then we would have to modify __array_finalize__ to prevent the\u001b[39;00m\n\u001b[1;32m   3220\u001b[0m \u001b[39m# mask of being reshaped if it hasn't been set up properly yet\u001b[39;00m\n\u001b[1;32m   3221\u001b[0m \u001b[39m# So it's easier to stick to the current version\u001b[39;00m\n\u001b[0;32m-> 3222\u001b[0m dout \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata[indx]\n\u001b[1;32m   3223\u001b[0m _mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mask\n\u001b[1;32m   3225\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_is_scalar\u001b[39m(m):\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "x_fn = lambda a_results_obj: a_results_obj.all_epochs_decoded_epoch_time_bins_mean[:,0]\n",
    "# y_fn = lambda a_results_obj: a_results_obj.all_epochs_all_cells_one_left_out_posterior_to_scrambled_pf_surprises_mean\n",
    "y_fn = lambda a_results_obj: a_results_obj.all_epochs_all_cells_one_left_out_posterior_to_pf_surprises_mean\n",
    "# y_fn = lambda a_results_obj: a_results_obj.all_epochs_computed_one_left_out_posterior_to_pf_surprises\n",
    "\n",
    "# (time_bins, neurons), (epochs, neurons), (epochs)\n",
    "# all_epochs_computed_one_left_out_posterior_to_pf_surprises, all_epochs_computed_cell_one_left_out_posterior_to_pf_surprises_mean, all_epochs_all_cells_one_left_out_posterior_to_pf_surprises_mean\n",
    "win, plots_tuple, legend = plot_long_short_any_values(long_results_obj, short_results_obj, x=x_fn, y=y_fn, limit_aclus=[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe80559",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
