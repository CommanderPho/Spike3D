{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from dash import Dash, html, dash_table\n",
    "import pandas as pd\n",
    "# final_dfs_dict\n",
    "df = pd.read_csv('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/2024-01-29_AcrossSession_Laps_per-Epoch.csv')\n",
    "\n",
    "# Initialize the app\n",
    "app = Dash(__name__)\n",
    "\n",
    "# App layout\n",
    "app.layout = html.Div([\n",
    "    html.Div(children='My First App with Data'),\n",
    "    dash_table.DataTable(data=df.to_dict('records'), page_size=10)\n",
    "])\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from dash import Dash, html, dash_table, dcc # (DCC stands for Dash Core Components)\n",
    "# dcc.Graph: used to render interactive graphs.\n",
    "import pandas as pd\n",
    "import plotly.io as pio\n",
    "template: str = 'plotly_dark' # set plotl template\n",
    "pio.templates.default = template\n",
    "import plotly.express as px\n",
    "\n",
    "# Incorporate data\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/gapminder2007.csv')\n",
    "\n",
    "# Initialize the app\n",
    "app = Dash(__name__)\n",
    "\n",
    "# App layout\n",
    "app.layout = html.Div([\n",
    "    html.Div(children='My First App with Data and a Graph'),\n",
    "    dash_table.DataTable(data=df.to_dict('records'), page_size=10),\n",
    "    dcc.Graph(figure=px.histogram(df, x='continent', y='lifeExp', histfunc='avg'))\n",
    "])\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from dash import Dash, html, dash_table, dcc, callback, Output, Input\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Incorporate data\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/gapminder2007.csv')\n",
    "\n",
    "# Initialize the app\n",
    "app = Dash(__name__)\n",
    "\n",
    "# App layout\n",
    "app.layout = html.Div([\n",
    "    html.Div(children='My First App with Data, Graph, and Controls'),\n",
    "    html.Hr(),\n",
    "    dash_table.DataTable(data=df.to_dict('records'), page_size=6),\n",
    "    dcc.Graph(figure={}, id='controls-and-graph'),\n",
    "    dcc.RadioItems(options=['pop', 'lifeExp', 'gdpPercap'], value='lifeExp', id='controls-and-radio-item'),\n",
    "])\n",
    "\n",
    "# Add controls to build the interaction\n",
    "@callback(\n",
    "    Output(component_id='controls-and-graph', component_property='figure'),\n",
    "    Input(component_id='controls-and-radio-item', component_property='value')\n",
    ")\n",
    "def update_graph(col_chosen):\n",
    "    fig = px.histogram(df, x='continent', y=col_chosen, histfunc='avg')\n",
    "    return fig\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from dash import Dash, html, dash_table, dcc, callback, Output, Input\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "\n",
    "# Incorporate data\n",
    "final_csv_export_paths = {'AcrossSession_Laps_per-Epoch': Path('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/2024-01-29_AcrossSession_Laps_per-Epoch.csv'),\n",
    " 'AcrossSession_Ripple_per-Epoch': Path('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/2024-01-29_AcrossSession_Ripple_per-Epoch.csv'),\n",
    " 'AcrossSession_Laps_per-TimeBin': Path('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/2024-01-29_AcrossSession_Laps_per-TimeBin.csv'),\n",
    " 'AcrossSession_Ripple_per-TimeBin': Path('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/2024-01-29_AcrossSession_Ripple_per-TimeBin.csv')}\n",
    "\n",
    "final_dfs_dict = {a_name:pd.read_csv(a_path.resolve()) for a_name, a_path in final_csv_export_paths.items()}\n",
    "\n",
    "options_list = list(final_csv_export_paths.keys())\n",
    "initial_option = options_list[0]\n",
    "\n",
    "# Initialize the app\n",
    "app = Dash(__name__)\n",
    "\n",
    "# App layout\n",
    "app.layout = html.Div([\n",
    "    html.Div(children='My Custom App with Data, Graph, and Controls'),\n",
    "    html.Hr(),\n",
    "    dcc.RadioItems(options=options_list, value=initial_option, id='controls-and-radio-item'),\n",
    "    dash_table.DataTable(data=df.to_dict('records'), page_size=6),\n",
    "    dcc.Graph(figure={}, id='controls-and-graph'),\n",
    "])\n",
    "\n",
    "# Add controls to build the interaction\n",
    "@callback(\n",
    "    Output(component_id='controls-and-graph', component_property='figure'),\n",
    "    Input(component_id='controls-and-radio-item', component_property='value')\n",
    ")\n",
    "def update_graph(col_chosen):\n",
    "    print(f'col_chosen: {col_chosen}')\n",
    "    a_df = final_dfs_dict[col_chosen]\n",
    "    # fig = px.histogram(df, x='continent', y=col_chosen, histfunc='avg')\n",
    "    # fig = px.histogram(a_df, x='continent', y='P_Long', histfunc='avg')\n",
    "    fig = px.scatter(a_df, x='delta_aligned_start_t', y='P_Long', title=f\"{col_chosen}\", color='session_name', size='time_bin_size')\n",
    "    return fig\n",
    "\n",
    "\n",
    "    # fig = px.histogram(df, x='continent', y=col_chosen, histfunc='avg')\n",
    "    # return fig\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1b5407ded00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dash import Dash, html, dcc, Input, Output, callback\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "\n",
    "app = Dash(__name__, external_stylesheets=external_stylesheets)\n",
    "\n",
    "df = pd.read_csv('https://plotly.github.io/datasets/country_indicators.csv')\n",
    "\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.Div([\n",
    "\n",
    "        html.Div([\n",
    "            dcc.Dropdown(\n",
    "                df['Indicator Name'].unique(),\n",
    "                'Fertility rate, total (births per woman)',\n",
    "                id='crossfilter-xaxis-column',\n",
    "            ),\n",
    "            dcc.RadioItems(\n",
    "                ['Linear', 'Log'],\n",
    "                'Linear',\n",
    "                id='crossfilter-xaxis-type',\n",
    "                labelStyle={'display': 'inline-block', 'marginTop': '5px'}\n",
    "            )\n",
    "        ],\n",
    "        style={'width': '49%', 'display': 'inline-block'}),\n",
    "\n",
    "        html.Div([\n",
    "            dcc.Dropdown(\n",
    "                df['Indicator Name'].unique(),\n",
    "                'Life expectancy at birth, total (years)',\n",
    "                id='crossfilter-yaxis-column'\n",
    "            ),\n",
    "            dcc.RadioItems(\n",
    "                ['Linear', 'Log'],\n",
    "                'Linear',\n",
    "                id='crossfilter-yaxis-type',\n",
    "                labelStyle={'display': 'inline-block', 'marginTop': '5px'}\n",
    "            )\n",
    "        ], style={'width': '49%', 'float': 'right', 'display': 'inline-block'})\n",
    "    ], style={\n",
    "        'padding': '10px 5px'\n",
    "    }),\n",
    "\n",
    "    html.Div([\n",
    "        dcc.Graph(\n",
    "            id='crossfilter-indicator-scatter',\n",
    "            hoverData={'points': [{'customdata': 'Japan'}]}\n",
    "        )\n",
    "    ], style={'width': '49%', 'display': 'inline-block', 'padding': '0 20'}),\n",
    "    html.Div([\n",
    "        dcc.Graph(id='x-time-series'),\n",
    "        dcc.Graph(id='y-time-series'),\n",
    "    ], style={'display': 'inline-block', 'width': '49%'}),\n",
    "\n",
    "    html.Div(dcc.Slider(\n",
    "        df['Year'].min(),\n",
    "        df['Year'].max(),\n",
    "        step=None,\n",
    "        id='crossfilter-year--slider',\n",
    "        value=df['Year'].max(),\n",
    "        marks={str(year): str(year) for year in df['Year'].unique()}\n",
    "    ), style={'width': '49%', 'padding': '0px 20px 20px 20px'})\n",
    "])\n",
    "\n",
    "\n",
    "@callback(\n",
    "    Output('crossfilter-indicator-scatter', 'figure'),\n",
    "    Input('crossfilter-xaxis-column', 'value'),\n",
    "    Input('crossfilter-yaxis-column', 'value'),\n",
    "    Input('crossfilter-xaxis-type', 'value'),\n",
    "    Input('crossfilter-yaxis-type', 'value'),\n",
    "    Input('crossfilter-year--slider', 'value'))\n",
    "def update_graph(xaxis_column_name, yaxis_column_name,\n",
    "                 xaxis_type, yaxis_type,\n",
    "                 year_value):\n",
    "    dff = df[df['Year'] == year_value]\n",
    "\n",
    "    fig = px.scatter(x=dff[dff['Indicator Name'] == xaxis_column_name]['Value'],\n",
    "            y=dff[dff['Indicator Name'] == yaxis_column_name]['Value'],\n",
    "            hover_name=dff[dff['Indicator Name'] == yaxis_column_name]['Country Name']\n",
    "            )\n",
    "\n",
    "    fig.update_traces(customdata=dff[dff['Indicator Name'] == yaxis_column_name]['Country Name'])\n",
    "\n",
    "    fig.update_xaxes(title=xaxis_column_name, type='linear' if xaxis_type == 'Linear' else 'log')\n",
    "\n",
    "    fig.update_yaxes(title=yaxis_column_name, type='linear' if yaxis_type == 'Linear' else 'log')\n",
    "\n",
    "    fig.update_layout(margin={'l': 40, 'b': 40, 't': 10, 'r': 0}, hovermode='closest')\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def create_time_series(dff, axis_type, title):\n",
    "\n",
    "    fig = px.scatter(dff, x='Year', y='Value')\n",
    "\n",
    "    fig.update_traces(mode='lines+markers')\n",
    "\n",
    "    fig.update_xaxes(showgrid=False)\n",
    "\n",
    "    fig.update_yaxes(type='linear' if axis_type == 'Linear' else 'log')\n",
    "\n",
    "    fig.add_annotation(x=0, y=0.85, xanchor='left', yanchor='bottom',\n",
    "                       xref='paper', yref='paper', showarrow=False, align='left',\n",
    "                       text=title)\n",
    "\n",
    "    fig.update_layout(height=225, margin={'l': 20, 'b': 30, 'r': 10, 't': 10})\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "@callback(\n",
    "    Output('x-time-series', 'figure'),\n",
    "    Input('crossfilter-indicator-scatter', 'hoverData'),\n",
    "    Input('crossfilter-xaxis-column', 'value'),\n",
    "    Input('crossfilter-xaxis-type', 'value'))\n",
    "def update_x_timeseries(hoverData, xaxis_column_name, axis_type):\n",
    "    country_name = hoverData['points'][0]['customdata']\n",
    "    dff = df[df['Country Name'] == country_name]\n",
    "    dff = dff[dff['Indicator Name'] == xaxis_column_name]\n",
    "    title = '<b>{}</b><br>{}'.format(country_name, xaxis_column_name)\n",
    "    return create_time_series(dff, axis_type, title)\n",
    "\n",
    "\n",
    "@callback(\n",
    "    Output('y-time-series', 'figure'),\n",
    "    Input('crossfilter-indicator-scatter', 'hoverData'),\n",
    "    Input('crossfilter-yaxis-column', 'value'),\n",
    "    Input('crossfilter-yaxis-type', 'value'))\n",
    "def update_y_timeseries(hoverData, yaxis_column_name, axis_type):\n",
    "    dff = df[df['Country Name'] == hoverData['points'][0]['customdata']]\n",
    "    dff = dff[dff['Indicator Name'] == yaxis_column_name]\n",
    "    return create_time_series(dff, axis_type, yaxis_column_name)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Four-CSV displaying version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from typing import List, Dict, Optional, Tuple, Union\n",
    "from dash import Dash, html, dash_table, dcc, callback, Output, Input\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "\n",
    "# Incorporate data\n",
    "final_csv_export_paths = {'AcrossSession_Laps_per-Epoch': Path('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/2024-01-29_AcrossSession_Laps_per-Epoch.csv'),\n",
    " 'AcrossSession_Ripple_per-Epoch': Path('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/2024-01-29_AcrossSession_Ripple_per-Epoch.csv'),\n",
    " 'AcrossSession_Laps_per-TimeBin': Path('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/2024-01-29_AcrossSession_Laps_per-TimeBin.csv'),\n",
    " 'AcrossSession_Ripple_per-TimeBin': Path('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/2024-01-29_AcrossSession_Ripple_per-TimeBin.csv')}\n",
    "\n",
    "final_dfs_dict = {a_name:pd.read_csv(a_path.resolve()) for a_name, a_path in final_csv_export_paths.items()}\n",
    "\n",
    "options_list = list(final_csv_export_paths.keys())\n",
    "initial_option = options_list[0]\n",
    "initial_dataframe: pd.DataFrame = final_dfs_dict[initial_option]\n",
    "\n",
    "# Initialize the app\n",
    "app = Dash(__name__)\n",
    "\n",
    "# App layout\n",
    "app.layout = html.Div([\n",
    "    html.Div(children='My Custom App with Data, Graph, and Controls'),\n",
    "    html.Hr(),\n",
    "    dcc.RadioItems(options=options_list, value=initial_option, id='controls-and-radio-item'),\n",
    "    dash_table.DataTable(data=initial_dataframe.to_dict('records'), page_size=6, id='tbl-datatable'),\n",
    "    dcc.Graph(figure={}, id='controls-and-graph'),\n",
    "])\n",
    "\n",
    "# Add controls to build the interaction\n",
    "@callback(\n",
    "    Output(component_id='controls-and-graph', component_property='figure'),\n",
    "    Input(component_id='controls-and-radio-item', component_property='value')\n",
    ")\n",
    "def update_graph(col_chosen):\n",
    "    print(f'update_graph(col_chosen: {col_chosen})')\n",
    "    data_results_df: pd.DataFrame = final_dfs_dict[col_chosen]\n",
    "    unique_sessions: List[str] = data_results_df['session_name'].unique().tolist()\n",
    "    num_unique_sessions: int = data_results_df['session_name'].nunique(dropna=True) # number of unique sessions, ignoring the NA entries\n",
    "\n",
    "    ## Extract the unique time bin sizes:\n",
    "    time_bin_sizes: List[float] = data_results_df['time_bin_size'].unique().tolist()\n",
    "    num_unique_time_bins: int = data_results_df.time_bin_size.nunique(dropna=True)\n",
    "    print(f'num_unique_sessions: {num_unique_sessions}, num_unique_time_bins: {num_unique_time_bins}')\n",
    "    fig = px.scatter(data_results_df, x='delta_aligned_start_t', y='P_Long', title=f\"{col_chosen}\", color='time_bin_size', range_y=[0.0, 1.0],\n",
    "                            labels={\"session_name\": \"Session\", \"time_bin_size\": \"tbin_size\"},\n",
    "                            facet_row='session_name', facet_row_spacing=0.04, # default is 0.07 when facet_col_wrap is used\n",
    "                            height=num_unique_sessions*200, width=1024,\n",
    "                            )\n",
    "    return fig\n",
    "\n",
    "\n",
    "@callback(\n",
    "    Output(component_id='tbl-datatable', component_property='data'),\n",
    "    Input(component_id='controls-and-radio-item', component_property='value')\n",
    ")\n",
    "def update_datatable(col_chosen):\n",
    "    print(f'update_datatable(col_chosen: {col_chosen})')\n",
    "    a_df = final_dfs_dict[col_chosen]\n",
    "    data = a_df.to_dict('records')\n",
    "    return data\n",
    "\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_unique_sessions: 13, num_unique_time_bins: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8052/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1b53f71d5b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import packages\n",
    "from typing import List, Dict, Optional, Tuple, Union\n",
    "from dash import Dash, html, dash_table, dcc, callback, Output, Input, State\n",
    "import dash_bootstrap_components as dbc\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "def _build_dash_app(final_dfs_dict):\n",
    "    ## DATA:    \n",
    "    options_list = list(final_dfs_dict.keys())\n",
    "    initial_option = options_list[0]\n",
    "    initial_dataframe: pd.DataFrame = final_dfs_dict[initial_option]\n",
    "    unique_sessions: List[str] = initial_dataframe['session_name'].unique().tolist()\n",
    "    num_unique_sessions: int = initial_dataframe['session_name'].nunique(dropna=True) # number of unique sessions, ignoring the NA entries\n",
    "\n",
    "    ## Extract the unique time bin sizes:\n",
    "    time_bin_sizes: List[float] = initial_dataframe['time_bin_size'].unique().tolist()\n",
    "    num_unique_time_bins: int = initial_dataframe.time_bin_size.nunique(dropna=True)\n",
    "    print(f'num_unique_sessions: {num_unique_sessions}, num_unique_time_bins: {num_unique_time_bins}')\n",
    "    enabled_time_bin_sizes = [time_bin_sizes[0], time_bin_sizes[-1]] # [0.03, 0.058, 0.10]\n",
    "\n",
    "    # Initialize the app\n",
    "    app = Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "\n",
    "    # App layout\n",
    "    app.layout = dbc.Container([\n",
    "        html.Div(children='My Custom App with Data, Graph, and Controls'),\n",
    "        html.Hr(),\n",
    "        dbc.Row([\n",
    "            dbc.Col(dcc.RadioItems(options=options_list, value=initial_option, id='controls-and-radio-item')),\n",
    "            # Add CheckboxGroup for time_bin_sizes\n",
    "            # html.Div(dcc.Checklist(options=[{'label':i, 'value': i} for i in final_dfs_dict[initial_option]['time_bin_size'].unique()], id='time-bin-checkboxes', inline=True)),\n",
    "            dbc.Col(dcc.Checklist(options=time_bin_sizes, value=enabled_time_bin_sizes, id='time-bin-checkboxes', inline=True)),\n",
    "        ]),\n",
    "        dbc.Row(dash_table.DataTable(data=initial_dataframe.to_dict('records'), page_size=6, id='tbl-datatable')),\n",
    "        dbc.Row(dcc.Graph(figure={}, id='controls-and-graph')),\n",
    "    ])\n",
    "\n",
    "\n",
    "    # Add controls to build the interaction\n",
    "    @callback(\n",
    "        Output(component_id='controls-and-graph', component_property='figure'),\n",
    "        [Input(component_id='controls-and-radio-item', component_property='value'),\n",
    "            State(component_id='time-bin-checkboxes', component_property='value'),\n",
    "        ]\n",
    "    )\n",
    "    def update_graph(col_chosen, chose_bin_sizes):\n",
    "        print(f'update_graph(col_chosen: {col_chosen}, chose_bin_sizes: {chose_bin_sizes})')\n",
    "        data_results_df: pd.DataFrame = final_dfs_dict[col_chosen]\n",
    "        # Filter dataframe by chosen bin sizes\n",
    "        data_results_df = data_results_df[data_results_df.time_bin_size.isin(chose_bin_sizes)]\n",
    "        \n",
    "        unique_sessions: List[str] = data_results_df['session_name'].unique().tolist()\n",
    "        num_unique_sessions: int = data_results_df['session_name'].nunique(dropna=True) # number of unique sessions, ignoring the NA entries\n",
    "\n",
    "        ## Extract the unique time bin sizes:\n",
    "        time_bin_sizes: List[float] = data_results_df['time_bin_size'].unique().tolist()\n",
    "        num_unique_time_bins: int = data_results_df.time_bin_size.nunique(dropna=True)\n",
    "        print(f'num_unique_sessions: {num_unique_sessions}, num_unique_time_bins: {num_unique_time_bins}')\n",
    "        fig = px.scatter(data_results_df, x='delta_aligned_start_t', y='P_Long', title=f\"{col_chosen}\", color='time_bin_size', range_y=[0.0, 1.0],\n",
    "                                labels={\"session_name\": \"Session\", \"time_bin_size\": \"tbin_size\"},\n",
    "                                facet_row='session_name', facet_row_spacing=0.04, # default is 0.07 when facet_col_wrap is used\n",
    "                                facet_col_wrap=2, facet_col_spacing=0.04,\n",
    "                                height=num_unique_sessions*200, width=1024,\n",
    "                                )\n",
    "        return fig\n",
    "\n",
    "\n",
    "    @callback(\n",
    "        Output(component_id='tbl-datatable', component_property='data'),\n",
    "        [Input(component_id='controls-and-radio-item', component_property='value'),\n",
    "            State(component_id='time-bin-checkboxes', component_property='value'),\n",
    "        ]\n",
    "    )\n",
    "    def update_datatable(col_chosen, chose_bin_sizes):\n",
    "        print(f'update_datatable(col_chosen: {col_chosen}, chose_bin_sizes: {chose_bin_sizes})')\n",
    "        a_df = final_dfs_dict[col_chosen]\n",
    "        # Filter dataframe by chosen bin sizes\n",
    "        a_df = a_df[a_df.time_bin_size.isin(chose_bin_sizes)]\n",
    "        data = a_df.to_dict('records')\n",
    "        return data\n",
    "\n",
    "    return app\n",
    "\n",
    "\n",
    "# Incorporate data\n",
    "final_csv_export_paths = {'AcrossSession_Laps_per-Epoch': Path('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/2024-01-29_AcrossSession_Laps_per-Epoch.csv'),\n",
    " 'AcrossSession_Ripple_per-Epoch': Path('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/2024-01-29_AcrossSession_Ripple_per-Epoch.csv'),\n",
    " 'AcrossSession_Laps_per-TimeBin': Path('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/2024-01-29_AcrossSession_Laps_per-TimeBin.csv'),\n",
    " 'AcrossSession_Ripple_per-TimeBin': Path('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/2024-01-29_AcrossSession_Ripple_per-TimeBin.csv')}\n",
    "\n",
    "final_dfs_dict = {a_name:pd.read_csv(a_path.resolve()) for a_name, a_path in final_csv_export_paths.items()}\n",
    "app = _build_dash_app(final_dfs_dict)\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=\"8052\", debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "y = np.random.randn(500)\n",
    "# Use `y` argument instead of `x` for horizontal histogram\n",
    "\n",
    "fig = go.Figure(data=[go.Histogram(y=y)])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.subplots as sp\n",
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "\n",
    "# assuming X and Y are your data\n",
    "# also assuming that the scatter is sorted in the way you want to split it\n",
    "X = np.random.randn(200)\n",
    "Y = np.random.randn(200)\n",
    "\n",
    "split = len(X) // 2  # get the point to split the data\n",
    "\n",
    "# creating subplots\n",
    "fig = sp.make_subplots(rows=1, cols=3, column_widths=[0.10, 0.80, 0.10], horizontal_spacing=0.01)\n",
    "\n",
    "# adding first histogram\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        y=X[:split],\n",
    "        name='first half',\n",
    "        marker_color='#EB89B5'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# adding scatter plot\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=X,\n",
    "        y=Y,\n",
    "        mode='markers',\n",
    "        marker_color='rgba(152, 0, 0, .8)',\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# adding the second histogram\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        y=X[split:],\n",
    "        name='second half',\n",
    "        marker_color='#330C73'\n",
    "    ),\n",
    "    row=1, col=3\n",
    ")\n",
    "\n",
    "# Plot!\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.subplots as sp\n",
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "\n",
    "# assuming X and Y are your data\n",
    "# also assuming that the scatter is sorted in the way you want to split it\n",
    "X = np.random.randn(200)\n",
    "Y = np.random.randn(200)\n",
    "\n",
    "split = len(X) // 2  # get the point to split the data\n",
    "\n",
    "# creating subplots\n",
    "fig = sp.make_subplots(rows=1, cols=3, column_widths=[0.10, 0.80, 0.10], horizontal_spacing=0.01)\n",
    "\n",
    "# adding first histogram\n",
    "# Calculate the histogram data\n",
    "hist1, bins1 = np.histogram(X[:split], bins='auto')\n",
    "\n",
    "# Adding the first histogram as a bar graph and making x negative\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=-bins1[:-1],\n",
    "        y=hist1,\n",
    "        marker_color='#EB89B5',\n",
    "        name='first half',\n",
    "\t\torientation='h',\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "\n",
    "# adding scatter plot\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=X,\n",
    "        y=Y,\n",
    "        mode='markers',\n",
    "        marker_color='rgba(152, 0, 0, .8)',\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# adding the second histogram\n",
    "\n",
    "# Calculate the histogram data for second half\n",
    "hist2, bins2 = np.histogram(X[split:], bins='auto')\n",
    "\n",
    "# Adding the second histogram\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=bins2[:-1],\n",
    "        y=hist2,\n",
    "        marker_color='#330C73',\n",
    "        name='second half',\n",
    "\t\torientation='h',\n",
    "    ),\n",
    "    row=1, col=3\n",
    ")\n",
    "\n",
    "\n",
    "# Plot!\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.templates\n",
    "\n",
    "template: str = 'plotly_dark'\n",
    "template=template, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_yellow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
