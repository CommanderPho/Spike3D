{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33f7f339",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[0️⃣ ReviewOfWork (Main Notebook) - Imports](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77d98a7b",
   "metadata": {
    "tags": [
     "run-group-0-interactive",
     "run-group-0",
     "2025-04-11 - full-session marginals"
    ]
   },
   "outputs": [],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "# %xmode Verbose\n",
    "# %xmode context\n",
    "%pdb off\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "# # Add exclusions for metaclass-using modules\n",
    "# %aimport -neuropy.core.session.dataSession\n",
    "# %aimport -neuropy.core.session.Formats.BaseDataSessionFormats\n",
    "# %aimport -neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat\n",
    "# %aimport -neuropy.core.session.Formats.Specific.BapunDataSessionFormat \n",
    "# %aimport -neuropy.core.session.Formats.Specific.RachelDataSessionFormat\n",
    "# %aimport -neuropy.core.session.Formats.Specific.HiroDataSessionFormat\n",
    "\n",
    "# !pip install viztracer\n",
    "# %load_ext viztracer\n",
    "# from viztracer import VizTracer\n",
    "\n",
    "# %load_ext memory_profiler\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "os.environ['QT_API'] = 'pyqt5'\n",
    "os.environ['PYQTGRAPH_QT_LIB'] = 'PyQt5'\n",
    "\n",
    "# from PyQt5.QtWebEngineWidgets import QWebEngineView ## this must come first, before any QtApplication is made: 'ImportError: QtWebEngineWidgets must be imported or Qt.AA_ShareOpenGLContexts must be set before a QCoreApplication instance is created'\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "import importlib\n",
    "from copy import deepcopy\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "# pd.options.mode.dtype_backend = 'pyarrow' # use new pyarrow backend instead of numpy\n",
    "\n",
    "from attrs import define, field, fields, Factory, make_class\n",
    "import tables as tb\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Pho's Formatting Preferences\n",
    "import builtins\n",
    "\n",
    "import IPython\n",
    "from IPython.core.formatters import PlainTextFormatter\n",
    "from IPython import get_ipython\n",
    "\n",
    "from pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\n",
    "set_pho_preferences_concise()\n",
    "# Jupyter-lab enable printing for any line on its own (instead of just the last one in the cell)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# BEGIN PPRINT CUSTOMIZATION ___________________________________________________________________________________________ #\n",
    "\n",
    "## IPython pprint\n",
    "from pyphocorehelpers.pprint import wide_pprint, wide_pprint_ipython, wide_pprint_jupyter, MAX_LINE_LENGTH\n",
    "# Override default pprint\n",
    "builtins.pprint = wide_pprint\n",
    "\n",
    "ip = get_ipython()\n",
    "\n",
    "from pyphocorehelpers.ipython_helpers import CustomFormatterMagics\n",
    "\n",
    "# Register the magic\n",
    "get_ipython().register_magics(CustomFormatterMagics)\n",
    "\n",
    "\n",
    "\n",
    "from pyphocorehelpers.pyqt_ipython_rendering_helpers import PyQtFormatters\n",
    "from pyphoplacecellanalysis.General.Mixins.DisplayHelpers import debug_widget_geometry\n",
    "\n",
    "# Register formatters for specific PyQt5 types\n",
    "# Create an instance and register formatters\n",
    "qt_formatters = PyQtFormatters()\n",
    "qt_formatters.register()\n",
    "\n",
    "# from pho_jupyter_preview_widget.display_helpers import array_repr_with_graphical_preview\n",
    "# from pho_jupyter_preview_widget.ipython_helpers import PreviewWidgetMagics\n",
    "\n",
    "# # Register the magic\n",
    "# ip.register_magics(PreviewWidgetMagics)\n",
    "\n",
    "# # %config_ndarray_preview width=500\n",
    "\n",
    "# # Register the custom display function for NumPy arrays\n",
    "# # ip.display_formatter.formatters['text/html'].for_type(np.ndarray, lambda arr: array_preview_with_graphical_shape_repr_html(arr))\n",
    "# # ip = array_repr_with_graphical_shape(ip=ip)\n",
    "# ip = array_repr_with_graphical_preview(ip=ip)\n",
    "# # ip = dataframe_show_more_button(ip=ip)\n",
    "\n",
    "text_formatter: PlainTextFormatter = ip.display_formatter.formatters['text/plain']\n",
    "text_formatter.max_width = MAX_LINE_LENGTH\n",
    "text_formatter.for_type(object, wide_pprint_jupyter)\n",
    "\n",
    "\n",
    "# END PPRINT CUSTOMIZATION ___________________________________________________________________________________________ #\n",
    "\n",
    "from pyphocorehelpers.print_helpers import get_now_time_str, get_now_day_str\n",
    "from pyphocorehelpers.indexing_helpers import get_dict_subset\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path, file_uri_from_path\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "import pyphocorehelpers.programming_helpers as programming_helpers\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "# from neuropy import core\n",
    "from typing import Dict, List, Tuple, Optional, Callable, Union, Any\n",
    "from typing_extensions import TypeAlias\n",
    "import nptyping as ND\n",
    "from nptyping import NDArray\n",
    "import neuropy.utils.type_aliases as types\n",
    "\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder, find_local_session_paths\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.core.epoch import NamedTimerange, Epoch\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.utils.matplotlib_helpers import matplotlib_file_only, matplotlib_configuration, matplotlib_configuration_update\n",
    "from neuropy.core.neuron_identities import NeuronIdentityTable, neuronTypesList, neuronTypesEnum\n",
    "from neuropy.utils.mixins.AttrsClassHelpers import AttrsBasedClassHelperMixin, serialized_field, serialized_attribute_field, non_serialized_field, custom_define\n",
    "from neuropy.utils.mixins.HDF5_representable import HDF_DeserializationMixin, post_deserialize, HDF_SerializationMixin, HDFMixin, HDF_Converter\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.neurons import NeuronType\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from neuropy.core.position import Position\n",
    "from neuropy.core.session.dataSession import DataSession\n",
    "from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent, PlacefieldSnapshot\n",
    "from neuropy.utils.debug_helpers import debug_print_placefield, debug_print_subsession_neuron_differences, debug_print_ratemap, debug_print_spike_counts, debug_plot_2d_binning, print_aligned_columns, parameter_sweeps, _plot_parameter_sweep, compare_placefields_info\n",
    "from neuropy.utils.indexing_helpers import NumpyHelpers, union_of_arrays, intersection_of_arrays, find_desired_sort_indicies, paired_incremental_sorting\n",
    "from pyphocorehelpers.print_helpers import print_object_memory_usage, print_dataframe_memory_usage, print_value_overview_only, DocumentationFilePrinter, print_keys_if_possible, generate_html_string, document_active_variables\n",
    "from pyphocorehelpers.programming_helpers import metadata_attributes\n",
    "from pyphocorehelpers.function_helpers import function_attributes\n",
    "## Pho Programming Helpers:\n",
    "import inspect\n",
    "from pyphocorehelpers.print_helpers import DocumentationFilePrinter, TypePrintMode, print_keys_if_possible, debug_dump_object_member_shapes, print_value_overview_only, document_active_variables\n",
    "from pyphocorehelpers.programming_helpers import IPythonHelpers, PythonDictionaryDefinitionFormat, MemoryManagement, inspect_callable_arguments, get_arguments_as_optional_dict, GeneratedClassDefinitionType, CodeConversion\n",
    "from pyphocorehelpers.notebook_helpers import NotebookCellExecutionLogger\n",
    "from pyphocorehelpers.gui.Qt.TopLevelWindowHelper import TopLevelWindowHelper, print_widget_hierarchy\n",
    "from pyphocorehelpers.indexing_helpers import reorder_columns, reorder_columns_relative, dict_to_full_array\n",
    "from pyphocorehelpers.DataStructure.RenderPlots.MatplotLibRenderPlots import MatplotlibRenderPlots\n",
    "\n",
    "doc_output_parent_folder: Path = Path('EXTERNAL/DEVELOPER_NOTES/DataStructureDocumentation').resolve() # ../.\n",
    "print(f\"doc_output_parent_folder: {doc_output_parent_folder}\")\n",
    "assert doc_output_parent_folder.exists()\n",
    "\n",
    "_notebook_path:Path = Path(IPythonHelpers.try_find_notebook_filepath(IPython.extract_module_locals())).resolve() # Finds the path of THIS notebook\n",
    "# _notebook_execution_logger: NotebookCellExecutionLogger = NotebookCellExecutionLogger(notebook_path=_notebook_path, enable_logging_to_file=False) # Builds a logger that records info about this notebook\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_load_session, batch_extended_computations, batch_evaluate_required_computations, batch_extended_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme # used in perform_pipeline_save\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import PipelineJupyterHelpers, CustomProcessingPhases\n",
    "\n",
    "\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "pg.setConfigOptions(useOpenGL=True)    # Use OpenGL for rendering which handles larger coordinates\n",
    "\n",
    "from pyphocorehelpers.exception_helpers import ExceptionPrintingContext, CapturedException\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import _find_any_context_neurons\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchSessionCompletionHandler # for `post_compute_validate(...)`\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BasePositionDecoder\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsResults\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends # for `_perform_long_short_instantaneous_spike_rate_groups_analysis`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import SingleBarResult, InstantaneousSpikeRateGroupsComputation, TruncationCheckingResults # for `BatchSessionCompletionHandler`, `AcrossSessionsAggregator`\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import SplitPartitionMembership\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalComputationFunctions, DirectionalLapsResult, TrackTemplates, DecoderDecodedEpochsResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderGlobalComputationFunctions,  RankOrderComputationsContainer, RankOrderResult, RankOrderAnalyses\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import EpochComputationFunctions, EpochComputationsComputationsContainer, NonPBEDimensionalDecodingResult, Compute_NonPBE_Epochs, KnownFilterEpochs\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.SequenceBasedComputations import WCorrShuffle, SequenceBasedComputationsContainer\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.ComputationFunctionRegistryHolder import ComputationFunctionRegistryHolder, computation_precidence_specifying_function, global_function\n",
    "\n",
    "from neuropy.utils.mixins.binning_helpers import transition_matrix\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import TransitionMatrixComputations\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates, get_proper_global_spikes_df\n",
    "\n",
    "from pyphocorehelpers.Filesystem.path_helpers import set_posix_windows\n",
    "\n",
    "from pyphocorehelpers.assertion_helpers import Assert\n",
    "\n",
    "# Plotting\n",
    "# import pylustrator # customization of figures\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "\n",
    "matplotlib.use('Qt5Agg')\n",
    "# %matplotlib inline\n",
    "# %matplotlib auto\n",
    "\n",
    "# _restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# import pylustrator # call `pylustrator.start()` before creating your first figure in code.\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap, visualize_heatmap_pyqtgraph # used in `plot_kourosh_activity_style_figure`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot, plot_raster_plot\n",
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import UnitColoringMode, DataSeriesColorHelpers\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import _build_default_tick, build_scatter_plot_kwargs\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.Render2DScrollWindowPlot import Render2DScrollWindowPlotMixin, ScatterItemData\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_extended_programmatic_figures, batch_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "from pyphoplacecellanalysis.General.Mixins.SpikesRenderingBaseMixin import SpikeEmphasisState\n",
    "from pyphoplacecellanalysis.General.Model.SpecificComputationParameterTypes import ComputationKWargParameters\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PAPER_FIGURE_figure_1_add_replay_epoch_rasters, PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_3, main_complete_figure_generations\n",
    "# from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import *\n",
    "\n",
    "# Jupyter Widget Interactive\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import interactive_pipeline_widget, interactive_pipeline_files\n",
    "from pyphocorehelpers.gui.Jupyter.simple_widgets import fullwidth_path_widget, render_colors\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import PipelineJupyterHelpers, CustomProcessingPhases, PipelinePickleFileSelectorWidget\n",
    "\n",
    "from datetime import datetime, date, timedelta\n",
    "from pyphocorehelpers.print_helpers import get_now_day_str, get_now_rounded_time_str\n",
    "\n",
    "DAY_DATE_STR: str = date.today().strftime(\"%Y-%m-%d\")\n",
    "DAY_DATE_TO_USE = f'{DAY_DATE_STR}' # used for filenames throught the notebook\n",
    "print(f'DAY_DATE_STR: {DAY_DATE_STR}, DAY_DATE_TO_USE: {DAY_DATE_TO_USE}')\n",
    "\n",
    "NOW_DATETIME: str = get_now_rounded_time_str()\n",
    "NOW_DATETIME_TO_USE = f'{NOW_DATETIME}' # used for filenames throught the notebook\n",
    "print(f'NOW_DATETIME: {NOW_DATETIME}, NOW_DATETIME_TO_USE: {NOW_DATETIME_TO_USE}')\n",
    "\n",
    "def get_global_variable(var_name):\n",
    "    \"\"\" used by `PipelineJupyterHelpers._build_pipeline_custom_processing_mode_selector_widget(...)` to update the notebook's variables \"\"\"\n",
    "    return globals()[var_name]\n",
    "    \n",
    "def update_global_variable(var_name, value):\n",
    "    \"\"\" used by `PipelineJupyterHelpers._build_pipeline_custom_processing_mode_selector_widget(...)` to update the notebook's variables \"\"\"\n",
    "    globals()[var_name] = value\n",
    "\n",
    "from pyphocorehelpers.gui.Jupyter.simple_widgets import build_global_data_root_parent_path_selection_widget\n",
    "all_paths = [Path(r'/home/halechr/FastData'), Path('/Volumes/SwapSSD/Data'), Path('/Users/pho/data'), Path(r'/media/halechr/MAX/Data'), Path(r'W:\\Data'), Path(r'/home/halechr/cloud/turbo/Data'), Path(r'/Volumes/MoverNew/data'), Path(r'/home/halechr/turbo/Data'), Path(r'/Users/pho/cloud/turbo/Data')] # Path('/Volumes/FedoraSSD/FastData'), \n",
    "global_data_root_parent_path = None\n",
    "def on_user_update_path_selection(new_path: Path):\n",
    "    global global_data_root_parent_path\n",
    "    new_global_data_root_parent_path = new_path.resolve()\n",
    "    global_data_root_parent_path = new_global_data_root_parent_path\n",
    "    print(f'global_data_root_parent_path changed to {global_data_root_parent_path}')\n",
    "    assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "            \n",
    "global_data_root_parent_path_widget = build_global_data_root_parent_path_selection_widget(all_paths, on_user_update_path_selection)\n",
    "global_data_root_parent_path_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e81646",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[0️⃣ Load Pipeline](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f07773d",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-0",
     "all",
     "run-group-0-interactive",
     "2025-04-11 - full-session marginals"
    ]
   },
   "outputs": [],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Load Data                                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "active_data_mode_name = 'kdiba'\n",
    "local_session_root_parent_context = IdentifyingContext(format_name=active_data_mode_name) # , animal_name='', configuration_name='one', session_name=a_sess.session_name\n",
    "local_session_root_parent_path = global_data_root_parent_path.joinpath('KDIBA')\n",
    "\n",
    "# [*] - indicates bad or session with a problem\n",
    "# 0, 1, 2, 3, 4, 5, 6, 7, [8], [9], 10, 11, [12], 13, 14, [15], [16], 17, \n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15') # Recomputed 2025-01-20 19:59 -- `ReviewOfWork_2025-01-20.ipynb`\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43') # Recomputed 2025-04-04 02:08 -- ``  \n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31') # Recomputed 2025-01-16 03:21 \n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19') # Recomputed 2025-01-07 13:31 \n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46') # Recomputed 2024-12-16 19:23 \n",
    "curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30') ## BLOCKING ERROR with pf2D computation (empty) for 5Hz 2024-12-02 15:24 \n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50') # Recomputed 2024-12-16 19:45 \n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54') # Recomputed 2024-12-16 19:29 -- about 3 good replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3') # Recomputed 2024-12-16 19:32 \n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25') # Recomputed 2024-12-16 19:33 -- about 5 good replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54') # Recomputed 2024-12-16 19:36 -- TONS of good replays, 10+ pages of them \n",
    "\n",
    "local_session_parent_path: Path = local_session_root_parent_path.joinpath(curr_context.animal, curr_context.exper_name) # 'gor01', 'one' - probably not needed anymore\n",
    "basedir: Path = local_session_parent_path.joinpath(curr_context.session_name).resolve()\n",
    "print(f'basedir: {str(basedir)}')\n",
    "\n",
    "epoch_name_includelist = None\n",
    "active_computation_functions_name_includelist=['lap_direction_determination',\n",
    "                                                'pf_computation',\n",
    "                                                'pfdt_computation',\n",
    "                                                # 'firing_rate_trends',\n",
    "                                                # 'pf_dt_sequential_surprise', \n",
    "                                            #    'ratemap_peaks_prominence2d',\n",
    "                                                'position_decoding', \n",
    "                                                # 'position_decoding_two_step', #'directional_decoders_epoch_heuristic_scoring',\n",
    "                                            #    'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping',\n",
    "                                            #     'long_short_inst_spike_rate_groups',\n",
    "                                            #     'long_short_endcap_analysis',\n",
    "                                            \n",
    "]\n",
    "\n",
    "## 'split_to_directional_laps' -- is global\n",
    "\n",
    "\n",
    "\n",
    "# Read if possible:\n",
    "saving_mode = PipelineSavingScheme.SKIP_SAVING\n",
    "force_reload = False\n",
    "\n",
    "# # Force write:\n",
    "# saving_mode = PipelineSavingScheme.TEMP_THEN_OVERWRITE\n",
    "# saving_mode = PipelineSavingScheme.OVERWRITE_IN_PLACE\n",
    "# force_reload = True\n",
    "\n",
    "selector, on_value_change = PipelineJupyterHelpers._build_pipeline_custom_processing_mode_selector_widget(update_global_variable_fn=update_global_variable, debug_print=False, enable_full_view=True)\n",
    "# selector.value = 'clean_run'\n",
    "selector.value = 'continued_run'\n",
    "# selector.value = 'final_run'\n",
    "on_value_change(dict(new=selector.value)) ## do update manually so the workspace variables reflect the set values\n",
    "## TODO: if loading is not possible, we need to change the `saving_mode` so that the new results are properly saved.\n",
    "print(f\"saving_mode: {saving_mode}, force_reload: {force_reload}\")\n",
    "\n",
    "extended_computations_include_includelist_phase_dict: Dict[str, CustomProcessingPhases] = CustomProcessingPhases.get_extended_computations_include_includelist_phase_dict()\n",
    "\n",
    "current_phase: CustomProcessingPhases = CustomProcessingPhases[selector.value]  # Assuming selector.value is an instance of CustomProcessingPhases\n",
    "extended_computations_include_includelist: List[str] = [key for key, value in extended_computations_include_includelist_phase_dict.items() if value <= current_phase]\n",
    "display(extended_computations_include_includelist)\n",
    "force_recompute_override_computations_includelist = None\n",
    "# force_recompute_override_computations_includelist = ['split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous'] # \n",
    "\n",
    "# ## INPUTS: basedir\n",
    "active_session_pickle_file_widget = PipelinePickleFileSelectorWidget(directory=basedir, on_update_global_variable_callback=update_global_variable, on_get_global_variable_callback=get_global_variable)\n",
    "\n",
    "_subfn_load, _subfn_save, _subfn_compute = active_session_pickle_file_widget._build_load_save_callbacks(global_data_root_parent_path=global_data_root_parent_path, active_data_mode_name=active_data_mode_name, basedir=basedir, saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                                             extended_computations_include_includelist=extended_computations_include_includelist, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist)\n",
    "\n",
    "## try selecting the first\n",
    "did_find_valid_selection: bool = active_session_pickle_file_widget.try_select_first_valid_files()\n",
    "\n",
    "# Display the widget\n",
    "active_session_pickle_file_widget.servable()\n",
    "# active_session_pickle_file_widget.try_select_first_valid_files()\n",
    "\n",
    "# OUTPUTS: active_session_pickle_file_widget, widget.active_local_pkl, widget.active_global_pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6e0657",
   "metadata": {
    "tags": [
     "run-group-0-interactive",
     "2025-04-11 - full-session marginals"
    ]
   },
   "outputs": [],
   "source": [
    "if did_find_valid_selection:\n",
    "\t_subfn_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac6b6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set default local comp pkl:\n",
    "default_selected_local_file_name: str = 'loadedSessPickle.pkl'\n",
    "default_local_section_indicies = [active_session_pickle_file_widget.local_file_browser_widget._data['File Name'].tolist().index(default_selected_local_file_name)]\n",
    "active_session_pickle_file_widget.local_file_browser_widget.selection = default_local_section_indicies\n",
    "\n",
    "## Set default global computation pkl:\n",
    "default_selected_global_file_name: str = 'global_computation_results.pkl'\n",
    "default_global_section_indicies = [active_session_pickle_file_widget.global_file_browser_widget._data['File Name'].tolist().index(default_selected_global_file_name)]\n",
    "active_session_pickle_file_widget.global_file_browser_widget.selection = default_global_section_indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c072a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.IPyWidgets.SaveAsWidget import PipelineBackupWidget\n",
    "\n",
    "backup_widget = PipelineBackupWidget(curr_active_pipeline)\n",
    "backup_widget.servable()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb1135e",
   "metadata": {},
   "source": [
    "## <a id='toc2_1_'></a>[2024-06-25 - Load from saved custom](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5515d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline, custom_suffix, proposed_load_pkl_path = active_session_pickle_file_widget.on_load_local(global_data_root_parent_path=global_data_root_parent_path, active_data_mode_name=active_data_mode_name, basedir=basedir, saving_mode=saving_mode, force_reload=force_reload)\n",
    "curr_active_pipeline = active_session_pickle_file_widget.on_load_global(curr_active_pipeline=curr_active_pipeline, basedir=basedir, extended_computations_include_includelist=extended_computations_include_includelist, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist,\n",
    "                                       skip_global_load=False, force_reload=False, override_global_computation_results_pickle_path=active_session_pickle_file_widget.active_global_pkl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9337ddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads custom pipeline pickles that were saved out via `custom_save_filepaths['pipeline_pkl'] = curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE, active_pickle_filename=custom_save_filenames['pipeline_pkl'])`\n",
    "\n",
    "## INPUTS: global_data_root_parent_path, active_data_mode_name, basedir, saving_mode, force_reload, custom_save_filenames\n",
    "# custom_suffix: str = '_withNewKamranExportedReplays'\n",
    "\n",
    "# custom_suffix: str = '_withNewComputedReplays'\n",
    "# custom_suffix: str = '_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0'\n",
    "\n",
    "# custom_save_filenames = {\n",
    "#     'pipeline_pkl':f'loadedSessPickle{custom_suffix}.pkl',\n",
    "#     'global_computation_pkl':f\"global_computation_results{custom_suffix}.pkl\",\n",
    "#     'pipeline_h5':f'pipeline{custom_suffix}.h5',\n",
    "# }\n",
    "# print(f'custom_save_filenames: {custom_save_filenames}')\n",
    "# custom_save_filepaths = {k:v for k, v in custom_save_filenames.items()}\n",
    "\n",
    "# # ==================================================================================================================== #\n",
    "# # PIPELINE LOADING                                                                                                     #\n",
    "# # ==================================================================================================================== #\n",
    "# # load the custom saved outputs\n",
    "# active_pickle_filename = custom_save_filenames['pipeline_pkl'] # 'loadedSessPickle_withParameters.pkl'\n",
    "# print(f'active_pickle_filename: \"{active_pickle_filename}\"')\n",
    "# # assert active_pickle_filename.exists()\n",
    "# active_session_h5_filename = custom_save_filenames['pipeline_h5'] # 'pipeline_withParameters.h5'\n",
    "# print(f'active_session_h5_filename: \"{active_session_h5_filename}\"')\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "## DO NOT allow recompute if the file doesn't exist!!\n",
    "# Computing loaded session pickle file results : \"W:/Data/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle_withNewComputedReplays.pkl\"... done.\n",
    "# Failure loading W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\loadedSessPickle_withNewComputedReplays.pkl.\n",
    "# proposed_load_pkl_path = basedir.joinpath(active_pickle_filename).resolve()\n",
    "\n",
    "## INPUTS: widget.active_global_pkl, widget.active_global_pkl\n",
    "\n",
    "if active_session_pickle_file_widget.active_global_pkl is None:\n",
    "    skip_global_load: bool = True\n",
    "    override_global_computation_results_pickle_path = None\n",
    "else:\n",
    "    skip_global_load: bool = False\n",
    "    override_global_computation_results_pickle_path = active_session_pickle_file_widget.active_global_pkl.resolve()\n",
    "    Assert.path_exists(override_global_computation_results_pickle_path)\n",
    "    override_global_computation_results_pickle_path\n",
    "\n",
    "\n",
    "proposed_load_pkl_path = active_session_pickle_file_widget.active_local_pkl.resolve()\n",
    "Assert.path_exists(proposed_load_pkl_path)\n",
    "proposed_load_pkl_path\n",
    "\n",
    "custom_suffix: str = active_session_pickle_file_widget.try_extract_custom_suffix()\n",
    "print(f'custom_suffix: \"{custom_suffix}\"')\n",
    "\n",
    "## OUTPUTS: custom_suffix, proposed_load_pkl_path, (override_global_computation_results_pickle_path, skip_global_load)\n",
    "from pyphocorehelpers.Filesystem.path_helpers import set_posix_windows\n",
    "## INPUTS: proposed_load_pkl_path\n",
    "assert proposed_load_pkl_path.exists(), f\"for a saved custom the file must exist!\"\n",
    "\n",
    "epoch_name_includelist=None\n",
    "active_computation_functions_name_includelist=['lap_direction_determination', 'pf_computation','firing_rate_trends', 'position_decoding']\n",
    "\n",
    "with set_posix_windows():\n",
    "    curr_active_pipeline: NeuropyPipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_includelist=epoch_name_includelist,\n",
    "                                            computation_functions_name_includelist=active_computation_functions_name_includelist,\n",
    "                                            saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                            skip_extended_batch_computations=True, debug_print=False, fail_on_exception=True, active_pickle_filename=proposed_load_pkl_path) # , active_pickle_filename = 'loadedSessPickle_withParameters.pkl'\n",
    "\n",
    "## Post Compute Validate 2023-05-16:\n",
    "was_updated = BatchSessionCompletionHandler.post_compute_validate(curr_active_pipeline) ## TODO: need to potentially re-save if was_updated. This will fail because constained versions not ran yet.\n",
    "if was_updated:\n",
    "    print(f'was_updated: {was_updated}')\n",
    "    try:\n",
    "        if saving_mode == PipelineSavingScheme.SKIP_SAVING:\n",
    "            print(f'WARNING: PipelineSavingScheme.SKIP_SAVING but need to save post_compute_validate changes!!')\n",
    "        else:\n",
    "            curr_active_pipeline.save_pipeline(saving_mode=saving_mode)\n",
    "    except Exception as e:\n",
    "        ## TODO: catch/log saving error and indicate that it isn't saved.\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'ERROR RE-SAVING PIPELINE after update. error: {e}')\n",
    "\n",
    "print(f'Pipeline loaded from custom pickle!!')\n",
    "## OUTPUT: curr_active_pipeline\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Global computations loading:                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "# Loads saved global computations that were saved out via: `custom_save_filepaths['global_computation_pkl'] = curr_active_pipeline.save_global_computation_results(override_global_pickle_filename=custom_save_filenames['global_computation_pkl'])`\n",
    "## INPUTS: custom_save_filenames\n",
    "## INPUTS: curr_active_pipeline, override_global_computation_results_pickle_path, extended_computations_include_includelist\n",
    "\n",
    "override_global_computation_results_pickle_path = None\n",
    "# override_global_computation_results_pickle_path = custom_save_filenames['global_computation_pkl']\n",
    "print(f'override_global_computation_results_pickle_path: \"{override_global_computation_results_pickle_path}\"')\n",
    "\n",
    "# Pre-load ___________________________________________________________________________________________________________ #\n",
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Pre-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "# valid_computed_results_output_list\n",
    "\n",
    "# Try Unpickling Global Computations to update pipeline ______________________________________________________________ #\n",
    "if (not force_reload) and (not skip_global_load): # not just force_reload, needs to recompute whenever the computation fails.\n",
    "    try:\n",
    "        # INPUTS: override_global_computation_results_pickle_path\n",
    "        with set_posix_windows():\n",
    "            sucessfully_updated_keys, successfully_loaded_keys = curr_active_pipeline.load_pickled_global_computation_results(override_global_computation_results_pickle_path=override_global_computation_results_pickle_path,\n",
    "                                                                                            allow_overwrite_existing=True, allow_overwrite_existing_allow_keys=extended_computations_include_includelist, ) # is new\n",
    "            print(f'sucessfully_updated_keys: {sucessfully_updated_keys}\\nsuccessfully_loaded_keys: {successfully_loaded_keys}')\n",
    "            did_any_paths_change: bool = curr_active_pipeline.post_load_fixup_sess_basedirs(updated_session_basepath=deepcopy(basedir)) ## use INPUT: basedir\n",
    "            \n",
    "    except FileNotFoundError as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'cannot load global results because pickle file does not exist! Maybe it has never been created? {e}')\n",
    "    except Exception as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'Unhandled exception: cannot load global results: {e}')\n",
    "        raise\n",
    "\n",
    "# Post-Load __________________________________________________________________________________________________________ #\n",
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "\n",
    "\n",
    "\n",
    "## fixup missing paths\n",
    "# self.basepath: WindowsPath('/nfs/turbo/umms-kdiba/KDIBA/gor01/one/2006-6-09_1-22-43')\n",
    "\n",
    "## INPUTS: basedir\n",
    "did_any_paths_change: bool = curr_active_pipeline.post_load_fixup_sess_basedirs(updated_session_basepath=deepcopy(basedir)) ## use INPUT: basedir\n",
    "\n",
    "# Compute ____________________________________________________________________________________________________________ #\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "force_recompute_global = force_reload\n",
    "# force_recompute_global = True\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "if (len(newly_computed_values) > 0):\n",
    "    print(f'newly_computed_values: {newly_computed_values}.')\n",
    "    if (saving_mode.value != 'skip_saving'):\n",
    "        print(f'Saving global results...')\n",
    "        try:\n",
    "            # curr_active_pipeline.global_computation_results.persist_time = datetime.now()\n",
    "            # Try to write out the global computation function results:\n",
    "            curr_active_pipeline.save_global_computation_results()\n",
    "        except Exception as e:\n",
    "            exception_info = sys.exc_info()\n",
    "            e = CapturedException(e, exception_info)\n",
    "            print(f'\\n\\n!!WARNING!!: saving the global results threw the exception: {e}')\n",
    "            print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "    else:\n",
    "        print(f'\\n\\n!!WARNING!!: changes to global results have been made but they will not be saved since saving_mode.value == \"skip_saving\"')\n",
    "        print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "else:\n",
    "    print(f'no changes in global results.')\n",
    "\n",
    "# Post-compute _______________________________________________________________________________________________________ #\n",
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=False, force_recompute_override_computations_includelist=[], debug_print=True)\n",
    "print(f'Post-compute validation: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "\n",
    "# Post-Load __________________________________________________________________________________________________________ #\n",
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "\n",
    "print(f'force_reload: {force_reload}, saving_mode: {saving_mode}')\n",
    "force_reload\n",
    "saving_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f813f01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## indicate that it was loaded with a custom suffix\n",
    "curr_active_pipeline.pickle_path ## correct\n",
    "curr_active_pipeline.global_computation_results_pickle_path ## correct\n",
    "\n",
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE, override_pickle_path=curr_active_pipeline.pickle_path, active_pickle_filename=curr_active_pipeline.pickle_path.name) #active_pickle_filename=\n",
    "curr_active_pipeline.save_global_computation_results(override_global_pickle_path=curr_active_pipeline.global_computation_results_pickle_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49de9fb9",
   "metadata": {},
   "source": [
    "## <a id='toc2_2_'></a>[0️⃣ RESUME Normal Pipeline Load](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9ba82e",
   "metadata": {},
   "source": [
    "## <a id='toc2_3_'></a>[0️⃣ Normal Pipeline Load](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8167df1c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-0",
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-full_session_LOO_decoding_analysis.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "# epoch_name_includelist = ['maze']\n",
    "\n",
    "curr_active_pipeline: NeuropyPipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_includelist=epoch_name_includelist,\n",
    "                                        computation_functions_name_includelist=active_computation_functions_name_includelist,\n",
    "                                        saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                        skip_extended_batch_computations=True, debug_print=True, fail_on_exception=False) #, time_bin_size = 0.025 time_bin_size = 0.058, override_parameters_flat_keypaths_dict = dict(), \n",
    "# , active_pickle_filename = 'loadedSessPickle_withParameters.pkl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b125667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.get_failed_computations()\n",
    "curr_active_pipeline.clear_all_failed_computations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76c7dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# {'maze1_odd': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze2_odd': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze_odd': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze1_even': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze2_even': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze_even': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze1_any': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze2_any': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze_any': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')}}\n",
    "\n",
    "_out = curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_split_to_directional_laps'], fail_on_exception=True, debug_print=True)\n",
    "\n",
    "\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_split_to_directional_laps'], computation_kwargs_list=[{}], \n",
    "#                                                   enabled_filter_names=None, fail_on_exception=True, debug_print=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8edcd94",
   "metadata": {
    "tags": [
     "run-group-0"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "## Post Compute Validate 2023-05-16:\n",
    "# was_updated = BatchSessionCompletionHandler.post_compute_validate(curr_active_pipeline) ## TODO: need to potentially re-save if was_updated. This will fail because constained versions not ran yet.\n",
    "was_updated = False\n",
    "if was_updated:\n",
    "    print(f'was_updated: {was_updated}')\n",
    "    try:\n",
    "        curr_active_pipeline.save_pipeline(saving_mode=saving_mode)\n",
    "    except Exception as e:\n",
    "        ## TODO: catch/log saving error and indicate that it isn't saved.\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'ERROR RE-SAVING PIPELINE after update. error: {e}')\n",
    "\n",
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Pre-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "# valid_computed_results_output_list\n",
    "if not force_reload: # not just force_reload, needs to recompute whenever the computation fails.\n",
    "    try:\n",
    "        # curr_active_pipeline.load_pickled_global_computation_results()\n",
    "        with set_posix_windows():\n",
    "            sucessfully_updated_keys, successfully_loaded_keys = curr_active_pipeline.load_pickled_global_computation_results(allow_overwrite_existing=True, allow_overwrite_existing_allow_keys=extended_computations_include_includelist) # is new\n",
    "            \n",
    "        print(f'sucessfully_updated_keys: {sucessfully_updated_keys}\\nsuccessfully_loaded_keys: {successfully_loaded_keys}')\n",
    "    except FileNotFoundError as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'cannot load global results because pickle file does not exist! Maybe it has never been created? {e}')\n",
    "    except Exception as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'Unhandled exception: cannot load global results: {e}')\n",
    "        raise\n",
    "\n",
    "# Recomputing active_epoch_placefields... \t done.\n",
    "# Recomputing active_epoch_placefields2D... \t done.\n",
    "# WARN: f\"len(self.is_non_firing_time_bin): 30459, self.num_time_windows: 30762\", trying to recompute them....\n",
    "# UNHANDLED EXCEPTION: Unable to allocate 3.46 GiB for an array with shape (15124, 30724) and data type float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9809aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.accumulated_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcac55a8",
   "metadata": {
    "tags": [
     "run-group-0",
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "force_recompute_global = force_reload # Post-load global computations: needs_computation_output_dict: ['rank_order_shuffle_analysis', 'directional_train_test_split', 'short_long_pf_overlap_analyses', 'wcorr_shuffle_analysis', 'extended_pf_peak_information', 'position_decoding_two_step']\n",
    "# force_recompute_global = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4321d2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fail_on_exception = False\n",
    "\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=fail_on_exception, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "if (len(newly_computed_values) > 0):\n",
    "    print(f'newly_computed_values: {newly_computed_values}.')\n",
    "    if (saving_mode.value != 'skip_saving'):\n",
    "        print(f'Saving global results...')\n",
    "        try:\n",
    "            # curr_active_pipeline.global_computation_results.persist_time = datetime.now()\n",
    "            # Try to write out the global computation function results:\n",
    "            curr_active_pipeline.save_global_computation_results()\n",
    "        except Exception as e:\n",
    "            exception_info = sys.exc_info()\n",
    "            e = CapturedException(e, exception_info)\n",
    "            print(f'\\n\\n!!WARNING!!: saving the global results threw the exception: {e}')\n",
    "            print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "    else:\n",
    "        print(f'\\n\\n!!WARNING!!: changes to global results have been made but they will not be saved since saving_mode.value == \"skip_saving\"')\n",
    "        print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "else:\n",
    "    print(f'no changes in global results.')\n",
    "\n",
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=fail_on_exception, progress_print=True,\n",
    "                                                    force_recompute=False, force_recompute_override_computations_includelist=[], debug_print=True)\n",
    "print(f'Post-compute validation: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615018da",
   "metadata": {},
   "source": [
    "## <a id='toc2_4_'></a>[0️⃣ Shared Post-Pipeline load stuff](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c842f5e4",
   "metadata": {
    "tags": [
     "run-group-0-interactive",
     "2025-04-11 - full-session marginals"
    ]
   },
   "outputs": [],
   "source": [
    "BATCH_DATE_TO_USE: str = f'{DAY_DATE_TO_USE}_GL'\n",
    "# BATCH_DATE_TO_USE: str = f'{DAY_DATE_TO_USE}_rMBP' # TODO: Change this as needed, templating isn't actually doing anything rn.\n",
    "# BATCH_DATE_TO_USE: str = f'{DAY_DATE_TO_USE}_Apogee'\n",
    "# BATCH_DATE_TO_USE: str = f'{DAY_DATE_TO_USE}_Lab'\n",
    " \n",
    "try:\n",
    "    if custom_suffix is not None:\n",
    "        BATCH_DATE_TO_USE = f'{BATCH_DATE_TO_USE}{custom_suffix}'\n",
    "        print(f'Adding custom suffix: \"{custom_suffix}\" - BATCH_DATE_TO_USE: \"{BATCH_DATE_TO_USE}\"')\n",
    "except NameError as err:\n",
    "    custom_suffix = None\n",
    "    print(f'NO CUSTOM SUFFIX.')\n",
    "\n",
    "known_collected_output_paths = [Path(v).resolve() for v in ['/nfs/turbo/umms-kdiba/Data/Output/collected_outputs', '/home/halechr/FastData/collected_outputs/',\n",
    "                                                           '/home/halechr/cloud/turbo/Data/Output/collected_outputs',\n",
    "                                                           r'C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\output\\collected_outputs',\n",
    "                                                           r\"K:\\scratch\\collected_outputs\",\n",
    "                                                           '/Users/pho/data/collected_outputs',\n",
    "                                                          'output/gen_scripts/']]\n",
    "collected_outputs_path = find_first_extant_path(known_collected_output_paths)\n",
    "assert collected_outputs_path.exists(), f\"collected_outputs_path: {collected_outputs_path} does not exist! Is the right computer's config commented out above?\"\n",
    "# fullwidth_path_widget(scripts_output_path, file_name_label='Scripts Output Path:')\n",
    "print(f'collected_outputs_path: {collected_outputs_path}')\n",
    "# collected_outputs_path.mkdir(exist_ok=True)\n",
    "# assert collected_outputs_path.exists()\n",
    "\n",
    "## Build the output prefix from the session context:\n",
    "active_context = curr_active_pipeline.get_session_context()\n",
    "curr_session_name: str = curr_active_pipeline.session_name # '2006-6-08_14-26-15'\n",
    "CURR_BATCH_OUTPUT_PREFIX: str = f\"{BATCH_DATE_TO_USE}-{curr_session_name}\"\n",
    "print(f'CURR_BATCH_OUTPUT_PREFIX: \"{CURR_BATCH_OUTPUT_PREFIX}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606e8116",
   "metadata": {},
   "source": [
    "## <a id='toc2_5_'></a>[Specific Recomputations](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f010d1a9",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "any_most_recent_computation_time, each_epoch_latest_computation_time, each_epoch_each_result_computation_completion_times, (global_computations_latest_computation_time, global_computation_completion_times) = curr_active_pipeline.get_computation_times(debug_print=False)\n",
    "# each_epoch_latest_computation_time\n",
    "each_epoch_each_result_computation_completion_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3d4f61",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd11d0f",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.clear_all_failed_computations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ff30b7",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computation_config.instantaneous_time_bin_size_seconds = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58db94e",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "force_recompute_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f285cd23",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "force_recompute_global = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47820977",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "extended_computations_include_includelist=['lap_direction_determination', 'pf_computation', 'firing_rate_trends', 'pfdt_computation',\n",
    "    # 'pf_dt_sequential_surprise',\n",
    "    #  'ratemap_peaks_prominence2d',\n",
    "    'extended_stats',\n",
    "    'long_short_decoding_analyses',\n",
    "    'jonathan_firing_rate_analysis',\n",
    "    'long_short_fr_indicies_analyses',\n",
    "    'short_long_pf_overlap_analyses',\n",
    "    'long_short_post_decoding',\n",
    "    # 'long_short_rate_remapping',\n",
    "    'long_short_inst_spike_rate_groups',\n",
    "    'long_short_endcap_analysis',\n",
    "    # 'spike_burst_detection',\n",
    "    'split_to_directional_laps',\n",
    "    'merged_directional_placefields',\n",
    "    # 'rank_order_shuffle_analysis',\n",
    "    # 'directional_decoders_decode_continuous',\n",
    "    # 'directional_decoders_evaluate_epochs',\n",
    "    # 'directional_decoders_epoch_heuristic_scoring',\n",
    "] # do only specified\n",
    "\n",
    "# ['split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous']\n",
    "\n",
    "# force_recompute_override_computations_includelist = [\n",
    "#     'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring',\n",
    "#     'split_to_directional_laps', 'lap_direction_determination', 'DirectionalLaps',\n",
    "#     'merged_directional_placefields',\n",
    "#     'directional_decoders_decode_continuous',\n",
    "# ]\n",
    "force_recompute_override_computations_includelist = None\n",
    "\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "newly_computed_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc0a702",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# extended_computations_include_includelist=['ratemap_peaks_prominence2d', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring',] # do only specified\n",
    "extended_computations_include_includelist=['rank_order_shuffle_analysis', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'ratemap_peaks_prominence2d', ] # do only specified\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db62d145",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "newly_computed_values = curr_active_pipeline.batch_extended_computations(include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = curr_active_pipeline.batch_evaluate_required_computations(include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02779f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27120a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "newly_computed_values = curr_active_pipeline.batch_extended_computations(include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3927a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = curr_active_pipeline.batch_evaluate_required_computations(include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8b307a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d357f9",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# mmm ## lots of m's to break computations\n",
    "\n",
    "## Next wave of computations\n",
    "extended_computations_include_includelist=['directional_decoders_epoch_heuristic_scoring',] # do only specified\n",
    "force_recompute_override_computations_includelist = deepcopy(extended_computations_include_includelist)\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272e20f8",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# 'rank_order_shuffle_analysis',\n",
    "## Next wave of computations\n",
    "extended_computations_include_includelist=['rank_order_shuffle_analysis'] # do only specified\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3efc4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'lap_direction_determination'\n",
    "extended_computations_include_includelist=['_split_to_directional_laps'] # do only specified\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=True)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_split_to_directional_laps'], computation_kwargs_list=None, enabled_filter_names=None, fail_on_exception=True, debug_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d834f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "curr_active_pipeline.get_failed_computations() # 'maze1_odd': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:973<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')}\n",
    "\n",
    "# curr_active_pipeline.rerun_failed_computations()\n",
    "# curr_active_pipeline.stage.rerun_failed_computations()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21411ae4",
   "metadata": {},
   "source": [
    "# Test 'generalized_specific_epochs_decoding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5611e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "force_recompute_override_computations_includelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fd11ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f146043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "force_recompute_global = False\n",
    "## Next wave of computations\n",
    "# extended_computations_include_includelist=['non_PBE_epochs_results', 'generalized_specific_epochs_decoding',] # do only specified\n",
    "extended_computations_include_includelist=['non_PBE_epochs_results'] # do only specified\n",
    "# force_recompute_override_computations_includelist = deepcopy(extended_computations_include_includelist)\n",
    "force_recompute_override_computations_includelist = []\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3832e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import EpochComputationFunctions, EpochComputationsComputationsContainer\n",
    "\n",
    "valid_EpochComputations_result: EpochComputationsComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['EpochComputations']\n",
    "a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult = valid_EpochComputations_result.a_generic_decoder_dict_decoded_epochs_dict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a18790",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_export_parent_output_path = self.collected_outputs_path.resolve()\n",
    "Assert.path_exists(parent_output_path)\n",
    "csv_save_paths_dict = a_new_fully_generic_result.default_export_all_CSVs(active_export_parent_output_path=active_export_parent_output_path, owning_pipeline_reference=curr_active_pipeline, decoding_time_bin_size=0.05)\n",
    "csv_save_paths_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182ac2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_man = curr_active_pipeline.get_output_manager()\n",
    "out_man."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ace824",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_computations_include_includelist=['non_PBE_epochs_results'] # do only specified\n",
    "# force_recompute_override_computations_includelist = deepcopy(extended_computations_include_includelist)\n",
    "force_recompute_override_computations_includelist = []\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7ecbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "force_recompute_global = False\n",
    "## Next wave of computations\n",
    "# extended_computations_include_includelist=['non_PBE_epochs_results', 'generalized_specific_epochs_decoding',] # do only specified\n",
    "extended_computations_include_includelist=['generalized_specific_epochs_decoding'] # do only specified\n",
    "# force_recompute_override_computations_includelist = deepcopy(extended_computations_include_includelist)\n",
    "force_recompute_override_computations_includelist = []\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74119ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Computation import ComputedPipelineStage, PipelineWithComputedPipelineStageMixin\n",
    "\n",
    "curr_active_pipeline.clear_all_failed_computations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d510c66",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# # Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "# newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True,\n",
    "#                                                     force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "\n",
    "\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['rank_order_shuffle_analysis','_add_extended_pf_peak_information',\n",
    " '_build_trial_by_trial_activity_metrics',\n",
    " '_decode_and_evaluate_epochs_using_directional_decoders',\n",
    " '_decode_continuous_using_directional_decoders',\n",
    " '_decoded_epochs_heuristic_scoring',\n",
    " '_split_train_test_laps_data',\n",
    " 'perform_wcorr_shuffle_analysis'], computation_kwargs_list=[{'num_shuffles': 100, 'skip_laps': False, 'minimum_inclusion_fr_Hz':2.0, 'included_qclu_values':[1,2,4,5,6,7]}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "\n",
    "\n",
    "force_recompute_override_computation_kwargs_dict = {'rank_order_shuffle_analysis': {'num_shuffles': 100, 'skip_laps': False, 'minimum_inclusion_fr_Hz':2.0, 'included_qclu_values':[1,2,4,5,6,7]},\n",
    " \n",
    "}\n",
    "\n",
    "force_recompute_override_computations_includelist = list(force_recompute_override_computation_kwargs_dict.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9bb808",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['rank_order_shuffle_analysis'], computation_kwargs_list=[{'num_shuffles': 5, 'skip_laps': False, 'minimum_inclusion_fr_Hz':2.0, 'included_qclu_values':[1,2,4,5,6,7]}], \n",
    "                                                  enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b985437c",
   "metadata": {
    "tags": [
     "run-continuous-decoding"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'],\n",
    "                                                  # computation_kwargs_list=[{'time_bin_size': 0.016, 'should_disable_cache':False}], \n",
    "                                                  computation_kwargs_list=[{'time_bin_size': 0.025, 'should_disable_cache':True}], \n",
    "                                                  # computation_kwargs_list=[{'time_bin_size': 0.058, 'should_disable_cache':False}], \n",
    "                                                  enabled_filter_names=None, fail_on_exception=True, debug_print=True)\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'], computation_kwargs_list=[{'time_bin_size': 0.058}], #computation_kwargs_list=[{'time_bin_size': 0.025}], \n",
    "#                                                   enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5c35cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.accumulated_errors\n",
    "curr_active_pipeline.global_computation_results.computation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99a2f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ac9f88",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# curr_active_pipeline.reload_default_computation_functions()\n",
    "# force_recompute_override_computations_includelist = ['_decode_continuous_using_directional_decoders']\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_decode_continuous_using_directional_decoders'], force_recompute_override_computations_includelist=force_recompute_override_computations_includelist,\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t   enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_decode_continuous_using_directional_decoders'], computation_kwargs_list=[{'time_bin_size': 0.025}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "# curr_active_pipeline.perform_specific_computation(extended_computations_include_includelist=['_decode_continuous_using_directional_decoders'], computation_kwargs_list=[{'time_bin_size': 0.02}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['merged_directional_placefields', 'directional_decoders_decode_continuous'], computation_kwargs_list=[{'laps_decoding_time_bin_size': 0.058}, {'time_bin_size': 0.058, 'should_disable_cache':False}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['merged_directional_placefields'], computation_kwargs_list=[{'laps_decoding_time_bin_size': 0.025}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "\n",
    "# 2024-04-20 - HACK -- FIXME: Invert the 'is_LR_dir' column since it is clearly reversed. No clue why.\n",
    "# fails due to some types thing?\n",
    "# \terr: Length of values (82) does not match length of index (80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd3dca2",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f748deeb",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# minimum ~10ms\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['merged_directional_placefields'], computation_kwargs_list=[{'ripple_decoding_time_bin_size': 0.002, 'laps_decoding_time_bin_size': 0.002}], enabled_filter_names=None, fail_on_exception=True, debug_print=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9ffa88",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# minimum ~10ms\n",
    "\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_evaluate_epochs'], computation_kwargs_list=[{'should_skip_radon_transform': True}], enabled_filter_names=None, fail_on_exception=True, debug_print=True)\n",
    "# ## produces: 'DirectionalDecodersEpochsEvaluations'\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_epoch_heuristic_scoring'], enabled_filter_names=None, fail_on_exception=True, debug_print=False) # OK FOR PICKLE\n",
    "\n",
    "time_bin_size: float = 0.058\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['merged_directional_placefields', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring'],\n",
    "                                                   computation_kwargs_list=[{'ripple_decoding_time_bin_size': time_bin_size, 'laps_decoding_time_bin_size': time_bin_size}, {'time_bin_size': time_bin_size}, {'should_skip_radon_transform': True},\n",
    "                                                                             {'same_thresh_fraction_of_track': 0.05, 'max_ignore_bins': 2, 'use_bin_units_instead_of_realworld': False, 'max_jump_distance_cm': 60.0}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa64687",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_bin_size: float = 0.025\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['merged_directional_placefields', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring'],\n",
    "                                                   computation_kwargs_list=[{'ripple_decoding_time_bin_size': time_bin_size, 'laps_decoding_time_bin_size': time_bin_size}, {'time_bin_size': time_bin_size}, {'should_skip_radon_transform': True},\n",
    "                                                                             {'same_thresh_fraction_of_track': 0.05, 'max_ignore_bins': 2, 'use_bin_units_instead_of_realworld': False, 'max_jump_distance_cm': 60.0}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b6a587",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring'],\n",
    "                                                   computation_kwargs_list=[{'should_skip_radon_transform': True},\n",
    "                                                                             {'same_thresh_fraction_of_track': 0.05, 'max_ignore_bins': 2, 'use_bin_units_instead_of_realworld': False, 'max_jump_distance_cm': 60.0}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e2eddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_global_computation_function_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0479935f",
   "metadata": {
    "tags": [
     "run-heuristic-filter-recompute"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_epoch_heuristic_scoring'],\n",
    "                                                   computation_kwargs_list=[{'same_thresh_fraction_of_track': 0.05, 'max_ignore_bins': 2, 'use_bin_units_instead_of_realworld': False, 'max_jump_distance_cm': 60.0}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92db81b",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# MemoryError: Unable to allocate 9.74 GiB for an array with shape (57, 22940809) and data type float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc02d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.SpecificComputationValidation import SpecificComputationValidator\n",
    "\n",
    "curr_active_pipeline.find_validators_providing_results('DirectionalDecodersEpochsEvaluations') ## answer: '_decode_and_evaluate_epochs_using_directional_decoders' or 'directional_decoders_evaluate_epochs'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f372737e",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['ratemap_peaks_prominence2d'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39417243",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['lap_direction_determination'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb81c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['non_PBE_epochs_results'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89757a66",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.utils.efficient_interval_search import filter_epochs_by_num_active_units\n",
    "\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_perform_long_short_firing_rate_analyses'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2745bd",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['EloyAnalysis'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4130eb2e",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_train_test_split'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72d567e",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['trial_by_trial_metrics'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da92d47",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['perform_wcorr_shuffle_analysis'], computation_kwargs_list=[{'num_shuffles': 350}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52a8eb8",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['merged_directional_placefields', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring'], computation_kwargs_list=[{'laps_decoding_time_bin_size': 0.025}, {'time_bin_size': 0.025}, {'should_skip_radon_transform': True}, {}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4dec23",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['merged_directional_placefields', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs',], computation_kwargs_list=[{'laps_decoding_time_bin_size': 0.002}, {'time_bin_size': 0.002}, {'should_skip_radon_transform': True},], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d012effc",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "['split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62493eb3",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=[\n",
    "    'merged_directional_placefields', \n",
    "    'long_short_decoding_analyses', #'pipeline_complete_compute_long_short_fr_indicies',\n",
    "    'jonathan_firing_rate_analysis',\n",
    "    'long_short_fr_indicies_analyses',\n",
    "    'short_long_pf_overlap_analyses',\n",
    "    'long_short_post_decoding',\n",
    "    'long_short_rate_remapping',\n",
    "    'long_short_inst_spike_rate_groups',\n",
    "    'long_short_endcap_analysis',\n",
    "    ], enabled_filter_names=None, fail_on_exception=False, debug_print=False) # , computation_kwargs_list=[{'should_skip_radon_transform': False}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ca34a0",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=[\n",
    "    # 'long_short_decoding_analyses', #'pipeline_complete_compute_long_short_fr_indicies',\n",
    "    'jonathan_firing_rate_analysis',\n",
    "    # 'long_short_fr_indicies_analyses',\n",
    "    'short_long_pf_overlap_analyses',\n",
    "    'long_short_post_decoding',\n",
    "    'long_short_inst_spike_rate_groups',\n",
    "    'long_short_endcap_analysis',\n",
    "    ], enabled_filter_names=None, fail_on_exception=False, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99749819",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "if 'TrainTestSplit' in curr_active_pipeline.global_computation_results.computed_data:\n",
    "    directional_train_test_split_result: TrainTestSplitResult = curr_active_pipeline.global_computation_results.computed_data.get('TrainTestSplit', None)\n",
    "    training_data_portion: float = directional_train_test_split_result.training_data_portion\n",
    "    test_data_portion: float = directional_train_test_split_result.test_data_portion\n",
    "    test_epochs_dict: Dict[str, pd.DataFrame] = directional_train_test_split_result.test_epochs_dict\n",
    "    train_epochs_dict: Dict[str, pd.DataFrame] = directional_train_test_split_result.train_epochs_dict\n",
    "    train_lap_specific_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_train_test_split_result.train_lap_specific_pf1D_Decoder_dict\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed38171",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData\n",
    "\n",
    "# directional_decoders_epochs_decode_result\n",
    "# save_path = Path(\"/Users/pho/data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-04-25_CustomDecodingResults.pkl\").resolve()\n",
    "# save_path = curr_active_pipeline.get_output_path().joinpath(\"2024-04-28_CustomDecodingResults.pkl\").resolve()\n",
    "save_path = curr_active_pipeline.get_output_path().joinpath(f\"{DAY_DATE_TO_USE}_CustomDecodingResults.pkl\").resolve()\n",
    "\n",
    "xbin = deepcopy(long_pf2D.xbin)\n",
    "xbin_centers = deepcopy(long_pf2D.xbin_centers)\n",
    "ybin = deepcopy(long_pf2D.ybin)\n",
    "ybin_centers = deepcopy(long_pf2D.ybin_centers)\n",
    "\n",
    "print(xbin_centers)\n",
    "save_dict = {\n",
    "'directional_decoders_epochs_decode_result': directional_decoders_epochs_decode_result.__getstate__(),\n",
    "'xbin': xbin, 'xbin_centers': xbin_centers}\n",
    "\n",
    "saveData(save_path, save_dict)\n",
    "print(f'save_path: {save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464b4531",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# 💾 Export CSVs: \n",
    "## INPUTS: directional_decoders_epochs_decode_result,\n",
    "\n",
    "extracted_merged_scores_df = directional_decoders_epochs_decode_result.build_complete_all_scores_merged_df()\n",
    "# extracted_merged_scores_df\n",
    "\n",
    "print(f'\\tAll scores df CSV exporting...')\n",
    "\n",
    "## Export CSVs:\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "export_df_dict = {'ripple_all_scores_merged_df': extracted_merged_scores_df}\n",
    "_csv_export_paths = directional_decoders_epochs_decode_result.perform_export_dfs_dict_to_csvs(extracted_dfs_dict=export_df_dict, parent_output_path=collected_outputs_path.resolve(), active_context=active_context, session_name=curr_session_name, curr_session_t_delta=t_delta,\n",
    "                                                                            #   user_annotation_selections={'ripple': any_good_selected_epoch_times},\n",
    "                                                                            #   valid_epochs_selections={'ripple': filtered_valid_epoch_times},\n",
    "                                                                            )\n",
    "\n",
    "print(f'\\t\\tsuccessfully exported ripple_all_scores_merged_df to {collected_outputs_path}!')\n",
    "_output_csv_paths_info_str: str = '\\n'.join([f'{a_name}: \"{file_uri_from_path(a_path)}\"' for a_name, a_path in _csv_export_paths.items()])\n",
    "print(f'\\t\\t\\tCSV Paths: {_output_csv_paths_info_str}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ac96c6",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "t_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a860a1",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "decoder_ripple_radon_transform_df_dict\n",
    "decoder_ripple_radon_transform_extras_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cbf34d",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "decoder_ripple_radon_transform_df_dict\n",
    "decoder_ripple_radon_transform_extras_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbcbb0c",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# filtered_laps_simple_pf_pearson_merged_df\n",
    "# filtered_ripple_simple_pf_pearson_merged_df\n",
    "# decoder_ripple_weighted_corr_df_dict\n",
    "ripple_weighted_corr_merged_df['ripple_start_t']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a95450",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "wcorr_column_names = ['wcorr_long_LR', 'wcorr_long_RL', 'wcorr_short_LR', 'wcorr_short_RL']\n",
    "filtered_ripple_simple_pf_pearson_merged_df.label = filtered_ripple_simple_pf_pearson_merged_df.label.astype('int64')\n",
    "ripple_weighted_corr_merged_df['label'] = ripple_weighted_corr_merged_df['ripple_idx'].astype('int64')\n",
    "\n",
    "filtered_ripple_simple_pf_pearson_merged_df.join(ripple_weighted_corr_merged_df[wcorr_column_names], on='start') # , on='label'\n",
    "# filtered_ripple_simple_pf_pearson_merged_df.merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4bc77f",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "ripple_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac433aac",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "print(list(ripple_weighted_corr_merged_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98e2381",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "a_decoded_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "a_decoded_filter_epochs_decoder_result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3599f8",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# paginated_multi_decoder_decoded_epochs_window.save_selections()\n",
    "\n",
    "a_decoded_filter_epochs_decoder_result_dict.epochs.find_data_indicies_from_epoch_times([380.75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899ee133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_general_decoder_dict_decoded_epochs_dict_result: GeneralDecoderDictDecodedEpochsDictResult = serialized_field(default=None, is_computable=True, repr=False, metadata={'field_added': '2025.03.09_0'})\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import GeneralDecoderDictDecodedEpochsDictResult, EpochComputationsComputationsContainer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3438b16",
   "metadata": {},
   "source": [
    "## <a id='toc2_6_'></a>[💾 Continue Saving/Exporting stuff](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce2cb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_global_computation_results() # newly_computed_values: [('pfdt_computation', 'maze_any')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57544dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_save_folder, split_save_paths, split_save_output_types, failed_keys = curr_active_pipeline.save_split_global_computation_results(debug_print=True,\n",
    "                                                                                                                                    #    include_includelist=['long_short_inst_spike_rate_groups'],\n",
    "                                                                                                                                       ) # encountered issue with pickling `long_short_post_decoding`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94911277",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.export_pipeline_to_h5() # NotImplementedError: a_field_attr: Attribute(name='LxC_aclus', default=None, validator=None, repr=True, eq=True, eq_key=None, order=True, order_key=None, hash=None, init=False, metadata=mappingproxy({'tags': ['dataset'], 'serialization': {'hdf': True}, 'custom_serialization_fn': None, 'hdf_metadata': {'track_eXclusive_cells': 'LxC'}}), type=<class 'numpy.ndarray'>, converter=None, kw_only=False, inherited=False, on_setattr=None, alias='LxC_aclus') could not be serialized and _ALLOW_GLOBAL_NESTED_EXPANSION is not allowed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78feaef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_drop_computed_result(computed_data_keys_to_drop=['SequenceBased'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c6fb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.clear_display_outputs()\n",
    "curr_active_pipeline.clear_registered_output_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b937bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import neuropy.core.session.dataSession as ds\n",
    "reload(ds)\n",
    "\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder, find_local_session_paths, DataSessionFormatBaseRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f232acb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE) ## #TODO 2024-02-16 14:25: - [ ] PicklingError: Can't pickle <function make_set_closure_cell.<locals>.set_closure_cell at 0x7fd35e66b700>: it's not found as attr._compat.make_set_closure_cell.<locals>.set_closure_cell\n",
    "# curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.OVERWRITE_IN_PLACE)\n",
    "# TypeError: cannot pickle 'traceback' object\n",
    "# Exception: Can't pickle <enum 'PipelineSavingScheme'>: it's not the same object as pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline.PipelineSavingScheme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7aac4f",
   "metadata": {},
   "source": [
    "## 💾 <a id='toc2_8_'></a>[Custom Save-Pipeleine As](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62302c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get from pipeline's parameters\n",
    "custom_save_filepaths, custom_save_filenames, custom_suffix = curr_active_pipeline.get_custom_pipeline_filenames_from_parameters()\n",
    "pickle_path = custom_save_filenames['pipeline_pkl']\n",
    "global_computation_pkl = custom_save_filenames['global_computation_pkl']\n",
    "\n",
    "# pickle_path = 'loadedSessPickle_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0_2025-01-20.pkl'\n",
    "# global_computation_pkl = 'global_computation_results_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0_2025-01-20.pkl'\n",
    "\n",
    "# pickle_path = 'loadedSessPickle_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0_2025-01-20.pkl'\n",
    "# global_computation_pkl = 'global_computation_results_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0_2025-01-20.pkl'\n",
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE, active_pickle_filename=pickle_path)\n",
    "curr_active_pipeline.save_global_computation_results(override_global_pickle_filename=global_computation_pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286756d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_session_pickle_file_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88078363",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_session_pickle_file_widget.active_local_pkl\n",
    "active_session_pickle_file_widget.active_global_pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a5c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.get_complete_session_context()\n",
    "custom_save_filepaths, custom_save_filenames, custom_suffix = curr_active_pipeline.get_custom_pipeline_filenames_from_parameters()\n",
    "custom_save_filepaths\n",
    "custom_save_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057d6831",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_custom_modified_filenames, did_save_success = curr_active_pipeline.try_save_pipeline_with_custom_user_modifiers(user_prefix='', user_suffix='2025-02-19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa97ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "did_save_success: bool = _try_user_custom_save_pipeline(curr_active_pipeline=curr_active_pipeline, user_custom_modified_filenames=user_custom_modified_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3242e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.pickle_path\n",
    "curr_active_pipeline.global_computation_results_pickle_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1147ec40",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_save_filenames['pipeline_pkl']\n",
    "custom_save_filenames['global_computation_pkl']\n",
    "\n",
    "pickle_path = 'loadedSessPickle_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0_2025-01-20.pkl'\n",
    "global_computation_pkl = 'global_computation_results_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0_2025-01-20.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123d9ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## indicate that it was loaded with a custom suffix\n",
    "curr_active_pipeline.pickle_path ## correct\n",
    "curr_active_pipeline.global_computation_results_pickle_path ## correct\n",
    "\n",
    "# curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE, override_pickle_path=curr_active_pipeline.pickle_path, active_pickle_filename=curr_active_pipeline.pickle_path.name) #active_pickle_filename=\n",
    "# curr_active_pipeline.save_global_computation_results(override_global_pickle_path=curr_active_pipeline.global_computation_results_pickle_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df1bdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE, override_pickle_path=curr_active_pipeline.pickle_path, active_pickle_filename='loadedSessPickle_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0_2025-01-20.pkl') #active_pickle_filename=\n",
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE, active_pickle_filename='loadedSessPickle_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0_FIXED_GRID_BIN_BOUNDS.pkl') #active_pickle_filename="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638c5ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE, active_pickle_filename='loadedSessPickle_withNormalComputedReplays-qclu_[1, 2]-frateThresh_5.0-FIXED_GRID_BIN_BOUNDS.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832773ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_global_computation_results(override_global_pickle_filename='global_computation_results_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0_FIXED_GRID_BIN_BOUNDS.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11015340",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE, active_pickle_filename='loadedSessPickle.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd8063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_global_computation_results(override_global_pickle_filename='global_computation_results.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944eedd6",
   "metadata": {},
   "source": [
    "#### <a id='toc2_8_1_1_'></a>[Get computation times/info:](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31cab8e",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "any_most_recent_computation_time, each_epoch_latest_computation_time, each_epoch_each_result_computation_completion_times, (global_computations_latest_computation_time, global_computation_completion_times) = curr_active_pipeline.get_computation_times(debug_print=False)\n",
    "# each_epoch_latest_computation_time\n",
    "# each_epoch_each_result_computation_completion_times\n",
    "# global_computation_completion_times\n",
    "\n",
    "# curr_active_pipeline.get_merged_computation_function_validators()\n",
    "# Get the names of the global and non-global computations:\n",
    "all_validators_dict = curr_active_pipeline.get_merged_computation_function_validators()\n",
    "global_only_validators_dict = {k:v for k, v in all_validators_dict.items() if v.is_global}\n",
    "non_global_only_validators_dict = {k:v for k, v in all_validators_dict.items() if (not v.is_global)}\n",
    "non_global_comp_names: List[str] = [v.short_name for k, v in non_global_only_validators_dict.items() if (not v.short_name.startswith('_DEP'))] # ['firing_rate_trends', 'spike_burst_detection', 'pf_dt_sequential_surprise', 'extended_stats', 'placefield_overlap', 'ratemap_peaks_prominence2d', 'velocity_vs_pf_simplified_count_density', 'EloyAnalysis', '_perform_specific_epochs_decoding', 'recursive_latent_pf_decoding', 'position_decoding_two_step', 'position_decoding', 'lap_direction_determination', 'pfdt_computation', 'pf_computation']\n",
    "global_comp_names: List[str] = [v.short_name for k, v in global_only_validators_dict.items() if (not v.short_name.startswith('_DEP'))] # ['long_short_endcap_analysis', 'long_short_inst_spike_rate_groups', 'long_short_post_decoding', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_decoding_analyses', 'PBE_stats', 'rank_order_shuffle_analysis', 'directional_decoders_epoch_heuristic_scoring', 'directional_decoders_evaluate_epochs', 'directional_decoders_decode_continuous', 'merged_directional_placefields', 'split_to_directional_laps']\n",
    "\n",
    "# mappings between the long computation function names and their short names:\n",
    "non_global_comp_names_map: Dict[str, str] = {v.computation_fn_name:v.short_name for k, v in non_global_only_validators_dict.items() if (not v.short_name.startswith('_DEP'))}\n",
    "global_comp_names_map: Dict[str, str] = {v.computation_fn_name:v.short_name for k, v in global_only_validators_dict.items() if (not v.short_name.startswith('_DEP'))} # '_perform_long_short_endcap_analysis': 'long_short_endcap_analysis', '_perform_long_short_instantaneous_spike_rate_groups_analysis': 'long_short_inst_spike_rate_groups', ...}\n",
    "\n",
    "# convert long function names to short-names:\n",
    "each_epoch_each_result_computation_completion_times = {an_epoch:{non_global_comp_names_map.get(k, k):v for k,v in a_results_dict.items()} for an_epoch, a_results_dict in each_epoch_each_result_computation_completion_times.items()}\n",
    "global_computation_completion_times = {global_comp_names_map.get(k, k):v for k,v in global_computation_completion_times.items()}\n",
    "\n",
    "each_epoch_each_result_computation_completion_times\n",
    "global_computation_completion_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81933aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "required_num_computation_rows: int = np.max([len(a_results_dict) for an_epoch, a_results_dict in each_epoch_each_result_computation_completion_times.items()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9852ae69",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[non_global_comp_names_map.get(k, k) for k,v in a_results_dict.items()] for an_epoch, a_results_dict in each_epoch_each_result_computation_completion_times.items()]\n",
    "\n",
    "# unique_comp_names_set = set([])\n",
    "unique_comp_names_list = []\n",
    "for an_epoch, a_results_dict in each_epoch_each_result_computation_completion_times.items():\n",
    "    for k,v in a_results_dict.items():\n",
    "        curr_comp_name: str = non_global_comp_names_map.get(k, k)\n",
    "        # unique_comp_names_set.add(curr_comp_name)\n",
    "        if curr_comp_name not in unique_comp_names_list:\n",
    "            unique_comp_names_list.append(curr_comp_name) ## preserving order\n",
    "        \n",
    "unique_comp_names_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da11a611",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_global_comp_names\n",
    "each_epoch_each_result_computation_completion_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d40193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use `curr_active_pipeline.filtered_epochs`\n",
    "filtered_epoch_column_names = deepcopy(list(curr_active_pipeline.filtered_epochs.keys()))\n",
    "num_filtered_epoch_columns: int = len(filtered_epoch_column_names)\n",
    "\n",
    "\n",
    "filtered_epoch_column_names\n",
    "num_filtered_epoch_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a769d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.PipelineComputationWidget.PipelineComputationWidget import PipelineComputationWidget\n",
    "\n",
    "win = PipelineComputationWidget(owning_pipeline=curr_active_pipeline)\n",
    "win.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144700b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.Extensions.pyqtgraph_helpers import TableSizingHelpers\n",
    "\n",
    "table_view = win.ui.tbl_EpochLocalResults\n",
    "total_height: float = TableSizingHelpers.determine_required_table_height(table_view)\n",
    "print(f'total_height: {total_height}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96580849",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_view.setMinimumHeight(total_height)  # Set the required height\n",
    "table_view.setMaximumHeight(total_height)  # Prevent scrolling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee4b1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_width: float = TableSizingHelpers.determine_required_table_width(table_view)\n",
    "print(f'total_width: {total_width}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967369f1",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_evaluate_required_computations\n",
    "\n",
    "# force_recompute_global = force_reload\n",
    "force_recompute_global = True\n",
    "# force_recompute_global = False\n",
    "active_probe_includelist = extended_computations_include_includelist\n",
    "# active_probe_includelist = ['lap_direction_determination']\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=active_probe_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "needs_computation_output_dict\n",
    "# valid_computed_results_output_list\n",
    "# remaining_include_function_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9aeeda",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "['merged_directional_placefields', ]\n",
    "\n",
    "['long_short_decoding_analyses', 'long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'extended_stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85822a88",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "replay_estimation_parameters = curr_active_pipeline.sess.config.preprocessing_parameters.epoch_estimation_parameters.replays\n",
    "assert replay_estimation_parameters is not None\n",
    "replay_estimation_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3799ab99",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "recompute_earlier_than_date = datetime(2024, 4, 1, 0, 0, 0)\n",
    "recompute_earlier_than_date\n",
    "\n",
    "each_epoch_needing_recompute = [an_epoch for an_epoch, last_computed_datetime in each_epoch_latest_computation_time.items() if (last_computed_datetime < recompute_earlier_than_date)]\n",
    "each_epoch_needing_recompute\n",
    "each_epoch_each_result_needing_recompute = {an_epoch:{a_computation_name:last_computed_datetime for a_computation_name, last_computed_datetime in last_computed_datetimes_dict.items() if (last_computed_datetime < recompute_earlier_than_date)} for an_epoch, last_computed_datetimes_dict in each_epoch_each_result_computation_completion_times.items()}\n",
    "each_epoch_each_result_needing_recompute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2792e869",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computation_times\n",
    "curr_active_pipeline.global_computation_results\n",
    "# curr_active_pipeline.try_load_split_pickled_global_computation_results\n",
    "\n",
    "global_computation_times = deepcopy(curr_active_pipeline.global_computation_results.computation_times.to_dict()) # DynamicParameters({'perform_rank_order_shuffle_analysis': datetime.datetime(2024, 4, 3, 5, 41, 31, 287680), '_decode_continuous_using_directional_decoders': datetime.datetime(2024, 4, 3, 5, 12, 7, 337326), '_perform_long_short_decoding_analyses': datetime.datetime(2024, 4, 3, 5, 43, 10, 361685), '_perform_long_short_pf_overlap_analyses': datetime.datetime(2024, 4, 3, 5, 43, 10, 489296), '_perform_long_short_firing_rate_analyses': datetime.datetime(2024, 4, 3, 5, 45, 3, 73472), '_perform_jonathan_replay_firing_rate_analyses': datetime.datetime(2024, 4, 3, 5, 45, 5, 168790), '_perform_long_short_post_decoding_analysis': datetime.datetime(2024, 2, 16, 18, 13, 4, 734621), '_perform_long_short_endcap_analysis': datetime.datetime(2024, 4, 3, 5, 45, 24, 274261), '_decode_and_evaluate_epochs_using_directional_decoders': datetime.datetime(2024, 4, 3, 5, 14, 37, 935482), '_perform_long_short_instantaneous_spike_rate_groups_analysis': datetime.datetime(2024, 4, 3, 5, 45, 24, 131955), '_split_to_directional_laps': datetime.datetime(2024, 4, 3, 5, 11, 22, 627789), '_build_merged_directional_placefields': datetime.datetime(2024, 4, 3, 5, 11, 28, 376078)})\n",
    "global_computation_times\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f8c99f",
   "metadata": {},
   "source": [
    "### <a id='toc2_8_2_'></a>[Custom Split Result Outputs](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce82b33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.print_helpers import print_object_memory_usage, print_filesystem_file_size\n",
    "\n",
    "print('test')\n",
    "curr_active_pipeline.global_computation_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac259988",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_object_memory_usage(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5e99c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.active_configs\n",
    "# Define default print format function if no custom one is provided:\n",
    "# see DocumentationFilePrinter._plain_text_format_curr_value and DocumentationFilePrinter._rich_text_format_curr_value for examples\n",
    "# custom_item_formatter = DocumentationFilePrinter._default_plain_text_formatter\n",
    "## Plaintext:\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "# custom_value_formatting_fn = partial(DocumentationFilePrinter.string_rep_if_short_enough, max_length=280, max_num_lines=1)\n",
    "custom_value_formatting_fn = partial(DocumentationFilePrinter.value_memory_usage_MB)\n",
    "custom_item_formatter = partial(DocumentationFilePrinter._default_plain_text_formatter, value_formatting_fn=custom_value_formatting_fn)\n",
    "\n",
    "# ## Rich:\n",
    "# custom_value_formatting_fn = partial(DocumentationFilePrinter.string_rep_if_short_enough, max_length=280, max_num_lines=1)\n",
    "# custom_item_formatter = partial(DocumentationFilePrinter._default_rich_text_formatter, value_formatting_fn=custom_value_formatting_fn)\n",
    "\n",
    "\n",
    "# print_keys_if_possible('curr_active_pipeline', curr_active_pipeline, max_depth=1, custom_item_formatter=custom_item_formatter)\n",
    "\n",
    "# curr_active_pipeline._stage: pyphoplacecellanalysis.General.Pipeline.Stages.Display.DisplayPipelineStage 6483.868 MB\n",
    "# \t│   ├── stage_name: str 0.000 MB\n",
    "# \t│   ├── basedir: pathlib.WindowsPath 0.001 MB\n",
    "# \t│   ├── load_function: NoneType\n",
    "# \t│   ├── post_load_functions: list 0.000 MB - (0,)\n",
    "# \t│   ├── loaded_data: dict 189.974 MB\n",
    "# \t│   ├── registered_load_function_dict: dict (children omitted)(all scalar values) - size: 0\n",
    "# \t│   ├── filtered_sessions: dict 1641.733 MB\n",
    "# \t│   ├── filtered_epochs: dict 0.004 MB\n",
    "# \t│   ├── filtered_contexts: pyphocorehelpers.DataStructure.dynamic_parameters.DynamicParameters 0.005 MB\n",
    "# \t│   ├── active_configs: dict 1.040 MB\n",
    "# \t│   ├── computation_results: dict 3791.355 MB\n",
    "# \t│   ├── global_computation_results: pyphoplacecellanalysis.General.Model.ComputationResults.ComputationResult 2691.828 MB\n",
    "# \t│   ├── registered_computation_function_dict: collections.OrderedDict 0.003 MB\n",
    "# \t│   ├── registered_global_computation_function_dict: collections.OrderedDict 0.003 MB\n",
    "\n",
    "\n",
    "## Document `curr_active_pipeline`\n",
    "doc_printer = DocumentationFilePrinter(doc_output_parent_folder=doc_output_parent_folder, doc_name='curr_active_pipeline')\n",
    "# doc_printer.save_documentation('curr_active_pipeline', curr_active_pipeline, non_expanded_item_keys=['_reverse_cellID_index_map'], max_depth=2, custom_rich_text_formatter=custom_item_formatter)\n",
    "doc_printer.save_documentation('curr_active_pipeline', curr_active_pipeline, non_expanded_item_keys=['_reverse_cellID_index_map'], max_depth=2, custom_plain_text_formatter=custom_item_formatter)\n",
    "\n",
    "# print_keys_if_possible('curr_active_pipeline._stage', curr_active_pipeline._stage, max_depth=2, custom_item_formatter=custom_item_formatter)\n",
    "\n",
    "# curr_active_pipeline.filtered_sessions\n",
    "\n",
    "# curr_active_pipeline.computation_results # 3791.355 MB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cf1236",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_printer.display_widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b5c928",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "from dill.detect import trace\n",
    "\n",
    "# Trace all variables in the current workspace\n",
    "trace(locals())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06acb3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_vars = {k: v for k, v in locals().items() if not k.startswith(\"__\")}\n",
    "trace(workspace_vars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5769b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import perform_split_save_dictlike_result\n",
    "\n",
    "split_folder = curr_active_pipeline.get_output_path().joinpath('split')\n",
    "split_folder.mkdir(exist_ok=True)\n",
    "\n",
    "['loaded_data', '']\n",
    "\n",
    "# active_computed_data = self.global_computation_results.computed_data\n",
    "# include_includelist = list(self.global_computation_results.computed_data.keys())\n",
    "# split_save_folder_name: str = f'{global_computation_results_pickle_path.stem}_split'\n",
    "# split_save_folder: Path = global_computation_results_pickle_path.parent.joinpath(split_save_folder_name).resolve()\n",
    "\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# 'computation_results' (local computations)                                                                           #\n",
    "# ==================================================================================================================== #\n",
    "# split_computation_results_dir = split_folder.joinpath('computation_results')\n",
    "# split_computation_results_dir.mkdir(exist_ok=True)\n",
    "# split_save_folder, split_save_paths, split_save_output_types, failed_keys = perform_split_save_dictlike_result(split_save_folder=split_computation_results_dir, active_computed_data=curr_active_pipeline.computation_results)\n",
    "\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# 'filtered_sessions'                                                                                                  #\n",
    "# ==================================================================================================================== #\n",
    "# split_filtered_sessions_dir = split_folder.joinpath('filtered_sessions')\n",
    "# split_filtered_sessions_dir.mkdir(exist_ok=True)\n",
    "# split_save_folder, split_save_paths, split_save_output_types, failed_keys = perform_split_save_dictlike_result(split_save_folder=split_filtered_sessions_dir, active_computed_data=curr_active_pipeline.filtered_sessions)\n",
    "\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# 'global_computation_results' (global computations)                                                                   #\n",
    "# ==================================================================================================================== #\n",
    "split_global_computation_results_dir = split_folder.joinpath('global_computation_results')\n",
    "split_global_computation_results_dir.mkdir(exist_ok=True)\n",
    "split_save_folder, split_save_paths, split_save_output_types, failed_keys = perform_split_save_dictlike_result(split_save_folder=split_global_computation_results_dir, active_computed_data=curr_active_pipeline.global_computation_results.computed_data) # .__dict__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcaf776",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benedict import benedict\n",
    "# curr_active_pipeline.computation_results ## a regular dict, convert to benedict\n",
    "# curr_active_pipeline.computation_results\n",
    "\n",
    "computation_results = benedict(curr_active_pipeline.computation_results)\n",
    "computation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3dc28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_result = computation_results['maze_any'] # ComputationResult\n",
    "# global_computation_results_split\n",
    "a_result_dict = a_result.to_dict()\n",
    "a_result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e982eb",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[0️⃣ Pho Interactive Pipeline Jupyter Widget](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce08192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import interactive_pipeline_widget, interactive_pipeline_files\n",
    "\n",
    "_pipeline_jupyter_widget = interactive_pipeline_widget(curr_active_pipeline=curr_active_pipeline)\n",
    "# display(_pipeline_jupyter_widget)\n",
    "_pipeline_jupyter_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474f4c95",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[1️⃣ End Run](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a533ba8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T23:21:40.700275900Z",
     "start_time": "2023-11-16T23:21:40.584273Z"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all",
     "2025-04-11 - full-session marginals"
    ]
   },
   "outputs": [],
   "source": [
    "# (long_one_step_decoder_1D, short_one_step_decoder_1D), (long_one_step_decoder_2D, short_one_step_decoder_2D) = compute_short_long_constrained_decoders(curr_active_pipeline, recalculate_anyway=True)\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_epoch_context, short_epoch_context, global_epoch_context = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_epoch_name, short_epoch_name, global_epoch_name)]\n",
    "long_epoch_obj, short_epoch_obj = [Epoch(curr_active_pipeline.sess.epochs.to_dataframe().epochs.label_slice(an_epoch_name.removesuffix('_any'))) for an_epoch_name in [long_epoch_name, short_epoch_name]] #TODO 2023-11-10 20:41: - [ ] Issue with getting actual Epochs from sess.epochs for directional laps: emerges because long_epoch_name: 'maze1_any' and the actual epoch label in curr_active_pipeline.sess.epochs is 'maze1' without the '_any' part.\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_computation_config, short_computation_config, global_computation_config = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "long_pf2D, short_pf2D, global_pf2D = long_results.pf2D, short_results.pf2D, global_results.pf2D\n",
    "\n",
    "assert short_epoch_obj.n_epochs > 0, f'long_epoch_obj: {long_epoch_obj}, short_epoch_obj: {short_epoch_obj}'\n",
    "assert long_epoch_obj.n_epochs > 0, f'long_epoch_obj: {long_epoch_obj}, short_epoch_obj: {short_epoch_obj}'\n",
    "\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "t_start, t_delta, t_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e348e0c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all",
     "2025-04-11 - full-session marginals"
    ]
   },
   "outputs": [],
   "source": [
    "# directional_merged_decoders_result = deepcopy(directional_decoders_epochs_decode_result)\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "\n",
    "spikes_df = deepcopy(curr_active_pipeline.sess.spikes_df)\n",
    "spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528460fb",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "2025-04-11 - full-session marginals"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "global_computation_results = curr_active_pipeline.global_computation_results\n",
    "\n",
    "rank_order_results = curr_active_pipeline.global_computation_results.computed_data.get('RankOrder', None) # : \"RankOrderComputationsContainer\"\n",
    "if rank_order_results is not None:\n",
    "    minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "else:        \n",
    "    ## get from parameters:\n",
    "    minimum_inclusion_fr_Hz: float = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.included_qclu_values\n",
    "\n",
    "\n",
    "directional_laps_results: DirectionalLapsResult = global_computation_results.computed_data['DirectionalLaps']\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\n",
    "# print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "# print(f'included_qclu_values: {included_qclu_values}')\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "ripple_decoding_time_bin_size: float = directional_merged_decoders_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_merged_decoders_result.laps_decoding_time_bin_size\n",
    "# pos_bin_size = _recover_position_bin_size(track_templates.get_decoders()[0]) # 3.793023081021702\n",
    "# print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}, ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}, pos_bin_size: {pos_bin_size}')\n",
    "# pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "\n",
    "## Simple Pearson Correlation\n",
    "assert spikes_df is not None\n",
    "(laps_simple_pf_pearson_merged_df, ripple_simple_pf_pearson_merged_df), corr_column_names = directional_merged_decoders_result.compute_simple_spike_time_v_pf_peak_x_by_epoch(track_templates=track_templates, spikes_df=deepcopy(spikes_df))\n",
    "## OUTPUTS: (laps_simple_pf_pearson_merged_df, ripple_simple_pf_pearson_merged_df), corr_column_names\n",
    "## Computes the highest-valued decoder for this score:\n",
    "try:\n",
    "    best_decoder_index_col_name: str = 'best_decoder_index'\n",
    "    laps_simple_pf_pearson_merged_df[best_decoder_index_col_name] = laps_simple_pf_pearson_merged_df[corr_column_names].abs().apply(lambda row: np.argmax(row.values), axis=1)\n",
    "    ripple_simple_pf_pearson_merged_df[best_decoder_index_col_name] = ripple_simple_pf_pearson_merged_df[corr_column_names].abs().apply(lambda row: np.argmax(row.values), axis=1)\n",
    "except KeyError as e:\n",
    "    pass # KeyError: \"None of [Index(['long_LR_pf_peak_x_pearsonr', 'long_RL_pf_peak_x_pearsonr', 'short_LR_pf_peak_x_pearsonr', 'short_RL_pf_peak_x_pearsonr'], dtype='object')] are in the [columns]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed4d1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_directional_pf1D_Decoder = directional_merged_decoders_result.all_directional_pf1D_Decoder\n",
    "pf1D = all_directional_pf1D_Decoder.pf\n",
    "# all_directional_pf1D_Decoder\n",
    "pf1D\n",
    "# all_directional_pf1D_Decoder.pf.plot_occupancy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1dc2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sort from left to right by peak location, and bottom-to-top by context\n",
    "# pf1D.peak_indicies\n",
    "# pf1D.peak_tuning_curve_center_of_mass_bin_coordinates\n",
    "\n",
    "# pf1D.get_tuning_curve_peak_df\n",
    "# pf1D.tuning_curves_dict\n",
    "# pf1D.tuning_curves\n",
    "\n",
    "pf1D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eed3e0c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all",
     "2025-04-11 - full-session marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult, SingleEpochDecodedResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)\n",
    "\n",
    "pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict\n",
    "decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict\n",
    "\n",
    "print(f'pos_bin_size: {pos_bin_size}')\n",
    "print(f'ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}')\n",
    "print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}')\n",
    "\n",
    "# Radon Transforms:\n",
    "decoder_laps_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_df_dict\n",
    "decoder_ripple_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_df_dict\n",
    "decoder_laps_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_extras_dict\n",
    "decoder_ripple_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_extras_dict\n",
    "\n",
    "# Weighted correlations:\n",
    "laps_weighted_corr_merged_df: pd.DataFrame = directional_decoders_epochs_decode_result.laps_weighted_corr_merged_df\n",
    "ripple_weighted_corr_merged_df: pd.DataFrame = directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "decoder_laps_weighted_corr_df_dict: Dict[str, pd.DataFrame] = directional_decoders_epochs_decode_result.decoder_laps_weighted_corr_df_dict\n",
    "decoder_ripple_weighted_corr_df_dict: Dict[str, pd.DataFrame] = directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict\n",
    "\n",
    "# Pearson's correlations:\n",
    "laps_simple_pf_pearson_merged_df: pd.DataFrame = directional_decoders_epochs_decode_result.laps_simple_pf_pearson_merged_df\n",
    "ripple_simple_pf_pearson_merged_df: pd.DataFrame = directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df\n",
    "\n",
    "# laps_simple_pf_pearson_merged_df\n",
    "# ripple_simple_pf_pearson_merged_df\n",
    "\n",
    "# ## Drop rows where all are missing\n",
    "# corr_column_names = ['long_LR_pf_peak_x_pearsonr', 'long_RL_pf_peak_x_pearsonr', 'short_LR_pf_peak_x_pearsonr', 'short_RL_pf_peak_x_pearsonr']\n",
    "# # ripple_simple_pf_pearson_merged_df.dropna(subset=corr_column_names, axis='index', how='all') # 350/412 rows\n",
    "# filtered_laps_simple_pf_pearson_merged_df: pd.DataFrame = laps_simple_pf_pearson_merged_df.dropna(subset=corr_column_names, axis='index', how='any') # 320/412 rows\n",
    "# filtered_ripple_simple_pf_pearson_merged_df: pd.DataFrame = ripple_simple_pf_pearson_merged_df.dropna(subset=corr_column_names, axis='index', how='any') # 320/412 rows\n",
    "\n",
    "## Update the `decoder_ripple_filter_epochs_decoder_result_dict` with the included epochs:\n",
    "# decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_ripple_filter_epochs_decoder_result_dict[a_name].filtered_by_epochs(filtered_ripple_simple_pf_pearson_merged_df.index) for a_name, a_df in decoder_ripple_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_laps_filter_epochs_decoder_result_dict[a_name].filtered_by_epochs(filtered_laps_simple_pf_pearson_merged_df.index) for a_name, a_df in decoder_laps_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_ripple_filter_epochs_decoder_result_dict[a_name].filtered_by_epoch_times(filtered_ripple_simple_pf_pearson_merged_df[['start', 'stop']].to_numpy()) for a_name, a_df in decoder_ripple_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_laps_filter_epochs_decoder_result_dict[a_name].filtered_by_epoch_times(filtered_laps_simple_pf_pearson_merged_df[['start', 'stop']].to_numpy()) for a_name, a_df in decoder_laps_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_ripple_filter_epochs_decoder_result_dict[a_name].filtered_by_epoch_times(filtered_ripple_simple_pf_pearson_merged_df['start'].to_numpy()) for a_name, a_df in decoder_ripple_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_laps_filter_epochs_decoder_result_dict[a_name].filtered_by_epoch_times(filtered_laps_simple_pf_pearson_merged_df['start'].to_numpy()) for a_name, a_df in decoder_laps_filter_epochs_decoder_result_dict.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b35196",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "2025-04-11 - full-session marginals"
    ]
   },
   "outputs": [],
   "source": [
    "# I have several python variables I want to print: t_start, t_delta, t_end\n",
    "# I want to generate a print statement that explicitly lists the variable name prior to its value like `print(f't_start: {t_start}, t_delta: {t_delta}, t_end: {t_end}')`\n",
    "# Currently I have to t_start, t_delta, t_end\n",
    "curr_active_pipeline.get_session_context()\n",
    "\n",
    "print(f'{curr_active_pipeline.session_name}:\\tt_start: {t_start}, t_delta: {t_delta}, t_end: {t_end}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49f5d4f",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all",
     "2025-04-11 - full-session marginals"
    ]
   },
   "outputs": [],
   "source": [
    "# Unpack all directional variables:\n",
    "## {\"even\": \"RL\", \"odd\": \"LR\"}\n",
    "long_LR_name, short_LR_name, global_LR_name, long_RL_name, short_RL_name, global_RL_name, long_any_name, short_any_name, global_any_name = ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "\n",
    "# Most popular\n",
    "# long_LR_name, short_LR_name, long_RL_name, short_RL_name, global_any_name\n",
    "\n",
    "# Unpacking for `(long_LR_name, long_RL_name, short_LR_name, short_RL_name)`\n",
    "(long_LR_context, long_RL_context, short_LR_context, short_RL_context) = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj, global_any_laps_epochs_obj = [curr_active_pipeline.computation_results[an_epoch_name].computation_config.pf_params.computation_epochs for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name, global_any_name)] # note has global also\n",
    "(long_LR_session, long_RL_session, short_LR_session, short_RL_session) = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)] # sessions are correct at least, seems like just the computation parameters are messed up\n",
    "(long_LR_results, long_RL_results, short_LR_results, short_RL_results) = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_computation_config, long_RL_computation_config, short_LR_computation_config, short_RL_computation_config) = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_pf1D, long_RL_pf1D, short_LR_pf1D, short_RL_pf1D) = (long_LR_results.pf1D, long_RL_results.pf1D, short_LR_results.pf1D, short_RL_results.pf1D)\n",
    "(long_LR_pf2D, long_RL_pf2D, short_LR_pf2D, short_RL_pf2D) = (long_LR_results.pf2D, long_RL_results.pf2D, short_LR_results.pf2D, short_RL_results.pf2D)\n",
    "(long_LR_pf1D_Decoder, long_RL_pf1D_Decoder, short_LR_pf1D_Decoder, short_RL_pf1D_Decoder) = (long_LR_results.pf1D_Decoder, long_RL_results.pf1D_Decoder, short_LR_results.pf1D_Decoder, short_RL_results.pf1D_Decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7104fc37",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all",
     "2025-04-11 - full-session marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult, DirectionalLapsResult, DirectionalDecodersContinuouslyDecodedResult\n",
    "\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']   \n",
    "rank_order_results: RankOrderComputationsContainer = curr_active_pipeline.global_computation_results.computed_data.get('RankOrder', None)\n",
    "if rank_order_results is not None:\n",
    "    minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "else:        \n",
    "    ## get from parameters:\n",
    "    minimum_inclusion_fr_Hz: float = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.included_qclu_values\n",
    "\n",
    "print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "print(f'included_qclu_values: {included_qclu_values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a6eab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_merged_decoders_result.laps_time_bin_marginals_df\n",
    "directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00672033",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_laps_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bb2118",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result ## here is a single result, but not a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f90757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_build_individual_time_bin_decoded_posteriors_df\n",
    "\n",
    "## From `directional_merged_decoders_result`\n",
    "# transfer_column_names_list: List[str] = ['maze_id', 'lap_dir', 'lap_id']\n",
    "transfer_column_names_list: List[str] = []\n",
    "filtered_laps_time_bin_marginals_df = _perform_build_individual_time_bin_decoded_posteriors_df(curr_active_pipeline, track_templates=track_templates, all_directional_laps_filter_epochs_decoder_result=directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result, transfer_column_names_list=transfer_column_names_list)\n",
    "filtered_laps_time_bin_marginals_df['lap_id'] = filtered_laps_time_bin_marginals_df['parent_epoch_label'].astype(int) + 1\n",
    "filtered_laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4c2073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result\n",
    "\n",
    "# directional_merged_decoders_result.all_directional_decoder_dict\n",
    "directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df77e66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import PhoPaginatedMultiDecoderDecodedEpochsWindow, DecodedEpochSlicesPaginatedFigureController, EpochSelectionsObject, ClickActionCallbacks\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.ThinButtonBar.ThinButtonBarWidget import ThinButtonBarWidget\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.PaginationCtrl.PaginationControlWidget import PaginationControlWidget, PaginationControlWidgetState\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from pyphoplacecellanalysis.Resources import GuiResources, ActionIcons, silx_resources_rc\n",
    "## INPUTS filtered_decoder_filter_epochs_decoder_result_dict\n",
    "# decoder_decoded_epochs_result_dict: generic\n",
    "\n",
    "app, paginated_multi_decoder_decoded_epochs_window, pagination_controller_dict = PhoPaginatedMultiDecoderDecodedEpochsWindow.init_from_track_templates(curr_active_pipeline, track_templates,\n",
    "                                                                                                # decoder_decoded_epochs_result_dict=decoder_ripple_filter_epochs_decoder_result_dict, epochs_name='ripple',\n",
    "                                                                                                # decoder_decoded_epochs_result_dict=filtered_decoder_filter_epochs_decoder_result_dict, epochs_name='ripple',\n",
    "                                                                                                # decoder_decoded_epochs_result_dict=filtered_ripple_simple_pf_pearson_merged_df, epochs_name='ripple',\n",
    "                                                                                                decoder_decoded_epochs_result_dict=long_like_during_post_delta_only_filtered_decoder_filter_epochs_decoder_result_dict, epochs_name='ripple', title='Long-like post-Delta Ripples Only', ## RIPPLE\n",
    "                                                                                                # decoder_decoded_epochs_result_dict=decoder_laps_filter_epochs_decoder_result_dict, epochs_name='laps', ## LAPS\n",
    "                                                                                                included_epoch_indicies=None, debug_print=False,\n",
    "                                                                                                params_kwargs={'enable_per_epoch_action_buttons': False,\n",
    "                                                                                                    'skip_plotting_most_likely_positions': True, 'skip_plotting_measured_positions': True, \n",
    "                                                                                                    'enable_decoded_most_likely_position_curve': False, 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': True,\n",
    "                                                                                                    # 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': False,\n",
    "                                                                                                    # 'disable_y_label': True,\n",
    "                                                                                                    'isPaginatorControlWidgetBackedMode': True,\n",
    "                                                                                                    'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True,\n",
    "                                                                                                    # 'debug_print': True,\n",
    "                                                                                                    'max_subplots_per_page': 10,\n",
    "                                                                                                    'scrollable_figure': False,\n",
    "                                                                                                    # 'scrollable_figure': True,\n",
    "                                                                                                    # 'posterior_heatmap_imshow_kwargs': dict(vmin=0.0075),\n",
    "                                                                                                    'use_AnchoredCustomText': False,\n",
    "                                                                                                    'should_suppress_callback_exceptions': False,\n",
    "                                                                                                    # 'build_fn': 'insets_view',\n",
    "                                                                                                })\n",
    "\n",
    "### attached raster viewer widget:\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.RankOrderRastersDebugger import RankOrderRastersDebugger\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import get_proper_global_spikes_df\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "\n",
    "## INPUTS: active_spikes_df\n",
    "# active_spikes_df = get_proper_global_spikes_df(curr_active_pipeline, minimum_inclusion_fr_Hz=5)\n",
    "\n",
    "# PosteriorExporting._perform_export_current_epoch_marginal_and_raster_images\n",
    "\n",
    "# _out_ripple_rasters, update_attached_raster_viewer_epoch_callback = build_attached_raster_viewer_widget(paginated_multi_decoder_decoded_epochs_window=paginated_multi_decoder_decoded_epochs_window, track_templates=track_templates, active_spikes_df=active_spikes_df, filtered_ripple_simple_pf_pearson_merged_df=filtered_epochs_df) ## BEST\n",
    "# _out_ripple_rasters, update_attached_raster_viewer_epoch_callback = build_attached_raster_viewer_widget(paginated_multi_decoder_decoded_epochs_window=paginated_multi_decoder_decoded_epochs_window, track_templates=track_templates, active_spikes_df=active_spikes_df, filtered_ripple_simple_pf_pearson_merged_df=filtered_ripple_simple_pf_pearson_merged_df) # original\n",
    "# _out_ripple_rasters, update_attached_raster_viewer_epoch_callback = build_attached_raster_viewer_widget(paginated_multi_decoder_decoded_epochs_window=paginated_multi_decoder_decoded_epochs_window, track_templates=track_templates, active_spikes_df=active_spikes_df, filtered_ripple_simple_pf_pearson_merged_df=extracted_merged_scores_df)\n",
    "_out_ripple_rasters, update_attached_raster_viewer_epoch_callback = paginated_multi_decoder_decoded_epochs_window.build_attached_raster_viewer_widget(track_templates=track_templates, active_spikes_df=active_spikes_df, filtered_epochs_df=long_like_during_post_delta_only_filter_epochs_df) # Long-like-during-post-delta\n",
    "\n",
    "\n",
    "# all_directional_laps_filter_epochs_decoder_result_value\n",
    "# laps_filter_epochs = ensure_dataframe(deepcopy(decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)) \n",
    "# _out_ripple_rasters, update_attached_raster_viewer_epoch_callback = build_attached_raster_viewer_widget(paginated_multi_decoder_decoded_epochs_window=paginated_multi_decoder_decoded_epochs_window, track_templates=track_templates, active_spikes_df=laps_spikes_df, filtered_ripple_simple_pf_pearson_merged_df=filtered_laps_simple_pf_pearson_merged_df) ## LAPS\n",
    "\n",
    "# _out_ripple_rasters: RankOrderRastersDebugger\n",
    "### Add yellow-blue marginals to `paginated_multi_decoder_decoded_epochs_window`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_decoded_epoch_slices\n",
    "from pyphocorehelpers.gui.Qt.widget_positioning_helpers import WidgetPositioningHelpers, DesiredWidgetLocation, WidgetGeometryInfo\n",
    "\n",
    "yellow_blue_trackID_marginals_plot_tuple = paginated_multi_decoder_decoded_epochs_window.build_attached_yellow_blue_track_identity_marginal_window(directional_merged_decoders_result, global_session, ripple_decoding_time_bin_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fee2d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean and max number of active aclus per time bin for each epoch (lap)\n",
    "filtered_laps_time_bin_marginals_df.groupby(['lap_id']).agg(n_unique_aclus_mean=('n_unique_aclus', 'mean'), n_unique_aclus_max=('n_unique_aclus', 'max')).reset_index()\n",
    "filtered_laps_time_bin_marginals_df.groupby(['maze_id']).agg(n_unique_aclus_mean=('n_unique_aclus', 'mean'), n_unique_aclus_max=('n_unique_aclus', 'max')).reset_index() ## per maze\n",
    "filtered_laps_time_bin_marginals_df.groupby(['maze_id', 'lap_dir']).agg(n_unique_aclus_mean=('n_unique_aclus', 'mean'), n_unique_aclus_max=('n_unique_aclus', 'max')).reset_index() # per maze x lap_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93346114",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "2025-04-11 - full-session marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.BatchCompletionHandler import BatchSessionCompletionHandler\n",
    "\n",
    "BatchSessionCompletionHandler.post_compute_validate(curr_active_pipeline=curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0617e7a3",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "2025-04-11 - full-session marginals"
    ]
   },
   "outputs": [],
   "source": [
    "list(directional_laps_results.directional_lap_specific_configs.keys()) # ['maze1_odd', 'maze1_even', 'maze2_odd', 'maze2_even']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912656a7",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all",
     "2025-04-11 - full-session marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "from neuropy.utils.indexing_helpers import NumpyHelpers\n",
    "\n",
    "if ('DirectionalDecodersEpochsEvaluations' in curr_active_pipeline.global_computation_results.computed_data) and (curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations'] is not None):\n",
    "    directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "    directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)\n",
    "\n",
    "    ## UNPACK HERE via direct property access:\n",
    "    pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "    ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "    laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "    print(f'{pos_bin_size = }, {ripple_decoding_time_bin_size = }, {laps_decoding_time_bin_size = }') # pos_bin_size = 3.8054171165052444, ripple_decoding_time_bin_size = 0.025, laps_decoding_time_bin_size = 0.2\n",
    "    decoder_laps_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict\n",
    "    decoder_ripple_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict\n",
    "    decoder_laps_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_df_dict\n",
    "    decoder_ripple_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_df_dict\n",
    "\n",
    "    # New items:\n",
    "    decoder_laps_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_extras_dict\n",
    "    decoder_ripple_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_extras_dict\n",
    "\n",
    "    # Weighted correlations:\n",
    "    laps_weighted_corr_merged_df = directional_decoders_epochs_decode_result.laps_weighted_corr_merged_df\n",
    "    ripple_weighted_corr_merged_df = directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "    decoder_laps_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_laps_weighted_corr_df_dict\n",
    "    decoder_ripple_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict\n",
    "\n",
    "    # Pearson's correlations:\n",
    "    laps_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.laps_simple_pf_pearson_merged_df\n",
    "    ripple_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df\n",
    "    \n",
    "    # for k, v in directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict.items():\n",
    "    #     print(f'{k}: v.decoding_time_bin_size: {v.decoding_time_bin_size}')\n",
    "    \n",
    "    individual_result_ripple_time_bin_sizes = [v.decoding_time_bin_size for k, v in directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict.items()]\n",
    "    if not np.allclose(ripple_decoding_time_bin_size, individual_result_ripple_time_bin_sizes):\n",
    "        individual_result_ripple_time_bin_size = individual_result_ripple_time_bin_sizes[0] # get the first\n",
    "        assert np.allclose(individual_result_ripple_time_bin_size, individual_result_ripple_time_bin_sizes), f\"`individual_result_ripple_time_bin_size ({individual_result_ripple_time_bin_size}) does not equal the individual result time bin sizes: {individual_result_ripple_time_bin_sizes}`. This can occur when there are epochs smaller than the desired size ({ripple_decoding_time_bin_size}) for the result and epochs_filtering_mode=EpochFilteringMode.ConstrainDecodingTimeBinSizeToMinimum\"\n",
    "        print(f'WARN: overriding directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size (original value: {directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size}) with individual_result_ripple_time_bin_size: {individual_result_ripple_time_bin_size}')\n",
    "        directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size = individual_result_ripple_time_bin_size # override the time_bin_size with the actually used one\n",
    "        ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "        print(f'{pos_bin_size = }, {ripple_decoding_time_bin_size = }, {laps_decoding_time_bin_size = }') # pos_bin_size = 3.8054171165052444, ripple_decoding_time_bin_size = 0.025, laps_decoding_time_bin_size = 0.2\n",
    "    else:\n",
    "        # all are close, it's good\n",
    "        pass\n",
    "\n",
    "    # assert np.allclose(ripple_decoding_time_bin_size, individual_result_ripple_time_bin_sizes), f\"`directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size ({ripple_decoding_time_bin_size}) does not equal the individual result time bin sizes: {individual_result_ripple_time_bin_sizes}`. This can occur when there are epochs smaller than the desired size ({ripple_decoding_time_bin_size}) for the result and epochs_filtering_mode=EpochFilteringMode.ConstrainDecodingTimeBinSizeToMinimum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f1c291",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "2025-04-11 - full-session marginals"
    ]
   },
   "outputs": [],
   "source": [
    "decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dce38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_decoders_epochs_decode_result # DecoderDecodedEpochsResult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881402df",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "2025-04-11 - full-session marginals"
    ]
   },
   "outputs": [],
   "source": [
    "# active_config_name: str = 'maze_any'\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "active_config_name: str = global_epoch_name # 'maze_any'\n",
    "active_config_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b80230",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "## INPUTS: curr_active_pipeline, active_config_name\n",
    "active_peak_prominence_2d_results = curr_active_pipeline.computation_results[active_config_name].computed_data.get('RatemapPeaksAnalysis', {}).get('PeakProminence2D', None)\n",
    "if active_peak_prominence_2d_results is None:\n",
    "    curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['ratemap_peaks_prominence2d'], enabled_filter_names=None, fail_on_exception=False, debug_print=False)\n",
    "    # curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['ratemap_peaks_prominence2d'], enabled_filter_names=[short_LR_name, short_RL_name, long_any_name, short_any_name], fail_on_exception=False, debug_print=False) # or at least\n",
    "    active_peak_prominence_2d_results = curr_active_pipeline.computation_results[active_config_name].computed_data.get('RatemapPeaksAnalysis', {}).get('PeakProminence2D', None)\n",
    "    assert active_peak_prominence_2d_results is not None, f\"bad even after computation\"\n",
    "\n",
    "# active_peak_prominence_2d_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238f67cb",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all",
     "run-continuous-decoding",
     "2025-04-11 - full-session marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalDecodersContinuouslyDecodedResult\n",
    "\n",
    "if 'DirectionalDecodersDecoded' in curr_active_pipeline.global_computation_results.computed_data:\n",
    "    directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "    all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "    pseudo2D_decoder: BasePositionDecoder = directional_decoders_decode_result.pseudo2D_decoder\n",
    "    spikes_df = directional_decoders_decode_result.spikes_df\n",
    "    continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "    previously_decoded_keys: List[float] = list(continuously_decoded_result_cache_dict.keys()) # [0.03333]\n",
    "    print(F'previously_decoded time_bin_sizes: {previously_decoded_keys}')\n",
    "    \n",
    "    time_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\n",
    "    print(f'time_bin_size: {time_bin_size}')\n",
    "    continuously_decoded_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_decode_result.most_recent_continuously_decoded_dict\n",
    "    all_directional_continuously_decoded_dict = continuously_decoded_dict or {} ## what is plotted in the `f'{a_decoder_name}_ContinuousDecode'` rows by `AddNewDirectionalDecodedEpochs_MatplotlibPlotCommand`\n",
    "    all_directional_continuously_decoded_dict\n",
    "\n",
    "    pseudo2D_decoder_continuously_decoded_result: DecodedFilterEpochsResult = continuously_decoded_dict.get('pseudo2D', None)\n",
    "    assert len(pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list) == 1\n",
    "    p_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0]\n",
    "    # p_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0]['p_x_given_n']\n",
    "    time_bin_containers = pseudo2D_decoder_continuously_decoded_result.time_bin_containers[0]\n",
    "    time_window_centers = time_bin_containers.centers\n",
    "    # p_x_given_n.shape # (62, 4, 209389)\n",
    "\n",
    "    ## Split across the 2nd axis to make 1D posteriors that can be displayed in separate dock rows:\n",
    "    assert p_x_given_n.shape[1] == 4, f\"expected the 4 pseudo-y bins for the decoder in p_x_given_n.shape[1]. but found p_x_given_n.shape: {p_x_given_n.shape}\"\n",
    "    split_pseudo2D_posteriors_dict = {k:np.squeeze(p_x_given_n[:, i, :]) for i, k in enumerate(('long_LR', 'long_RL', 'short_LR', 'short_RL'))}\n",
    "    split_pseudo2D_posteriors_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d92b4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_decoders_decode_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e1ee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_directional_pf1D_Decoder_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b4e959",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.SequenceBasedComputations import WCorrShuffle, SequenceBasedComputationsContainer\n",
    "\n",
    "wcorr_shuffle_results: SequenceBasedComputationsContainer = curr_active_pipeline.global_computation_results.computed_data.get('SequenceBased', None)\n",
    "if wcorr_shuffle_results is not None:    \n",
    "    wcorr_ripple_shuffle: WCorrShuffle = wcorr_shuffle_results.wcorr_ripple_shuffle\n",
    "    if wcorr_ripple_shuffle is not None:\n",
    "        print(f'wcorr_ripple_shuffle.n_completed_shuffles: {wcorr_ripple_shuffle.n_completed_shuffles}')\n",
    "    else:\n",
    "        print(f'SequenceBased is computed but `wcorr_shuffle_results.wcorr_ripple_shuffle` is None.')        \n",
    "else:\n",
    "    print(f'SequenceBased is not computed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e9cc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['trial_by_trial_metrics'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "directional_trial_by_trial_activity_result = curr_active_pipeline.global_computation_results.computed_data.get('TrialByTrialActivity', None) ## try again to get the result\n",
    "assert directional_trial_by_trial_activity_result is not None, f\"directional_trial_by_trial_activity_result is None even after forcing recomputation!!\"\n",
    "print(f'\\t done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d7394a",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "2025-04-11 - full-session marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.reliability import TrialByTrialActivity\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrialByTrialActivityResult\n",
    "\n",
    "directional_trial_by_trial_activity_result: TrialByTrialActivityResult = curr_active_pipeline.global_computation_results.computed_data.get('TrialByTrialActivity', None)\n",
    "if directional_trial_by_trial_activity_result is None:\n",
    "    # if `KeyError: 'TrialByTrialActivity'` recompute\n",
    "    print(f'TrialByTrialActivity is not computed, computing it...')\n",
    "    curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['trial_by_trial_metrics'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "    directional_trial_by_trial_activity_result = curr_active_pipeline.global_computation_results.computed_data.get('TrialByTrialActivity', None) ## try again to get the result\n",
    "    assert directional_trial_by_trial_activity_result is not None, f\"directional_trial_by_trial_activity_result is None even after forcing recomputation!!\"\n",
    "    print(f'\\t done.')\n",
    "\n",
    "## unpack either way:\n",
    "any_decoder_neuron_IDs = directional_trial_by_trial_activity_result.any_decoder_neuron_IDs\n",
    "active_pf_dt: PfND_TimeDependent = directional_trial_by_trial_activity_result.active_pf_dt\n",
    "directional_lap_epochs_dict: Dict[str, Epoch] = directional_trial_by_trial_activity_result.directional_lap_epochs_dict\n",
    "directional_active_lap_pf_results_dicts: Dict[str, TrialByTrialActivity] = directional_trial_by_trial_activity_result.directional_active_lap_pf_results_dicts\n",
    "stability_dict = {k:list(v.aclu_to_stability_score_dict.values()) for k,v in directional_active_lap_pf_results_dicts.items()}\n",
    "stability_df: pd.DataFrame = pd.DataFrame({'aclu': any_decoder_neuron_IDs, **stability_dict})\n",
    "## OUTPUTS: stability_df, stability_dict\n",
    "\n",
    "## OUTPUTS: directional_trial_by_trial_activity_result, directional_active_lap_pf_results_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fad74c",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "wcorr_shuffle_results: SequenceBasedComputationsContainer = curr_active_pipeline.global_computation_results.computed_data.get('SequenceBased', None)\n",
    "if wcorr_shuffle_results is not None:    \n",
    "    wcorr_ripple_shuffle: WCorrShuffle = wcorr_shuffle_results.wcorr_ripple_shuffle\n",
    "    if wcorr_ripple_shuffle is not None:  \n",
    "        print(f'wcorr_ripple_shuffle.n_completed_shuffles: {wcorr_ripple_shuffle.n_completed_shuffles}')\n",
    "    else:\n",
    "        print(f'SequenceBased is computed but wcorr_ripple_shuffle is None.')\n",
    "else:\n",
    "    print(f'SequenceBased is not computed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ed0870",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "run-continuous-decoding",
     "2025-04-11 - full-session marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult, SingleEpochDecodedResult\n",
    "\n",
    "most_recent_time_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\n",
    "# most_recent_time_bin_size\n",
    "most_recent_continuously_decoded_dict = deepcopy(directional_decoders_decode_result.most_recent_continuously_decoded_dict)\n",
    "# most_recent_continuously_decoded_dict\n",
    "\n",
    "## Adds in the 'pseudo2D' decoder in:\n",
    "time_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\n",
    "# time_bin_size: float = 0.01\n",
    "print(f'time_bin_size: {time_bin_size}')\n",
    "continuously_decoded_dict = continuously_decoded_result_cache_dict[time_bin_size]\n",
    "pseudo2D_decoder_continuously_decoded_result = continuously_decoded_dict.get('pseudo2D', None)\n",
    "if pseudo2D_decoder_continuously_decoded_result is None:\n",
    "    # compute here...\n",
    "    ## Currently used for both cases to decode:\n",
    "    t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "    single_global_epoch_df: pd.DataFrame = pd.DataFrame({'start': [t_start], 'stop': [t_end], 'label': [0]}) # Build an Epoch object containing a single epoch, corresponding to the global epoch for the entire session:\n",
    "    single_global_epoch: Epoch = Epoch(single_global_epoch_df)\n",
    "    spikes_df = directional_decoders_decode_result.spikes_df\n",
    "    pseudo2D_decoder_continuously_decoded_result: DecodedFilterEpochsResult = pseudo2D_decoder.decode_specific_epochs(spikes_df=deepcopy(spikes_df), filter_epochs=single_global_epoch, decoding_time_bin_size=time_bin_size, debug_print=False)\n",
    "    continuously_decoded_dict['pseudo2D'] = pseudo2D_decoder_continuously_decoded_result\n",
    "    continuously_decoded_dict\n",
    "    \n",
    "pseudo2D_decoder_continuously_decoded_single_result: SingleEpochDecodedResult = pseudo2D_decoder_continuously_decoded_result.get_result_for_epoch(0)\n",
    "pseudo2D_decoder_continuously_decoded_single_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eab4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudo2D_decoder_continuously_decoded_single_result.epoch_info_tuple\n",
    "pseudo2D_decoder_continuously_decoded_single_result.nbins\n",
    "pseudo2D_decoder_continuously_decoded_single_result.p_x_given_n\n",
    "pseudo2D_decoder_continuously_decoded_single_result.p_x_given_n.shape # (57, 4, 29951)\n",
    "\n",
    "\n",
    "short_RL_only = pseudo2D_decoder_continuously_decoded_single_result.p_x_given_n[:, 3, :]\n",
    "np.shape(short_RL_only)\n",
    "\n",
    "debug_portion_short_RL_only = short_RL_only[:, :1000]\n",
    "\n",
    "\n",
    "plt.figure(clear=True)\n",
    "plt.imshow(debug_portion_short_RL_only)\n",
    "# plt.plot(np.sum(short_RL_only, axis=0))\n",
    "# plt.plot(np.cumsum(np.sum(short_RL_only, axis=0)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f48287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88344ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import SingleEpochDecodedResult\n",
    "\n",
    "\n",
    "only_result.p_x_given_n\n",
    "only_result.time_bin_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ee77bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo2D_decoder_continuously_decoded_result.filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2dc5fe",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all",
     "2025-04-11 - full-session marginals"
    ]
   },
   "outputs": [],
   "source": [
    "# NEW 2023-11-22 method: Get the templates (which can be filtered by frate first) and the from those get the decoders):        \n",
    "# track_templates: TrackTemplates = directional_laps_results.get_shared_aclus_only_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # shared-only\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, included_qclu_values=included_qclu_values) # non-shared-only\n",
    "long_LR_decoder, long_RL_decoder, short_LR_decoder, short_RL_decoder = track_templates.get_decoders()\n",
    "\n",
    "# Unpack all directional variables:\n",
    "## {\"even\": \"RL\", \"odd\": \"LR\"}\n",
    "long_LR_name, short_LR_name, global_LR_name, long_RL_name, short_RL_name, global_RL_name, long_any_name, short_any_name, global_any_name = ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "# Unpacking for `(long_LR_name, long_RL_name, short_LR_name, short_RL_name)`\n",
    "(long_LR_context, long_RL_context, short_LR_context, short_RL_context) = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj, global_any_laps_epochs_obj = [curr_active_pipeline.computation_results[an_epoch_name].computation_config.pf_params.computation_epochs for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name, global_any_name)] # note has global also\n",
    "(long_LR_session, long_RL_session, short_LR_session, short_RL_session) = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)] # sessions are correct at least, seems like just the computation parameters are messed up\n",
    "(long_LR_results, long_RL_results, short_LR_results, short_RL_results) = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_computation_config, long_RL_computation_config, short_LR_computation_config, short_RL_computation_config) = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_pf1D, long_RL_pf1D, short_LR_pf1D, short_RL_pf1D) = (long_LR_results.pf1D, long_RL_results.pf1D, short_LR_results.pf1D, short_RL_results.pf1D)\n",
    "(long_LR_pf2D, long_RL_pf2D, short_LR_pf2D, short_RL_pf2D) = (long_LR_results.pf2D, long_RL_results.pf2D, short_LR_results.pf2D, short_RL_results.pf2D)\n",
    "(long_LR_pf1D_Decoder, long_RL_pf1D_Decoder, short_LR_pf1D_Decoder, short_RL_pf1D_Decoder) = (long_LR_results.pf1D_Decoder, long_RL_results.pf1D_Decoder, short_LR_results.pf1D_Decoder, short_RL_results.pf1D_Decoder)\n",
    "\n",
    "if rank_order_results is not None:\n",
    "    # `LongShortStatsItem` form (2024-01-02):\n",
    "    # LR_results_real_values = np.array([(a_result_item.long_stats_z_scorer.real_value, a_result_item.short_stats_z_scorer.real_value) for epoch_id, a_result_item in rank_order_results.LR_ripple.ranked_aclus_stats_dict.items()])\n",
    "    # RL_results_real_values = np.array([(a_result_item.long_stats_z_scorer.real_value, a_result_item.short_stats_z_scorer.real_value) for epoch_id, a_result_item in rank_order_results.RL_ripple.ranked_aclus_stats_dict.items()])\n",
    "    LR_results_long_short_z_diffs = np.array([a_result_item.long_short_z_diff for epoch_id, a_result_item in rank_order_results.LR_ripple.ranked_aclus_stats_dict.items()])\n",
    "    RL_results_long_short_z_diff = np.array([a_result_item.long_short_z_diff for epoch_id, a_result_item in rank_order_results.RL_ripple.ranked_aclus_stats_dict.items()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c260739a4f36c662",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "2025-04-11 - full-session marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrainTestSplitResult\n",
    "\n",
    "if 'TrainTestSplit' in curr_active_pipeline.global_computation_results.computed_data:\n",
    "    directional_train_test_split_result: TrainTestSplitResult = curr_active_pipeline.global_computation_results.computed_data.get('TrainTestSplit', None)\n",
    "    training_data_portion: float = directional_train_test_split_result.training_data_portion\n",
    "    test_data_portion: float = directional_train_test_split_result.test_data_portion\n",
    "    test_epochs_dict: Dict[str, pd.DataFrame] = directional_train_test_split_result.test_epochs_dict\n",
    "    train_epochs_dict: Dict[str, pd.DataFrame] = directional_train_test_split_result.train_epochs_dict\n",
    "    train_lap_specific_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_train_test_split_result.train_lap_specific_pf1D_Decoder_dict\n",
    "    \n",
    "long_LR_name, short_LR_name, global_LR_name, long_RL_name, short_RL_name, global_RL_name, long_any_name, short_any_name, global_any_name = ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj = [curr_active_pipeline.computation_results[an_epoch_name].computation_config.pf_params.computation_epochs for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)] # note has global also\n",
    "long_LR_name, long_RL_name, short_LR_name, short_RL_name = track_templates.get_decoder_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec18cf18",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "2025-04-11 - full-session marginals"
    ]
   },
   "outputs": [],
   "source": [
    "if 'burst_detection' in curr_active_pipeline.computation_results[global_epoch_name].computed_data:\n",
    "    active_burst_intervals = curr_active_pipeline.computation_results[global_epoch_name].computed_data['burst_detection']['burst_intervals']\n",
    "# active_burst_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d31f37d",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "2025-04-11 - full-session marginals"
    ]
   },
   "outputs": [],
   "source": [
    "active_extended_stats = global_results.get('extended_stats', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9554d3bf5955d9d3",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "2025-04-11 - full-session marginals"
    ]
   },
   "outputs": [],
   "source": [
    "# Time-dependent\n",
    "long_pf1D_dt, short_pf1D_dt, global_pf1D_dt = long_results.pf1D_dt, short_results.pf1D_dt, global_results.pf1D_dt\n",
    "long_pf2D_dt, short_pf2D_dt, global_pf2D_dt = long_results.pf2D_dt, short_results.pf2D_dt, global_results.pf2D_dt\n",
    "global_pf1D_dt: PfND_TimeDependent = global_results.pf1D_dt\n",
    "global_pf2D_dt: PfND_TimeDependent = global_results.pf2D_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7a8050",
   "metadata": {},
   "outputs": [],
   "source": [
    "## long_short_endcap_analysis: checks for cells localized to the endcaps that have their placefields truncated after shortening the track\n",
    "truncation_checking_result: TruncationCheckingResults = curr_active_pipeline.global_computation_results.computed_data.long_short_endcap\n",
    "disappearing_endcap_aclus = truncation_checking_result.disappearing_endcap_aclus\n",
    "# disappearing_endcap_aclus\n",
    "trivially_remapping_endcap_aclus = truncation_checking_result.minor_remapping_endcap_aclus\n",
    "# trivially_remapping_endcap_aclus\n",
    "significant_distant_remapping_endcap_aclus = truncation_checking_result.significant_distant_remapping_endcap_aclus\n",
    "# significant_distant_remapping_endcap_aclus\n",
    "# appearing_aclus = jonathan_firing_rate_analysis_result.neuron_replay_stats_df[jonathan_firing_rate_analysis_result.neuron_replay_stats_df['track_membership'] == SplitPartitionMembership.RIGHT_ONLY].index\n",
    "# appearing_aclus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8ff5d1",
   "metadata": {},
   "source": [
    "# <a id='toc5_'></a>[1️⃣ POST-Compute:](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728c46e6",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "21"
    },
    "tags": [
     "unwrap",
     "initial",
     "run-group-end-run",
     "all",
     "2025-04-11 - full-session marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalDisplayFunctions\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multi_sort_raster_browser\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.RankOrderRastersDebugger import RankOrderRastersDebugger\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import paired_separately_sort_neurons, paired_incremental_sort_neurons # _display_directional_template_debugger\n",
    "from neuropy.utils.indexing_helpers import paired_incremental_sorting, union_of_arrays, intersection_of_arrays, find_desired_sort_indicies\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.ScrollBarWithSpinBox.ScrollBarWithSpinBox import ScrollBarWithSpinBox\n",
    "\n",
    "from neuropy.utils.mixins.HDF5_representable import HDF_SerializationMixin\n",
    "from pyphoplacecellanalysis.General.Model.ComputationResults import ComputedResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderAnalyses, RankOrderResult, ShuffleHelper, Zscorer, LongShortStatsTuple, DirectionalRankOrderLikelihoods, DirectionalRankOrderResult, RankOrderComputationsContainer\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import TimeColumnAliasesProtocol\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderComputationsContainer\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import DirectionalRankOrderResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "\n",
    "## Display Testing\n",
    "# from pyphoplacecellanalysis.External.pyqtgraph import QtGui\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.Extensions.pyqtgraph_helpers import pyqtplot_build_image_bounds_extent, pyqtplot_plot_image\n",
    "\n",
    "spikes_df = curr_active_pipeline.sess.spikes_df\n",
    "rank_order_results: RankOrderComputationsContainer = curr_active_pipeline.global_computation_results.computed_data.get('RankOrder', None)\n",
    "if rank_order_results is not None:\n",
    "    minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "    ripple_result_tuple, laps_result_tuple = rank_order_results.ripple_most_likely_result_tuple, rank_order_results.laps_most_likely_result_tuple\n",
    "\n",
    "else:        \n",
    "    ## get from parameters:\n",
    "    minimum_inclusion_fr_Hz: float = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.included_qclu_values\n",
    "\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, included_qclu_values=included_qclu_values) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\n",
    "print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "print(f'included_qclu_values: {included_qclu_values}')\n",
    "# ripple_result_tuple\n",
    "\n",
    "## Unpacks `rank_order_results`: \n",
    "# global_replays = Epoch(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].replay))\n",
    "# global_replays = TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].replay))\n",
    "# active_replay_epochs, active_epochs_df, active_selected_spikes_df = combine_rank_order_results(rank_order_results, global_replays, track_templates=track_templates)\n",
    "# active_epochs_df\n",
    "\n",
    "# ripple_result_tuple.directional_likelihoods_tuple.long_best_direction_indices\n",
    "dir_index_to_direction_name_map: Dict[int, str] = {0:'LR', 1:\"RL\"}\n",
    "\n",
    "if rank_order_results is not None:\n",
    "    ## All three DataFrames are the same number of rows, each with one row corresponding to an Epoch:\n",
    "    active_replay_epochs_df = deepcopy(rank_order_results.LR_ripple.epochs_df)\n",
    "    # active_replay_epochs_df\n",
    "\n",
    "    # Change column type to int8 for columns: 'long_best_direction_indices', 'short_best_direction_indices'\n",
    "    # directional_likelihoods_df = pd.DataFrame.from_dict(ripple_result_tuple.directional_likelihoods_tuple._asdict()).astype({'long_best_direction_indices': 'int8', 'short_best_direction_indices': 'int8'})\n",
    "    directional_likelihoods_df = ripple_result_tuple.directional_likelihoods_df\n",
    "    # directional_likelihoods_df\n",
    "\n",
    "    # 2023-12-15 - Newest method:\n",
    "    laps_merged_complete_epoch_stats_df: pd.DataFrame = rank_order_results.laps_merged_complete_epoch_stats_df ## New method\n",
    "    ripple_merged_complete_epoch_stats_df: pd.DataFrame = rank_order_results.ripple_merged_complete_epoch_stats_df ## New method\n",
    "\n",
    "\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "\n",
    "all_directional_decoder_dict_value = directional_merged_decoders_result.all_directional_decoder_dict\n",
    "all_directional_pf1D_Decoder_value = directional_merged_decoders_result.all_directional_pf1D_Decoder\n",
    "# long_directional_pf1D_Decoder_value = directional_merged_decoders_result.long_directional_pf1D_Decoder\n",
    "# long_directional_decoder_dict_value = directional_merged_decoders_result.long_directional_decoder_dict\n",
    "# short_directional_pf1D_Decoder_value = directional_merged_decoders_result.short_directional_pf1D_Decoder\n",
    "# short_directional_decoder_dict_value = directional_merged_decoders_result.short_directional_decoder_dict\n",
    "\n",
    "all_directional_laps_filter_epochs_decoder_result_value = directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result\n",
    "all_directional_ripple_filter_epochs_decoder_result_value = directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result\n",
    "\n",
    "laps_directional_marginals, laps_directional_all_epoch_bins_marginal, laps_most_likely_direction_from_decoder, laps_is_most_likely_direction_LR_dir  = directional_merged_decoders_result.laps_directional_marginals_tuple\n",
    "laps_track_identity_marginals, laps_track_identity_all_epoch_bins_marginal, laps_most_likely_track_identity_from_decoder, laps_is_most_likely_track_identity_Long = directional_merged_decoders_result.laps_track_identity_marginals_tuple\n",
    "ripple_directional_marginals, ripple_directional_all_epoch_bins_marginal, ripple_most_likely_direction_from_decoder, ripple_is_most_likely_direction_LR_dir  = directional_merged_decoders_result.ripple_directional_marginals_tuple\n",
    "ripple_track_identity_marginals, ripple_track_identity_all_epoch_bins_marginal, ripple_most_likely_track_identity_from_decoder, ripple_is_most_likely_track_identity_Long = directional_merged_decoders_result.ripple_track_identity_marginals_tuple\n",
    "\n",
    "ripple_decoding_time_bin_size: float = directional_merged_decoders_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_merged_decoders_result.laps_decoding_time_bin_size\n",
    "\n",
    "print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}, ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}')\n",
    "\n",
    "laps_all_epoch_bins_marginals_df = directional_merged_decoders_result.laps_all_epoch_bins_marginals_df\n",
    "ripple_all_epoch_bins_marginals_df = directional_merged_decoders_result.ripple_all_epoch_bins_marginals_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753ca336",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "# from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import HeuristicReplayScoring\n",
    "from neuropy.core.epoch import find_data_indicies_from_epoch_times\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_filter_replay_epochs\n",
    "\n",
    "# filtered_epochs_df, filtered_decoder_filter_epochs_decoder_result_dict, filtered_ripple_all_epoch_bins_marginals_df = None, None, None\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-_perform_filter_replay_epochs.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "filtered_epochs_df, filtered_decoder_filter_epochs_decoder_result_dict, filtered_ripple_all_epoch_bins_marginals_df = _perform_filter_replay_epochs(curr_active_pipeline, global_epoch_name, track_templates, decoder_ripple_filter_epochs_decoder_result_dict, ripple_all_epoch_bins_marginals_df, ripple_decoding_time_bin_size=ripple_decoding_time_bin_size, should_only_include_user_selected_epochs=False)\n",
    "filtered_epochs_df\n",
    "# filtered_ripple_all_epoch_bins_marginals_df\n",
    "\n",
    "## 1m 38s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92aad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_sess: DataSession = curr_active_pipeline.sess\n",
    "global_session.compute_pbe_epochs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca48dd6",
   "metadata": {},
   "source": [
    "### <a id='toc5_1_1_'></a>[2024-06-25 - Advanced Time-dependent decoding:](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c76fbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Directional Versions: 'long_LR':\n",
    "from neuropy.core.epoch import subdivide_epochs, ensure_dataframe\n",
    "\n",
    "\n",
    "## INPUTS: long_LR_epochs_obj, long_LR_results\n",
    "\n",
    "a_pf1D_dt: PfND_TimeDependent = deepcopy(long_LR_results.pf1D_dt)\n",
    "a_pf2D_dt: PfND_TimeDependent = deepcopy(long_LR_results.pf2D_dt)\n",
    "\n",
    "# Example usage\n",
    "df: pd.DataFrame = ensure_dataframe(deepcopy(long_LR_epochs_obj)) \n",
    "df['epoch_type'] = 'lap'\n",
    "df['interval_type_id'] = 666\n",
    "\n",
    "# subdivide_bin_size = 0.200  # Specify the size of each sub-epoch in seconds\n",
    "subdivide_bin_size = 0.050\n",
    "subdiv_df: pd.DataFrame = subdivide_epochs(df, subdivide_bin_size)\n",
    "# print(subdivided_df)\n",
    "\n",
    "## Evolve the ratemaps:\n",
    "_a_pf1D_dt_snapshots = a_pf1D_dt.batch_snapshotting(subdiv_df, reset_at_start=True)\n",
    "_a_pf2D_dt_snapshots = a_pf2D_dt.batch_snapshotting(subdiv_df, reset_at_start=True)\n",
    "# a_pf2D_dt.plot_ratemaps_2D()\n",
    "\n",
    "## takes about 2 mins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788d8b7e",
   "metadata": {},
   "source": [
    "# <a id='toc6_'></a>[/ 🛑 End Run Section 🛑](#toc0_)\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7433b81f",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "## Find the time series of Long-likely events\n",
    "# type(long_RL_results) # DynamicParameters\n",
    "long_LR_pf1D_Decoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d2363d",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "type(all_directional_decoder_dict_value)\n",
    "list(all_directional_decoder_dict_value.keys()) # ['long_LR', 'long_RL', 'short_LR', 'short_RL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634e6027",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "laps_all_epoch_bins_marginals_df\n",
    "laps_most_likely_direction_from_decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdabd71",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "type(ripple_result_tuple) # pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations.DirectionalRankOrderResult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fca534c",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "assert isinstance(ripple_result_tuple, DirectionalRankOrderResult) \n",
    "\n",
    "ripple_result_tuple.plot_histograms(num='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15629dae",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import DirectionalRankOrderResult\n",
    "from pyphocorehelpers.DataStructure.RenderPlots.MatplotLibRenderPlots import MatplotlibRenderPlots \n",
    "\n",
    "# @register_type_display(DirectionalRankOrderResult)\n",
    "def plot_histograms(self: DirectionalRankOrderResult, **kwargs) -> \"MatplotlibRenderPlots\":\n",
    "    \"\"\" \n",
    "    num='RipplesRankOrderZscore'\n",
    "    \"\"\"\n",
    "    print(f'.plot_histograms(..., kwargs: {kwargs})')\n",
    "    fig = plt.figure(layout=\"constrained\", **kwargs)\n",
    "    ax_dict = fig.subplot_mosaic(\n",
    "        [\n",
    "            [\"long_short_best_z_score_diff\", \"long_short_best_z_score_diff\"],\n",
    "            [\"long_best_z_scores\", \"short_best_z_scores\"],\n",
    "        ],\n",
    "    )\n",
    "    plots = (pd.DataFrame({'long_best_z_scores': self.long_best_dir_z_score_values}).hist(ax=ax_dict['long_best_z_scores'], bins=21, alpha=0.8),\n",
    "        pd.DataFrame({'short_best_z_scores': self.short_best_dir_z_score_values}).hist(ax=ax_dict['short_best_z_scores'], bins=21, alpha=0.8),\n",
    "        pd.DataFrame({'long_short_best_z_score_diff': self.long_short_best_dir_z_score_diff_values}).hist(ax=ax_dict['long_short_best_z_score_diff'], bins=21, alpha=0.8),\n",
    "    )\n",
    "    return MatplotlibRenderPlots(name='plot_histogram_figure', figures=[fig], axes=ax_dict)\n",
    "\n",
    "\n",
    "# register_type_display(plot_histograms, DirectionalRankOrderResult)\n",
    "## Call the newly added `plot_histograms` function on the `ripple_result_tuple` object which is of type `DirectionalRankOrderResult`:\n",
    "assert isinstance(ripple_result_tuple, DirectionalRankOrderResult) \n",
    "ripple_result_tuple.plot_histograms(num='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c291690",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "ripple_result_tuple.plot_histograms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b30bcb",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# 💾 CSVs \n",
    "print(f'\\t try saving to CSV...')\n",
    "merged_complete_epoch_stats_df = rank_order_results.ripple_merged_complete_epoch_stats_df ## New method\n",
    "merged_complete_epoch_stats_df\n",
    "merged_complete_ripple_epoch_stats_df_output_path = curr_active_pipeline.get_output_path().joinpath(f'{DAY_DATE_TO_USE}_merged_complete_epoch_stats_df.csv').resolve()\n",
    "merged_complete_epoch_stats_df.to_csv(merged_complete_ripple_epoch_stats_df_output_path)\n",
    "print(f'\\t saving to CSV: {merged_complete_ripple_epoch_stats_df_output_path} done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60749347",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "all",
     "active-2025-01-20"
    ]
   },
   "outputs": [],
   "source": [
    "print(f'\\tdone. building global result.')\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "selected_spikes_df = deepcopy(curr_active_pipeline.global_computation_results.computed_data['RankOrder'].LR_ripple.selected_spikes_df)\n",
    "# active_epochs = global_computation_results.computed_data['RankOrder'].ripple_most_likely_result_tuple.active_epochs\n",
    "active_epochs = deepcopy(curr_active_pipeline.global_computation_results.computed_data['RankOrder'].LR_ripple.epochs_df)\n",
    "track_templates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz)\n",
    "\n",
    "ripple_combined_epoch_stats_df, ripple_new_output_tuple = RankOrderAnalyses.pandas_df_based_correlation_computations(selected_spikes_df=selected_spikes_df, active_epochs_df=active_epochs, track_templates=track_templates, num_shuffles=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313886d9",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# new_output_tuple (output_active_epoch_computed_values, valid_stacked_arrays, real_stacked_arrays, n_valid_shuffles) = ripple_new_output_tuple\n",
    "curr_active_pipeline.global_computation_results.computed_data['RankOrder'].ripple_combined_epoch_stats_df, curr_active_pipeline.global_computation_results.computed_data['RankOrder'].ripple_new_output_tuple = ripple_combined_epoch_stats_df, ripple_new_output_tuple\n",
    "print(f'done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6f086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Display the `TrainTestSplitResult` in a `PhoPaginatedMultiDecoderDecodedEpochsWindow`\n",
    "from neuropy.core.epoch import Epoch, ensure_dataframe\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import add_laps_groundtruth_information_to_dataframe\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import PhoPaginatedMultiDecoderDecodedEpochsWindow\n",
    "\n",
    "## INPUTS: train_decoded_results_dict\n",
    "# decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs # looks like 'lap_dir' column is wrong\n",
    "\n",
    "# active_results: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(decoder_laps_filter_epochs_decoder_result_dict)\n",
    "active_results: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy({k:v.decoder_result for k, v in _out_separate_decoder_results[0].items()})\n",
    "\n",
    "laps_app, laps_paginated_multi_decoder_decoded_epochs_window, laps_pagination_controller_dict = PhoPaginatedMultiDecoderDecodedEpochsWindow.init_from_track_templates(curr_active_pipeline, track_templates,\n",
    "                            decoder_decoded_epochs_result_dict=active_results, epochs_name='laps', included_epoch_indicies=None, \n",
    "    params_kwargs={'enable_per_epoch_action_buttons': False,\n",
    "    'skip_plotting_most_likely_positions': False, 'skip_plotting_measured_positions': False, \n",
    "    # 'enable_decoded_most_likely_position_curve': False, 'enable_radon_transform_info': True, 'enable_weighted_correlation_info': False,\n",
    "    'enable_decoded_most_likely_position_curve': True, 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': False,\n",
    "    # 'disable_y_label': True,\n",
    "    # 'isPaginatorControlWidgetBackedMode': True,\n",
    "    # 'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True,\n",
    "    # 'debug_print': True,\n",
    "    'max_subplots_per_page': 10,\n",
    "    'scrollable_figure': True,\n",
    "    # 'posterior_heatmap_imshow_kwargs': dict(vmin=0.0075),\n",
    "    'use_AnchoredCustomText': False,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3d15bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_build_individual_time_bin_decoded_posteriors_df\n",
    "\n",
    "transfer_column_names_list: List[str] = ['maze_id', 'lap_dir', 'lap_id']\n",
    "filtered_laps_time_bin_marginals_df = _perform_build_individual_time_bin_decoded_posteriors_df(curr_active_pipeline, track_templates=track_templates, all_directional_laps_filter_epochs_decoder_result=all_directional_laps_filter_epochs_decoder_result, transfer_column_names_list=transfer_column_names_list)\n",
    "filtered_laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e0053b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import co_filter_epochs_and_spikes\n",
    "\n",
    "## INPUTS: all_directional_laps_filter_epochs_decoder_result\n",
    "transfer_column_names_list: List[str] = ['maze_id', 'lap_dir', 'lap_id']\n",
    "TIME_OVERLAP_PREVENTION_EPSILON: float = 1e-12\n",
    "(laps_directional_marginals_tuple, laps_track_identity_marginals_tuple, laps_non_marginalized_decoder_marginals_tuple), laps_marginals_df = all_directional_laps_filter_epochs_decoder_result.compute_marginals(epoch_idx_col_name='lap_idx', epoch_start_t_col_name='lap_start_t',\n",
    "                                                                                                                                                    additional_transfer_column_names=['start','stop','label','duration','lap_id','lap_dir','maze_id','is_LR_dir'])\n",
    "laps_directional_marginals, laps_directional_all_epoch_bins_marginal, laps_most_likely_direction_from_decoder, laps_is_most_likely_direction_LR_dir  = laps_directional_marginals_tuple\n",
    "laps_track_identity_marginals, laps_track_identity_all_epoch_bins_marginal, laps_most_likely_track_identity_from_decoder, laps_is_most_likely_track_identity_Long = laps_track_identity_marginals_tuple\n",
    "non_marginalized_decoder_marginals, non_marginalized_decoder_all_epoch_bins_marginal, most_likely_decoder_idxs, non_marginalized_decoder_all_epoch_bins_decoder_probs_df = laps_non_marginalized_decoder_marginals_tuple\n",
    "laps_time_bin_marginals_df: pd.DataFrame = all_directional_laps_filter_epochs_decoder_result.build_per_time_bin_marginals_df(active_marginals_tuple=(laps_directional_marginals, laps_track_identity_marginals, non_marginalized_decoder_marginals),\n",
    "                                                                                                                              columns_tuple=(['P_LR', 'P_RL'], ['P_Long', 'P_Short'], ['long_LR', 'long_RL', 'short_LR', 'short_RL']), transfer_column_names_list=transfer_column_names_list)\n",
    "laps_time_bin_marginals_df['start'] = laps_time_bin_marginals_df['start'] + TIME_OVERLAP_PREVENTION_EPSILON ## ENSURE NON-OVERLAPPING\n",
    "\n",
    "## INPUTS: laps_time_bin_marginals_df\n",
    "# active_min_num_unique_aclu_inclusions_requirement: int = track_templates.min_num_unique_aclu_inclusions_requirement(curr_active_pipeline, required_min_percentage_of_active_cells=0.33333333333333)\n",
    "active_min_num_unique_aclu_inclusions_requirement = None # must be none for individual `time_bin` periods\n",
    "filtered_laps_time_bin_marginals_df, active_spikes_df = co_filter_epochs_and_spikes(active_spikes_df=get_proper_global_spikes_df(curr_active_pipeline, minimum_inclusion_fr_Hz=curr_active_pipeline.global_computation_config.rank_order_shuffle_analysis.minimum_inclusion_fr_Hz),\n",
    "                                                                  active_epochs_df=laps_time_bin_marginals_df, included_aclus=track_templates.any_decoder_neuron_IDs, min_num_unique_aclu_inclusions=active_min_num_unique_aclu_inclusions_requirement,\n",
    "                                                                epoch_id_key_name='lap_individual_time_bin_id', no_interval_fill_value=-1, add_unique_aclus_list_column=True, drop_non_epoch_spikes=True)\n",
    "filtered_laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff8fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean and max number of active aclus per time bin for each epoch (lap)\n",
    "filtered_laps_time_bin_marginals_df.groupby(['lap_id']).agg(n_unique_aclus_mean=('n_unique_aclus', 'mean'), n_unique_aclus_max=('n_unique_aclus', 'max')).reset_index()\n",
    "filtered_laps_time_bin_marginals_df.groupby(['maze_id']).agg(n_unique_aclus_mean=('n_unique_aclus', 'mean'), n_unique_aclus_max=('n_unique_aclus', 'max')).reset_index() ## per maze\n",
    "filtered_laps_time_bin_marginals_df.groupby(['maze_id', 'lap_dir']).agg(n_unique_aclus_mean=('n_unique_aclus', 'mean'), n_unique_aclus_max=('n_unique_aclus', 'max')).reset_index() # per maze x lap_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e6cdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cb39d3",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# {frozenset({('desired_shared_decoding_time_bin_size', 0.025), ('minimum_event_duration', 0.05), ('use_single_time_bin_per_epoch', False)}): 0.025,\n",
    "#  frozenset({('desired_shared_decoding_time_bin_size', 0.03), ('minimum_event_duration', 0.05), ('use_single_time_bin_per_epoch', False)}): 0.03,\n",
    "#  frozenset({('desired_shared_decoding_time_bin_size', 0.044), ('minimum_event_duration', 0.05), ('use_single_time_bin_per_epoch', False)}): 0.044,\n",
    "#  frozenset({('desired_shared_decoding_time_bin_size', 0.05), ('minimum_event_duration', 0.05), ('use_single_time_bin_per_epoch', False)}): 0.05}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d4ce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_trial_by_trial_result.directional_active_lap_pf_results_dicts\n",
    "a_trial_by_trial_result.directional_lap_epochs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944c59a0",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "several_time_bin_sizes_ripple_df\n",
    "\n",
    "ripple_out_path # 'K:/scratch/collected_outputs/2024-07-05-kdiba_gor01_two_2006-6-07_16-40-19__withNewKamranExportedReplays-(ripple_marginals_df).csv'\n",
    "# 'K:/scratch/collected_outputs/2024-07-05-kdiba_gor01_two_2006-6-07_16-40-19__withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-(ripple_marginals_df).csv'\n",
    "several_time_bin_sizes_time_bin_ripple_df\n",
    "\n",
    "ripple_time_bin_marginals_out_path # 'K:/scratch/collected_outputs/2024-07-05-kdiba_gor01_two_2006-6-07_16-40-19__withNewKamranExportedReplays-(ripple_time_bin_marginals_df).csv'\n",
    "# 'K:/scratch/collected_outputs/2024-07-05-kdiba_gor01_two_2006-6-07_16-40-19__withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-(ripple_time_bin_marginals_df).csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2dfa3e",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "v: DecoderDecodedEpochsResult = list(output_directional_decoders_epochs_decode_results_dict.values())[0]\n",
    "v.add_all_extra_epoch_columns(curr_active_pipeline=curr_active_pipeline, track_templates=track_templates)\n",
    "# _out = v.export_csvs(parent_output_path=collected_outputs_path, active_context=curr_active_pipeline.get_session_context(), session_name=curr_active_pipeline.session_name, curr_session_t_delta=t_delta)\n",
    "\n",
    "# assert self.collected_outputs_path.exists()\n",
    "# curr_session_name: str = curr_active_pipeline.session_name # '2006-6-08_14-26-15'\n",
    "# CURR_BATCH_OUTPUT_PREFIX: str = f\"{self.BATCH_DATE_TO_USE}-{curr_session_name}\"\n",
    "# print(f'CURR_BATCH_OUTPUT_PREFIX: {CURR_BATCH_OUTPUT_PREFIX}')\n",
    "\n",
    "# from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_extended_computations\n",
    "# curr_active_pipeline.reload_default_computation_functions()\n",
    "# batch_extended_computations(curr_active_pipeline, include_includelist=['merged_directional_placefields'], include_global_functions=True, fail_on_exception=True, force_recompute=False)\n",
    "# directional_merged_decoders_result = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "\n",
    "# active_context = curr_active_pipeline.get_session_context()\n",
    "# _out = directional_merged_decoders_result.compute_and_export_marginals_df_csvs(parent_output_path=self.collected_outputs_path, active_context=active_context)\n",
    "# print(f'successfully exported marginals_df_csvs to {self.collected_outputs_path}!')\n",
    "# (laps_marginals_df, laps_out_path), (ripple_marginals_df, ripple_out_path) = _out\n",
    "# (laps_marginals_df, laps_out_path, laps_time_bin_marginals_df, laps_time_bin_marginals_out_path), (ripple_marginals_df, ripple_out_path, ripple_time_bin_marginals_df, ripple_time_bin_marginals_out_path) = _out\n",
    "# print(f'\\tlaps_out_path: {laps_out_path}\\n\\tripple_out_path: {ripple_out_path}\\n\\tdone.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58b6311",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa94d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "_across_session_results_extended_dict['perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260a8b74",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "## Take extra computations from `_decode_and_evaluate_epochs_using_directional_decoders` and integrate into the multi-time-bin results from `perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _compute_all_df_score_metrics\n",
    "\n",
    "should_skip_radon_transform = True\n",
    "## Recompute the epoch scores/metrics such as radon transform and wcorr:\n",
    "\n",
    "a_sweep_tuple, a_pseudo_2D_result = list(output_full_directional_merged_decoders_result.items())[0]\n",
    "a_decoder_laps_filter_epochs_decoder_result_dict = deepcopy(a_pseudo_2D_result.all_directional_laps_filter_epochs_decoder_result)\n",
    "a_decoder_ripple_filter_epochs_decoder_result_dict = deepcopy(a_pseudo_2D_result.all_directional_ripple_filter_epochs_decoder_result)\n",
    "\n",
    "(decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict), merged_df_outputs_tuple, raw_dict_outputs_tuple = _compute_all_df_score_metrics(directional_merged_decoders_result, track_templates,\n",
    "                                                                                                                                                                                    decoder_laps_filter_epochs_decoder_result_dict=a_decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict=a_decoder_ripple_filter_epochs_decoder_result_dict,\n",
    "                                                                                                                                                                                    spikes_df=deepcopy(curr_active_pipeline.sess.spikes_df),\n",
    "                                                                                                                                                                                    should_skip_radon_transform=should_skip_radon_transform)\n",
    "laps_radon_transform_merged_df, ripple_radon_transform_merged_df, laps_weighted_corr_merged_df, ripple_weighted_corr_merged_df, laps_simple_pf_pearson_merged_df, ripple_simple_pf_pearson_merged_df = merged_df_outputs_tuple\n",
    "decoder_laps_radon_transform_df_dict, decoder_ripple_radon_transform_df_dict, decoder_laps_radon_transform_extras_dict, decoder_ripple_radon_transform_extras_dict, decoder_laps_weighted_corr_df_dict, decoder_ripple_weighted_corr_df_dict = raw_dict_outputs_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfda868",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# `_perform_compute_custom_epoch_decoding`\n",
    "\n",
    "a_sweep_tuple\n",
    "# a_pseudo_2D_result.all_directional_laps_filter_epochs_decoder_result\n",
    "# a_pseudo_2D_result\n",
    "# a_pseudo_2D_result.short_directional_decoder_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9603a0",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# print_keys_if_possible('several_time_bin_sizes_laps_df', several_time_bin_sizes_laps_df)\n",
    "print_keys_if_possible('output_full_directional_merged_decoders_result', output_full_directional_merged_decoders_result, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a71abd",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# get_file_pat\n",
    "collected_outputs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c0f606",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "output_laps_decoding_accuracy_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dd6f87",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# from neuropy.utils.matplotlib_helpers import pho_jointplot\n",
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import pho_jointplot, plot_histograms\n",
    "sns.set_theme(style=\"ticks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4b238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# from neuropy.utils.matplotlib_helpers import pho_jointplot\n",
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import pho_jointplot, plot_histograms\n",
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "# def pho_jointplot(*args, **kwargs):\n",
    "# \t\"\"\" wraps sns.jointplot to allow adding titles/axis labels/etc.\"\"\"\n",
    "# \ttitle = kwargs.pop('title', None)\n",
    "# \t_out = sns.jointplot(*args, **kwargs)\n",
    "# \tif title is not None:\n",
    "# \t\tplt.suptitle(title)\n",
    "# \treturn _out\n",
    "\n",
    "common_kwargs = dict(ylim=(0,1), hue='time_bin_size') # , marginal_kws=dict(bins=25, fill=True)\n",
    "# sns.jointplot(data=a_laps_all_epoch_bins_marginals_df, x='lap_start_t', y='P_Long', kind=\"scatter\", color=\"#4CB391\")\n",
    "pho_jointplot(data=several_time_bin_sizes_laps_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Laps: per epoch') #color=\"#4CB391\")\n",
    "pho_jointplot(data=several_time_bin_sizes_ripple_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Ripple: per epoch')\n",
    "pho_jointplot(data=several_time_bin_sizes_time_bin_ripple_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Ripple: per time bin')\n",
    "pho_jointplot(data=several_time_bin_sizes_time_bin_laps_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Laps: per time bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43311ee",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import plot_histograms\n",
    "\n",
    "# You can use it like this:\n",
    "plot_histograms('Laps', 'One Session', several_time_bin_sizes_time_bin_laps_df, \"several\")\n",
    "plot_histograms('Ripples', 'One Session', several_time_bin_sizes_time_bin_ripple_df, \"several\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a33b924",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "several_time_bin_sizes_ripple_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2a9d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.displot(\n",
    "#     several_time_bin_sizes_laps_df, x=\"P_Long\", col=\"species\", row=\"time_bin_size\",\n",
    "#     binwidth=3, height=3, facet_kws=dict(margin_titles=True),\n",
    "# )\n",
    "\n",
    "sns.displot(\n",
    "    several_time_bin_sizes_laps_df, x='delta_aligned_start_t', y='P_Long', row=\"time_bin_size\",\n",
    "    binwidth=3, height=3, facet_kws=dict(margin_titles=True),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495ef2bb",
   "metadata": {},
   "source": [
    "# <a id='toc7_'></a>[🎨 2024-02-06 - Other Plotting](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5623a2",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": [
     "all",
     "run-group-display",
     "run-spike_raster_window_test",
     "2025-04-11 - full-session marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.TimeSynchronizedPlacefieldsPlotter import TimeSynchronizedPlacefieldsPlotter\n",
    "\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "\n",
    "#  Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "curr_active_pipeline.prepare_for_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83293544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots\n",
    "\n",
    "_out = batch_perform_all_plots(curr_active_pipeline, debug_print=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86d59de",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968df7ce",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Display import DisplayFunctionItem\n",
    "from pyphocorehelpers.gui.Qt.tree_helpers import find_tree_item_by_text\n",
    "from pyphoplacecellanalysis.GUI.Qt.MainApplicationWindows.LauncherWidget.LauncherWidget import LauncherWidget\n",
    "\n",
    "widget = LauncherWidget()\n",
    "# widget.debug_print = True\n",
    "treeWidget = widget.mainTreeWidget # QTreeWidget\n",
    "widget.build_for_pipeline(curr_active_pipeline=curr_active_pipeline)\n",
    "widget.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b653dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = dict()\n",
    "_out['_display_directional_laps_overview'] = curr_active_pipeline.display(display_function='_display_directional_laps_overview', active_session_configuration_context=None) # _display_directional_laps_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce79ac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import perform_add_1D_track_bounds_lines\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out = dict()\n",
    "_out['_display_grid_bin_bounds_validation_y'] = curr_active_pipeline.display(display_function='_display_grid_bin_bounds_validation', active_session_configuration_context=None, is_x_axis=False) # _display_grid_bin_bounds_validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465a1575",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out['_display_grid_bin_bounds_validation_x'] = curr_active_pipeline.display(display_function='_display_grid_bin_bounds_validation', active_session_configuration_context=None, is_x_axis=True) # _display_grid_bin_bounds_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6595b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps).trimmed_to_non_overlapping() \n",
    "global_laps_epochs_df = global_laps.to_dataframe()\n",
    "_out_ripple_rasters: RankOrderRastersDebugger = RankOrderRastersDebugger.init_rank_order_debugger(global_spikes_df, deepcopy(global_laps_epochs_df),\n",
    "                                                                                                track_templates, None,\n",
    "                                                                                                None, None,\n",
    "                                                                                                dock_add_locations = dict(zip(('long_LR', 'long_RL', 'short_LR', 'short_RL'), (['right'], ['right'], ['right'], ['right']))),\n",
    "                                                                                                )\n",
    "_out_ripple_rasters.set_top_info_bar_visibility(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed34de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.Extensions.pyqtgraph_helpers import LayoutScrollability, pyqtplot_build_image_bounds_extent\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.TemplateDebugger import BaseTemplateDebuggingMixin, build_pf1D_heatmap_with_labels_and_peaks, TrackTemplates\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.BinByBinDecodingDebugger import BinByBinDecodingDebugger \n",
    "\n",
    "# Example usage:\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps).trimmed_to_non_overlapping() \n",
    "global_laps_epochs_df = global_laps.to_dataframe()\n",
    "global_laps_epochs_df\n",
    "\n",
    "## INPUTS: \n",
    "time_bin_size: float = 0.250\n",
    "a_lap_id: int = 9\n",
    "a_decoder_name = 'long_LR'\n",
    "epoch_id_col_name = 'lap_id'\n",
    "## COMPUTED: \n",
    "a_decoder_idx: int = track_templates.get_decoder_names().index(a_decoder_name)\n",
    "a_decoder = deepcopy(track_templates.long_LR_decoder)\n",
    "(_out_decoded_time_bin_edges, _out_decoded_unit_specific_time_binned_spike_counts, _out_decoded_active_unit_lists, _out_decoded_active_p_x_given_n, _out_decoded_active_plots_data) = BinByBinDecodingDebugger.build_spike_counts_and_decoder_outputs(a_decoder=a_decoder, epochs_df=global_laps_epochs_df, spikes_df=global_spikes_df, epoch_id_col_name=epoch_id_col_name, time_bin_size=time_bin_size)\n",
    "win, out_pf1D_decoder_template_objects, (_out_decoded_active_plots, _out_decoded_active_plots_data) = BinByBinDecodingDebugger.build_time_binned_decoder_debug_plots(a_decoder=a_decoder, an_epoch_id=a_lap_id, _out_decoded_time_bin_edges=_out_decoded_time_bin_edges, _out_decoded_active_p_x_given_n=_out_decoded_active_p_x_given_n,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  _out_decoded_active_unit_lists=_out_decoded_active_unit_lists, _out_decoded_active_plots_data=_out_decoded_active_plots_data, debug_print=True)\n",
    "\n",
    "## All-in-one mode:\n",
    "# win, out_pf1D_decoder_template_objects, (_out_decoded_active_plots, _out_decoded_active_plots_data) = BinByBinDecodingDebugger.plot_bin_by_bin_decoding_example(curr_active_pipeline=curr_active_pipeline, track_templates=track_templates, time_bin_size=time_bin_size, a_lap_id=a_lap_id, a_decoder_name=a_decoder_name)\n",
    "\n",
    "print(f\"Returned window: {win}\")\n",
    "print(f\"Returned decoder objects: {out_pf1D_decoder_template_objects}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345ec76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_cm_x_grid_bin_bounds\n",
    "\n",
    "global_session.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e03666",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pf1D_decoder_template_objects[0].plots_data.spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe2e4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lap_specific_spikes_df = _out_decoded_active_plots_data[a_lap_id].spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb7178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_plot = plots['root_plot']\n",
    "# Create a vertical line at x=3\n",
    "v_line = CustomInfiniteLine(pos=0.0, angle=90, pen=pg.mkPen('r', width=2), label='first lap spike')\n",
    "root_plot.addItem(v_line)\n",
    "plots['v_line'] = v_line\n",
    "\n",
    "## Set Labels\n",
    "# plots['root_plot'].set_xlabel('First PBE spike relative to first lap spike (t=0)')\n",
    "# plots['root_plot'].set_ylabel('Cell')\n",
    "plots['root_plot'].setTitle(\"First PBE spike relative to first lap spike (t=0)\", color='white', size='24pt')\n",
    "# plots['root_plot'].setLabel('top', 'First PBE spike relative to first lap spike (t=0)', size='22pt') # , color='blue'\n",
    "plots['root_plot'].setLabel('left', 'Cell ID', color='white', size='12pt') # , units='V', color='red'\n",
    "plots['root_plot'].setLabel('bottom', 'Time (relative to first lap spike for each cell)', color='white', units='s', size='12pt') # , color='blue'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f9d837",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_lap_id: int = 6\n",
    "# time_bin_edges = _out_decoded_unit_specific_time_binned_spike_counts[a_lap_id]\n",
    "time_bin_edges = _out_decoded_time_bin_edges[a_lap_id]\n",
    "n_epoch_time_bins: int = len(time_bin_edges) - 1\n",
    "print(f'a_lap_id: {a_lap_id}, n_epoch_time_bins: {n_epoch_time_bins}')\n",
    "\n",
    "## INPUTS: a_lap_id, an_img_extents, _out_decoded_unit_specific_time_binned_spike_counts, _out_decoded_active_unit_lists\n",
    "# Create a main GraphicsLayoutWidget\n",
    "win = pg.GraphicsLayoutWidget()\n",
    "\n",
    "# Store plot references\n",
    "plots = []\n",
    "out_pf1D_decoder_template_objects = []\n",
    "\n",
    "# Add a single plot that spans the entire width\n",
    "# spanning_plot = pg.PlotItem(title=\"Spanning Plot\")\n",
    "# win.addItem(spanning_plot, row=win.ci.rowCount() - 1, col=0, colspan=n_epoch_time_bins)\n",
    "spanning_posterior_plot = win.addPlot(title=\"P_x_given_n Plot\", row=0, rowspan=1, col=0, colspan=n_epoch_time_bins)  # Add the plot , col=0\n",
    "spanning_posterior_plot.setTitle(\"P_x_given_n Plot - Covers Entire Width\")\n",
    "\n",
    "most_likely_positions, p_x_given_n, most_likely_position_indicies, flat_outputs_container = _out_decoded_active_p_x_given_n[a_lap_id] ## UNPACK\n",
    "\n",
    "# _obj.pf1D_heatmap\n",
    "flat_p_x_given_n = deepcopy(p_x_given_n) #active_lap_decoded_pos_outputs['flat_p_x_given_n']\n",
    "# most_likely_position_flat_indicies = active_lap_decoded_pos_outputs['most_likely_position_flat_indicies']\n",
    "img_item = _simply_plot_posterior_in_pyqtgraph_plotitem(curr_plot=spanning_posterior_plot, image=flat_p_x_given_n, xbin_edges=np.arange(n_epoch_time_bins+1), ybin_edges=deepcopy(a_decoder.xbin))\n",
    "\n",
    "win.nextRow()  # Move to the next row\n",
    "\n",
    "\n",
    "## Get data\n",
    "active_bin_unit_specific_time_binned_spike_counts = _out_decoded_unit_specific_time_binned_spike_counts[a_lap_id]\n",
    "active_lap_active_aclu_spike_counts_list = _out_decoded_active_unit_lists[a_lap_id]\n",
    "active_lap_decoded_pos_outputs = _out_decoded_active_p_x_given_n[a_lap_id]\n",
    "# Add PlotItems to the layout horizontally\n",
    "# Add n_epoch_time_bins plots to the first row\n",
    "for a_time_bin_idx in np.arange(n_epoch_time_bins):\n",
    "    active_bin_active_aclu_spike_counts_dict = active_lap_active_aclu_spike_counts_list[a_time_bin_idx]\n",
    "    active_bin_active_aclu_spike_count_values = np.array(list(active_bin_active_aclu_spike_counts_dict.values()))\n",
    "    active_bin_active_aclu_bin_normalized_spike_count_values = active_bin_active_aclu_spike_count_values / np.sum(active_bin_active_aclu_spike_count_values) # relative number of spikes ... todo.. prioritizes high-firing\n",
    "    aclu_override_alpha_weights = 0.8 + (0.2 * active_bin_active_aclu_bin_normalized_spike_count_values) # ensure the items are at least 0.8 opaque, and allow them to scale between 0.8-1.0\n",
    "    \n",
    "    active_bin_aclus = np.array(list(active_bin_active_aclu_spike_counts_dict.keys()))\n",
    "    # active_aclu_override_alpha_weights_dict = dict(zip(active_bin_aclus, active_bin_active_aclu_bin_normalized_spike_count_values))\n",
    "    active_solo_override_num_spikes_weights = dict(zip(active_bin_aclus, active_bin_active_aclu_bin_normalized_spike_count_values))\n",
    "    active_aclu_override_alpha_weights_dict = dict(zip(active_bin_aclus, aclu_override_alpha_weights))\n",
    "    print(f'a_time_bin_idx: {a_time_bin_idx}/{n_epoch_time_bins} - active_bin_aclus: {active_bin_aclus}')\n",
    "    ## build the plot:\n",
    "    # plot = win.addPlot(title=f\"Plot {a_time_bin_idx+1}\")\n",
    "    plot = win.addPlot(title=f\"Plot {a_time_bin_idx+1}\", row=1, rowspan=1, col=a_time_bin_idx, colspan=1)\n",
    "    plot.getViewBox().setBorder(color=(200, 200, 200), width=1)  # Red border, 2px thick\n",
    "    # Enable the grid only along the x-axis\n",
    "    spanning_posterior_plot.showGrid(x=True, y=True)\n",
    "    # Set the x-axis tick spacing to 1 unit\n",
    "    x_axis = spanning_posterior_plot.getAxis('bottom')\n",
    "    x_axis.setTickSpacing(major=5, minor=1)  # Set major tick intervals to 1 unit\n",
    "\n",
    "    plots.append(plot)  # Store the reference\n",
    "    # curr_img, out_colors_heatmap_image_matrix = build_pf1D_heatmap_with_labels_and_peaks(pf1D_decoder=a_decoder, visible_aclus=active_bin_aclus, plot_item=plot, img_extents_rect=an_img_extents, a_decoder_aclu_to_color_map=a_decoder_aclu_to_color_map)\n",
    "    # _obj = BaseTemplateDebuggingMixin.init_from_decoder(a_decoder=a_decoder, win=win)\n",
    "    _obj = BaseTemplateDebuggingMixin.init_from_decoder(a_decoder=a_decoder, win=plot)\n",
    "    _obj.update_base_decoder_debugger_data(included_neuron_ids=active_bin_aclus, solo_override_alpha_weights=active_aclu_override_alpha_weights_dict, solo_override_num_spikes_weights=active_solo_override_num_spikes_weights)\n",
    "    out_pf1D_decoder_template_objects.append(_obj)  # Store the reference\n",
    "    \n",
    "    # active_bin_active_aclu_bin_normalized_spike_count_values\n",
    "    \n",
    "    # if a_time_bin_idx < (n_epoch_time_bins - 1):\n",
    "    #     win.nextColumn()  # Move to the next column for horizontal layout\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# Add a new row with a single plot spanning the entire width\n",
    "win.nextRow()  # Move to the next row\n",
    "# # Add a single plot that spans the entire width\n",
    "# # spanning_plot = pg.PlotItem(title=\"Spanning Plot\")\n",
    "# # win.addItem(spanning_plot, row=win.ci.rowCount() - 1, col=0, colspan=n_epoch_time_bins)\n",
    "# spanning_plot = win.addPlot(title=\"Spanning Plot\", colspan=n_epoch_time_bins)  # Add the plot , col=0\n",
    "# spanning_plot.setTitle(\"Spanning Plot - Covers Entire Width\")\n",
    "\n",
    "# most_likely_positions, p_x_given_n, most_likely_position_indicies, flat_outputs_container = _out_decoded_active_p_x_given_n[a_lap_id] ## UNPACK\n",
    "\n",
    "# # _obj.pf1D_heatmap\n",
    "# flat_p_x_given_n = deepcopy(p_x_given_n) #active_lap_decoded_pos_outputs['flat_p_x_given_n']\n",
    "# # most_likely_position_flat_indicies = active_lap_decoded_pos_outputs['most_likely_position_flat_indicies']\n",
    "# img_item = _simply_plot_posterior_in_pyqtgraph_plotitem(curr_plot=spanning_plot, image=flat_p_x_given_n, xbin_edges=np.arange(n_epoch_time_bins+1), ybin_edges=deepcopy(a_decoder.xbin))\n",
    "\n",
    "# Show the layout\n",
    "win.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb562f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable the grid only along the x-axis\n",
    "spanning_posterior_plot.showGrid(x=True, y=True)\n",
    "# Set the x-axis tick spacing to 1 unit\n",
    "x_axis = spanning_posterior_plot.getAxis('bottom')\n",
    "x_axis.setTickSpacing(major=5, minor=1)  # Set major tick intervals to 1 unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31b3422",
   "metadata": {},
   "outputs": [],
   "source": [
    "spanning_posterior_plot.showGrid(True, True, 0.7)\n",
    "# Adjust the view to ensure the image fills the entire plot width\n",
    "spanning_posterior_plot.setAspectLocked(False)  # Allow non-uniform scaling\n",
    "spanning_posterior_plot.getViewBox().setLimits(xMin=0, xMax=your_image_data.shape[1], yMin=0, yMax=your_image_data.shape[0])\n",
    "\n",
    "# Scale the image to fill the entire width\n",
    "spanning_posterior_plot.getViewBox().enableAutoRange()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25283bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch_time_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1529c71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = dict()\n",
    "_out['_display_directional_merged_pfs'] = curr_active_pipeline.display(display_function='_display_directional_merged_pfs', active_session_configuration_context=None) # _display_directional_merged_pfs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece249c2",
   "metadata": {},
   "source": [
    "n_epoch_time_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721d7f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "win.nextRow()\n",
    "lbl = win.addLabel(text='HUGE', colspan=n_epoch_time_bins) # , row=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a0506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the span to cover all columns in the row\n",
    "win.ci.layout.setRowStretchFactor(win.ci.rowCount() - 1, 1)  # Adjust the stretch factor for the new row\n",
    "win.ci.layout.setColumnStretchFactor(0, n_epoch_time_bins)   # Ensure it spans all columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f91cc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "spanning_plot2 = win.addPlot(title=\"Spanning Plot3\", row=1, rowspan=1, col=0, colspan=n_epoch_time_bins)  # Add the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7a808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spanning_plot2.setTitle(\"Spanning Plot - Covers Entire Width\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f611651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the span to cover all columns in the row\n",
    "win.ci.layout.setRowStretchFactor(win.ci.rowCount() - 1, 1)  # Adjust the stretch factor for the new row\n",
    "win.ci.layout.setColumnStretchFactor(0, n_epoch_time_bins)   # Ensure it spans all columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cae0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.decoder_difference import display_predicted_position_difference\n",
    "\n",
    "active_computed_data = curr_active_pipeline.computation_results[global_epoch_name]\n",
    "active_resampled_pos_df = active_computed_data.extended_stats.time_binned_position_df.copy() # active_computed_data.extended_stats.time_binned_position_df  # 1717 rows × 16 columns\n",
    "active_resampled_measured_positions = active_resampled_pos_df[['x','y']].to_numpy() # The measured positions resampled (interpolated) at the window centers. \n",
    "display_predicted_position_difference(active_one_step_decoder, active_two_step_decoder, active_resampled_measured_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd6298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(p_x_given_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1738f798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.TemplateDebugger import BaseTemplateDebuggingMixin, build_pf1D_heatmap_with_labels_and_peaks, TrackTemplates\n",
    "\n",
    "_obj = BaseTemplateDebuggingMixin.init_from_decoder(a_decoder=a_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe064948",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "curr_img, out_colors_heatmap_image_matrix = build_pf1D_heatmap_with_labels_and_peaks(pf1D_decoder=a_decoder, visible_aclus=active_bin_aclus, plot_item=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c18797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.TemplateDebugger import TemplateDebugger\n",
    "\n",
    "_out_TemplateDebugger: TemplateDebugger = TemplateDebugger.init_templates_debugger(track_templates) # , included_any_context_neuron_ids\n",
    "\n",
    "# _out_ui.root_dockAreaWindow\n",
    "# _out_ui.dock_widgets[a_decoder_name]\n",
    "\n",
    "## Plots:\n",
    "# _out_plots.pf1D_heatmaps[a_decoder_name] = visualize_heatmap_pyqtgraph(curr_curves, title=title_str, show_value_labels=False, show_xticks=False, show_yticks=False, show_colorbar=False, win=None, defer_show=True) # Sort to match first decoder (long_LR)\n",
    "# Adds aclu text labels with appropriate colors to y-axis: uses `sorted_shared_sort_neuron_IDs`:\n",
    "# curr_win, curr_img = _out_plots.pf1D_heatmaps[a_decoder_name] # win, img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eecf66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: \n",
    "a_decoder_aclu_to_color_map = deepcopy(_out_TemplateDebugger.plots_data['sort_helper_neuron_id_to_neuron_colors_dicts'][a_decoder_idx])\n",
    "a_decoder_aclu_to_color_map\n",
    "# _out_TemplateDebugger.plots_data['out_colors_heatmap_image_matrix_dicts'][a_decoder_idx]\n",
    "an_img_extents = deepcopy(_out_TemplateDebugger.plots_data['active_pfs_img_extents_dict'])[a_decoder_name] # [0.0, 0, 289.2117008543986, 35.0]\n",
    "an_img_extents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0aa9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out_TemplateDebugger.params\n",
    "# _out_TemplateDebugger.plots_data.data_keys\n",
    "\n",
    "a_decoder_name\n",
    "\n",
    "\n",
    "a_decoder_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd155ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd6e7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time_bin_size: float = 0.500 # 500ms\n",
    "t_start = 0.0\n",
    "t_end = 2093.8978568242164\n",
    "_decoded_pos_outputs, (unit_specific_time_binned_spike_counts, time_bin_edges, spikes_df) = easy_independent_decoding(long_LR_decoder, spikes_df=spikes_df, time_bin_size=time_bin_size, t_start=t_start, t_end=t_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9e1715",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_template_debugger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9851ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_t_bin_idx: int = 0\n",
    "# active_aclus_list = _out_decoded_active_unit_lists[a_row.lap_id][a_t_bin_idx]\n",
    "\n",
    "_out_TemplateDebugger.update_cell_emphasis(solo_emphasized_aclus=active_bin_aclus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4173061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_TemplateDebugger.pf1D_heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b761e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.indexing_helpers import compute_paginated_grid_config\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.pyqtplot_common import pyqtplot_common_setup\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.Extensions.pyqtgraph_helpers import LayoutScrollability, pyqtplot_build_image_bounds_extent, set_small_title\n",
    "from neuropy.utils.matplotlib_helpers import _scale_current_placefield_to_acceptable_range, _build_neuron_identity_label # for display_all_pf_2D_pyqtgraph_binned_image_rendering\n",
    "from pyphocorehelpers.gui.Qt.color_helpers import ColormapHelpers\n",
    "\n",
    "class HeatmapLayout(pg.QtWidgets.QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Create layout\n",
    "        layout = pg.QtWidgets.QVBoxLayout(self)\n",
    "        layout.setContentsMargins(0, 0, 0, 0)\n",
    "        layout.setSpacing(0)\n",
    "        \n",
    "        # Top row: variable number of heatmaps\n",
    "        self.top_row = pg.GraphicsLayoutWidget()\n",
    "        self.top_row.setContentsMargins(0, 0, 0, 0)\n",
    "        self.top_plots = []\n",
    "        layout.addWidget(self.top_row)\n",
    "\n",
    "        # Bottom row: single heatmap\n",
    "        self.bottom_row = pg.GraphicsLayoutWidget()\n",
    "        self.bottom_row.setContentsMargins(0, 0, 0, 0)\n",
    "        self.bottom_plot = self.bottom_row.addPlot()\n",
    "        self.bottom_plot.setContentsMargins(0, 0, 0, 0)\n",
    "        self.bottom_img = pg.ImageItem()\n",
    "        self.bottom_plot.addItem(self.bottom_img)\n",
    "        layout.addWidget(self.bottom_row)\n",
    "        \n",
    "        # Style plots\n",
    "        for p in [self.bottom_plot]:\n",
    "            p.showAxis('left', True)\n",
    "            p.showAxis('bottom', True)\n",
    "            p.getAxis('left').setLabel(\"Y-Axis\")\n",
    "            p.getAxis('bottom').setLabel(\"X-Axis\")\n",
    "            p.setContentsMargins(0, 0, 0, 0)\n",
    "            p.setDefaultPadding(0)\n",
    "            \n",
    "\n",
    "    def update_top_heatmaps(self, data_list):\n",
    "        self.top_row.clear()\n",
    "        self.top_plots = []\n",
    "        for data in data_list:\n",
    "            plot = self.top_row.addPlot()\n",
    "            plot.setContentsMargins(0, 0, 0, 0)\n",
    "            plot.setDefaultPadding(0)\n",
    "            img = pg.ImageItem(data)\n",
    "            plot.addItem(img)\n",
    "            plot.showAxis('left', True)\n",
    "            plot.getAxis('left').setLabel(\"Y-Axis\")\n",
    "            plot.hideAxis('bottom')\n",
    "            self.top_plots.append(plot)\n",
    "            self.top_row.nextRow()\n",
    "\n",
    "    def update_bottom_heatmap(self, data):\n",
    "        self.bottom_img.setImage(data)\n",
    "\n",
    "## Testing\n",
    "window = pg.QtWidgets.QMainWindow()\n",
    "widget = HeatmapLayout()\n",
    "\n",
    "# Example data\n",
    "top_data_list = [np.random.rand(10, 10), np.random.rand(15, 10)]\n",
    "bottom_data = np.random.rand(20, 20)\n",
    "\n",
    "widget.update_top_heatmaps(top_data_list)\n",
    "widget.update_bottom_heatmap(bottom_data)\n",
    "\n",
    "window.setCentralWidget(widget)\n",
    "window.resize(800, 600)\n",
    "window.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99251ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parent_root_widget = None\n",
    "root_render_widget = None\n",
    "# Need to go from (n_epochs, n_neurons, n_pos_bins) -> (n_neurons, n_xbins, n_ybins)\n",
    "n_epochs, n_neurons, n_pos_bins = np.shape(z_scored_tuning_map_matrix)\n",
    "images = z_scored_tuning_map_matrix.transpose(1, 2, 0) # (71, 57, 22)\n",
    "xbin_edges=active_one_step_decoder.xbin\n",
    "assert (len(xbin_edges)-1) == n_pos_bins, f\"n_pos_bins: {n_pos_bins}, len(xbin_edges): {len(xbin_edges)} \"\n",
    "# ybin_edges=active_one_step_decoder.ybin\n",
    "ybin_edges = np.arange(n_epochs+1) - 0.5 # correct ybin_edges are n_epochs\n",
    "root_render_widget, parent_root_widget, app = pyqtplot_common_setup(f'TrialByTrialActivityArray: {np.shape(images)}', app=app, parent_root_widget=parent_root_widget, root_render_widget=root_render_widget) ## 🚧 TODO: BUG: this makes a new QMainWindow to hold this item, which is inappropriate if it's to be rendered as a child of another control\n",
    "\n",
    "pg.setConfigOptions(imageAxisOrder='col-major') # this causes the placefields to be rendered horizontally, like they were in _temp_pyqtplot_plot_image_array\n",
    "\n",
    "\n",
    "\n",
    "## build pg.GraphicsLayoutWidget(...) required to hold the decoding preview\n",
    "root = pg.GraphicsLayoutWidget(title='Decoding Example')\n",
    "\n",
    "\n",
    "root.addItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b18f74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.SpecificComputationValidation import SpecificComputationValidator\n",
    "\n",
    "def _build_default_required_computation_keys_computation_validator_fn_factory():\n",
    "    def _subfn(curr_active_pipeline, computation_filter_name='maze'):\n",
    "        has_all_required_local_keys: bool = np.all(np.isin((a_fn_callable.input_requires or []),  list(curr_active_pipeline.computation_results[computation_filter_name].computed_data.keys())))\n",
    "        has_all_required_global_keys: bool = np.all(np.isin((a_fn_callable.requires_global_keys or []),  list(curr_active_pipeline.global_computation_results.computed_data.keys())))\n",
    "        has_all_required_keys: bool = (has_all_required_local_keys and has_all_required_global_keys)\n",
    "        return has_all_required_keys\n",
    "    return _subfn\n",
    "\n",
    "\n",
    "should_use_nice_display_names: bool = False\n",
    "display_function_items = widget.get_display_function_items()\n",
    "display_fn_validators_dict = {}\n",
    "\n",
    "for a_fcn_name, a_disp_fn_item in display_function_items.items():\n",
    "    # extract the info from the function:\n",
    "    # if hasattr(a_fcn, 'short_name') and a_fcn.short_name is not None:\n",
    "    #     active_name = a_fcn.short_name or a_fcn_name\n",
    "    # else:\n",
    "    #     active_name = a_fcn_name\n",
    "\n",
    "    # active_name: str = a_disp_fn_item.name\n",
    "    if should_use_nice_display_names:\n",
    "        active_name: str = a_disp_fn_item.best_display_name\n",
    "    else:\n",
    "        active_name: str = a_disp_fn_item.name # function name\n",
    "\n",
    "    a_fn_callable = a_disp_fn_item.fn_callable\n",
    "\n",
    "    if ((not hasattr(a_fn_callable, 'validate_computation_test')) or (a_fn_callable.validate_computation_test is None)):\n",
    "        a_fn_callable.validate_computation_test = _build_default_required_computation_keys_computation_validator_fn_factory()\n",
    "\n",
    "    display_fn_validators_dict[a_fcn_name] = SpecificComputationValidator.init_from_decorated_fn(a_fn_callable)\n",
    "    # a_disp_fn_item\n",
    "    # a_fn_handle = widget.curr_active_pipeline.plot.__getattr__(a_disp_fn_item.name)\n",
    "    # a_fn_handle\n",
    "\n",
    "    # a_validate_computation_test = lambda curr_active_pipeline, computation_filter_name='maze': (curr_active_pipeline.computation_results[computation_filter_name].computed_data['pf1D_Decoder'], curr_active_pipeline.computation_results[computation_filter_name].computed_data['pf2D_Decoder'])\n",
    "\n",
    "\n",
    "# display_function_items\n",
    "# a_fn_handle.\n",
    "display_fn_validators_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3bbc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "display_fn_validators_dict = {}\n",
    "\n",
    "\n",
    "{k:SpecificComputationValidator.init_from_decorated_fn(v) for k,v in self.registered_merged_computation_function_dict.items() if hasattr(v, 'validate_computation_test') and (v.validate_computation_test is not None)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d2c89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.computation_results['maze_any'].computed_data\n",
    "\n",
    "_out = curr_active_pipeline.display('_display_plot_marginal_1D_most_likely_position_comparisons', active_session_configuration_context='maze_any', most_likely_positions_mode='standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0170fae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out = dict()\n",
    "# _out['_display_1d_placefield_occupancy'] = curr_active_pipeline.display('_display_1d_placefield_occupancy') # _display_1d_placefield_occupancy\n",
    "\n",
    "# _out = dict()\n",
    "# _out['_display_1d_placefield_occupancy'] = curr_active_pipeline.display(display_function='_display_1d_placefield_occupancy', active_session_configuration_context='kdiba_gor01_one_2006-6-09_1-22-43_maze_any_any') # _display_1d_placefield_occupancy\n",
    "\n",
    "_out = dict()\n",
    "_out['_display_1d_placefield_occupancy'] = curr_active_pipeline.display(display_function='_display_1d_placefield_occupancy', active_session_configuration_context=IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43',filter_name='maze1_any',lap_dir='any'), plot_pos_bin_axes=False) # _display_1d_placefield_occupancy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce055b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsWidgets.EpochsEditorItem import EpochsEditor # perform_plot_laps_diagnoser\n",
    "\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_epoch_context, short_epoch_context, global_epoch_context = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_epoch_name, short_epoch_name, global_epoch_name)]\n",
    "long_epoch_obj, short_epoch_obj = [Epoch(curr_active_pipeline.sess.epochs.to_dataframe().epochs.label_slice(an_epoch_name.removesuffix('_any'))) for an_epoch_name in [long_epoch_name, short_epoch_name]] #TODO 2023-11-10 20:41: - [ ] Issue with getting actual Epochs from sess.epochs for directional laps: emerges because long_epoch_name: 'maze1_any' and the actual epoch label in curr_active_pipeline.sess.epochs is 'maze1' without the '_any' part.\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "\n",
    "# sess = curr_active_pipeline.sess\n",
    "sess = global_session\n",
    "\n",
    "# pos_df = sess.compute_position_laps() # ensures the laps are computed if they need to be:\n",
    "position_obj = deepcopy(sess.position)\n",
    "position_obj.compute_higher_order_derivatives()\n",
    "pos_df = position_obj.compute_smoothed_position_info(N=20) ## Smooth the velocity curve to apply meaningful logic to it\n",
    "pos_df = position_obj.to_dataframe()\n",
    "# Drop rows with missing data in columns: 't', 'velocity_x_smooth' and 2 other columns. This occurs from smoothing\n",
    "pos_df = pos_df.dropna(subset=['t', 'x_smooth', 'velocity_x_smooth', 'acceleration_x_smooth']).reset_index(drop=True)\n",
    "curr_laps_df = sess.laps.to_dataframe()\n",
    "curr_laps_df\n",
    "epochs_editor = EpochsEditor.init_laps_diagnoser(pos_df, curr_laps_df, include_velocity=True, include_accel=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1b2f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show step-by-step how the decoder works\n",
    "\n",
    "## Show pseudo2D merged placefields:\n",
    "_out = dict()\n",
    "_out['_display_directional_merged_pfs'] = curr_active_pipeline.display(display_function='_display_directional_merged_pfs', active_session_configuration_context=None) # _display_directional_merged_pfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6c97ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.sess.neurons\n",
    "\n",
    "# co_filter_epochs_and_spikes("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed02317",
   "metadata": {},
   "source": [
    "### <a id='toc7_1_1_'></a>[2025-01-20 - Decoding step-by-step](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7d8dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import get_proper_global_spikes_df\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import easy_independent_decoding\n",
    "\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "all_directional_pf1D_Decoder: BasePositionDecoder = deepcopy(directional_merged_decoders_result.all_directional_pf1D_Decoder) # all-directions\n",
    "# directional_merged_decoders_result\n",
    "\n",
    "# a_1D_decoder: PfND = directional_merged_decoders_result.all_directional_decoder_dict['long_LR']\n",
    "\n",
    "long_LR_decoder: BasePositionDecoder = deepcopy(track_templates.long_LR_decoder)\n",
    "\n",
    "# ratemap: Ratemap = all_directional_pf1D_Decoder.ratemap\n",
    "\n",
    "## Pass in epochs to decode, for example, the laps\n",
    "laps = deepcopy(curr_active_pipeline.sess.laps)\n",
    "\n",
    "spikes_df: pd.DataFrame = deepcopy(curr_active_pipeline.sess.spikes_df)\n",
    "# spikes_df: pd.DataFrame = get_proper_global_spikes_df(curr_active_pipeline)\n",
    "# spikes_df = spikes_df.spikes.sliced_by_neuron_id(all_directional_pf1D_Decoder.neuron_IDs)\n",
    "# spikes_df\n",
    "\n",
    "## Given a list of discrete, equally-sized `time_bin_edges`, and a `spikes_df` pd.DataFrame of neuron spike times:\n",
    "\n",
    "## use the column 'aclu', which contains a distinct unit ID\n",
    "\n",
    "## count up the number of spikes occuring for each neuron (aclu-value) in each time bin, according to the column 't_rel_seconds' and collect the result in a numpy matrix `unit_specific_time_binned_spike_counts`\n",
    "\n",
    "\n",
    "# _ratemap\n",
    "# neuron_ids = deepcopy(spikes_df.spikes.neuron_ids) # array([ 5, 10, 14, 15, 24, 25, 26, 31, 32, 33, 41, 49, 50, 51, 55, 58, 64, 69, 70, 73, 74, 75, 76, 78, 82, 83, 85, 86, 90, 92, 93, 96])\n",
    "# array([  3,   4,   5,   7,   9,  10,  11,  14,  15,  16,  17,  21,  24,  25,  26,  31,  32,  33,  34,  35,  36,  37,  41,  45,  48,  49,  50,  51,  53,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  66,  67,  68,  69,  70,  71,  73,  74,  75,  76,  78,  82,  83,  84,  85,  86,  88,  89,  90,  92,  93,  96,  98, 100, 102, 107, 108])\n",
    "# neuron_ids\n",
    "# neuron_IDs = deepcopy(all_directional_pf1D_Decoder.neuron_IDs) # array([  2,   5,   8,  10,  14,  15,  23,  24,  25,  26,  31,  32,  33,  41,  49,  50,  51,  55,  58,  64,  69,  70,  73,  74,  75,  76,  78,  82,  83,  85,  86,  90,  92,  93,  96, 109])\n",
    "# neuron_IDs\n",
    "\n",
    "neuron_IDs = deepcopy(long_LR_decoder.neuron_IDs) # array([  2,   5,   8,  10,  14,  15,  23,  24,  25,  26,  31,  32,  33,  41,  49,  50,  51,  55,  58,  64,  69,  70,  73,  74,  75,  76,  78,  82,  83,  85,  86,  90,  92,  93,  96, 109])\n",
    "neuron_IDs\n",
    "\n",
    "# all_directional_pf1D_Decoder.slic\n",
    "spikes_df = spikes_df.spikes.sliced_by_neuron_id(neuron_IDs) ## filter everything down\n",
    "# all_directional_pf1D_Decoder.pf.spikes_df = deepcopy(spikes_df)\n",
    "## Need to update .pf._filtered_spikes_df now:\n",
    "\n",
    "# all_directional_pf1D_Decoder = all_directional_pf1D_Decoder.get_by_id(ids=neuron_IDs, defer_compute_all=True)\n",
    "# all_directional_pf1D_Decoder\n",
    "\n",
    "# ratemap = ratemap.get_by_id(ids=neuron_IDs)\n",
    "# all_directional_pf1D_Decoder._ratemap = ratemap\n",
    "# all_directional_pf1D_Decoder.compute()\n",
    "# ratemap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3b046d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.filtered_epochs\n",
    "time_bin_size: float = 0.025\n",
    "t_start = 0.0\n",
    "t_end = 2093.8978568242164\n",
    "time_bin_edges: NDArray = np.arange(t_start, t_end + time_bin_size, time_bin_size)\n",
    "# time_bin_edges\n",
    "unique_units = np.unique(spikes_df['aclu']) # sorted\n",
    "unit_specific_time_binned_spike_counts: NDArray = np.array([\n",
    "    np.histogram(spikes_df.loc[spikes_df['aclu'] == unit, 't_rel_seconds'], bins=time_bin_edges)[0]\n",
    "    for unit in unique_units\n",
    "])\n",
    "unit_specific_time_binned_spike_counts\n",
    " \n",
    "## OUTPUT: time_bin_edges, unit_specific_time_binned_spike_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a7916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## `easy_independent_decoding`\n",
    "_decoded_pos_outputs, (unit_specific_time_binned_spike_counts, time_bin_edges, spikes_df) = easy_independent_decoding(long_LR_decoder, spikes_df=spikes_df, time_bin_size=time_bin_size, t_start=t_start, t_end=t_end)\n",
    "most_likely_positions, p_x_given_n, most_likely_position_indicies, flat_outputs_container = _decoded_pos_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1b3216",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_x_given_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809362d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(most_likely_positions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2a6c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "_decoded_pos_outputs = long_LR_decoder.decode(unit_specific_time_binned_spike_counts=unit_specific_time_binned_spike_counts, time_bin_size=time_bin_size, output_flat_versions=True, debug_print=True)\n",
    "# _decoded_pos_outputs = all_directional_pf1D_Decoder.decode(unit_specific_time_binned_spike_counts=unit_specific_time_binned_spike_counts, time_bin_size=0.020, output_flat_versions=True, debug_print=True)\n",
    "_decoded_pos_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbae7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_directional_pf1D_Decoder.neuron_IDs # array([  2,   5,   8,  10,  14,  15,  23,  24,  25,  26,  31,  32,  33,  41,  49,  50,  51,  55,  58,  64,  69,  70,  73,  74,  75,  76,  78,  82,  83,  85,  86,  90,  92,  93,  96, 109])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ee5251",
   "metadata": {},
   "outputs": [],
   "source": [
    "_decoded_pos_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c71ddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.laps import Laps\n",
    "\n",
    "\n",
    "curr_laps_df = Laps._compute_lap_dir_from_smoothed_velocity(laps_df=curr_laps_df, global_session=global_session, replace_existing=True)\n",
    "curr_laps_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd23d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_editor.plots.lap_epoch_widgets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe294f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.get_session_context()\n",
    "\n",
    "# Context(format_name= 'kdiba', animal= 'gor01', exper_name= 'one', session_name= '2006-6-09_1-22-43')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56697b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_df = deepcopy(epochs_editor.get_user_labeled_epochs_df())\n",
    "laps_df\n",
    "laps_df.to_clipboard(sep=',', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341aaedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop the first two laps:\n",
    "laps_df = laps_df[laps_df['lap_id'] > 2].reset_index(drop=True)\n",
    "laps_df\n",
    "## re-index\n",
    "laps_df['lap_id'] = laps_df.index\n",
    "laps_df['label'] = laps_df.index\n",
    "laps_df.to_clipboard(sep=',', excel=False)\n",
    "# laps_df[['start', 'stop', 'lap_dir']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad33e3c",
   "metadata": {
    "tags": [
     "active-2025-01-13"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import override_laps\n",
    "\n",
    "override_laps_df: Optional[pd.DataFrame] = UserAnnotationsManager.get_hardcoded_laps_override_dict().get(curr_active_pipeline.get_session_context(), None)\n",
    "if override_laps_df is not None:\n",
    "    print(f'overriding laps....')\n",
    "    display(override_laps_df)\n",
    "    override_laps(curr_active_pipeline, override_laps_df=override_laps_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ea0059",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacing_computation_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff3fcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "override_laps_df\n",
    "# override_laps_obj.filtered_by_lap_flat_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c601c54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_filtered_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b80e699",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.replace_session_laps_with_estimates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2482b0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.plotting.placemaps import plot_placefield_occupancy\n",
    "\n",
    "plot_placefield_occupancy(global_pf1D, plot_pos_bin_axes=True)\n",
    "# global_pf1D.plot_occupancy(plot_pos_bin_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2808c7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to separate out the main-track vs.the platforms so that I can impose continuity constraints (for filtering replays via step-sizes) only on the bins of the main track.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd9d391",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.epochs\n",
    "# global_session.epochs\n",
    "# long_session.epochs\n",
    "# short_session.epochs\n",
    "## find first lap\n",
    "global_laps\n",
    "\n",
    "# curr_active_pipeline.sess.position.to_dataframe()\n",
    "long_session.position.to_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca411f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "active_sess_config = deepcopy(curr_active_pipeline.active_sess_config)\n",
    "# absolute_start_timestamp: float = active_sess_config.absolute_start_timestamp\n",
    "loaded_track_limits = active_sess_config.loaded_track_limits # x_midpoint, \n",
    "loaded_track_limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d8bd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "(first_valid_pos_time, last_valid_pos_time) = curr_active_pipeline.find_first_and_last_valid_position_times()\n",
    "first_valid_pos_time, last_valid_pos_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f464ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.get_all_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e68bec8",
   "metadata": {
    "tags": [
     "active",
     "great"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.plotting.figure import pretty_plot\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.placefield import plot_1d_placecell_validations\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.placefield import plot_single_cell_1D_placecell_validation\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.placefield import _subfn_plot_pf1D_placefield\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import test_plotRaw_v_time\n",
    "\n",
    "\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "\n",
    "\n",
    "# global_session.config.plotting_config\n",
    "active_config = deepcopy(curr_active_pipeline.active_configs[global_epoch_name])\n",
    "active_pf1D = deepcopy(global_pf1D)\n",
    "\n",
    "fig = plt.figure(figsize=(23, 9.7), clear=True, num='test_plotRaw_v_time')\n",
    "# Need axes:\n",
    "# Layout Subplots in Figure:\n",
    "gs = fig.add_gridspec(1, 8)\n",
    "gs.update(wspace=0, hspace=0.05) # set the spacing between axes. # `wspace=0`` is responsible for sticking the pf and the activity axes together with no spacing\n",
    "ax_activity_v_time = fig.add_subplot(gs[0, :-1]) # all except the last element are the trajectory over time\n",
    "ax_pf_tuning_curve = fig.add_subplot(gs[0, -1], sharey=ax_activity_v_time) # The last element is the tuning curve\n",
    "# if should_include_labels:\n",
    "    # ax_pf_tuning_curve.set_title('Normalized Placefield', fontsize='14')\n",
    "ax_pf_tuning_curve.set_xticklabels([])\n",
    "ax_pf_tuning_curve.set_yticklabels([])\n",
    "\n",
    "\n",
    "cellind: int = 2\n",
    "\n",
    "kwargs = {}\n",
    "# jitter the curve_value for each spike based on the time it occured along the curve:\n",
    "spikes_color_RGB = kwargs.get('spikes_color', (0, 0, 0))\n",
    "spikes_alpha = kwargs.get('spikes_alpha', 0.8)\n",
    "# print(f'spikes_color: {spikes_color_RGB}')\n",
    "should_plot_bins_grid = kwargs.get('should_plot_bins_grid', False)\n",
    "\n",
    "should_include_trajectory = kwargs.get('should_include_trajectory', True) # whether the plot should include \n",
    "should_include_labels = kwargs.get('should_include_labels', True) # whether the plot should include text labels, like the title, axes labels, etc\n",
    "should_include_plotRaw_v_time_spikes = kwargs.get('should_include_spikes', True) # whether the plot should include plotRaw_v_time-spikes, should be set to False to plot completely with the new all spikes mode\n",
    "use_filtered_positions: bool = kwargs.pop('use_filtered_positions', False)\n",
    "\n",
    "# position_plot_kwargs = {'color': '#393939c8', 'linewidth': 1.0, 'zorder':5} | kwargs.get('position_plot_kwargs', {}) # passed into `active_epoch_placefields1D.plotRaw_v_time`\n",
    "position_plot_kwargs = {'color': '#757575c8', 'linewidth': 1.0, 'zorder':5} | kwargs.get('position_plot_kwargs', {}) # passed into `active_epoch_placefields1D.plotRaw_v_time`\n",
    "\n",
    "\n",
    "# _out = test_plotRaw_v_time(active_pf1D=active_pf1D, cellind=cellind)\n",
    "# spike_plot_kwargs = {'linestyle':'none', 'markersize':5.0, 'marker': '.', 'markerfacecolor':spikes_color_RGB, 'markeredgecolor':spikes_color_RGB, 'zorder':10} ## OLDER\n",
    "spike_plot_kwargs = {'zorder':10} ## OLDER\n",
    "\n",
    "\n",
    "# active_pf1D.plotRaw_v_time(cellind, ax=ax_activity_v_time, spikes_alpha=spikes_alpha,\n",
    "# \tposition_plot_kwargs=position_plot_kwargs,\n",
    "# \tspike_plot_kwargs=spike_plot_kwargs,\n",
    "# \tshould_include_labels=should_include_labels, should_include_trajectory=should_include_trajectory, should_include_spikes=should_include_plotRaw_v_time_spikes,\n",
    "# \tuse_filtered_positions=use_filtered_positions,\n",
    "# ) # , spikes_color=spikes_color, spikes_alpha=spikes_alpha\n",
    "\n",
    "_out = test_plotRaw_v_time(active_pf1D=active_pf1D, cellind=cellind, ax=ax_activity_v_time, spikes_alpha=spikes_alpha,\n",
    "    position_plot_kwargs=position_plot_kwargs,\n",
    "    spike_plot_kwargs=spike_plot_kwargs,\n",
    "    should_include_labels=should_include_labels, should_include_trajectory=should_include_trajectory, should_include_spikes=should_include_plotRaw_v_time_spikes,\n",
    "    use_filtered_positions=use_filtered_positions,\n",
    ")\n",
    "\n",
    "_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be863cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_out = _subfn_plot_pf1D_placefield(active_epoch_placefields1D=active_pf1D, placefield_cell_index=cellind,\n",
    "                                ax_activity_v_time=ax_activity_v_time, ax_pf_tuning_curve=ax_pf_tuning_curve, pf_tuning_curve_ax_position='right')\n",
    "_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b30c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as itt\n",
    "from mpl_multitab import MplMultiTab\n",
    "\n",
    "n_cells = active_placefields1D.ratemap.n_neurons\n",
    "out_figures_list = []\n",
    "out_axes_list = []\n",
    "\n",
    "if should_save:\n",
    "    curr_parent_out_path = plotting_config.active_output_parent_dir.joinpath('1d Placecell Validation')\n",
    "    curr_parent_out_path.mkdir(parents=True, exist_ok=True)        \n",
    "    \n",
    "# Tabbed Matplotlib Figure Mode:\n",
    "ui = MplMultiTab(title='plot_1d_placecell_validations')\n",
    "\n",
    "\n",
    "for a_decoder_name, a_decoder in track_templates.get_decoders_dict().items():\n",
    "    print(f'a_decoder_name: {a_decoder}')\n",
    "    curr_pf1D = a_decoder.pf\n",
    "    curr_pf1D.    \n",
    "\n",
    "    fig = ui.add_tab(f'Dataset {c.upper()}', f'Observation {m}')\n",
    "    ax = fig.subplots()\n",
    "    \n",
    "\n",
    "\n",
    "for i in np.arange(n_cells):\n",
    "    curr_cell_id = active_placefields1D.cell_ids[i]\n",
    "    # fig = ui.add_tab(f'Dataset {modifier_string}', f'Cell {curr_cell_id}') # Tabbed mode only\n",
    "    fig = ui.add_tab(f'Cell{curr_cell_id}')\n",
    "\n",
    "    fig, axs = plot_single_cell_1D_placecell_validation(active_placefields1D, i, extant_fig=fig, **(plot_kwargs or {}))\n",
    "    out_figures_list.append(fig)\n",
    "    out_axes_list.append(axs)\n",
    "\n",
    "# once done, save out as specified\n",
    "common_basename = active_placefields1D.str_for_filename(prefix_string=modifier_string)\n",
    "if should_save:\n",
    "    common_basename = active_placefields1D.str_for_filename(prefix_string=modifier_string)\n",
    "    if save_mode == 'separate_files':\n",
    "        # make a subdirectory for this run (with these parameters and such)\n",
    "        curr_specific_parent_out_path = curr_parent_out_path.joinpath(common_basename)\n",
    "        curr_specific_parent_out_path.mkdir(parents=True, exist_ok=True)\n",
    "        print(f'Attempting to write {n_cells} separate figures to {str(curr_specific_parent_out_path)}')\n",
    "        for i in np.arange(n_cells):\n",
    "            print('Saving figure {} of {}...'.format(i, n_cells))\n",
    "            curr_cell_id = active_placefields1D.cell_ids[i]\n",
    "            fig = out_figures_list[i]\n",
    "            # curr_cell_filename = 'pf1D-' + modifier_string + _filename_for_placefield(active_placefields1D, curr_cell_id) + '.png'\n",
    "            curr_cell_basename = '-'.join([common_basename, f'cell_{curr_cell_id:02d}'])\n",
    "            # add the file extension\n",
    "            curr_cell_filename = f'{curr_cell_basename}.png'\n",
    "            active_pf_curr_cell_output_filepath = curr_specific_parent_out_path.joinpath(curr_cell_filename)\n",
    "            fig.savefig(active_pf_curr_cell_output_filepath)\n",
    "    elif save_mode == 'pdf':\n",
    "        print('saving multipage pdf...')\n",
    "        curr_cell_basename = common_basename\n",
    "        # add the file extension\n",
    "        curr_cell_filename = f'{curr_cell_basename}-multipage_pdf.pdf'\n",
    "        pdf_save_path = curr_parent_out_path.joinpath(curr_cell_filename)\n",
    "        save_to_multipage_pdf(out_figures_list, save_file_path=pdf_save_path)\n",
    "    else:\n",
    "        raise ValueError\n",
    "    print('\\t done.')\n",
    "\n",
    "\n",
    "# ui.show() # Tabbed mode only\n",
    "_final_out = MatplotlibRenderPlots(name=f'{common_basename}', figures=out_figures_list, axes=out_axes_list, ui=ui)\n",
    "## OUTPUT: _final_out\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38ee8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_pf1D.run_spk_pos\n",
    "active_pf1D.spk_pos\n",
    "active_pf1D.run_spk_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c8e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_pf1D.ratemap_spiketrains\n",
    "active_pf1D.ratemap_spiketrains_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d290ccab",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = plot_1d_placecell_validations(active_pf1D, active_config.plotting_config, modifier_string='lap_only', should_save=False)\n",
    "# _out = curr_active_pipeline.display('_display_1d_placefield_validations', 'maze_any')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f853e158",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out.ui.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71088cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib_configuration_update(\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e362334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with matplotlib_interactivity(is_interactive=True):\n",
    "_out.figures[0].show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc6123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qclu_included_aclus = curr_active_pipeline.determine_good_aclus_by_qclu(included_qclu_values=[1,2,4,9])\n",
    "qclu_included_aclus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9e4db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_neuron_ids_list = [a_decoder.pf.ratemap.neuron_ids for a_decoder in (long_LR_decoder, long_RL_decoder, short_LR_decoder, short_RL_decoder)]\n",
    "original_neuron_ids_list = [a_decoder.pf.ratemap.neuron_ids for a_decoder in track_templates.get_decoders_dict().values()]\n",
    "original_neuron_ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9a96b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_names = track_templates.get_decoder_names() # ('long_LR', 'long_RL', 'short_LR', 'short_RL')\n",
    "decoder_names = TrackTemplates.get_decoder_names() # ('long_LR', 'long_RL', 'short_LR', 'short_RL')\n",
    "\n",
    "link = #00fff7\n",
    "link_visited = #ffaaff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a46a4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_print = True\n",
    "## INPUTS: included_qclu_values\n",
    "included_qclu_values = [1, 2]\n",
    "\n",
    "# modified_neuron_ids_dict = track_templates.determine_decoder_aclus_filtered_by_qclu(included_qclu_values=included_qclu_values)\n",
    "\n",
    "# filtered_track_templates = track_templates.filtered_by_frate_and_qclu(minimum_inclusion_fr_Hz=None, included_qclu_values=None)\n",
    "# filtered_track_templates = track_templates.filtered_by_frate_and_qclu(included_qclu_values=included_qclu_values)\n",
    "filtered_track_templates = track_templates.filtered_by_frate_and_qclu(minimum_inclusion_fr_Hz=5.0, included_qclu_values=[1, 2])\n",
    "\n",
    "# modified_neuron_ids_dict\n",
    "filtered_track_templates.decoder_neuron_IDs_list\n",
    "_out = dict()\n",
    "_out['_display_short_long_firing_rate_index_comparison'] = curr_active_pipeline.display(display_function='_display_short_long_firing_rate_index_comparison', active_session_configuration_context=None) # _display_short_long_firing_rate_index_comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a1ed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_included_aclus_dict = {}\n",
    "# for a_decoder in track_templates.get_decoders_dict().values():\n",
    "    # a_decoder.pf.spikes_df\n",
    "for a_decoder_name, a_decoder in track_templates.get_decoders_dict().items():\n",
    "    neuron_identities: pd.DataFrame = deepcopy(a_decoder.pf.filtered_spikes_df).spikes.extract_unique_neuron_identities()\n",
    "    if debug_print:\n",
    "        print(f\"original {len(neuron_identities)}\")\n",
    "    filtered_neuron_identities: pd.DataFrame = neuron_identities[neuron_identities.neuron_type == NeuronType.PYRAMIDAL]\n",
    "    if debug_print:\n",
    "        print(f\"post PYRAMIDAL filtering {len(filtered_neuron_identities)}\")\n",
    "    filtered_neuron_identities = filtered_neuron_identities[['aclu', 'shank', 'cluster', 'qclu']]\n",
    "    filtered_neuron_identities = filtered_neuron_identities[np.isin(filtered_neuron_identities.qclu, included_qclu_values)] # drop [6, 7], which are said to have double fields - 80 remain\n",
    "    if debug_print:\n",
    "        print(f\"post (qclu != [6, 7]) filtering {len(filtered_neuron_identities)}\")\n",
    "    # filtered_neuron_identities\n",
    "    final_included_aclus = filtered_neuron_identities['aclu'].to_numpy()\n",
    "    final_included_aclus_dict[a_decoder_name] = final_included_aclus.tolist()\n",
    "\n",
    "\n",
    "final_included_aclus_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543a7317",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display_output_history_list\n",
    "curr_active_pipeline.display_output_last_added_context\n",
    "curr_active_pipeline.last_added_display_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd79d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_templates.any_decoder_neuron_IDs\n",
    "track_templates.decoder_neuron_IDs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acad4458",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650eea58",
   "metadata": {
    "tags": [
     "all",
     "spike_raster_window",
     "display",
     "gui",
     "run-spike_raster_window_test",
     "2025-04-11 - full-session marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import Spike2DRaster\n",
    "from pyphoplacecellanalysis.GUI.Qt.SpikeRasterWindows.Spike3DRasterWindowWidget import Spike3DRasterWindowWidget\n",
    "from pyphoplacecellanalysis.GUI.Qt.PlaybackControls.Spike3DRasterBottomPlaybackControlBarWidget import Spike3DRasterBottomPlaybackControlBar\n",
    "\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.spike_raster_widgets import _setup_spike_raster_window_for_debugging\n",
    "\n",
    "# Gets the existing SpikeRasterWindow or creates a new one if one doesn't already exist:\n",
    "spike_raster_window, (active_2d_plot, active_3d_plot, main_graphics_layout_widget, main_plot_widget, background_static_scroll_plot_widget) = Spike3DRasterWindowWidget.find_or_create_if_needed(curr_active_pipeline, force_create_new=True)\n",
    "\n",
    "all_global_menus_actionsDict, global_flat_action_dict = _setup_spike_raster_window_for_debugging(spike_raster_window)\n",
    "\n",
    "# preview_overview_scatter_plot: pg.ScatterPlotItem  = active_2d_plot.plots.preview_overview_scatter_plot # ScatterPlotItem \n",
    "# preview_overview_scatter_plot.setDownsampling(auto=True, method='subsample', dsRate=10)\n",
    "main_graphics_layout_widget: pg.GraphicsLayoutWidget = active_2d_plot.ui.main_graphics_layout_widget\n",
    "wrapper_layout: pg.QtWidgets.QVBoxLayout = active_2d_plot.ui.wrapper_layout\n",
    "main_content_splitter = active_2d_plot.ui.main_content_splitter # QSplitter\n",
    "layout = active_2d_plot.ui.layout\n",
    "background_static_scroll_window_plot = active_2d_plot.plots.background_static_scroll_window_plot # PlotItem\n",
    "main_plot_widget = active_2d_plot.plots.main_plot_widget # PlotItem\n",
    "active_window_container_layout = active_2d_plot.ui.active_window_container_layout # GraphicsLayout, first item of `main_graphics_layout_widget` -- just the active raster window I think, there is a strange black space above it\n",
    "bottom_bar: Spike3DRasterBottomPlaybackControlBar = spike_raster_window.bottom_playback_control_bar_widget\n",
    "# bottom_bar.log_print('test manual log entry')\n",
    "bottom_bar.add_log_line('test manual log entry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae14b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feb774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccad938",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(spike_raster_window.spike_raster_plt_2d.params.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743a2479",
   "metadata": {},
   "outputs": [],
   "source": [
    "_raster_tracks_out_dict = active_2d_plot.prepare_pyqtgraph_rasterPlot_track(name_modifier_suffix='raster_window', should_link_to_main_plot_widget=True)\n",
    "dock_config, time_sync_pyqtgraph_widget, raster_root_graphics_layout_widget, raster_plot_item, rasters_display_outputs_tuple = list(_raster_tracks_out_dict.values())[0]\n",
    "an_app, a_win, a_plots, a_plots_data = rasters_display_outputs_tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae4fada",
   "metadata": {},
   "outputs": [],
   "source": [
    "_interval_tracks_out_dict = active_2d_plot.prepare_pyqtgraph_intervalPlot_tracks(enable_interval_overview_track=True, should_remove_all_and_re_add=True, should_link_to_main_plot_widget=False)\n",
    "interval_window_dock_config, intervals_dock, intervals_time_sync_pyqtgraph_widget, intervals_root_graphics_layout_widget, intervals_plot_item = _interval_tracks_out_dict['intervals']\n",
    "if 'interval_overview' in _interval_tracks_out_dict:\n",
    "    interval_overview_window_dock_config, intervals_overview_dock, intervals_overview_time_sync_pyqtgraph_widget, intervals_overview_root_graphics_layout_widget, intervals_overview_plot_item = _interval_tracks_out_dict['interval_overview']\n",
    "    intervals_overview_plot_item.setXRange(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time, padding=0) ## global frame\n",
    "    # intervals_overview_time_sync_pyqtgraph_widget.setMaximumHeight(39)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f2fcb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a016e6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_dock.setMaximumHeight(39)\n",
    "intervals_overview_dock.setMaximumHeight(39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b35efdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_time_sync_pyqtgraph_widget.setMaximumHeight(39)\n",
    "intervals_overview_time_sync_pyqtgraph_widget.setMaximumHeight(39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e29b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(intervals_time_sync_pyqtgraph_widget.sizePolicy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1db6c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_time_sync_pyqtgraph_widget.sizePolicy()\n",
    "a_size = intervals_time_sync_pyqtgraph_widget.size()\n",
    "display(a_size)\n",
    "str(a_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab74f913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.DisplayHelpers import debug_widget_geometry\n",
    "from pyphoplacecellanalysis.General.Mixins.DisplayHelpers import debug_widget_size_policy\n",
    "\n",
    "\n",
    "time_sync_pyqtgraph_widget.setSizePolicy(\n",
    "    QSizePolicy.Preferred,  # Horizontal policy\n",
    "    QSizePolicy.Expanding   # Vertical policy set to Expanding\n",
    ")\n",
    "# Make the layout give more stretch priority to your stretching widget\n",
    "time_sync_pyqtgraph_widget.layout().setStretchFactor(time_sync_pyqtgraph_widget, 1)  # Give it stretch factor > 0\n",
    "\n",
    "\n",
    "intervals_time_sync_pyqtgraph_widget.setSizePolicy(\n",
    "    QSizePolicy.Preferred,  # Horizontal policy\n",
    "    QSizePolicy.Preferred   # Vertical policy - will not stretch\n",
    ")\n",
    "intervals_time_sync_pyqtgraph_widget.layout().setStretchFactor(intervals_time_sync_pyqtgraph_widget, 0)  # No stretch\n",
    "\n",
    "\n",
    "intervals_overview_time_sync_pyqtgraph_widget.setSizePolicy(\n",
    "    QSizePolicy.Preferred,  # Horizontal policy\n",
    "    QSizePolicy.Preferred   # Vertical policy - will not stretch\n",
    ")\n",
    "intervals_overview_time_sync_pyqtgraph_widget.layout().setStretchFactor(intervals_overview_time_sync_pyqtgraph_widget, 0)  # No stretch\n",
    "\n",
    "\n",
    "non_stretching_widgets = [intervals_time_sync_pyqtgraph_widget, intervals_overview_time_sync_pyqtgraph_widget]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025d38b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "debug_widget_geometry(intervals_time_sync_pyqtgraph_widget)\n",
    "debug_widget_geometry(time_sync_pyqtgraph_widget)\n",
    "debug_widget_geometry(intervals_overview_time_sync_pyqtgraph_widget)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f20031",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_time_sync_pyqtgraph_widget.setMaximumHeight(39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0385995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_widget = intervals_time_sync_pyqtgraph_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8d3e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_time_sync_pyqtgraph_widget.setContentsMargins(0, 0, 0, 0)\n",
    "# intervals_time_sync_pyqtgraph_widget.updateGeometry()\n",
    "intervals_time_sync_pyqtgraph_widget.size()\n",
    "intervals_time_sync_pyqtgraph_widget.sizeHint()\n",
    "intervals_time_sync_pyqtgraph_widget.sizeIncrement()\n",
    "intervals_time_sync_pyqtgraph_widget.sizePolicy()\n",
    "\n",
    "\n",
    "intervals_time_sync_pyqtgraph_widget.minimumHeight()\n",
    "intervals_time_sync_pyqtgraph_widget.baseSize()\n",
    "intervals_time_sync_pyqtgraph_widget.height()\n",
    "intervals_time_sync_pyqtgraph_widget.maximumHeight()\n",
    "\n",
    "# <PyQt5.QtWidgets.QSizePolicy object at 0x000001E1F9B80DD0>\n",
    "# intervals_time_sync_pyqtgraph_widget.stretch\n",
    "\n",
    "# intervals_time_sync_pyqtgraph_widget.setMaximumHeight()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddd14f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5.QtWidgets import QSizePolicy\n",
    "\n",
    "general_policies = {QSizePolicy.Fixed: \"Fixed\", QSizePolicy.Minimum: \"Minimum\",\n",
    "            QSizePolicy.Maximum: \"Maximum\", QSizePolicy.Preferred: \"Preferred\",\n",
    "            QSizePolicy.Expanding: \"Expanding\", QSizePolicy.MinimumExpanding: \"MinimumExpanding\",\n",
    "            QSizePolicy.Ignored: \"Ignored\"}\n",
    "\n",
    "\n",
    "general_policies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1c5ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(intervals_time_sync_pyqtgraph_widget.sizePolicy())\n",
    "display(intervals_time_sync_pyqtgraph_widget.sizePolicy())\n",
    "\n",
    "a_policy = intervals_time_sync_pyqtgraph_widget.sizePolicy()\n",
    "\n",
    "h_policy_idx = a_policy.horizontalPolicy()\n",
    "v_policy_idx = a_policy.verticalPolicy()\n",
    "\n",
    "h_policy_idx\n",
    "v_policy_idx\n",
    "\n",
    "h_policy = general_policies.get(h_policy_idx, f\"Unknown({h_policy_idx})\")\n",
    "v_policy = general_policies.get(v_policy_idx, f\"Unknown({v_policy_idx})\")\n",
    "                        \n",
    "f\"QSizePolicy(horizontal={h_policy}, vertical={v_policy}, h_stretch={a_policy.horizontalStretch()}, v_stretch={a_policy.verticalStretch()})\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e413f522",
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_window = spike_raster_window.spikes_window # SpikesDataframeWindow; pyphoplacecellanalysis.General.Model.TimeWindow.TimeWindow\n",
    "spikes_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aded71e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.total_data_start_time\n",
    "spike_raster_window.total_data_end_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51bfa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.total_data_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2d9eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setXLink\n",
    "# a_win # CustomGraphicsLayoutWidget \n",
    "# time_sync_pyqtgraph_widget # PyqtgraphTimeSynchronizedWidget \n",
    "# raster_plot_item\n",
    "\n",
    "### Zoom to entire data time range:\n",
    "# active_2d_plot\n",
    "raster_plot_item.setXLink(None)\n",
    "raster_plot_item.setXRange(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time, padding=0) ## global frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c754c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_dock_ids_list = active_2d_plot.get_group_only_flat_dock_identifiers_list()\n",
    "leaf_dock_ids_list = active_2d_plot.get_leaf_only_flat_dock_identifiers_list()\n",
    "group_dock_ids_list\n",
    "\n",
    "\n",
    "group_dock_raw_identifiers_list = [v.lstrip('GROUP[').rstrip(']') for v in group_dock_ids_list] # 'GROUP[ContinuousDecode_0.03]' -> 'ContinuousDecode_0.03'\n",
    "group_dock_raw_identifiers_list\n",
    "# spike_raster_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb984228",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_group_container_id: str = group_dock_ids_list[0] # 'GROUP[ContinuousDecode_0.03]'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e70360",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dock_items_dict: Dict[str, List[Dock]] = active_2d_plot.get_dockGroup_dock_dict()\n",
    "grouped_dock_items_dict\n",
    "\n",
    "# {'ContinuousDecode_ - t_bin_size: 0.025': [<Dock ContinuousDecode_long_LR - t_bin_size: 0.025 (65, 200)>,\n",
    "#   <Dock ContinuousDecode_long_RL - t_bin_size: 0.025 (65, 200)>,\n",
    "#   <Dock ContinuousDecode_short_LR - t_bin_size: 0.025 (65, 200)>,\n",
    "#   <Dock ContinuousDecode_short_RL - t_bin_size: 0.025 (65, 200)>],\n",
    "#  'ContinuousDecode_0.03': [<Dock DirectionalDecodersDecoded[long_LR]0.03 (65, 200)>,\n",
    "#   <Dock DirectionalDecodersDecoded[long_RL]0.03 (65, 200)>,\n",
    "#   <Dock DirectionalDecodersDecoded[short_LR]0.03 (65, 200)>,\n",
    "#   <Dock DirectionalDecodersDecoded[short_RL]0.03 (65, 200)>]}\n",
    "\n",
    "a_group_container_id: str = group_dock_ids_list[0]\n",
    "a_group_id: str = group_dock_raw_identifiers_list[0]\n",
    "flat_group_dockitems_list: List[Dock] = grouped_dock_items_dict[a_group_id]\n",
    "flat_group_dockitems_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba94a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup children:\n",
    "for a_dock in flat_group_dockitems_list:\n",
    "    # a_dock_identifier: str = a_dock.name()\n",
    "    # ## format nested child docks:\n",
    "    # a_dock.config.showCloseButton = False\n",
    "    # a_dock.config.showCollapseButton = False\n",
    "    # a_dock.config.showGroupButton = False\n",
    "    # a_dock.config.corner_radius='0px'\n",
    "    # a_dock.updateStyle()\n",
    "    active_2d_plot.dock_manager_widget.displayDockArea.addDock(dock=a_dock) ## move the dock items as children to the new container\n",
    "    # active_2d_plot.displayDockArea.moveDock(\n",
    "    # nested_dynamic_docked_widget_container.displayDockArea.addDock(dock=a_dock) ## move the dock items as children to the new container\n",
    "    \n",
    "## remove the group\n",
    "active_2d_plot.dock_manager_widget.remove_display_dock(identifier=a_group_container_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d570e8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.dock_manager_widget.unwrap_docks_in_nested_dock_area(dock_group_name='ContinuousDecode_0.03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fa4144",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dock all Grouped results from `'DockedWidgets.Pseudo2DDecodedEpochsDockedMatplotlibView'`\n",
    "## INPUTS: active_2d_plot\n",
    "nested_dock_items, nested_dynamic_docked_widget_container_widgets = active_2d_plot.ui.dynamic_docked_widget_container.layout_dockGroups()\n",
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()\n",
    "## OUTPUTS: nested_dock_items, nested_dynamic_docked_widget_container_widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8362a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import add_continuous_decoded_posterior\n",
    "\n",
    "(nested_dock_items, nested_dynamic_docked_widget_container_widgets), (a_continuously_decoded_dict, pseudo2D_decoder, all_directional_pf1D_Decoder_dict) = add_continuous_decoded_posterior(spike_raster_window=spike_raster_window, curr_active_pipeline=curr_active_pipeline, desired_time_bin_size=0.05, debug_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967df72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Increase the window duration centered\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import plot_attached_BinByBinDecodingDebugger\n",
    "\n",
    "## INPUTS: a_decoder, a_decoded_result\n",
    "win, out_pf1D_decoder_template_objects, (plots_container, plots_data), _on_update_fcn = plot_attached_BinByBinDecodingDebugger(spike_raster_window, curr_active_pipeline, a_decoder=a_decoder, a_decoded_result=a_decoded_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62a8afa",
   "metadata": {
    "tags": [
     "active-2025-02-25"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import plot_attached_BinByBinDecodingDebugger\n",
    "## Plot one of the continuous results for the most recently computed time_bin_size:\n",
    "\n",
    "\n",
    "# all_directional_pf1D_Decoder_dict\n",
    "a_decoder_name: str = 'long'\n",
    "a_decoder = results1D.decoders[a_decoder_name]\n",
    "a_decoded_result = results1D.continuous_results[a_decoder_name]\n",
    "\n",
    "## INPUTS: a_decoder, a_decoded_result\n",
    "win, out_pf1D_decoder_template_objects, (plots_container, plots_data), _on_update_fcn = plot_attached_BinByBinDecodingDebugger(spike_raster_window, curr_active_pipeline, a_decoder=a_decoder, a_decoded_result=a_decoded_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a20a893",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_main_raster_plot: bool = (active_2d_plot.plots.main_plot_widget is not None)\n",
    "_raster_tracks_out_dict = active_2d_plot.prepare_pyqtgraph_rasterPlot_track(name_modifier_suffix='raster_window', should_link_to_main_plot_widget=has_main_raster_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcbc56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.External.pyqtgraph.dockarea.Dock import Dock, DockDisplayConfig\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import FigureWidgetDockDisplayConfig\n",
    "\n",
    "flat_dock_item_tuple_dict: Dict[str, Tuple] = active_2d_plot.get_flat_dock_item_tuple_dict()\n",
    "group_only_flat_dockwidgets_dict = {k:a_widget for k, (a_dock, a_widget) in flat_dock_item_tuple_dict.items() if ('GROUP' == a_dock.config.additional_metadata.get('type', 'LEAF')) }\n",
    "leaf_only_flat_dockwidgets_dict = {k:a_widget for k, (a_dock, a_widget) in flat_dock_item_tuple_dict.items() if ('LEAF' == a_dock.config.additional_metadata.get('type', 'LEAF')) }\n",
    "group_only_flat_dockwidgets_dict\n",
    "leaf_only_flat_dockwidgets_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea403e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "active_2d_plot.get_flat_dockitems_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff28fdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import AddNewDecodedPosteriors_MatplotlibPlotCommand\n",
    "from pyphoplacecellanalysis.External.pyqtgraph.dockarea.Dock import Dock, DockDisplayConfig\n",
    "\n",
    "flat_dock_item_tuple_dict: Dict[str, Tuple] = active_2d_plot.get_flat_dock_item_tuple_dict()\n",
    "flat_dock_item_tuple_dict\n",
    "\n",
    "# flat_docks_dict = {k:a_dock for k, (a_dock, a_widget) in flat_dock_item_tuple_dict.items() if ('ContinuousDecode_ - t_bin_size: 0.025' in a_dock.config.dock_group_names) }\n",
    "flat_dockwidgets_dict = {k:a_widget for k, (a_dock, a_widget) in flat_dock_item_tuple_dict.items() if ('ContinuousDecode_ - t_bin_size: 0.025' in a_dock.config.dock_group_names) }\n",
    "flat_dockwidgets_dict\n",
    "\n",
    "# flat_dock_item_tuple_dict = {k:a_widget if a_dock.grou for k, (a_dock, a_widget) in flat_dock_item_tuple_dict.items()}\n",
    "\n",
    "# flat_dockwidgets_list = active_2d_plot.get_flat_widgets_list()\n",
    "# flat_dockwidgets_list\n",
    "# active_2d_plot.get_dock_groups()\n",
    "\n",
    "_all_tracks_out_artists = {}\n",
    "for k, a_widget in flat_dockwidgets_dict.items():\n",
    "    _out_artists = AddNewDecodedPosteriors_MatplotlibPlotCommand._perform_overlay_measured_position(identifier_name=k, widget=a_widget, matplotlib_fig=a_widget.fig, matplotlib_fig_axes=a_widget.axes, measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()))\n",
    "    _all_tracks_out_artists[k] = _out_artists\n",
    "    a_widget.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8fc993",
   "metadata": {},
   "outputs": [],
   "source": [
    "_all_tracks_out_artists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8580701",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, a_widget in flat_dockwidgets_dict.items():\n",
    "    a_widget.plots.measured_position_artists = _all_tracks_out_artists[k]\n",
    "    \n",
    "    # a_widget.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21b7f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_playback_control_bar_widget = spike_raster_window.bottom_playback_control_bar_widget # Spike3DRasterBottomPlaybackControlBar \n",
    "comboActiveJumpTargetSeries = bottom_playback_control_bar_widget.ui.comboActiveJumpTargetSeries # QComboBox \n",
    "comboActiveJumpTargetSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd1d42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Dock all Grouped results from `'DockedWidgets.Pseudo2DDecodedEpochsDockedMatplotlibView'`\n",
    "## INPUTS: active_2d_plot\n",
    "nested_dock_items, nested_dynamic_docked_widget_container_widgets = active_2d_plot.ui.dynamic_docked_widget_container.layout_dockGroups()\n",
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()\n",
    "## OUTPUTS: nested_dock_items, nested_dynamic_docked_widget_container_widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191b20f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()\n",
    "grouped_dock_items_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8084d27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.ui.dynamic_docked_widget_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53ed9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.NestedDockAreaWidget import NestedDockAreaWidget\n",
    "\n",
    "dock_manager_widget: NestedDockAreaWidget = active_2d_plot.dock_manager_widget\n",
    "grouped_dock_items_dict = dock_manager_widget.get_dockGroup_dock_dict()\n",
    "grouped_dock_items_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3ee32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dock_items_dict = active_2d_plot.dock_manager_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c521a076",
   "metadata": {},
   "outputs": [],
   "source": [
    "comboActiveJumpTargetSeries.setCurrentText('Laps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5ebfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.Specific2DRenderTimeEpochs import General2DRenderTimeEpochs, Replays_2DRenderTimeEpochs, Ripples_2DRenderTimeEpochs, SessionEpochs2DRenderTimeEpochs, PBE_2DRenderTimeEpochs, Laps2DRenderTimeEpochs, SpikeBurstIntervals_2DRenderTimeEpochs, NewNonPBE_2DRenderTimeEpochs # Time Intervals/Epochs\n",
    "\n",
    "background_static_scroll_window_plot = active_2d_plot.plots.background_static_scroll_window_plot # PlotItem\n",
    "main_plot_widget = active_2d_plot.plots.main_plot_widget # PlotItem\n",
    "\n",
    "for an_interval_rendering_plot in active_2d_plot.interval_rendering_plots:\n",
    "    _out = NewNonPBE_2DRenderTimeEpochs.add_render_time_epochs(curr_sess=curr_active_pipeline.sess.non_pbe, destination_plot=an_interval_rendering_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f45c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.params.debug_print = True\n",
    "spike_raster_window.enable_debug_print = True\n",
    "active_2d_plot.params.debug_print = True\n",
    "# active_2d_plot.debug_print = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61371822",
   "metadata": {},
   "outputs": [],
   "source": [
    "extant_conn = spike_raster_window.ui.additional_connections.get('spike_3d_to_2d_window_crosshair_connection', None)\n",
    "extant_conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7200fc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.ui.left_side_bar_connections = spike_raster_window.SpikeRasterLeftSidebarControlsMixin_connectSignals(spike_raster_window.ui.leftSideToolbarWidget)\n",
    "spike_raster_window.ui.left_side_bar_connections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0491ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fix window title to display the session context post-hoc\n",
    "desired_window_title: str = curr_active_pipeline.get_complete_session_identifier_string() # 'kdiba_gor01_two_2006-6-07_16-40-19__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 8, 9]-frateThresh_5.0'\n",
    "spike_raster_window.window().setWindowTitle(desired_window_title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b12684",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.params.is_crosshair_trace_enabled = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c0c6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_crosshairs to `active_2d_plot`\n",
    "active_time_sync_pyqtgraph_widgets: Dict[str, PyqtgraphTimeSynchronizedWidget] = {identifier:active_matplotlib_view_widget for identifier, active_matplotlib_view_widget in active_2d_plot.ui.matplotlib_view_widgets.items() if active_matplotlib_view_widget.is_pyqtgraph_based()}\n",
    "active_time_sync_pyqtgraph_widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da93cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_name, a_time_sync_widget in active_2d_plot.ui.matplotlib_view_widgets.items():\n",
    "    print(f'a_name: {a_name}')\n",
    "    # a_time_sync_widget.plots_data\n",
    "    a_time_sync_widget.plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd315de",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_side_bar_controls = spike_raster_window.ui.leftSideToolbarWidget\n",
    "left_side_bar_controls.crosshair_trace_time = \"test\"\n",
    "\n",
    "left_side_bar_controls.ui.lblCrosshairTraceStaticLabel.setVisible(True)\n",
    "left_side_bar_controls.ui.lblCrosshairTraceValue.setVisible(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d4effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.PyqtgraphTimeSynchronizedWidget import PyqtgraphTimeSynchronizedWidget\n",
    "\n",
    "def on_crosshair_updated_signal(self, name, trace_value):\n",
    "    print(f'on_crosshair_updated_signal(self: {self}, name: \"{name}\", trace_value: \"{trace_value}\")')\n",
    "    left_side_bar_controls = spike_raster_window.ui.leftSideToolbarWidget\n",
    "    left_side_bar_controls.crosshair_trace_time = trace_value\n",
    "    \n",
    "    # self.ui.lblCrosshairTraceStaticLabel.setVisible(True)\n",
    "    # self.ui.lblCrosshairTraceValue.setVisible(True)\n",
    "\n",
    "\n",
    "for a_name, a_time_sync_widget in active_2d_plot.ui.matplotlib_view_widgets.items():\n",
    "    print(f'a_name: {a_name}')\n",
    "    try:\n",
    "        a_time_sync_widget.update_crosshair_trace(wants_crosshairs_trace=True)\n",
    "        a_time_sync_widget.sigCrosshairsUpdated.connect(on_crosshair_updated_signal)\n",
    "    except KeyError as e:\n",
    "        # KeyError: 'connections'\n",
    "        pass\n",
    "        print(f'\\tfailed.')\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6843c773",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_time_sync_pyqtgraph_widgets['new_curves_separate_plot'].update_crosshair_trace(wants_crosshairs_trace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76ab4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277a736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4254723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(spike_raster_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05d7666",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.plots.main_plot_widget\n",
    "\n",
    "main_plot_widget = active_2d_plot.plots.main_plot_widget # PlotItem\n",
    "main_plot_widget.setMinimumHeight(20.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9cf1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_window_container_layout\n",
    "# main_graphics_layout_widget.ci # GraphicsLayout\n",
    "main_graphics_layout_widget.ci.childItems()\n",
    "# main_graphics_layout_widget.setHidden(True) ## hides too much\n",
    "main_graphics_layout_widget.setHidden(False)\n",
    "\n",
    "# main_graphics_layout_widget\n",
    "\n",
    "active_window_container_layout.setBorder(pg.mkPen('yellow', width=4.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7399378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_window_container_layout.allChildItems()\n",
    "active_window_container_layout.setPreferredHeight(200.0)\n",
    "active_window_container_layout.setMaximumHeight(800.0)\n",
    "active_window_container_layout.setSpacing(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a6aaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set stretch factors to control priority\n",
    "main_graphics_layout_widget.ci.layout.setRowStretchFactor(0, 400)  # Plot1: lowest priority\n",
    "main_graphics_layout_widget.ci.layout.setRowStretchFactor(1, 2)  # Plot2: mid priority\n",
    "main_graphics_layout_widget.ci.layout.setRowStretchFactor(2, 2)  # Plot3: highest priority\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5f61dd",
   "metadata": {
    "tags": [
     "_perform_plot_multi_decoder_meas_pred_position_track",
     "active-2025-01-16"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalDecodersContinuouslyDecodedResult\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import SynchronizedPlotMode\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_1D_most_likely_position_comparsions\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DecoderIdentityColors\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_plot_multi_decoder_meas_pred_position_track\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "\n",
    "## Build the new dock track:\n",
    "dock_identifier: str = 'Continuous Decoding Performance'\n",
    "ts_widget, fig, ax_list = active_2d_plot.add_new_matplotlib_render_plot_widget(name=dock_identifier)\n",
    "## Get the needed data:\n",
    "directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "previously_decoded_keys: List[float] = list(continuously_decoded_result_cache_dict.keys()) # [0.03333]\n",
    "print(F'previously_decoded time_bin_sizes: {previously_decoded_keys}')\n",
    "\n",
    "time_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\n",
    "print(f'time_bin_size: {time_bin_size}')\n",
    "continuously_decoded_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_decode_result.most_recent_continuously_decoded_dict\n",
    "all_directional_continuously_decoded_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = {k:v for k, v in (continuously_decoded_dict or {}).items() if k in TrackTemplates.get_decoder_names()} ## what is plotted in the `f'{a_decoder_name}_ContinuousDecode'` rows by `AddNewDirectionalDecodedEpochs_MatplotlibPlotCommand`\n",
    "## OUT: all_directional_continuously_decoded_dict\n",
    "## Draw the position meas/decoded on the plot widget\n",
    "## INPUT: fig, ax_list, all_directional_continuously_decoded_dict, track_templates\n",
    "\n",
    "_out_artists =  _perform_plot_multi_decoder_meas_pred_position_track(curr_active_pipeline, fig, ax_list, desired_time_bin_size=1.0, enable_flat_line_drawing=True)\n",
    "\n",
    "## sync up the widgets\n",
    "active_2d_plot.sync_matplotlib_render_plot_widget(dock_identifier, sync_mode=SynchronizedPlotMode.TO_WINDOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b589d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Need to figure out what the heck is going on, why are they all decoding to the same position?\n",
    "curr_active_pipeline.find_validators_providing_results(probe_provided_result_keys=['DirectionalDecodersDecoded'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb84d393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders'] # uses `DirectionalMergedDecoders`.\n",
    "\n",
    "# all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_merged_decoders_result.all_directional_decoder_dict # This does not work, because the values in the returned dictionary are PfND, not 1D decoders\n",
    "all_directional_pf1D_Decoder_value = directional_merged_decoders_result.all_directional_pf1D_Decoder\n",
    "\n",
    "pseudo2D_decoder: BasePositionDecoder = all_directional_pf1D_Decoder_value\n",
    "pseudo2D_decoder.xbin_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6256a7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder2D_result: DecodedFilterEpochsResult = continuously_decoded_dict['pseudo2D']\n",
    "decoder2D_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcd9f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder2D_result.filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a618e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_name:types.DecoderName = 'long_LR'\n",
    "\n",
    "\n",
    "result: DecodedFilterEpochsResult = all_directional_continuously_decoded_dict[decoder_name]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5477803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.binning_helpers import BinningContainer\n",
    "\n",
    "time_binning_container: BinningContainer = result.time_bin_containers[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd34e905",
   "metadata": {},
   "outputs": [],
   "source": [
    "marginals_out = result.compute_marginals()\n",
    "marginals_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677f13f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_x_given_n = result.p_x_given_n_list[0]\n",
    "p_x_given_n.shape # (63, 36101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33f6342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1dbc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow, LayoutScrollability\n",
    "\n",
    "out = BasicBinnedImageRenderingWindow(p_x_given_n.T, xbins=time_binning_container.centers, ybins=pseudo2D_decoder.xbin_centers, name='p_x_given_n', title=\"Continuously Decoded Position Posterior\", variable_label='p_x_given_n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38325e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df['truth_decoder_name'] = pos_df['truth_decoder_name'].fillna('')\n",
    "pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bed9c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_color_dict: Dict[types.DecoderName, str] = DecoderIdentityColors.build_decoder_color_dict()\n",
    "\n",
    "decoded_pos_line_kwargs = dict(lw=1.0, color='gray', alpha=0.8, marker='+', markersize=6, animated=False)\n",
    "inactive_decoded_pos_line_kwargs = dict(lw=0.3, alpha=0.2, marker='.', markersize=2, animated=False)\n",
    "active_decoded_pos_line_kwargs = dict(lw=1.0, alpha=0.8, marker='+', markersize=6, animated=False)\n",
    "\n",
    "\n",
    "_out_data = {}\n",
    "_out_data_plot_kwargs = {}\n",
    "# curr_active_pipeline.global_computation_results.t\n",
    "for a_decoder_name, a_decoder in track_templates.get_decoders_dict().items():\n",
    "    a_continuously_decoded_result = all_directional_continuously_decoded_dict[a_decoder_name]\n",
    "    a_decoder_color = decoder_color_dict[a_decoder_name]\n",
    "    \n",
    "    assert len(a_continuously_decoded_result.p_x_given_n_list) == 1\n",
    "    p_x_given_n = a_continuously_decoded_result.p_x_given_n_list[0]\n",
    "    # p_x_given_n = a_continuously_decoded_result.p_x_given_n_list[0]['p_x_given_n']\n",
    "    time_bin_containers = a_continuously_decoded_result.time_bin_containers[0]\n",
    "    time_window_centers = time_bin_containers.centers\n",
    "    # p_x_given_n.shape # (62, 4, 209389)\n",
    "    a_marginal_x = a_continuously_decoded_result.marginal_x_list[0]\n",
    "    # active_time_window_variable = a_decoder.active_time_window_centers\n",
    "    active_time_window_variable = time_window_centers\n",
    "    active_most_likely_positions_x = a_marginal_x['most_likely_positions_1D'] # a_decoder.most_likely_positions[:,0].T\n",
    "    _out_data[a_decoder_name] = pd.DataFrame({'t': time_window_centers, 'x': active_most_likely_positions_x, 'binned_time': np.arange(len(time_window_centers))})\n",
    "    _out_data[a_decoder_name] = _out_data[a_decoder_name].position.adding_lap_info(laps_df=laps_df, inplace=False)\n",
    "    _out_data[a_decoder_name] = _out_data[a_decoder_name].time_point_event.adding_true_decoder_identifier(t_start=t_start, t_delta=t_delta, t_end=t_end) ## ensures ['maze_id', 'is_LR_dir']\n",
    "    _out_data[a_decoder_name]['is_active_decoder_time'] = (_out_data[a_decoder_name]['truth_decoder_name'].fillna('', inplace=False) == a_decoder_name)\n",
    "\n",
    "    # is_active_decoder_time = (_out_data[a_decoder_name]['truth_decoder_name'] == a_decoder_name)\n",
    "    active_decoder_time_points = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] == a_decoder_name]['t'].to_numpy()\n",
    "    active_decoder_most_likely_positions_x = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] == a_decoder_name]['x'].to_numpy()\n",
    "    active_decoder_inactive_time_points = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] != a_decoder_name]['t'].to_numpy()\n",
    "    active_decoder_inactive_most_likely_positions_x = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] != a_decoder_name]['x'].to_numpy()\n",
    "    ## could fill y with np.nan instead of getting shorter?\n",
    "    _out_data_plot_kwargs[a_decoder_name] = (dict(x=active_decoder_time_points, y=active_decoder_most_likely_positions_x, color=a_decoder_color, **active_decoded_pos_line_kwargs), dict(x=active_decoder_inactive_time_points, y=active_decoder_inactive_most_likely_positions_x, color=a_decoder_color, **inactive_decoded_pos_line_kwargs))\n",
    "\n",
    "_out_data_plot_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8972db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out_data[a_decoder_name] = _out_data[a_decoder_name].position.adding_lap_info(laps_df=laps_df, inplace=False)\n",
    "# _out_data[a_decoder_name] = _out_data[a_decoder_name].time_point_event.adding_true_decoder_identifier(t_start=t_start, t_delta=t_delta, t_end=t_end) ## ensures ['maze_id', 'is_LR_dir']\n",
    "\n",
    "# is_active_decoder_time = (_out_data[a_decoder_name]['truth_decoder_name'] == a_decoder_name)\n",
    "active_decoder_time_points = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] == a_decoder_name]['t'].to_numpy()\n",
    "active_decoder_most_likely_positions_x = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] == a_decoder_name]['x'].to_numpy()\n",
    "active_decoder_inactive_time_points = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] != a_decoder_name]['t'].to_numpy()\n",
    "active_decoder_inactive_most_likely_positions_x = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] != a_decoder_name]['x'].to_numpy()\n",
    "\n",
    "_out_data[a_decoder_name] = ((active_decoder_time_points, active_decoder_most_likely_positions_x), (active_decoder_inactive_time_points, active_decoder_inactive_most_likely_positions_x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dd7358",
   "metadata": {},
   "outputs": [],
   "source": [
    "partitioned_dfs = partition_df_dict(pos_df, partitionColumn='truth_decoder_name')\n",
    "\n",
    "a_decoder_name: str = 'short_LR'\n",
    "a_binned_time_grouped_df = partitioned_dfs[a_decoder_name].groupby('binned_time', axis='index', dropna=True)\n",
    "a_binned_time_grouped_df = a_binned_time_grouped_df.median().dropna(axis='index', subset=['x']) ## without the `.dropna(axis='index', subset=['x'])` part it gets an exhaustive df for all possible values of 'binned_time', even those not listed\n",
    "\n",
    "a_matching_binned_times = a_binned_time_grouped_df.reset_index(drop=False)['binned_time']\n",
    "a_matching_binned_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f61fd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "## split into two dfs for each decoder -- the supported and the unsupported\n",
    "partition\n",
    "\n",
    "PandasHelpers.safe_pandas_get_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f2e753",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df.dropna(axis='index', subset=['lap', 'truth_decoder_name'], inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604e0329",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_df: pd.DataFrame = global_laps_obj.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990b67c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import find_epochs_overlapping_other_epochs\n",
    "\n",
    "## INPUTS: global_laps\n",
    "_out_split_pseudo2D_posteriors_dict = {}\n",
    "_out_split_pseudo2D_out_dict = {}\n",
    "pre_filtered_col_names = ['pre_filtered_most_likely_position_indicies', 'pre_filtered_most_likely_position'] # 'pre_filtered_time_bin_containers', 'pre_filtered_p_x_given_n', \n",
    "post_filtered_col_names = [a_col_name.removeprefix('pre_filtered_') for a_col_name in pre_filtered_col_names] # ['time_bin_containers', 'most_likely_position_indicies', 'most_likely_position']\n",
    "print(post_filtered_col_names)\n",
    "for a_time_bin_size, pseudo2D_decoder_continuously_decoded_result in continuously_decoded_pseudo2D_decoder_dict.items():\n",
    "    print(f'a_time_bin_size: {a_time_bin_size}')\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size] = {'pre_filtered_p_x_given_n': None, 'pre_filtered_time_bin_containers': None, 'pre_filtered_most_likely_position_indicies': None, 'pre_filtered_most_likely_position': None, \n",
    "                                                     'is_timebin_included': None, 'p_x_given_n': None} # , 'time_window_centers': None\n",
    "    # pseudo2D_decoder_continuously_decoded_result: DecodedFilterEpochsResult = continuously_decoded_dict.get('pseudo2D', None)\n",
    "    assert len(pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list) == 1\n",
    "    p_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0]\n",
    "    # p_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0]['p_x_given_n']\n",
    "    time_bin_containers = pseudo2D_decoder_continuously_decoded_result.time_bin_containers[0]\n",
    "    # time_window_centers = time_bin_containers.centers\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position_indicies'] = deepcopy(pseudo2D_decoder_continuously_decoded_result.most_likely_position_indicies_list[0])\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position'] = deepcopy(pseudo2D_decoder_continuously_decoded_result.most_likely_positions_list[0])\n",
    "    ## INPUTS: time_bin_containers, global_laps\n",
    "    left_edges = deepcopy(time_bin_containers.left_edges)\n",
    "    right_edges = deepcopy(time_bin_containers.right_edges)\n",
    "    continuous_time_binned_computation_epochs_df: pd.DataFrame = pd.DataFrame({'start': left_edges, 'stop': right_edges, 'label': np.arange(len(left_edges))})\n",
    "    is_timebin_included: NDArray = find_epochs_overlapping_other_epochs(epochs_df=continuous_time_binned_computation_epochs_df, epochs_df_required_to_overlap=deepcopy(global_laps))\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_p_x_given_n'] = p_x_given_n\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_time_bin_containers'] = time_bin_containers\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['is_timebin_included'] = is_timebin_included\n",
    "    # continuous_time_binned_computation_epochs_df['is_in_laps'] = is_timebin_included\n",
    "    ## filter by whether it's included or not:\n",
    "    p_x_given_n = p_x_given_n[:, :, is_timebin_included]\n",
    "    # time_window_centers = \n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['p_x_given_n'] = p_x_given_n\n",
    "    # _out_split_pseudo2D_out_dict[a_time_bin_size]['time_window_centers'] = time_window_centers[is_timebin_included]\n",
    "    # p_x_given_n.shape # (62, 4, 209389)\n",
    "\n",
    "    ## Split across the 2nd axis to make 1D posteriors that can be displayed in separate dock rows:\n",
    "    assert p_x_given_n.shape[1] == 4, f\"expected the 4 pseudo-y bins for the decoder in p_x_given_n.shape[1]. but found p_x_given_n.shape: {p_x_given_n.shape}\"\n",
    "    # split_pseudo2D_posteriors_dict = {k:np.squeeze(p_x_given_n[:, i, :]) for i, k in enumerate(('long_LR', 'long_RL', 'short_LR', 'short_RL'))}\n",
    "    _out_split_pseudo2D_posteriors_dict[a_time_bin_size] = deepcopy(p_x_given_n)\n",
    "    \n",
    "    # for a_col_name in pre_filtered_col_names:\n",
    "    #     filtered_col_name = a_col_name.removeprefix('pre_filtered_')\n",
    "    #     print(f'a_col_name: {a_col_name}, filtered_col_name: {filtered_col_name}, shape: {np.shape(_out_split_pseudo2D_out_dict[a_time_bin_size][a_col_name])}')\n",
    "    #     _out_split_pseudo2D_out_dict[a_time_bin_size][filtered_col_name] = _out_split_pseudo2D_out_dict[a_time_bin_size][a_col_name][is_timebin_included, :]\n",
    "        \n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['most_likely_position_indicies'] = _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position_indicies'][:, is_timebin_included]\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['most_likely_position'] = _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position'][is_timebin_included, :]\n",
    "    \n",
    "\n",
    "p_x_given_n.shape # (n_position_bins, n_decoding_models, n_time_bins) - (57, 4, 29951)\n",
    "\n",
    "## OUTPUTS: _out_split_pseudo2D_posteriors_dict, _out_split_pseudo2D_out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d25155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_most_likely_position_comparsions\n",
    "\n",
    "# fig, axs = plot_most_likely_position_comparsions(pho_custom_decoder, axs=ax, sess.position.to_dataframe())\n",
    "fig, axs = plot_most_likely_position_comparsions(computation_result.computed_data['pf2D_Decoder'], computation_result.sess.position.to_dataframe(), **overriding_dict_with(lhs_dict={'show_posterior':True, 'show_one_step_most_likely_positions_plots':True}, **kwargs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93036009",
   "metadata": {},
   "source": [
    "### <a id='toc7_1_2_'></a>[🔝 Dock Track Widgets](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67f05bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.add_new_embedded_pyqtgraph_render_plot_widget("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4637029",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.dock_manager_widget.add_display_dock("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9f3acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.get_flat_dockitems_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f946a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.layout_dockGroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb8dc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.get_group_only_flat_dock_identifiers_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d822fa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.get_leaf_only_flat_dock_identifiers_list()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd739ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_dock in active_2d_plot.get_flat_dockitems_list():\n",
    "    a_dock.showTitleBar()\n",
    "    # a_dock.updateStyle()\n",
    "    a_dock.config\n",
    "    a_dock.setOrientation('horizontal', force=True)\n",
    "    a_dock.updateStyle()\n",
    "    a_dock.update() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f51940",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dock Tree Widget should register with `dock_manager_widget` (DynamicDockDisplayAreaContentMixin) so that it recieves and issues updates when dock items are added/changed/closed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fc1767",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import DockDisplayColors, CustomDockDisplayConfig\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.NestedDockAreaWidget import NestedDockAreaWidget\n",
    "\n",
    "name='group_dock_widget'\n",
    "dockSize=(500,50*4)\n",
    "dockAddLocationOpts=['bottom']\n",
    "\n",
    "display_config = CustomDockDisplayConfig(showCloseButton=True, showCollapseButton=True, showGroupButton=True, orientation='horizontal')\n",
    "## Add the container to hold dynamic matplotlib plot widgets:\n",
    "nested_dynamic_docked_widget_container = NestedDockAreaWidget()\n",
    "nested_dynamic_docked_widget_container.setObjectName(\"nested_dynamic_docked_widget_container\")\n",
    "nested_dynamic_docked_widget_container.setSizePolicy(pg.QtGui.QSizePolicy.Expanding, pg.QtGui.QSizePolicy.Preferred)\n",
    "nested_dynamic_docked_widget_container.setMinimumHeight(40)\n",
    "nested_dynamic_docked_widget_container.setContentsMargins(0, 0, 0, 0)\n",
    "_, dDisplayItem = active_2d_plot.ui.dynamic_docked_widget_container.add_display_dock(name, dockSize=dockSize, display_config=display_config, widget=nested_dynamic_docked_widget_container, dockAddLocationOpts=dockAddLocationOpts, autoOrientation=False)\n",
    "dDisplayItem.setOrientation('horizontal', force=True)\n",
    "dDisplayItem.updateStyle()\n",
    "dDisplayItem.update() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0aea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_docked_widget_container: NestedDockAreaWidget  = active_2d_plot.ui.dynamic_docked_widget_container\n",
    "# dynamic_docked_widget_container.dynamic_display_dict\n",
    "\n",
    "name_list = ['intervals', 'rasters[raster_window]', 'new_curves_separate_plot']\n",
    "for a_name in name_list:\n",
    "    a_dock = dynamic_docked_widget_container.find_display_dock(a_name)\n",
    "    a_dock\n",
    "    a_dock.hideTitleBar()\n",
    "    # a_dock.labelHidden = True\n",
    "    a_dock.updateStyle()\n",
    "    \n",
    "\n",
    "\n",
    "# dynamic_docked_widget_container.find_display_dock('intervals').hideTitleBar()\n",
    "# dynamic_docked_widget_container.find_display_dock('rasters[raster_window]').hideTitleBar()\n",
    "# dynamic_docked_widget_container.find_display_dock('new_curves_separate_plot').hideTitleBar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9939b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_print_dock_sizes(active_2d_plot):\n",
    "    \"\"\" prints the size variables for each Dock item \n",
    "    \"\"\"\n",
    "    from pyphoplacecellanalysis.General.Mixins.DisplayHelpers import debug_widget_geometry\n",
    "\n",
    "    flat_dockitems_list = active_2d_plot.ui.dynamic_docked_widget_container.get_flat_dockitems_list()\n",
    "    for a_dock in flat_dockitems_list:\n",
    "        print(f'a_dock: {a_dock}')\n",
    "        debug_widget_geometry(a_dock)\n",
    "        \n",
    "    print('\\tdone.')\n",
    "        \n",
    "\n",
    "debug_print_dock_sizes(active_2d_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c932dcce",
   "metadata": {
    "tags": [
     "dock-widgets"
    ]
   },
   "outputs": [],
   "source": [
    "flat_widgets_list = active_2d_plot.ui.dynamic_docked_widget_container.get_flat_widgets_list()\n",
    "flat_dockitems_list = active_2d_plot.ui.dynamic_docked_widget_container.get_flat_dockitems_list()\n",
    "flat_dock_identifiers_list = active_2d_plot.ui.dynamic_docked_widget_container.get_flat_dock_identifiers_list()\n",
    "# flat_dockitems_list\n",
    "flat_dock_identifiers_list\n",
    "# flat_widgets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03657d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "rasters_dock = active_2d_plot.ui.dynamic_docked_widget_container.find_display_dock('rasters[raster_window]')\n",
    "rasters_dock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98199475",
   "metadata": {},
   "outputs": [],
   "source": [
    "rasters_dock.stretch()\n",
    "rasters_dock.setStretch(y=240)\n",
    "rasters_dock.stretch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4405ffad",
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_dock_items = {}\n",
    "nested_dynamic_docked_widget_container_widgets = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fd4da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()\n",
    "# flat_widgets_list = active_2d_plot.ui.dynamic_docked_widget_container.get_flat_widgets_list()\n",
    "# dock_group_name: str = 'ContinuousDecode_ - t_bin_size: 0.025'\n",
    "dock_group_name: str = 'ContinuousDecode_ - t_bin_size: 0.05'\n",
    "flat_group_dockitems_list = grouped_dock_items_dict[dock_group_name]\n",
    "dDisplayItem, nested_dynamic_docked_widget_container = active_2d_plot.ui.dynamic_docked_widget_container.build_wrapping_nested_dock_area(flat_group_dockitems_list, dock_group_name=dock_group_name)\n",
    "nested_dock_items[dock_group_name] = dDisplayItem\n",
    "nested_dynamic_docked_widget_container_widgets[dock_group_name] = nested_dynamic_docked_widget_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432310ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: active_2d_plot\n",
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()\n",
    "nested_dock_items = {}\n",
    "nested_dynamic_docked_widget_container_widgets = {}\n",
    "for dock_group_name, flat_group_dockitems_list in grouped_dock_items_dict.items():\n",
    "    dDisplayItem, nested_dynamic_docked_widget_container = active_2d_plot.ui.dynamic_docked_widget_container.build_wrapping_nested_dock_area(flat_group_dockitems_list, dock_group_name=dock_group_name)\n",
    "    nested_dock_items[dock_group_name] = dDisplayItem\n",
    "    nested_dynamic_docked_widget_container_widgets[dock_group_name] = nested_dynamic_docked_widget_container\n",
    "\n",
    "## OUTPUTS: nested_dock_items, nested_dynamic_docked_widget_container_widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d095b42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_wrapping_nested_dock_area\n",
    "\n",
    "dynamic_docked_widget_container = active_2d_plot.ui.dynamic_docked_widget_container # NestedDockAreaWidget \n",
    "dynamic_docked_widget_container.build_wrapping_nested_dock_area(f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0f9b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_crosshairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85366f3c",
   "metadata": {},
   "source": [
    "## <a id='toc7_2_'></a>[2025-02-17 - Dock Item \"Track\" sizing](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f80e740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.NestedDockAreaWidget import NestedDockAreaWidget\n",
    "\n",
    "dock_manager_widget: NestedDockAreaWidget  = active_2d_plot.dock_manager_widget\n",
    "dock_manager_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7954acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()\n",
    "grouped_dock_items_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbc4bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_dock_items, nested_dynamic_docked_widget_container_widgets = dock_manager_widget.layout_dockGroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9b64d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dock_manager_widget.get_flat_dockitems_list()\n",
    "\n",
    "flat_dockitems_list = dock_manager_widget.get_flat_dockitems_list() ## get the non-grouped dockitems\n",
    "flat_dockitems_list\n",
    "# flat_dockitems_list[0].widgets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497f2289",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dock: Dock = flat_dockitems_list[-1]\n",
    "a_dock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9496b8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_dock_stretch_sizes_list = [a_dock.stretch() for a_dock in flat_dockitems_list] # [(500, 40), (500, 50), (65, 200), (65, 200), (65, 200), (65, 200), (500, 321), (500, 25)]\n",
    "flat_dock_stretch_sizes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d0b1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_dock_stretch_sizes = np.array(flat_dock_stretch_sizes_list)\n",
    "total_height: float = np.sum(flat_dock_stretch_sizes, axis=0)[-1] ## total height of all docks\n",
    "total_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c6c246",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_dock_configs_list = [a_dock.config for a_dock in flat_dockitems_list]\n",
    "flat_dock_configs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dad856",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dock: Dock = flat_dockitems_list[0]\n",
    "a_dock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71138bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_keys_if_possible(curr_key='dynamic_display_dict', curr_value=dock_manager_widget.dynamic_display_dict, max_depth=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb42af97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.External.pyqtgraph.dockarea.Dock import Dock, DockDisplayConfig, DockLabel\n",
    "\n",
    "print(f'active_2d_plot.get_leaf_only_flat_dock_identifiers_list(): {active_2d_plot.get_leaf_only_flat_dock_identifiers_list()}')\n",
    "leaf_only_flat_docks_dict: Dict[str, Dock] = {k:active_2d_plot.find_display_dock(k) for k in active_2d_plot.get_leaf_only_flat_dock_identifiers_list()}\n",
    "print(f'leaf_only_flat_docks_dict: {leaf_only_flat_docks_dict}')\n",
    "\n",
    "leaf_only_flat_docks_geometry_size_list = [(a_dock.width(), a_dock.height()) for k, a_dock in leaf_only_flat_docks_dict.items()] # [(1855, 69), (1855, 69), (1855, 71), (1855, 71), (1855, 71), (1855, 73), (1855, 64), (1855, 85), (1855, 30)]\n",
    "leaf_only_flat_docks_geometry_sizes = np.vstack(leaf_only_flat_docks_geometry_size_list)\n",
    "leaf_only_flat_docks_geometry_sizes\n",
    "\n",
    "\n",
    "single_track_height_unit: int = 30 ## how tall a single track height unit is, determining the minimum height of a track\n",
    "\n",
    "\n",
    "total_leaf_only_flat_docks_geometry_size = np.sum(leaf_only_flat_docks_geometry_sizes, axis=0)\n",
    "total_leaf_only_flat_docks_geometry_size\n",
    "\n",
    "leaf_only_flat_docks_stretch_list = [a_dock.stretch() for k, a_dock in leaf_only_flat_docks_dict.items()] # [(500, 40), (500, 50), (65, 200), (65, 200), (65, 200), (65, 200), (10, 4), (10, 4), (10, 1)]\n",
    "leaf_only_flat_docks_stretchs = np.vstack(leaf_only_flat_docks_stretch_list)\n",
    "leaf_only_flat_docks_stretchs\n",
    "\n",
    "# leaf_only_flat_docks_dict\n",
    "\n",
    "# active_2d_plot.get_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb50aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_only_flat_docks_dict['intervals'].setStretch(x=10, y=4)\n",
    "\n",
    "leaf_only_flat_docks_dict['new_curves_separate_plot'].setStretch(x=10, y=4)\n",
    "for a_name in ['ContinuousDecode_long_LR - t_bin_size: 0.025', 'ContinuousDecode_long_RL - t_bin_size: 0.025', 'ContinuousDecode_short_LR - t_bin_size: 0.025', 'ContinuousDecode_short_RL - t_bin_size: 0.025']:\n",
    "\tleaf_only_flat_docks_dict[a_name].setStretch(x=10, y=4)\n",
    "\tleaf_only_flat_docks_dict[a_name].setMinimumHeight(30)  # Set a smaller minimum height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591bd986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.External.pyqtgraph.dockarea.Dock import debug_widget_geometry\n",
    "\n",
    "# active_2d_plot.get_leaf_only_flat_dock_identifiers_list()\n",
    "\n",
    "dock_items_dict = {k:v[-1] for k, v in output_dict.items()}\n",
    "# dock_items_dict = {k:v[-1] for k, v in MASKED_output_dict.items()}\n",
    "dock_items_dict\n",
    "\n",
    "a_dock_item = dock_items_dict['PBE_marginal_over_track_ID']\n",
    "a_dock_item.setStretch(x=10, y=1)  # Same larger height stretch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b0acc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for k, v in dock_items_dict.items():\n",
    "    print(f'k: {k}')\n",
    "    # debug_widget_geometry(v, widget_name=k)\n",
    "    # Allow one dock to be smaller than its minimum size hint\n",
    "    v.widgetArea.setMinimumHeight(30)  # Set a smaller minimum height\n",
    "    \n",
    "    v.debug_print(widget_name=k)\n",
    "    # Assuming you have three docks\n",
    "    # v.stretch()  # Small height stretch\n",
    "\n",
    "    # smallDock.setStretch(x=10, y=1)  # Small height stretch\n",
    "    # tallDock1.setStretch(x=10, y=3)  # Larger height stretch\n",
    "    # tallDock2.setStretch(x=10, y=3)  # Same larger height stretch\n",
    "\n",
    "    # v.label.debug_print(label_name=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3fe261",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.dissolve_all_dockGroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db33f073",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.layout_dockGroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c45eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dock_items_dict: Dict[str, List[Dock]] = active_2d_plot.get_dockGroup_dock_dict()\n",
    "grouped_dock_items_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693f5fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.dock_manager_widget.nested_dock_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9046712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a_group_id, a_group_dock in active_2d_plot.dock_manager_widget.nested_dock_items.items():\n",
    "# \ta_group_container_id: str = f'GROUP[{a_group_id}]'\n",
    "# \tdel active_2d_plot.dock_manager_widget.nested_dock_items[a_group_id]\n",
    "\t\n",
    "# active_2d_plot.dock_manager_widget.nested_dock_items.clear()\n",
    "active_2d_plot.dock_manager_widget.nested_dock_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99688c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_dock_ids_list = active_2d_plot.get_group_only_flat_dock_identifiers_list()\n",
    "group_dock_ids_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6059b40a",
   "metadata": {},
   "source": [
    "#### <a id='toc7_2_1_1_'></a>[Spike3DRasterWindow - Right Sidebar Widgets](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eff235",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.on_update_right_sidebar_visible_interval_info_tables()\n",
    "spike_raster_window.build_dock_area_managing_tree_widget()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9d696e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.EpochRenderConfigWidget.EpochRenderConfigWidget import EpochRenderConfigWidget, EpochRenderConfigsListWidget\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import DockDisplayColors, CustomDockDisplayConfig\n",
    "\n",
    "an_epochs_display_list_widget: EpochRenderConfigsListWidget = spike_raster_window.build_epoch_intervals_visual_configs_widget()\n",
    "an_epochs_display_list_widget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549f454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_raster_plot.ui.epochs_render_configs_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa59d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.build_neuron_visual_configs_widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3738059c",
   "metadata": {},
   "source": [
    "## <a id='toc7_3_'></a>[💯 2025-01-22 - Add Selection Widget for SpikeRaster3DWindow](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bb8383",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_plt_2d: Spike2DRaster = spike_raster_window.spike_raster_plt_2d\n",
    "a_range_selection_widget, range_selection_root_graphics_layout_widget, range_selection_plot_item, range_selection_dDisplayItem = spike_raster_plt_2d.add_new_embedded_pyqtgraph_render_plot_widget(name='range_selection_capture_widget', dockSize=(500,25))\n",
    "range_selection_dDisplayItem.setMaximumHeight(25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cde7d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c1edcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attrs import define, field, Factory\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsObjects.CustomInfiniteLine import CustomInfiniteLine\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsObjects.CustomLinearRegionItem import CustomLinearRegionItem\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsObjects.CustomIntervalRectsItem import CustomIntervalRectsItem\n",
    "\n",
    "\n",
    "@define(slots=False)\n",
    "class UserTimelineSelections:\n",
    "    point_selections: List[pg.TargetItem] = field(default=Factory(list))\n",
    "    line_selections: List[CustomInfiniteLine] = field(default=Factory(list))\n",
    "    range_selections: List[CustomLinearRegionItem] = field(default=Factory(list))\n",
    "    \n",
    "\n",
    "selections: UserTimelineSelections = UserTimelineSelections()\n",
    "selections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af0c666",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Add three infinite lines with labels\n",
    "inf1 = pg.InfiniteLine(movable=True, angle=90, label='x={value:0.2f}', \n",
    "                       labelOpts={'position':0.1, 'color': (200,200,100), 'fill': (200,200,200,50), 'movable': True})\n",
    "inf2 = pg.InfiniteLine(movable=True, angle=0, pen=(0, 0, 200), bounds = [-20, 20], hoverPen=(0,200,0), label='y={value:0.2f}mm', \n",
    "                       labelOpts={'color': (200,0,0), 'movable': True, 'fill': (0, 0, 200, 100)})\n",
    "inf3 = pg.InfiniteLine(movable=True, angle=45, pen='g', label='diagonal',\n",
    "                       labelOpts={'rotateAxis': [1, 0], 'fill': (0, 200, 0, 100), 'movable': True})\n",
    "inf1.setPos([2,2])\n",
    "p1.addItem(inf1)\n",
    "p1.addItem(inf2)\n",
    "p1.addItem(inf3)\n",
    "\n",
    "targetItem1 = pg.TargetItem()\n",
    "\n",
    "targetItem2 = pg.TargetItem(\n",
    "    pos=(30, 5),\n",
    "    size=20,\n",
    "    symbol=\"star\",\n",
    "    pen=\"#F4511E\",\n",
    "    label=\"vert={1:0.2f}\",\n",
    "    labelOpts={\n",
    "        \"offset\": QtCore.QPoint(15, 15)\n",
    "    }\n",
    ")\n",
    "targetItem2.label().setAngle(45)\n",
    "\n",
    "targetItem3 = pg.TargetItem(\n",
    "    pos=(10, 10),\n",
    "    size=10,\n",
    "    symbol=\"x\",\n",
    "    pen=\"#00ACC1\",\n",
    ")\n",
    "targetItem3.setLabel(\n",
    "    \"Third Label\",\n",
    "    {\n",
    "        \"anchor\": QtCore.QPointF(0.5, 0.5),\n",
    "        \"offset\": QtCore.QPointF(30, 0),\n",
    "        \"color\": \"#558B2F\",\n",
    "        \"rotateAxis\": (0, 1)\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "def callableFunction(x, y):\n",
    "    return f\"Square Values: ({x**2:.4f}, {y**2:.4f})\"\n",
    "\n",
    "targetItem4 = pg.TargetItem(\n",
    "    pos=(10, -10),\n",
    "    label=callableFunction\n",
    ")\n",
    "\n",
    "p1.addItem(targetItem1)\n",
    "p1.addItem(targetItem2)\n",
    "p1.addItem(targetItem3)\n",
    "p1.addItem(targetItem4)\n",
    "\n",
    "# Add a linear region with a label\n",
    "lr = pg.LinearRegionItem(values=[70, 80])\n",
    "p1.addItem(lr)\n",
    "label = pg.InfLineLabel(lr.lines[1], \"region 1\", position=0.95, rotateAxis=(1,0), anchor=(1, 1))\n",
    "\n",
    "\n",
    "\n",
    "vb=DragSelectViewBox()\n",
    "plotItem=pg.PlotItem(viewBox=vb)\n",
    "plotWidget=pg.PlotWidget(plotItem=plotItem)\n",
    "plotWidget.plot([0,1,2,3],[10,5,7,3],pen='b')\n",
    "plotWidget.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be99f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QMainWindow, QVBoxLayout, QWidget\n",
    "import pyqtgraph as pg\n",
    "\n",
    "class PlotWithSelection(pg.PlotWidget):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        # Initialize variables to track the selection\n",
    "        self.start_pos = None\n",
    "        self.end_pos = None\n",
    "        self.is_selecting = False\n",
    "        \n",
    "        # Disable default panning\n",
    "        self.setMouseTracking(True)\n",
    "        self.plotItem.vb.setMouseEnabled(x=False, y=False)  # Disable default panning/zooming\n",
    "\n",
    "    def mousePressEvent(self, event):\n",
    "        if event.button() == Qt.LeftButton:\n",
    "            # Get the position where the mouse was clicked\n",
    "            pos = self.plotItem.vb.mapSceneToView(event.pos())\n",
    "            self.start_pos = pos.x()\n",
    "            self.is_selecting = True\n",
    "        else:\n",
    "            super().mousePressEvent(event)\n",
    "\n",
    "    def mouseMoveEvent(self, event):\n",
    "        if self.is_selecting:\n",
    "            # Update the end position while dragging\n",
    "            pos = self.plotItem.vb.mapSceneToView(event.pos())\n",
    "            self.end_pos = pos.x()\n",
    "            self.update_selection()\n",
    "        else:\n",
    "            super().mouseMoveEvent(event)\n",
    "\n",
    "    def mouseReleaseEvent(self, event):\n",
    "        if event.button() == Qt.LeftButton and self.is_selecting:\n",
    "            # Get the final position where the mouse was released\n",
    "            pos = self.plotItem.vb.mapSceneToView(event.pos())\n",
    "            self.end_pos = pos.x()\n",
    "\n",
    "            # Ensure that the start and end positions are valid\n",
    "            if self.start_pos is not None and self.end_pos is not None:\n",
    "                # Create a new LinearRegionItem\n",
    "                region = pg.LinearRegionItem(values=(min(self.start_pos, self.end_pos), max(self.start_pos, self.end_pos)))\n",
    "                self.addItem(region)\n",
    "\n",
    "            # Reset the selection state\n",
    "            self.start_pos = None\n",
    "            self.end_pos = None\n",
    "            self.is_selecting = False\n",
    "        else:\n",
    "            super().mouseReleaseEvent(event)\n",
    "\n",
    "    def update_selection(self):\n",
    "        # Optionally, you can draw a temporary selection line here\n",
    "        pass\n",
    "\n",
    "# Example usage\n",
    "win = QMainWindow()\n",
    "central_widget = QWidget()\n",
    "layout = QVBoxLayout(central_widget)\n",
    "\n",
    "plot_widget = PlotWithSelection()\n",
    "plot_widget.plot([1, 5, 2, 4, 3], pen='r')  # Example data\n",
    "\n",
    "layout.addWidget(plot_widget)\n",
    "win.setCentralWidget(central_widget)\n",
    "win.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599e7a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_selection_plot_item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8736da11",
   "metadata": {},
   "source": [
    "# <a id='toc10_'></a>[Other Misc Plotting Stuff](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521bba12",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.plot._display_directional_template_debugger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb5ba90",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_template_debugger')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e9208a",
   "metadata": {},
   "source": [
    "### <a id='toc10_1_1_'></a>[Resume display stuff](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50f2ef8",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from flexitext import flexitext\n",
    "from neuropy.utils.matplotlib_helpers import FormattedFigureText, FigureMargins ## flexitext version\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out = curr_active_pipeline.display('_display_directional_track_template_pf1Ds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d2b444",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# _restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080c1041",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_two_step_decoder_prediction_error_2D', global_epoch_context, variable_name='p_x_given_n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e05b045",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_plot_most_likely_position_comparisons', global_epoch_context) # , variable_name='p_x_given_n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddebd9e",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_laps_overview')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d805c37",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_laps_overview')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3c3cea",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "'_display_directional_laps_overview'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb98e796",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# '_display_directional_merged_pfs'\n",
    "_out = curr_active_pipeline.display('_display_directional_merged_pfs', plot_all_directions=False, plot_long_directional=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47076a61",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "'_display_1d_placefield_occupancy'\n",
    "'_display_placemaps_pyqtplot_2D'\n",
    " '_display_2d_placefield_occupancy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481df233",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_2d_placefield_occupancy', global_any_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694d0a20",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_grid_bin_bounds_validation')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fbe6ee",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "_out = curr_active_pipeline.display('_display_running_and_replay_speeds_over_time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58951b11",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.utils.matplotlib_helpers import add_rectangular_selector, add_range_selector\n",
    "\n",
    "\n",
    "# epoch_name = global_any_name\n",
    "epoch_name = short_epoch_name\n",
    "computation_result = curr_active_pipeline.computation_results[epoch_name]\n",
    "grid_bin_bounds = computation_result.computation_config['pf_params'].grid_bin_bounds\n",
    "epoch_context = curr_active_pipeline.filtered_contexts[epoch_name]\n",
    "print(grid_bin_bounds)     \n",
    "fig, ax = computation_result.computed_data.pf2D.plot_occupancy(identifier_details_list=[epoch_name], active_context=epoch_context) \n",
    "\n",
    "# rect_selector, set_extents, reset_extents = add_rectangular_selector(fig, ax, initial_selection=grid_bin_bounds) # (24.82, 257.88), (125.52, 149.19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada4720b",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import add_vertical_track_bounds_lines\n",
    "\n",
    "grid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\n",
    "long_track_line_collection, short_track_line_collection = add_vertical_track_bounds_lines(grid_bin_bounds=grid_bin_bounds, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b862a66",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.peak_location_representing import compute_placefield_center_of_mass_positions\n",
    "\n",
    "\n",
    "epoch_name = global_any_name\n",
    "computation_result = curr_active_pipeline.computation_results[epoch_name]\n",
    "grid_bin_bounds = deepcopy(computation_result.computation_config['pf_params'].grid_bin_bounds)\n",
    "epoch_context = curr_active_pipeline.filtered_contexts[epoch_name]\n",
    "\n",
    "grid_bin_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65654f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5905e90b",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "grid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\n",
    "grid_bin_bounds\n",
    "long_pf2D.xbin\n",
    "long_pf2D.ybin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befc3d1d",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "occupancy = deepcopy(long_pf2D.occupancy) # occupancy.shape # (60, 15)\n",
    "xbin = deepcopy(long_pf2D.xbin)\n",
    "ybin = deepcopy(long_pf2D.ybin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0416d4",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from scipy import ndimage # used for `compute_placefield_center_of_masses`\n",
    "from neuropy.utils.mixins.peak_location_representing import compute_occupancy_center_of_mass_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6352663",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "occupancy_x_center_dict = {k:compute_occupancy_center_of_mass_positions(v.pf.occupancy, xbin=v.pf.xbin, ybin=v.pf.ybin).item() for k, v in track_templates.get_decoders_dict().items()}\n",
    "occupancy_x_center_dict # {'long_LR': 162.99271603199625, 'long_RL': 112.79866056603696, 'short_LR': 138.45611791646, 'short_RL': 130.78889937230684}\n",
    "\n",
    "occupancy_mask_x_center_dict = {k:compute_occupancy_center_of_mass_positions(v.pf.visited_occupancy_mask, xbin=v.pf.xbin, ybin=v.pf.ybin).item() for k, v in track_templates.get_decoders_dict().items()}\n",
    "occupancy_mask_x_center_dict # {'long_LR': 135.66781520875904, 'long_RL': 130.0042755113645, 'short_LR': 133.77996864296085, 'short_RL': 143.21920147195175}\n",
    "\n",
    "\n",
    "# {k:compute_occupancy_center_of_mass_positions(v.pf.occupancy, xbin=v.pf.xbin, ybin=v.pf.ybin).item() for k, v in track_templates.get_decoders_dict().items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb029d8",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "occupancy = deepcopy(long_pf2D.occupancy) # occupancy.shape # (60, 15)\n",
    "xbin = deepcopy(long_pf2D.xbin)\n",
    "ybin = deepcopy(long_pf2D.ybin)\n",
    "\n",
    "# masked_nonzero_occupancy = deepcopy(long_pf2D.nan_never_visited_occupancy)\n",
    "\n",
    "masked_nonzero_occupancy = deepcopy(long_pf2D.visited_occupancy_mask)\n",
    "\n",
    "# occupancy_CoM_positions = compute_occupancy_center_of_mass_positions(occupancy, xbin=long_pf2D.xbin, ybin=long_pf2D.ybin)\n",
    "occupancy_CoM_positions = compute_occupancy_center_of_mass_positions(masked_nonzero_occupancy, xbin=long_pf2D.xbin, ybin=long_pf2D.ybin) # array([127.704, 145.63])\n",
    "occupancy_CoM_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097c3b06",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "long_pf2D.nan_never_visited_occupancy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4caa06",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_display_function_docs_dict# '_display_grid_bin_bounds_validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f963a7",
   "metadata": {
    "tags": [
     "all",
     "2025-01-23"
    ]
   },
   "outputs": [],
   "source": [
    "## Extracting on 2024-02-06 to display the LR/RL directions instead of the All/Long/Short pfs:\n",
    "def _display_directional_merged_pfs(owning_pipeline_reference, global_computation_results, computation_results, active_configs, include_includelist=None, save_figure=True, included_any_context_neuron_ids=None,\n",
    "                                    plot_all_directions=True, plot_long_directional=False, plot_short_directional=False, **kwargs):\n",
    "    \"\"\" Plots the merged pseduo-2D pfs/ratemaps. Plots: All-Directions, Long-Directional, Short-Directional in seperate windows. \n",
    "    \n",
    "    History: this is the Post 2022-10-22 display_all_pf_2D_pyqtgraph_binned_image_rendering-based method:\n",
    "    \"\"\"\n",
    "    from pyphoplacecellanalysis.Pho2D.PyQtPlots.plot_placefields import pyqtplot_plot_image_array, display_all_pf_2D_pyqtgraph_binned_image_rendering\n",
    "    from pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow \n",
    "    from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import LayoutScrollability\n",
    "\n",
    "    defer_render = kwargs.pop('defer_render', False)\n",
    "    directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "    active_merged_pf_plots_data_dict = {} #empty dict\n",
    "    \n",
    "    if plot_all_directions:\n",
    "        active_merged_pf_plots_data_dict[owning_pipeline_reference.build_display_context_for_session(track_config='All-Directions', display_fn_name='display_all_pf_2D_pyqtgraph_binned_image_rendering')] = directional_merged_decoders_result.all_directional_pf1D_Decoder.pf # all-directions\n",
    "    if plot_long_directional:\n",
    "        active_merged_pf_plots_data_dict[owning_pipeline_reference.build_display_context_for_session(track_config='Long-Directional', display_fn_name='display_all_pf_2D_pyqtgraph_binned_image_rendering')] = directional_merged_decoders_result.long_directional_pf1D_Decoder.pf # Long-only\n",
    "    if plot_short_directional:\n",
    "        active_merged_pf_plots_data_dict[owning_pipeline_reference.build_display_context_for_session(track_config='Short-Directional', display_fn_name='display_all_pf_2D_pyqtgraph_binned_image_rendering')] = directional_merged_decoders_result.short_directional_pf1D_Decoder.pf # Short-only\n",
    "\n",
    "    out_plots_dict = {}\n",
    "    \n",
    "    for active_context, active_pf_2D in active_merged_pf_plots_data_dict.items():\n",
    "        # figure_format_config = {} # empty dict for config\n",
    "        neuron_values = deepcopy(active_pf_2D.peak_tuning_curve_center_of_mass_bin_coordinates)\n",
    "        sort_indices = np.lexsort((neuron_values[:, 1], neuron_values[:, 0]))\n",
    "        figure_format_config = {'scrollability_mode': LayoutScrollability.NON_SCROLLABLE, 'included_unit_indicies': sort_indices} # kwargs # kwargs as default figure_format_config\n",
    "        out_all_pf_2D_pyqtgraph_binned_image_fig: BasicBinnedImageRenderingWindow  = display_all_pf_2D_pyqtgraph_binned_image_rendering(active_pf_2D, figure_format_config) # output is BasicBinnedImageRenderingWindow\n",
    "    \n",
    "        # Set the window title from the context\n",
    "        out_all_pf_2D_pyqtgraph_binned_image_fig.setWindowTitle(f'{active_context.get_description()}')\n",
    "        out_plots_dict[active_context] = out_all_pf_2D_pyqtgraph_binned_image_fig\n",
    "\n",
    "        # Tries to update the display of the item:\n",
    "        names_list = [v for v in list(out_all_pf_2D_pyqtgraph_binned_image_fig.plots.keys()) if v not in ('name', 'context')]\n",
    "        for a_name in names_list:\n",
    "            # Adjust the size of the text for the item by passing formatted text\n",
    "            a_plot: pg.PlotItem = out_all_pf_2D_pyqtgraph_binned_image_fig.plots[a_name].mainPlotItem # PlotItem \n",
    "            # no clue why 2 is a good value for this...\n",
    "            a_plot.titleLabel.setMaximumHeight(2)\n",
    "            a_plot.layout.setRowFixedHeight(0, 2)\n",
    "            a_plot.layout.setRowFixedHeight(1, 10)\n",
    "            plot_viewbox = a_plot.getViewBox()\n",
    "            # plot_viewbox.setMinimumHeight(200)  # Set a reasonable minimum height\n",
    "            plot_viewbox.setMaximumHeight(15)  # Set a fixed height to prevent stretching\n",
    "            plot_viewbox.setBorder(None)  # Remove the border\n",
    "            plot_viewbox.setBackgroundColor(None)\n",
    "                        \n",
    "            # # Add a spacer at the bottom\n",
    "            # spacer = pg.QtWidgets.QGraphicsWidget()\n",
    "            # spacer.setSizePolicy(pg.QtWidgets.QSizePolicy.Expanding, pg.QtWidgets.QSizePolicy.Expanding)  # Flexible spacer\n",
    "            # # Add the spacer to the layout\n",
    "            # row_count = a_plot.layout.rowCount()  # Get current row count\n",
    "            # a_plot.layout.addItem(spacer, row_count, 0, 1, a_plot.layout.columnCount())  # Add spacer to the last row\n",
    "            \n",
    "\n",
    "        if not defer_render:\n",
    "            out_all_pf_2D_pyqtgraph_binned_image_fig.show()\n",
    "\n",
    "    return out_plots_dict\n",
    "\n",
    "\n",
    "out_plots_dict = _display_directional_merged_pfs(curr_active_pipeline, curr_active_pipeline.global_computation_results, computation_results=None, active_configs=None, include_includelist=None, save_figure=True, included_any_context_neuron_ids=None,\n",
    "                                    plot_all_directions=True, plot_long_directional=False, plot_short_directional=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15824da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_all_pf_2D_pyqtgraph_binned_image_fig: BasicBinnedImageRenderingWindow = list(out_plots_dict.values())[0]\n",
    "# Tries to update the display of the item:\n",
    "names_list = [v for v in list(out_all_pf_2D_pyqtgraph_binned_image_fig.plots.keys()) if v not in ('name', 'context')]\n",
    "for a_name in names_list:\n",
    "    # Adjust the size of the text for the item by passing formatted text\n",
    "    a_plot: pg.PlotItem = out_all_pf_2D_pyqtgraph_binned_image_fig.plots[a_name].mainPlotItem # PlotItem \n",
    "    # no clue why 2 is a good value for this...\n",
    "    a_plot.titleLabel.setMaximumHeight(2)\n",
    "    a_plot.layout.setRowFixedHeight(0, 2)\n",
    "    a_plot.getViewBox().setBorder(None)  # Remove the border\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c38fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_plot.layoutDirection()\n",
    "a_plot.layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f36e973",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyphocorehelpers.gui.Qt.color_helpers import ColormapHelpers\n",
    "        \n",
    "ColormapHelpers.mpl_to_pg_colormap(color_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf715bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_pf2D = directional_merged_decoders_result.all_directional_pf1D_Decoder.pf # all-directions\n",
    "active_pf2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054feb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.shape()\n",
    "\n",
    "neuron_values = deepcopy(active_pf2D.peak_tuning_curve_center_of_mass_bin_coordinates)\n",
    "\n",
    "sort_indices = np.lexsort((neuron_values[:, 1], neuron_values[:, 0]))\n",
    "sort_indices\n",
    "\n",
    "neuron_values[sort_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfeb03c",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "# _out = curr_active_pipeline.display('_display_directional_merged_pfs', plot_all_directions=True, plot_long_directional=False, plot_short_directional=False)\n",
    "_out = curr_active_pipeline.display('_display_directional_merged_pf_decoded_epochs') # scrollable_figure=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb499f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_merged_pf_decoded_epochs_marginals') # scrollable_figure=True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cce23e",
   "metadata": {},
   "source": [
    "# <a id='toc21_'></a>[✅ `batch_user_completion_helpers` Batch Computation Testing](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a098a16",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_1_'></a>[Call `compute_and_export_session_trial_by_trial_performance_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd8d05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_session_trial_by_trial_performance_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "return_full_decoding_results: bool = True\n",
    "save_hdf: bool = True\n",
    "save_csvs:bool = True\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "additional_session_context = None\n",
    "try:\n",
    "    if custom_suffix is not None:\n",
    "        additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "        print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "except NameError as err:\n",
    "    additional_session_context = None\n",
    "    print(f'NO CUSTOM SUFFIX.')    \n",
    "    \n",
    "active_laps_decoding_time_bin_size: float = 0.25\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_session_trial_by_trial_performance_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict, active_laps_decoding_time_bin_size=active_laps_decoding_time_bin_size,\n",
    "                                                # # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None)\n",
    "                                                )\n",
    "\n",
    "\n",
    "callback_outputs = _across_session_results_extended_dict['compute_and_export_session_trial_by_trial_performance_completion_function']\n",
    "a_trial_by_trial_result = callback_outputs['a_trial_by_trial_result']\n",
    "subset_neuron_IDs_dict = callback_outputs['subset_neuron_IDs_dict']\n",
    "subset_decode_results_dict = callback_outputs['subset_decode_results_dict']\n",
    "subset_decode_results_track_id_correct_performance_dict = callback_outputs['subset_decode_results_track_id_correct_performance_dict']\n",
    "subset_neuron_IDs_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ecbe84",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_2_'></a>[Call `export_rank_order_results_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22800b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import export_rank_order_results_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "# _across_session_results_extended_dict = {}\n",
    "\n",
    "# additional_session_context = None\n",
    "# try:\n",
    "#     if custom_suffix is not None:\n",
    "#         additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "#         print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "# except NameError as err:\n",
    "#     additional_session_context = None\n",
    "#     print(f'NO CUSTOM SUFFIX.')    \n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | export_rank_order_results_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                # # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None)\n",
    "                                                should_save_pkl=False, should_save_CSV=True,\n",
    "                                                )\n",
    "\n",
    "\n",
    "callback_outputs = _across_session_results_extended_dict['export_rank_order_results_completion_function']\n",
    "merged_complete_ripple_epoch_stats_df_output_path = callback_outputs['merged_complete_ripple_epoch_stats_df_output_path']\n",
    "minimum_inclusion_fr_Hz = callback_outputs['minimum_inclusion_fr_Hz']\n",
    "included_qclu_values = callback_outputs['included_qclu_values']\n",
    "print(f'merged_complete_ripple_epoch_stats_df_output_path: {merged_complete_ripple_epoch_stats_df_output_path}') # \"2024-11-15_Lab-2006-6-09_1-22-43_merged_complete_epoch_stats_df.csv\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34757ebd",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_3_'></a>[Call `compute_and_export_session_wcorr_shuffles_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf5cc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_session_wcorr_shuffles_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "# additional_session_context = None\n",
    "# try:\n",
    "#     if custom_suffix is not None:\n",
    "#         additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "#         print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "# except NameError as err:\n",
    "#     additional_session_context = None\n",
    "#     print(f'NO CUSTOM SUFFIX.')    \n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_session_wcorr_shuffles_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                # # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None)\n",
    "                                                )\n",
    "\n",
    "\n",
    "callback_outputs = _across_session_results_extended_dict['compute_and_export_session_wcorr_shuffles_completion_function']\n",
    "wcorr_shuffles_data_output_filepath = callback_outputs['wcorr_shuffles_data_output_filepath']\n",
    "standalone_MAT_filepath = callback_outputs['standalone_MAT_filepath']\n",
    "ripple_WCorrShuffle_df_export_CSV_path = callback_outputs['ripple_WCorrShuffle_df_export_CSV_path']\n",
    "print(f'wcorr_shuffles_data_output_filepath: {wcorr_shuffles_data_output_filepath}') # \"2024-11-15_Lab-2006-6-09_1-22-43_merged_complete_epoch_stats_df.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5693589d",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_4_'></a>[Call `compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fd5080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _subfn_compute_complete_df_metrics\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "try:\n",
    "    if _across_session_results_extended_dict is not None:\n",
    "        pass\n",
    "    else:\n",
    "        _across_session_results_extended_dict = {}\n",
    "except NameError as err:\n",
    "    _across_session_results_extended_dict = {}\n",
    "    \n",
    "additional_session_context = None\n",
    "try:\n",
    "    if custom_suffix is not None:\n",
    "        additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "        print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "except NameError as err:\n",
    "    additional_session_context = None\n",
    "    print(f'NO CUSTOM SUFFIX.')    \n",
    "\n",
    "# ripple_decoding_time_bin_size_override = 0.058\n",
    "ripple_decoding_time_bin_size_override = 0.025\n",
    "needs_recompute_heuristics = True\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                ripple_decoding_time_bin_size_override=ripple_decoding_time_bin_size_override,\n",
    "                                                laps_decoding_time_bin_size_override=None,\n",
    "                                                needs_recompute_heuristics=needs_recompute_heuristics, allow_append_to_session_h5_file=False, save_hdf=True, force_recompute_all_decoding=True, \n",
    "                                                )\n",
    "\n",
    "callback_outputs = _across_session_results_extended_dict['compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function']\n",
    "ripple_decoding_time_bin_size_override = callback_outputs['ripple_decoding_time_bin_size_override']\n",
    "print(f'ripple_decoding_time_bin_size_override: {ripple_decoding_time_bin_size_override}')\n",
    "output_csv_paths = callback_outputs['output_csv_paths']\n",
    "print(f'output_csv_paths: {output_csv_paths}')\n",
    "output_hdf_paths = callback_outputs['output_hdf_paths']\n",
    "print(f'output_hdf_paths: {output_hdf_paths}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c82f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benedict import benedict\n",
    "\n",
    "_across_session_results_extended_dict = benedict(_across_session_results_extended_dict)\n",
    "out_ripple_all_scores_merged_df_csv = Path(_across_session_results_extended_dict['compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function.output_csv_paths.ripple_all_scores_merged_df']).resolve()\n",
    "Assert.path_exists(out_ripple_all_scores_merged_df_csv)\n",
    "\n",
    "out_ripple_all_scores_merged_df_csv.parent\n",
    "'C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2025-03-08_Apogee-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 8, 9]-frateThresh_5.0-(ripple_all_scores_merged_df)_tbin-0.025.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286f1cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_across_session_results_extended_dict['compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8daa277",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_ripple_all_scores_merged_hdf5_files = [Path(v).resolve() for v in _across_session_results_extended_dict['compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function.output_hdf_paths']]\n",
    "Assert.path_exists(out_ripple_all_scores_merged_hdf5_files[0])\n",
    "print(f'out_ripple_all_scores_merged_hdf5_files[0]: \"{out_ripple_all_scores_merged_hdf5_files[0].as_posix()}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101d7d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_path = '/home/halechr/FastData/collected_outputs/2024-11-22_Lab-kdiba_gor01_one_2006-6-12_15-55-31__withNormalComputedReplays-qclu_[1, 2]-frateThresh_5.0-(ripple_all_scores_merged_df)_tbin-0.025.csv'\n",
    "csv_path = '/home/halechr/FastData/collected_outputs/2024-11-22_Lab-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0-(ripple_all_scores_merged_df)_tbin-0.016.csv'\n",
    "test_df = pd.read_csv(csv_path)\n",
    "test_df\n",
    "\n",
    "\n",
    "test_df[np.logical_not(test_df['short_best_jump'].isnull())]['short_best_jump']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121efeb3",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_5_'></a>[Call `perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5732d32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _subfn_compute_complete_df_metrics\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "return_full_decoding_results: bool = True\n",
    "save_hdf: bool = False\n",
    "save_csvs:bool = False\n",
    "# _across_session_results_extended_dict = {}\n",
    "\n",
    "try:\n",
    "    if _across_session_results_extended_dict is not None:\n",
    "        pass\n",
    "    else:\n",
    "        _across_session_results_extended_dict = {}\n",
    "except NameError as err:\n",
    "    _across_session_results_extended_dict = {}\n",
    "    \n",
    "additional_session_context = None\n",
    "try:\n",
    "    if custom_suffix is not None:\n",
    "        additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "        print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "except NameError as err:\n",
    "    additional_session_context = None\n",
    "    print(f'NO CUSTOM SUFFIX.')\n",
    "\n",
    "# %pdb on\n",
    "## Combine the output of `perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function` into two dataframes for the laps, one per-epoch and one per-time-bin\n",
    "# desired_shared_decoding_time_bin_sizes = np.linspace(start=0.030, stop=0.5, num=10)\n",
    "# desired_shared_decoding_time_bin_sizes = np.linspace(start=0.005, stop=0.03, num=10)\n",
    "# _across_session_results_extended_dict = _across_session_results_extended_dict | perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function(a_dummy, None,\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\tcurr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\tacross_session_results_extended_dict=_across_session_results_extended_dict, save_hdf=save_hdf, return_full_decoding_results=return_full_decoding_results,\n",
    "#                                                 desired_shared_decoding_time_bin_sizes=desired_shared_decoding_time_bin_sizes,\n",
    "#                                                 )\n",
    "\n",
    "# desired_laps_decoding_time_bin_size = [None] # doesn't work\n",
    "# desired_laps_decoding_time_bin_size = [1.5] # large so it doesn't take long\n",
    "# desired_ripple_decoding_time_bin_size = [0.010, 0.020]\n",
    "# desired_ripple_decoding_time_bin_size = [0.010, 0.020, 0.025]\n",
    "\n",
    "# desired_shared_decoding_time_bin_sizes = np.array([0.025, 0.030, 0.044, 0.050, 0.058, 0.072, 0.086, 0.100])\n",
    "# desired_shared_decoding_time_bin_sizes = np.array([0.025, 0.030, 0.044, 0.050, 0.058,])\n",
    "# desired_shared_decoding_time_bin_sizes = np.array([0.010, 0.025, 0.058,])\n",
    "desired_shared_decoding_time_bin_sizes = np.array([0.025, 0.050,])\n",
    "# desired_shared_decoding_time_bin_sizes = np.array([0.058,])\n",
    "# custom_all_param_sweep_options, param_sweep_option_n_values = parameter_sweeps(desired_laps_decoding_time_bin_size=desired_laps_decoding_time_bin_size,\n",
    "#                                                                                 desired_ripple_decoding_time_bin_size=desired_ripple_decoding_time_bin_size,\n",
    "#                                                                         use_single_time_bin_per_epoch=[False],\n",
    "#                                                                         minimum_event_duration=[desired_ripple_decoding_time_bin_size[-1]])\n",
    "\n",
    "# Shared time bin sizes\n",
    "custom_all_param_sweep_options, param_sweep_option_n_values = parameter_sweeps(desired_shared_decoding_time_bin_size=desired_shared_decoding_time_bin_sizes, use_single_time_bin_per_epoch=[False], minimum_event_duration=[desired_shared_decoding_time_bin_sizes[-1]]) # with Ripples\n",
    "\n",
    "\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict, save_hdf=save_hdf, save_csvs=save_csvs, return_full_decoding_results=return_full_decoding_results,\n",
    "                                                # desired_shared_decoding_time_bin_sizes = np.linspace(start=0.030, stop=0.5, num=4),\n",
    "                                                custom_all_param_sweep_options=custom_all_param_sweep_options, # directly provide the parameter sweeps\n",
    "                                                # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None)\n",
    "                                                additional_session_context = None,\n",
    "                                                )\n",
    "\n",
    "\n",
    "if return_full_decoding_results:\n",
    "    # with `return_full_decoding_results == True`\n",
    "    out_path, output_laps_decoding_accuracy_results_df, output_extracted_result_tuples, combined_multi_timebin_outputs_tuple, output_full_directional_merged_decoders_result, output_directional_decoders_epochs_decode_results_dict, output_saved_individual_sweep_files_dict = _across_session_results_extended_dict['perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function']\n",
    "    # validate the result:\n",
    "    {k:v.all_directional_laps_filter_epochs_decoder_result.decoding_time_bin_size for k,v in output_full_directional_merged_decoders_result.items()}\n",
    "    # assert np.all([np.isclose(dict(k)['desired_shared_decoding_time_bin_size'], v.all_directional_laps_filter_epochs_decoder_result.decoding_time_bin_size) for k,v in output_full_directional_merged_decoders_result.items()]), f\"the desired time_bin_size in the parameters should match the one used that will appear in the decoded result\"\n",
    "\n",
    "else:\n",
    "    # with `return_full_decoding_results == False`\n",
    "    out_path, output_laps_decoding_accuracy_results_df, output_extracted_result_tuples, combined_multi_timebin_outputs_tuple, output_saved_individual_sweep_files_dict = _across_session_results_extended_dict['perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function']\n",
    "    output_full_directional_merged_decoders_result = None\n",
    "\n",
    "\n",
    "(several_time_bin_sizes_laps_df, laps_out_path, several_time_bin_sizes_time_bin_laps_df, laps_time_bin_marginals_out_path), (several_time_bin_sizes_ripple_df, ripple_out_path, several_time_bin_sizes_time_bin_ripple_df, ripple_time_bin_marginals_out_path) = combined_multi_timebin_outputs_tuple\n",
    "\n",
    "#  exported files: {'laps_out_path': WindowsPath('K:/scratch/collected_outputs/2024-09-27-kdiba_gor01_two_2006-6-07_16-40-19_None-(laps_marginals_df).csv'), 'laps_time_bin_marginals_out_path': WindowsPath('K:/scratch/collected_outputs/2024-09-27-kdiba_gor01_two_2006-6-07_16-40-19_None-(laps_time_bin_marginals_df).csv'), 'ripple_out_path': WindowsPath('K:/scratch/collected_outputs/2024-09-27-kdiba_gor01_two_2006-6-07_16-40-19_None-(ripple_marginals_df).csv'), 'ripple_time_bin_marginals_out_path': WindowsPath('K:/scratch/collected_outputs/2024-09-27-kdiba_gor01_two_2006-6-07_16-40-19_None-(ripple_time_bin_marginals_df).csv')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fc9d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.get_all_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc64a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_saved_individual_sweep_files_dict\n",
    "# combined_multi_timebin_outputs_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcd8258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import DisplaySpecifyingIdentifyingContext, CollisionOutcome\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Computation import PipelineWithComputedPipelineStageMixin\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Computation import session_context_filename_formatting_fn\n",
    "from pyphocorehelpers.print_helpers import get_now_day_str, get_now_rounded_time_str\n",
    "\n",
    "curr_active_pipeline.session_name\n",
    "# complete_session_context, (curr_session_context,  additional_session_context) = curr_active_pipeline.get_complete_session_context(parts_separator='_')\n",
    "\n",
    "# complete_session_context.get_description(separator='|') # 'kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays_qclu_[1, 2, 4, 6, 7, 9]_frateThresh_5.0'\n",
    "# complete_session_context.get_specific_purpose_description(specific_purpose='filename_formatting') # 'kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays_qclu_[1, 2, 4, 6, 7, 9]_frateThresh_5.0'\n",
    "# curr_active_pipeline.get_complete_session_identifier_string(parts_separator='_', sub_parts_separator='|') # 'kdiba-gor01-one-2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0'\n",
    "curr_active_pipeline.get_complete_session_identifier_string(parts_separator='_', custom_parameter_keyvalue_parts_separator='-', session_identity_parts_separator='_')\n",
    "\n",
    "# \"kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_1.0\"\n",
    "\n",
    "out_path, out_filename, out_basename = curr_active_pipeline.build_complete_session_identifier_filename_string(output_date_str=None, data_identifier_str=\"(ripple_WCorrShuffle_df)\", parent_output_path=None, out_extension='.csv', extra_parts=None, ensure_no_duplicate_parts=False)\n",
    "out_filename # '2024-11-19_0148AM-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0-(ripple_WCorrShuffle_df).csv'\n",
    "# out_path, out_filename, out_basename = curr_active_pipeline.build_complete_session_identifier_filename_string(output_date_str=get_now_rounded_time_str(), data_identifier_str=\"(ripple_WCorrShuffle_df)\", parent_output_path=None, out_extension='.csv', extra_parts=None, ensure_no_duplicate_parts=False)\n",
    "# out_path, out_filename, out_basename = curr_active_pipeline.build_complete_session_identifier_filename_string(data_identifier_str=\"(ripple_WCorrShuffle_df)\", parent_output_path=None, out_extension='.csv', extra_parts=None, ensure_no_duplicate_parts=True)\n",
    "out_path, out_filename, out_basename = curr_active_pipeline.build_complete_session_identifier_filename_string(data_identifier_str=\"(ripple_WCorrShuffle_df)\", parent_output_path=None, out_extension='.csv', suffix_string='_tbin-0.025')\n",
    "out_filename  # '2024-11-19_0148AM-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0-(ripple_WCorrShuffle_df)_tbin-0.025.csv'\n",
    "\n",
    "# \"2024-11-18_1020PM-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_1.0-(ripple_WCorrShuffle_df)_tbin-0.025.csv\"\n",
    "# \"2024-11-19_0125AM-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0-(ripple_WCorrShuffle_df).csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8b1579",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_session_context.get_raw_identifying_context()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a21cabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_session_context\n",
    "\n",
    "# ['format_name', 'animal', 'exper_name', 'session_name']\n",
    "curr_session_context.get_description()\n",
    "curr_session_context.get_specific_purpose_description(specific_purpose='filename_formatting')\n",
    "\n",
    "curr_session_context.to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82ac92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_test_complete_session_context: DisplaySpecifyingIdentifyingContext = DisplaySpecifyingIdentifyingContext.init_from_context(a_context=curr_active_pipeline.get_session_context(), \n",
    "        specific_purpose_display_dict={'filename_formatting': session_context_filename_formatting_fn,},\n",
    "        #  display_dict={'epochs_source': lambda k, v: to_filename_conversion_dict[v],\n",
    "        #         'included_qclu_values': lambda k, v: f\"qclu_{v}\",\n",
    "        #         'minimum_inclusion_fr_Hz': lambda k, v: f\"frateThresh_{v:.1f}\",\n",
    "        # },\n",
    "    )\n",
    "_test_complete_session_context\n",
    "_test_complete_session_context.get_description()\n",
    "_test_complete_session_context.get_specific_purpose_description(specific_purpose='filename_formatting')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ef185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "additional_session_context.get_description()\n",
    "additional_session_context.get_specific_purpose_description(specific_purpose='filename_formatting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c4da3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _test_complete_session_context: DisplaySpecifyingIdentifyingContext = curr_session_context.adding_context(collision_prefix='_additional', strategy=CollisionOutcome.FAIL_IF_DIFFERENT, **additional_session_context.to_dict())\n",
    "_test_complete_session_context: DisplaySpecifyingIdentifyingContext = curr_session_context.adding_context(collision_prefix='_additional', strategy=CollisionOutcome.FAIL_IF_DIFFERENT, **additional_session_context.get_raw_identifying_context().to_dict())\n",
    "\n",
    "\n",
    "_test_complete_session_context\n",
    "_test_complete_session_context.get_description()\n",
    "_test_complete_session_context.get_specific_purpose_description(specific_purpose='filename_formatting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5026a5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.get_complete_session_identifier_string(parts_separator='_')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14a1e08",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_6_'></a>[Call `compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb60e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import DisplaySpecifyingIdentifyingContext, IdentifyingContext\n",
    "# from pyphoplacecellanalysis.General.Pipeline.Stages.Computation import PipelineWithComputedPipelineStageMixin\n",
    "\n",
    "complete_session_context, (session_context, additional_session_context) = curr_active_pipeline.get_complete_session_context()\n",
    "session_context\n",
    "additional_session_context\n",
    "complete_session_context\n",
    "\n",
    "\n",
    "session_context.get_description()\n",
    "additional_session_context.get_description()\n",
    "complete_session_context.get_description()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0d9a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_session_context.get_specific_purpose_description(specific_purpose='filename_formatting') # additional_session_context.get_specific_purpose_description(specific_purpose='filename_formatting')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76164cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_session_context.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e58214",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_session_context.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c303453",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_session_context.get_specific_purpose_description(specific_purpose='filename_formatting') # '-_withNormalComputedReplays-frateThresh_5.0-qclu_[1, 2, 4, 6, 7, 9]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9185d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_session_context.get_description() # 'kdiba_gor01_two_2006-6-12_16-53-46__withNormalComputedReplays_qclu_[1, 2, 4, 6, 7, 9]_frateThresh_5.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a789e08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_context = complete_session_context\n",
    "active_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc10c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "active_context.get_description()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497465d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "# return_full_decoding_results: bool = True\n",
    "# save_hdf: bool = True\n",
    "# save_csvs:bool = True\n",
    "\n",
    "try:\n",
    "    _across_session_results_extended_dict\n",
    "except NameError as e:\n",
    "    _across_session_results_extended_dict = {} # initialize\n",
    "\n",
    "additional_session_context = None\n",
    "try:\n",
    "    if custom_suffix is not None:\n",
    "        additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "        print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "except NameError as err:\n",
    "    additional_session_context = None\n",
    "    print(f'NO CUSTOM SUFFIX.')    \n",
    "    \n",
    "rank_order_results = curr_active_pipeline.global_computation_results.computed_data.get('RankOrder', None)\n",
    "if rank_order_results is not None:\n",
    "    minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "else:        \n",
    "    ## get from parameters:\n",
    "    minimum_inclusion_fr_Hz: float = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.included_qclu_values\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict, included_qclu_values=included_qclu_values, minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, drop_previous_result_and_compute_fresh=True, num_wcorr_shuffles=1024,\n",
    "                                                # # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None)\n",
    "                                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb49fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function' in _across_session_results_extended_dict\n",
    "compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_output = deepcopy(_across_session_results_extended_dict['compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function'])\n",
    "# compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_output\n",
    "callback_outputs = deepcopy(_across_session_results_extended_dict['compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function'])\n",
    "\n",
    "custom_suffix = callback_outputs['custom_suffix']\n",
    "replay_epoch_variations = callback_outputs['replay_epoch_variations']\n",
    "replay_epoch_outputs = callback_outputs['replay_epoch_outputs']\n",
    "\n",
    "replay_epoch_name = 'normal_computed'\n",
    "a_replay_epoch_variation: Epoch = replay_epoch_variations[replay_epoch_name]\n",
    "a_replay_epoch_outputs = replay_epoch_outputs[replay_epoch_name]\n",
    "\n",
    "## Unpack `a_replay_epoch_outputs`\n",
    "exported_evt_file_path = a_replay_epoch_outputs['exported_evt_file_path']\n",
    "did_change = a_replay_epoch_outputs['did_change']\n",
    "custom_save_filenames = a_replay_epoch_outputs['custom_save_filenames']\n",
    "custom_save_filepaths = a_replay_epoch_outputs['custom_save_filepaths']\n",
    "custom_suffix = a_replay_epoch_outputs['custom_suffix']\n",
    "wcorr_ripple_shuffle_all_df = a_replay_epoch_outputs['wcorr_ripple_shuffle_all_df']\n",
    "all_shuffles_only_best_decoder_wcorr_df = a_replay_epoch_outputs['all_shuffles_only_best_decoder_wcorr_df']\n",
    "standalone_pkl_filepath = a_replay_epoch_outputs['standalone_pkl_filepath']\n",
    "standalone_mat_filepath = a_replay_epoch_outputs['standalone_mat_filepath']\n",
    "active_context = a_replay_epoch_outputs['active_context']\n",
    "export_files_dict = a_replay_epoch_outputs['export_files_dict']\n",
    "# params_description_str = a_replay_epoch_outputs['params_description_str']\n",
    "# footer_annotation_text = a_replay_epoch_outputs['footer_annotation_text']\n",
    "# out_hist_fig_result = a_replay_epoch_outputs['out_hist_fig_result']\n",
    "\n",
    "\n",
    "custom_save_filenames\n",
    "custom_save_filepaths\n",
    "export_files_dict\n",
    "# print_keys_if_possible('callback_outputs', compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_output, max_depth=3)\n",
    "# a_replay_epoch_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d41b45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_strs = []\n",
    "for k, v in a_replay_epoch_outputs.items():\n",
    "    code_strs.append(f\"{k} = a_replay_epoch_outputs['{k}']\")\n",
    "\n",
    "print('\\n'.join(code_strs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6d6e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_output['export_files_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8beeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_epoch_outputs = deepcopy(compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_output['replay_epoch_outputs'])\n",
    "# replay_epoch_outputs\n",
    "\n",
    "normal_computed_replay_epoch_outputs = replay_epoch_outputs['normal_computed']\n",
    "normal_computed_replay_epoch_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a3bfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(replay_epoch_outputs.keys())\n",
    "\n",
    "export_files_dict = normal_computed_replay_epoch_outputs['export_files_dict']\n",
    "export_files_dict\n",
    "\n",
    "export_file_path_ripple_WCorrShuffle_df = export_files_dict['ripple_WCorrShuffle_df'] # 'W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-11-18_1020PM-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_1.0-(ripple_WCorrShuffle_df)_tbin-0.025.csv'\n",
    "export_file_path_ripple_WCorrShuffle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a46edd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_save_filepaths = normal_computed_replay_epoch_outputs['custom_save_filepaths'] ## these seem to be misnamed AND redundant\n",
    "custom_save_filepaths\n",
    "\n",
    "ripple_csv_out_path = custom_save_filepaths['ripple_csv_out_path'] # 'K:/scratch/collected_outputs/2024-11-18-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_1.0_withNormalComputedReplays-frateThresh_1.0-qclu_[1, 2, 4, 6, 7, 9]-(ripple_marginals_df).csv'\n",
    "ripple_csv_out_path\n",
    "\n",
    "ripple_csv_time_bin_marginals = custom_save_filepaths['ripple_csv_time_bin_marginals'] # 'K:/scratch/collected_outputs/2024-11-18-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_1.0_withNormalComputedReplays-frateThresh_1.0-qclu_[1, 2, 4, 6, 7, 9]-(ripple_time_bin_marginals_df).csv'\n",
    "ripple_csv_time_bin_marginals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3f496b",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_7_'></a>[Call `compute_and_export_session_trial_by_trial_performance_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be44b166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_session_trial_by_trial_performance_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "return_full_decoding_results: bool = True\n",
    "save_hdf: bool = True\n",
    "save_csvs:bool = True\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "additional_session_context = None\n",
    "try:\n",
    "    if custom_suffix is not None:\n",
    "        additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "        print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "except NameError as err:\n",
    "    additional_session_context = None\n",
    "    print(f'NO CUSTOM SUFFIX.')    \n",
    "    \n",
    "active_laps_decoding_time_bin_size: float = 0.025\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_session_trial_by_trial_performance_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict, active_laps_decoding_time_bin_size=active_laps_decoding_time_bin_size,\n",
    "                                                # # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None)\n",
    "                                                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e427751",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_outputs = _across_session_results_extended_dict['compute_and_export_session_trial_by_trial_performance_completion_function']\n",
    "a_trial_by_trial_result: TrialByTrialActivityResult = callback_outputs['a_trial_by_trial_result']\n",
    "subset_neuron_IDs_dict = callback_outputs['subset_neuron_IDs_dict']\n",
    "subset_decode_results_dict = callback_outputs['subset_decode_results_dict']\n",
    "subset_decode_results_track_id_correct_performance_dict = callback_outputs['subset_decode_results_track_id_correct_performance_dict']\n",
    "directional_active_lap_pf_results_dicts: Dict[types.DecoderName, TrialByTrialActivity] = a_trial_by_trial_result.directional_active_lap_pf_results_dicts\n",
    "_out_subset_decode_results_track_id_correct_performance_dict = callback_outputs['subset_decode_results_track_id_correct_performance_dict']\n",
    "_out_subset_decode_results_dict = callback_outputs['subset_decode_results_dict']\n",
    "(complete_decoded_context_correctness_tuple, laps_marginals_df, all_directional_pf1D_Decoder, all_test_epochs_df, test_all_directional_decoder_result, all_directional_laps_filter_epochs_decoder_result, _out_separate_decoder_results)  = _out_subset_decode_results_dict['any_decoder'] ## get the result for all cells\n",
    "filtered_laps_time_bin_marginals_df: pd.DataFrame = callback_outputs['subset_decode_results_time_bin_marginals_df_dict']['filtered_laps_time_bin_marginals_df']\n",
    "# active_results: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy({k:v.decoder_result for k, v in _out_separate_decoder_results[0].items()})\n",
    "active_results: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy({k:v for k, v in _out_separate_decoder_results[1].items()})\n",
    "filtered_laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276588e6",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_8_'></a>[Call `compute_and_export_cell_first_spikes_characteristics_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a69538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_cell_first_spikes_characteristics_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "try:\n",
    "    _across_session_results_extended_dict\n",
    "except NameError as e:\n",
    "    _across_session_results_extended_dict = {} # initialize\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_cell_first_spikes_characteristics_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                # # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None)\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855bd06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import figures_plot_cell_first_spikes_characteristics_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "try:\n",
    "    _across_session_results_extended_dict\n",
    "except NameError as e:\n",
    "    _across_session_results_extended_dict = {} # initialize\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | figures_plot_cell_first_spikes_characteristics_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                # # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None),\n",
    "                                                later_appearing_cell_lap_start_id=4,\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4624b606",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_9_'></a>[Call `kdiba_session_post_fixup_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef1b68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyphoplacecellanalysis.General.type_aliases as types\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import PostHocPipelineFixup, kdiba_session_post_fixup_completion_function, SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "# additional_session_context = None\n",
    "# try:\n",
    "#     if custom_suffix is not None:\n",
    "#         additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "#         print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "# except NameError as err:\n",
    "#     additional_session_context = None\n",
    "#     print(f'NO CUSTOM SUFFIX.')    \n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | kdiba_session_post_fixup_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                force_recompute=False, is_dry_run=False,\n",
    "                                                )\n",
    "\n",
    "\n",
    "# callback_outputs = _across_session_results_extended_dict['kdiba_session_post_fixup_completion_function'] # 'PostHocPipelineFixup'\n",
    "# loaded_track_limits = callback_outputs['loaded_track_limits']\n",
    "# a_config_dict = callback_outputs['a_config_dict']\n",
    "# print(f'loaded_track_limits: {loaded_track_limits}') \n",
    "    \n",
    "\n",
    "#  'computation_results[\"maze_any\"]': False, 'filtered_sessions[\"maze1_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze1_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze1_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze1_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze2_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze2_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze2_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze2_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze1_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_even\"].config.pix2cm': False, 'filtered_sessions[\"maze1_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.grid_bin': True, 'filtered_sessions[\"maze1_even\"].config.track_start_t': True, 'filtered_sessions[\"maze1_even\"].config.track_end_t': True, 'filtered_sessions[\"maze2_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_even\"].config.pix2cm': False, 'filtered_sessions[\"maze2_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.grid_bin': True, 'filtered_sessions[\"maze2_even\"].config.track_start_t': True, 'filtered_sessions[\"maze2_even\"].config.track_end_t': True, 'filtered_sessions[\"maze_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze_even\"].config.pix2cm': False, 'filtered_sessions[\"maze_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.grid_bin': True, 'filtered_sessions[\"maze_even\"].config.track_start_t': True, 'filtered_sessions[\"maze_even\"].config.track_end_t': True, 'filtered_sessions[\"maze1_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_any\"].config.pix2cm': False, 'filtered_sessions[\"maze1_any\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.grid_bin': True, 'filtered_sessions[\"maze1_any\"].config.track_start_t': True, 'filtered_sessions[\"maze1_any\"].config.track_end_t': True, 'filtered_sessions[\"maze2_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_any\"].config.pix2cm': False, 'filtered_sessions[\"maze2_any\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.grid_bin': True, 'filtered_sessions[\"maze2_any\"].config.track_start_t': True, 'filtered_sessions[\"maze2_any\"].config.track_end_t': True, 'filtered_sessions[\"maze_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze_any\"].config.pix2cm': False, 'filtered_sessions[\"maze_any\"].config.real_unit_grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.real_cm_grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.grid_bin': True, 'filtered_sessions[\"maze_any\"].config.track_start_t': False, 'filtered_sessions[\"maze_any\"].config.track_end_t': False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdfd908",
   "metadata": {},
   "outputs": [],
   "source": [
    "_across_session_results_extended_dict\n",
    "\n",
    "# 'filtered_sessions[\"maze1_odd\"].loaded_track_limits': False,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.pix2cm': False,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.real_unit_grid_bin_bounds': True,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.real_cm_grid_bin_bounds': True,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.grid_bin_bounds': True,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.grid_bin': True,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.track_start_t': True,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.track_end_t': True,\n",
    "\n",
    "['real_unit_grid_bin_bounds', 'real_cm_grid_bin_bounds', 'grid_bin_bounds', 'grid_bin', 'track_start_t', 'track_end_t']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c43d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.filtered_sessions[\"maze1_odd\"].config.real_unit_grid_bin_bounds\n",
    "curr_active_pipeline.filtered_sessions[\"maze_even\"].config.grid_bin_bounds\n",
    "curr_active_pipeline.filtered_sessions[\"maze1_odd\"].config.grid_bin_bounds\n",
    "curr_active_pipeline.filtered_sessions[\"maze1_odd\"].config.loaded_track_limits\n",
    "curr_active_pipeline.filtered_sessions[\"maze1_odd\"].config.track_start_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650ee1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.filtered_sessions['maze1_even'].config.real_unit_grid_bin_bounds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a3bd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# extended_computations_include_includelist=['ratemap_peaks_prominence2d', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring',] # do only specified\n",
    "computation_functions_name_includelist = ['_perform_baseline_placefield_computation', '_perform_time_dependent_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_time_dependent_pf_sequential_surprise_computation_perform_two_step_position_decoding_computation']\n",
    " #['rank_order_shuffle_analysis', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'ratemap_peaks_prominence2d', ] # do only specified\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=computation_functions_name_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=False, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=True)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963bf33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_include_function_names # {'_perform_pf_find_ratemap_peaks_computation': False, '_perform_time_dependent_pf_sequential_surprise_computation_perform_two_step_position_decoding_computation': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3d93e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=computation_functions_name_includelist, computation_kwargs_list=None, enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b70e5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# curr_active_pipeline.perform_computations(computation_functions_name_includelist=computation_functions_name_includelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2bc08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# curr_active_pipeline.active_configs # Dict[types.FilterContextName, InteractivePlaceCellConfig]\n",
    "# curr_active_pipeline.computation_results # Dict[types.FilterContextName, ComputationResult]\n",
    "\n",
    "# curr_active_pipeline.computation_results['maze1_odd'].computation_config # DynamicContainer\n",
    "# curr_active_pipeline.computation_results['maze1_odd'].computation_config.pf_params # PlacefieldComputationParameters\n",
    "\n",
    "\n",
    "grid_bin_bounds = deepcopy(curr_active_pipeline.computation_results['maze1_odd'].computation_config.pf_params.grid_bin_bounds) # ((0.0, 287.7697841726619), (115.10791366906477, 172.66187050359713))\n",
    "\n",
    "grid_bin = deepcopy(curr_active_pipeline.computation_results['maze1_odd'].computation_config.pf_params.grid_bin) # (3.8054171165052444, 1.4477079927649104)\n",
    "\n",
    "grid_bin_bounds\n",
    "# long_any_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1885e4bc",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_10_'></a>[Call `generalized_decode_epochs_dict_and_export_results_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a876004",
   "metadata": {
    "tags": [
     "2025-04-11 - full-session marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext, DisplaySpecifyingIdentifyingContext, set_context_print_options\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "\n",
    "# Usage example:\n",
    "reset_printer = set_context_print_options(include_property_names=True)\n",
    "\n",
    "# Later to restore default behavior:\n",
    "# reset_printer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb70e5e",
   "metadata": {
    "tags": [
     "2025-04-11 - full-session marginals"
    ]
   },
   "outputs": [],
   "source": [
    "import pyphoplacecellanalysis.General.type_aliases as types\n",
    "from neuropy.utils.mixins.binning_helpers import BinningContainer, BinningInfo\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import generalized_decode_epochs_dict_and_export_results_completion_function, SimpleBatchComputationDummy\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult #, KnownNamedDecoderTrainedComputeEpochsType, KnownNamedDecodingEpochsType, MaskedTimeBinFillType, DataTimeGrain, GenericResultTupleIndexType\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "\n",
    "epochs_decoding_time_bin_size: float = 0.050\n",
    "## Settings:\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-generalized_decode_epochs_dict_and_export_results_completion_function.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | generalized_decode_epochs_dict_and_export_results_completion_function(a_dummy, None,\n",
    "                                                    curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                    across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                    force_recompute=True,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tepochs_decoding_time_bin_size=epochs_decoding_time_bin_size,\n",
    "                                                )\n",
    "\n",
    "callback_outputs = _across_session_results_extended_dict['generalized_decode_epochs_dict_and_export_results_completion_function'] # 'PostHocPipelineFixup'\n",
    "a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult = callback_outputs['a_new_fully_generic_result']\n",
    "csv_save_paths_dict: Dict[str, Path] = callback_outputs['csv_save_paths_dict']\n",
    "a_new_fully_generic_result\n",
    "\n",
    "# a_config_dict = callback_outputs['a_config_dict']\n",
    "# print(f'loaded_track_limits: {loaded_track_limits}') \n",
    "\n",
    "## OUTPUTS: a_new_fully_generic_result\n",
    " \n",
    "#  'computation_results[\"maze_any\"]': False, 'filtered_sessions[\"maze1_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze1_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze1_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze1_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze2_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze2_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze2_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze2_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze1_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_even\"].config.pix2cm': False, 'filtered_sessions[\"maze1_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.grid_bin': True, 'filtered_sessions[\"maze1_even\"].config.track_start_t': True, 'filtered_sessions[\"maze1_even\"].config.track_end_t': True, 'filtered_sessions[\"maze2_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_even\"].config.pix2cm': False, 'filtered_sessions[\"maze2_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.grid_bin': True, 'filtered_sessions[\"maze2_even\"].config.track_start_t': True, 'filtered_sessions[\"maze2_even\"].config.track_end_t': True, 'filtered_sessions[\"maze_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze_even\"].config.pix2cm': False, 'filtered_sessions[\"maze_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.grid_bin': True, 'filtered_sessions[\"maze_even\"].config.track_start_t': True, 'filtered_sessions[\"maze_even\"].config.track_end_t': True, 'filtered_sessions[\"maze1_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_any\"].config.pix2cm': False, 'filtered_sessions[\"maze1_any\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.grid_bin': True, 'filtered_sessions[\"maze1_any\"].config.track_start_t': True, 'filtered_sessions[\"maze1_any\"].config.track_end_t': True, 'filtered_sessions[\"maze2_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_any\"].config.pix2cm': False, 'filtered_sessions[\"maze2_any\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.grid_bin': True, 'filtered_sessions[\"maze2_any\"].config.track_start_t': True, 'filtered_sessions[\"maze2_any\"].config.track_end_t': True, 'filtered_sessions[\"maze_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze_any\"].config.pix2cm': False, 'filtered_sessions[\"maze_any\"].config.real_unit_grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.real_cm_grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.grid_bin': True, 'filtered_sessions[\"maze_any\"].config.track_start_t': False, 'filtered_sessions[\"maze_any\"].config.track_end_t': False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bc6a92",
   "metadata": {
    "tags": [
     "2025-04-11 - full-session marginals"
    ]
   },
   "outputs": [],
   "source": [
    "# Save To pickle:\n",
    "## INPUTS: a_new_fully_generic_result\n",
    "# BATCH_DATE_TO_USE: str = f'2025-04-11_Apogee'\n",
    "# BATCH_DATE_TO_USE: str = f'2025-04-11_GL_{epochs_decoding_time_bin_size}'\n",
    "\n",
    "# parent_export_path = Path('/home/halechr/repos/Spike3D/data').resolve()\n",
    "parent_export_path = Path('data').resolve()\n",
    "\n",
    "a_new_fully_generic_result_export_basepath = parent_export_path.joinpath(f'{BATCH_DATE_TO_USE}_{epochs_decoding_time_bin_size}_a_new_fully_generic_result')\n",
    "# a_new_fully_generic_result_HDF5_export_path: Path = a_new_fully_generic_result_export_basepath.with_suffix('.h5').resolve()\n",
    "# a_new_fully_generic_result.to_hdf(file_path=a_new_fully_generic_result_HDF5_export_path, key='a_new_fully_generic_result', debug_print=True, OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True) # , OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True\n",
    "\n",
    "out_PKL_export_path: Path = a_new_fully_generic_result_export_basepath.with_suffix('.pkl').resolve()\n",
    "print(f'out_PKL_export_path: {out_PKL_export_path}')\n",
    "a_new_fully_generic_result.save(pkl_output_path=out_PKL_export_path)\n",
    "# \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca9a6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyphoplacecellanalysis.General.type_aliases as types\n",
    "from neuropy.utils.mixins.binning_helpers import BinningContainer, BinningInfo\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import generalized_decode_epochs_dict_and_export_results_completion_function, SimpleBatchComputationDummy\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult #, KnownNamedDecoderTrainedComputeEpochsType, KnownNamedDecodingEpochsType, MaskedTimeBinFillType, DataTimeGrain, GenericResultTupleIndexType\n",
    "\n",
    "## Load from previous pickle:\n",
    "# input_path = Path(f'/home/halechr/repos/Spike3D/data/2025-04-11_Apogee_a_new_fully_generic_result.pkl').resolve()\n",
    "input_path = Path(f'data/2025-04-11_Apogee_a_new_fully_generic_result.pkl').resolve()\n",
    "Assert.path_exists(input_path)\n",
    "a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult = GenericDecoderDictDecodedEpochsDictResult.from_file(pkl_path=input_path)\n",
    "a_new_fully_generic_result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532ec01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "epochs_decoding_time_bin_size = 0.025\n",
    "\n",
    "## ensure all optional fields are present before output:\n",
    "# Add the maze_id to the active_filter_epochs so we can see how properties change as a function of which track the replay event occured on:\n",
    "for k in list(a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict.keys()):\n",
    "    a_df = a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict[k]\n",
    "    ## note in per-epoch mode we use the start of the epoch (because for example laps are long and we want to see as soon as it starts) but for time bins we use the center time.\n",
    "    time_column_name: str = TimeColumnAliasesProtocol.find_first_extant_suitable_columns_name(a_df, col_connonical_name='t', required_columns_synonym_dict={\"t\":{'t_bin_center', 'lap_start_t', 'ripple_start_t', 'epoch_start_t'}}, should_raise_exception_on_fail=True)\n",
    "    assert time_column_name in a_df\n",
    "    a_df['delta_aligned_start_t'] = a_df[time_column_name] - t_delta ## subtract off t_delta\n",
    "    a_df = a_df.across_session_identity.add_session_df_columns(session_name=session_name, time_bin_size=epochs_decoding_time_bin_size, curr_session_t_delta=t_delta, time_col=time_column_name)\n",
    "    a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict[k] = a_df\n",
    "    # display(a_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64837420",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export to CSVs:\n",
    "csv_save_paths = {}\n",
    "active_export_parent_output_path = a_dummy.collected_outputs_path.resolve()\n",
    "# Assert.path_exists(parent_output_path)\n",
    "\n",
    "## INPUTS: collected_outputs_path\n",
    "decoding_time_bin_size: float = epochs_decoding_time_bin_size\n",
    "\n",
    "complete_session_context, (session_context, additional_session_context) = curr_active_pipeline.get_complete_session_context()\n",
    "active_context = complete_session_context ## This context isn't enough! Easiest to build using `curr_active_pipeline` directly.\n",
    "\n",
    "def _subfn_custom_export_df_to_csv(export_df: pd.DataFrame, data_identifier_str: str = f'(laps_marginals_df)', parent_output_path: Path=None):\n",
    "    \"\"\" captures CURR_BATCH_DATE_TO_USE, `curr_active_pipeline`\n",
    "    \"\"\"\n",
    "    output_date_str: str = get_now_rounded_time_str(rounded_minutes=10)\n",
    "    out_path, out_filename, out_basename = curr_active_pipeline.build_complete_session_identifier_filename_string(output_date_str=output_date_str, data_identifier_str=data_identifier_str, parent_output_path=parent_output_path, out_extension='.csv')\n",
    "    export_df.to_csv(out_path)\n",
    "    return out_path \n",
    "\n",
    "\n",
    "custom_export_df_to_csv_fn = _subfn_custom_export_df_to_csv\n",
    "\n",
    "\n",
    "# build_complete_session_identifier_filename_string\n",
    "\n",
    "\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "earliest_delta_aligned_t_start, t_delta, latest_delta_aligned_t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "# tbin_values_dict={'laps': decoding_time_bin_size, 'pbe': decoding_time_bin_size, 'non_pbe': decoding_time_bin_size, 'FAT': decoding_time_bin_size}\n",
    "\n",
    "# csv_save_paths_dict = GenericDecoderDictDecodedEpochsDictResult._perform_export_dfs_dict_to_csvs(extracted_dfs_dict=a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict,\n",
    "csv_save_paths_dict = a_new_fully_generic_result.export_csvs(\n",
    "                                        parent_output_path=active_export_parent_output_path.resolve(),\n",
    "                                        active_context=active_context, session_name=session_name, #curr_active_pipeline=curr_active_pipeline,\n",
    "                                        decoding_time_bin_size=decoding_time_bin_size,\n",
    "                                        curr_session_t_delta=t_delta, \n",
    "                                        custom_export_df_to_csv_fn=custom_export_df_to_csv_fn,\n",
    "                                        )\n",
    "\n",
    "print(f'csv_save_paths_dict: {csv_save_paths_dict}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac5441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_files_dict = {}\n",
    "\n",
    "tbin_values_dict = {'laps': decoding_time_bin_size, 'pbe': decoding_time_bin_size, 'non_pbe': decoding_time_bin_size, 'FAT': decoding_time_bin_size}\n",
    "\n",
    "## to restrict to specific variables\n",
    "# _df_variables_names = ['laps_weighted_corr_merged_df', 'ripple_weighted_corr_merged_df', 'laps_simple_pf_pearson_merged_df', 'ripple_simple_pf_pearson_merged_df']\n",
    "# if export_df_variable_names is None:\n",
    "#     # export all by default\n",
    "#     export_df_variable_names = _df_variables_names\n",
    "\n",
    "## Build the function that uses curr_active_pipeline to build the correct filename and actually output the .csv to the right place\n",
    "def _subfn_custom_export_df_to_csv(export_df: pd.DataFrame, data_identifier_str: str = f'(laps_marginals_df)', parent_output_path: Path=None):\n",
    "    \"\"\" captures `curr_active_pipeline`\n",
    "    \"\"\"\n",
    "    output_date_str: str = get_now_rounded_time_str(rounded_minutes=10)\n",
    "    out_path, out_filename, out_basename = curr_active_pipeline.build_complete_session_identifier_filename_string(output_date_str=output_date_str, data_identifier_str=data_identifier_str, parent_output_path=parent_output_path, out_extension='.csv')\n",
    "    export_df.to_csv(out_path)\n",
    "    return out_path \n",
    "\n",
    "    \n",
    "extracted_dfs_dict = a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict # {a_df_name:getattr(self, a_df_name) for a_df_name in export_df_variable_names}\n",
    "if len(extracted_dfs_dict) > 0:\n",
    "    export_files_dict = export_files_dict | a_new_fully_generic_result._perform_export_dfs_dict_to_csvs(extracted_dfs_dict=extracted_dfs_dict, parent_output_path=active_export_parent_output_path.resolve(),\n",
    "                                                                                                         tbin_values_dict=tbin_values_dict,\n",
    "                                                                                    active_context=active_context, session_name=session_name,\n",
    "                                                                                    # curr_session_t_delta=t_delta, user_annotation_selections=None, valid_epochs_selections=None, custom_export_df_to_csv_fn=custom_export_df_to_csv_fn,\n",
    "                                                                                    # use_single_FAT_df=False,\n",
    "                                                                                    use_single_FAT_df=True,\n",
    "                                                                                    custom_export_df_to_csv_fn=_subfn_custom_export_df_to_csv,\n",
    "                                                                                    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291c55c7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff34e956",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04b00958",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1269a3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_new_fully_generic_result.get_matching_contexts(IdentifyingContext(), return_multiple_matches=True, ) ## this only returns 3 results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97171718",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get old results\n",
    "# decoder_laps_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict)\n",
    "# all_directional_ripple_filter_epochs_decoder_result: DecodedFilterEpochsResult = directional_merged_decoders_result.laps_all_epoch_bins_marginals_df\n",
    "# decoder_laps_filter_epochs_decoder_result_dict.compute_marginals()\n",
    "laps_all_epoch_bins_marginals_df = deepcopy(directional_merged_decoders_result.laps_all_epoch_bins_marginals_df)\n",
    "laps_all_epoch_bins_marginals_df\n",
    "\n",
    "\n",
    "# active_marginals=ripple_track_identity_marginals, columns=['P_LR', 'P_RL']\n",
    "# active_marginals=ripple_track_identity_marginals, columns=['P_Long', 'P_Short']\n",
    "# _build_multiple_per_time_bin_marginals(a_decoder_result=decoder_laps_filter_epochs_decoder_result_dict, active_marginals_tuple=(laps_directional_all_epoch_bins_marginal, laps_track_identity_all_epoch_bins_marginal), columns_tuple=(['P_LR', 'P_RL'], ['P_Long', 'P_Short']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d1bf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get new results\n",
    "best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_matching_contexts(context_query=IdentifyingContext(trained_compute_epochs='laps', time_bin_size=0.025, known_named_decoding_epochs_type='laps', decoder_identifier='pseudo2D', masked_time_bin_fill_type='ignore'), debug_print=True, return_multiple_matches=False)\n",
    "\n",
    "## Plot them against each other for comparison\n",
    "a_decoded_marginal_posterior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3de43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_result.decoding_time_bin_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a9b927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext, CollisionOutcome\n",
    "\n",
    "matching_contexts, match_count = IdentifyingContext.find_best_matching_contexts(IdentifyingContext(trained_compute_epochs='non_pbe', time_bin_size=0.025, decoder_identifier='pseudo2D'), a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict, allow_partial_matches=True) # , known_named_decoding_epochs_type='laps'\n",
    "matching_contexts\n",
    "match_count\n",
    "\n",
    "# [Context(trained_compute_epochs= 'non_pbe', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_time_bin'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'last_valid', data_grain= 'per_time_bin'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'dropped', data_grain= 'per_time_bin')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f688b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "matching_contexts, match_count = IdentifyingContext.find_best_matching_contexts(IdentifyingContext(trained_compute_epochs='non_pbe', time_bin_size=0.025, decoder_identifier='pseudo2D', masked_time_bin_fill_type='ignore'), a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict, allow_partial_matches=True) # , masked_time_bin_fill_type='ignore', known_named_decoding_epochs_type='laps'\n",
    "matching_contexts\n",
    "match_count\n",
    "\n",
    "# [Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'ignore'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'non_pbe', masked_time_bin_fill_type= 'ignore')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d1660c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get new results\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=IdentifyingContext(trained_compute_epochs='non_pbe', time_bin_size=0.025), debug_print=True, return_multiple_matches=True) # , decoder_identifier='pseudo2D', known_named_decoding_epochs_type='laps'\n",
    "# flat_context_list\n",
    "# flat_result_context_dict\n",
    "\n",
    "\n",
    "# flat_decoded_marginal_posterior_df_context_dictFound 3 matches for a_result\n",
    "# Found 4 matches for a_decoder\n",
    "# Found 3 matches for a_decoded_marginal_posterior_df\n",
    "for k, v in flat_decoded_marginal_posterior_df_context_dict.items():\n",
    "\tdisplay(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7788f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_laps_filter_epochs_decoder_result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff79ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "\n",
    "curr_active_pipeline.reload_default_computation_functions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859549d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## firing statistics to bins instead of boolean masking by those meeting criteria\n",
    "spikes_df: pd.DataFrame = get_proper_global_spikes_df(curr_active_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1beeb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "# %aimport pyphoplacecellanalysis.Analysis.Decoder.context_dependent\n",
    "\n",
    "## Get a specific context to plot: \n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=2, decoder_identifier='long_LR', time_bin_size=0.025, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore')\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', time_bin_size=0.025, known_named_decoding_epochs_type='pbe') # , decoder_identifier='long_LR', masked_time_bin_fill_type='ignore', pfND_ndim=2\n",
    "\n",
    "best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, debug_print=True)\n",
    "print(f'best_matching_context: {best_matching_context}')\n",
    "# a_decoded_marginal_posterior_df\n",
    "## OUTPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder\n",
    "a_decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19730492",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "\n",
    "a_new_fully_generic_result = a_new_fully_generic_result.compute_continuous_fn(curr_active_pipeline=curr_active_pipeline, debug_print=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ba7dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(a_new_fully_generic_result.decoders.keys())\n",
    "\n",
    "\n",
    "search_context = IdentifyingContext(pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global') # , data_grain= 'per_time_bin -- not really relevant: ['masked_time_bin_fill_type', 'known_named_decoding_epochs_type', 'data_grain']\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=search_context, return_multiple_matches=True, debug_print=True)\n",
    "# a_context, a_result, a_decoder, _ = a_new_fully_generic_result.get_results_matching_contexts(context_query=search_context, return_multiple_matches=False, debug_print=True)\n",
    "# a_decoder\n",
    "flat_context_list\n",
    "# flat_decoder_context_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef17ee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get a specific context to plot:\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='long_LR', time_bin_size=0.025, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore')\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore') # , decoder_identifier='long_LR'\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, known_named_decoding_epochs_type='laps') # , masked_time_bin_fill_type='ignore', decoder_identifier='long_LR'\n",
    "\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', time_bin_size=0.025) # , known_named_decoding_epochs_type='laps'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "flat_context_list\n",
    "## OUTPUTS: flat_context_list: List[IdentifyingContext], flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict\n",
    "## OUTPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e64168",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', time_bin_size=0.025) # , known_named_decoding_epochs_type='laps'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "flat_context_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5977a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import build_single_plotly_marginal_scatter_and_hist_over_time\n",
    "\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "epochs_decoding_time_bin_size: float = 0.025\n",
    "\n",
    "#INPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder\n",
    "_flat_out_figs_dict = {}\n",
    "\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "flat_context_list\n",
    "\n",
    "for a_ctxt, a_decoded_marginal_posterior_df in flat_decoded_marginal_posterior_df_context_dict.items():\n",
    "    print(a_ctxt)\n",
    "    \n",
    "    # Add the maze_id to the active_filter_epochs so we can see how properties change as a function of which track the replay event occured on:\n",
    "    a_decoded_marginal_posterior_df = a_decoded_marginal_posterior_df.across_session_identity.add_session_df_columns(session_name=session_name, time_bin_size=epochs_decoding_time_bin_size, curr_session_t_delta=t_delta) # , time_col='t'\n",
    "        \n",
    "    a_fig, a_figure_context = build_single_plotly_marginal_scatter_and_hist_over_time(a_decoded_posterior_df=a_decoded_marginal_posterior_df, a_target_context=a_ctxt)\n",
    "    a_fig = a_fig.update_layout(height=300, margin=dict(t=20, b=0),  # Set top and bottom margins to 0\n",
    "                        )  # Set your desired height\n",
    "    _flat_out_figs_dict[a_figure_context] = a_fig\n",
    "\n",
    "    a_fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eac0c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _plot_plotly_stack_marginal_scatter_and_hist_over_time\n",
    "\n",
    "\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "epochs_decoding_time_bin_size: float = 0.025\n",
    "\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type='laps', data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "_flat_out_figs_dict = _plot_plotly_stack_marginal_scatter_and_hist_over_time(flat_decoded_marginal_posterior_df_context_dict=flat_decoded_marginal_posterior_df_context_dict, session_name=session_name, t_delta=t_delta, epochs_decoding_time_bin_size=epochs_decoding_time_bin_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307e4bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='non_pbe', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type='pbe', data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "_flat_out_figs_dict = _plot_plotly_stack_marginal_scatter_and_hist_over_time(flat_decoded_marginal_posterior_df_context_dict=flat_decoded_marginal_posterior_df_context_dict, session_name=session_name, t_delta=t_delta, epochs_decoding_time_bin_size=epochs_decoding_time_bin_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ff5846",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ensure all optional fields are present before output:\n",
    "# Add the maze_id to the active_filter_epochs so we can see how properties change as a function of which track the replay event occured on:\n",
    "for k in list(a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict.keys()):\n",
    "    a_df = a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict[k]\n",
    "    ## note in per-epoch mode we use the start of the epoch (because for example laps are long and we want to see as soon as it starts) but for time bins we use the center time.\n",
    "    time_column_name: str = TimeColumnAliasesProtocol.find_first_extant_suitable_columns_name(a_df, col_connonical_name='t', required_columns_synonym_dict={\"t\":{'t_bin_center', 'lap_start_t', 'ripple_start_t', 'epoch_start_t'}}, should_raise_exception_on_fail=True)\n",
    "    assert time_column_name in a_df\n",
    "    a_df['delta_aligned_start_t'] = a_df[time_column_name] - t_delta ## subtract off t_delta\n",
    "    a_df = a_df.across_session_identity.add_session_df_columns(session_name=session_name, time_bin_size=epochs_decoding_time_bin_size, curr_session_t_delta=t_delta, time_col=time_column_name)\n",
    "    a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict[k] = a_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4819748",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='non_pbe', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size= 0.025, data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps', known_named_decoding_epochs_type='pbe'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "_flat_out_figs_dict = _plot_plotly_stack_marginal_scatter_and_hist_over_time(flat_decoded_marginal_posterior_df_context_dict=flat_decoded_marginal_posterior_df_context_dict, session_name=session_name, t_delta=t_delta, epochs_decoding_time_bin_size=epochs_decoding_time_bin_size)\n",
    "# flat_decoded_marginal_posterior_df_context_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61b7ea0",
   "metadata": {},
   "source": [
    "#### 🟢🟢⚓🟢🟢 Add to SpikeRaster2D as tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fd2c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot = spike_raster_window.spike_raster_plt_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1b9486",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=0.025, masked_time_bin_fill_type='last_valid', data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "print(f'flat_context_list: {flat_context_list}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddc3d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_context = IdentifyingContext(known_named_decoding_epochs_type='global') # , data_grain= 'per_time_bin -- not really relevant: ['masked_time_bin_fill_type', 'known_named_decoding_epochs_type', 'data_grain']\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=search_context, return_multiple_matches=True, debug_print=True)\n",
    "# a_context, a_result, a_decoder, _ = a_new_fully_generic_result.get_results_matching_contexts(context_query=search_context, return_multiple_matches=False, debug_print=True)\n",
    "# a_decoder\n",
    "flat_context_list\n",
    "# flat_decoder_context_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963dd30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, DockDisplayColors\n",
    "\n",
    "\n",
    "search_context = IdentifyingContext(pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global') # , data_grain= 'per_time_bin -- not really relevant: ['masked_time_bin_fill_type', 'known_named_decoding_epochs_type', 'data_grain']\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=search_context, return_multiple_matches=True, debug_print=True)\n",
    "# a_context, a_result, a_decoder, _ = a_new_fully_generic_result.get_results_matching_contexts(context_query=search_context, return_multiple_matches=False, debug_print=True)\n",
    "# a_decoder\n",
    "flat_context_list\n",
    "# flat_decoder_context_dict\n",
    "\n",
    "unique_decoder_names_map: Dict = {'laps': ['long_LR', 'long_RL', 'short_LR', 'short_RL'], 'non_pbe': ['long', 'short']}\n",
    "\n",
    "\n",
    "for a_ctxt, a_result in flat_result_context_dict.items():\n",
    "    ## INPUTS: laps_pseudo2D_continuous_specific_decoded_result: DecodedFilterEpochsResult\n",
    "    a_decoder = flat_decoder_context_dict[a_ctxt]\n",
    "    \n",
    "    unique_decoder_names = unique_decoder_names_map[a_ctxt.get('trained_compute_epochs', None)] # ['long', 'short']\n",
    "    unique_decoder_names = [f\"{a_ctxt}[{k}]\" for k in unique_decoder_names]\n",
    "    \n",
    "    a_pseudo2D_split_to_1D_continuous_results_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = a_result.split_pseudo2D_result_to_1D_result(pseudo2D_decoder_names_list=unique_decoder_names)    \n",
    "    a_pseudo2D_split_to_1D_continuous_results_dict = {k:v for k, (_o, v) in zip(unique_decoder_names, a_pseudo2D_split_to_1D_continuous_results_dict.items())} ## change to the long unique indicies so they match the decoders\n",
    "    \n",
    "    # a_pseudo2D_split_to_1D_continuous_results_dict\n",
    "    \n",
    "    active_time_bin_size: float = a_result.decoding_time_bin_size\n",
    "    info_string: str = f'{active_time_bin_size:.3f}'\n",
    "    dock_group_sep_character: str = '_'\n",
    "    showCloseButton = True\n",
    "    _common_dock_config_kwargs = {'dock_group_names': [dock_group_sep_character.join([f'LapsDecode', info_string])], 'showCloseButton': showCloseButton}\n",
    "\n",
    "    # dock_configs: Dict[str, CustomDockDisplayConfig] = {k:deepcopy(CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_global_dock_colors, **_common_dock_config_kwargs)) for k in unique_decoder_names}\n",
    "    dock_configs: Dict[str, CustomDockDisplayConfig] = {k:deepcopy(CustomDockDisplayConfig(custom_get_colors_callback_fn=DockDisplayColors.get_random_dock_colors_for_key_fn(key=k), **_common_dock_config_kwargs)) for k in unique_decoder_names}\n",
    "    \n",
    "    # flat_decoder_context_dict\n",
    "\n",
    "    # pf1D_Decoder_dict = {k:deepcopy(v) for k, v in a_decoder.items() if k in unique_decoder_names}\n",
    "\n",
    "    pf1D_Decoder_dict = {k:deepcopy(a_decoder) for k in unique_decoder_names} ## this is dumb, but it provides xlims!\n",
    "\n",
    "    output_dict = active_2d_plot.add_docked_decoded_results_dict_tracks(name=f'LapsDecode', a_decoded_result_dict=a_pseudo2D_split_to_1D_continuous_results_dict, dock_configs=dock_configs,\n",
    "                                                                                                pf1D_Decoder_dict=pf1D_Decoder_dict,\n",
    "                                                                                                measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "                                                                                                extended_dock_title_info=info_string)\n",
    "\n",
    "\n",
    "    # # pf1D_Decoder_dict = {k:deepcopy(v) for k, v in a_decoder.items() if k in unique_decoder_names}\n",
    "\n",
    "\n",
    "    # ## a_1D_continuous_decoded_result: SingleEpochDecodedResult\n",
    "    # a_dock_config = dock_configs[a_decoder_name]\n",
    "    # a_1D_decoder: BasePositionDecoder = pf1D_Decoder_dict[a_decoder_name]\n",
    "    # _out_tuple = self.add_docked_decoded_posterior_track_from_result(name=f'{name}[{a_decoder_name}]', a_dock_config=a_dock_config, a_1D_decoded_result=a_1D_decoded_result,\n",
    "    #                                                                                         xbin = deepcopy(a_1D_decoder.xbin), measured_position_df=deepcopy(measured_position_df), **kwargs) # , should_defer_render=False\n",
    "    # identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = _out_tuple\n",
    "    # ## Add `a_decoded_result` to the plots_data\n",
    "    # widget.plots_data.a_decoded_result = a_1D_decoded_result\n",
    "    # widget.plots_data.a_decoder = deepcopy(a_1D_decoder)\n",
    "    # output_dict[a_decoder_name] = (identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem) ## add again\n",
    "\n",
    "\n",
    "# output_dict = active_2d_plot.add_docked_decoded_results_dict_tracks(name=f'LapsDecode', a_decoded_result_dict=a_pseudo2D_split_to_1D_continuous_results_dict, dock_configs=dock_configs, pf1D_Decoder_dict=flat_decoder_context_dict,\n",
    "#                                                                                             measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "#                                                                                             extended_dock_title_info=info_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfc623b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_decoding_time_bin_size: float = 0.025\n",
    "\n",
    "for a_ctxt, a_df in flat_decoded_marginal_posterior_df_context_dict.items():\n",
    "    time_bin_size = epochs_decoding_time_bin_size\n",
    "    info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "    plot_row_identifier: str = a_ctxt.get_description(subset_includelist=['known_named_decoding_epochs_type', 'masked_time_bin_fill_type'], include_property_names=True, key_value_separator=':', separator='|', replace_separator_in_property_names='-')\n",
    "    a_time_window_centers = a_df['t_bin_center'].to_numpy() \n",
    "    a_1D_posterior = a_df[['P_Long', 'P_Short']].to_numpy().T\n",
    "\n",
    "    identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dock_item = active_2d_plot.add_docked_marginal_track(name=plot_row_identifier,  # 'non-PBE_marginal_over_track_ID',\n",
    "                                                                                            time_window_centers=a_time_window_centers, a_1D_posterior=a_1D_posterior, extended_dock_title_info=info_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e2705a",
   "metadata": {},
   "source": [
    "# <a id='toc24_'></a>[2025-03-04 - Final Histogram](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7a94ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benedict import benedict\n",
    "filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict = benedict(a_general_decoder_dict_decoded_epochs_dict_result.filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict)\n",
    "filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict.keypaths() # ['laps', 'laps.ignore', 'laps.last_valid', 'laps.nan_filled', 'non_pbe', 'non_pbe.ignore', 'non_pbe.last_valid', 'non_pbe.nan_filled', 'pbe', 'pbe.ignore', 'pbe.last_valid', 'pbe.nan_filled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaeaed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cb49e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "template: str = 'plotly_dark' # set plotl template\n",
    "pio.templates.default = template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed73ff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_export_path = Path(r'K:\\scratch\\output').resolve()\n",
    "non_pbe_marginals_PKL_export_path: Path = non_pbe_marginals_export_basepath.with_suffix('.pkl').resolve()\n",
    "a_general_decoder_dict_decoded_epochs_dict_result.save(pkl_output_path=non_pbe_marginals_PKL_export_path)\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26590c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_a_general_decoder_dict_decoded_epochs_dict_result: GeneralDecoderDictDecodedEpochsDictResult =  GeneralDecoderDictDecodedEpochsDictResult.from_file(pkl_path=non_pbe_marginals_PKL_export_path)\n",
    "loaded_a_general_decoder_dict_decoded_epochs_dict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fde2b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_pbe_marginals_export_basepath = parent_export_path.joinpath(f'{BATCH_DATE_TO_USE}_non_pbe_marginals_export')\n",
    "non_pbe_marginals_HDF5_export_path: Path = non_pbe_marginals_export_basepath.with_suffix('.h5').resolve()\n",
    "a_general_decoder_dict_decoded_epochs_dict_result.to_hdf(file_path=non_pbe_marginals_HDF5_export_path, key='a_general_decoder_dict_decoded_epochs_dict_result', debug_print=True) # , OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c933ae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: a_new_fully_generic_result\n",
    "BATCH_DATE_TO_USE: str = f'2025-04-11_Apogee'\n",
    "\n",
    "# parent_export_path = Path('/home/halechr/repos/Spike3D/data').resolve()\n",
    "parent_export_path = Path('data').resolve()\n",
    "\n",
    "a_new_fully_generic_result_export_basepath = parent_export_path.joinpath(f'{BATCH_DATE_TO_USE}_a_new_fully_generic_result')\n",
    "# a_new_fully_generic_result_HDF5_export_path: Path = a_new_fully_generic_result_export_basepath.with_suffix('.h5').resolve()\n",
    "# a_new_fully_generic_result.to_hdf(file_path=a_new_fully_generic_result_HDF5_export_path, key='a_new_fully_generic_result', debug_print=True, OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True) # , OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True\n",
    "\n",
    "out_PKL_export_path: Path = a_new_fully_generic_result_export_basepath.with_suffix('.pkl').resolve()\n",
    "print(f'out_PKL_export_path: {out_PKL_export_path}')\n",
    "a_new_fully_generic_result.save(pkl_output_path=out_PKL_export_path)\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a003258",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loaded_a_general_decoder_dict_decoded_epochs_dict_result: GeneralDecoderDictDecodedEpochsDictResult =  GeneralDecoderDictDecodedEpochsDictResult.from_file(pkl_path=out_PKL_export_path)\n",
    "loaded_a_general_decoder_dict_decoded_epochs_dict_result\n",
    "non_pbe_marginals_export_basepath = parent_export_path.joinpath(f'{BATCH_DATE_TO_USE}_non_pbe_marginals_export')\n",
    "non_pbe_marginals_HDF5_export_path: Path = non_pbe_marginals_export_basepath.with_suffix('.h5').resolve()\n",
    "a_general_decoder_dict_decoded_epochs_dict_result.to_hdf(file_path=non_pbe_marginals_HDF5_export_path, key='a_general_decoder_dict_decoded_epochs_dict_result', debug_print=True) # , OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c0a51e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02555045",
   "metadata": {},
   "outputs": [],
   "source": [
    "## OUTPUTS: flat_context_list: List[IdentifyingContext], flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict\n",
    "## OUTPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc27e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute and plot the new tracks:\n",
    "# non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict, non_PBE_marginal_over_track_ID, (time_bin_containers, time_window_centers) = nonPBE_results._build_merged_joint_placefields_and_decode(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)))\n",
    "unique_added_track_identifiers = nonPBE_results.add_to_SpikeRaster2D_tracks(active_2d_plot=active_2d_plot, non_PBE_all_directional_pf1D_Decoder=non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result=pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict=continuous_decoded_results_dict, non_PBE_marginal_over_track_ID=non_PBE_marginal_over_track_ID, time_window_centers=time_window_centers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8a218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.enable_interaction_events_debug_print = True\n",
    "spike_raster_window.enable_debug_print = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645e0aa6",
   "metadata": {
    "tags": [
     "active-2025-03-11"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import build_single_plotly_marginal_scatter_and_hist_over_time\n",
    "\n",
    "#INPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder\n",
    "_flat_out_figs_dict = {}\n",
    "a_fig, a_figure_context = build_single_plotly_marginal_scatter_and_hist_over_time(a_decoded_posterior_df=a_decoded_marginal_posterior_df, a_target_context=a_target_context)\n",
    "_flat_out_figs_dict[a_figure_context] = a_fig\n",
    "\n",
    "a_fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d39b4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoded_marginal_posterior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69dd71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = a_general_decoder_dict_decoded_epochs_dict_result.build_plotly_marginal_scatter_and_hist_over_time()\n",
    "\n",
    "# _flat_out_figs_dict = a_general_decoder_dict_decoded_epochs_dict_result.build_plotly_marginal_scatter_and_hist_over_time(debug_print=False)\n",
    "\n",
    "# display(list(_flat_out_figs_dict.values())[0])\n",
    "\n",
    "# Display all figures in the dictionary\n",
    "for fig in _flat_out_figs_dict.values():\n",
    "    display(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33e4ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_pre_post_delta_scatter\n",
    "## INPUTS: a_general_decoder_dict_decoded_epochs_dict_result\n",
    "\n",
    "histogram_bins: int = 25\n",
    "debug_print = False\n",
    "# 'masked_laps': 'Laps (Masked)', 'masked_laps': 'Laps (Nan-masked)')\n",
    "# masked_bin_fill_modes: ['ignore', 'last_valid', 'nan_filled', 'dropped']\n",
    "\n",
    "_flat_out_figs_dict = {}\n",
    "\n",
    "for a_known_decoded_epochs_type, a_decoded_posterior_dfs_dict in a_general_decoder_dict_decoded_epochs_dict_result.filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict.items():\n",
    "    if debug_print:\n",
    "        print(f'a_known_decoded_epochs_type: \"{a_known_decoded_epochs_type}\"')\n",
    "    for masking_bin_fill_mode, a_decoded_posterior_df in a_decoded_posterior_dfs_dict.items():\n",
    "        if debug_print:\n",
    "            print(f'\\tmasking_bin_fill_mode: \"{masking_bin_fill_mode}\"')\n",
    "        plot_row_identifier: str = f'{a_known_decoded_epochs_type.capitalize()} - {masking_bin_fill_mode.capitalize()} decoder' # should be like 'Laps (Masked) from Non-PBE decoder'\n",
    "        \n",
    "        fig, figure_context = plotly_pre_post_delta_scatter(data_results_df=deepcopy(a_decoded_posterior_df), out_scatter_fig=None, \n",
    "                                        histogram_variable_name='P_Short', hist_kwargs=dict(), histogram_bins=histogram_bins,\n",
    "                                        common_plot_kwargs=dict(),\n",
    "                                        px_scatter_kwargs = dict(x='delta_aligned_start_t', y='P_Short', title=plot_row_identifier))\n",
    "        _flat_out_figs_dict[figure_context] = fig\n",
    "        \n",
    "# ['laps', 'non_PBE']\n",
    "# ['a', 'masked', 'dropping_masked']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b1d063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(list(_flat_out_figs_dict.values())[0])\n",
    "\n",
    "# # Display all figures in the dictionary\n",
    "# for fig in _flat_out_figs_dict.values():\n",
    "#     display(fig)\n",
    "\n",
    "from pyphoplacecellanalysis.External.pyqtgraph.Qt import QtWidgets\n",
    "from pyphoplacecellanalysis.External.pyqtgraph.dockarea import DockArea, Dock\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.PlotlyFigurePyQtWidget import PlotlyDockContainer, PlotlyWidget\n",
    "\n",
    "## INPUTS: _flat_out_figs_dict\n",
    "# Create the container\n",
    "container: PlotlyDockContainer = PlotlyDockContainer()\n",
    "# Display all figures in the dictionary\n",
    "for a_fig_context, fig in _flat_out_figs_dict.items():\n",
    "    container.add_figure(fig, name=f\"{a_fig_context}\", position='bottom')\n",
    "\n",
    "# Show the container\n",
    "container.resize(1200, 800)\n",
    "container.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2b07d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8877a367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7629aca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1406bcd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d06c39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bf036ef",
   "metadata": {},
   "source": [
    "### <a id='toc24_1_1_'></a>[Plotting Tracks on Spike2DRaster](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b821068",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Never used: all at once:\n",
    "a_dock_config = None\n",
    "_out_tuple = active_2d_plot.add_docked_decoded_posterior_track_from_result(name=f'laps_pseudo2D_continuous_specific_decoded_result', a_dock_config=a_dock_config, a_1D_decoded_result=laps_pseudo2D_continuous_specific_decoded_result,\n",
    "                                                                                xbin = deepcopy(non_PBE_all_directional_pf1D_Decoder.xbin), measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "                                                                                extended_dock_title_info='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb37b1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, DockDisplayColors\n",
    "\n",
    "active_time_bin_size: float = pseudo2D_continuous_specific_decoded_result.decoding_time_bin_size\n",
    "info_string: str = f'{active_time_bin_size:.3f}'\n",
    "dock_group_sep_character: str = '_'\n",
    "showCloseButton = True\n",
    "_common_dock_config_kwargs = {'dock_group_names': [dock_group_sep_character.join([f'LapsDecode', info_string])], 'showCloseButton': showCloseButton}\n",
    "dock_configs: Dict[str, CustomDockDisplayConfig] = dict(zip(unique_decoder_names,\n",
    "                        (CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_long_dock_colors, **_common_dock_config_kwargs),\n",
    "                        CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_short_dock_colors, **_common_dock_config_kwargs))))\n",
    "                        \n",
    "\n",
    "pf1D_Decoder_dict = {k:deepcopy(v) for k, v in results1D.decoders.items() if k in unique_decoder_names}\n",
    "\n",
    "output_dict = active_2d_plot.add_docked_decoded_results_dict_tracks(name=f'LapsDecode', a_decoded_result_dict=laps_pseudo2D_split_to_1D_continuous_results_dict, dock_configs=dock_configs, pf1D_Decoder_dict=pf1D_Decoder_dict,\n",
    "                                                                                            measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "                                                                                            extended_dock_title_info=info_string, dockSize=(10, 4))\n",
    "\n",
    "a_dock_config = CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_global_dock_colors, **_common_dock_config_kwargs)\n",
    "marginal_y_p_x_given_n_list = [deepcopy(v.p_x_given_n) for v in laps_pseudo2D_continuous_specific_decoded_result.marginal_y_list]\n",
    "_out_tuple = active_2d_plot.add_docked_decoded_posterior_slices_track(name=f'PBE_marginal_over_track_ID', a_dock_config=a_dock_config,\n",
    "                                                                                slices_time_window_centers=laps_pseudo2D_continuous_specific_decoded_result.time_window_centers, slices_posteriors=marginal_y_p_x_given_n_list,\n",
    "                                                                                xbin=None, xbin_labels=unique_decoder_names, measured_position_df=None, extended_dock_title_info=info_string, posterior_heatmap_imshow_kwargs=dict(), dockSize=(10, 1))\n",
    "output_dict['PBE_marginal_over_track_ID'] = _out_tuple\n",
    "# active_2d_plot.layout_dockGroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44547381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "\n",
    "## INPUTS: masked_laps_pseudo2D_split_to_1D_continuous_results_dict, masked_laps_pseudo2D_continuous_specific_decoded_result\n",
    "_common_dock_config_kwargs = {'dock_group_names': [dock_group_sep_character.join([f'MASKED_LapsDecode', info_string])], 'showCloseButton': showCloseButton}\n",
    "masked_dock_configs: Dict[str, CustomDockDisplayConfig] = dict(zip(unique_decoder_names,\n",
    "                        (CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_long_dock_colors, **_common_dock_config_kwargs),\n",
    "                        CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_short_dock_colors, **_common_dock_config_kwargs))))\n",
    "                        \n",
    "\n",
    "pf1D_Decoder_dict = {k:deepcopy(v) for k, v in results1D.decoders.items() if k in unique_decoder_names}\n",
    "\n",
    "MASKED_output_dict = active_2d_plot.add_docked_decoded_results_dict_tracks(name=f'MASKED_LapsDecode', a_decoded_result_dict=masked_laps_pseudo2D_split_to_1D_continuous_results_dict, dock_configs=masked_dock_configs, pf1D_Decoder_dict=pf1D_Decoder_dict,\n",
    "                                                                                            measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "                                                                                            extended_dock_title_info=info_string, dockSize=(10, 4))\n",
    "\n",
    "a_dock_config = CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_global_dock_colors, **_common_dock_config_kwargs)\n",
    "marginal_y_p_x_given_n_list = [deepcopy(v.p_x_given_n) for v in masked_laps_pseudo2D_continuous_specific_decoded_result.marginal_y_list]\n",
    "_masked_out_tuple = active_2d_plot.add_docked_decoded_posterior_slices_track(name=f'MASKED_PBE_marginal_over_track_ID', a_dock_config=a_dock_config,\n",
    "                                                                                slices_time_window_centers=masked_laps_pseudo2D_continuous_specific_decoded_result.time_window_centers, slices_posteriors=marginal_y_p_x_given_n_list,\n",
    "                                                                                xbin=None, xbin_labels=unique_decoder_names, measured_position_df=None, extended_dock_title_info=info_string, posterior_heatmap_imshow_kwargs=dict(), dockSize=(10, 1))\n",
    "MASKED_output_dict['MASKED_PBE_marginal_over_track_ID'] = _masked_out_tuple\n",
    "# active_2d_plot.layout_dockGroups()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7abd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flat_time_window_centers, flat_marginal_y_p_x_given_n = laps_pseudo2D_continuous_specific_decoded_result.get_pseudo2D_result_to_pseudo2D_marginalization_result(pseudo2D_decoder_names_list=unique_decoder_names) ## this is wrong\n",
    "time_bin_size = epochs_decoding_time_bin_size\n",
    "info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "# identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dock_item = active_2d_plot.add_docked_marginal_track(name='non-PBE_marginal_over_track_ID',\n",
    "#                                                                                         time_window_centers=flat_time_window_centers, a_1D_posterior=flat_marginal_y_p_x_given_n, extended_dock_title_info=info_string)\n",
    "\n",
    "marginal_y_p_x_given_n_list = [deepcopy(v.p_x_given_n) for v in laps_pseudo2D_continuous_specific_decoded_result.marginal_y_list]\n",
    "_out_tuple = active_2d_plot.add_docked_decoded_posterior_slices_track(name=f'PBE_marginal_over_track_ID', a_dock_config=None,\n",
    "                                                                                slices_time_window_centers=laps_pseudo2D_continuous_specific_decoded_result.time_window_centers, slices_posteriors=marginal_y_p_x_given_n_list,\n",
    "                                                                                xbin=None, measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "                                                                                extended_dock_title_info=info_string, posterior_heatmap_imshow_kwargs=dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05b98bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_pseudo2D_continuous_specific_decoded_result.p_x_given_n_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcb7eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timebins, flat_time_bin_containers, timebins_p_x_given_n = laps_pseudo2D_continuous_specific_decoded_result.flatten()\n",
    "\n",
    "desired_total_n_timebins, updated_is_masked_bin, updated_time_bin_containers, updated_timebins_p_x_given_n = laps_pseudo2D_continuous_specific_decoded_result.flatten_to_masked_values()\n",
    "\n",
    "# flat_time_bin_containers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e43cb3",
   "metadata": {},
   "source": [
    "### <a id='toc24_1_2_'></a>[Plotting Histograms Directly](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff6b535",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot: directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_pre_post_delta_scatter\n",
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import plot_histograms\n",
    "\n",
    "## INPUTS: masked_pseudo2D_continuous_specific_decoded_result\n",
    "masked_pseudo2D_continuous_specific_decoded_result = deepcopy(masked_pseudo2D_continuous_specific_decoded_result)\n",
    "ripple_weighted_corr_merged_df\n",
    "\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "## INPUTS: track_marginal_posterior_df\n",
    "\n",
    "# You can use it like this:\n",
    "_out0: \"MatplotlibRenderPlots\" = plot_histograms(data_type='Laps', session_spec='1 Session', data_results_df=track_marginal_posterior_df, time_bin_duration_str=\"25 ms\")\n",
    "# _out1: \"MatplotlibRenderPlots\" = plot_histograms(data_type='Ripples', session_spec='All Sessions', data_results_df=all_sessions_ripple_time_bin_df, time_bin_duration_str=\"75 ms\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20af0225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "\n",
    "if ('DirectionalDecodersEpochsEvaluations' in curr_active_pipeline.global_computation_results.computed_data) and (curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations'] is not None):\n",
    "    directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "    directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)\n",
    "\n",
    "    ## UNPACK HERE via direct property access:\n",
    "    pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "    ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "    laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "    print(f'{pos_bin_size = }, {ripple_decoding_time_bin_size = }, {laps_decoding_time_bin_size = }') # pos_bin_size = 3.8054171165052444, ripple_decoding_time_bin_size = 0.025, laps_decoding_time_bin_size = 0.2\n",
    "    decoder_laps_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict\n",
    "    decoder_ripple_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict\n",
    "    decoder_laps_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_df_dict\n",
    "    decoder_ripple_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_df_dict\n",
    "\n",
    "    # New items:\n",
    "    decoder_laps_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_extras_dict\n",
    "    decoder_ripple_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_extras_dict\n",
    "\n",
    "    # Weighted correlations:\n",
    "    laps_weighted_corr_merged_df = directional_decoders_epochs_decode_result.laps_weighted_corr_merged_df\n",
    "    ripple_weighted_corr_merged_df = directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "    decoder_laps_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_laps_weighted_corr_df_dict\n",
    "    decoder_ripple_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict\n",
    "\n",
    "    # Pearson's correlations:\n",
    "    laps_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.laps_simple_pf_pearson_merged_df\n",
    "    ripple_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603edd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_session_name: str = curr_active_pipeline.session_name # '2006-6-08_14-26-15'\n",
    "CURR_BATCH_OUTPUT_PREFIX: str = f\"{BATCH_DATE_TO_USE}-{curr_session_name}\"\n",
    "print(f'CURR_BATCH_OUTPUT_PREFIX: {CURR_BATCH_OUTPUT_PREFIX}')\n",
    "\n",
    "# active_context = curr_active_pipeline.get_session_context().adding_context_if_missing(custom_\n",
    "\n",
    "# session_name: str = curr_active_pipeline.session_name\n",
    "\n",
    "active_context = curr_active_pipeline.get_session_context()\n",
    "session_name: str = f\"{curr_active_pipeline.session_name}{custom_suffix}\" ## appending this here is a hack, but it makes the correct filename\n",
    "active_context = active_context.adding_context_if_missing(suffix=custom_suffix)\n",
    "session_ctxt_key:str = active_context.get_description(separator='|', subset_includelist=(IdentifyingContext._get_session_context_keys() + ['suffix']))\n",
    "\n",
    "earliest_delta_aligned_t_start, t_delta, latest_delta_aligned_t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "active_context\n",
    "session_ctxt_key\n",
    "# Shifts the absolute times to delta-relative values, as would be needed to draw on a 'delta_aligned_start_t' axis:\n",
    "delta_relative_t_start, delta_relative_t_delta, delta_relative_t_end = np.array([earliest_delta_aligned_t_start, t_delta, latest_delta_aligned_t_end]) - t_delta\n",
    "# decoder_user_selected_epoch_times_dict, any_good_selected_epoch_times = DecoderDecodedEpochsResult.load_user_selected_epoch_times(curr_active_pipeline)\n",
    "# any_good_selected_epoch_indicies = filtered_ripple_simple_pf_pearson_merged_df.epochs.matching_epoch_times_slice(any_good_selected_epoch_times)\n",
    "# df = filter_epochs_dfs_by_annotation_times(curr_active_pipeline, any_good_selected_epoch_times, ripple_decoding_time_bin_size=ripple_decoding_time_bin_size, filtered_ripple_simple_pf_pearson_merged_df, ripple_weighted_corr_merged_df)\n",
    "# df\n",
    "\n",
    "# collected_outputs_path = self.collected_outputs_path.resolve()\n",
    "\n",
    "collected_outputs_path = collected_outputs_path.resolve()\n",
    "\n",
    "## Export CSVs:\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d550bf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "def _update_ripple_df(a_ripple_df):\n",
    "    \"\"\" captures: session_name, t_start, t_delta, t_end, ripple_decoding_time_bin_size \"\"\"\n",
    "    if ('time_bin_size' not in a_ripple_df.columns) and (ripple_decoding_time_bin_size is not None):\n",
    "        ## add the column\n",
    "        a_ripple_df['time_bin_size'] = ripple_decoding_time_bin_size\n",
    "    # Add the maze_id to the active_filter_epochs so we can see how properties change as a function of which track the replay event occured on:\n",
    "    a_ripple_df = DecoderDecodedEpochsResult.add_session_df_columns(a_ripple_df, session_name=session_name, time_bin_size=None, t_start=t_start, curr_session_t_delta=t_delta, t_end=t_end, time_col='ripple_start_t')\n",
    "    return a_ripple_df\n",
    "\n",
    "directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df = _update_ripple_df(directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df)\n",
    "directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df = _update_ripple_df(directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df)\n",
    "    \n",
    "ripple_weighted_corr_merged_df = directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "ripple_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df\n",
    "\n",
    "## UPDATES: directional_decoders_epochs_decode_result\n",
    "## OUTPUTS: ripple_simple_pf_pearson_merged_df, ripple_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127cd14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_simple_pf_pearson_merged_df\n",
    "ripple_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec606dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "# directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict # vector for each decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161d321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_pseudo2D_continuous_specific_decoded_result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fa02d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot: directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_pre_post_delta_scatter\n",
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import plot_histograms\n",
    "\n",
    "## INPUTS: masked_pseudo2D_continuous_specific_decoded_result\n",
    "masked_pseudo2D_continuous_specific_decoded_result = deepcopy(masked_pseudo2D_continuous_specific_decoded_result)\n",
    "ripple_weighted_corr_merged_df\n",
    "\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "# You can use it like this:\n",
    "_out0: \"MatplotlibRenderPlots\" = plot_histograms(data_type='Continuous', session_spec='1 Session', data_results_df=masked_pseudo2D_continuous_specific_decoded_result, time_bin_duration_str=\"25 ms\")\n",
    "# _out1: \"MatplotlibRenderPlots\" = plot_histograms(data_type='Ripples', session_spec='All Sessions', data_results_df=all_sessions_ripple_time_bin_df, time_bin_duration_str=\"75 ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e17e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram_bins = 'auto'\n",
    "histogram_bins: int = 25\n",
    "\n",
    "# ripple_weighted_corr_merged_df = ripple_weighted_corr_merged_df[['P_Short','delta_aligned_start_t', 'time_bin_size']]\n",
    "ripple_weighted_corr_merged_df = ripple_weighted_corr_merged_df[['P_Short','delta_aligned_start_t', 'time_bin_size']]\n",
    "new_ripple_fig, new_ripple_fig_context = plotly_pre_post_delta_scatter(data_results_df=ripple_weighted_corr_merged_df, out_scatter_fig=None, histogram_bins=histogram_bins,\n",
    "                                                                        px_scatter_kwargs=dict(title='Ripple'), histogram_variable_name='P_Short')\n",
    "\n",
    "# new_laps_fig = new_laps_fig.update_layout(fig_size_kwargs, \n",
    "#     xaxis_title=\"X Axis Title\",\n",
    "#     yaxis_title=\"Y Axis Title\",\n",
    "#     legend_title=\"Legend Title\",\n",
    "#     font=dict(\n",
    "#         family=\"Courier New, monospace\",\n",
    "#         size=18,\n",
    "#         color=\"RebeccaPurple\"\n",
    "#     ),\n",
    "# )\n",
    "# Update x-axis labels\n",
    "# new_laps_fig.update_xaxes(title_text=\"Num Time Bins\", row=1, col=1)\n",
    "# new_laps_fig.update_xaxes(title_text=\"Delta-aligned Event Time (seconds)\", row=1, col=2)\n",
    "# new_laps_fig.update_xaxes(title_text=\"Num Time Bins\", row=1, col=3)\n",
    "\n",
    "\n",
    "_extras_output_dict = {}\n",
    "_extras_output_dict[\"y_mid_line\"] = new_ripple_fig.add_hline(y=0.5, line=dict(color=\"rgba(0.8,0.8,0.8,.75)\", width=2), row='all', col='all')\n",
    "\n",
    "new_ripple_fig\n",
    "\n",
    "\n",
    "\n",
    "# # Update layout to add a title to the legend\n",
    "# new_fig_ripples.update_layout(\n",
    "#     legend_title_text='Is User Selected'  # Add a title to the legend\n",
    "# )\n",
    "\n",
    "# fig_to_clipboard(new_fig_ripples, **fig_size_kwargs)\n",
    "\n",
    "# new_laps_fig_context: IdentifyingContext = new_laps_fig_context.adding_context_if_missing(epoch='withNewKamranExportedReplays', num_sessions=num_sessions, plot_type='scatter+hist', comparison='pre-post-delta', variable_name=variable_name)\n",
    "# figure_out_paths = save_plotly(a_fig=new_laps_fig, a_fig_context=new_laps_fig_context)\n",
    "# new_laps_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59a55fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_PBE_marginal_over_track_ID # (2, 44887) - which track it's using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a48222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import find_epochs_overlapping_other_epochs\n",
    "\n",
    "# INPUTS: track_marginal_posterior_df\n",
    "\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "global_session = curr_active_pipeline.filtered_sessions[global_epoch_name]\n",
    "\n",
    "# global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps) # .trimmed_to_non_overlapping()\n",
    "global_laps_epochs_df = global_laps.to_dataframe()\n",
    "# active_test_epochs_df: pd.DataFrame = deepcopy(global_laps_epochs_df)\n",
    "global_laps_epochs_df\n",
    "\n",
    "\n",
    "# global_laps_epochs_df\n",
    "is_included: NDArray = find_epochs_overlapping_other_epochs(epochs_df=track_marginal_posterior_df, epochs_df_required_to_overlap=deepcopy(global_laps_epochs_df))\n",
    "track_marginal_posterior_df['is_in_laps'] = is_included\n",
    "track_marginal_posterior_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ad6c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_PBE_marginal_over_track_ID.shape # (2, 44887) - which track it's using\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01fe90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window_centers.shape # (44887,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9176dca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build into a marginal df like `all_sessions_laps_df`:\n",
    "track_marginal_posterior_df : pd.DataFrame = pd.DataFrame({'t':deepcopy(time_window_centers), 'P_Long': np.squeeze(non_PBE_marginal_over_track_ID[0, :]), 'P_Short': np.squeeze(non_PBE_marginal_over_track_ID[1, :]), 'time_bin_size': pseudo2D_continuous_specific_decoded_result.decoding_time_bin_size})\n",
    "track_marginal_posterior_df['delta_aligned_start_t'] = track_marginal_posterior_df['t'] - t_delta ## subtract off t_delta\n",
    "track_marginal_posterior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af44479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "template: str = 'plotly_dark' # set plotl template\n",
    "pio.templates.default = template\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_pre_post_delta_scatter\n",
    "\n",
    "\n",
    "histogram_bins: int = 25\n",
    "\n",
    "# new_laps_fig = plotly_pre_post_delta_scatter(data_results_df=deepcopy(all_sessions_laps_df), out_scatter_fig=fig_laps, histogram_bins=histogram_bins, px_scatter_kwargs = dict(title='Laps'))\n",
    "fig, figure_context = plotly_pre_post_delta_scatter(data_results_df=deepcopy(track_marginal_posterior_df)[['delta_aligned_start_t', 'P_Long', 'time_bin_size']], out_scatter_fig=None, histogram_bins=histogram_bins, px_scatter_kwargs = dict(title='Continuous'))\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3b13c7",
   "metadata": {},
   "source": [
    "### <a id='toc25_1_1_'></a>[🚧🔜 2025-02-26 -  Plot 1D pseudo2D Continuous Decodings and their marginals over TrackID on SpikeRaster2D track - uses `AddNewDecodedPosteriors_MatplotlibPlotCommand.prepare_and_perform_custom_decoder_decoded_epochs(...)`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9569f931",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_bin_size = epochs_decoding_time_bin_size\n",
    "info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dock_item = active_2d_plot.add_docked_marginal_track(name='non-PBE_marginal_over_track_ID',\n",
    "                                                                                        time_window_centers=time_window_centers, a_1D_posterior=non_PBE_marginal_over_track_ID, extended_dock_title_info=info_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfd6308",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_decoded_results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94401b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AddNewDecodedEpochMarginal_MatplotlibPlotCommand._perform_add_new_decoded_posterior_marginal_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4f1cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dock all Grouped results from `'DockedWidgets.Pseudo2DDecodedEpochsDockedMatplotlibView'`\n",
    "## INPUTS: active_2d_plot\n",
    "nested_dock_items, nested_dynamic_docked_widget_container_widgets = active_2d_plot.ui.dynamic_docked_widget_container.layout_dockGroups()\n",
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e99ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d58a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_ax.remove(line_measured_position)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6931df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_results = curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['non_PBE_epochs_results'], computation_kwargs_list=[dict(epochs_decoding_time_bin_size=0.025, frame_divide_bin_size=5.0, compute_1D=True, compute_2D=False, drop_previous_result_and_compute_fresh=True, skip_training_test_split=False)],\n",
    "                                                                                                                                            enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3232a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['non_PBE_epochs_results'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb2b869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs_decoding_time_bin_size = 0.050\n",
    "# subdivide_bin_size = 0.250\n",
    "\n",
    "epochs_decoding_time_bin_size = 1.0\n",
    "subdivide_bin_size = 1.0\n",
    "\n",
    "_out_results = curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['non_PBE_epochs_results'], computation_kwargs_list=[dict(epochs_decoding_time_bin_size=epochs_decoding_time_bin_size, frame_divide_bin_size=subdivide_bin_size, compute_1D=True, compute_2D=True, drop_previous_result_and_compute_fresh=False)],\n",
    "                                                                                                                                            enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b103e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [np.shape(v) for v in a_result.p_x_given_n_list]\n",
    "\n",
    "np.sum([np.prod(np.shape(v)) for v in a_result.p_x_given_n_list])\n",
    "\n",
    "# np.vstack([np.shape(v) for v in a_result.p_x_given_n_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464af0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData, loadData\n",
    "\n",
    "# output_save_parent_path: Path = Path(r\"C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\data\").resolve()\n",
    "output_save_parent_path: Path = curr_active_pipeline.get_output_path().resolve()\n",
    "# hdf5_output_path: Path = curr_active_pipeline.get_output_path().joinpath('2025-02-14_results_nonPBEDecoding_2D.h5')\n",
    "# pkl_output_path: Path = output_save_parent_path.joinpath('2025-02-18_results_EpochComputations_nonPBEDecoding.pkl')\n",
    "pkl_output_path: Path = output_save_parent_path.joinpath('2025-02-20_results_EpochComputations_nonPBEDecoding.pkl')\n",
    "print(f'pkl_output_path: \"{pkl_output_path}\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5d8014",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "saveData(pkl_output_path, nonPBE_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad5e355",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load from pickle:\n",
    "print(f'pkl_output_path: {pkl_output_path}')\n",
    "nonPBE_results = loadData(pkl_path=pkl_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b617c11",
   "metadata": {},
   "source": [
    "## <a id='toc32_2_'></a>[Get 1D representations of the Pseudo2D track (4 decoders) so they can be plotted on seperate tracks and bin-debugged independently.](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b821104",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = active_2d_plot.compute_if_needed_and_add_continuous_decoded_posterior(curr_active_pipeline=curr_active_pipeline, desired_time_bin_size=0.025, debug_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2e7918",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3c784d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.indexing_helpers import get_dict_subset\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalDecodersContinuouslyDecodedResult, DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import SingleEpochDecodedResult\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, DockDisplayColors\n",
    "\n",
    "debug_print = True\n",
    "\n",
    "## Uses the `global_computation_results.computed_data['DirectionalDecodersDecoded']`\n",
    "directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "pseudo2D_decoder: BasePositionDecoder = directional_decoders_decode_result.pseudo2D_decoder  # merged pseudo2D decoder\n",
    "all_directional_pf1D_Decoder_dict: Dict[types.DecoderName, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict ## separate 1D decoders\n",
    "\n",
    "continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "\n",
    "\n",
    "all_time_bin_sizes_output_dict: Dict[float, Dict[types.DecoderName, SingleEpochDecodedResult]] = directional_decoders_decode_result.split_pseudo2D_continuous_result_to_1D_continuous_result()\n",
    "## OUTPUTS: all_directional_pf1D_Decoder_dict, all_time_bin_sizes_output_dict, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50c1170",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uses `AddNewDecodedPosteriors_MatplotlibPlotCommand._perform_add_new_decoded_posterior_row(...)` to build the 4 tracks from the split result:\n",
    "# active_2d_plot.add_new_embedded_pyqtgraph_render_plot_widget(\n",
    "\"\"\"\n",
    "add_new_matplotlib_render_plot_widget\n",
    "add_new_matplotlib_render_plot_widget\n",
    "add_new_embedded_pyqtgraph_render_plot_widget\n",
    "\"\"\"\n",
    "## INPUTS: all_time_bin_sizes_output_dict\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import AddNewDecodedPosteriors_MatplotlibPlotCommand\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, DockDisplayColors\n",
    "\n",
    "## plot only a single time bin for now:\n",
    "cached_decoded_time_bin_size_list = list(all_time_bin_sizes_output_dict.keys())\n",
    "assert len(cached_decoded_time_bin_size_list) > 0\n",
    "active_time_bin_size: float = cached_decoded_time_bin_size_list[0]\n",
    "info_string: str = f'{active_time_bin_size:.2f}'\n",
    "## one for each of the four decoders:\n",
    "a_split_pseudo2D_continuous_result_to_1D_continuous_result_dict: Dict[types.DecoderName, SingleEpochDecodedResult] = all_time_bin_sizes_output_dict[active_time_bin_size]\n",
    "dock_group_sep_character: str = '_'\n",
    "showCloseButton = True\n",
    "_common_dock_config_kwargs = {'dock_group_names': [dock_group_sep_character.join([f'ContinuousDecode', info_string])], 'showCloseButton': showCloseButton}\n",
    "dock_configs = dict(zip(('long_LR', 'long_RL', 'short_LR', 'short_RL'),\n",
    "\t\t\t\t\t\t(CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Laps.get_LR_dock_colors, **_common_dock_config_kwargs),\n",
    "                        CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Laps.get_RL_dock_colors, **_common_dock_config_kwargs),\n",
    "                        CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Laps.get_LR_dock_colors, **_common_dock_config_kwargs),\n",
    "                        CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Laps.get_RL_dock_colors, **_common_dock_config_kwargs))))\n",
    "\n",
    "\n",
    "## all at once:\n",
    "output_dict = active_2d_plot.add_docked_decoded_results_dict_tracks(name=f'DirectionalDecodersDecoded', a_decoded_result_dict=a_split_pseudo2D_continuous_result_to_1D_continuous_result_dict, dock_configs=dock_configs, pf1D_Decoder_dict=all_directional_pf1D_Decoder_dict,\n",
    "                                                                                            measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "                                                                                            extended_dock_title_info=info_string)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6828e1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Need all_directional_pf1D_Decoder_dict\n",
    "output_dict = {}\n",
    "for a_decoder_name, a_1D_continuous_decoded_result in a_split_pseudo2D_continuous_result_to_1D_continuous_result_dict.items():\n",
    "    ## a_1D_continuous_decoded_result: SingleEpochDecodedResult\n",
    "    a_dock_config = dock_configs[a_decoder_name]\n",
    "    a_1D_decoder: BasePositionDecoder = all_directional_pf1D_Decoder_dict[a_decoder_name]\n",
    "    # _out_tuple = AddNewDecodedPosteriors_MatplotlibPlotCommand._perform_add_new_decoded_posterior_row(curr_active_pipeline=curr_active_pipeline, active_2d_plot=active_2d_plot, a_dock_config=a_dock_config, a_decoder_name=a_decoder_name, a_position_decoder=a_1D_decoder,\n",
    "    #                                                             time_window_centers=a_1D_continuous_decoded_result.time_bin_container.centers, a_1D_posterior=a_1D_continuous_decoded_result.p_x_given_n, extended_dock_title_info=info_string)\n",
    "    _out_tuple = active_2d_plot.add_docked_decoded_posterior_track(name=f'DirectionalDecodersDecoded[{a_decoder_name}]', a_dock_config=a_dock_config,\n",
    "                                                                                            time_window_centers=a_1D_continuous_decoded_result.time_bin_container.centers, a_1D_posterior=a_1D_continuous_decoded_result.p_x_given_n,\n",
    "                                                                                            xbin = deepcopy(a_1D_decoder.xbin), measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "                                                                                            extended_dock_title_info=info_string)\n",
    "\n",
    "    identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = _out_tuple\n",
    "    ## Add `a_decoded_result` to the plots_data\n",
    "    widget.plots_data.a_decoded_result = a_1D_continuous_decoded_result\n",
    "    widget.plots_data.a_decoder = deepcopy(a_1D_decoder)\n",
    "    output_dict[a_decoder_name] = _out_tuple\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56538c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_decoder_name, an_out_tuple in output_dict.items():\n",
    "    identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = an_out_tuple\n",
    "    print(f'a_decoder_name: {a_decoder_name} -- identifier_name: \"{identifier_name}\"')\n",
    "\n",
    "    # dDisplayItem.orientation\n",
    "    dDisplayItem.autoOrient = False\n",
    "    # dDisplayItem.setOrientation('horizontal', force=True)\n",
    "    dDisplayItem.setOrientation('vertical', force=True)\n",
    "    dDisplayItem.label.relayout_text()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f833550",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_decoder_name, an_out_tuple in output_dict.items():\n",
    "    identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = an_out_tuple\n",
    "    print(f'a_decoder_name: {a_decoder_name} -- identifier_name: \"{identifier_name}\"')\n",
    "    # widget.plots_data.data_keys\n",
    "    widget.plots_data.a_decoded_result = a_1D_continuous_decoded_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450d37f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import plot_attached_BinByBinDecodingDebugger\n",
    "\n",
    "a_decoder_name: types.DecoderName = 'long_LR'\n",
    "identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = output_dict[a_decoder_name]\n",
    "a_1D_continuous_decoded_result = widget.plots_data.a_decoded_result\n",
    "a_decoder = widget.plots_data.a_decoder\n",
    "## INPUTS: a_decoder, a_decoded_result\n",
    "win, out_pf1D_decoder_template_objects, (plots_container, plots_data), _on_update_fcn = plot_attached_BinByBinDecodingDebugger(spike_raster_window, curr_active_pipeline, a_decoder=a_decoder, a_decoded_result=a_1D_continuous_decoded_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b217f221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_1D_continuous_decoded_result.epoch_info_tuple\n",
    "a_1D_continuous_decoded_result.time_bin_container.center_info.step\n",
    "a_1D_continuous_decoded_result.time_bin_container.edge_info.step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c4a72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, CustomCyclicColorsDockDisplayConfig, NamedColorScheme\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import new_plot_raster_plot #, NewSimpleRaster, paired_separately_sort_neurons\n",
    "\n",
    "_raster_tracks_out_dict = {}\n",
    "## Enables creating a new pyqtgraph-based track to display the intervals/epochs\n",
    "dock_config = CustomCyclicColorsDockDisplayConfig(named_color_scheme=NamedColorScheme.grey, showCloseButton=True, showCollapseButton=False, showGroupButton=False, corner_radius=\"0px\", hideTitleBar=True)\n",
    "name = f'rasters[{name_modifier_suffix}]'\n",
    "time_sync_pyqtgraph_widget, raster_root_graphics_layout_widget, raster_plot_item, raster_dock = self.add_new_embedded_pyqtgraph_render_plot_widget(name=name, dockSize=(500, 120), display_config=dock_config)\n",
    "\n",
    "if raster_plot_item not in self.params.custom_interval_rendering_plots:\n",
    "    self.params.custom_interval_rendering_plots.append(raster_plot_item) ## this signals that it should recieve updates for its intervals somewhere else\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15a97f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# all_time_bin_sizes_output_dict = {'non_marginalized_raw_result': [], 'marginal_over_direction': [], 'marginal_over_track_ID': []}\n",
    "# flat_all_time_bin_sizes_output_tuples_list: List[Tuple] = []\n",
    "\n",
    "for time_bin_size, a_continuously_decoded_dict in continuously_decoded_result_cache_dict.items():\n",
    "    ## Each iteration here adds 4 more tracks -- one for each decoding context\n",
    "    \n",
    "    # a_continuously_decoded_dict: Dict[str, DecodedFilterEpochsResult]\n",
    "    if debug_print:\n",
    "        print(f'time_bin_size: {time_bin_size}')\n",
    "\n",
    "    info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "    \n",
    "    ## Uses the `global_computation_results.computed_data['DirectionalDecodersDecoded']`\n",
    "    # all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "    # continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "\n",
    "    continuously_decoded_dict = a_continuously_decoded_dict\n",
    "    \n",
    "\n",
    "    # continuously_decoded_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(directional_decoders_decode_result.most_recent_continuously_decoded_dict)\n",
    "    assert continuously_decoded_dict is not None\n",
    "\n",
    "    ## Get the separate 1D results, these are ready-to-go:\n",
    "    all_directional_pf1D_Decoder_continuous_results_dict: Dict[types.DecoderName, SingleEpochDecodedResult] = {k:v.get_result_for_epoch(0) for k, v in get_dict_subset(continuously_decoded_dict, subset_includelist=None, subset_excludelist=['pseudo2D']).items()}\n",
    "    \n",
    "\n",
    "    ## Extract the Pseudo2D results as separate 1D tracks\n",
    "    ## INPUTS: most_recent_continuously_decoded_dict: Dict[str, DecodedFilterEpochsResult], info_string\n",
    "    \n",
    "    # all_directional_continuously_decoded_dict = most_recent_continuously_decoded_dict or {}\n",
    "    pseudo2D_decoder_continuously_decoded_result: DecodedFilterEpochsResult = continuously_decoded_dict.get('pseudo2D', None)\n",
    "    assert len(pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list) == 1\n",
    "    single_pseudo2D_decoder_continuously_decoded_result: SingleEpochDecodedResult = pseudo2D_decoder_continuously_decoded_result.get_result_for_epoch(0)\n",
    "    \n",
    "\n",
    "    p_x_given_n = single_pseudo2D_decoder_continuously_decoded_result.p_x_given_n ## continuous -- meaning single epoch\n",
    "    # p_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0]['p_x_given_n']\n",
    "    time_bin_container = single_pseudo2D_decoder_continuously_decoded_result.time_bin_container\n",
    "    time_window_centers = time_bin_container.centers\n",
    "    \n",
    "\n",
    "    # p_x_given_n.shape # (62, 4, 209389)\n",
    "\n",
    "    ## Split across the 2nd axis to make 1D posteriors that can be displayed in separate dock rows:\n",
    "    assert p_x_given_n.shape[1] == 4, f\"expected the 4 pseudo-y bins for the decoder in p_x_given_n.shape[1]. but found p_x_given_n.shape: {p_x_given_n.shape}\"\n",
    "    split_pseudo2D_posteriors_dict = {k:np.squeeze(p_x_given_n[:, i, :]) for i, k in enumerate(('long_LR', 'long_RL', 'short_LR', 'short_RL'))}\n",
    "\n",
    "    # Need all_directional_pf1D_Decoder_dict\n",
    "    output_dict = {}\n",
    "    output_pseudo2D_split_to_1D_continuous_results_dict: Dict[types.DecoderName, SingleEpochDecodedResult] = {}\n",
    "\n",
    "    # for a_decoder_name, a_1D_posterior in split_pseudo2D_posteriors_dict.items():\n",
    "    for i, a_decoder_name in enumerate(('long_LR', 'long_RL', 'short_LR', 'short_RL')):\n",
    "        ## make separate `SingleEpochDecodedResult` objects\n",
    "        \n",
    "        # all_directional_pf1D_Decoder_continuous_results_dict\n",
    "        output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name] = deepcopy(single_pseudo2D_decoder_continuously_decoded_result) ## copy the whole pseudo2D result\n",
    "        # output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].p_x_given_n = a_1D_posterior ## or could squish them here\n",
    "        output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].p_x_given_n = np.squeeze(output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].p_x_given_n[:, i, :]) ## or could squish them here\n",
    "        \n",
    "        # _out_tuple = dict(a_decoder_name=a_decoder_name, a_position_decoder=pseudo2D_decoder, time_window_centers=time_window_centers, a_1D_posterior=a_1D_posterior)\n",
    "        # identifier_name, widget, matplotlib_fig, matplotlib_fig_axes = _out_tuple\n",
    "        # output_dict[a_decoder_name] = _out_tuple\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## OUTPUTS: all_directional_pf1D_Decoder_dict: Dict[types.DecoderName, BasePositionDecoder], all_directional_pf1D_Decoder_continuous_results_dict: Dict[types.DecoderName, SingleEpochDecodedResult]\n",
    "## OUTPUTS: pseudo2D_decoder: BasePositionDecoder, single_pseudo2D_decoder_continuously_decoded_result: SingleEpochDecodedResult, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea54c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].p_x_given_n.shape\n",
    "# output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].most_likely_positions\n",
    "\n",
    "# output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name]._test_find_fields_by_shape_metadata()\n",
    "\n",
    "## Marginals are wrong afterwards, and most-likely positions have too many dimensions\n",
    "\n",
    "\n",
    "# pseudo2D_decoder_continuously_decoded_result.perform_compute_marginals\n",
    "output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].most_likely_positions\n",
    "output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].marginal_x\n",
    "\n",
    "output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].marginal_x['p_x_given_n'].shape ## these are okay, (n_x_bins, n_t_bins)\n",
    "output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].marginal_y['p_x_given_n'].shape ## these are bad, (n_decoder_names, n_t_bins)\n",
    "\n",
    "\n",
    "output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].most_likely_positions["
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522aab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo2D_decoder_continuously_decoded_result.pos_bin_edges\n",
    "pseudo2D_decoder_continuously_decoded_result.n_pos_bins\n",
    "continuously_decoded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566c4c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_bin_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1687f8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_pseudo2D_decoder_continuously_decoded_result.to_hdf(\n",
    "import h5py\n",
    "\n",
    "hdf5_output_path: Path = curr_active_pipeline.get_output_path().joinpath('test_data.h5')\n",
    "with h5py.File(hdf5_output_path, 'w') as f: ## open the path as a HDF5 file handle:\n",
    "    single_pseudo2D_decoder_continuously_decoded_result.to_hdf(f, key='single_pseudo2D_decoder_continuously_decoded_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5b63de",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_pseudo2D_decoder_continuously_decoded_result\n",
    "single_pseudo2D_decoder_continuously_decoded_result.marginal_y['p_x_given_n'].shape\n",
    "single_pseudo2D_decoder_continuously_decoded_result.marginal_x['p_x_given_n'].shape\n",
    "\n",
    "\n",
    "\n",
    "# single_pseudo2D_decoder_continuously_decoded_result.epoch_info_tuple\n",
    "single_pseudo2D_decoder_continuously_decoded_result.p_x_given_n.shape # (59, 4, 69487)\n",
    "# single_pseudo2D_decoder_continuously_decoded_result.get_posterior_as_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0a366c",
   "metadata": {},
   "source": [
    "# <a id='toc33_'></a>[Mice, Mark 1](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9251c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the time bins with insufficient spikes in them.\n",
    "\n",
    "## Darken them by overlaying something\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ff7444",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _plot_low_firing_time_bins_overlay_image\n",
    "\n",
    "\n",
    "# results1D.decoders['global'] #.unit_specific_time_binned_spike_counts  #.shape\n",
    "# results2D.a_result2D.spkcount\n",
    "\n",
    "# time_bin_edges: NDArray = deepcopy(results1D.continuous_results['global'].time_bin_edges[0])\n",
    "# spikes_df: pd.DataFrame = deepcopy(get_proper_global_spikes_df(curr_active_pipeline))\n",
    "# unit_specific_time_binned_spike_counts, (is_time_bin_active, inactive_mask, mask_rgba) = compute_unit_time_binned_spike_counts_and_mask(spikes_df=spikes_df, time_bin_edges=time_bin_edges)\n",
    "\n",
    "\n",
    "for a_decoder_name, a_1D_continuous_decoded_result in a_split_pseudo2D_continuous_result_to_1D_continuous_result_dict.items():\n",
    "    ## a_1D_continuous_decoded_result: SingleEpochDecodedResult\n",
    "    a_1D_decoder: BasePositionDecoder = all_directional_pf1D_Decoder_dict[a_decoder_name]\n",
    "    _out_tuple = output_dict[a_decoder_name]\n",
    "    identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = _out_tuple\n",
    "    ## add num spikes per time bin masking:    \n",
    "    time_bin_edges: NDArray = deepcopy(a_1D_continuous_decoded_result.time_bin_edges)\n",
    "    spikes_df: pd.DataFrame = deepcopy(get_proper_global_spikes_df(curr_active_pipeline))\n",
    "    unit_specific_time_binned_spike_counts, (is_time_bin_active, inactive_mask, mask_rgba) = compute_unit_time_binned_spike_counts_and_mask(spikes_df=spikes_df, time_bin_edges=time_bin_edges)\n",
    "\n",
    "    ## add data to plots_data:\n",
    "    widget.plots_data.time_bin_edges = time_bin_edges\n",
    "    widget.plots_data.spikes_df = spikes_df\n",
    "    widget.plots_data.unit_specific_time_binned_spike_counts = unit_specific_time_binned_spike_counts\n",
    "    widget.plots_data.is_time_bin_active = is_time_bin_active\n",
    "    widget.plots_data.mask_rgba = mask_rgba\n",
    "    \n",
    "    ## Add overlay plot to hide bins that don't meet the firing criteria:\n",
    "    _plot_low_firing_time_bins_overlay_image(widget=widget, time_bin_edges=time_bin_edges, mask_rgba=mask_rgba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd2108b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _plot_low_firing_time_bins_overlay_image, add_unit_spike_count_visualization\n",
    "\n",
    "# time_window_centers = deepcopy(results1D.continuous_results['global'].time_bin_containers[0].centers)\n",
    "## INPUTS: unique_units, time_bin_edges, unit_specific_time_binned_spike_counts\n",
    "time_bin_edges: NDArray = deepcopy(results1D.continuous_results['global'].time_bin_edges[0])\n",
    "spikes_df: pd.DataFrame = deepcopy(get_proper_global_spikes_df(curr_active_pipeline))\n",
    "# unique_units = np.unique(spikes_df['aclu']) # sorted\n",
    "unit_specific_time_binned_spike_counts, unique_units, (is_time_bin_active, inactive_mask, mask_rgba) = spikes_df.spikes.compute_unit_time_binned_spike_counts_and_mask(time_bin_edges=time_bin_edges)\n",
    "widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = add_unit_spike_count_visualization(active_2d_plot, neuron_ids=unique_units, time_bin_edges=time_bin_edges, unit_specific_time_binned_spike_counts=unit_specific_time_binned_spike_counts, a_dock_config=None, extended_dock_title_info=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da04fee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import Epoch\n",
    "\n",
    "_starts = deepcopy(results1D.continuous_results['global'].time_bin_containers[0].left_edges)\n",
    "_stops = deepcopy(results1D.continuous_results['global'].time_bin_containers[0].right_edges)\n",
    "all_decoding_time_bin_epochs: Epoch = Epoch.from_starts_stops_arrays(starts=_starts, stops=_stops)\n",
    "active_time_bin_epochs: Epoch = all_decoding_time_bin_epochs.boolean_indicies_slice(is_time_bin_active)\n",
    "inactive_time_bin_epochs: Epoch = all_decoding_time_bin_epochs.boolean_indicies_slice(inactive_mask)\n",
    "\n",
    "## OUTPUTS: active_time_bin_epochs, inactive_time_bin_epochs\n",
    "\n",
    "active_time_bin_epochs_df: pd.DataFrame = active_time_bin_epochs.epochs.get_valid_df().epochs.get_non_overlapping_df().epochs.get_valid_df()\n",
    "active_time_bin_epochs_df['label'] = active_time_bin_epochs_df['label'].astype(int) \n",
    "active_time_bin_epochs_df\n",
    "\n",
    "## OUTPUTS: active_time_bin_epochs_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b1a2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from neuropy.core.epoch import find_data_indicies_from_epoch_times, ensure_Epoch, ensure_dataframe\n",
    "from neuropy.utils.mixins.time_slicing import add_epochs_id_identity\n",
    "from pyphoplacecellanalysis.General.Mixins.SpikesRenderingBaseMixin import SpikeEmphasisState\n",
    "\n",
    "spikes_df: pd.DataFrame = spike_raster_window.spike_raster_plt_2d.spikes_df\n",
    "\n",
    "# spikes_df.spikes.time_sliced(active_time_bin_epochs)\n",
    "\n",
    "# Convert the Epoch object to a numpy array of start/stop times\n",
    "# epoch_times = active_time_bin_epochs.to_dataframe()[['start', 'stop']].to_numpy()\n",
    "\n",
    "# # Find indices\n",
    "# spike_indices = find_data_indicies_from_epoch_times(spikes_df, epoch_times=epoch_times, atol=1e-3)\n",
    "# spike_indices\n",
    "\n",
    "# Add epoch IDs to spikes_df\n",
    "spikes_df = add_epochs_id_identity(spikes_df, active_time_bin_epochs_df, epoch_id_key_name='active_time_bin_epoch_id', epoch_label_column_name='label')\n",
    "# spikes_df\n",
    "\n",
    "# Then filter for spikes within any epoch (not NaN)\n",
    "active_time_bin_spike_indices = spikes_df[~np.isnan(spikes_df['active_time_bin_epoch_id'])].index.values\n",
    "active_time_bin_spike_indices\n",
    "\n",
    "is_spike_included_in_active_time_bin_epoch = ~np.isnan(spikes_df['active_time_bin_epoch_id'])\n",
    "is_spike_excluded_from_active_time_bin_epoch = np.isnan(spikes_df['active_time_bin_epoch_id'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c669c8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.spike_raster_plt_2d.update_spike_emphasis(is_spike_excluded_from_active_time_bin_epoch, SpikeEmphasisState.Deemphasized)\n",
    "# spike_raster_window.spike_raster_plt_2d.update_spike_emphasis(is_spike_excluded_from_active_time_bin_epoch, SpikeEmphasisState.Hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97af5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import find_data_indicies_from_epoch_times, ensure_Epoch, ensure_dataframe\n",
    "from neuropy.utils.mixins.time_slicing import add_epochs_id_identity\n",
    "\n",
    "\n",
    "spikes_df: pd.DataFrame = spike_raster_window.spike_raster_plt_2d.spikes_df\n",
    "\n",
    "# spikes_df.spikes.time_sliced(active_time_bin_epochs)\n",
    "\n",
    "# Convert the Epoch object to a numpy array of start/stop times\n",
    "# epoch_times = active_time_bin_epochs.to_dataframe()[['start', 'stop']].to_numpy()\n",
    "\n",
    "# # Find indices\n",
    "# spike_indices = find_data_indicies_from_epoch_times(spikes_df, epoch_times=epoch_times, atol=1e-3)\n",
    "# spike_indices\n",
    "\n",
    "# Add epoch IDs to spikes_df\n",
    "spikes_df = add_epochs_id_identity(spikes_df, active_time_bin_epochs_df, epoch_id_key_name='active_time_bin_epoch_id', epoch_label_column_name='label')\n",
    "# spikes_df\n",
    "\n",
    "# Then filter for spikes within any epoch (not NaN)\n",
    "active_time_bin_spike_indices = spikes_df[~np.isnan(spikes_df['active_time_bin_epoch_id'])].index.values\n",
    "active_time_bin_spike_indices\n",
    "\n",
    "is_spike_included_in_active_time_bin_epoch = ~np.isnan(spikes_df['active_time_bin_epoch_id'])\n",
    "is_spike_excluded_from_active_time_bin_epoch = np.isnan(spikes_df['active_time_bin_epoch_id'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4307f0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example 1: De-emphasize spikes excluded from the placefield calculations:\n",
    "is_spike_included_in_pf = np.isin(spike_raster_window.spike_raster_plt_2d.spikes_df.index, active_pf_2D.filtered_spikes_df.index)\n",
    "spike_raster_window.spike_raster_plt_2d.update_spike_emphasis(np.logical_not(is_spike_included_in_pf), SpikeEmphasisState.Deemphasized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c011fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_ax = matplotlib_fig_axes[0]\n",
    "an_ax.get_ylim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f86be67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _plot_low_firing_time_bins_overlay_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2eb3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get other tracks, add the mask to the axes\n",
    "widget, matplotlib_fig, matplotlib_fig_axes = active_2d_plot.find_matplotlib_render_plot_widget(\"ContinuousDecode_long_LR - t_bin_size: 0.025\")\n",
    "_plot_low_firing_time_bins_overlay_image(widget=widget, time_bin_edges=time_bin_edges, mask_rgba=mask_rgba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaa78e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "widget, matplotlib_fig, matplotlib_fig_axes = active_2d_plot.find_matplotlib_render_plot_widget(\"ContinuousDecode_long_RL - t_bin_size: 0.025\")\n",
    "_plot_low_firing_time_bins_overlay_image(widget=widget, time_bin_edges=time_bin_edges, mask_rgba=mask_rgba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc1c5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "widget, matplotlib_fig, matplotlib_fig_axes = active_2d_plot.find_matplotlib_render_plot_widget(\"ContinuousDecode_short_LR - t_bin_size: 0.025\")\n",
    "_plot_low_firing_time_bins_overlay_image(widget=widget, time_bin_edges=time_bin_edges, mask_rgba=mask_rgba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8bdaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "widget, matplotlib_fig, matplotlib_fig_axes = active_2d_plot.find_matplotlib_render_plot_widget(\"ContinuousDecode_short_RL - t_bin_size: 0.025\")\n",
    "_plot_low_firing_time_bins_overlay_image(widget=widget, time_bin_edges=time_bin_edges, mask_rgba=mask_rgba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d3d140",
   "metadata": {},
   "outputs": [],
   "source": [
    "widget, matplotlib_fig, matplotlib_fig_axes = active_2d_plot.find_matplotlib_render_plot_widget(\"ContinuousDecode_short_RL - t_bin_size: 0.025\")\n",
    "_plot_low_firing_time_bins_overlay_image(widget=widget, time_bin_edges=time_bin_edges, mask_rgba=mask_rgba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e4af49",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.get_leaf_only_flat_dock_identifiers_list()\n",
    "\n",
    "['ContinuousDecode_long_LR - t_bin_size: 0.025', 'ContinuousDecode_long_RL - t_bin_size: 0.025', 'ContinuousDecode_short_LR - t_bin_size: 0.025', 'ContinuousDecode_short_RL - t_bin_size: 0.025']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd481163",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_item_identifiers_list = ['ContinuousDecode_long_LR - t_bin_size: 0.025', 'ContinuousDecode_long_RL - t_bin_size: 0.025', 'ContinuousDecode_short_LR - t_bin_size: 0.025', 'ContinuousDecode_short_RL - t_bin_size: 0.025', 'ContinuousDecode_longnon-PBE-pseudo2D marginals', 'ContinuousDecode_shortnon-PBE-pseudo2D marginals', 'non-PBE_marginal_over_track_ID_ContinuousDecode - t_bin_size: 0.05', 'Masked Non-PBE Pseudo2D']\n",
    "for an_identifier in target_item_identifiers_list:\n",
    "    widget, matplotlib_fig, matplotlib_fig_axes = active_2d_plot.find_matplotlib_render_plot_widget(an_identifier)\n",
    "    if widget is not None:\n",
    "        _plot_low_firing_time_bins_overlay_image(widget=widget, time_bin_edges=time_bin_edges, mask_rgba=mask_rgba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66ce480",
   "metadata": {},
   "source": [
    "# <a id='toc34_'></a>[General Decoding Record with Frozen Decoding Parameters Tuples](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0889b292",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dict of decoding results, where the decoders used for decoding are built from: nonPBE_Long, nonPBE_Short, Laps_LongLR, Laps_LongRL, Laps_ShortLR, Laps_ShortRL\n",
    "## qclu, frHz\n",
    "# All Decoders should be continuous (decoding the entire session as a single epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e6797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import EpochsAccessor, Epoch, ensure_dataframe, ensure_Epoch\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import EpochComputationFunctions, EpochComputationsComputationsContainer, NonPBEDimensionalDecodingResult, Compute_NonPBE_Epochs, KnownFilterEpochs\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import GeneralDecoderDictDecodedEpochsDictResult, GenericResultTupleIndexType, KnownNamedDecodingEpochsType, MaskedTimeBinFillType\n",
    "\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "\n",
    "## Unpack from pipeline:\n",
    "nonPBE_results: EpochComputationsComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['EpochComputations']\n",
    "a_new_NonPBE_Epochs_obj: Compute_NonPBE_Epochs = nonPBE_results.a_new_NonPBE_Epochs_obj\n",
    "results1D: NonPBEDimensionalDecodingResult = nonPBE_results.results1D\n",
    "results2D: NonPBEDimensionalDecodingResult = nonPBE_results.results2D\n",
    "\n",
    "epochs_decoding_time_bin_size = nonPBE_results.epochs_decoding_time_bin_size\n",
    "frame_divide_bin_size = nonPBE_results.frame_divide_bin_size\n",
    "\n",
    "print(f'{epochs_decoding_time_bin_size = }, {frame_divide_bin_size = }')\n",
    "\n",
    "assert (results1D is not None)\n",
    "assert (results2D is not None)\n",
    "\n",
    "## New computed properties:\n",
    "a_general_decoder_dict_decoded_epochs_dict_result: GeneralDecoderDictDecodedEpochsDictResult = nonPBE_results.a_general_decoder_dict_decoded_epochs_dict_result ## get the pre-decoded result\n",
    "a_general_decoder_dict_decoded_epochs_dict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098dbf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# 2025-02-20 20:06 New `nonPBE_results._build_merged_joint_placefields_and_decode` method                              #\n",
    "# ==================================================================================================================== #\n",
    "non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict, non_PBE_marginal_over_track_ID, (time_bin_containers, time_window_centers, track_marginal_posterior_df) = nonPBE_results._build_merged_joint_placefields_and_decode(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)))\n",
    "masked_pseudo2D_continuous_specific_decoded_result, _mask_index_tuple = pseudo2D_continuous_specific_decoded_result.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)))\n",
    "## OUTPUTS: pseudo2D_continuous_specific_decoded_result, non_PBE_marginal_over_track_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1ffbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'DirectionalMergedDecoders' in curr_active_pipeline.global_computation_results.computed_data:\n",
    "    # DirectionalMergedDecoders: Get the result after computation:\n",
    "    directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "    a_new_fully_generic_result = a_new_fully_generic_result.adding_directional_pseudo2D_decoder_results_filtered_by_spikes_per_t_bin_masked(directional_merged_decoders_result=directional_merged_decoders_result)\n",
    "else:\n",
    "    print('WARN: missing \"DirectionalMergedDecoders\" global result. Skipping.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f11aef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.get_complete_session_context()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37a4b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict, non_PBE_marginal_over_track_ID, (time_bin_containers, time_window_centers, track_marginal_posterior_df), masked_pseudo2D_continuous_specific_decoded_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf7487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_attributes(short_name=None, tags=['WORKING'], input_requires=[], output_provides=[], uses=[], used_by=[], creation_date='2025-03-04 11:36', related_items=[])\n",
    "def add_decoded_posterior_row(active_2d_plot, identifier_name: str, a_decoder: BasePositionDecoder, a_decoded_result: DecodedFilterEpochsResult, extended_dock_title_info: Optional[str]=None):\n",
    "    \"\"\" adds a new decoder track to the active_2d_plot \n",
    "    \"\"\"\n",
    "    from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import SynchronizedPlotMode\n",
    "    from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_1D_most_likely_position_comparsions\n",
    "    from neuropy.utils.matplotlib_helpers import get_heatmap_cmap\n",
    "    from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import FixedCustomColormaps\n",
    "    from pyphocorehelpers.gui.Qt.color_helpers import ColormapHelpers\n",
    "\n",
    "    ## ✅ Add a new row for each of the four 1D directional decoders:\n",
    "    # identifier_name: str = f'ContinuousDecode_{a_decoder_name}'\n",
    "    if extended_dock_title_info is not None:\n",
    "        identifier_name += extended_dock_title_info ## add extra info like the time_bin_size in ms\n",
    "    # print(f'identifier_name: {identifier_name}')\n",
    "\n",
    "    # print(f'identifier_name: {identifier_name}')\n",
    "    widget, matplotlib_fig, matplotlib_fig_axes, dock_item = active_2d_plot.add_new_matplotlib_render_plot_widget(name=identifier_name, dockSize=(65, 200), display_config=None, sync_mode=SynchronizedPlotMode.TO_WINDOW)\n",
    "    an_ax = matplotlib_fig_axes[0]\n",
    "\n",
    "    active_decoder = deepcopy(a_decoder)\n",
    "    assert a_decoded_result is not None, f\"a_decoded_result should not be None anymore.\"\n",
    "\n",
    "    if a_decoded_result is not None:\n",
    "        active_result = deepcopy(a_decoded_result) # already decoded\n",
    "        assert (active_result.num_filter_epochs == 1), f\"currently only supports decoded results (DecodedFilterEpochsResult) computed with a single epoch for all time bins, but active_result.num_filter_epochs: {active_result.num_filter_epochs}\"\n",
    "        active_marginals = active_result.marginal_x_list[0]\n",
    "    else:\n",
    "        # no previously decoded result, fallback to the decoder's internal properties        \n",
    "        active_marginals = active_decoder.marginal.x\n",
    "        \n",
    "\n",
    "    variable_name='x'\n",
    "    active_bins = deepcopy(active_decoder.xbin)\n",
    "    time_window_centers = deepcopy(active_result.time_bin_containers[0].centers)\n",
    "    # active_most_likely_positions = active_marginals.most_likely_positions_1D # Raw decoded positions\n",
    "    active_most_likely_positions = None\n",
    "    active_posterior = active_marginals.p_x_given_n\n",
    "\n",
    "    # active_posterior = deepcopy(a_1D_posterior)\n",
    "    \n",
    "    # most_likely_positions_mode: 'standard'|'corrected'\n",
    "    # fig, curr_ax = curr_active_pipeline.display('_display_plot_marginal_1D_most_likely_position_comparisons', _active_config_name, variable_name='x', most_likely_positions_mode='corrected', ax=an_ax) # ax=active_2d_plot.ui.matplotlib_view_widget.ax\n",
    "    posterior_heatmap_imshow_kwargs = dict(\n",
    "        cmap = get_heatmap_cmap(cmap='viridis', bad_color='black', under_color='white', over_color='red'),\n",
    "    )\n",
    "\n",
    "    measured_position_df = None # Note: for some reason setting `measured_position_df` to anything other than None here messes up the plotting entirely. Set it to None now, and if we want measured positions plot them after\n",
    "    ## Actual plotting portion:\n",
    "    fig, an_ax = plot_1D_most_likely_position_comparsions(measured_position_df=None, time_window_centers=time_window_centers, xbin=active_bins,\n",
    "                                                            posterior=active_posterior,\n",
    "                                                            active_most_likely_positions_1D=active_most_likely_positions,\n",
    "                                                            ax=an_ax, variable_name=variable_name, debug_print=True, enable_flat_line_drawing=False,\n",
    "                                                            posterior_heatmap_imshow_kwargs=posterior_heatmap_imshow_kwargs)\n",
    "\n",
    "\n",
    "\n",
    "    widget.plots_data.active_decoder = active_decoder\n",
    "    widget.plots_data.a_decoded_result = a_decoded_result\n",
    "\n",
    "    # active_bins = active_decoder.xbin\n",
    "\n",
    "    # # active_most_likely_positions = active_marginals.most_likely_positions_1D # Raw decoded positions\n",
    "    # active_most_likely_positions = None\n",
    "    # active_posterior = active_marginals.p_x_given_n\n",
    "    return widget, matplotlib_fig, an_ax, dock_item\n",
    "\n",
    "\n",
    "add_decoded_posterior_row(active_2d_plot, identifier_name=f'Masked Non-PBE Pseudo2D', a_decoder=deepcopy(non_PBE_all_directional_pf1D_Decoder), a_decoded_result=masked_pseudo2D_continuous_specific_decoded_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91d6d4b",
   "metadata": {},
   "source": [
    "### <a id='toc34_1_1_'></a>[🚧🔜 2025-02-26 -  Plot 1D pseudo2D Continuous Decodings and their marginals over TrackID on SpikeRaster2D track - uses `AddNewDecodedPosteriors_MatplotlibPlotCommand.prepare_and_perform_custom_decoder_decoded_epochs(...)`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4299cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import AddNewDecodedPosteriors_MatplotlibPlotCommand, AddNewDecodedEpochMarginal_MatplotlibPlotCommand\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, CustomCyclicColorsDockDisplayConfig, NamedColorScheme\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalDecodersContinuouslyDecodedResult\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import PlottingHelpers\n",
    "\n",
    "## Main INPUT: continuous_specific_decoded_results_dict\n",
    "display_output = {}\n",
    "\n",
    "\n",
    "AddNewDecodedPosteriors_MatplotlibPlotCommand._build_dock_group_id(extended_dock_title_info='non-PBE-pseudo2D marginals')\n",
    "## INPUTS: pseudo2D_continuous_specific_decoded_result, non_PBE_marginal_over_track_ID\n",
    "\n",
    "# override_dock_group_name: str = 'non_pbe_continuous_decoding_plot_group'\n",
    "override_dock_group_name: str = None ## this feature doesn't work\n",
    "_cont_posteriors_output_dict = AddNewDecodedPosteriors_MatplotlibPlotCommand.prepare_and_perform_custom_decoder_decoded_epochs(curr_active_pipeline=curr_active_pipeline, active_2d_plot=active_2d_plot,\n",
    "                                                                                                                continuously_decoded_dict=continuous_decoded_results_dict, info_string='non-PBE-pseudo2D marginals', # results1D.continuous_results\n",
    "                                                                                                                xbin=deepcopy(results1D.decoders['global'].xbin), skip_plotting_measured_positions=False, debug_print=False,\n",
    "                                                                                                                dock_group_name=override_dock_group_name)\n",
    "\n",
    "\n",
    "display_output.update(_cont_posteriors_output_dict)\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Plot the Decodings and their Marginals over TrackID as new Tracks                                                    #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "## INPUTS: non_PBE_marginal_over_track_ID\n",
    "\n",
    "## Manually call `AddNewDecodedEpochMarginal_MatplotlibPlotCommand` to add the custom marginals track to the active SpikeRaster3DWindow\n",
    "time_bin_size = epochs_decoding_time_bin_size\n",
    "info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "\n",
    "dock_config = CustomCyclicColorsDockDisplayConfig(showCloseButton=True, named_color_scheme=NamedColorScheme.grey)\n",
    "dock_config.dock_group_names = [override_dock_group_name] # , 'non-PBE Continuous Decoding'\n",
    "\n",
    "_marginalized_post_output_dict = {}\n",
    "a_posterior_name: str = 'non-PBE_marginal_over_track_ID'\n",
    "assert non_PBE_marginal_over_track_ID.shape[0] == 2, f\"expected the 2 marginalized pseudo-y bins for the decoder in non_PBE_marginal_over_track_ID.shape[1]. but found non_PBE_marginal_over_track_ID.shape: {non_PBE_marginal_over_track_ID.shape}\"\n",
    "_marginalized_post_output_dict[a_posterior_name] = AddNewDecodedEpochMarginal_MatplotlibPlotCommand._perform_add_new_decoded_posterior_marginal_row(curr_active_pipeline=curr_active_pipeline, active_2d_plot=active_2d_plot, a_dock_config=dock_config,\n",
    "                                                                                    a_variable_name=a_posterior_name, xbin=np.arange(2), time_window_centers=time_window_centers, a_1D_posterior=non_PBE_marginal_over_track_ID, extended_dock_title_info=info_string)\n",
    "display_output.update({'a_posterior_name': _marginalized_post_output_dict[a_posterior_name]})\n",
    "\n",
    "## Draw the \"Long\", \"Short\" labels\n",
    "identifier_name, widget, matplotlib_fig, matplotlib_fig_axes = _marginalized_post_output_dict[a_posterior_name]\n",
    "label_artists_dict = {}\n",
    "for i, ax in enumerate(matplotlib_fig_axes):\n",
    "    label_artists_dict[ax] = PlottingHelpers.helper_matplotlib_add_pseudo2D_marginal_labels(ax, y_bin_labels=['short','long'], enable_draw_decoder_colored_lines=False)\n",
    "_marginalized_post_output_dict[a_posterior_name] = (identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, label_artists_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149fcf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dock all Grouped results from `'DockedWidgets.Pseudo2DDecodedEpochsDockedMatplotlibView'`\n",
    "## INPUTS: active_2d_plot\n",
    "nested_dock_items, nested_dynamic_docked_widget_container_widgets = active_2d_plot.ui.dynamic_docked_widget_container.layout_dockGroups()\n",
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4dd842",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Manually draw the red \"current position\" lines:\n",
    "## extracted from `plot_1D_most_likely_position_comparsions`\n",
    "\n",
    "measured_position_df: pd.DataFrame = deepcopy(results1D.pos_df)\n",
    "\n",
    "identifier_names = ['ContinuousDecode_longnon-PBE-pseudo2D marginals', 'ContinuousDecode_shortnon-PBE-pseudo2D marginals']\n",
    "out_artists = {}\n",
    "out_artists['measured_pos_artists'] = {}\n",
    "for an_identifier in identifier_names:\n",
    "    widget, matplotlib_fig, matplotlib_fig_axes = active_2d_plot.find_matplotlib_render_plot_widget(an_identifier)\n",
    "    an_ax = matplotlib_fig_axes[0]\n",
    "    ## INPUTS: measured_position_df, an_ax\n",
    "    # Actual Position Plots (red line):\n",
    "    # actual_postion_plot_kwargs = {'color': '#ff000066', 'alpha': 0.6, 'marker': '+', 'markersize': 4, 'animated': False}\n",
    "    # actual_postion_plot_kwargs = {'color': '#ff000066', 'alpha': 0.6, 'marker': 'none', 'animated': False}\n",
    "    actual_postion_plot_kwargs = {'color': '#ff000066', 'alpha': 0.35, 'marker': 'none', 'animated': False}\n",
    "    variable_name = 'x'\n",
    "    a_line_measured_position = an_ax.plot(measured_position_df['t'].to_numpy(), measured_position_df[variable_name].to_numpy(), label=f'measured {variable_name}', **actual_postion_plot_kwargs) # Opaque RED # , linestyle='dashed', linewidth=2, color='#ff0000ff'\n",
    "    out_artists['measured_pos_artists'] = a_line_measured_position\n",
    "\n",
    "    ## draw when done:\n",
    "    an_ax.get_figure().canvas.draw_idle()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c6d576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.Menus.BaseMenuProviderMixin import BaseMenuCommand\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import AddNewDecodedPosteriors_MatplotlibPlotCommand\n",
    "\n",
    "\n",
    "@define(slots=False)\n",
    "class TimelineTrack:\n",
    "    dock: Dock = field()\n",
    "    widget: TimelinePlotterBase = field()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6376f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = curr_active_pipeline.sess.epochs.to_dataframe() #.to_clipboard()\n",
    "print(df.to_dict('list'))\n",
    "# \tstart\tstop\tlabel\tduration\n",
    "# 0\t0.0\t1029.316608761903\tmaze1\t1029.316608761903\n",
    "# 1\t1029.316608761903\t1737.1968310000375\tmaze2\t707.8802222381346\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e3d821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nptyping as ND\n",
    "from nptyping import NDArray\n",
    "from neuropy.core.epoch import EpochsAccessor, Epoch\n",
    "from neuropy.core.flattened_spiketrains import SpikesAccessor\n",
    "\n",
    "test_epochs_df: pd.DataFrame = pd.DataFrame({'start': [0.0, 1029.316608761903], 'stop': [1029.316608761903, 1737.1968310000375], 'label': ['maze1', 'maze2'], 'duration': [1029.316608761903, 707.8802222381346]})\n",
    "epochs: Epoch = Epoch(test_epochs_df) # Epoch(...) # Create an Epoch object as needed\n",
    "\n",
    "test_epochs_df.epochs.is_gapless_overlap_df()\n",
    "\n",
    "# test_epochs_df.epochs.get_non_overlapping_df(debug_print=True)\n",
    "\n",
    "time_bin_edges: NDArray = deepcopy(results1D.continuous_results['global'].time_bin_edges[0])\n",
    "spikes_df: pd.DataFrame = deepcopy(get_proper_global_spikes_df(curr_active_pipeline))\n",
    "# unit_specific_time_binned_spike_counts, included_neuron_ids = spikes_df.spikes.compute_unit_time_binned_spike_counts(time_bin_edges=time_bin_edges)\n",
    "\n",
    "unit_specific_time_binned_spike_counts: NDArray[ND.Shape[\"N_ACLUS, N_TIME_BINS\"], ND.Int] = spikes_df.spikes.compute_unit_time_binned_spike_counts(time_bin_edges=time_bin_edges)[0]\n",
    "included_neuron_ids: NDArray[ND.Shape[\"N_ACLUS\"], ND.Int] = spikes_df.spikes.compute_unit_time_binned_spike_counts(time_bin_edges=time_bin_edges)[1]\n",
    "unit_specific_time_binned_spike_counts\n",
    "\n",
    "# isinstance(unit_specific_time_binned_spike_counts, NDArray[ND.Shape[\"n_aclus, n_time_bins\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f89c52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(spikes_df.spikes.get_split_by_unit()[0])\n",
    "spikes_df.slice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb796232",
   "metadata": {},
   "source": [
    "# <a id='toc36_'></a>[2025-03-11 Apply the masking strategy introduced with the non-PBE epoch analyses on the other `DecodedFilterEpochsResult`s produced by the lap-constructed decoders (TrackTemplates)](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342da66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from neuropy.core.epoch import ensure_dataframe, ensure_Epoch\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring\n",
    "from neuropy.utils.result_context import DisplaySpecifyingIdentifyingContext\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import EpochFilteringMode, _compute_proper_filter_epochs\n",
    "\n",
    "KnownNamedDecoderTrainedComputeEpochsType = Literal['laps', 'non_pbe']\n",
    "\n",
    "filtered_epochs_df = None\n",
    "\n",
    "## INPUTS: curr_active_pipeline, track_templates, a_decoded_filter_epochs_decoder_result_dict\n",
    "\n",
    "## INPUTS: directional_decoders_epochs_decode_result, filtered_epochs_df\n",
    "\n",
    "\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "# directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = deepcopy(curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']) ## GENERAL\n",
    "# a_new_fully_generic_result = _subfn_add_spikes_per_t_bin_masked_variants(a_new_fully_generic_result, directional_decoders_epochs_decode_result=directional_decoders_epochs_decode_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ba386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict, non_PBE_marginal_over_track_ID, (time_bin_containers, time_window_centers, track_marginal_posterior_df) = nonPBE_results._build_merged_joint_placefields_and_decode(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)))\n",
    "masked_pseudo2D_continuous_specific_decoded_result, _mask_index_tuple = pseudo2D_continuous_specific_decoded_result.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)))\n",
    "# (all_time_bin_indicies, last_valid_indicies) = _mask_index_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5739b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from typing import Literal\n",
    "# Define a type that can only be one of these specific strings\n",
    "KnownNamedDecodingEpochsType = Literal['laps', 'replay', 'ripple', 'pbe', 'non_pbe']\n",
    "# Define a type that can only be one of these specific strings\n",
    "MaskedTimeBinFillType = Literal['ignore', 'last_valid', 'nan_filled', 'dropped'] ## used in `DecodedFilterEpochsResult.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(...)` to specify how invalid bins (due to too few spikes) are treated.\n",
    "\n",
    "GenericResultTupleIndexType: TypeAlias = IdentifyingContext # an template/stand-in variable that aims to abstract away the unique-hashable index of a single result computed with a given set of parameters. Not yet fully implemented 2025-03-09 17:50 \n",
    "\n",
    "\n",
    "test_identifier: IdentifyingContext = IdentifyingContext(known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='last_valid')\n",
    "\n",
    "test_identifier.get_description(include_property_names=True, separator=\"|\", key_value_separator=':') # , replace_separator_in_property_names='|'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828384eb",
   "metadata": {
    "tags": [
     "active-2025-03-11"
    ]
   },
   "outputs": [],
   "source": [
    "## OUTPUTS:\n",
    "# a_new_fully_generic_result\n",
    "\n",
    "for a_context, a_marginal_df in a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict.items():\n",
    "    param_sep_str: str = '¦'\n",
    "    # param_sep_str: str = ''\n",
    "    # param_sep_str: str = ' ⁖'\n",
    "    key_val_sep_str: str = ':'\n",
    "    a_ctxt_str: str = a_context.get_description(separator=param_sep_str, replace_separator_in_property_names='_', include_property_names=True, key_value_separator=key_val_sep_str)\n",
    "    # a_ctxt_str: str = a_context.get_initialization_code_string()\n",
    "    print(f'a_context: \"<{a_ctxt_str}>\" - np.shape(a_marginal_df): {np.shape(a_marginal_df)}')\n",
    "    \n",
    "\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:laps¦masked_time_bin_fill_type:ignore\" - np.shape(a_marginal_df): (14350, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:laps¦masked_time_bin_fill_type:last_valid\" - np.shape(a_marginal_df): (14350, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:laps¦masked_time_bin_fill_type:nan_filled\" - np.shape(a_marginal_df): (14350, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:pbe¦masked_time_bin_fill_type:ignore\" - np.shape(a_marginal_df): (1569, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:pbe¦masked_time_bin_fill_type:last_valid\" - np.shape(a_marginal_df): (1569, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:pbe¦masked_time_bin_fill_type:nan_filled\" - np.shape(a_marginal_df): (1569, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:non_pbe¦masked_time_bin_fill_type:ignore\" - np.shape(a_marginal_df): (43377, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:non_pbe¦masked_time_bin_fill_type:last_valid\" - np.shape(a_marginal_df): (43377, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:non_pbe¦masked_time_bin_fill_type:nan_filled\" - np.shape(a_marginal_df): (43377, 9)\n",
    "# a_context: \"trained_compute_epochs:laps¦pfND_ndim:1¦decoder_identifier:pseudo2D¦time_bin_size:0.025¦known_named_decoding_epochs_type:laps¦masked_time_bin_fill_type:ignore¦data_grain:per_time_bin\" - np.shape(a_marginal_df): (14350, 15)\n",
    "# a_context: \"trained_compute_epochs:laps¦pfND_ndim:1¦decoder_identifier:pseudo2D¦time_bin_size:0.025¦known_named_decoding_epochs_type:laps¦masked_time_bin_fill_type:ignore¦data_grain:per_epoch\" - np.shape(a_marginal_df): (74, 6)\n",
    "# a_context: \"trained_compute_epochs:laps¦pfND_ndim:1¦decoder_identifier:pseudo2D¦time_bin_size:0.025¦known_named_decoding_epochs_type:pbe¦masked_time_bin_fill_type:ignore¦data_grain:per_time_bin\" - np.shape(a_marginal_df): (1165, 15)\n",
    "# a_context: \"trained_compute_epochs:laps¦pfND_ndim:1¦decoder_identifier:pseudo2D¦time_bin_size:0.025¦known_named_decoding_epochs_type:pbe¦masked_time_bin_fill_type:ignore¦data_grain:per_epoch\" - np.shape(a_marginal_df): (133, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188ef752",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a_new_fully_generic_result.filter_epochs_pseudo2D_continuous_specific_decoded_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38476959",
   "metadata": {},
   "source": [
    "##### <a id='toc36_1_1_1_1_'></a>[2025-03-11 11:13 not sure if this is the old version or if it adds something to the `a_new_fully_generic_result`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f9ccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Common/shared for all decoded epochs:\n",
    "unique_decoder_names = ['long', 'short']\n",
    "non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict, non_PBE_marginal_over_track_ID, (time_bin_containers, time_window_centers, track_marginal_posterior_df) = nonPBE_results._build_merged_joint_placefields_and_decode(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline))) # , filter_epochs=deepcopy(global_any_laps_epochs_obj)\n",
    "\n",
    "## from dict of filter_epochs to decode:\n",
    "global_replays_df: pd.DataFrame = TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].replay))\n",
    "filter_epochs_to_decode_dict: Dict[KnownNamedDecodingEpochsType, Epoch] = {'laps': ensure_Epoch(deepcopy(global_any_laps_epochs_obj)),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   'pbe': ensure_Epoch(deepcopy(global_session.pbe.get_non_overlapping())),\n",
    "\t\t\t\t\t\t\t\t#  'ripple': ensure_Epoch(deepcopy(global_session.ripple)),\n",
    "\t\t\t\t\t\t\t\t#   'replay': ensure_Epoch(deepcopy(global_replays_df)),\n",
    "\t\t\t\t\t\t\t\t  'non_pbe': ensure_Epoch(deepcopy(global_session.non_pbe)),\n",
    "\t\t\t\t\t\t\t\t  }\n",
    "# filter_epochs_to_decode_dict\n",
    "\n",
    "## Perform the decoding and masking as needed for invalid bins:\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "a_general_decoder_dict_decoded_epochs_dict_result: GeneralDecoderDictDecodedEpochsDictResult = EpochComputationsComputationsContainer._build_output_decoded_posteriors(non_PBE_all_directional_pf1D_Decoder=non_PBE_all_directional_pf1D_Decoder, # pseudo2D_continuous_specific_decoded_result=pseudo2D_continuous_specific_decoded_result,\n",
    "    filter_epochs_to_decode_dict=filter_epochs_to_decode_dict,\n",
    "    unique_decoder_names=unique_decoder_names, spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), epochs_decoding_time_bin_size=epochs_decoding_time_bin_size,\n",
    "    session_name=session_name, t_start=t_start, t_delta=t_delta, t_end=t_end,\n",
    ")\n",
    "\n",
    "\n",
    "## OUTPUTS: filter_epochs_pseudo2D_continuous_specific_decoded_result, filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict\n",
    "# 58sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d05ac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# filter_epochs_pseudo2D_continuous_specific_decoded_result, filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict\n",
    "retro_general_decoder_dict_decoded_epochs_dict_result: GeneralDecoderDictDecodedEpochsDictResult = EpochComputationsComputationsContainer._build_output_decoded_posteriors(non_PBE_all_directional_pf1D_Decoder=non_PBE_all_directional_pf1D_Decoder, # pseudo2D_continuous_specific_decoded_result=pseudo2D_continuous_specific_decoded_result,\n",
    "    filter_epochs_to_decode_dict=filter_epochs_to_decode_dict,\n",
    "    unique_decoder_names=unique_decoder_names, spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), epochs_decoding_time_bin_size=epochs_decoding_time_bin_size,\n",
    "    session_name=session_name, t_start=t_start, t_delta=t_delta, t_end=t_end,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021b0ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try fresh 2025-03-11-style decoding of the TrackTemplates:\n",
    "global_session = curr_active_pipeline.filtered_sessions[global_epoch_name]\n",
    "\n",
    "## from dict of filter_epochs to decode:\n",
    "global_replays_df: pd.DataFrame = TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(deepcopy(global_session.replay))\n",
    "global_any_laps_epochs_obj = curr_active_pipeline.computation_results[global_epoch_name].computation_config.pf_params.computation_epochs # global_session.get\n",
    "filter_epochs_to_decode_dict: Dict[KnownNamedDecodingEpochsType, Epoch] = {'laps': ensure_Epoch(deepcopy(global_any_laps_epochs_obj)),\n",
    "                                                                        'pbe': ensure_Epoch(deepcopy(global_session.pbe.get_non_overlapping())),\n",
    "                                #  'ripple': ensure_Epoch(deepcopy(global_session.ripple)),\n",
    "                                #   'replay': ensure_Epoch(deepcopy(global_replays_df)),\n",
    "                                'non_pbe': ensure_Epoch(deepcopy(global_session.non_pbe)),\n",
    "                                }\n",
    "# filter_epochs_to_decode_dict\n",
    "\n",
    "## constrain all epochs to be at least two decoding time bins long, or drop them entirely:\n",
    "filter_epochs_to_decode_dict = {k:_compute_proper_filter_epochs(epochs_df=v, desired_decoding_time_bin_size=epochs_decoding_time_bin_size, minimum_event_duration=(2.0 * epochs_decoding_time_bin_size), mode=EpochFilteringMode.DropShorter)[0] for k, v in filter_epochs_to_decode_dict.items()} # `[0]` gets just the dataframe, as in DropShorter mode the time_bin_size is unchanged\n",
    "\n",
    "## Perform the decoding and masking as needed for invalid bins:\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6a401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_decoders_epochs_decode_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d78f078",
   "metadata": {},
   "source": [
    "# 2025-03-24 Add a dynamic dock holding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1a91c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_bin_size = epochs_decoding_time_bin_size\n",
    "info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dock_item = active_2d_plot.add_docked_marginal_track(name='non-PBE_marginal_over_track_ID',\n",
    "                                                                                        time_window_centers=time_window_centers, a_1D_posterior=non_PBE_marginal_over_track_ID, extended_dock_title_info=info_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40f3b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import build_single_plotly_marginal_scatter_and_hist_over_time\n",
    "\n",
    "#INPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder\n",
    "_flat_out_figs_dict = {}\n",
    "a_fig, a_figure_context = build_single_plotly_marginal_scatter_and_hist_over_time(a_decoded_posterior_df=a_decoded_marginal_posterior_df, a_target_context=a_target_context)\n",
    "_flat_out_figs_dict[a_figure_context] = a_fig\n",
    "\n",
    "a_fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbc4734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58f0db22",
   "metadata": {},
   "source": [
    "# 2025-03-17 `DataFrameFilter` with FAT result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c9c117",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: all_sessions_ripple_time_bin_df\n",
    "# all_sessions_laps_df, all_sessions_laps_time_bin_df, \n",
    "# all_sessions_ripple_df, all_sessions_ripple_time_bin_df, \n",
    "a_new_fully_generic_result\n",
    "\n",
    "FAT_df: pd.DataFrame = deepcopy(a_new_fully_generic_result.single_FAT_df)\n",
    "# Add the maze_id to the active_filter_epochs so we can see how properties change as a function of which track the replay event occured on:\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "FAT_df = DecoderDecodedEpochsResult.add_session_df_columns(FAT_df, session_name=session_name, time_bin_size=None, curr_session_t_delta=t_delta) # , time_col='ripple_start_t'\n",
    "FAT_df['custom_replay_name'] = FAT_df['session_name']\n",
    "complete_session_context, (session_context, additional_session_context) = curr_active_pipeline.get_complete_session_context()\n",
    "complete_session_context\n",
    "\n",
    "resolution_multiplier = 1.0\n",
    "all_sessions_ripple_df = deepcopy(FAT_df.pho.constrain_df_cols(data_grain='per_epoch', known_named_decoding_epochs_type='pbe')).reset_index(drop=True, inplace=False) # , decoder_identifier='pseudo2D', masked_time_bin_fill_type=['ignore'], trained_compute_epochs='laps'\n",
    "all_sessions_ripple_time_bin_df = deepcopy(FAT_df.pho.constrain_df_cols(data_grain='per_time_bin', known_named_decoding_epochs_type='pbe')).reset_index(drop=True, inplace=False)\n",
    "\n",
    "all_sessions_laps_df = deepcopy(FAT_df.pho.constrain_df_cols(data_grain='per_epoch', known_named_decoding_epochs_type='laps')).reset_index(drop=True, inplace=False)\n",
    "all_sessions_laps_time_bin_df = deepcopy(FAT_df.pho.constrain_df_cols(data_grain='per_time_bin', known_named_decoding_epochs_type='laps')).reset_index(drop=True, inplace=False)\n",
    "\n",
    "all_sessions_laps_time_bin_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f438d2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.options.mode.copy_on_write = False\n",
    "# pd.options.mode.chained_assignment = 'raise'\n",
    "# pd.options.mode.chained_assignment = None\n",
    "from neuropy.utils.indexing_helpers import flatten, NumpyHelpers, PandasHelpers\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import DataFrameFilter\n",
    "\n",
    "additional_filter_predicates = {}\n",
    "\n",
    "## ensure that the qclu is always before the frateThresh, reversing them if needed:\n",
    "replay_name: str = 'withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0'\n",
    "time_bin_size: float = 0.025\n",
    "# time_bin_size: Tuple[float] = (0.025, 0.058)\n",
    "save_plotly = False\n",
    "earliest_delta_aligned_t_start = t_start\n",
    "latest_delta_aligned_t_end = t_end\n",
    "# split_by_column: str = 'animal'\n",
    "split_by_kwargs: str = {\n",
    "    # 'color': 'session_name',\n",
    "    # 'color': 'animal',\n",
    "    # 'size': 'session_experience_rank', 'size_max': 10,\n",
    "    # 'size': 'duration', 'size_max': 10,\n",
    "}\n",
    "\n",
    "_build_filter_changed_plotly_plotting_callback_fn = DataFrameFilter._build_plot_callback(earliest_delta_aligned_t_start=earliest_delta_aligned_t_start, latest_delta_aligned_t_end=latest_delta_aligned_t_end, save_plotly=save_plotly,\n",
    "                                                                                          resolution_multiplier=resolution_multiplier,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t#   px_scatter_kwargs = {'symbol': 'session_name'},\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# px_scatter_kwargs = {'color': 'session_name', 'facet_row': 'time_bin_size'}, hist_kwargs = {'color': 'session_name', 'facet_row': 'time_bin_size'},\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# px_scatter_kwargs = {'color': 'session_name'}, hist_kwargs = {'color': 'session_name'}, ## Split by session_name\n",
    "                                            px_scatter_kwargs = {\n",
    "                                                # 'color': 'session_name',\n",
    "    \t\t\t\t\t\t\t\t\t\t    # 'size': 'session_experience_rank', 'size_max': 10,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t# 'size': 'duration', 'size_max': 10,\n",
    "                                                **split_by_kwargs,\n",
    "\t\t\t\t\t\t\t\t\t\t\t},\n",
    "\t\t\t\t\t\t\t\t\t\t\t hist_kwargs = {\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t**split_by_kwargs,\n",
    "                                            }, ## Split by session_name\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  \n",
    ")\n",
    "\n",
    "df_filter: DataFrameFilter = DataFrameFilter(\n",
    "    all_sessions_ripple_df=all_sessions_ripple_df,\n",
    "    all_sessions_ripple_time_bin_df=all_sessions_ripple_time_bin_df,\n",
    "    # all_sessions_MultiMeasure_ripple_df=all_sessions_MultiMeasure_ripple_df,\n",
    "    # all_sessions_all_scores_ripple_df=all_sessions_all_scores_ripple_df,\n",
    "    # all_sessions_all_scores_ripple_df=_temp_filtered_all_sessions_all_scores_ripple_df,\n",
    "    all_sessions_laps_df=all_sessions_laps_df,\n",
    "    all_sessions_laps_time_bin_df=all_sessions_laps_time_bin_df,\n",
    "    # all_sessions_MultiMeasure_laps_df=all_sessions_MultiMeasure_laps_df,\n",
    "    additional_filter_predicates=additional_filter_predicates,\n",
    "    on_filtered_dataframes_changed_callback_fns={'build_filter_changed_plotly_plotting_callback_fn': _build_filter_changed_plotly_plotting_callback_fn},\n",
    "    active_plot_df_name='filtered_all_sessions_laps_time_bin_df',\n",
    "\t# hover_posterior_data=a_posterior_loader,\n",
    "    # hover_posterior_data=posterior_datasource,\n",
    ")\n",
    "\n",
    "\n",
    "# Add additional columns _____________________________________________________________________________________________ #\n",
    "df_filter.build_extra_control_widget(a_name='trained_compute_epochs', df_col_name='trained_compute_epochs', a_widget_label='TrainedComputeEpochs :')\n",
    "df_filter.build_extra_control_widget(a_name='pfND_ndim', df_col_name='pfND_ndim', a_widget_label='pfND_ndim:')\n",
    "df_filter.build_extra_control_widget(a_name='decoder_identifier', df_col_name='decoder_identifier', a_widget_label='decoder_identifier:')\n",
    "# df_filter.build_extra_control_widget(a_name='data_grain', df_col_name='data_grain', a_widget_label='data_grain:')\n",
    "df_filter.build_extra_control_widget(a_name='masked_time_bin_fill_type', df_col_name='masked_time_bin_fill_type', a_widget_label='masked_time_bin_fill_type:')\n",
    "# df_filter.build_extra_control_widget(a_name='known_named_decoding_epochs_type', df_col_name='known_named_decoding_epochs_type', a_widget_label='known_named_decoding_epochs_type:')\n",
    "\n",
    "\n",
    "# Set initial values: ________________________________________________________________________________________________ #\n",
    "# df_filter.replay_name = replay_name # 'withNormalComputedReplays-frateThresh_5.0-qclu_[1, 2, 4, 6, 7, 9]'\n",
    "# df_filter.time_bin_size = time_bin_size\n",
    "df_filter.update_filters()\n",
    "df_filter.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41fef63",
   "metadata": {},
   "source": [
    "# 2025-03-24 Get the old result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8652f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = deepcopy(curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']) ## GENERAL\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = deepcopy(curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders'])\n",
    "spikes_df = deepcopy(get_proper_global_spikes_df(curr_active_pipeline))\n",
    "\n",
    "laps_all_epoch_bins_marginals_df: pd.DataFrame = deepcopy(directional_merged_decoders_result.laps_all_epoch_bins_marginals_df)\n",
    "laps_time_bin_marginals_df: pd.DataFrame = deepcopy(directional_merged_decoders_result.laps_time_bin_marginals_df)\n",
    "laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf31bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "laps_time_bin_marginals_df = laps_time_bin_marginals_df.across_session_identity.add_session_df_columns(session_name=session_name, time_bin_size=0.025, t_start=t_start, curr_session_t_delta=t_delta, t_end=t_end)\n",
    "laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31db373a",
   "metadata": {},
   "source": [
    "# 🟢🎯 2025-04-05 'non_pbe_endcap' epochs, which are the non_pbe epochs with the laps also subtracted out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a2f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import ensure_dataframe, ensure_Epoch\n",
    "\n",
    "## Compute the 'non_pbe_endcap' epochs, which are the non_pbe epochs with the laps also subtracted out\n",
    "non_pbe_df = ensure_dataframe(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].non_pbe))\n",
    "laps_df = ensure_dataframe(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps))\n",
    "\n",
    "non_pbe_endcaps_df = non_pbe_df.epochs.subtracting(laps_df)\n",
    "non_pbe_endcaps_df = non_pbe_endcaps_df.epochs.modify_each_epoch_by(additive_factor=-0.008, final_output_minimum_epoch_duration=0.050) # minimum length to consider is 50ms, contract each epoch inward by -8ms (4ms on each side)\n",
    "non_pbe_endcaps_df = non_pbe_endcaps_df.epochs.adding_or_updating_metadata(track_identity='global', interval_datasource_name=f'global_EndcapsNonPBE') # train_test_period='train', training_data_portion=training_data_portion, \n",
    "\n",
    "non_pbe_endcaps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4bf8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(curr_active_pipeline.filtered_sessions[global_epoch_name].non_pbe)\n",
    "curr_active_pipeline.filtered_sessions[global_epoch_name].non_pbe_endcaps = ensure_Epoch(non_pbe_endcaps_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008be9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = active_2d_plot.add_rendered_intervals(non_pbe_endcaps_df, name='non-PBE-Endaps', child_plots=[background_static_scroll_plot_widget, main_plot_widget], debug_print=True) ## add interval rectangles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc35fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_base_context = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=time_bin_size, data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='ignore'\n",
    "a_best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_matching_contexts(a_base_context, return_multiple_matches=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132f2ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_decoding_time_bin_size = 0.025\n",
    "\n",
    "# filter_epochs = curr_active_pipeline.filtered_sessions[global_epoch_name].non_pbe_endcaps\n",
    "filter_epochs = curr_active_pipeline.filtered_sessions[global_epoch_name].non_pbe_endcaps\n",
    "\n",
    "a_pseudo2D_continuous_specific_decoded_result: DecodedFilterEpochsResult = a_decoder.decode_specific_epochs(spikes_df = deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), filter_epochs=filter_epochs, decoding_time_bin_size=epochs_decoding_time_bin_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaab89f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import EpochComputationsComputationsContainer\n",
    "\n",
    "## INPUTS: a_decoder\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "epochs_decoding_time_bin_size = 0.025\n",
    "\n",
    "a_base_context = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=time_bin_size, data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='ignore'\n",
    "a_best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_matching_contexts(a_base_context, return_multiple_matches=False)\n",
    "\n",
    "filter_epochs_to_decode_dict = {IdentifyingContext(known_named_decoding_epochs_type='laps'):deepcopy(laps_df),\n",
    "\t\t\t\t\t\t\t\t# IdentifyingContext(known_named_decoding_epochs_type='pbes'):deepcopy(non_pbe_df),\n",
    "\t\t\t\t\t\t\t\tIdentifyingContext(known_named_decoding_epochs_type='non_pbe_endcaps'):deepcopy(non_pbe_endcaps_df),\n",
    "}\n",
    "\n",
    "_temp_out_tuple = EpochComputationsComputationsContainer._build_context_general_output_decoded_posteriors(non_PBE_all_directional_pf1D_Decoder=a_decoder, filter_epochs_to_decode_dict=filter_epochs_to_decode_dict,\n",
    "    # unique_decoder_names=['long', 'short'],\n",
    "\tunique_decoder_names=['long_LR', 'long_RL', 'short_LR', 'short_RL'],\n",
    "\tspikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), epochs_decoding_time_bin_size=epochs_decoding_time_bin_size,\n",
    "    session_name=session_name, t_start=t_start, t_delta=t_delta, t_end=t_end,\n",
    ")\n",
    "\n",
    "filter_epochs_to_decoded_dict, filter_epochs_pseudo2D_continuous_specific_decoded_result, filter_epochs_decoder_dict, filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict = _temp_out_tuple\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d1034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: filter_epochs_to_decoded_dict, filter_epochs_pseudo2D_continuous_specific_decoded_result, filter_epochs_decoder_dict, filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict\n",
    "debug_print = True\n",
    "\n",
    "for a_new_context, a_filter_epoch_to_decode in filter_epochs_to_decoded_dict.items():\n",
    "    a_new_result = filter_epochs_pseudo2D_continuous_specific_decoded_result[a_new_context]\n",
    "    a_decoder = filter_epochs_decoder_dict[a_new_context]\n",
    "    a_new_decoded_marginal_posterior_df = filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict[a_new_context]\n",
    "\n",
    "    _was_update_success = a_new_fully_generic_result.updating_results_for_context(new_context=a_new_context, a_result=a_new_result, a_decoder=deepcopy(a_decoder), a_decoded_marginal_posterior_df=a_new_decoded_marginal_posterior_df, an_epoch_to_decode=a_filter_epoch_to_decode, debug_print=debug_print)\n",
    "    if not _was_update_success:\n",
    "        print(f'\\t\\tWARN: update failed for context: {a_new_context}')\n",
    "\n",
    "print(f'done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fffbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "\n",
    "## INPUTS: a_new_fully_generic_result\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "spikes_df = deepcopy(get_proper_global_spikes_df(curr_active_pipeline))\n",
    "\n",
    "epochs_decoding_time_bin_size = 0.025\n",
    "\n",
    "## get the base decoder we'll use for decoding\n",
    "a_base_context = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=time_bin_size, data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='ignore'\n",
    "a_best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_matching_contexts(a_base_context, return_multiple_matches=False)\n",
    "\n",
    "filter_epochs_to_decode_dict = {deepcopy(a_best_matching_context).overwriting_context(known_named_decoding_epochs_type='laps'):deepcopy(laps_df),\n",
    "                        # deepcopy(a_best_matching_context).overwriting_context(known_named_decoding_epochs_type='pbes'):deepcopy(non_pbe_df),\n",
    "                        deepcopy(a_best_matching_context).overwriting_context(known_named_decoding_epochs_type='non_pbe_endcaps'):deepcopy(non_pbe_endcaps_df),\n",
    "}\n",
    "\n",
    "a_new_fully_generic_result = a_new_fully_generic_result.perform_decoding(an_all_directional_pf1D_Decoder=a_decoder, filter_epochs_to_decode_dict=filter_epochs_to_decode_dict,\n",
    "                                    spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), epochs_decoding_time_bin_size=epochs_decoding_time_bin_size,\n",
    "                                    session_name=session_name, t_start=t_start, t_delta=t_delta, t_end=t_end,\n",
    "                                )\n",
    "\n",
    "## OUTPUTS: a_new_fully_generic_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfcddf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "\n",
    "a_new_fully_generic_result = GenericDecoderDictDecodedEpochsDictResult._reload_class(a_new_fully_generic_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1693f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_new_fully_generic_result.updating_results_for_context("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a9d603",
   "metadata": {},
   "source": [
    "#### #TODO 2025-04-05 06:03: - [ ] Decode the new epoch and plot the hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c2fcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import GeneralDecoderDictDecodedEpochsDictResult, EpochComputationsComputationsContainer, GenericResultTupleIndexType, KnownNamedDecodingEpochsType, MaskedTimeBinFillType\n",
    "\n",
    "## INPUTS: non_pbe_endcaps_df\n",
    "epochs_decoding_time_bin_size = 0.025\n",
    "\n",
    "## Common/shared for all decoded epochs:\n",
    "unique_decoder_names = ['long', 'short']\n",
    "non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict, non_PBE_marginal_over_track_ID, (time_bin_containers, time_window_centers, track_marginal_posterior_df) = nonPBE_results._build_merged_joint_placefields_and_decode(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline))) # , filter_epochs=deepcopy(global_any_laps_epochs_obj)\n",
    "\n",
    "## from dict of filter_epochs to decode:\n",
    "global_replays_df: pd.DataFrame = TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].replay))\n",
    "filter_epochs_to_decode_dict: Dict[KnownNamedDecodingEpochsType, Epoch] = {\n",
    "    # 'laps': ensure_Epoch(deepcopy(global_any_laps_epochs_obj)),\n",
    "    # 'pbe': ensure_Epoch(deepcopy(global_session.pbe.get_non_overlapping())),\n",
    "    # 'ripple': ensure_Epoch(deepcopy(global_session.ripple)),\n",
    "    # 'replay': ensure_Epoch(deepcopy(global_replays_df)),\n",
    "    # 'non_pbe': ensure_Epoch(deepcopy(global_session.non_pbe)),\n",
    "    'non_pbe_endcaps': ensure_Epoch(deepcopy(non_pbe_endcaps_df)),\n",
    "}\n",
    "## constrain all epochs to be at least two decoding time bins long, or drop them entirely:\n",
    "filter_epochs_to_decode_dict = {k:_compute_proper_filter_epochs(epochs_df=v, desired_decoding_time_bin_size=epochs_decoding_time_bin_size, minimum_event_duration=(2.0 * epochs_decoding_time_bin_size), mode=EpochFilteringMode.DropShorter)[0] for k, v in filter_epochs_to_decode_dict.items()} # `[0]` gets just the dataframe, as in DropShorter mode the time_bin_size is unchanged\n",
    "# OUTPUTS: filter_epochs_to_decode_dict\n",
    "\n",
    "\n",
    "## Perform the decoding and masking as needed for invalid bins:\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "a_general_decoder_dict_decoded_epochs_dict_result: GeneralDecoderDictDecodedEpochsDictResult = EpochComputationsComputationsContainer._build_output_decoded_posteriors(non_PBE_all_directional_pf1D_Decoder=non_PBE_all_directional_pf1D_Decoder, # pseudo2D_continuous_specific_decoded_result=pseudo2D_continuous_specific_decoded_result,\n",
    "    filter_epochs_to_decode_dict=filter_epochs_to_decode_dict,\n",
    "    unique_decoder_names=unique_decoder_names, spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), epochs_decoding_time_bin_size=epochs_decoding_time_bin_size,\n",
    "    session_name=session_name, t_start=t_start, t_delta=t_delta, t_end=t_end,\n",
    ")\n",
    "## OUTPUTS: a_general_decoder_dict_decoded_epochs_dict_result\n",
    "\n",
    "## OUTPUTS: filter_epochs_pseudo2D_continuous_specific_decoded_result, filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict\n",
    "# 58sec\n",
    "\n",
    "\n",
    "## Try fresh 2025-03-11-style decoding of the TrackTemplates:\n",
    "\n",
    "## Perform the decoding and masking as needed for invalid bins:\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05531766",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1782ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benedict import benedict\n",
    "filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict = benedict(a_general_decoder_dict_decoded_epochs_dict_result.filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict)\n",
    "filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict.keypaths() # ['laps', 'laps.ignore', 'laps.last_valid', 'laps.nan_filled', 'non_pbe', 'non_pbe.ignore', 'non_pbe.last_valid', 'non_pbe.nan_filled', 'pbe', 'pbe.ignore', 'pbe.last_valid', 'pbe.nan_filled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f20398f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "template: str = 'plotly_dark' # set plotl template\n",
    "pio.templates.default = template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a43d92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute and plot the new tracks:\n",
    "# non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict, non_PBE_marginal_over_track_ID, (time_bin_containers, time_window_centers) = nonPBE_results._build_merged_joint_placefields_and_decode(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)))\n",
    "unique_added_track_identifiers = nonPBE_results.add_to_SpikeRaster2D_tracks(active_2d_plot=active_2d_plot, non_PBE_all_directional_pf1D_Decoder=non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result=pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict=continuous_decoded_results_dict, non_PBE_marginal_over_track_ID=non_PBE_marginal_over_track_ID, time_window_centers=time_window_centers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebe5462",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import build_single_plotly_marginal_scatter_and_hist_over_time\n",
    "\n",
    "#INPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder\n",
    "_flat_out_figs_dict = {}\n",
    "a_fig, a_figure_context = build_single_plotly_marginal_scatter_and_hist_over_time(a_decoded_posterior_df=a_decoded_marginal_posterior_df, a_target_context=a_target_context)\n",
    "_flat_out_figs_dict[a_figure_context] = a_fig\n",
    "\n",
    "a_fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96641b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoded_marginal_posterior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295078f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = a_general_decoder_dict_decoded_epochs_dict_result.build_plotly_marginal_scatter_and_hist_over_time()\n",
    "\n",
    "# _flat_out_figs_dict = a_general_decoder_dict_decoded_epochs_dict_result.build_plotly_marginal_scatter_and_hist_over_time(debug_print=False)\n",
    "\n",
    "# display(list(_flat_out_figs_dict.values())[0])\n",
    "\n",
    "# Display all figures in the dictionary\n",
    "for fig in _flat_out_figs_dict.values():\n",
    "    display(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db216ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import build_single_plotly_marginal_scatter_and_hist_over_time\n",
    "\n",
    "#INPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder\n",
    "_flat_out_figs_dict = {}\n",
    "# a_target_context = curr_active_pipeline.build_display_context_for_filtered_session(filtered_session_name='maze_any', display_fn_name='DirectionalMergedDecoders')\n",
    "a_target_context = curr_active_pipeline.build_display_context_for_session(display_fn_name='DirectionalMergedDecoders', time_bin_size=0.025)\n",
    "a_fig, a_figure_context = build_single_plotly_marginal_scatter_and_hist_over_time(a_decoded_posterior_df=laps_time_bin_marginals_df, a_target_context=a_target_context)\n",
    "_flat_out_figs_dict[a_figure_context] = a_fig\n",
    "\n",
    "a_fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03d3caf",
   "metadata": {},
   "source": [
    "# 2025-03-24 11:19 TimeBinAggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36957842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "\n",
    "# INPUT: a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult \n",
    "a_new_fully_generic_result.get_matching_contexts(context_query=IdentifyingContext(data_grain= 'per_epoch'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a5eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_new_fully_generic_result.get_matching_contexts(context_query=IdentifyingContext())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f289430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "a_new_fully_generic_result.get_matching_contexts(context_query=IdentifyingContext(trained_compute_epochs='laps', decoder_identifier='pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type='laps',\n",
    "    masked_time_bin_fill_type='ignore',\n",
    "    # masked_time_bin_fill_type='dropped',\n",
    "    data_grain= 'per_time_bin'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51118ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get all non-global, `data_grain= 'per_time_bin'`\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=IdentifyingContext(trained_compute_epochs='laps', decoder_identifier='pseudo2D', time_bin_size=0.025,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t known_named_decoding_epochs_type=['pbe', 'laps'],\n",
    "    masked_time_bin_fill_type='ignore',\n",
    "    # masked_time_bin_fill_type='dropped',\n",
    "    data_grain= 'per_time_bin'))        \n",
    "        \n",
    "flat_decoded_marginal_posterior_df_context_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8390426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_matching_context, a_result, a_decoder, a_decoded_time_bin_marginal_posterior_df = a_new_fully_generic_result.get_results_matching_contexts(context_query=IdentifyingContext(trained_compute_epochs='laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'global', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'), return_multiple_matches=False)\n",
    "best_matching_context, a_result, a_decoder, a_decoded_time_bin_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=IdentifyingContext(trained_compute_epochs='laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type='laps',\n",
    "    masked_time_bin_fill_type='ignore',\n",
    "    # masked_time_bin_fill_type='dropped',\n",
    "    data_grain= 'per_time_bin'))\n",
    "\n",
    "a_decoded_time_bin_marginal_posterior_df\n",
    "\n",
    "## OUTPUTS: a_decoded_time_bin_marginal_posterior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592a128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_matching_context, a_result, a_decoder, a_decoded_time_bin_marginal_posterior_df = a_new_fully_generic_result.get_results_matching_contexts(context_query=IdentifyingContext(trained_compute_epochs='laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'global', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'), return_multiple_matches=False)\n",
    "best_matching_context, a_result, a_decoder, a_decoded_time_bin_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=IdentifyingContext(trained_compute_epochs='laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type='pbe',\n",
    "    masked_time_bin_fill_type='ignore',\n",
    "    # masked_time_bin_fill_type='dropped',\n",
    "    data_grain= 'per_time_bin'))\n",
    "\n",
    "a_decoded_time_bin_marginal_posterior_df\n",
    "\n",
    "## OUTPUTS: a_decoded_time_bin_marginal_posterior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729d8a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(list(a_decoded_time_bin_marginal_posterior_df.columns)) # ['P_LR', 'P_RL', 'P_Long', 'P_Short', 'long_LR', 'long_RL', 'short_LR', 'short_RL', 'result_t_bin_idx', 'epoch_df_idx', 'parent_epoch_label', 'label', 'start', 't_bin_center', 'stop', 'delta_aligned_start_t', 'session_name', 'time_bin_size', 'pre_post_delta_category', 'trained_compute_epochs', 'pfND_ndim', 'decoder_identifier', 'known_named_decoding_epochs_type', 'masked_time_bin_fill_type', 'data_grain', 'is_t_bin_center_fake', 'rolling_avg_P_Short', 'mean_P_Short']\n",
    "broken_columns_dict = {IdentifyingContext(known_named_decoding_epochs_type= 'global', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'): ['result_t_bin_idx', 'epoch_df_idx', 'parent_epoch_label'],\n",
    "                      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses.time_bin_aggregation import TimeBinAggregation\n",
    "\n",
    "## INPUTS: a_decoded_time_bin_marginal_posterior_df\n",
    "\n",
    "n_rolling_avg_window_tbins: int = 3\n",
    "# Create a copy to avoid modifying the original\n",
    "result_df = a_decoded_time_bin_marginal_posterior_df.copy()\n",
    "epoch_partitioned_dfs_dict = a_decoded_time_bin_marginal_posterior_df.pho.partition_df_dict(partitionColumn='parent_epoch_label')\n",
    "\n",
    "# Process each partition\n",
    "for k, df in epoch_partitioned_dfs_dict.items():\n",
    "    rolling_avg = TimeBinAggregation.ToPerEpoch.peak_rolling_avg(df=df, column='P_Short', window=n_rolling_avg_window_tbins)    \n",
    "    # Calculate the mean of P_Short for this group\n",
    "    mean_p_short = TimeBinAggregation.ToPerEpoch.mean(df=df, column='P_Short')\n",
    "\n",
    "    # Get indices from this partition\n",
    "    indices = df.index\n",
    "    # Assign the result to the corresponding rows in the result dataframe\n",
    "    result_df.loc[indices, 'rolling_avg_P_Short'] = rolling_avg\n",
    "    result_df.loc[indices, 'mean_P_Short'] = mean_p_short  # Same mean value for all rows in group\n",
    "    \n",
    "    # result_df.loc[indices\n",
    "\n",
    "## OUTPUTS: result_df\n",
    "\n",
    "a_decoded_time_bin_marginal_posterior_df = deepcopy(result_df)\n",
    "a_decoded_time_bin_marginal_posterior_df\n",
    "\n",
    "# Then keep only the first entry for each 'parent_epoch_label'\n",
    "a_decoded_per_epoch_marginals_df = a_decoded_time_bin_marginal_posterior_df.groupby('parent_epoch_label').first().reset_index()\n",
    "a_decoded_per_epoch_marginals_df\n",
    "\n",
    "## OUTPUTS: a_decoded_time_bin_marginal_posterior_df, a_decoded_per_epoch_marginals_df\n",
    "## Columns of interest: 'rolling_avg_P_Short'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bc734a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses.time_bin_aggregation import TimeBinAggregation\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "\n",
    "a_decoded_per_epoch_marginals_df, a_decoded_time_bin_marginal_posterior_df = GenericDecoderDictDecodedEpochsDictResult._perform_per_epoch_time_bin_aggregation(a_decoded_time_bin_marginal_posterior_df=a_decoded_time_bin_marginal_posterior_df, probabilitY_column_to_aggregate='P_Short', n_rolling_avg_window_tbins=3)\n",
    "\n",
    "a_decoded_time_bin_marginal_posterior_df\n",
    "a_decoded_per_epoch_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae48cb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext, CollisionOutcome\n",
    "from neuropy.analyses.time_bin_aggregation import TimeBinAggregation\n",
    "\n",
    "## get all non-global, `data_grain= 'per_time_bin'`\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=IdentifyingContext(trained_compute_epochs='laps', decoder_identifier='pseudo2D', time_bin_size=0.025,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t known_named_decoding_epochs_type=['pbe', 'laps'],\n",
    "    masked_time_bin_fill_type=('ignore', 'dropped'),\n",
    "    # masked_time_bin_fill_type='dropped',\n",
    "    data_grain= 'per_time_bin'))        \n",
    "\n",
    "\n",
    "\n",
    "_newly_updated_values_tuple = a_new_fully_generic_result.compute_all_per_epoch_aggregations_from_per_time_bin_results(flat_decoded_marginal_posterior_df_context_dict=flat_decoded_marginal_posterior_df_context_dict)\n",
    "per_time_bin_to_per_epoch_context_map_dict, flat_decoded_marginal_posterior_df_per_epoch_marginals_df_context_dict, flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict = _newly_updated_values_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5a33a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## INPUTS: flat_decoded_marginal_posterior_df_context_dict\n",
    "per_time_bin_to_per_epoch_context_map_dict = {}\n",
    "flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict = {}\n",
    "flat_decoded_marginal_posterior_df_per_epoch_marginals_df_context_dict = {}\n",
    "for a_per_time_bin_ctxt, a_decoded_time_bin_marginal_posterior_df in flat_decoded_marginal_posterior_df_context_dict.items():\n",
    "    a_decoded_per_epoch_marginals_df, a_decoded_time_bin_marginal_posterior_df = GenericDecoderDictDecodedEpochsDictResult._perform_per_epoch_time_bin_aggregation(a_decoded_time_bin_marginal_posterior_df=a_decoded_time_bin_marginal_posterior_df, probabilitY_column_to_aggregate='P_Short', n_rolling_avg_window_tbins=3)\n",
    "    a_per_epoch_ctxt = TimeBinAggregation.ToPerEpoch.get_per_epoch_ctxt_from_per_time_bin_ctxt(a_per_time_bin_ctxt=a_per_time_bin_ctxt)\n",
    "    per_time_bin_to_per_epoch_context_map_dict[a_per_time_bin_ctxt] = a_per_epoch_ctxt\n",
    "    flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict[a_per_time_bin_ctxt] = deepcopy(a_decoded_time_bin_marginal_posterior_df)\n",
    "    flat_decoded_marginal_posterior_df_per_epoch_marginals_df_context_dict[a_per_epoch_ctxt] = a_decoded_per_epoch_marginals_df\n",
    "\n",
    "\n",
    "## OUTPUTS: per_time_bin_to_per_epoch_context_map_dict, flat_decoded_marginal_posterior_df_per_epoch_marginals_df_context_dict, flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict\n",
    "flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict\n",
    "flat_decoded_marginal_posterior_df_per_epoch_marginals_df_context_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f9ca7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: per_time_bin_to_per_epoch_context_map_dict, flat_decoded_marginal_posterior_df_per_epoch_marginals_df_context_dict, flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict\n",
    "# flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict\n",
    "# flat_decoded_marginal_posterior_df_per_epoch_marginals_df_context_dict\n",
    "\n",
    "for a_per_time_bin_ctxt, a_decoded_time_bin_marginal_posterior_df in flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict.items():\n",
    "    a_per_epoch_ctxt = per_time_bin_to_per_epoch_context_map_dict[a_per_time_bin_ctxt]\n",
    "    a_decoded_time_bin_marginal_posterior_df = flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict[a_per_time_bin_ctxt]\n",
    "    a_decoded_per_epoch_marginals_df = flat_decoded_marginal_posterior_df_per_epoch_marginals_df_context_dict[a_per_epoch_ctxt]\n",
    "    a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict[a_per_time_bin_ctxt] = a_decoded_time_bin_marginal_posterior_df\n",
    "    a_best_matching_context, a_result, a_decoder, a_decoded_time_bin_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(a_per_time_bin_ctxt)\n",
    "    # a_best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_matching_context(a_per_time_bin_ctxt, return_multiple_matches=False)\n",
    "    # a_result\n",
    "    print(f'updating: \"{a_per_epoch_ctxt}\"')\n",
    "    print(f\"\\tWARN: TODO 2025-04-07 19:22: - [ ] a_result is wrong, it's the per-time-bin version not the per-epoch version\") #TODO 2025-04-07 19:22: - [ ] a_result is wrong, it's the per-time-bin version not the per-epoch version\n",
    "\n",
    "    ## need to get updated a_decoder, a_result\n",
    "    \n",
    "    # a_dropping_masked_pseudo2D_continuous_specific_decoded_result, _dropping_mask_index_tuple = a_result.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(spikes_df=deepcopy(spikes_df), masked_bin_fill_mode=a_masked_bin_fill_mode) ## Masks the low-firing bins so they don't confound the analysis.\n",
    "    # ## Computes marginals for `dropping_masked_laps_pseudo2D_continuous_specific_decoded_result`\n",
    "    # a_dropping_masked_decoded_marginal_posterior_df = DirectionalPseudo2DDecodersResult.perform_compute_specific_marginals(a_result=a_dropping_masked_pseudo2D_continuous_specific_decoded_result, marginal_context=a_masked_updated_context)\n",
    "    a_new_fully_generic_result.updating_results_for_context(new_context=a_per_epoch_ctxt, a_result=deepcopy(a_result), a_decoder=deepcopy(a_decoder), a_decoded_marginal_posterior_df=deepcopy(a_decoded_per_epoch_marginals_df)) ## update using the result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd3ce45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a_new_fully_generic_result.updating_results_for_context(new_context=a_masked_updated_context, a_result=deepcopy(a_dropping_masked_pseudo2D_continuous_specific_decoded_result), a_decoder=deepcopy(a_decoder), a_decoded_marginal_posterior_df=deepcopy(a_dropping_masked_decoded_marginal_posterior_df)) ## update using the result\n",
    "\n",
    "\n",
    "## INPUTS: a_new_fully_generic_result\n",
    "base_contexts_list = [IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=time_bin_size, known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='ignore', data_grain='per_time_bin'),\n",
    "                    IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=time_bin_size, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore', data_grain='per_time_bin'),\n",
    "                    IdentifyingContext(trained_compute_epochs='non_pbe', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=time_bin_size, known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='ignore', data_grain='per_time_bin'),\n",
    "                    IdentifyingContext(trained_compute_epochs='non_pbe', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=time_bin_size, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore', data_grain='per_time_bin')]\n",
    "masked_contexts_dict = {}\n",
    "\n",
    "for a_base_context in base_contexts_list:\n",
    "\n",
    "    a_best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_matching_contexts(a_base_context, return_multiple_matches=False)\n",
    "    ## `a_decoder` is None for some reason?`\n",
    "    ## INPUTS: a_result, masked_bin_fill_mode\n",
    "    a_masked_updated_context: IdentifyingContext = deepcopy(a_best_matching_context).overwriting_context(masked_time_bin_fill_type=a_masked_bin_fill_mode, data_grain='per_time_bin')\n",
    "    masked_contexts_dict[a_base_context] = a_masked_updated_context\n",
    "    if debug_print:\n",
    "        print(f'a_masked_updated_context: {a_masked_updated_context}')\n",
    "    \n",
    "    ## MASKED with NaNs (no backfill):\n",
    "    a_dropping_masked_pseudo2D_continuous_specific_decoded_result, _dropping_mask_index_tuple = a_result.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(spikes_df=deepcopy(spikes_df), masked_bin_fill_mode=a_masked_bin_fill_mode) ## Masks the low-firing bins so they don't confound the analysis.\n",
    "    ## Computes marginals for `dropping_masked_laps_pseudo2D_continuous_specific_decoded_result`\n",
    "    a_dropping_masked_decoded_marginal_posterior_df = DirectionalPseudo2DDecodersResult.perform_compute_specific_marginals(a_result=a_dropping_masked_pseudo2D_continuous_specific_decoded_result, marginal_context=a_masked_updated_context)\n",
    "    a_new_fully_generic_result.updating_results_for_context(new_context=a_masked_updated_context, a_result=deepcopy(a_dropping_masked_pseudo2D_continuous_specific_decoded_result), a_decoder=deepcopy(a_decoder), a_decoded_marginal_posterior_df=deepcopy(a_dropping_masked_decoded_marginal_posterior_df)) ## update using the result\n",
    "    \n",
    "## OUTPUTS: masked_contexts_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4273d42a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c76f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import build_single_plotly_marginal_scatter_and_hist_over_time\n",
    "\n",
    "## INPUTS: a_decoded_time_bin_marginal_posterior_df\n",
    "#INPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder\n",
    "_flat_out_figs_dict = {}\n",
    "# a_target_context = curr_active_pipeline.build_display_context_for_filtered_session(filtered_session_name='maze_any', display_fn_name='DirectionalMergedDecoders')\n",
    "a_target_context = curr_active_pipeline.build_display_context_for_session(display_fn_name='a_decoded_time_bin_marginal_posterior_df', time_bin_size=0.025)\n",
    "a_fig, a_figure_context = build_single_plotly_marginal_scatter_and_hist_over_time(a_decoded_posterior_df=a_decoded_time_bin_marginal_posterior_df, a_target_context=a_target_context, y='P_Short')\n",
    "_flat_out_figs_dict[a_figure_context] = a_fig\n",
    "\n",
    "a_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d75da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import build_single_plotly_marginal_scatter_and_hist_over_time\n",
    "\n",
    "## INPUTS: a_decoded_per_epoch_marginals_df\n",
    "#INPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder\n",
    "y_var_name: str = 'rolling_avg_P_Short'\n",
    "_flat_out_figs_dict = {}\n",
    "# a_target_context = curr_active_pipeline.build_display_context_for_filtered_session(filtered_session_name='maze_any', display_fn_name='DirectionalMergedDecoders')\n",
    "a_target_context = curr_active_pipeline.build_display_context_for_session(display_fn_name='a_decoded_per_epoch_marginals_df', time_bin_size=0.025)\n",
    "a_fig, a_figure_context = build_single_plotly_marginal_scatter_and_hist_over_time(a_decoded_posterior_df=a_decoded_per_epoch_marginals_df, a_target_context=a_target_context, y=y_var_name)\n",
    "_flat_out_figs_dict[a_figure_context] = a_fig\n",
    "\n",
    "a_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ce3de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder\n",
    "_flat_out_figs_dict = {}\n",
    "# a_target_context = curr_active_pipeline.build_display_context_for_filtered_session(filtered_session_name='maze_any', display_fn_name='DirectionalMergedDecoders')\n",
    "a_target_context = curr_active_pipeline.build_display_context_for_session(display_fn_name='laps_per_epoch_marginals_df', time_bin_size=0.025)\n",
    "a_fig, a_figure_context = build_single_plotly_marginal_scatter_and_hist_over_time(a_decoded_posterior_df=laps_per_epoch_marginals_df, a_target_context=a_target_context)\n",
    "_flat_out_figs_dict[a_figure_context] = a_fig\n",
    "\n",
    "a_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a467e0bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71f63cb8",
   "metadata": {},
   "source": [
    "# 2025-04-14 - Getting the new Global Computation Output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3622b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "from neuropy.core.epoch import EpochsAccessor, Epoch, ensure_dataframe, ensure_Epoch\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import EpochComputationFunctions, EpochComputationsComputationsContainer, NonPBEDimensionalDecodingResult, Compute_NonPBE_Epochs, KnownFilterEpochs\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import GeneralDecoderDictDecodedEpochsDictResult, GenericResultTupleIndexType, KnownNamedDecodingEpochsType, MaskedTimeBinFillType\n",
    "\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "\n",
    "## Unpack from pipeline:\n",
    "nonPBE_results: EpochComputationsComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['EpochComputations']\n",
    "a_new_NonPBE_Epochs_obj: Compute_NonPBE_Epochs = nonPBE_results.a_new_NonPBE_Epochs_obj\n",
    "results1D: NonPBEDimensionalDecodingResult = nonPBE_results.results1D\n",
    "results2D: NonPBEDimensionalDecodingResult = nonPBE_results.results2D\n",
    "\n",
    "epochs_decoding_time_bin_size = nonPBE_results.epochs_decoding_time_bin_size\n",
    "frame_divide_bin_size = nonPBE_results.frame_divide_bin_size\n",
    "\n",
    "print(f'{epochs_decoding_time_bin_size = }, {frame_divide_bin_size = }')\n",
    "\n",
    "assert (results1D is not None)\n",
    "# assert (results2D is not None)\n",
    "\n",
    "## New computed properties:\n",
    "a_general_decoder_dict_decoded_epochs_dict_result: GeneralDecoderDictDecodedEpochsDictResult = nonPBE_results.a_general_decoder_dict_decoded_epochs_dict_result ## get the pre-decoded result\n",
    "a_general_decoder_dict_decoded_epochs_dict_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0904082e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unpack from pipeline:\n",
    "valid_EpochComputations_result: EpochComputationsComputationsContainer = global_computation_results.computed_data['EpochComputations'] # owning_pipeline_reference.global_computation_results.computed_data['EpochComputations']\n",
    "assert valid_EpochComputations_result is not None\n",
    "epochs_decoding_time_bin_size: float = valid_EpochComputations_result.epochs_decoding_time_bin_size ## just get the standard size. Currently assuming all things are the same size!\n",
    "print(f'\\tepochs_decoding_time_bin_size: {epochs_decoding_time_bin_size}')\n",
    "assert epochs_decoding_time_bin_size == valid_EpochComputations_result.epochs_decoding_time_bin_size, f\"\\tERROR: nonPBE_results.epochs_decoding_time_bin_size: {valid_EpochComputations_result.epochs_decoding_time_bin_size} != epochs_decoding_time_bin_size: {epochs_decoding_time_bin_size}\"\n",
    "a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult = valid_EpochComputations_result.a_generic_decoder_dict_decoded_epochs_dict_result ## get existing\n",
    "a_new_fully_generic_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef58694",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_context = IdentifyingContext(known_named_decoding_epochs_type='global') # , data_grain= 'per_time_bin -- not really relevant: ['masked_time_bin_fill_type', 'known_named_decoding_epochs_type', 'data_grain']\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=search_context, return_multiple_matches=True, debug_print=True)\n",
    "# a_context, a_result, a_decoder, _ = a_new_fully_generic_result.get_results_matching_contexts(context_query=search_context, return_multiple_matches=False, debug_print=True)\n",
    "# a_decoder\n",
    "flat_context_list\n",
    "# flat_decoder_context_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fba4e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: a_new_fully_generic_result\n",
    "\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', masked_time_bin_fill_type='dropped', data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps', time_bin_size=0.025\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='nan_filled', data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps', time_bin_size=0.025\n",
    "# flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=False)\n",
    "# flat_context_list\n",
    "# flat_decoded_marginal_posterior_df_context_dict\n",
    "best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=a_target_context, debug_print=False)\n",
    "\n",
    "print(f'best_matching_context: {best_matching_context}')\n",
    "## OUTPUTS: flat_decoder_context_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de69542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: a_decoded_marginal_posterior_df, best_matching_context, a_decoder\n",
    "time_bin_size = epochs_decoding_time_bin_size\n",
    "info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "plot_row_identifier: str = best_matching_context.get_description(subset_includelist=['known_named_decoding_epochs_type', 'masked_time_bin_fill_type'], include_property_names=True, key_value_separator=':', separator='|', replace_separator_in_property_names='-')\n",
    "a_time_window_centers = a_decoded_marginal_posterior_df['t_bin_center'].to_numpy() \n",
    "a_1D_posterior = a_decoded_marginal_posterior_df[['P_Long', 'P_Short']].to_numpy().T\n",
    "xbin = deepcopy(a_decoder.xbin)\n",
    "a_variable_name: str = 'P_Short'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374612ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_global_decoded_result: SingleEpochDecodedResult = a_result.get_result_for_epoch(0) # SingleEpochDecodedResult\n",
    "a_global_decoded_result.p_x_given_n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9e4656",
   "metadata": {},
   "source": [
    "# 2025-04-11 - Full-session decoded marginal outputs as yellow-blue plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421fcd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _plot_all_time_decoded_marginal_figures\n",
    "\n",
    "## INPUTS: a_new_fully_generic_result\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='nan_filled', data_grain='per_time_bin')\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='ignore', data_grain='per_time_bin')\n",
    "best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=a_target_context, debug_print=False)\n",
    "epochs_decoding_time_bin_size = best_matching_context.get('time_bin_size', None)\n",
    "assert epochs_decoding_time_bin_size is not None\n",
    "\n",
    "_all_tracks_active_out_figure_paths, _all_tracks_out_artists, _all_tracks_out_axes = _plot_all_time_decoded_marginal_figures(curr_active_pipeline=curr_active_pipeline, best_matching_context=best_matching_context, a_decoded_marginal_posterior_df=a_decoded_marginal_posterior_df, spike_raster_window=spike_raster_window, active_2d_plot=active_2d_plot, epochs_decoding_time_bin_size=epochs_decoding_time_bin_size)\n",
    "_all_tracks_active_out_figure_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ca483a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _plot_all_time_decoded_marginal_figures_non_interactive\n",
    "\n",
    "## INPUTS: a_new_fully_generic_result\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='nan_filled', data_grain='per_time_bin')\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='ignore', data_grain='per_time_bin')\n",
    "best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=a_target_context, debug_print=False)\n",
    "epochs_decoding_time_bin_size = best_matching_context.get('time_bin_size', None)\n",
    "assert epochs_decoding_time_bin_size is not None\n",
    "\n",
    "_all_tracks_active_out_figure_paths, _all_tracks_out_artists, _all_tracks_out_axes = _plot_all_time_decoded_marginal_figures_non_interactive(curr_active_pipeline=curr_active_pipeline, best_matching_context=best_matching_context, a_decoded_marginal_posterior_df=a_decoded_marginal_posterior_df, epochs_decoding_time_bin_size=epochs_decoding_time_bin_size)\n",
    "_all_tracks_active_out_figure_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862973dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import Spike2DRaster\n",
    "from pyphoplacecellanalysis.GUI.Qt.SpikeRasterWindows.Spike3DRasterWindowWidget import Spike3DRasterWindowWidget\n",
    "from pyphoplacecellanalysis.GUI.Qt.PlaybackControls.Spike3DRasterBottomPlaybackControlBarWidget import Spike3DRasterBottomPlaybackControlBar\n",
    "\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.spike_raster_widgets import _setup_spike_raster_window_for_debugging\n",
    "\n",
    "# Gets the existing SpikeRasterWindow or creates a new one if one doesn't already exist:\n",
    "spike_raster_window, (active_2d_plot, active_3d_plot, main_graphics_layout_widget, main_plot_widget, background_static_scroll_plot_widget) = Spike3DRasterWindowWidget.find_or_create_if_needed(curr_active_pipeline, force_create_new=True)\n",
    "\n",
    "all_global_menus_actionsDict, global_flat_action_dict = _setup_spike_raster_window_for_debugging(spike_raster_window)\n",
    "\n",
    "# preview_overview_scatter_plot: pg.ScatterPlotItem  = active_2d_plot.plots.preview_overview_scatter_plot # ScatterPlotItem \n",
    "# preview_overview_scatter_plot.setDownsampling(auto=True, method='subsample', dsRate=10)\n",
    "main_graphics_layout_widget: pg.GraphicsLayoutWidget = active_2d_plot.ui.main_graphics_layout_widget\n",
    "wrapper_layout: pg.QtWidgets.QVBoxLayout = active_2d_plot.ui.wrapper_layout\n",
    "main_content_splitter = active_2d_plot.ui.main_content_splitter # QSplitter\n",
    "layout = active_2d_plot.ui.layout\n",
    "background_static_scroll_window_plot = active_2d_plot.plots.background_static_scroll_window_plot # PlotItem\n",
    "main_plot_widget = active_2d_plot.plots.main_plot_widget # PlotItem\n",
    "active_window_container_layout = active_2d_plot.ui.active_window_container_layout # GraphicsLayout, first item of `main_graphics_layout_widget` -- just the active raster window I think, there is a strange black space above it\n",
    "bottom_bar: Spike3DRasterBottomPlaybackControlBar = spike_raster_window.bottom_playback_control_bar_widget\n",
    "# bottom_bar.log_print('test manual log entry')\n",
    "bottom_bar.add_log_line('test manual log entry')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed2631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import Spike2DRaster, SynchronizedPlotMode\n",
    "from pyphoplacecellanalysis.GUI.Qt.SpikeRasterWindows.Spike3DRasterWindowWidget import Spike3DRasterWindowWidget\n",
    "\n",
    "# _all_tracks_out_artists['new_curves_separate_plot']\n",
    "active_2d_plot.sync_matplotlib_render_plot_widget(identifier='new_curves_separate_plot', sync_mode=SynchronizedPlotMode.TO_GLOBAL_DATA) ## set sync mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038f4769",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(_all_tracks_active_out_figure_paths.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ac430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image # create_gif_from_images\n",
    "from pyphocorehelpers.plotting.media_output_helpers import get_array_as_image_stack, save_array_as_image_stack, vertical_image_stack\n",
    "\n",
    "# Let's assume you have a list of images\n",
    "out_figs_paths = list(_all_tracks_active_out_figure_paths.values()) # ['image1.png', 'image2.png', 'image3.png']  # replace this with actual paths to your images\n",
    "imgs = [Image.open(i) for i in out_figs_paths]\n",
    "imgs[0]\n",
    "imgs[1]\n",
    "imgs[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a15f4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_img = get_array_as_image_stack(imgs, offset=0, single_image_alpha_level=0.85)\n",
    "output_img = vertical_image_stack(imgs, v_overlap=0, padding=0)\n",
    "output_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d77c8f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7e6a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.PyqtgraphTimeSynchronizedWidget import PyqtgraphTimeSynchronizedWidget\n",
    "\n",
    "widget: PyqtgraphTimeSynchronizedWidget = _all_tracks_out_artists['new_curves_separate_plot']\n",
    "\n",
    "widget.getRootPlotItem().setXRange(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time, padding=0) ## global frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f4cb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "widget.update(None, defer_render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4108ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_2d_plot.setW\n",
    "\n",
    "start_t = spike_raster_window.total_data_start_time\n",
    "end_t = spike_raster_window.total_data_end_time\n",
    "start_t, end_t\n",
    "\n",
    "active_2d_plot.Render2DScrollWindowPlot_on_window_update(start_t, end_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d345b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_fractional_seconds: float = 1244.907\n",
    "spike_raster_window.update_animation(total_fractional_seconds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e258a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_1D_most_likely_position_comparsions\n",
    "from neuropy.utils.matplotlib_helpers import get_heatmap_cmap\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import PlottingHelpers\n",
    "\n",
    "extended_dock_title_info = ''\n",
    "a_variable_name = ''\n",
    "\n",
    "if a_variable_name is None:\n",
    "    a_variable_name = name\n",
    "\n",
    "if a_dock_config is None:\n",
    "    override_dock_group_name: str = None ## this feature doesn't work\n",
    "    a_dock_config = CustomCyclicColorsDockDisplayConfig(showCloseButton=True, named_color_scheme=NamedColorScheme.grey)\n",
    "    a_dock_config.dock_group_names = [override_dock_group_name] # , 'non-PBE Continuous Decoding'\n",
    "\n",
    "\n",
    "n_xbins, n_t_bins = np.shape(a_1D_posterior)\n",
    "\n",
    "if xbin is None:\n",
    "    xbin = np.arange(n_xbins)\n",
    "\n",
    "## ✅ Add a new row for each of the four 1D directional decoders:\n",
    "identifier_name: str = name\n",
    "if extended_dock_title_info is not None:\n",
    "    identifier_name += extended_dock_title_info ## add extra info like the time_bin_size in ms\n",
    "print(f'identifier_name: {identifier_name}')\n",
    "widget, matplotlib_fig, matplotlib_fig_axes, dock_item = self.add_new_matplotlib_render_plot_widget(name=identifier_name, dockSize=(25, 200), display_config=a_dock_config)\n",
    "an_ax = matplotlib_fig_axes[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5cd1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "variable_name: str = a_variable_name\n",
    "\n",
    "# active_most_likely_positions = active_marginals.most_likely_positions_1D # Raw decoded positions\n",
    "active_most_likely_positions = None\n",
    "active_posterior = deepcopy(a_1D_posterior)\n",
    "\n",
    "posterior_heatmap_imshow_kwargs = dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9c6a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## No existing axes/dock:\n",
    "an_ax = None\n",
    "variable_name: str = a_variable_name\n",
    "active_most_likely_positions = None\n",
    "active_posterior = deepcopy(a_1D_posterior)\n",
    "posterior_heatmap_imshow_kwargs = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed427fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_1D_most_likely_position_comparsions\n",
    "from neuropy.utils.matplotlib_helpers import get_heatmap_cmap\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import PlottingHelpers\n",
    "\n",
    "# most_likely_positions_mode: 'standard'|'corrected'\n",
    "## Actual plotting portion:\n",
    "fig, an_ax = plot_1D_most_likely_position_comparsions(measured_position_df=None, time_window_centers=time_window_centers, xbin=deepcopy(xbin),\n",
    "                                                        posterior=active_posterior,\n",
    "                                                        active_most_likely_positions_1D=active_most_likely_positions,\n",
    "                                                        ax=an_ax, variable_name=variable_name, debug_print=True, enable_flat_line_drawing=False,\n",
    "                                                        posterior_heatmap_imshow_kwargs=posterior_heatmap_imshow_kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f18e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Update the params\n",
    "widget.params.variable_name = variable_name\n",
    "widget.params.posterior_heatmap_imshow_kwargs = deepcopy(posterior_heatmap_imshow_kwargs)\n",
    "widget.params.enable_flat_line_drawing = False\n",
    "if extended_dock_title_info is not None:\n",
    "    widget.params.extended_dock_title_info = deepcopy(extended_dock_title_info)\n",
    "    \n",
    "## Update the plots_data\n",
    "if time_window_centers is not None:\n",
    "    widget.plots_data.time_window_centers = deepcopy(time_window_centers)\n",
    "if xbin is not None:\n",
    "    widget.plots_data.xbin = deepcopy(xbin)\n",
    "if active_most_likely_positions is not None:\n",
    "    widget.plots_data.active_most_likely_positions = deepcopy(active_most_likely_positions)\n",
    "widget.plots_data.variable_name = variable_name\n",
    "if a_1D_posterior is not None:\n",
    "    widget.plots_data.matrix = deepcopy(a_1D_posterior)\n",
    "\n",
    "widget.draw() # alternative to accessing through full path?\n",
    "# self.sync_matplotlib_render_plot_widget(identifier_name) # Sync it with the active window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea454b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot = spike_raster_window.spike_raster_plt_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f47551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_interval_tracks_out_dict = active_2d_plot.prepare_pyqtgraph_intervalPlot_tracks(enable_interval_overview_track=True, should_remove_all_and_re_add=True, should_link_to_main_plot_widget=False)\n",
    "interval_window_dock_config, intervals_dock, intervals_time_sync_pyqtgraph_widget, intervals_root_graphics_layout_widget, intervals_plot_item = _interval_tracks_out_dict['intervals']\n",
    "if 'interval_overview' in _interval_tracks_out_dict:\n",
    "    interval_overview_window_dock_config, intervals_overview_dock, intervals_overview_time_sync_pyqtgraph_widget, intervals_overview_root_graphics_layout_widget, intervals_overview_plot_item = _interval_tracks_out_dict['interval_overview']\n",
    "    intervals_overview_plot_item.setXRange(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time, padding=0) ## global frame\n",
    "    # intervals_overview_time_sync_pyqtgraph_widget.setMaximumHeight(39)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9bef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot = spike_raster_window.spike_raster_plt_2d\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=0.025, masked_time_bin_fill_type='last_valid', data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "print(f'flat_context_list: {flat_context_list}')\n",
    "\n",
    "search_context = IdentifyingContext(known_named_decoding_epochs_type='global') # , data_grain= 'per_time_bin -- not really relevant: ['masked_time_bin_fill_type', 'known_named_decoding_epochs_type', 'data_grain']\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=search_context, return_multiple_matches=True, debug_print=True)\n",
    "# a_context, a_result, a_decoder, _ = a_new_fully_generic_result.get_results_matching_contexts(context_query=search_context, return_multiple_matches=False, debug_print=True)\n",
    "# a_decoder\n",
    "flat_context_list\n",
    "# flat_decoder_context_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ecc4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_overview_time_sync_pyqtgraph_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2083ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the relevant data to plot\n",
    "\n",
    "search_context = IdentifyingContext(pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin') # , data_grain= 'per_time_bin -- not really relevant: ['masked_time_bin_fill_type', 'known_named_decoding_epochs_type', 'data_grain']\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=search_context, return_multiple_matches=True, debug_print=False)\n",
    "# flat_decoded_marginal_posterior_df_context_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6faa78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, DockDisplayColors\n",
    "\n",
    "\n",
    "\n",
    "unique_decoder_names_map: Dict = {'laps': ['long_LR', 'long_RL', 'short_LR', 'short_RL'], 'non_pbe': ['long', 'short']}\n",
    "\n",
    "\n",
    "for a_ctxt, a_result in flat_result_context_dict.items():\n",
    "    ## INPUTS: laps_pseudo2D_continuous_specific_decoded_result: DecodedFilterEpochsResult\n",
    "    a_decoder = flat_decoder_context_dict[a_ctxt]\n",
    "    \n",
    "    unique_decoder_names = unique_decoder_names_map[a_ctxt.get('trained_compute_epochs', None)] # ['long', 'short']\n",
    "    unique_decoder_names = [f\"{a_ctxt}[{k}]\" for k in unique_decoder_names]\n",
    "    \n",
    "    \n",
    "    active_time_bin_size: float = a_result.decoding_time_bin_size\n",
    "    info_string: str = f'{active_time_bin_size:.3f}'\n",
    "    dock_group_sep_character: str = '_'\n",
    "    showCloseButton = True\n",
    "    _common_dock_config_kwargs = {'dock_group_names': [dock_group_sep_character.join([f'LapsDecode', info_string])], 'showCloseButton': showCloseButton}\n",
    "\n",
    "    dock_configs: Dict[str, CustomDockDisplayConfig] = {k:deepcopy(CustomDockDisplayConfig(custom_get_colors_callback_fn=DockDisplayColors.get_random_dock_colors_for_key_fn(key=k), **_common_dock_config_kwargs)) for k in unique_decoder_names}\n",
    "    \n",
    "    pf1D_Decoder_dict = {k:deepcopy(a_decoder) for k in unique_decoder_names} ## this is dumb, but it provides xlims!\n",
    "\n",
    "    # output_dict = active_2d_plot.add_docked_decoded_results_dict_tracks(name=f'LapsDecode', a_decoded_result_dict=a_pseudo2D_split_to_1D_continuous_results_dict, dock_configs=dock_configs,\n",
    "    #                                                                                             pf1D_Decoder_dict=pf1D_Decoder_dict,\n",
    "    #                                                                                             measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "    #                                                                                             extended_dock_title_info=info_string)\n",
    "\n",
    "\n",
    "    # # pf1D_Decoder_dict = {k:deepcopy(v) for k, v in a_decoder.items() if k in unique_decoder_names}\n",
    "\n",
    "\n",
    "    # ## a_1D_continuous_decoded_result: SingleEpochDecodedResult\n",
    "    # a_dock_config = dock_configs[a_decoder_name]\n",
    "    # a_1D_decoder: BasePositionDecoder = pf1D_Decoder_dict[a_decoder_name]\n",
    "    # _out_tuple = self.add_docked_decoded_posterior_track_from_result(name=f'{name}[{a_decoder_name}]', a_dock_config=a_dock_config, a_1D_decoded_result=a_1D_decoded_result,\n",
    "    #                                                                                         xbin = deepcopy(a_1D_decoder.xbin), measured_position_df=deepcopy(measured_position_df), **kwargs) # , should_defer_render=False\n",
    "    # identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = _out_tuple\n",
    "    # ## Add `a_decoded_result` to the plots_data\n",
    "    # widget.plots_data.a_decoded_result = a_1D_decoded_result\n",
    "    # widget.plots_data.a_decoder = deepcopy(a_1D_decoder)\n",
    "    # output_dict[a_decoder_name] = (identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem) ## add again\n",
    "\n",
    "\n",
    "# output_dict = active_2d_plot.add_docked_decoded_results_dict_tracks(name=f'LapsDecode', a_decoded_result_dict=a_pseudo2D_split_to_1D_continuous_results_dict, dock_configs=dock_configs, pf1D_Decoder_dict=flat_decoder_context_dict,\n",
    "#                                                                                             measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "#                                                                                             extended_dock_title_info=info_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6fb8e8",
   "metadata": {},
   "source": [
    "# 2025-04-14 - Correctly output the decoded posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a457a39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import EpochComputationFunctions, EpochComputationsComputationsContainer\n",
    "\n",
    "valid_EpochComputations_result: EpochComputationsComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['EpochComputations']\n",
    "a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult = valid_EpochComputations_result.a_generic_decoder_dict_decoded_epochs_dict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443581ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# epochs_decoding_time_bin_size: float = 0.025\n",
    "epochs_decoding_time_bin_size: float = 0.025\n",
    "\n",
    "_all_tracks_out_artists = {}\n",
    "for a_ctxt, a_df in flat_decoded_marginal_posterior_df_context_dict.items():\n",
    "    time_bin_size = epochs_decoding_time_bin_size\n",
    "    info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "    plot_row_identifier: str = a_ctxt.get_description(subset_includelist=['known_named_decoding_epochs_type', 'masked_time_bin_fill_type'], include_property_names=True, key_value_separator=':', separator='|', replace_separator_in_property_names='-')\n",
    "    a_time_window_centers = a_df['t_bin_center'].to_numpy() \n",
    "    a_1D_posterior = a_df[['P_Long', 'P_Short']].to_numpy().T\n",
    "\n",
    "    identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dock_item = active_2d_plot.add_docked_marginal_track(name=plot_row_identifier, time_window_centers=a_time_window_centers, a_1D_posterior=a_1D_posterior, extended_dock_title_info=info_string)\n",
    "    _all_tracks_out_artists[identifier_name] = widget\n",
    "    intervals_overview_plot_item.setXRange(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time, padding=0) ## global frame\n",
    "    matplotlib_fig_axes[0].set_xlim(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time)\n",
    "    widget.draw()\n",
    "\n",
    "\n",
    "## Make a new matplotlib figure (in a new window) that contains a copy of `matplotlib_fig_axes` inserted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c48a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "dock_item.config.hideTitleBar = True\n",
    "dock_item.hideTitleBar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed02db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib_fig.savefig('data/my_figure.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f235b20",
   "metadata": {
    "tags": [
     "2025-04-14_run_posterior_outputs"
    ]
   },
   "outputs": [],
   "source": [
    "complete_session_context, (session_context, additional_session_context) = curr_active_pipeline.get_complete_session_context()\n",
    "\n",
    "active_out_figure_paths, final_context = curr_active_pipeline.output_figure(final_context=complete_session_context.overwriting_context(display='decoded_P_Short_Posterior'), fig=matplotlib_fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b294ee0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ba4b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c9b536",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.PyqtgraphTimeSynchronizedWidget import PyqtgraphTimeSynchronizedWidget\n",
    "\n",
    "active_2d_plot: Spike2DRaster = active_2d_plot\n",
    "a_dock = active_2d_plot.find_display_dock(identifier='new_curves_separate_plot')\n",
    "widget: PyqtgraphTimeSynchronizedWidget = a_dock.widgets[0]\n",
    "\n",
    "widget.getRootPlotItem().setXRange(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time, padding=0) ## global frame\n",
    "# widget.getRootPlotItem().set_xlim(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time)\n",
    "widget.update(None)\n",
    "\n",
    "# get_flat_widgets_list("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0e6c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.PyqtgraphTimeSynchronizedWidget import PyqtgraphTimeSynchronizedWidget\n",
    "\n",
    "active_2d_plot: Spike2DRaster = active_2d_plot\n",
    "a_dock, widget = active_2d_plot.find_dock_item_tuple(identifier='new_curves_separate_plot')\n",
    "widget.getRootPlotItem().setXRange(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time, padding=0) ## global frame\n",
    "widget.update(None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c045c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export Position over time Figure:\n",
    "complete_session_context, (session_context, additional_session_context) = curr_active_pipeline.get_complete_session_context()\n",
    "\n",
    "active_out_figure_paths, final_context = curr_active_pipeline.output_figure(final_context=complete_session_context.overwriting_context(display='pos_over_t'), fig=widget.getRootPlotItem())\n",
    "active_out_figure_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30f519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export Epoch Interval figure:\n",
    "active_2d_plot: Spike2DRaster = active_2d_plot\n",
    "a_dock, widget = active_2d_plot.find_dock_item_tuple(identifier='interval_overview')\n",
    "widget.getRootPlotItem().setXRange(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time, padding=0) ## global frame\n",
    "widget.update(None)\n",
    "complete_session_context, (session_context, additional_session_context) = curr_active_pipeline.get_complete_session_context()\n",
    "active_out_figure_paths, final_context = curr_active_pipeline.output_figure(final_context=complete_session_context.overwriting_context(display='interval_epochs_overview'), fig=widget.getRootPlotItem())\n",
    "active_out_figure_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec97aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "matplotlib_fig_axes[0].set_xlim(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00109aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import AddNewDecodedPosteriors_MatplotlibPlotCommand\n",
    "from pyphoplacecellanalysis.External.pyqtgraph.dockarea.Dock import Dock, DockDisplayConfig\n",
    "\n",
    "flat_dock_item_tuple_dict: Dict[str, Tuple] = active_2d_plot.get_flat_dock_item_tuple_dict()\n",
    "flat_dock_item_tuple_dict\n",
    "\n",
    "# flat_docks_dict = {k:a_dock for k, (a_dock, a_widget) in flat_dock_item_tuple_dict.items() if ('ContinuousDecode_ - t_bin_size: 0.025' in a_dock.config.dock_group_names) }\n",
    "flat_dockwidgets_dict = {k:a_widget for k, (a_dock, a_widget) in flat_dock_item_tuple_dict.items() if ('ContinuousDecode_ - t_bin_size: 0.025' in a_dock.config.dock_group_names) }\n",
    "\n",
    "# _all_tracks_out_artists = {}\n",
    "for k, a_widget in _all_tracks_out_artists.items():\n",
    "    print(f'k: {k}')\n",
    "    _out_artists = AddNewDecodedPosteriors_MatplotlibPlotCommand._perform_overlay_measured_position(identifier_name=k, widget=a_widget, matplotlib_fig=a_widget.fig, matplotlib_fig_axes=a_widget.axes, measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()))\n",
    "    # _all_tracks_out_artists[k] = _out_artists\n",
    "    a_widget.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f170d0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib_fig_axes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf70eb7",
   "metadata": {},
   "source": [
    "## Export Attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fc9e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.External.pyqtgraph.exporters import MatplotlibExporter\n",
    "\n",
    "# Create the exporter\n",
    "exporter = MatplotlibExporter(intervals_plot_item)\n",
    "\n",
    "# Export to a Matplotlib window\n",
    "exporter.export()\n",
    "\n",
    "# Access the Matplotlib window (the last one created)\n",
    "mpl_window = MatplotlibExporter.windows[-1]\n",
    "\n",
    "# Get the Figure object and do additional customization\n",
    "fig = mpl_window.getFigure()\n",
    "\n",
    "# Now you can use the matplotlib API to customize further\n",
    "# fig.suptitle(\"My Custom Title\")\n",
    "# fig.savefig(\"exported_plot.png\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bec1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure in a new window with the same data\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "# Function to create a standalone copy of a matplotlib figure\n",
    "def create_standalone_copy(original_fig, original_axes):\n",
    "    # Create new figure with the same size\n",
    "    new_fig = Figure(figsize=original_fig.get_size_inches())\n",
    "    new_fig.tight_layout = original_fig.tight_layout\n",
    "    \n",
    "    # Copy each axis from the original to the new figure\n",
    "    for i, ax in enumerate(original_axes):\n",
    "        new_ax = new_fig.add_subplot(len(original_axes), 1, i+1)\n",
    "        \n",
    "        # Copy plot elements (lines, collections, etc.)\n",
    "        for line in ax.get_lines():\n",
    "            new_ax.plot(line.get_xdata(), line.get_ydata(), \n",
    "                       color=line.get_color(), \n",
    "                       linestyle=line.get_linestyle(),\n",
    "                       linewidth=line.get_linewidth(),\n",
    "                       marker=line.get_marker(),\n",
    "                       markersize=line.get_markersize())\n",
    "        \n",
    "        # Copy collections (like imshow, pcolormesh, etc.)\n",
    "        for collection in ax.collections:\n",
    "            new_ax.add_collection(collection.copy())\n",
    "        \n",
    "        # Copy labels and limits\n",
    "        new_ax.set_title(ax.get_title())\n",
    "        new_ax.set_xlabel(ax.get_xlabel())\n",
    "        new_ax.set_ylabel(ax.get_ylabel())\n",
    "        new_ax.set_xlim(ax.get_xlim())\n",
    "        new_ax.set_ylim(ax.get_ylim())\n",
    "    \n",
    "    # Create a new standalone window to display the figure\n",
    "    plt_fig = plt.figure()\n",
    "    plt_manager = plt_fig.canvas.manager\n",
    "    plt_manager.canvas.figure = new_fig\n",
    "    new_fig.set_canvas(plt_manager.canvas)\n",
    "    \n",
    "    return new_fig\n",
    "\n",
    "\n",
    "\n",
    "# After creating and configuring matplotlib_fig and matplotlib_fig_axes\n",
    "# Create a standalone copy\n",
    "standalone_fig = create_standalone_copy(matplotlib_fig, matplotlib_fig_axes)\n",
    "standalone_fig.suptitle(f\"Standalone: {plot_row_identifier}\")\n",
    "\n",
    "# Display the standalone figure\n",
    "plt.figure(standalone_fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4520105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg\n",
    "import pyqtgraph as pg\n",
    "from PyQt5 import QtWidgets\n",
    "\n",
    "# Create a matplotlib figure with Qt backend\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "canvas = FigureCanvasQTAgg(fig)\n",
    "ax1 = fig.add_subplot(211)  # First subplot for matplotlib\n",
    "\n",
    "# Set up a PyQt widget to hold everything\n",
    "main_widget = QtWidgets.QWidget()\n",
    "layout = QtWidgets.QVBoxLayout(main_widget)\n",
    "layout.addWidget(canvas)\n",
    "\n",
    "# Create PyQtGraph plot and add to layout\n",
    "pg_plot = pg.PlotWidget()\n",
    "layout.addWidget(pg_plot)\n",
    "\n",
    "# Now you can plot in both systems\n",
    "ax1.plot([1, 2, 3], [1, 4, 9], 'b-')\n",
    "pg_plot.plot([1, 2, 3], [5, 2, 3], pen='r')\n",
    "\n",
    "main_widget.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d847a7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg\n",
    "import pyqtgraph as pg\n",
    "import numpy as np\n",
    "\n",
    "# Create a window\n",
    "app = pg.mkQApp()\n",
    "win = pg.GraphicsLayoutWidget()\n",
    "win.setWindowTitle('Combined Plot')\n",
    "\n",
    "# Add pyqtgraph plot in the first row\n",
    "p1 = win.addPlot(row=0, col=0)\n",
    "p1.plot(np.random.normal(size=100), pen='g')\n",
    "\n",
    "# Create matplotlib figure and embed it in the second row\n",
    "fig = plt.figure(figsize=(5, 4))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot([0, 1, 2], [1, 3, 2])\n",
    "fig.tight_layout()\n",
    "canvas = FigureCanvasQTAgg(fig)\n",
    "\n",
    "# Add matplotlib canvas as a widget item\n",
    "proxy = win.addViewBox(row=1, col=0)\n",
    "proxy.setDefaultPadding(0)\n",
    "proxy_widget = pg.widgets.RemoteGraphicsView.QtWidgets.QGraphicsProxyWidget()\n",
    "proxy_widget.setWidget(canvas)\n",
    "proxy.addItem(proxy_widget)\n",
    "\n",
    "win.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13928537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Adding matplotlib figure to pyqtgraph\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyqtgraph as pg\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "# Create matplotlib figure\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot([1, 2, 3], [3, 1, 4])\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save to buffer\n",
    "buf = BytesIO()\n",
    "fig.savefig(buf, format='png')\n",
    "buf.seek(0)\n",
    "img = np.array(Image.open(buf))\n",
    "\n",
    "# Display in pyqtgraph\n",
    "pg_win = pg.GraphicsLayoutWidget()\n",
    "view = pg_win.addViewBox()\n",
    "img_item = pg.ImageItem(img)\n",
    "view.addItem(img_item)\n",
    "pg_win.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420e288e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
