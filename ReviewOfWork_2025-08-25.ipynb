{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33f7f339",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[0️⃣ ReviewOfWork (Main Notebook) - Imports](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d98a7b",
   "metadata": {
    "tags": [
     "run-group-0-interactive",
     "run-group-0",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "# %xmode Verbose\n",
    "# %xmode context\n",
    "%pdb off\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "# # Add exclusions for metaclass-using modules\n",
    "# %aimport -neuropy.core.session.dataSession\n",
    "# %aimport -neuropy.core.session.Formats.BaseDataSessionFormats\n",
    "# %aimport -neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat\n",
    "# %aimport -neuropy.core.session.Formats.Specific.BapunDataSessionFormat \n",
    "# %aimport -neuropy.core.session.Formats.Specific.RachelDataSessionFormat\n",
    "# %aimport -neuropy.core.session.Formats.Specific.HiroDataSessionFormt\n",
    "\n",
    "# # !pip install viztracer\n",
    "%load_ext viztracer\n",
    "from viztracer import VizTracer\n",
    "\n",
    "# %load_ext memory_profiler\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "os.environ['QT_API'] = 'pyqt5'\n",
    "os.environ['PYQTGRAPH_QT_LIB'] = 'PyQt5'\n",
    "\n",
    "# from PyQt5.QtWebEngineWidgets import QWebEngineView ## this must come first, before any QtApplication is made: 'ImportError: QtWebEngineWidgets must be imported or Qt.AA_ShareOpenGLContexts must be set before a QCoreApplication instance is created'\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "import importlib\n",
    "from copy import deepcopy\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "# pd.options.mode.dtype_backend = 'pyarrow' # use new pyarrow backend instead of numpy\n",
    "\n",
    "from attrs import define, field, fields, Factory, make_class\n",
    "import tables as tb\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Pho's Formatting Preferences\n",
    "import builtins\n",
    "\n",
    "import IPython\n",
    "from IPython.core.formatters import PlainTextFormatter\n",
    "from IPython import get_ipython\n",
    "\n",
    "from pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\n",
    "# set_pho_preferences_concise()\n",
    "set_pho_preferences_verbose()\n",
    "# Jupyter-lab enable printing for any line on its own (instead of just the last one in the cell)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# BEGIN PPRINT CUSTOMIZATION ___________________________________________________________________________________________ #\n",
    "\n",
    "## IPython pprint\n",
    "from pyphocorehelpers.pprint import wide_pprint, wide_pprint_ipython, wide_pprint_jupyter, MAX_LINE_LENGTH\n",
    "# Override default pprint\n",
    "builtins.pprint = wide_pprint\n",
    "\n",
    "ip = get_ipython()\n",
    "\n",
    "from pyphocorehelpers.ipython_helpers import CustomFormatterMagics\n",
    "\n",
    "# Register the magic\n",
    "get_ipython().register_magics(CustomFormatterMagics)\n",
    "\n",
    "\n",
    "\n",
    "from pyphocorehelpers.pyqt_ipython_rendering_helpers import PyQtFormatters\n",
    "from pyphoplacecellanalysis.General.Mixins.DisplayHelpers import debug_widget_geometry\n",
    "\n",
    "# Register formatters for specific PyQt5 types\n",
    "# Create an instance and register formatters\n",
    "qt_formatters = PyQtFormatters()\n",
    "qt_formatters.register()\n",
    "\n",
    "\n",
    "from pyphocorehelpers.print_helpers import render_scrollable_colored_table_from_dataframe, render_scrollable_colored_table\n",
    "\n",
    "# # import pho_jupyter_preview_widget\n",
    "# from pyphocorehelpers.pho_jupyter_preview_widget.ipython_helpers import PreviewWidgetMagics\n",
    "# from pyphocorehelpers.pho_jupyter_preview_widget.display_helpers import array_repr_with_graphical_preview\n",
    "\n",
    "# # # # Register the magic\n",
    "# ip.register_magics(PreviewWidgetMagics)\n",
    "\n",
    "# %config_ndarray_preview width=500\n",
    "\n",
    "# Register the custom display function for NumPy arrays\n",
    "# ip.display_formatter.formatters['text/html'].for_type(np.ndarray, lambda arr: array_preview_with_graphical_shape_repr_html(arr))\n",
    "# ip = array_repr_with_graphical_shape(ip=ip)\n",
    "# ip = array_repr_with_graphical_preview(ip=ip)\n",
    "# ip = dataframe_show_more_button(ip=ip)\n",
    "\n",
    "print(f'MAX_LINE_LENGTH: {MAX_LINE_LENGTH}')\n",
    "text_formatter: PlainTextFormatter = ip.display_formatter.formatters['text/plain']\n",
    "text_formatter.max_width = MAX_LINE_LENGTH\n",
    "text_formatter.for_type(object, wide_pprint_jupyter)\n",
    "\n",
    "\n",
    "# END PPRINT CUSTOMIZATION ___________________________________________________________________________________________ #\n",
    "\n",
    "from pyphocorehelpers.print_helpers import get_now_time_str, get_now_day_str\n",
    "from pyphocorehelpers.indexing_helpers import get_dict_subset\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path, file_uri_from_path\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "import pyphocorehelpers.programming_helpers as programming_helpers\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "# from neuropy import core\n",
    "from typing import Dict, List, Tuple, Optional, Callable, Union, Any\n",
    "from typing_extensions import TypeAlias\n",
    "import nptyping as ND\n",
    "from nptyping import NDArray\n",
    "import neuropy.utils.type_aliases as types\n",
    "\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder, find_local_session_paths\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.core.epoch import NamedTimerange, Epoch\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.utils.matplotlib_helpers import matplotlib_file_only, matplotlib_configuration, matplotlib_configuration_update\n",
    "from neuropy.core.neuron_identities import NeuronIdentityTable, neuronTypesList, neuronTypesEnum\n",
    "from neuropy.utils.mixins.AttrsClassHelpers import AttrsBasedClassHelperMixin, serialized_field, serialized_attribute_field, non_serialized_field, custom_define\n",
    "from neuropy.utils.mixins.HDF5_representable import HDF_DeserializationMixin, post_deserialize, HDF_SerializationMixin, HDFMixin, HDF_Converter\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.neurons import NeuronType\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from neuropy.core.position import Position\n",
    "from neuropy.core.session.dataSession import DataSession\n",
    "from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent, PlacefieldSnapshot\n",
    "from neuropy.utils.debug_helpers import debug_print_placefield, debug_print_subsession_neuron_differences, debug_print_ratemap, debug_print_spike_counts, debug_plot_2d_binning, print_aligned_columns, parameter_sweeps, _plot_parameter_sweep, compare_placefields_info\n",
    "from neuropy.utils.indexing_helpers import NumpyHelpers, union_of_arrays, intersection_of_arrays, find_desired_sort_indicies, paired_incremental_sorting\n",
    "from pyphocorehelpers.print_helpers import print_object_memory_usage, print_dataframe_memory_usage, print_value_overview_only, DocumentationFilePrinter, print_keys_if_possible, generate_html_string, document_active_variables\n",
    "from pyphocorehelpers.programming_helpers import metadata_attributes\n",
    "from pyphocorehelpers.function_helpers import function_attributes\n",
    "## Pho Programming Helpers:\n",
    "import inspect\n",
    "from pyphocorehelpers.print_helpers import DocumentationFilePrinter, TypePrintMode, print_keys_if_possible, debug_dump_object_member_shapes, print_value_overview_only, document_active_variables\n",
    "from pyphocorehelpers.programming_helpers import IPythonHelpers, PythonDictionaryDefinitionFormat, MemoryManagement, inspect_callable_arguments, get_arguments_as_optional_dict, GeneratedClassDefinitionType, CodeConversion\n",
    "from pyphocorehelpers.notebook_helpers import NotebookCellExecutionLogger\n",
    "from pyphocorehelpers.gui.Qt.TopLevelWindowHelper import TopLevelWindowHelper, print_widget_hierarchy\n",
    "from pyphocorehelpers.indexing_helpers import reorder_columns, reorder_columns_relative, dict_to_full_array\n",
    "from pyphocorehelpers.DataStructure.RenderPlots.MatplotLibRenderPlots import MatplotlibRenderPlots\n",
    "\n",
    "doc_output_parent_folder: Path = Path('EXTERNAL/DEVELOPER_NOTES/DataStructureDocumentation').resolve() # ../.\n",
    "print(f\"doc_output_parent_folder: {doc_output_parent_folder}\")\n",
    "assert doc_output_parent_folder.exists()\n",
    "\n",
    "_notebook_path:Path = Path(IPythonHelpers.try_find_notebook_filepath(IPython.extract_module_locals())).resolve() # Finds the path of THIS notebook\n",
    "# _notebook_execution_logger: NotebookCellExecutionLogger = NotebookCellExecutionLogger(notebook_path=_notebook_path, enable_logging_to_file=False) # Builds a logger that records info about this notebook\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_load_session, batch_extended_computations, batch_evaluate_required_computations, BatchPlotting # BatchPlotting.batch_extended_programmatic_figures\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme # used in perform_pipeline_save\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import PipelineJupyterHelpers, CustomProcessingPhases\n",
    "\n",
    "\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "pg.setConfigOptions(useOpenGL=True)    # Use OpenGL for rendering which handles larger coordinates\n",
    "\n",
    "from pyphocorehelpers.exception_helpers import ExceptionPrintingContext, CapturedException\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import _find_any_context_neurons\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchSessionCompletionHandler # for `post_compute_validate(...)`\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BasePositionDecoder\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsResults\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends # for `_perform_long_short_instantaneous_spike_rate_groups_analysis`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import SingleBarResult, InstantaneousSpikeRateGroupsComputation, TruncationCheckingResults # for `BatchSessionCompletionHandler`, `AcrossSessionsAggregator`\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import SplitPartitionMembership\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalComputationFunctions, DirectionalLapsResult, TrackTemplates, DecoderDecodedEpochsResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderGlobalComputationFunctions,  RankOrderComputationsContainer, RankOrderResult, RankOrderAnalyses\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import EpochComputationFunctions, EpochComputationsComputationsContainer, DecodingResultND, Compute_NonPBE_Epochs, KnownFilterEpochs\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.SequenceBasedComputations import WCorrShuffle, SequenceBasedComputationsContainer\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.ComputationFunctionRegistryHolder import ComputationFunctionRegistryHolder, computation_precidence_specifying_function, global_function\n",
    "\n",
    "from neuropy.utils.mixins.binning_helpers import transition_matrix\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import TransitionMatrixComputations\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates, get_proper_global_spikes_df\n",
    "\n",
    "from pyphocorehelpers.Filesystem.path_helpers import set_posix_windows\n",
    "\n",
    "from pyphocorehelpers.assertion_helpers import Assert\n",
    "\n",
    "# Plotting\n",
    "# import pylustrator # customization of figures\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "\n",
    "matplotlib.use('Qt5Agg')\n",
    "# %matplotlib inline\n",
    "# %matplotlib auto\n",
    "\n",
    "# _restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# import pylustrator # call `pylustrator.start()` before creating your first figure in code.\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap, visualize_heatmap_pyqtgraph # used in `plot_kourosh_activity_style_figure`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot, plot_raster_plot\n",
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import UnitColoringMode, DataSeriesColorHelpers\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import _build_default_tick, build_scatter_plot_kwargs\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.Render2DScrollWindowPlot import Render2DScrollWindowPlotMixin, ScatterItemData\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import BatchPlotting # BatchPlotting.batch_extended_programmatic_figures, BatchPlotting.batch_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "from pyphoplacecellanalysis.General.Mixins.SpikesRenderingBaseMixin import SpikeEmphasisState\n",
    "from pyphoplacecellanalysis.General.Model.SpecificComputationParameterTypes import ComputationKWargParameters\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PAPER_FIGURE_figure_1_add_replay_epoch_rasters, PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_3, main_complete_figure_generations\n",
    "# from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import *\n",
    "\n",
    "# Jupyter Widget Interactive\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import interactive_pipeline_widget, interactive_pipeline_files\n",
    "from pyphocorehelpers.gui.Jupyter.simple_widgets import fullwidth_path_widget, render_colors\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import PipelineJupyterHelpers, CustomProcessingPhases, PipelinePickleFileSelectorWidget\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.PhoContainerTool import GenericMatplotlibContainer, GenericPyQtGraphContainer, PhoBaseContainerTool\n",
    "\n",
    "from datetime import datetime, date, timedelta\n",
    "from pyphocorehelpers.print_helpers import get_now_day_str, get_now_rounded_time_str\n",
    "\n",
    "DAY_DATE_STR: str = date.today().strftime(\"%Y-%m-%d\")\n",
    "DAY_DATE_TO_USE = f'{DAY_DATE_STR}' # used for filenames throught the notebook\n",
    "print(f'DAY_DATE_STR: {DAY_DATE_STR}, DAY_DATE_TO_USE: {DAY_DATE_TO_USE}')\n",
    "\n",
    "NOW_DATETIME: str = get_now_rounded_time_str()\n",
    "NOW_DATETIME_TO_USE = f'{NOW_DATETIME}' # used for filenames throught the notebook\n",
    "print(f'NOW_DATETIME: {NOW_DATETIME}, NOW_DATETIME_TO_USE: {NOW_DATETIME_TO_USE}')\n",
    "\n",
    "def get_global_variable(var_name):\n",
    "    \"\"\" used by `PipelineJupyterHelpers._build_pipeline_custom_processing_mode_selector_widget(...)` to update the notebook's variables \"\"\"\n",
    "    return globals()[var_name]\n",
    "    \n",
    "def update_global_variable(var_name, value):\n",
    "    \"\"\" used by `PipelineJupyterHelpers._build_pipeline_custom_processing_mode_selector_widget(...)` to update the notebook's variables \"\"\"\n",
    "    globals()[var_name] = value\n",
    "\n",
    "from pyphocorehelpers.gui.Jupyter.simple_widgets import build_global_data_root_parent_path_selection_widget\n",
    "all_paths = [Path(r'/home/halechr/FastData'), Path('/Volumes/SwapSSD/Data'), Path('/Users/pho/data'), Path(r'/media/halechr/MAX/Data'), Path(r'W:\\Data'), Path(r'/home/halechr/cloud/turbo/Data'), Path(r'/Volumes/MoverNew/data'), Path(r'/home/halechr/turbo/Data'), Path(r'/Users/pho/cloud/turbo/Data')] # Path('/Volumes/FedoraSSD/FastData'), \n",
    "global_data_root_parent_path = None\n",
    "def on_user_update_path_selection(new_path: Path):\n",
    "    global global_data_root_parent_path\n",
    "    new_global_data_root_parent_path = new_path.resolve()\n",
    "    global_data_root_parent_path = new_global_data_root_parent_path\n",
    "    print(f'global_data_root_parent_path changed to {global_data_root_parent_path}')\n",
    "    assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "            \n",
    "global_data_root_parent_path_widget = build_global_data_root_parent_path_selection_widget(all_paths, on_user_update_path_selection)\n",
    "global_data_root_parent_path_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7502127c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.plotting.hairy_lines_plot import HairyLinePlot\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out = curr_active_pipeline.display(display_function='_display_decoded_trackID_marginal_hairy_position', active_session_configuration_context=None, include_includelist=[], save_figure=True) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e81646",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[0️⃣ Load Pipeline](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f07773d",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-0",
     "all",
     "run-group-0-interactive",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Load Data                                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "active_data_mode_name = 'kdiba'\n",
    "local_session_root_parent_context = IdentifyingContext(format_name=active_data_mode_name) # , animal_name='', configuration_name='one', session_name=a_sess.session_name\n",
    "local_session_root_parent_path = global_data_root_parent_path.joinpath('KDIBA')\n",
    "\n",
    "# [*] - indicates bad or session with a problem\n",
    "# 0, 1, 2, 3, 4, 5, 6, 7, [8], [9], 10, 11, [12], 13, 14, [15], [16], 17, \n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-07_11-26-53')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15') # Recomputed 2025-06-10 00:56\n",
    "curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43') # Recomputed for 2.0Hz, allACLUS 2025-07-17 07:25\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31') # Recomputed 2025-06-10 01:16 \n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19') # Recomputed 2025-06-10 01:56  -- notedy ylims shifted up by about half the track width\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46') # Recomputed 2025-06-10 02:27 -- HIGH ANTICIPATION\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30') ## BLOCKING ERROR with pf2D computation (empty) for 5Hz 2024-12-02 15:24 \n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50') # Recomputed 2025-06-10 02:40  -- Moderately HGIH ANTICIPATION\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54') # 2025-06-10 02:52 -- about 3 good replays\n",
    "## BAD # curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3') # Recomputed 2025-06-10 03:23 -- HIGH ANTICIPATION - BAD\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25') # Recomputed 2024-12-16 19:33 -- about 5 good replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54') # Recomputed 2024-12-16 19:36 -- TONS of good replays, 10+ pages of them \n",
    "\n",
    "local_session_parent_path: Path = local_session_root_parent_path.joinpath(curr_context.animal, curr_context.exper_name) # 'gor01', 'one' - probably not needed anymore\n",
    "basedir: Path = local_session_parent_path.joinpath(curr_context.session_name).resolve()\n",
    "print(f'basedir: {str(basedir)}')\n",
    "\n",
    "epoch_name_includelist = None\n",
    "active_computation_functions_name_includelist=['lap_direction_determination',\n",
    "                                                'pf_computation',\n",
    "                                                'pfdt_computation',\n",
    "                                                # 'firing_rate_trends',\n",
    "                                                # 'pf_dt_sequential_surprise', \n",
    "                                            #    'ratemap_peaks_prominence2d',\n",
    "                                                'position_decoding', \n",
    "                                                # 'position_decoding_two_step', #'directional_decoders_epoch_heuristic_scoring',\n",
    "                                            #    'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping',\n",
    "                                            #     'long_short_inst_spike_rate_groups',\n",
    "                                            #     'long_short_endcap_analysis',\n",
    "                                            \n",
    "]\n",
    "\n",
    "## 'split_to_directional_laps' -- is global\n",
    "\n",
    "\n",
    "\n",
    "# Read if possible:\n",
    "saving_mode = PipelineSavingScheme.SKIP_SAVING\n",
    "force_reload = False\n",
    "\n",
    "# # Force write:\n",
    "# saving_mode = PipelineSavingScheme.TEMP_THEN_OVERWRITE\n",
    "# # saving_mode = PipelineSavingScheme.OVERWRITE_IN_PLACE\n",
    "# force_reload = True\n",
    "\n",
    "selector, on_value_change = PipelineJupyterHelpers._build_pipeline_custom_processing_mode_selector_widget(update_global_variable_fn=update_global_variable, debug_print=False, enable_full_view=True)\n",
    "# selector.value = 'clean_run'\n",
    "selector.value = 'continued_run'\n",
    "# selector.value = 'final_run'\n",
    "on_value_change(dict(new=selector.value)) ## do update manually so the workspace variables reflect the set values\n",
    "## TODO: if loading is not possible, we need to change the `saving_mode` so that the new results are properly saved.\n",
    "print(f\"saving_mode: {saving_mode}, force_reload: {force_reload}\")\n",
    "\n",
    "extended_computations_include_includelist_phase_dict: Dict[str, CustomProcessingPhases] = CustomProcessingPhases.get_extended_computations_include_includelist_phase_dict()\n",
    "\n",
    "current_phase: CustomProcessingPhases = CustomProcessingPhases[selector.value]  # Assuming selector.value is an instance of CustomProcessingPhases\n",
    "extended_computations_include_includelist: List[str] = [key for key, value in extended_computations_include_includelist_phase_dict.items() if value <= current_phase]\n",
    "display(extended_computations_include_includelist)\n",
    "force_recompute_override_computations_includelist = None\n",
    "# force_recompute_override_computations_includelist = ['split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous'] # \n",
    "\n",
    "# ## INPUTS: basedir\n",
    "active_session_pickle_file_widget = PipelinePickleFileSelectorWidget(directory=basedir, on_update_global_variable_callback=update_global_variable, on_get_global_variable_callback=get_global_variable)\n",
    "\n",
    "_subfn_load, _subfn_save, _subfn_compute, _subfn_compute_new = active_session_pickle_file_widget._build_load_save_callbacks(global_data_root_parent_path=global_data_root_parent_path, active_data_mode_name=active_data_mode_name, basedir=basedir, saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                                             extended_computations_include_includelist=extended_computations_include_includelist, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist)\n",
    "\n",
    "## try selecting the first\n",
    "did_find_valid_selection: bool = active_session_pickle_file_widget.try_select_first_valid_files()\n",
    "\n",
    "# Display the widget\n",
    "active_session_pickle_file_widget.servable()\n",
    "# active_session_pickle_file_widget.try_select_first_valid_files()\n",
    "\n",
    "# OUTPUTS: active_session_pickle_file_widget, widget.active_local_pkl, widget.active_global_pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6e0657",
   "metadata": {
    "tags": [
     "run-group-0-interactive",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "if did_find_valid_selection:\n",
    "\t_subfn_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c038f64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_subfn_compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3776d302",
   "metadata": {},
   "outputs": [],
   "source": [
    "_subfn_compute_new()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabb8569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom_suffix: str = '_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0'\n",
    "\n",
    "minimum_inclusion_fr_Hz = active_session_pickle_file_widget.current_parameter_values['minimum_inclusion_fr_Hz']\n",
    "included_qclu_values = active_session_pickle_file_widget.current_parameter_values['included_qclu_values']\n",
    "\n",
    "included_qclu_values\n",
    "\n",
    "custom_suffix: str = f'_withNewComputedReplays-qclu_{included_qclu_values}-frateThresh_{minimum_inclusion_fr_Hz:2f}'\n",
    "custom_suffix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac6b6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set default local comp pkl:\n",
    "default_selected_local_file_name: str = 'loadedSessPickle.pkl'\n",
    "default_local_section_indicies = [active_session_pickle_file_widget.local_file_browser_widget._data['File Name'].tolist().index(default_selected_local_file_name)]\n",
    "active_session_pickle_file_widget.local_file_browser_widget.selection = default_local_section_indicies\n",
    "\n",
    "## Set default global computation pkl:\n",
    "default_selected_global_file_name: str = 'global_computation_results.pkl'\n",
    "default_global_section_indicies = [active_session_pickle_file_widget.global_file_browser_widget._data['File Name'].tolist().index(default_selected_global_file_name)]\n",
    "active_session_pickle_file_widget.global_file_browser_widget.selection = default_global_section_indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaac9d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.pickle_path\n",
    "# curr_active_pipeline.has_associated_pickle\n",
    "curr_active_pipeline.save_pipeline( "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c072a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.IPyWidgets.SaveAsWidget import PipelineBackupWidget\n",
    "\n",
    "backup_widget = PipelineBackupWidget(curr_active_pipeline)\n",
    "backup_widget.servable()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb1135e",
   "metadata": {},
   "source": [
    "## <a id='toc2_1_'></a>[2024-06-25 - Load from saved custom](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5515d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline, custom_suffix, proposed_load_pkl_path = active_session_pickle_file_widget.on_load_local(global_data_root_parent_path=global_data_root_parent_path, active_data_mode_name=active_data_mode_name, basedir=basedir, saving_mode=saving_mode, force_reload=force_reload)\n",
    "curr_active_pipeline = active_session_pickle_file_widget.on_load_global(curr_active_pipeline=curr_active_pipeline, basedir=basedir, extended_computations_include_includelist=extended_computations_include_includelist, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist,\n",
    "                                       skip_global_load=False, force_reload=False, override_global_computation_results_pickle_path=active_session_pickle_file_widget.active_global_pkl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9337ddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads custom pipeline pickles that were saved out via `custom_save_filepaths['pipeline_pkl'] = curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE, active_pickle_filename=custom_save_filenames['pipeline_pkl'])`\n",
    "\n",
    "## INPUTS: global_data_root_parent_path, active_data_mode_name, basedir, saving_mode, force_reload, custom_save_filenames\n",
    "# custom_suffix: str = '_withNewKamranExportedReplays'\n",
    "\n",
    "# custom_suffix: str = '_withNewComputedReplays'\n",
    "# custom_suffix: str = '_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0'\n",
    "\n",
    "# custom_save_filenames = {\n",
    "#     'pipeline_pkl':f'loadedSessPickle{custom_suffix}.pkl',\n",
    "#     'global_computation_pkl':f\"global_computation_results{custom_suffix}.pkl\",\n",
    "#     'pipeline_h5':f'pipeline{custom_suffix}.h5',\n",
    "# }\n",
    "# print(f'custom_save_filenames: {custom_save_filenames}')\n",
    "# custom_save_filepaths = {k:v for k, v in custom_save_filenames.items()}\n",
    "\n",
    "# # ==================================================================================================================== #\n",
    "# # PIPELINE LOADING                                                                                                     #\n",
    "# # ==================================================================================================================== #\n",
    "# # load the custom saved outputs\n",
    "# active_pickle_filename = custom_save_filenames['pipeline_pkl'] # 'loadedSessPickle_withParameters.pkl'\n",
    "# print(f'active_pickle_filename: \"{active_pickle_filename}\"')\n",
    "# # assert active_pickle_filename.exists()\n",
    "# active_session_h5_filename = custom_save_filenames['pipeline_h5'] # 'pipeline_withParameters.h5'\n",
    "# print(f'active_session_h5_filename: \"{active_session_h5_filename}\"')\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "## DO NOT allow recompute if the file doesn't exist!!\n",
    "# Computing loaded session pickle file results : \"W:/Data/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle_withNewComputedReplays.pkl\"... done.\n",
    "# Failure loading W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\loadedSessPickle_withNewComputedReplays.pkl.\n",
    "# proposed_load_pkl_path = basedir.joinpath(active_pickle_filename).resolve()\n",
    "\n",
    "## INPUTS: widget.active_global_pkl, widget.active_global_pkl\n",
    "\n",
    "if active_session_pickle_file_widget.active_global_pkl is None:\n",
    "    skip_global_load: bool = True\n",
    "    override_global_computation_results_pickle_path = None\n",
    "else:\n",
    "    skip_global_load: bool = False\n",
    "    override_global_computation_results_pickle_path = active_session_pickle_file_widget.active_global_pkl.resolve()\n",
    "    Assert.path_exists(override_global_computation_results_pickle_path)\n",
    "    override_global_computation_results_pickle_path\n",
    "\n",
    "\n",
    "proposed_load_pkl_path = active_session_pickle_file_widget.active_local_pkl.resolve()\n",
    "Assert.path_exists(proposed_load_pkl_path)\n",
    "proposed_load_pkl_path\n",
    "\n",
    "custom_suffix: str = active_session_pickle_file_widget.try_extract_custom_suffix()\n",
    "print(f'custom_suffix: \"{custom_suffix}\"')\n",
    "\n",
    "## OUTPUTS: custom_suffix, proposed_load_pkl_path, (override_global_computation_results_pickle_path, skip_global_load)\n",
    "from pyphocorehelpers.Filesystem.path_helpers import set_posix_windows\n",
    "## INPUTS: proposed_load_pkl_path\n",
    "assert proposed_load_pkl_path.exists(), f\"for a saved custom the file must exist!\"\n",
    "\n",
    "epoch_name_includelist=None\n",
    "active_computation_functions_name_includelist=['lap_direction_determination', 'pf_computation','firing_rate_trends', 'position_decoding']\n",
    "\n",
    "with set_posix_windows():\n",
    "    curr_active_pipeline: NeuropyPipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_includelist=epoch_name_includelist,\n",
    "                                            computation_functions_name_includelist=active_computation_functions_name_includelist,\n",
    "                                            saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                            skip_extended_batch_computations=True, debug_print=False, fail_on_exception=True, active_pickle_filename=proposed_load_pkl_path) # , active_pickle_filename = 'loadedSessPickle_withParameters.pkl'\n",
    "\n",
    "## Post Compute Validate 2023-05-16:\n",
    "was_updated = BatchSessionCompletionHandler.post_compute_validate(curr_active_pipeline) ## TODO: need to potentially re-save if was_updated. This will fail because constained versions not ran yet.\n",
    "if was_updated:\n",
    "    print(f'was_updated: {was_updated}')\n",
    "    try:\n",
    "        if saving_mode == PipelineSavingScheme.SKIP_SAVING:\n",
    "            print(f'WARNING: PipelineSavingScheme.SKIP_SAVING but need to save post_compute_validate changes!!')\n",
    "        else:\n",
    "            curr_active_pipeline.save_pipeline(saving_mode=saving_mode)\n",
    "    except Exception as e:\n",
    "        ## TODO: catch/log saving error and indicate that it isn't saved.\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'ERROR RE-SAVING PIPELINE after update. error: {e}')\n",
    "\n",
    "print(f'Pipeline loaded from custom pickle!!')\n",
    "## OUTPUT: curr_active_pipeline\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Global computations loading:                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "# Loads saved global computations that were saved out via: `custom_save_filepaths['global_computation_pkl'] = curr_active_pipeline.save_global_computation_results(override_global_pickle_filename=custom_save_filenames['global_computation_pkl'])`\n",
    "## INPUTS: custom_save_filenames\n",
    "## INPUTS: curr_active_pipeline, override_global_computation_results_pickle_path, extended_computations_include_includelist\n",
    "\n",
    "override_global_computation_results_pickle_path = None\n",
    "# override_global_computation_results_pickle_path = custom_save_filenames['global_computation_pkl']\n",
    "print(f'override_global_computation_results_pickle_path: \"{override_global_computation_results_pickle_path}\"')\n",
    "\n",
    "# Pre-load ___________________________________________________________________________________________________________ #\n",
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Pre-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "# valid_computed_results_output_list\n",
    "\n",
    "# Try Unpickling Global Computations to update pipeline ______________________________________________________________ #\n",
    "if (not force_reload) and (not skip_global_load): # not just force_reload, needs to recompute whenever the computation fails.\n",
    "    try:\n",
    "        # INPUTS: override_global_computation_results_pickle_path\n",
    "        with set_posix_windows():\n",
    "            sucessfully_updated_keys, successfully_loaded_keys = curr_active_pipeline.load_pickled_global_computation_results(override_global_computation_results_pickle_path=override_global_computation_results_pickle_path,\n",
    "                                                                                            allow_overwrite_existing=True, allow_overwrite_existing_allow_keys=extended_computations_include_includelist, ) # is new\n",
    "            print(f'sucessfully_updated_keys: {sucessfully_updated_keys}\\nsuccessfully_loaded_keys: {successfully_loaded_keys}')\n",
    "            did_any_paths_change: bool = curr_active_pipeline.post_load_fixup_sess_basedirs(updated_session_basepath=deepcopy(basedir)) ## use INPUT: basedir\n",
    "            \n",
    "    except FileNotFoundError as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'cannot load global results because pickle file does not exist! Maybe it has never been created? {e}')\n",
    "    except Exception as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'Unhandled exception: cannot load global results: {e}')\n",
    "        raise\n",
    "\n",
    "# Post-Load __________________________________________________________________________________________________________ #\n",
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "\n",
    "\n",
    "\n",
    "## fixup missing paths\n",
    "# self.basepath: WindowsPath('/nfs/turbo/umms-kdiba/KDIBA/gor01/one/2006-6-09_1-22-43')\n",
    "\n",
    "## INPUTS: basedir\n",
    "did_any_paths_change: bool = curr_active_pipeline.post_load_fixup_sess_basedirs(updated_session_basepath=deepcopy(basedir)) ## use INPUT: basedir\n",
    "\n",
    "# Compute ____________________________________________________________________________________________________________ #\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "force_recompute_global = force_reload\n",
    "# force_recompute_global = True\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "if (len(newly_computed_values) > 0):\n",
    "    print(f'newly_computed_values: {newly_computed_values}.')\n",
    "    if (saving_mode.value != 'skip_saving'):\n",
    "        print(f'Saving global results...')\n",
    "        try:\n",
    "            # curr_active_pipeline.global_computation_results.persist_time = datetime.now()\n",
    "            # Try to write out the global computation function results:\n",
    "            curr_active_pipeline.save_global_computation_results()\n",
    "        except Exception as e:\n",
    "            exception_info = sys.exc_info()\n",
    "            e = CapturedException(e, exception_info)\n",
    "            print(f'\\n\\n!!WARNING!!: saving the global results threw the exception: {e}')\n",
    "            print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "    else:\n",
    "        print(f'\\n\\n!!WARNING!!: changes to global results have been made but they will not be saved since saving_mode.value == \"skip_saving\"')\n",
    "        print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "else:\n",
    "    print(f'no changes in global results.')\n",
    "\n",
    "# Post-compute _______________________________________________________________________________________________________ #\n",
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=False, force_recompute_override_computations_includelist=[], debug_print=True)\n",
    "print(f'Post-compute validation: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "\n",
    "# Post-Load __________________________________________________________________________________________________________ #\n",
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "\n",
    "print(f'force_reload: {force_reload}, saving_mode: {saving_mode}')\n",
    "force_reload\n",
    "saving_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f813f01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## indicate that it was loaded with a custom suffix\n",
    "curr_active_pipeline.pickle_path ## correct\n",
    "curr_active_pipeline.global_computation_results_pickle_path ## correct\n",
    "\n",
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE, override_pickle_path=curr_active_pipeline.pickle_path, active_pickle_filename=curr_active_pipeline.pickle_path.name) #active_pickle_filename=\n",
    "curr_active_pipeline.save_global_computation_results(override_global_pickle_path=curr_active_pipeline.global_computation_results_pickle_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49de9fb9",
   "metadata": {},
   "source": [
    "## 0️⃣💾 Save Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba28da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_selected_local_file_name: str = 'loadedSessPickle.pkl'\n",
    "# if curr_active_pipeline.pickle_path is None:\n",
    "#     curr_active_pipeline.pickle_path = Path('W:/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/loadedSessPickle.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89fe1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## indicate that it was loaded with a custom suffix\n",
    "curr_active_pipeline.pickle_path ## correct\n",
    "curr_active_pipeline.global_computation_results_pickle_path ## correct\n",
    "\n",
    "if curr_active_pipeline.pickle_path is None:\n",
    "    active_pickle_filename = 'loadedSessPickle.pkl'\n",
    "else:\n",
    "    active_pickle_filename = curr_active_pipeline.pickle_path.name\n",
    "    \n",
    "print(f'active_pickle_filename: {active_pickle_filename}')\n",
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE, override_pickle_path=curr_active_pipeline.pickle_path, active_pickle_filename=active_pickle_filename) #active_pickle_filename=\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ca7575",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_global_computation_results(override_global_pickle_path=curr_active_pipeline.global_computation_results_pickle_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89e138b",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_save_folder, split_save_paths, split_save_output_types, failed_keys = curr_active_pipeline.save_split_global_computation_results(override_global_pickle_path=curr_active_pipeline.global_computation_results_pickle_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af499f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Easily serialize in a portable way\n",
    "curr_active_pipeline.save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9ba82e",
   "metadata": {},
   "source": [
    "## <a id='toc2_3_'></a>[0️⃣ Normal Pipeline Load](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8167df1c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-0",
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-full_session_LOO_decoding_analysis.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "# epoch_name_includelist = ['maze']\n",
    "\n",
    "curr_active_pipeline: NeuropyPipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_includelist=epoch_name_includelist,\n",
    "                                        computation_functions_name_includelist=active_computation_functions_name_includelist,\n",
    "                                        saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                        skip_extended_batch_computations=True, debug_print=True, fail_on_exception=False) #, time_bin_size = 0.025 time_bin_size = 0.058, override_parameters_flat_keypaths_dict = dict(), \n",
    "# , active_pickle_filename = 'loadedSessPickle_withParameters.pkl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b125667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.get_failed_computations()\n",
    "curr_active_pipeline.clear_all_failed_computations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76c7dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# {'maze1_odd': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze2_odd': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze_odd': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze1_even': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze2_even': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze_even': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze1_any': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze2_any': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze_any': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')}}\n",
    "\n",
    "_out = curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_split_to_directional_laps'], fail_on_exception=True, debug_print=True)\n",
    "\n",
    "\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_split_to_directional_laps'], computation_kwargs_list=[{}], \n",
    "#                                                   enabled_filter_names=None, fail_on_exception=True, debug_print=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8edcd94",
   "metadata": {
    "tags": [
     "run-group-0"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "## Post Compute Validate 2023-05-16:\n",
    "# was_updated = BatchSessionCompletionHandler.post_compute_validate(curr_active_pipeline) ## TODO: need to potentially re-save if was_updated. This will fail because constained versions not ran yet.\n",
    "was_updated = False\n",
    "if was_updated:\n",
    "    print(f'was_updated: {was_updated}')\n",
    "    try:\n",
    "        curr_active_pipeline.save_pipeline(saving_mode=saving_mode)\n",
    "    except Exception as e:\n",
    "        ## TODO: catch/log saving error and indicate that it isn't saved.\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'ERROR RE-SAVING PIPELINE after update. error: {e}')\n",
    "\n",
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Pre-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "# valid_computed_results_output_list\n",
    "if not force_reload: # not just force_reload, needs to recompute whenever the computation fails.\n",
    "    try:\n",
    "        # curr_active_pipeline.load_pickled_global_computation_results()\n",
    "        with set_posix_windows():\n",
    "            sucessfully_updated_keys, successfully_loaded_keys = curr_active_pipeline.load_pickled_global_computation_results(allow_overwrite_existing=True, allow_overwrite_existing_allow_keys=extended_computations_include_includelist) # is new\n",
    "            \n",
    "        print(f'sucessfully_updated_keys: {sucessfully_updated_keys}\\nsuccessfully_loaded_keys: {successfully_loaded_keys}')\n",
    "    except FileNotFoundError as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'cannot load global results because pickle file does not exist! Maybe it has never been created? {e}')\n",
    "    except Exception as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'Unhandled exception: cannot load global results: {e}')\n",
    "        raise\n",
    "\n",
    "# Recomputing active_epoch_placefields... \t done.\n",
    "# Recomputing active_epoch_placefields2D... \t done.\n",
    "# WARN: f\"len(self.is_non_firing_time_bin): 30459, self.num_time_windows: 30762\", trying to recompute them....\n",
    "# UNHANDLED EXCEPTION: Unable to allocate 3.46 GiB for an array with shape (15124, 30724) and data type float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9809aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.accumulated_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcac55a8",
   "metadata": {
    "tags": [
     "run-group-0",
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "force_recompute_global = force_reload # Post-load global computations: needs_computation_output_dict: ['rank_order_shuffle_analysis', 'directional_train_test_split', 'short_long_pf_overlap_analyses', 'wcorr_shuffle_analysis', 'extended_pf_peak_information', 'position_decoding_two_step']\n",
    "# force_recompute_global = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4321d2fc",
   "metadata": {
    "tags": [
     "run-group-0"
    ]
   },
   "outputs": [],
   "source": [
    "fail_on_exception = False\n",
    "\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=fail_on_exception, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "if (len(newly_computed_values) > 0):\n",
    "    print(f'newly_computed_values: {newly_computed_values}.')\n",
    "    if (saving_mode.value != 'skip_saving'):\n",
    "        print(f'Saving global results...')\n",
    "        try:\n",
    "            # curr_active_pipeline.global_computation_results.persist_time = datetime.now()\n",
    "            # Try to write out the global computation function results:\n",
    "            curr_active_pipeline.save_global_computation_results()\n",
    "        except Exception as e:\n",
    "            exception_info = sys.exc_info()\n",
    "            e = CapturedException(e, exception_info)\n",
    "            print(f'\\n\\n!!WARNING!!: saving the global results threw the exception: {e}')\n",
    "            print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "    else:\n",
    "        print(f'\\n\\n!!WARNING!!: changes to global results have been made but they will not be saved since saving_mode.value == \"skip_saving\"')\n",
    "        print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "else:\n",
    "    print(f'no changes in global results.')\n",
    "\n",
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=fail_on_exception, progress_print=True,\n",
    "                                                    force_recompute=False, force_recompute_override_computations_includelist=[], debug_print=True)\n",
    "print(f'Post-compute validation: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615018da",
   "metadata": {},
   "source": [
    "## <a id='toc2_4_'></a>[0️⃣ Shared Post-Pipeline load stuff](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c842f5e4",
   "metadata": {
    "tags": [
     "run-group-0-interactive",
     "run-2025-04-11_full-session_marginals",
     "run-group-0"
    ]
   },
   "outputs": [],
   "source": [
    "# BATCH_DATE_TO_USE: str = f'{DAY_DATE_TO_USE}_GL'\n",
    "# BATCH_DATE_TO_USE: str = f'{DAY_DATE_TO_USE}_rMBP' # TODO: Change this as needed, templating isn't actually doing anything rn.\n",
    "BATCH_DATE_TO_USE: str = f'{DAY_DATE_TO_USE}_Apogee'\n",
    "# BATCH_DATE_TO_USE: str = f'{DAY_DATE_TO_USE}_Lab'\n",
    " \n",
    "try:\n",
    "    if custom_suffix is not None:\n",
    "        BATCH_DATE_TO_USE = f'{BATCH_DATE_TO_USE}{custom_suffix}'\n",
    "        print(f'Adding custom suffix: \"{custom_suffix}\" - BATCH_DATE_TO_USE: \"{BATCH_DATE_TO_USE}\"')\n",
    "except NameError as err:\n",
    "    custom_suffix = None\n",
    "    print(f'NO CUSTOM SUFFIX.')\n",
    "\n",
    "known_collected_output_paths = [Path(v).resolve() for v in ['/nfs/turbo/umms-kdiba/Data/Output/collected_outputs', '/home/halechr/FastData/collected_outputs/',\n",
    "                                                           '/home/halechr/cloud/turbo/Data/Output/collected_outputs',\n",
    "                                                           r'C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\output\\collected_outputs',\n",
    "                                                           r\"K:\\scratch\\collected_outputs\",\n",
    "                                                           '/Users/pho/data/collected_outputs',\n",
    "                                                          'output/gen_scripts/']]\n",
    "collected_outputs_path = find_first_extant_path(known_collected_output_paths)\n",
    "assert collected_outputs_path.exists(), f\"collected_outputs_path: {collected_outputs_path} does not exist! Is the right computer's config commented out above?\"\n",
    "# fullwidth_path_widget(scripts_output_path, file_name_label='Scripts Output Path:')\n",
    "print(f'collected_outputs_path: {collected_outputs_path}')\n",
    "# collected_outputs_path.mkdir(exist_ok=True)\n",
    "# assert collected_outputs_path.exists()\n",
    "\n",
    "## Build the output prefix from the session context:\n",
    "active_context = curr_active_pipeline.get_session_context()\n",
    "curr_session_name: str = curr_active_pipeline.session_name # '2006-6-08_14-26-15'\n",
    "CURR_BATCH_OUTPUT_PREFIX: str = f\"{BATCH_DATE_TO_USE}-{curr_session_name}\"\n",
    "print(f'CURR_BATCH_OUTPUT_PREFIX: \"{CURR_BATCH_OUTPUT_PREFIX}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606e8116",
   "metadata": {},
   "source": [
    "## <a id='toc2_5_'></a>[Specific Recomputations](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f010d1a9",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "any_most_recent_computation_time, each_epoch_latest_computation_time, each_epoch_each_result_computation_completion_times, (global_computations_latest_computation_time, global_computation_completion_times) = curr_active_pipeline.get_computation_times(debug_print=False)\n",
    "# each_epoch_latest_computation_time\n",
    "each_epoch_each_result_computation_completion_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3d4f61",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd11d0f",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.clear_all_failed_computations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ff30b7",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computation_config.instantaneous_time_bin_size_seconds = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3046503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import InstantaneousSpikeRateGroupsComputation\n",
    "\n",
    "# Example usage of the complete round-trip functionality:\n",
    "\n",
    "# 1. Create and compute the original object\n",
    "# inst_fr_comp = InstantaneousSpikeRateGroupsComputation(instantaneous_time_bin_size_seconds=0.02) # 20ms bins\n",
    "# inst_fr_comp = InstantaneousSpikeRateGroupsComputation(instantaneous_time_bin_size_seconds=0.001) # 1ms bins\n",
    "inst_fr_comp = InstantaneousSpikeRateGroupsComputation(instantaneous_time_bin_size_seconds=1000.0) # 1sec bins\n",
    "inst_fr_comp.compute(curr_active_pipeline=curr_active_pipeline)\n",
    "\n",
    "# 2. Get comprehensive DataFrame\n",
    "across_session_inst_fr_computation_df: pd.DataFrame = inst_fr_comp.get_comprehensive_dataframe()\n",
    "print(f\"DataFrame shape: {across_session_inst_fr_computation_df.shape}\")\n",
    "print(f\"Columns: {across_session_inst_fr_computation_df.columns.tolist()}\")\n",
    "across_session_inst_fr_computation_df\n",
    "\n",
    "across_session_inst_fr_summary_df: pd.DataFrame = inst_fr_comp.get_summary_dataframe()\n",
    "across_session_inst_fr_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc5c098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inst_fr_comp_1ms = deepcopy(inst_fr_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1d308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inst_fr_comp_1ms = InstantaneousSpikeRateGroupsComputation(instantaneous_time_bin_size_seconds=0.001) # 1ms bins\n",
    "inst_fr_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a24a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_fr_comp.LxC_ReplayDeltaPlus.inst_fr_df_list # epoch_agg_inst_fr_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed50c9d0",
   "metadata": {},
   "source": [
    "#### Base Sampling Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4b5302",
   "metadata": {},
   "outputs": [],
   "source": [
    "across_session_inst_fr_computation_df\n",
    "\n",
    "across_session_inst_fr_summary_df: pd.DataFrame = inst_fr_comp.get_summary_dataframe()\n",
    "across_session_inst_fr_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e434077b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1715cf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsVisualizations\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PaperFigureTwo\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import InstantaneousFiringRatesDataframeAccessor\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import SingleBarResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import InstantaneousSpikeRateGroupsComputation\n",
    "\n",
    "across_session_inst_fr_summary_df = inst_fr_comp.get_summary_dataframe()\n",
    "\n",
    "# num_sessions: int = across_session_inst_fr_computation_df['session_uid'].nunique(dropna=True)\n",
    "across_session_inst_fr_computation_shell_obj, visualization_df = InstantaneousFiringRatesDataframeAccessor.build_shell_object_for_plot(loaded_result_df=across_session_inst_fr_summary_df)\n",
    "# Perform the actual plotting:\n",
    "fig2_ctxt, fig2, _fig_2_output_dict = AcrossSessionsVisualizations.across_sessions_bar_graphs(across_session_inst_fr_computation_shell_obj, num_sessions=1, save_figure=False, enable_tiny_point_labels=False, enable_hover_labels=False, write_vector_format=False, prepare_for_publication=False) # fig2_export_folder\n",
    "fig2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05e9bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(comprehensive_df.columns)) # ['aclu', 'neuron_type', 'cell_index_in_type', 'instantaneous_time_bin_size_seconds', 'session_format_name', 'session_animal', 'session_exper_name', 'session_session_name', 'replay_delta_minus_pop_mean', 'replay_delta_minus_pop_std', 'replay_delta_minus_pop_n_cells', 'replay_delta_plus_pop_mean', 'replay_delta_plus_pop_std', 'replay_delta_plus_pop_n_cells', 'theta_delta_minus_pop_mean', 'theta_delta_minus_pop_std', 'theta_delta_minus_pop_n_cells', 'theta_delta_plus_pop_mean', 'theta_delta_plus_pop_std', 'theta_delta_plus_pop_n_cells', 'replay_delta_minus_firing_rate', 'replay_delta_plus_firing_rate', 'theta_delta_minus_firing_rate', 'theta_delta_plus_firing_rate', 'LxC_ReplayDeltaMinus_summary_mean', 'LxC_ReplayDeltaMinus_summary_std', 'LxC_ReplayDeltaPlus_summary_mean', 'LxC_ReplayDeltaPlus_summary_std', 'SxC_ReplayDeltaMinus_summary_mean', 'SxC_ReplayDeltaMinus_summary_std', 'SxC_ReplayDeltaPlus_summary_mean', 'SxC_ReplayDeltaPlus_summary_std', 'LxC_ThetaDeltaMinus_summary_mean', 'LxC_ThetaDeltaMinus_summary_std', 'LxC_ThetaDeltaPlus_summary_mean', 'LxC_ThetaDeltaPlus_summary_std', 'SxC_ThetaDeltaMinus_summary_mean', 'SxC_ThetaDeltaMinus_summary_std', 'SxC_ThetaDeltaPlus_summary_mean', 'SxC_ThetaDeltaPlus_summary_std', 'format_name', 'animal', 'exper_name', 'session_name', 'session_uid', 'neuron_uid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cb8a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_fr_comp.AnyC_aclus # (66, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12962971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inst_fr_comp.AnyC_ThetaDeltaMinus.spike_counts_df_list\n",
    "\n",
    "inst_fr_comp.AnyC_ThetaDeltaMinus.epoch_unit_fr_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9df903",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_LS_eXclusivity_threshold: bool = 0.85\n",
    "\n",
    "# inst_fr_comp.AnyC_ThetaDeltaPlus.epoch_unit_fr_df_list\n",
    "# pre_post_delta_ResultSets = (inst_fr_comp.AnyC_ThetaDeltaMinus, inst_fr_comp.AnyC_ThetaDeltaPlus)\n",
    "# for a_pre_post_delta_result in pre_post_delta_ResultSets:\n",
    "#     total_spikes_per_unit = pd.concat(inst_fr_comp.AnyC_ThetaDeltaPlus.spike_counts_df_list, axis='index', ignore_index=True).sum(axis=0) ## one for each cell\n",
    "    \n",
    "pre_total_spikes_per_unit = pd.concat(inst_fr_comp.AnyC_ThetaDeltaMinus.spike_counts_df_list, axis='index', ignore_index=True).sum(axis=0) ## one for each cell\n",
    "post_total_spikes_per_unit = pd.concat(inst_fr_comp.AnyC_ThetaDeltaPlus.spike_counts_df_list, axis='index', ignore_index=True).sum(axis=0) ## one for each cell\n",
    "total_both = pre_total_spikes_per_unit + post_total_spikes_per_unit\n",
    "pre_post_diff = post_total_spikes_per_unit - pre_total_spikes_per_unit\n",
    "# pre_post_diff\n",
    "\n",
    "pct_long = (pre_total_spikes_per_unit / total_both)\n",
    "pct_short = (post_total_spikes_per_unit / total_both)\n",
    "\n",
    "is_cell_n_spikes_LxC = (pct_long >= cell_LS_eXclusivity_threshold)\n",
    "pct_long.index.to_numpy()[is_cell_n_spikes_LxC]\n",
    "\n",
    "is_cell_n_spikes_SxC = (pct_short >= cell_LS_eXclusivity_threshold)\n",
    "pct_long.index.to_numpy()[is_cell_n_spikes_SxC]\n",
    "\n",
    "# pct_long\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016b5cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_fr_comp.LxC_ThetaDeltaMinus.spike_counts_df_list\n",
    "# inst_fr_comp.LxC_ThetaDeltaMinus.epoch_unit_fr_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edaafd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_fr_comp.LxC_ReplayDeltaMinus.inst_fr_df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72000ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'theta_delta_minus_firing_rate', 'theta_delta_plus_firing_rate'\n",
    "\n",
    "for a_period_name in ['theta', 'replay']:\n",
    "    comprehensive_df[f'{a_period_name}_delta_diff_pop_mean'] = comprehensive_df[f'{a_period_name}_delta_plus_pop_mean'] - comprehensive_df[f'{a_period_name}_delta_minus_pop_mean']\n",
    "    comprehensive_df[f'{a_period_name}_delta_diff_firing_rate'] = comprehensive_df[f'{a_period_name}_delta_plus_firing_rate'] - comprehensive_df[f'{a_period_name}_delta_minus_firing_rate']\n",
    "    comprehensive_df[f'{a_period_name}_delta_diff_firing_rate'] = comprehensive_df[f'{a_period_name}_delta_plus_firing_rate'] - comprehensive_df[f'{a_period_name}_delta_minus_firing_rate']\n",
    "\n",
    "comprehensive_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f4ac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehensive_df[comprehensive_df.duplicated(subset=['aclu'], keep='last')]\n",
    "\n",
    "# df = df.drop_duplicates(subset=['aclu'], keep='last', ignore_index=True, inplace=False) ## drop any duplicate aclus, keep the last (AnyC version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d042f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_fr_comp.AnyC_ThetaDeltaMinus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b124cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import InstantaneousSpikeRateGroupsComputation\n",
    "\n",
    "# # 3. Test round-trip conversion\n",
    "# is_roundtrip_successful = inst_fr_comp.test_round_trip()\n",
    "# print(f\"Round-trip successful: {is_roundtrip_successful}\")\n",
    "\n",
    "# # 4. Save to file\n",
    "# inst_fr_comp.save_comprehensive_dataframe('data.parquet', format='parquet')\n",
    "\n",
    "# # 5. Load from file and reconstruct object\n",
    "# reconstructed_comp = InstantaneousSpikeRateGroupsComputation.load_from_comprehensive_dataframe(\n",
    "#     'data.parquet', format='parquet'\n",
    "# )\n",
    "\n",
    "# # 6. Validate the DataFrame\n",
    "# validation_result = inst_fr_comp.validate_comprehensive_dataframe()\n",
    "# print(f\"Validation result: {validation_result}\")\n",
    "\n",
    "# # 7. Get summary information\n",
    "# summary = inst_fr_comp.get_dataframe_summary()\n",
    "# print(f\"DataFrame summary: {summary}\")\n",
    "\n",
    "# 8. Direct reconstruction from DataFrame\n",
    "df = inst_fr_comp.get_comprehensive_dataframe()\n",
    "reconstructed_comp2 = InstantaneousSpikeRateGroupsComputation.from_comprehensive_dataframe(df)\n",
    "\n",
    "# 9. Compare original and reconstructed objects\n",
    "print(f\"LxC aclus match: {np.array_equal(inst_fr_comp.LxC_aclus, reconstructed_comp2.LxC_aclus)}\")\n",
    "print(f\"SxC aclus match: {np.array_equal(inst_fr_comp.SxC_aclus, reconstructed_comp2.SxC_aclus)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58db94e",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "force_recompute_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f285cd23",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "force_recompute_global = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47820977",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "extended_computations_include_includelist=['lap_direction_determination', 'pf_computation', 'firing_rate_trends', 'pfdt_computation',\n",
    "    # 'pf_dt_sequential_surprise',\n",
    "    #  'ratemap_peaks_prominence2d',\n",
    "    'extended_stats',\n",
    "    'long_short_decoding_analyses',\n",
    "    'jonathan_firing_rate_analysis',\n",
    "    'long_short_fr_indicies_analyses',\n",
    "    'short_long_pf_overlap_analyses',\n",
    "    'long_short_post_decoding',\n",
    "    # 'long_short_rate_remapping',\n",
    "    'long_short_inst_spike_rate_groups',\n",
    "    'long_short_endcap_analysis',\n",
    "    # 'spike_burst_detection',\n",
    "    'split_to_directional_laps',\n",
    "    'merged_directional_placefields',\n",
    "    'rank_order_shuffle_analysis',\n",
    "    'directional_decoders_decode_continuous',\n",
    "    'directional_decoders_evaluate_epochs',\n",
    "    'directional_decoders_epoch_heuristic_scoring',\n",
    "] # do only specified\n",
    "\n",
    "# ['split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous']\n",
    "\n",
    "# force_recompute_override_computations_includelist = [\n",
    "#     'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring',\n",
    "#     'split_to_directional_laps', 'lap_direction_determination', 'DirectionalLaps',\n",
    "#     'merged_directional_placefields',\n",
    "#     'directional_decoders_decode_continuous',\n",
    "# ]\n",
    "force_recompute_override_computations_includelist = None\n",
    "\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "newly_computed_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc0a702",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# extended_computations_include_includelist=['ratemap_peaks_prominence2d', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring',] # do only specified\n",
    "extended_computations_include_includelist=['rank_order_shuffle_analysis', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs' ] # do only specified\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db62d145",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "newly_computed_values = curr_active_pipeline.batch_extended_computations(include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = curr_active_pipeline.batch_evaluate_required_computations(include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02779f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27120a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "newly_computed_values = curr_active_pipeline.batch_extended_computations(include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3927a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = curr_active_pipeline.batch_evaluate_required_computations(include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8b307a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d357f9",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# mmm ## lots of m's to break computations\n",
    "\n",
    "## Next wave of computations\n",
    "extended_computations_include_includelist=['directional_decoders_epoch_heuristic_scoring',] # do only specified\n",
    "force_recompute_override_computations_includelist = deepcopy(extended_computations_include_includelist)\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617dbaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mmm ## lots of m's to break computations\n",
    "\n",
    "## Next wave of computations\n",
    "extended_computations_include_includelist=['rank_order_shuffle_analysis',] # do only specified\n",
    "force_recompute_override_computations_includelist = deepcopy(extended_computations_include_includelist)\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8184bc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_dropped_keys, local_dropped_keys = curr_active_pipeline.perform_drop_computed_result(computed_data_keys_to_drop = ['DirectionalLaps', 'DirectionalDecodersDecoded'], debug_print=True) ## would like it to drop all downstream dependent computations as well\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3efc4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'lap_direction_determination'\n",
    "extended_computations_include_includelist=['_split_to_directional_laps'] # do only specified\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=True)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_split_to_directional_laps'], computation_kwargs_list=None, enabled_filter_names=None, fail_on_exception=True, debug_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d34cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.find_downstream_dependencies(provided_global_keys=['DirectionalLaps'], debug_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d834f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "curr_active_pipeline.get_failed_computations() # 'maze1_odd': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:973<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')}\n",
    "\n",
    "# curr_active_pipeline.rerun_failed_computations()\n",
    "# curr_active_pipeline.stage.rerun_failed_computations()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e982eb",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[0️⃣ Pho Interactive Pipeline Jupyter Widget](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce08192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import interactive_pipeline_widget, interactive_pipeline_files\n",
    "\n",
    "_pipeline_jupyter_widget = interactive_pipeline_widget(curr_active_pipeline=curr_active_pipeline)\n",
    "# display(_pipeline_jupyter_widget)\n",
    "_pipeline_jupyter_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474f4c95",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[1️⃣ End Run](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a533ba8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T23:21:40.700275900Z",
     "start_time": "2023-11-16T23:21:40.584273Z"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "# (long_one_step_decoder_1D, short_one_step_decoder_1D), (long_one_step_decoder_2D, short_one_step_decoder_2D) = compute_short_long_constrained_decoders(curr_active_pipeline, recalculate_anyway=True)\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_epoch_context, short_epoch_context, global_epoch_context = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_epoch_name, short_epoch_name, global_epoch_name)]\n",
    "long_epoch_obj, short_epoch_obj = [Epoch(curr_active_pipeline.sess.epochs.to_dataframe().epochs.label_slice(an_epoch_name.removesuffix('_any'))) for an_epoch_name in [long_epoch_name, short_epoch_name]] #TODO 2023-11-10 20:41: - [ ] Issue with getting actual Epochs from sess.epochs for directional laps: emerges because long_epoch_name: 'maze1_any' and the actual epoch label in curr_active_pipeline.sess.epochs is 'maze1' without the '_any' part.\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_computation_config, short_computation_config, global_computation_config = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "long_pf2D, short_pf2D, global_pf2D = long_results.pf2D, short_results.pf2D, global_results.pf2D\n",
    "\n",
    "assert short_epoch_obj.n_epochs > 0, f'long_epoch_obj: {long_epoch_obj}, short_epoch_obj: {short_epoch_obj}'\n",
    "assert long_epoch_obj.n_epochs > 0, f'long_epoch_obj: {long_epoch_obj}, short_epoch_obj: {short_epoch_obj}'\n",
    "\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "t_start, t_delta, t_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e348e0c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "# directional_merged_decoders_result = deepcopy(directional_decoders_epochs_decode_result)\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "\n",
    "spikes_df = deepcopy(curr_active_pipeline.sess.spikes_df)\n",
    "spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528460fb",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "global_computation_results = curr_active_pipeline.global_computation_results\n",
    "\n",
    "rank_order_results = curr_active_pipeline.global_computation_results.computed_data.get('RankOrder', None) # : \"RankOrderComputationsContainer\"\n",
    "if rank_order_results is not None:\n",
    "    minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "else:        \n",
    "    ## get from parameters:\n",
    "    minimum_inclusion_fr_Hz: float = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.included_qclu_values\n",
    "\n",
    "\n",
    "directional_laps_results: DirectionalLapsResult = global_computation_results.computed_data['DirectionalLaps']\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\n",
    "# print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "# print(f'included_qclu_values: {included_qclu_values}')\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "ripple_decoding_time_bin_size: float = directional_merged_decoders_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_merged_decoders_result.laps_decoding_time_bin_size\n",
    "# pos_bin_size = _recover_position_bin_size(track_templates.get_decoders()[0]) # 3.793023081021702\n",
    "# print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}, ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}, pos_bin_size: {pos_bin_size}')\n",
    "# pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "\n",
    "## Simple Pearson Correlation\n",
    "assert spikes_df is not None\n",
    "(laps_simple_pf_pearson_merged_df, ripple_simple_pf_pearson_merged_df), corr_column_names = directional_merged_decoders_result.compute_simple_spike_time_v_pf_peak_x_by_epoch(track_templates=track_templates, spikes_df=deepcopy(spikes_df))\n",
    "## OUTPUTS: (laps_simple_pf_pearson_merged_df, ripple_simple_pf_pearson_merged_df), corr_column_names\n",
    "## Computes the highest-valued decoder for this score:\n",
    "try:\n",
    "    best_decoder_index_col_name: str = 'best_decoder_index'\n",
    "    laps_simple_pf_pearson_merged_df[best_decoder_index_col_name] = laps_simple_pf_pearson_merged_df[corr_column_names].abs().apply(lambda row: np.argmax(row.values), axis=1)\n",
    "    ripple_simple_pf_pearson_merged_df[best_decoder_index_col_name] = ripple_simple_pf_pearson_merged_df[corr_column_names].abs().apply(lambda row: np.argmax(row.values), axis=1)\n",
    "except KeyError as e:\n",
    "    pass # KeyError: \"None of [Index(['long_LR_pf_peak_x_pearsonr', 'long_RL_pf_peak_x_pearsonr', 'short_LR_pf_peak_x_pearsonr', 'short_RL_pf_peak_x_pearsonr'], dtype='object')] are in the [columns]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed4d1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_directional_pf1D_Decoder = directional_merged_decoders_result.all_directional_pf1D_Decoder\n",
    "pf1D = all_directional_pf1D_Decoder.pf\n",
    "# all_directional_pf1D_Decoder\n",
    "pf1D\n",
    "# all_directional_pf1D_Decoder.pf.plot_occupancy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1dc2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sort from left to right by peak location, and bottom-to-top by context\n",
    "# pf1D.peak_indicies\n",
    "# pf1D.peak_tuning_curve_center_of_mass_bin_coordinates\n",
    "\n",
    "# pf1D.get_tuning_curve_peak_df\n",
    "# pf1D.tuning_curves_dict\n",
    "# pf1D.tuning_curves\n",
    "\n",
    "# pf1D\n",
    "directional_laps_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eed3e0c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult, SingleEpochDecodedResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)\n",
    "\n",
    "pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict\n",
    "decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict\n",
    "\n",
    "print(f'pos_bin_size: {pos_bin_size}')\n",
    "print(f'ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}')\n",
    "print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}')\n",
    "\n",
    "# Radon Transforms:\n",
    "decoder_laps_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_df_dict\n",
    "decoder_ripple_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_df_dict\n",
    "decoder_laps_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_extras_dict\n",
    "decoder_ripple_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_extras_dict\n",
    "\n",
    "# Weighted correlations:\n",
    "laps_weighted_corr_merged_df: pd.DataFrame = directional_decoders_epochs_decode_result.laps_weighted_corr_merged_df\n",
    "ripple_weighted_corr_merged_df: pd.DataFrame = directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "decoder_laps_weighted_corr_df_dict: Dict[str, pd.DataFrame] = directional_decoders_epochs_decode_result.decoder_laps_weighted_corr_df_dict\n",
    "decoder_ripple_weighted_corr_df_dict: Dict[str, pd.DataFrame] = directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict\n",
    "\n",
    "# Pearson's correlations:\n",
    "laps_simple_pf_pearson_merged_df: pd.DataFrame = directional_decoders_epochs_decode_result.laps_simple_pf_pearson_merged_df\n",
    "ripple_simple_pf_pearson_merged_df: pd.DataFrame = directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df\n",
    "\n",
    "# laps_simple_pf_pearson_merged_df\n",
    "# ripple_simple_pf_pearson_merged_df\n",
    "\n",
    "# ## Drop rows where all are missing\n",
    "# corr_column_names = ['long_LR_pf_peak_x_pearsonr', 'long_RL_pf_peak_x_pearsonr', 'short_LR_pf_peak_x_pearsonr', 'short_RL_pf_peak_x_pearsonr']\n",
    "# # ripple_simple_pf_pearson_merged_df.dropna(subset=corr_column_names, axis='index', how='all') # 350/412 rows\n",
    "# filtered_laps_simple_pf_pearson_merged_df: pd.DataFrame = laps_simple_pf_pearson_merged_df.dropna(subset=corr_column_names, axis='index', how='any') # 320/412 rows\n",
    "# filtered_ripple_simple_pf_pearson_merged_df: pd.DataFrame = ripple_simple_pf_pearson_merged_df.dropna(subset=corr_column_names, axis='index', how='any') # 320/412 rows\n",
    "\n",
    "## Update the `decoder_ripple_filter_epochs_decoder_result_dict` with the included epochs:\n",
    "# decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_ripple_filter_epochs_decoder_result_dict[a_name].filtered_by_epochs(filtered_ripple_simple_pf_pearson_merged_df.index) for a_name, a_df in decoder_ripple_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_laps_filter_epochs_decoder_result_dict[a_name].filtered_by_epochs(filtered_laps_simple_pf_pearson_merged_df.index) for a_name, a_df in decoder_laps_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_ripple_filter_epochs_decoder_result_dict[a_name].filtered_by_epoch_times(filtered_ripple_simple_pf_pearson_merged_df[['start', 'stop']].to_numpy()) for a_name, a_df in decoder_ripple_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_laps_filter_epochs_decoder_result_dict[a_name].filtered_by_epoch_times(filtered_laps_simple_pf_pearson_merged_df[['start', 'stop']].to_numpy()) for a_name, a_df in decoder_laps_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_ripple_filter_epochs_decoder_result_dict[a_name].filtered_by_epoch_times(filtered_ripple_simple_pf_pearson_merged_df['start'].to_numpy()) for a_name, a_df in decoder_ripple_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_laps_filter_epochs_decoder_result_dict[a_name].filtered_by_epoch_times(filtered_laps_simple_pf_pearson_merged_df['start'].to_numpy()) for a_name, a_df in decoder_laps_filter_epochs_decoder_result_dict.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987755c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b35196",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "# I have several python variables I want to print: t_start, t_delta, t_end\n",
    "# I want to generate a print statement that explicitly lists the variable name prior to its value like `print(f't_start: {t_start}, t_delta: {t_delta}, t_end: {t_end}')`\n",
    "# Currently I have to t_start, t_delta, t_end\n",
    "curr_active_pipeline.get_session_context()\n",
    "\n",
    "print(f'{curr_active_pipeline.session_name}:\\tt_start: {t_start}, t_delta: {t_delta}, t_end: {t_end}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49f5d4f",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "# Unpack all directional variables:\n",
    "## {\"even\": \"RL\", \"odd\": \"LR\"}\n",
    "long_LR_name, short_LR_name, global_LR_name, long_RL_name, short_RL_name, global_RL_name, long_any_name, short_any_name, global_any_name = ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "\n",
    "# Most popular\n",
    "# long_LR_name, short_LR_name, long_RL_name, short_RL_name, global_any_name\n",
    "\n",
    "# Unpacking for `(long_LR_name, long_RL_name, short_LR_name, short_RL_name)`\n",
    "(long_LR_context, long_RL_context, short_LR_context, short_RL_context) = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj, global_any_laps_epochs_obj = [curr_active_pipeline.computation_results[an_epoch_name].computation_config.pf_params.computation_epochs for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name, global_any_name)] # note has global also\n",
    "(long_LR_session, long_RL_session, short_LR_session, short_RL_session) = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)] # sessions are correct at least, seems like just the computation parameters are messed up\n",
    "(long_LR_results, long_RL_results, short_LR_results, short_RL_results) = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_computation_config, long_RL_computation_config, short_LR_computation_config, short_RL_computation_config) = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_pf1D, long_RL_pf1D, short_LR_pf1D, short_RL_pf1D) = (long_LR_results.pf1D, long_RL_results.pf1D, short_LR_results.pf1D, short_RL_results.pf1D)\n",
    "(long_LR_pf2D, long_RL_pf2D, short_LR_pf2D, short_RL_pf2D) = (long_LR_results.pf2D, long_RL_results.pf2D, short_LR_results.pf2D, short_RL_results.pf2D)\n",
    "(long_LR_pf1D_Decoder, long_RL_pf1D_Decoder, short_LR_pf1D_Decoder, short_RL_pf1D_Decoder) = (long_LR_results.pf1D_Decoder, long_RL_results.pf1D_Decoder, short_LR_results.pf1D_Decoder, short_RL_results.pf1D_Decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7104fc37",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult, DirectionalLapsResult, DirectionalDecodersContinuouslyDecodedResult\n",
    "\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']   \n",
    "rank_order_results: RankOrderComputationsContainer = curr_active_pipeline.global_computation_results.computed_data.get('RankOrder', None)\n",
    "if rank_order_results is not None:\n",
    "    minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "else:        \n",
    "    ## get from parameters:\n",
    "    minimum_inclusion_fr_Hz: float = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.included_qclu_values\n",
    "\n",
    "print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "print(f'included_qclu_values: {included_qclu_values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4a6873",
   "metadata": {
    "tags": [
     "run-group-end-run"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring, HeuristicsResult\n",
    "\n",
    "a_heuristics_result: HeuristicsResult = curr_active_pipeline.global_computation_results.computed_data['Heuristics']\n",
    "a_heuristics_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a6eab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_merged_decoders_result.laps_time_bin_marginals_df\n",
    "directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00672033",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_laps_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bb2118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result ## here is a single result, but not a dict\n",
    "# directional_merged_decoders_result # DirectionalPseudo2DDecodersResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f90757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_build_individual_time_bin_decoded_posteriors_df\n",
    "\n",
    "## From `directional_merged_decoders_result`\n",
    "# transfer_column_names_list: List[str] = ['maze_id', 'lap_dir', 'lap_id']\n",
    "transfer_column_names_list: List[str] = []\n",
    "filtered_laps_time_bin_marginals_df = _perform_build_individual_time_bin_decoded_posteriors_df(curr_active_pipeline, track_templates=track_templates, all_directional_laps_filter_epochs_decoder_result=directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result, transfer_column_names_list=transfer_column_names_list)\n",
    "filtered_laps_time_bin_marginals_df['lap_id'] = filtered_laps_time_bin_marginals_df['parent_epoch_label'].astype(int) + 1\n",
    "filtered_laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4c2073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result\n",
    "\n",
    "# directional_merged_decoders_result.all_directional_decoder_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f99c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_build_individual_time_bin_decoded_posteriors_df\n",
    "\n",
    "all_directional_laps_filter_epochs_decoder_result = deepcopy(directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result)\n",
    "filtered_laps_time_bin_marginals_df = _perform_build_individual_time_bin_decoded_posteriors_df(curr_active_pipeline, track_templates=track_templates, all_directional_laps_filter_epochs_decoder_result=all_directional_laps_filter_epochs_decoder_result)\n",
    "filtered_laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a924aa9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6abc14c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df77e66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import PhoPaginatedMultiDecoderDecodedEpochsWindow, DecodedEpochSlicesPaginatedFigureController, EpochSelectionsObject, ClickActionCallbacks\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.ThinButtonBar.ThinButtonBarWidget import ThinButtonBarWidget\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.PaginationCtrl.PaginationControlWidget import PaginationControlWidget, PaginationControlWidgetState\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from pyphoplacecellanalysis.Resources import GuiResources, ActionIcons, silx_resources_rc\n",
    "## INPUTS filtered_decoder_filter_epochs_decoder_result_dict\n",
    "# decoder_decoded_epochs_result_dict: generic\n",
    "\n",
    "app, paginated_multi_decoder_decoded_epochs_window, pagination_controller_dict = PhoPaginatedMultiDecoderDecodedEpochsWindow.init_from_track_templates(curr_active_pipeline, track_templates,\n",
    "                                                                                                # decoder_decoded_epochs_result_dict=decoder_ripple_filter_epochs_decoder_result_dict, epochs_name='ripple',\n",
    "                                                                                                decoder_decoded_epochs_result_dict=filtered_decoder_filter_epochs_decoder_result_dict, epochs_name='ripple',\n",
    "                                                                                                # decoder_decoded_epochs_result_dict=filtered_ripple_simple_pf_pearson_merged_df, epochs_name='ripple',\n",
    "                                                                                                # decoder_decoded_epochs_result_dict=long_like_during_post_delta_only_filtered_decoder_filter_epochs_decoder_result_dict, epochs_name='ripple', title='Long-like post-Delta Ripples Only', ## RIPPLE\n",
    "                                                                                                # decoder_decoded_epochs_result_dict=decoder_laps_filter_epochs_decoder_result_dict, epochs_name='laps', ## LAPS\n",
    "                                                                                                included_epoch_indicies=None, debug_print=False,\n",
    "                                                                                                params_kwargs={'enable_per_epoch_action_buttons': False,\n",
    "                                                                                                    'skip_plotting_most_likely_positions': True, 'skip_plotting_measured_positions': True, \n",
    "                                                                                                    'enable_decoded_most_likely_position_curve': False, 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': True,\n",
    "                                                                                                    # 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': False,\n",
    "                                                                                                    # 'disable_y_label': True,\n",
    "                                                                                                    'isPaginatorControlWidgetBackedMode': True,\n",
    "                                                                                                    'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True,\n",
    "                                                                                                    # 'debug_print': True,\n",
    "                                                                                                    'max_subplots_per_page': 10,\n",
    "                                                                                                    'scrollable_figure': False,\n",
    "                                                                                                    # 'scrollable_figure': True,\n",
    "                                                                                                    # 'posterior_heatmap_imshow_kwargs': dict(vmin=0.0075),\n",
    "                                                                                                    'use_AnchoredCustomText': False,\n",
    "                                                                                                    'should_suppress_callback_exceptions': False,\n",
    "                                                                                                    # 'build_fn': 'insets_view',\n",
    "                                                                                                })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ce9677",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### attached raster viewer widget:\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.RankOrderRastersDebugger import RankOrderRastersDebugger\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import get_proper_global_spikes_df\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "\n",
    "## INPUTS: active_spikes_df\n",
    "# active_spikes_df = get_proper_global_spikes_df(curr_active_pipeline, minimum_inclusion_fr_Hz=5)\n",
    "\n",
    "active_spikes_df = get_proper_global_spikes_df(curr_active_pipeline)\n",
    "\n",
    "# PosteriorExporting._perform_export_current_epoch_marginal_and_raster_images\n",
    "\n",
    "\n",
    "\n",
    "# _out_ripple_rasters, update_attached_raster_viewer_epoch_callback = paginated_multi_decoder_decoded_epochs_window.build_attached_raster_viewer_widget(track_templates=track_templates, active_spikes_df=active_spikes_df, filtered_epochs_df=filtered_epochs_df) ## BEST\n",
    "# _out_ripple_rasters, update_attached_raster_viewer_epoch_callback = paginated_multi_decoder_decoded_epochs_window.build_attached_raster_viewer_widget(track_templates=track_templates, active_spikes_df=active_spikes_df, filtered_epochs_df=filtered_ripple_simple_pf_pearson_merged_df) # original\n",
    "_out_ripple_rasters, update_attached_raster_viewer_epoch_callback = paginated_multi_decoder_decoded_epochs_window.build_attached_raster_viewer_widget(track_templates=track_templates, active_spikes_df=active_spikes_df, filtered_epochs_df=extracted_merged_scores_df)\n",
    "# _out_ripple_rasters, update_attached_raster_viewer_epoch_callback = paginated_multi_decoder_decoded_epochs_window.build_attached_raster_viewer_widget(track_templates=track_templates, active_spikes_df=active_spikes_df, filtered_epochs_df=long_like_during_post_delta_only_filter_epochs_df) # Long-like-during-post-delta\n",
    "\n",
    "\n",
    "# all_directional_laps_filter_epochs_decoder_result_value\n",
    "# laps_filter_epochs = ensure_dataframe(deepcopy(decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)) \n",
    "# _out_ripple_rasters, update_attached_raster_viewer_epoch_callback = paginated_multi_decoder_decoded_epochs_window.build_attached_raster_viewer_widget(track_templates=track_templates, active_spikes_df=laps_spikes_df, filtered_epochs_df=filtered_laps_simple_pf_pearson_merged_df) ## LAPS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d2fead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66d41af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out_ripple_rasters: RankOrderRastersDebugger\n",
    "### Add yellow-blue marginals to `paginated_multi_decoder_decoded_epochs_window`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_decoded_epoch_slices\n",
    "from pyphocorehelpers.gui.Qt.widget_positioning_helpers import WidgetPositioningHelpers, DesiredWidgetLocation, WidgetGeometryInfo\n",
    "\n",
    "yellow_blue_trackID_marginals_plot_tuple = paginated_multi_decoder_decoded_epochs_window.build_attached_yellow_blue_track_identity_marginal_window(directional_merged_decoders_result, global_session, ripple_decoding_time_bin_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fee2d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean and max number of active aclus per time bin for each epoch (lap)\n",
    "filtered_laps_time_bin_marginals_df.groupby(['lap_id']).agg(n_unique_aclus_mean=('n_unique_aclus', 'mean'), n_unique_aclus_max=('n_unique_aclus', 'max')).reset_index()\n",
    "filtered_laps_time_bin_marginals_df.groupby(['maze_id']).agg(n_unique_aclus_mean=('n_unique_aclus', 'mean'), n_unique_aclus_max=('n_unique_aclus', 'max')).reset_index() ## per maze\n",
    "filtered_laps_time_bin_marginals_df.groupby(['maze_id', 'lap_dir']).agg(n_unique_aclus_mean=('n_unique_aclus', 'mean'), n_unique_aclus_max=('n_unique_aclus', 'max')).reset_index() # per maze x lap_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93346114",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.BatchCompletionHandler import BatchSessionCompletionHandler\n",
    "\n",
    "BatchSessionCompletionHandler.post_compute_validate(curr_active_pipeline=curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0617e7a3",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "list(directional_laps_results.directional_lap_specific_configs.keys()) # ['maze1_odd', 'maze1_even', 'maze2_odd', 'maze2_even']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912656a7",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "from neuropy.utils.indexing_helpers import NumpyHelpers\n",
    "\n",
    "if ('DirectionalDecodersEpochsEvaluations' in curr_active_pipeline.global_computation_results.computed_data) and (curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations'] is not None):\n",
    "    directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "    directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)\n",
    "\n",
    "    ## UNPACK HERE via direct property access:\n",
    "    pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "    ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "    laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "    print(f'{pos_bin_size = }, {ripple_decoding_time_bin_size = }, {laps_decoding_time_bin_size = }') # pos_bin_size = 3.8054171165052444, ripple_decoding_time_bin_size = 0.025, laps_decoding_time_bin_size = 0.2\n",
    "    decoder_laps_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict\n",
    "    decoder_ripple_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict\n",
    "    decoder_laps_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_df_dict\n",
    "    decoder_ripple_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_df_dict\n",
    "\n",
    "    # New items:\n",
    "    decoder_laps_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_extras_dict\n",
    "    decoder_ripple_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_extras_dict\n",
    "\n",
    "    # Weighted correlations:\n",
    "    laps_weighted_corr_merged_df = directional_decoders_epochs_decode_result.laps_weighted_corr_merged_df\n",
    "    ripple_weighted_corr_merged_df = directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "    decoder_laps_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_laps_weighted_corr_df_dict\n",
    "    decoder_ripple_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict\n",
    "\n",
    "    # Pearson's correlations:\n",
    "    laps_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.laps_simple_pf_pearson_merged_df\n",
    "    ripple_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df\n",
    "    \n",
    "    # for k, v in directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict.items():\n",
    "    #     print(f'{k}: v.decoding_time_bin_size: {v.decoding_time_bin_size}')\n",
    "    \n",
    "    individual_result_ripple_time_bin_sizes = [v.decoding_time_bin_size for k, v in directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict.items()]\n",
    "    if not np.allclose(ripple_decoding_time_bin_size, individual_result_ripple_time_bin_sizes):\n",
    "        individual_result_ripple_time_bin_size = individual_result_ripple_time_bin_sizes[0] # get the first\n",
    "        assert np.allclose(individual_result_ripple_time_bin_size, individual_result_ripple_time_bin_sizes), f\"`individual_result_ripple_time_bin_size ({individual_result_ripple_time_bin_size}) does not equal the individual result time bin sizes: {individual_result_ripple_time_bin_sizes}`. This can occur when there are epochs smaller than the desired size ({ripple_decoding_time_bin_size}) for the result and epochs_filtering_mode=EpochFilteringMode.ConstrainDecodingTimeBinSizeToMinimum\"\n",
    "        print(f'WARN: overriding directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size (original value: {directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size}) with individual_result_ripple_time_bin_size: {individual_result_ripple_time_bin_size}')\n",
    "        directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size = individual_result_ripple_time_bin_size # override the time_bin_size with the actually used one\n",
    "        ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "        print(f'{pos_bin_size = }, {ripple_decoding_time_bin_size = }, {laps_decoding_time_bin_size = }') # pos_bin_size = 3.8054171165052444, ripple_decoding_time_bin_size = 0.025, laps_decoding_time_bin_size = 0.2\n",
    "    else:\n",
    "        # all are close, it's good\n",
    "        pass\n",
    "\n",
    "    # assert np.allclose(ripple_decoding_time_bin_size, individual_result_ripple_time_bin_sizes), f\"`directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size ({ripple_decoding_time_bin_size}) does not equal the individual result time bin sizes: {individual_result_ripple_time_bin_sizes}`. This can occur when there are epochs smaller than the desired size ({ripple_decoding_time_bin_size}) for the result and epochs_filtering_mode=EpochFilteringMode.ConstrainDecodingTimeBinSizeToMinimum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f1c291",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dce38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directional_decoders_epochs_decode_result # DecoderDecodedEpochsResult\n",
    "# laps_weighted_corr_merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881402df",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "# active_config_name: str = 'maze_any'\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "active_config_name: str = global_epoch_name # 'maze_any'\n",
    "active_config_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b80230",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "## INPUTS: curr_active_pipeline, active_config_name\n",
    "active_peak_prominence_2d_results = curr_active_pipeline.computation_results[active_config_name].computed_data.get('RatemapPeaksAnalysis', {}).get('PeakProminence2D', None)\n",
    "if active_peak_prominence_2d_results is None:\n",
    "    curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['ratemap_peaks_prominence2d'], enabled_filter_names=None, fail_on_exception=False, debug_print=False)\n",
    "    # curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['ratemap_peaks_prominence2d'], enabled_filter_names=[short_LR_name, short_RL_name, long_any_name, short_any_name], fail_on_exception=False, debug_print=False) # or at least\n",
    "    active_peak_prominence_2d_results = curr_active_pipeline.computation_results[active_config_name].computed_data.get('RatemapPeaksAnalysis', {}).get('PeakProminence2D', None)\n",
    "    assert active_peak_prominence_2d_results is not None, f\"bad even after computation\"\n",
    "\n",
    "# active_peak_prominence_2d_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7706d485",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(active_peak_prominence_2d_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238f67cb",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all",
     "run-continuous-decoding",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalDecodersContinuouslyDecodedResult\n",
    "\n",
    "if 'DirectionalDecodersDecoded' in curr_active_pipeline.global_computation_results.computed_data:\n",
    "    directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "    all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "    pseudo2D_decoder: BasePositionDecoder = directional_decoders_decode_result.pseudo2D_decoder\n",
    "    spikes_df = directional_decoders_decode_result.spikes_df\n",
    "    continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "    previously_decoded_keys: List[float] = list(continuously_decoded_result_cache_dict.keys()) # [0.03333]\n",
    "    print(F'previously_decoded time_bin_sizes: {previously_decoded_keys}')\n",
    "    \n",
    "    time_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\n",
    "    print(f'time_bin_size: {time_bin_size}')\n",
    "    continuously_decoded_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_decode_result.most_recent_continuously_decoded_dict\n",
    "    all_directional_continuously_decoded_dict = continuously_decoded_dict or {} ## what is plotted in the `f'{a_decoder_name}_ContinuousDecode'` rows by `AddNewDirectionalDecodedEpochs_MatplotlibPlotCommand`\n",
    "    all_directional_continuously_decoded_dict\n",
    "\n",
    "    pseudo2D_decoder_continuously_decoded_result: DecodedFilterEpochsResult = continuously_decoded_dict.get('pseudo2D', None)\n",
    "    assert len(pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list) == 1\n",
    "    p_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0]\n",
    "    # p_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0]['p_x_given_n']\n",
    "    time_bin_containers = pseudo2D_decoder_continuously_decoded_result.time_bin_containers[0]\n",
    "    time_window_centers = time_bin_containers.centers\n",
    "    # p_x_given_n.shape # (62, 4, 209389)\n",
    "\n",
    "    ## Split across the 2nd axis to make 1D posteriors that can be displayed in separate dock rows:\n",
    "    assert p_x_given_n.shape[1] == 4, f\"expected the 4 pseudo-y bins for the decoder in p_x_given_n.shape[1]. but found p_x_given_n.shape: {p_x_given_n.shape}\"\n",
    "    split_pseudo2D_posteriors_dict = {k:np.squeeze(p_x_given_n[:, i, :]) for i, k in enumerate(('long_LR', 'long_RL', 'short_LR', 'short_RL'))}\n",
    "    split_pseudo2D_posteriors_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d92b4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_decoders_decode_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e1ee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_directional_pf1D_Decoder_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b4e959",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.SequenceBasedComputations import WCorrShuffle, SequenceBasedComputationsContainer\n",
    "\n",
    "wcorr_shuffle_results: SequenceBasedComputationsContainer = curr_active_pipeline.global_computation_results.computed_data.get('SequenceBased', None)\n",
    "if wcorr_shuffle_results is not None:    \n",
    "    wcorr_ripple_shuffle: WCorrShuffle = wcorr_shuffle_results.wcorr_ripple_shuffle\n",
    "    if wcorr_ripple_shuffle is not None:\n",
    "        print(f'wcorr_ripple_shuffle.n_completed_shuffles: {wcorr_ripple_shuffle.n_completed_shuffles}')\n",
    "    else:\n",
    "        print(f'SequenceBased is computed but `wcorr_shuffle_results.wcorr_ripple_shuffle` is None.')        \n",
    "else:\n",
    "    print(f'SequenceBased is not computed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e9cc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['trial_by_trial_metrics'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "directional_trial_by_trial_activity_result = curr_active_pipeline.global_computation_results.computed_data.get('TrialByTrialActivity', None) ## try again to get the result\n",
    "assert directional_trial_by_trial_activity_result is not None, f\"directional_trial_by_trial_activity_result is None even after forcing recomputation!!\"\n",
    "print(f'\\t done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d7394a",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.reliability import TrialByTrialActivity\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrialByTrialActivityResult\n",
    "\n",
    "directional_trial_by_trial_activity_result: TrialByTrialActivityResult = curr_active_pipeline.global_computation_results.computed_data.get('TrialByTrialActivity', None)\n",
    "if directional_trial_by_trial_activity_result is None:\n",
    "    # if `KeyError: 'TrialByTrialActivity'` recompute\n",
    "    print(f'TrialByTrialActivity is not computed, computing it...')\n",
    "    curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['trial_by_trial_metrics'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "    directional_trial_by_trial_activity_result = curr_active_pipeline.global_computation_results.computed_data.get('TrialByTrialActivity', None) ## try again to get the result\n",
    "    assert directional_trial_by_trial_activity_result is not None, f\"directional_trial_by_trial_activity_result is None even after forcing recomputation!!\"\n",
    "    print(f'\\t done.')\n",
    "\n",
    "## unpack either way:\n",
    "any_decoder_neuron_IDs = directional_trial_by_trial_activity_result.any_decoder_neuron_IDs\n",
    "active_pf_dt: PfND_TimeDependent = directional_trial_by_trial_activity_result.active_pf_dt\n",
    "directional_lap_epochs_dict: Dict[str, Epoch] = directional_trial_by_trial_activity_result.directional_lap_epochs_dict\n",
    "directional_active_lap_pf_results_dicts: Dict[str, TrialByTrialActivity] = directional_trial_by_trial_activity_result.directional_active_lap_pf_results_dicts\n",
    "stability_dict = {k:list(v.aclu_to_stability_score_dict.values()) for k,v in directional_active_lap_pf_results_dicts.items()}\n",
    "stability_df: pd.DataFrame = pd.DataFrame({'aclu': any_decoder_neuron_IDs, **stability_dict})\n",
    "## OUTPUTS: stability_df, stability_dict\n",
    "\n",
    "## OUTPUTS: directional_trial_by_trial_activity_result, directional_active_lap_pf_results_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fad74c",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "wcorr_shuffle_results: SequenceBasedComputationsContainer = curr_active_pipeline.global_computation_results.computed_data.get('SequenceBased', None)\n",
    "if wcorr_shuffle_results is not None:    \n",
    "    wcorr_ripple_shuffle: WCorrShuffle = wcorr_shuffle_results.wcorr_ripple_shuffle\n",
    "    if wcorr_ripple_shuffle is not None:  \n",
    "        print(f'wcorr_ripple_shuffle.n_completed_shuffles: {wcorr_ripple_shuffle.n_completed_shuffles}')\n",
    "    else:\n",
    "        print(f'SequenceBased is computed but wcorr_ripple_shuffle is None.')\n",
    "else:\n",
    "    print(f'SequenceBased is not computed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ed0870",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "run-continuous-decoding",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult, SingleEpochDecodedResult\n",
    "\n",
    "most_recent_time_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\n",
    "# most_recent_time_bin_size\n",
    "most_recent_continuously_decoded_dict = deepcopy(directional_decoders_decode_result.most_recent_continuously_decoded_dict)\n",
    "# most_recent_continuously_decoded_dict\n",
    "\n",
    "## Adds in the 'pseudo2D' decoder in:\n",
    "time_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\n",
    "# time_bin_size: float = 0.01\n",
    "print(f'time_bin_size: {time_bin_size}')\n",
    "continuously_decoded_dict = continuously_decoded_result_cache_dict[time_bin_size]\n",
    "pseudo2D_decoder_continuously_decoded_result = continuously_decoded_dict.get('pseudo2D', None)\n",
    "if pseudo2D_decoder_continuously_decoded_result is None:\n",
    "    # compute here...\n",
    "    ## Currently used for both cases to decode:\n",
    "    t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "    single_global_epoch_df: pd.DataFrame = pd.DataFrame({'start': [t_start], 'stop': [t_end], 'label': [0]}) # Build an Epoch object containing a single epoch, corresponding to the global epoch for the entire session:\n",
    "    single_global_epoch: Epoch = Epoch(single_global_epoch_df)\n",
    "    spikes_df = directional_decoders_decode_result.spikes_df\n",
    "    pseudo2D_decoder_continuously_decoded_result: DecodedFilterEpochsResult = pseudo2D_decoder.decode_specific_epochs(spikes_df=deepcopy(spikes_df), filter_epochs=single_global_epoch, decoding_time_bin_size=time_bin_size, debug_print=False)\n",
    "    continuously_decoded_dict['pseudo2D'] = pseudo2D_decoder_continuously_decoded_result\n",
    "    continuously_decoded_dict\n",
    "    \n",
    "pseudo2D_decoder_continuously_decoded_single_result: SingleEpochDecodedResult = pseudo2D_decoder_continuously_decoded_result.get_result_for_epoch(0)\n",
    "pseudo2D_decoder_continuously_decoded_single_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eab4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudo2D_decoder_continuously_decoded_single_result.epoch_info_tuple\n",
    "pseudo2D_decoder_continuously_decoded_single_result.nbins\n",
    "pseudo2D_decoder_continuously_decoded_single_result.p_x_given_n\n",
    "pseudo2D_decoder_continuously_decoded_single_result.p_x_given_n.shape # (57, 4, 29951)\n",
    "\n",
    "\n",
    "short_RL_only = pseudo2D_decoder_continuously_decoded_single_result.p_x_given_n[:, 3, :]\n",
    "np.shape(short_RL_only)\n",
    "\n",
    "debug_portion_short_RL_only = short_RL_only[:, :1000]\n",
    "\n",
    "\n",
    "plt.figure(clear=True)\n",
    "plt.imshow(debug_portion_short_RL_only)\n",
    "# plt.plot(np.sum(short_RL_only, axis=0))\n",
    "# plt.plot(np.cumsum(np.sum(short_RL_only, axis=0)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f48287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88344ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import SingleEpochDecodedResult\n",
    "\n",
    "\n",
    "only_result.p_x_given_n\n",
    "only_result.time_bin_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ee77bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo2D_decoder_continuously_decoded_result.filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2dc5fe",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "# NEW 2023-11-22 method: Get the templates (which can be filtered by frate first) and the from those get the decoders):        \n",
    "# track_templates: TrackTemplates = directional_laps_results.get_shared_aclus_only_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # shared-only\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, included_qclu_values=included_qclu_values) # non-shared-only\n",
    "long_LR_decoder, long_RL_decoder, short_LR_decoder, short_RL_decoder = track_templates.get_decoders()\n",
    "\n",
    "# Unpack all directional variables:\n",
    "## {\"even\": \"RL\", \"odd\": \"LR\"}\n",
    "long_LR_name, short_LR_name, global_LR_name, long_RL_name, short_RL_name, global_RL_name, long_any_name, short_any_name, global_any_name = ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "# Unpacking for `(long_LR_name, long_RL_name, short_LR_name, short_RL_name)`\n",
    "(long_LR_context, long_RL_context, short_LR_context, short_RL_context) = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj, global_any_laps_epochs_obj = [curr_active_pipeline.computation_results[an_epoch_name].computation_config.pf_params.computation_epochs for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name, global_any_name)] # note has global also\n",
    "(long_LR_session, long_RL_session, short_LR_session, short_RL_session) = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)] # sessions are correct at least, seems like just the computation parameters are messed up\n",
    "(long_LR_results, long_RL_results, short_LR_results, short_RL_results) = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_computation_config, long_RL_computation_config, short_LR_computation_config, short_RL_computation_config) = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_pf1D, long_RL_pf1D, short_LR_pf1D, short_RL_pf1D) = (long_LR_results.pf1D, long_RL_results.pf1D, short_LR_results.pf1D, short_RL_results.pf1D)\n",
    "(long_LR_pf2D, long_RL_pf2D, short_LR_pf2D, short_RL_pf2D) = (long_LR_results.pf2D, long_RL_results.pf2D, short_LR_results.pf2D, short_RL_results.pf2D)\n",
    "(long_LR_pf1D_Decoder, long_RL_pf1D_Decoder, short_LR_pf1D_Decoder, short_RL_pf1D_Decoder) = (long_LR_results.pf1D_Decoder, long_RL_results.pf1D_Decoder, short_LR_results.pf1D_Decoder, short_RL_results.pf1D_Decoder)\n",
    "\n",
    "if rank_order_results is not None:\n",
    "    # `LongShortStatsItem` form (2024-01-02):\n",
    "    # LR_results_real_values = np.array([(a_result_item.long_stats_z_scorer.real_value, a_result_item.short_stats_z_scorer.real_value) for epoch_id, a_result_item in rank_order_results.LR_ripple.ranked_aclus_stats_dict.items()])\n",
    "    # RL_results_real_values = np.array([(a_result_item.long_stats_z_scorer.real_value, a_result_item.short_stats_z_scorer.real_value) for epoch_id, a_result_item in rank_order_results.RL_ripple.ranked_aclus_stats_dict.items()])\n",
    "    LR_results_long_short_z_diffs = np.array([a_result_item.long_short_z_diff for epoch_id, a_result_item in rank_order_results.LR_ripple.ranked_aclus_stats_dict.items()])\n",
    "    RL_results_long_short_z_diff = np.array([a_result_item.long_short_z_diff for epoch_id, a_result_item in rank_order_results.RL_ripple.ranked_aclus_stats_dict.items()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c260739a4f36c662",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrainTestSplitResult\n",
    "\n",
    "if 'TrainTestSplit' in curr_active_pipeline.global_computation_results.computed_data:\n",
    "    directional_train_test_split_result: TrainTestSplitResult = curr_active_pipeline.global_computation_results.computed_data.get('TrainTestSplit', None)\n",
    "    training_data_portion: float = directional_train_test_split_result.training_data_portion\n",
    "    test_data_portion: float = directional_train_test_split_result.test_data_portion\n",
    "    test_epochs_dict: Dict[str, pd.DataFrame] = directional_train_test_split_result.test_epochs_dict\n",
    "    train_epochs_dict: Dict[str, pd.DataFrame] = directional_train_test_split_result.train_epochs_dict\n",
    "    train_lap_specific_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_train_test_split_result.train_lap_specific_pf1D_Decoder_dict\n",
    "    \n",
    "long_LR_name, short_LR_name, global_LR_name, long_RL_name, short_RL_name, global_RL_name, long_any_name, short_any_name, global_any_name = ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj = [curr_active_pipeline.computation_results[an_epoch_name].computation_config.pf_params.computation_epochs for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)] # note has global also\n",
    "long_LR_name, long_RL_name, short_LR_name, short_RL_name = track_templates.get_decoder_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec18cf18",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "if 'burst_detection' in curr_active_pipeline.computation_results[global_epoch_name].computed_data:\n",
    "    active_burst_intervals = curr_active_pipeline.computation_results[global_epoch_name].computed_data['burst_detection']['burst_intervals']\n",
    "# active_burst_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d31f37d",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "active_extended_stats = global_results.get('extended_stats', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9554d3bf5955d9d3",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "# Time-dependent\n",
    "long_pf1D_dt, short_pf1D_dt, global_pf1D_dt = long_results.pf1D_dt, short_results.pf1D_dt, global_results.pf1D_dt\n",
    "long_pf2D_dt, short_pf2D_dt, global_pf2D_dt = long_results.pf2D_dt, short_results.pf2D_dt, global_results.pf2D_dt\n",
    "global_pf1D_dt: PfND_TimeDependent = global_results.pf1D_dt\n",
    "global_pf2D_dt: PfND_TimeDependent = global_results.pf2D_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7a8050",
   "metadata": {},
   "outputs": [],
   "source": [
    "## long_short_endcap_analysis: checks for cells localized to the endcaps that have their placefields truncated after shortening the track\n",
    "truncation_checking_result: TruncationCheckingResults = curr_active_pipeline.global_computation_results.computed_data.long_short_endcap\n",
    "disappearing_endcap_aclus = truncation_checking_result.disappearing_endcap_aclus\n",
    "# disappearing_endcap_aclus\n",
    "trivially_remapping_endcap_aclus = truncation_checking_result.minor_remapping_endcap_aclus\n",
    "# trivially_remapping_endcap_aclus\n",
    "significant_distant_remapping_endcap_aclus = truncation_checking_result.significant_distant_remapping_endcap_aclus\n",
    "# significant_distant_remapping_endcap_aclus\n",
    "# appearing_aclus = jonathan_firing_rate_analysis_result.neuron_replay_stats_df[jonathan_firing_rate_analysis_result.neuron_replay_stats_df['track_membership'] == SplitPartitionMembership.RIGHT_ONLY].index\n",
    "# appearing_aclus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8ff5d1",
   "metadata": {},
   "source": [
    "# <a id='toc5_'></a>[1️⃣ POST-Compute:](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728c46e6",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "21"
    },
    "tags": [
     "unwrap",
     "initial",
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalDisplayFunctions\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multi_sort_raster_browser\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.RankOrderRastersDebugger import RankOrderRastersDebugger\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import paired_separately_sort_neurons, paired_incremental_sort_neurons # _display_directional_template_debugger\n",
    "from neuropy.utils.indexing_helpers import paired_incremental_sorting, union_of_arrays, intersection_of_arrays, find_desired_sort_indicies\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.ScrollBarWithSpinBox.ScrollBarWithSpinBox import ScrollBarWithSpinBox\n",
    "\n",
    "from neuropy.utils.mixins.HDF5_representable import HDF_SerializationMixin\n",
    "from pyphoplacecellanalysis.General.Model.ComputationResults import ComputedResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderAnalyses, RankOrderResult, ShuffleHelper, Zscorer, LongShortStatsTuple, DirectionalRankOrderLikelihoods, DirectionalRankOrderResult, RankOrderComputationsContainer\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import TimeColumnAliasesProtocol\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderComputationsContainer\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import DirectionalRankOrderResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "\n",
    "## Display Testing\n",
    "# from pyphoplacecellanalysis.External.pyqtgraph import QtGui\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.Extensions.pyqtgraph_helpers import pyqtplot_build_image_bounds_extent, pyqtplot_plot_image\n",
    "\n",
    "spikes_df = curr_active_pipeline.sess.spikes_df\n",
    "rank_order_results: RankOrderComputationsContainer = curr_active_pipeline.global_computation_results.computed_data.get('RankOrder', None)\n",
    "if rank_order_results is not None:\n",
    "    minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "    ripple_result_tuple, laps_result_tuple = rank_order_results.ripple_most_likely_result_tuple, rank_order_results.laps_most_likely_result_tuple\n",
    "\n",
    "else:        \n",
    "    ## get from parameters:\n",
    "    minimum_inclusion_fr_Hz: float = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.included_qclu_values\n",
    "\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, included_qclu_values=included_qclu_values) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\n",
    "print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "print(f'included_qclu_values: {included_qclu_values}')\n",
    "# ripple_result_tuple\n",
    "\n",
    "# ripple_result_tuple.directional_likelihoods_tuple.long_best_direction_indices\n",
    "dir_index_to_direction_name_map: Dict[int, str] = {0:'LR', 1:\"RL\"}\n",
    "\n",
    "if rank_order_results is not None:\n",
    "    ## All three DataFrames are the same number of rows, each with one row corresponding to an Epoch:\n",
    "    active_replay_epochs_df = deepcopy(rank_order_results.LR_ripple.epochs_df)\n",
    "    # active_replay_epochs_df\n",
    "\n",
    "    # Change column type to int8 for columns: 'long_best_direction_indices', 'short_best_direction_indices'\n",
    "    # directional_likelihoods_df = pd.DataFrame.from_dict(ripple_result_tuple.directional_likelihoods_tuple._asdict()).astype({'long_best_direction_indices': 'int8', 'short_best_direction_indices': 'int8'})\n",
    "    directional_likelihoods_df = ripple_result_tuple.directional_likelihoods_df\n",
    "    # directional_likelihoods_df\n",
    "\n",
    "    # 2023-12-15 - Newest method:\n",
    "    laps_merged_complete_epoch_stats_df: pd.DataFrame = rank_order_results.laps_merged_complete_epoch_stats_df ## New method\n",
    "    ripple_merged_complete_epoch_stats_df: pd.DataFrame = rank_order_results.ripple_merged_complete_epoch_stats_df ## New method\n",
    "\n",
    "\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "\n",
    "all_directional_decoder_dict_value = directional_merged_decoders_result.all_directional_decoder_dict\n",
    "all_directional_pf1D_Decoder_value = directional_merged_decoders_result.all_directional_pf1D_Decoder\n",
    "# long_directional_pf1D_Decoder_value = directional_merged_decoders_result.long_directional_pf1D_Decoder\n",
    "# long_directional_decoder_dict_value = directional_merged_decoders_result.long_directional_decoder_dict\n",
    "# short_directional_pf1D_Decoder_value = directional_merged_decoders_result.short_directional_pf1D_Decoder\n",
    "# short_directional_decoder_dict_value = directional_merged_decoders_result.short_directional_decoder_dict\n",
    "\n",
    "all_directional_laps_filter_epochs_decoder_result_value = directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result\n",
    "all_directional_ripple_filter_epochs_decoder_result_value = directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result\n",
    "\n",
    "laps_directional_marginals, laps_directional_all_epoch_bins_marginal, laps_most_likely_direction_from_decoder, laps_is_most_likely_direction_LR_dir  = directional_merged_decoders_result.laps_directional_marginals_tuple\n",
    "laps_track_identity_marginals, laps_track_identity_all_epoch_bins_marginal, laps_most_likely_track_identity_from_decoder, laps_is_most_likely_track_identity_Long = directional_merged_decoders_result.laps_track_identity_marginals_tuple\n",
    "ripple_directional_marginals, ripple_directional_all_epoch_bins_marginal, ripple_most_likely_direction_from_decoder, ripple_is_most_likely_direction_LR_dir  = directional_merged_decoders_result.ripple_directional_marginals_tuple\n",
    "ripple_track_identity_marginals, ripple_track_identity_all_epoch_bins_marginal, ripple_most_likely_track_identity_from_decoder, ripple_is_most_likely_track_identity_Long = directional_merged_decoders_result.ripple_track_identity_marginals_tuple\n",
    "\n",
    "ripple_decoding_time_bin_size: float = directional_merged_decoders_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_merged_decoders_result.laps_decoding_time_bin_size\n",
    "\n",
    "print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}, ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}')\n",
    "\n",
    "laps_all_epoch_bins_marginals_df = directional_merged_decoders_result.laps_all_epoch_bins_marginals_df\n",
    "ripple_all_epoch_bins_marginals_df = directional_merged_decoders_result.ripple_all_epoch_bins_marginals_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d2f342",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_merged_complete_epoch_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdb4ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_directional_marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753ca336",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "# from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import HeuristicReplayScoring\n",
    "from neuropy.core.epoch import find_data_indicies_from_epoch_times\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_filter_replay_epochs\n",
    "\n",
    "# filtered_epochs_df, filtered_decoder_filter_epochs_decoder_result_dict, filtered_ripple_all_epoch_bins_marginals_df = None, None, None\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-_perform_filter_replay_epochs.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "filtered_epochs_df, filtered_decoder_filter_epochs_decoder_result_dict, filtered_ripple_all_epoch_bins_marginals_df = _perform_filter_replay_epochs(curr_active_pipeline, global_epoch_name, track_templates, decoder_ripple_filter_epochs_decoder_result_dict, ripple_all_epoch_bins_marginals_df, ripple_decoding_time_bin_size=ripple_decoding_time_bin_size, should_only_include_user_selected_epochs=False)\n",
    "filtered_epochs_df\n",
    "# filtered_ripple_all_epoch_bins_marginals_df\n",
    "\n",
    "## 1m 38s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a32882",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ripple_all_epoch_bins_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92aad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_sess: DataSession = curr_active_pipeline.sess\n",
    "global_session.compute_pbe_epochs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca48dd6",
   "metadata": {},
   "source": [
    "### <a id='toc5_1_1_'></a>[2024-06-25 - Advanced Time-dependent decoding:](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c76fbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Directional Versions: 'long_LR':\n",
    "from neuropy.core.epoch import subdivide_epochs, ensure_dataframe\n",
    "from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent\n",
    "\n",
    "## INPUTS: long_LR_epochs_obj, long_LR_results\n",
    "\n",
    "a_pf1D_dt: PfND_TimeDependent = deepcopy(long_LR_results.pf1D_dt)\n",
    "a_pf2D_dt: PfND_TimeDependent = deepcopy(long_LR_results.pf2D_dt)\n",
    "\n",
    "# Example usage\n",
    "df: pd.DataFrame = ensure_dataframe(deepcopy(long_LR_epochs_obj)) \n",
    "df['epoch_type'] = 'lap'\n",
    "df['interval_type_id'] = 666\n",
    "\n",
    "# subdivide_bin_size = 0.200  # Specify the size of each sub-epoch in seconds\n",
    "subdivide_bin_size = 0.050\n",
    "subdiv_df: pd.DataFrame = subdivide_epochs(df, subdivide_bin_size)\n",
    "# print(subdivided_df)\n",
    "\n",
    "## Evolve the ratemaps:\n",
    "_a_pf1D_dt_snapshots = a_pf1D_dt.batch_snapshotting(subdiv_df, reset_at_start=True)\n",
    "_a_pf2D_dt_snapshots = a_pf2D_dt.batch_snapshotting(subdiv_df, reset_at_start=True)\n",
    "# a_pf2D_dt.plot_ratemaps_2D()\n",
    "\n",
    "## takes about 2 mins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ea5ec7",
   "metadata": {},
   "source": [
    "# 2025-08-19 - Aclu First Placefield Stability Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d33293",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import AcluFirstPlacefieldStabilityThresholdFigure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14155360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merged: pd.DataFrame = AcluFirstSignifianceFigure._compute_bump(fr_threshold_Hz= 1.0)\n",
    "with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-AcluFirstPlacefieldStabilityThresholdFigure.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "    df_merged, decoder_outputs, pf1D_dt_outputs, pf1D_dt_snapshot_outputs = AcluFirstPlacefieldStabilityThresholdFigure._compute_for_all_decoders(curr_active_pipeline, track_templates, fr_threshold_Hz=2.0)\n",
    "    # ~2m\n",
    "    # 10m+ not sure why I started taking so long, I think I just modified the return values (returning more of them)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87d36c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged ## add to TrialByTrialActivity figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6aa43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = AcluFirstPlacefieldStabilityThresholdFigure.plot_aclus_first_significance_figure(curr_active_pipeline=curr_active_pipeline, track_templates=track_templates, df_merged=df_merged, is_delta_relative=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8769a8d4",
   "metadata": {
    "tags": [
     "aclufirstplacefieldstabilitythresholdfigure"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.TrialByTrialActivityWindow import TrialByTrialActivityWindow\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "_out = curr_active_pipeline.display('_display_placefield_stable_formation_time_distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87786ec0",
   "metadata": {},
   "source": [
    "#### 2025-08-20 - Not yet finished - add each aclu first-stable-pf time to TrialByTrialActivity figure\n",
    "The difficulty lies in mapping the from one of the `df_merged` columns to trial/lap # (ranging [-2.5, 163.5] on the y-axis of each subplot)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7017c03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d3385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.TrialByTrialActivityWindow import TrialByTrialActivityWindow\n",
    "\n",
    "_out = dict()\n",
    "_out['_display_trial_to_trial_reliability'] = curr_active_pipeline.display(display_function='_display_trial_to_trial_reliability', active_session_configuration_context=None) # _display_trial_to_trial_reliability\n",
    "a_TbyT_activity_win: TrialByTrialActivityWindow = _out['_display_trial_to_trial_reliability']\n",
    "\n",
    "# a_TbyT_activity_win.add_pf_stable_formation_time_distribution_results(df_merged=df_merged) # Get the current view rectangle of the plot\n",
    "## INPUTS: df_merged, a_TbyT_activity_win\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788d8b7e",
   "metadata": {},
   "source": [
    "# <a id='toc6_'></a>[/ 🛑 End Run Section 🛑](#toc0_)\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7433b81f",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "## Find the time series of Long-likely events\n",
    "# type(long_RL_results) # DynamicParameters\n",
    "long_LR_pf1D_Decoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d2363d",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "type(all_directional_decoder_dict_value)\n",
    "list(all_directional_decoder_dict_value.keys()) # ['long_LR', 'long_RL', 'short_LR', 'short_RL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634e6027",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "laps_all_epoch_bins_marginals_df\n",
    "laps_most_likely_direction_from_decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdabd71",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "type(ripple_result_tuple) # pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations.DirectionalRankOrderResult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fca534c",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "assert isinstance(ripple_result_tuple, DirectionalRankOrderResult) \n",
    "\n",
    "ripple_result_tuple.plot_histograms(num='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15629dae",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import DirectionalRankOrderResult\n",
    "from pyphocorehelpers.DataStructure.RenderPlots.MatplotLibRenderPlots import MatplotlibRenderPlots \n",
    "\n",
    "# @register_type_display(DirectionalRankOrderResult)\n",
    "def plot_histograms(self: DirectionalRankOrderResult, **kwargs) -> \"MatplotlibRenderPlots\":\n",
    "    \"\"\" \n",
    "    num='RipplesRankOrderZscore'\n",
    "    \"\"\"\n",
    "    print(f'.plot_histograms(..., kwargs: {kwargs})')\n",
    "    fig = plt.figure(layout=\"constrained\", **kwargs)\n",
    "    ax_dict = fig.subplot_mosaic(\n",
    "        [\n",
    "            [\"long_short_best_z_score_diff\", \"long_short_best_z_score_diff\"],\n",
    "            [\"long_best_z_scores\", \"short_best_z_scores\"],\n",
    "        ],\n",
    "    )\n",
    "    plots = (pd.DataFrame({'long_best_z_scores': self.long_best_dir_z_score_values}).hist(ax=ax_dict['long_best_z_scores'], bins=21, alpha=0.8),\n",
    "        pd.DataFrame({'short_best_z_scores': self.short_best_dir_z_score_values}).hist(ax=ax_dict['short_best_z_scores'], bins=21, alpha=0.8),\n",
    "        pd.DataFrame({'long_short_best_z_score_diff': self.long_short_best_dir_z_score_diff_values}).hist(ax=ax_dict['long_short_best_z_score_diff'], bins=21, alpha=0.8),\n",
    "    )\n",
    "    return MatplotlibRenderPlots(name='plot_histogram_figure', figures=[fig], axes=ax_dict)\n",
    "\n",
    "\n",
    "# register_type_display(plot_histograms, DirectionalRankOrderResult)\n",
    "## Call the newly added `plot_histograms` function on the `ripple_result_tuple` object which is of type `DirectionalRankOrderResult`:\n",
    "assert isinstance(ripple_result_tuple, DirectionalRankOrderResult) \n",
    "ripple_result_tuple.plot_histograms(num='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c291690",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "ripple_result_tuple.plot_histograms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b30bcb",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# 💾 CSVs \n",
    "print(f'\\t try saving to CSV...')\n",
    "merged_complete_epoch_stats_df = rank_order_results.ripple_merged_complete_epoch_stats_df ## New method\n",
    "merged_complete_epoch_stats_df\n",
    "merged_complete_ripple_epoch_stats_df_output_path = curr_active_pipeline.get_output_path().joinpath(f'{DAY_DATE_TO_USE}_merged_complete_epoch_stats_df.csv').resolve()\n",
    "merged_complete_epoch_stats_df.to_csv(merged_complete_ripple_epoch_stats_df_output_path)\n",
    "print(f'\\t saving to CSV: {merged_complete_ripple_epoch_stats_df_output_path} done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60749347",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "all",
     "active-2025-01-20"
    ]
   },
   "outputs": [],
   "source": [
    "print(f'\\tdone. building global result.')\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "selected_spikes_df = deepcopy(curr_active_pipeline.global_computation_results.computed_data['RankOrder'].LR_ripple.selected_spikes_df)\n",
    "# active_epochs = global_computation_results.computed_data['RankOrder'].ripple_most_likely_result_tuple.active_epochs\n",
    "active_epochs = deepcopy(curr_active_pipeline.global_computation_results.computed_data['RankOrder'].LR_ripple.epochs_df)\n",
    "track_templates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz)\n",
    "\n",
    "ripple_combined_epoch_stats_df, ripple_new_output_tuple = RankOrderAnalyses.pandas_df_based_correlation_computations(selected_spikes_df=selected_spikes_df, active_epochs_df=active_epochs, track_templates=track_templates, num_shuffles=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313886d9",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# new_output_tuple (output_active_epoch_computed_values, valid_stacked_arrays, real_stacked_arrays, n_valid_shuffles) = ripple_new_output_tuple\n",
    "curr_active_pipeline.global_computation_results.computed_data['RankOrder'].ripple_combined_epoch_stats_df, curr_active_pipeline.global_computation_results.computed_data['RankOrder'].ripple_new_output_tuple = ripple_combined_epoch_stats_df, ripple_new_output_tuple\n",
    "print(f'done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6f086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Display the `TrainTestSplitResult` in a `PhoPaginatedMultiDecoderDecodedEpochsWindow`\n",
    "from neuropy.core.epoch import Epoch, ensure_dataframe\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import add_laps_groundtruth_information_to_dataframe\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import PhoPaginatedMultiDecoderDecodedEpochsWindow\n",
    "\n",
    "## INPUTS: train_decoded_results_dict\n",
    "# decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs # looks like 'lap_dir' column is wrong\n",
    "\n",
    "# active_results: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(decoder_laps_filter_epochs_decoder_result_dict)\n",
    "active_results: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy({k:v.decoder_result for k, v in _out_separate_decoder_results[0].items()})\n",
    "\n",
    "laps_app, laps_paginated_multi_decoder_decoded_epochs_window, laps_pagination_controller_dict = PhoPaginatedMultiDecoderDecodedEpochsWindow.init_from_track_templates(curr_active_pipeline, track_templates,\n",
    "                            decoder_decoded_epochs_result_dict=active_results, epochs_name='laps', included_epoch_indicies=None, \n",
    "    params_kwargs={'enable_per_epoch_action_buttons': False,\n",
    "    'skip_plotting_most_likely_positions': False, 'skip_plotting_measured_positions': False, \n",
    "    # 'enable_decoded_most_likely_position_curve': False, 'enable_radon_transform_info': True, 'enable_weighted_correlation_info': False,\n",
    "    'enable_decoded_most_likely_position_curve': True, 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': False,\n",
    "    # 'disable_y_label': True,\n",
    "    # 'isPaginatorControlWidgetBackedMode': True,\n",
    "    # 'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True,\n",
    "    # 'debug_print': True,\n",
    "    'max_subplots_per_page': 10,\n",
    "    'scrollable_figure': True,\n",
    "    # 'posterior_heatmap_imshow_kwargs': dict(vmin=0.0075),\n",
    "    'use_AnchoredCustomText': False,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3d15bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_build_individual_time_bin_decoded_posteriors_df\n",
    "\n",
    "transfer_column_names_list: List[str] = ['maze_id', 'lap_dir', 'lap_id']\n",
    "filtered_laps_time_bin_marginals_df = _perform_build_individual_time_bin_decoded_posteriors_df(curr_active_pipeline, track_templates=track_templates, all_directional_laps_filter_epochs_decoder_result=all_directional_laps_filter_epochs_decoder_result, transfer_column_names_list=transfer_column_names_list)\n",
    "filtered_laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e0053b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import co_filter_epochs_and_spikes\n",
    "\n",
    "## INPUTS: all_directional_laps_filter_epochs_decoder_result\n",
    "transfer_column_names_list: List[str] = ['maze_id', 'lap_dir', 'lap_id']\n",
    "TIME_OVERLAP_PREVENTION_EPSILON: float = 1e-12\n",
    "(laps_directional_marginals_tuple, laps_track_identity_marginals_tuple, laps_non_marginalized_decoder_marginals_tuple), laps_marginals_df = all_directional_laps_filter_epochs_decoder_result.compute_marginals(epoch_idx_col_name='lap_idx', epoch_start_t_col_name='lap_start_t',\n",
    "                                                                                                                                                    additional_transfer_column_names=['start','stop','label','duration','lap_id','lap_dir','maze_id','is_LR_dir'])\n",
    "laps_directional_marginals, laps_directional_all_epoch_bins_marginal, laps_most_likely_direction_from_decoder, laps_is_most_likely_direction_LR_dir  = laps_directional_marginals_tuple\n",
    "laps_track_identity_marginals, laps_track_identity_all_epoch_bins_marginal, laps_most_likely_track_identity_from_decoder, laps_is_most_likely_track_identity_Long = laps_track_identity_marginals_tuple\n",
    "non_marginalized_decoder_marginals, non_marginalized_decoder_all_epoch_bins_marginal, most_likely_decoder_idxs, non_marginalized_decoder_all_epoch_bins_decoder_probs_df = laps_non_marginalized_decoder_marginals_tuple\n",
    "laps_time_bin_marginals_df: pd.DataFrame = all_directional_laps_filter_epochs_decoder_result.build_per_time_bin_marginals_df(active_marginals_tuple=(laps_directional_marginals, laps_track_identity_marginals, non_marginalized_decoder_marginals),\n",
    "                                                                                                                              columns_tuple=(['P_LR', 'P_RL'], ['P_Long', 'P_Short'], ['long_LR', 'long_RL', 'short_LR', 'short_RL']), transfer_column_names_list=transfer_column_names_list)\n",
    "laps_time_bin_marginals_df['start'] = laps_time_bin_marginals_df['start'] + TIME_OVERLAP_PREVENTION_EPSILON ## ENSURE NON-OVERLAPPING\n",
    "\n",
    "## INPUTS: laps_time_bin_marginals_df\n",
    "# active_min_num_unique_aclu_inclusions_requirement: int = track_templates.min_num_unique_aclu_inclusions_requirement(curr_active_pipeline, required_min_percentage_of_active_cells=0.33333333333333)\n",
    "active_min_num_unique_aclu_inclusions_requirement = None # must be none for individual `time_bin` periods\n",
    "filtered_laps_time_bin_marginals_df, active_spikes_df = co_filter_epochs_and_spikes(active_spikes_df=get_proper_global_spikes_df(curr_active_pipeline, minimum_inclusion_fr_Hz=curr_active_pipeline.global_computation_config.rank_order_shuffle_analysis.minimum_inclusion_fr_Hz),\n",
    "                                                                  active_epochs_df=laps_time_bin_marginals_df, included_aclus=track_templates.any_decoder_neuron_IDs, min_num_unique_aclu_inclusions=active_min_num_unique_aclu_inclusions_requirement,\n",
    "                                                                epoch_id_key_name='lap_individual_time_bin_id', no_interval_fill_value=-1, add_unique_aclus_list_column=True, drop_non_epoch_spikes=True)\n",
    "filtered_laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff8fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean and max number of active aclus per time bin for each epoch (lap)\n",
    "filtered_laps_time_bin_marginals_df.groupby(['lap_id']).agg(n_unique_aclus_mean=('n_unique_aclus', 'mean'), n_unique_aclus_max=('n_unique_aclus', 'max')).reset_index()\n",
    "filtered_laps_time_bin_marginals_df.groupby(['maze_id']).agg(n_unique_aclus_mean=('n_unique_aclus', 'mean'), n_unique_aclus_max=('n_unique_aclus', 'max')).reset_index() ## per maze\n",
    "filtered_laps_time_bin_marginals_df.groupby(['maze_id', 'lap_dir']).agg(n_unique_aclus_mean=('n_unique_aclus', 'mean'), n_unique_aclus_max=('n_unique_aclus', 'max')).reset_index() # per maze x lap_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e6cdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cb39d3",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# {frozenset({('desired_shared_decoding_time_bin_size', 0.025), ('minimum_event_duration', 0.05), ('use_single_time_bin_per_epoch', False)}): 0.025,\n",
    "#  frozenset({('desired_shared_decoding_time_bin_size', 0.03), ('minimum_event_duration', 0.05), ('use_single_time_bin_per_epoch', False)}): 0.03,\n",
    "#  frozenset({('desired_shared_decoding_time_bin_size', 0.044), ('minimum_event_duration', 0.05), ('use_single_time_bin_per_epoch', False)}): 0.044,\n",
    "#  frozenset({('desired_shared_decoding_time_bin_size', 0.05), ('minimum_event_duration', 0.05), ('use_single_time_bin_per_epoch', False)}): 0.05}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d4ce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_trial_by_trial_result.directional_active_lap_pf_results_dicts\n",
    "a_trial_by_trial_result.directional_lap_epochs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944c59a0",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "several_time_bin_sizes_ripple_df\n",
    "\n",
    "ripple_out_path # 'K:/scratch/collected_outputs/2024-07-05-kdiba_gor01_two_2006-6-07_16-40-19__withNewKamranExportedReplays-(ripple_marginals_df).csv'\n",
    "# 'K:/scratch/collected_outputs/2024-07-05-kdiba_gor01_two_2006-6-07_16-40-19__withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-(ripple_marginals_df).csv'\n",
    "several_time_bin_sizes_time_bin_ripple_df\n",
    "\n",
    "ripple_time_bin_marginals_out_path # 'K:/scratch/collected_outputs/2024-07-05-kdiba_gor01_two_2006-6-07_16-40-19__withNewKamranExportedReplays-(ripple_time_bin_marginals_df).csv'\n",
    "# 'K:/scratch/collected_outputs/2024-07-05-kdiba_gor01_two_2006-6-07_16-40-19__withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-(ripple_time_bin_marginals_df).csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2dfa3e",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "v: DecoderDecodedEpochsResult = list(output_directional_decoders_epochs_decode_results_dict.values())[0]\n",
    "v.add_all_extra_epoch_columns(curr_active_pipeline=curr_active_pipeline, track_templates=track_templates)\n",
    "# _out = v.export_csvs(parent_output_path=collected_outputs_path, active_context=curr_active_pipeline.get_session_context(), session_name=curr_active_pipeline.session_name, curr_session_t_delta=t_delta)\n",
    "\n",
    "# assert self.collected_outputs_path.exists()\n",
    "# curr_session_name: str = curr_active_pipeline.session_name # '2006-6-08_14-26-15'\n",
    "# CURR_BATCH_OUTPUT_PREFIX: str = f\"{self.BATCH_DATE_TO_USE}-{curr_session_name}\"\n",
    "# print(f'CURR_BATCH_OUTPUT_PREFIX: {CURR_BATCH_OUTPUT_PREFIX}')\n",
    "\n",
    "# from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_extended_computations\n",
    "# curr_active_pipeline.reload_default_computation_functions()\n",
    "# batch_extended_computations(curr_active_pipeline, include_includelist=['merged_directional_placefields'], include_global_functions=True, fail_on_exception=True, force_recompute=False)\n",
    "# directional_merged_decoders_result = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "\n",
    "# active_context = curr_active_pipeline.get_session_context()\n",
    "# _out = directional_merged_decoders_result.compute_and_export_marginals_df_csvs(parent_output_path=self.collected_outputs_path, active_context=active_context)\n",
    "# print(f'successfully exported marginals_df_csvs to {self.collected_outputs_path}!')\n",
    "# (laps_marginals_df, laps_out_path), (ripple_marginals_df, ripple_out_path) = _out\n",
    "# (laps_marginals_df, laps_out_path, laps_time_bin_marginals_df, laps_time_bin_marginals_out_path), (ripple_marginals_df, ripple_out_path, ripple_time_bin_marginals_df, ripple_time_bin_marginals_out_path) = _out\n",
    "# print(f'\\tlaps_out_path: {laps_out_path}\\n\\tripple_out_path: {ripple_out_path}\\n\\tdone.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58b6311",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa94d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "_across_session_results_extended_dict['perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260a8b74",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "## Take extra computations from `_decode_and_evaluate_epochs_using_directional_decoders` and integrate into the multi-time-bin results from `perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _compute_all_df_score_metrics\n",
    "\n",
    "should_skip_radon_transform = True\n",
    "## Recompute the epoch scores/metrics such as radon transform and wcorr:\n",
    "\n",
    "a_sweep_tuple, a_pseudo_2D_result = list(output_full_directional_merged_decoders_result.items())[0]\n",
    "a_decoder_laps_filter_epochs_decoder_result_dict = deepcopy(a_pseudo_2D_result.all_directional_laps_filter_epochs_decoder_result)\n",
    "a_decoder_ripple_filter_epochs_decoder_result_dict = deepcopy(a_pseudo_2D_result.all_directional_ripple_filter_epochs_decoder_result)\n",
    "\n",
    "(decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict), merged_df_outputs_tuple, raw_dict_outputs_tuple = _compute_all_df_score_metrics(directional_merged_decoders_result, track_templates,\n",
    "                                                                                                                                                                                    decoder_laps_filter_epochs_decoder_result_dict=a_decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict=a_decoder_ripple_filter_epochs_decoder_result_dict,\n",
    "                                                                                                                                                                                    spikes_df=deepcopy(curr_active_pipeline.sess.spikes_df),\n",
    "                                                                                                                                                                                    should_skip_radon_transform=should_skip_radon_transform)\n",
    "laps_radon_transform_merged_df, ripple_radon_transform_merged_df, laps_weighted_corr_merged_df, ripple_weighted_corr_merged_df, laps_simple_pf_pearson_merged_df, ripple_simple_pf_pearson_merged_df = merged_df_outputs_tuple\n",
    "decoder_laps_radon_transform_df_dict, decoder_ripple_radon_transform_df_dict, decoder_laps_radon_transform_extras_dict, decoder_ripple_radon_transform_extras_dict, decoder_laps_weighted_corr_df_dict, decoder_ripple_weighted_corr_df_dict = raw_dict_outputs_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfda868",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# `_perform_compute_custom_epoch_decoding`\n",
    "\n",
    "a_sweep_tuple\n",
    "# a_pseudo_2D_result.all_directional_laps_filter_epochs_decoder_result\n",
    "# a_pseudo_2D_result\n",
    "# a_pseudo_2D_result.short_directional_decoder_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9603a0",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# print_keys_if_possible('several_time_bin_sizes_laps_df', several_time_bin_sizes_laps_df)\n",
    "print_keys_if_possible('output_full_directional_merged_decoders_result', output_full_directional_merged_decoders_result, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a71abd",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# get_file_pat\n",
    "collected_outputs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c0f606",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "output_laps_decoding_accuracy_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dd6f87",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# from neuropy.utils.matplotlib_helpers import pho_jointplot\n",
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import pho_jointplot, plot_histograms\n",
    "sns.set_theme(style=\"ticks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4b238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# from neuropy.utils.matplotlib_helpers import pho_jointplot\n",
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import pho_jointplot, plot_histograms\n",
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "# def pho_jointplot(*args, **kwargs):\n",
    "# \t\"\"\" wraps sns.jointplot to allow adding titles/axis labels/etc.\"\"\"\n",
    "# \ttitle = kwargs.pop('title', None)\n",
    "# \t_out = sns.jointplot(*args, **kwargs)\n",
    "# \tif title is not None:\n",
    "# \t\tplt.suptitle(title)\n",
    "# \treturn _out\n",
    "\n",
    "common_kwargs = dict(ylim=(0,1), hue='time_bin_size') # , marginal_kws=dict(bins=25, fill=True)\n",
    "# sns.jointplot(data=a_laps_all_epoch_bins_marginals_df, x='lap_start_t', y='P_Long', kind=\"scatter\", color=\"#4CB391\")\n",
    "pho_jointplot(data=several_time_bin_sizes_laps_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Laps: per epoch') #color=\"#4CB391\")\n",
    "pho_jointplot(data=several_time_bin_sizes_ripple_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Ripple: per epoch')\n",
    "pho_jointplot(data=several_time_bin_sizes_time_bin_ripple_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Ripple: per time bin')\n",
    "pho_jointplot(data=several_time_bin_sizes_time_bin_laps_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Laps: per time bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43311ee",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import plot_histograms\n",
    "\n",
    "# You can use it like this:\n",
    "plot_histograms('Laps', 'One Session', several_time_bin_sizes_time_bin_laps_df, \"several\")\n",
    "plot_histograms('Ripples', 'One Session', several_time_bin_sizes_time_bin_ripple_df, \"several\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a33b924",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "several_time_bin_sizes_ripple_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2a9d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.displot(\n",
    "#     several_time_bin_sizes_laps_df, x=\"P_Long\", col=\"species\", row=\"time_bin_size\",\n",
    "#     binwidth=3, height=3, facet_kws=dict(margin_titles=True),\n",
    "# )\n",
    "\n",
    "sns.displot(\n",
    "    several_time_bin_sizes_laps_df, x='delta_aligned_start_t', y='P_Long', row=\"time_bin_size\",\n",
    "    binwidth=3, height=3, facet_kws=dict(margin_titles=True),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495ef2bb",
   "metadata": {},
   "source": [
    "# <a id='toc7_'></a>[🎨 2024-02-06 - Other Plotting](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5623a2",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": [
     "all",
     "run-group-display",
     "run-spike_raster_window_test",
     "run-2025-04-11_full-session_marginals",
     "run-display-launcher-widget",
     "run-group-mergedcolorplot"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.TimeSynchronizedPlacefieldsPlotter import TimeSynchronizedPlacefieldsPlotter\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import FileOutputManager\n",
    "\n",
    "# For PlotWidget\n",
    "pg.setConfigOptions(useOpenGL=True)\n",
    "\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "\n",
    "#  Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "curr_active_pipeline.prepare_for_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83293544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots\n",
    "\n",
    "_out = batch_perform_all_plots(curr_active_pipeline, debug_print=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f299f5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import BatchPhoJonathanFiguresHelper\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import FileOutputManager\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import BatchPlotting\n",
    "from neuropy.plotting.ratemaps import BackgroundRenderingOptions\n",
    "\n",
    "\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "mpl.rcParams['toolbar'] = 'None' # disable toolbars\n",
    "matplotlib.use('AGG') # non-interactive backend ## 2022-08-16 - Surprisingly this works to make the matplotlib figures render only to .png file, not appear on the screen!\n",
    "\n",
    "if BatchPlotting._fig_out_man is None:\n",
    "    collected_figures_folder, fig_out_man = BatchPlotting.find_batch_programmatic_figures_output_dir()\n",
    "    assert fig_out_man is not None\n",
    "\n",
    "out_man: FileOutputManager = deepcopy(BatchPlotting._fig_out_man) # curr_active_pipeline.get_output_manager(figure_output_location=FigureOutputLocation.CUSTOM, context_to_path_mode=ContextToPathMode.GLOBAL_UNIQUE, override_output_parent_path=collected_outputs_path)\n",
    "_batch_figure_kwargs = dict(override_fig_man=out_man,\n",
    "                            #  write_vector_format=False, write_png=True,\n",
    "                            write_vector_format=True, write_png=False,\n",
    "                            )\n",
    "\n",
    "\n",
    "## Exports all cells to the `BatchPhoJonathanFiguresHelper` but without the top part:\n",
    "# PhoJonathan Results:\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "jonathan_firing_rate_analysis_result = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis\n",
    "neuron_replay_stats_df, short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset = jonathan_firing_rate_analysis_result.get_cell_track_partitions(frs_index_inclusion_magnitude=0.2)\n",
    "## all cells:\n",
    "included_cells = [55, # SxC\n",
    "                  \n",
    "]\n",
    "fig_1c_figures_all_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, included_unit_neuron_IDs=included_cells, n_max_page_rows=20, show_only_refined_cells=False, disable_top_row=True, **_batch_figure_kwargs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9f8e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = dict()\n",
    "_out['_display_directional_template_debugger'] = curr_active_pipeline.display(display_function='_display_directional_template_debugger', active_session_configuration_context=None) # _display_directional_template_debugger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86d59de",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968df7ce",
   "metadata": {
    "tags": [
     "all",
     "run-display-launcher-widget"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Display import DisplayFunctionItem\n",
    "from pyphocorehelpers.gui.Qt.tree_helpers import find_tree_item_by_text\n",
    "from pyphoplacecellanalysis.GUI.Qt.MainApplicationWindows.LauncherWidget.LauncherWidget import LauncherWidget\n",
    "\n",
    "widget = LauncherWidget()\n",
    "# widget.debug_print = True\n",
    "treeWidget = widget.mainTreeWidget # QTreeWidget\n",
    "widget.build_for_pipeline(curr_active_pipeline=curr_active_pipeline)\n",
    "widget.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b14728",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_trial_by_trial_activity_result: TrialByTrialActivityResult = curr_active_pipeline.global_computation_results.computed_data.pop('TrialByTrialActivity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b338e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "_out = dict()\n",
    "_out['_display_trial_to_trial_reliability'] = curr_active_pipeline.display(display_function='_display_trial_to_trial_reliability', active_session_configuration_context=None) # _display_trial_to_trial_reliability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e3c30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsWidgets.EpochsEditorItem import EpochsEditor # perform_plot_laps_diagnoser\n",
    "\n",
    "_out = dict()\n",
    "_out['_display_directional_laps_overview'] = curr_active_pipeline.display(display_function='_display_directional_laps_overview', active_session_configuration_context=None) # _display_directional_laps_overview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939504b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.TemplateDebugger import TemplateDebugger\n",
    "\n",
    "pg.setConfigOption('background', 'w')\n",
    "pg.setConfigOption('foreground', 'k')\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "_out = dict()\n",
    "_out['_display_directional_template_debugger'] = curr_active_pipeline.display(display_function='_display_directional_template_debugger', active_session_configuration_context=None,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  use_incremental_sorting=True, prepare_for_publication=True) # _display_directional_template_debugger\n",
    "graphics_output_dict = _out['_display_directional_template_debugger']\n",
    "\n",
    "template_debugger: TemplateDebugger = graphics_output_dict['obj']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6d3186",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_debugger.sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24116c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_export_dict = template_debugger.save_figure(shared_output_file_prefix = f'output/2025-07-23') ## #TODO 2025-07-21 11:58: - [ ] Kinda works, but has a black background and bad text sizes and stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787749da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2010ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53a5ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "6 * 300  # 1800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962c7e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.External.pyqtgraph.exporters.SVGExporter import SVGExporter\n",
    "\n",
    "shared_output_file_prefix = f'output/2025-07-22'\n",
    "_out_pf1D_heatmaps = template_debugger.plots.pf1D_heatmaps\n",
    "# _out_pf1D_heatmaps = graphics_output_dict['plots']\n",
    "for a_decoder_name, a_decoder_heatmap_tuple in _out_pf1D_heatmaps.items():\n",
    "    a_win, a_img = a_decoder_heatmap_tuple\n",
    "    # a_win.export_image(f'{a_decoder_name}_heatmap.png')\n",
    "    print(f'a_win: {type(a_win)}')\n",
    "    # save to file\n",
    "    export_file_path = Path(f'{shared_output_file_prefix}_test_{a_decoder_name}_heatmap').with_suffix('.svg').resolve() # '.svg' # .resolve()\n",
    "    # export_file_path = Path(f'{shared_output_file_prefix}_test_{a_decoder_name}_heatmap').with_suffix('.png').resolve() # '.svg' # .resolve()\n",
    "    export_pyqtgraph_plot(a_win.plotItem, savepath=export_file_path) # works\n",
    "    print(f'exporting to {export_file_path}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecb64e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdbabf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "\n",
    "override_laps_df: Optional[pd.DataFrame] = UserAnnotationsManager.get_hardcoded_laps_override_dict().get(curr_active_pipeline.get_session_context(), None)\n",
    "if override_laps_df is not None:\n",
    "    print(f'overriding laps....')\n",
    "    display(override_laps_df)\n",
    "    did_any_change = curr_active_pipeline.override_laps(override_laps_df=override_laps_df, debug_print=True)\n",
    "    print(f'did_any_change: {did_any_change}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe53ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from neuropy.core.laps import Laps\n",
    "\n",
    "user_labeled_laps_df: pd.DataFrame = deepcopy(UserAnnotationsManager.get_hardcoded_laps_override_dict()[curr_active_pipeline.get_session_context()])\n",
    "user_labeled_laps_df['lap_id'] = user_labeled_laps_df.index + 1\n",
    "user_labeled_laps_df['label'] = user_labeled_laps_df.index\n",
    "## OUTPUTS: user_labeled_laps_df\n",
    "## INPUTS: user_labeled_laps_df\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "user_labeled_laps: Laps = Laps(laps=user_labeled_laps_df)\n",
    "user_labeled_laps.update_lap_dir_from_smoothed_velocity(pos_input=curr_active_pipeline.sess.position)\n",
    "user_labeled_laps.update_maze_id_if_needed(t_start=t_start, t_delta=t_delta, t_end=t_end)\n",
    "user_labeled_laps_df = user_labeled_laps.to_dataframe()\n",
    "\n",
    "user_labeled_laps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31506be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_labeled_laps_df.laps_accessor.to_Laps_obj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcbc3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_labeled_laps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df185a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_labeled_laps_df.laps_accessor.compute_lap_dir_from_net_displacement(global_session=curr_active_pipeline.sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388cdb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add in corrected columns to laps_df:\n",
    "user_labeled_laps_df = user_labeled_laps_df.merge(lap_displacement_df[['lap', 'is_LR_dir', 'lap_dir']], left_on='lap_id', right_on='lap', how='left')\n",
    "user_labeled_laps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e00486",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsWidgets.EpochsEditorItem import EpochsEditor # perform_plot_laps_diagnoser\n",
    "\n",
    "new_epochs_editor: EpochsEditor = EpochsEditor.init_laps_diagnoser(pos_df=curr_active_pipeline.sess.position.to_dataframe(), curr_laps_df=user_labeled_laps_df)\n",
    "new_epochs_editor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d1a3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsWidgets.EpochsEditorItem import EpochsEditor # perform_plot_laps_diagnoser\n",
    "\n",
    "new_epochs_editor: EpochsEditor = EpochsEditor.init_laps_diagnoser(pos_df=curr_active_pipeline.sess.position.to_dataframe(), curr_laps_df=curr_active_pipeline.sess.laps.to_dataframe())\n",
    "new_epochs_editor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e798969",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the user-updated laps from the EpochsEditor\n",
    "user_labeled_laps_df: pd.DataFrame = deepcopy(new_epochs_editor.get_user_labeled_epochs_df())\n",
    "user_labeled_laps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32119566",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_labeled_laps_df[['start', 'stop', 'lap_dir']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22ef94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsWidgets.EpochsEditorItem import EpochsEditor # perform_plot_laps_diagnoser\n",
    "_out = curr_active_pipeline.display_output[IdentifyingContext(format_name= 'kdiba', animal= 'gor01', exper_name= 'one', session_name= '2006-6-07_11-26-53', display_fn_name= '_display_directional_laps_overview')]\n",
    "_epochs_editor: EpochsEditor = _out['ui'][0]\n",
    "_epochs_editor\n",
    "# type(_out)\n",
    "# list(_out.keys())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282d952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_epochs_editor.set_user_labeled_epochs_df(user_labeled_laps_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7b57a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the user-updated laps from the EpochsEditor\n",
    "user_labeled_laps_df: pd.DataFrame = deepcopy(_epochs_editor.get_user_labeled_epochs_df())\n",
    "user_labeled_laps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e33a32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7543010",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_labeled_laps_df.iloc[9, 'is_LR_dir'] = False \n",
    "\n",
    "\n",
    "user_labeled_laps_df['is_LR_dir'].iloc[9] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6354d9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_labeled_laps_df = user_labeled_laps_df.sort_values(by=['start', 'stop'], ascending=True, axis='index', ignore_index=True)\n",
    "user_labeled_laps_df['lap_id'] = user_labeled_laps_df.index\n",
    "user_labeled_laps_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35bf402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_df = curr_active_pipeline.sess.position.to_dataframe()\n",
    "\n",
    "pos_df = global_session.position.to_dataframe()\n",
    "_new_epoch_editor: EpochsEditor = EpochsEditor.init_laps_diagnoser(pos_df=pos_df, curr_laps_df=user_labeled_laps_df)\n",
    "_new_epoch_editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161e7bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.get_session_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc740956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_labeled_laps_df[['start', 'stop', 'lap_dir']].to_clipboard(excel=True, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950e3c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_labeled_laps_df[['start', 'stop', 'lap_dir']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab95f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.gui.Qt.color_helpers import ColormapHelpers\n",
    "from pyphoplacecellanalysis.External.pyqtgraph_extensions.graphicsItems.LabelItem.ClickableLabelItem import SelectableLabelItem\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.TrialByTrialActivityWindow import TrialByTrialActivityWindow\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "cmap = ColormapHelpers.create_transparent_colormap(cmap_name='Reds', lower_bound_alpha=0.01, should_return_LinearSegmentedColormap=False)\n",
    "cmap\n",
    "\n",
    "_out = dict()\n",
    "pg.setConfigOption('antialias', False)\n",
    "_out['_display_trial_to_trial_reliability'] = curr_active_pipeline.display(display_function='_display_trial_to_trial_reliability', active_session_configuration_context=None, cmap=cmap, is_publication_ready_figure=True) # _display_trial_to_trial_reliability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a879f8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out['_display_trial_to_trial_reliability'] #.plots['main_graphics_layout_widget']\n",
    "# _out['_display_trial_to_trial_reliability'].plots['root_render_widget']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb7ca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_to_trial_reliability_save_path = Path('data').joinpath('trial_to_trial_reliability.svg').resolve()\n",
    "\n",
    "export_pyqtgraph_plot(_out['_display_trial_to_trial_reliability'].plots['root_render_widget'], savepath=trial_to_trial_reliability_save_path) # works\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e56dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = dict()\n",
    "_out['_display_pf_peak_prominence2d_plots'] = curr_active_pipeline.display(display_function='_display_pf_peak_prominence2d_plots', active_session_configuration_context=IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43',filter_name='maze2_odd',lap_dir='odd'),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   neuron_id=8) # _display_pf_peak_prominence2d_plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990d7f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b653dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out['_display_directional_laps_overview'] = curr_active_pipeline.display(display_function='_display_directional_laps_overview', active_session_configuration_context=None) # _display_directional_laps_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df692641",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams\n",
    "# set_yticklabels\n",
    "\n",
    "# Set major tick label size for both x and y axes\n",
    "# ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "matplotlib.rc('xtick', labelsize=5)\n",
    "matplotlib.rc('ytick', labelsize=5)\n",
    "mpl.rcParams['font.family'] = 'Arial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8a5ca1",
   "metadata": {
    "tags": [
     "run-group-publication"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.plotting.ratemaps import plot_ratemap_1D\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out = dict()\n",
    "\n",
    "fig1_common_kwargs = dict(save_figure=True, write_vector_format=True, write_png=False, prepare_for_publication=True, bbox_inches='tight', pad_inches=0, aclu_labels_strokewidth=1)\n",
    "_out['_display_directional_track_template_pf1Ds'] = curr_active_pipeline.display(display_function='_display_directional_track_template_pf1Ds', active_session_configuration_context=None, **fig1_common_kwargs) # _display_directional_track_template_pf1Ds\n",
    "_out['_display_directional_track_template_pf1Ds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9705d6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for decoder_name, an_ax in _out['_display_directional_track_template_pf1Ds'].axes_dict.items():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce79ac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import perform_add_1D_track_bounds_lines\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "_out = dict()\n",
    "_out['_display_grid_bin_bounds_validation_x'] = curr_active_pipeline.display(display_function='_display_grid_bin_bounds_validation', active_session_configuration_context=None, is_x_axis=True) # _display_grid_bin_bounds_validation\n",
    "_out['_display_grid_bin_bounds_validation_y'] = curr_active_pipeline.display(display_function='_display_grid_bin_bounds_validation', active_session_configuration_context=None, is_x_axis=False) # _display_grid_bin_bounds_validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465a1575",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfd3606",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out = dict()\n",
    "_out['_display_directional_track_remapping_diagram'] = curr_active_pipeline.display(display_function='_display_directional_track_remapping_diagram', active_session_configuration_context=None, draw_point_aclu_labels=True, use_unique_aclu_colors=False, write_vector_format=True,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t) # _display_grid_bin_bounds_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad8ae03",
   "metadata": {},
   "source": [
    "### Plots the tracks with the vertical long/short platform lines overlayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048f6f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import test_LinearTrackDimensions_2D_Matplotlib, add_vertical_track_bounds_lines\n",
    "\n",
    "session_cm_grid_bin_bounds = UserAnnotationsManager.get_hardcoded_specific_session_override_dict()[curr_active_pipeline.get_session_context()]['cm_grid_bin_bounds']\n",
    "session_cm_grid_bin_bounds = BoundsRect.init_from_grid_bin_bounds(session_cm_grid_bin_bounds)\n",
    "session_cm_grid_bin_bounds\n",
    "\n",
    "x_mid, y_mid = session_cm_grid_bin_bounds.center_point\n",
    "\n",
    "long_offset = (x_mid, y_mid)\n",
    "short_offset = (x_mid, y_mid)\n",
    "fig, ax1, ax2 = test_LinearTrackDimensions_2D_Matplotlib(long_offset=long_offset, short_offset=short_offset)\n",
    "\n",
    "grid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\n",
    "long_track_line_collection, short_track_line_collection = add_vertical_track_bounds_lines(grid_bin_bounds=deepcopy(long_pf2D.config.grid_bin_bounds), ax=ax1)\n",
    "long_track_line_collection, short_track_line_collection = add_vertical_track_bounds_lines(grid_bin_bounds=deepcopy(short_pf2D.config.grid_bin_bounds), ax=ax2)\n",
    "\n",
    "# long_notable_x_platform_positions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d59b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722390a6",
   "metadata": {
    "tags": [
     "run-group-publication"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import CellFieldRemappingModels\n",
    "\n",
    "# LS_pf_peak_x_diff = ['LS_pf_peak_x_diff']\n",
    "# active_scatter_all_neuron_stats_table[['long_LR_pf1D_peak', 'long_RL_pf1D_peak']]\n",
    "# active_scatter_all_neuron_stats_table[['short_LR_pf1D_peak', 'short_RL_pf1D_peak', 'peak_diff_LR_pf1D_peak', 'peak_diff_RL_pf1D_peak']]\n",
    "\n",
    "all_neuron_stats_table: pd.DataFrame = AcrossSessionsResults.build_neuron_identities_df_for_CSV(curr_active_pipeline=curr_active_pipeline)\n",
    "active_scatter_all_neuron_stats_table = CellFieldRemappingModels.fix_has_considerable_remapping_column(all_neuron_stats_table=all_neuron_stats_table)\n",
    "active_scatter_all_neuron_stats_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4dcfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_errors, best_model_name = CellFieldRemappingModels.main_evaluate_remapping_models(active_scatter_all_neuron_stats_table=active_scatter_all_neuron_stats_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1a371c",
   "metadata": {
    "tags": [
     "run-group-publication"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsResults # for .build_neuron_identities_df_for_CSV\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PhoPublicationFigureHelper\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import TrackRemappingDiagramFigure\n",
    "\n",
    "# 2025-06-09 18:22 - Added combined output helper:        \n",
    "# all_neuron_stats_table: pd.DataFrame = AcrossSessionsResults.build_neuron_identities_df_for_CSV(curr_active_pipeline=curr_active_pipeline)\n",
    "# active_scatter_all_neuron_stats_table: pd.DataFrame = deepcopy(all_neuron_stats_table).fillna(value=np.nan, inplace=False) ## fill all Pandas.NA values with np.nan so they can be correctly cast to floats\n",
    "# active_scatter_all_neuron_stats_table\n",
    "\n",
    "## INPUTS: active_scatter_all_neuron_stats_table\n",
    "use_pf2D_peaks: bool = False\n",
    "\n",
    "_fig_container = TrackRemappingDiagramFigure.plot_publication_bidirectional_track_remapping_diagram(all_neuron_stats_table=active_scatter_all_neuron_stats_table,\n",
    "    use_pf2D_peaks=use_pf2D_peaks, use_considerable_remapping_cells_only=False,\n",
    "    # common_circle_points_kwargs = dict(alpha=0.9, picker=False, plotnonfinite=False),\n",
    "    # common_BOTH_only_circle_points_kwargs = dict(alpha=0.6, picker=False, plotnonfinite=False, marker='o', zorder=9),\t\n",
    "    common_circle_points_kwargs = dict(alpha=0.9, picker=False, plotnonfinite=False, linewidths=0),\n",
    "    common_BOTH_only_circle_points_kwargs = dict(alpha=0.9, picker=False, plotnonfinite=False, marker='d', zorder=9),\t\t\n",
    "\n",
    "    # arrowprops_kwargs = dict(arrowstyle=\"fancy, head_length=0.25, head_width=0.25, tail_width=0.05\", alpha=0.6, zorder=1),\n",
    "    # arrowprops_kwargs = dict(arrowstyle=\"fancy, head_length=0.9, head_width=0.25, tail_width=0.01\", alpha=0.6, zorder=1),\n",
    "    # arrowprops_kwargs = dict(arrowstyle=\"fancy, head_length=0.25, head_width=0.25, tail_width=0.05\", mutation_scale=1, alpha=0.6, zorder=1),\n",
    "    arrowprops_kwargs = dict(arrowstyle=\"simple\", lw=0.01, alpha=0.6, zorder=1), # , mutation_scale=10\n",
    "\t\n",
    "    # base_1D_height = 1.0, top_bottom_padding = 0.025,  intra_track_y_spacing = 0.05, scatter_point_size = 15.0, # Defaults\n",
    "    base_1D_height = 1.0, top_bottom_padding = 0.2125,  intra_track_y_spacing = 0.25, scatter_point_size = 7.0, # Smaller\n",
    "    base_platform_additive_height = 0.1, long_height_multiplier = 1.0, common_1D_platform_height = 0.25, common_1D_track_height = 0.1, track_to_baseline_padding = 0.05,\n",
    "\tedgecolors = \"#00000000\", # should be provided here and not within `common_circle_points_kwargs` or `common_BOTH_only_circle_points_kwargs` because the real edgecolors need to have one value for each point \n",
    "\t\n",
    "    considerable_remapping_emphasis_color='red',\n",
    "    # considerable_remapping_emphasis_color=None,\n",
    "    write_vector_format=True,\n",
    "\tskip_RL_direction_tracks=True,\n",
    ")\n",
    "_fig_container\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043e463b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_fig_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b8f357",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89837555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalDisplayFunctions\n",
    "\n",
    "collector = DirectionalPlacefieldGlobalDisplayFunctions._display_directional_track_remapping_diagram(owning_pipeline_reference=curr_active_pipeline, global_computation_results=curr_active_pipeline.global_computation_results, computation_results=None, active_configs=None, save_figure=False, is_dark_mode=False)\n",
    "collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20264629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PAPER_FIGURE_figure_1_full\n",
    "\n",
    "pf1d_compare_graphics, (example_epoch_rasters_L, example_epoch_rasters_S), example_stacked_epoch_graphics, fig_1c_figures_out_dict = PAPER_FIGURE_figure_1_full(curr_active_pipeline, prepare_for_publication=True, write_vector_format=True) # did not display the pf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5507c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out = dict()\n",
    "_out['_display_pf_peak_prominence2d_plots'] = curr_active_pipeline.display(display_function='_display_pf_peak_prominence2d_plots', active_session_configuration_context=IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43',filter_name='maze1_odd',lap_dir='odd')) # _display_pf_peak_prominence2d_plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cb9f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out['3d_interactive_spike_and_behavior_browser'] = curr_active_pipeline.display(display_function='_display_3d_interactive_spike_and_behavior_browser', active_session_configuration_context=None) # _display_grid_bin_bounds_validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9039fb3",
   "metadata": {},
   "source": [
    "#### 2025-06-26 - InteractivePlaceCellDataExplorer with Long & Short Placefields - Not Finished\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f90de3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.InteractivePlaceCellDataExplorer import InteractivePlaceCellDataExplorer\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out = {}\n",
    "global_any_context = curr_active_pipeline.filtered_contexts[global_any_name]\n",
    "_out['_display_3d_interactive_tuning_curves_plotter'] = curr_active_pipeline.display(display_function='_display_3d_interactive_tuning_curves_plotter', active_session_configuration_context=global_any_context,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t separate_window = False,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t params_kwargs={'show_legend': False, 'should_display_placefield_points': False, 'should_nan_non_visited_elements': False, 'zScalingFactor': 500.0, 'debug_print': False},\n",
    "                                                                                    #  panel_controls_mode = 'Panel',\n",
    "                                                                                    # panel_controls_mode = 'Qt',\n",
    "                                                                                    panel_controls_mode = None,\n",
    "                                                                                    # debug_print=False,\n",
    "                                                                                    ) # _display_grid_bin_bounds_validation\n",
    "\n",
    "\n",
    "## Move the long-maze to -`maze_y_offset` units and the short-maze to +`maze_y_offset` units along the y-axis \n",
    "ipcDataExplorer: InteractivePlaceCellDataExplorer = _out['_display_3d_interactive_tuning_curves_plotter']['ipcDataExplorer']\n",
    "pActiveTuningCurvesPlotter = _out['_display_3d_interactive_tuning_curves_plotter']['plotter']\n",
    "pane = _out['_display_3d_interactive_tuning_curves_plotter']['pane']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbaf985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import LongShort3DPlacefieldsHelpers\n",
    "\n",
    "pane = LongShort3DPlacefieldsHelpers._plot_long_short_placefields(ipcDataExplorer=ipcDataExplorer, long_pf2D=long_pf2D, short_pf2D=short_pf2D, maze_y_offset=20.0)\n",
    "# ipcDataExplorer.p.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace9a90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in ipcDataExplorer.plots.tuningCurvePlotActors.items():\n",
    "    v.SetVisibility(0)\n",
    "    peaks = v.get('peaks', None)\n",
    "    if peaks:\n",
    "        peaks.SetVisibility(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ipcDataExplorer.plots_data['tuningCurvePlotData']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c056786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipcDataExplorer.plots.tuningCurvePlotActors[3]['long']['peaks']\n",
    "# ipcDataExplorer.plots.tuningCurvePlotActors[3]['peaks'].SetVisibility(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2eb151",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import LongShort3DPlacefieldsHelpers\n",
    "\n",
    "# active_config_name: str = short_epoch_name # 'maze_any'\n",
    "# print(f'active_config_name: {active_config_name}')\n",
    "# active_peak_prominence_2d_results = curr_active_pipeline.computation_results[active_config_name].computed_data.get('RatemapPeaksAnalysis', {}).get('PeakProminence2D', None)\n",
    "\n",
    "# # pActiveTuningCurvesPlotter = None\n",
    "# # display_output = display_output | curr_active_pipeline.display('_display_3d_interactive_tuning_curves_plotter', active_config_name, extant_plotter=display_output.get('pActiveTuningCurvesPlotter', None), panel_controls_mode='Qt', should_nan_non_visited_elements=False, zScalingFactor=2000.0) # Works now!\n",
    "# # ipcDataExplorer = display_output['ipcDataExplorer']\n",
    "# # display_output['pActiveTuningCurvesPlotter'] = display_output.pop('plotter') # rename the key from the generic \"plotter\" to \"pActiveSpikesBehaviorPlotter\" to avoid collisions with others\n",
    "# # pActiveTuningCurvesPlotter = display_output['pActiveTuningCurvesPlotter']\n",
    "# # root_dockAreaWindow, placefieldControlsContainerWidget, pf_widgets = display_output['pane'] # for Qt mode\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "# render_all_neuron_peak_prominence_2d_results_on_pyvista_plotter(ipcDataExplorer, active_peak_prominence_2d_results)\n",
    "LongShort3DPlacefieldsHelpers.render_long_short_all_neuron_peak_prominence_2d_results_on_pyvista_plotter(ipcDataExplorer,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t long_peak_prominence_2d_results=curr_active_pipeline.computation_results[long_epoch_name].computed_data.get('RatemapPeaksAnalysis', {}).get('PeakProminence2D', None),\n",
    "                                                                                                         short_peak_prominence_2d_results=curr_active_pipeline.computation_results[short_epoch_name].computed_data.get('RatemapPeaksAnalysis', {}).get('PeakProminence2D', None),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51d1e83",
   "metadata": {},
   "source": [
    "### PhoJonathan Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c430bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9741581a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "## INPUTS: pos_df\n",
    "pos_df: pd.DataFrame = global_session.position.to_dataframe()\n",
    "\n",
    "# Assume pos_df has columns 't' (time) and 'x' (position)\n",
    "pos_df = pos_df.sort_values('t').reset_index(drop=True)\n",
    "\n",
    "# 1. Tangent slope  m = dx/dt  (use central differences with np.gradient)\n",
    "pos_df['m_tan'] = np.gradient(pos_df['x'].values,\n",
    "                              pos_df['t'].values)   # dx/dt\n",
    "\n",
    "# 2a. Slope of the normal line\n",
    "pos_df['m_normal'] = -1.0 / pos_df['m_tan']          # −1/m\n",
    "\n",
    "# 2b. Raw 2-D normal vector  n = (−m , 1)\n",
    "pos_df['n_vec'] = list(zip(-pos_df['m_tan'], np.ones(len(pos_df))))\n",
    "\n",
    "# 2c. Unit-length normal vector\n",
    "n_x = -pos_df['m_tan'].values\n",
    "n_t = np.ones_like(n_x)\n",
    "norm = np.sqrt(n_x**2 + n_t**2)\n",
    "pos_df['n_unit_x'] = n_x / norm\n",
    "pos_df['n_unit_t'] = n_t / norm\n",
    "\n",
    "# Optional: drop helper columns if you like\n",
    "pos_df = pos_df.drop(columns=['m_tan'])\n",
    "\n",
    "pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68667a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pos_df: pd.DataFrame = global_session.position.to_dataframe()\n",
    "\n",
    "pos_df\n",
    "# smoothed_column_names = PositionComputedDataMixin._smoothed_column_labels(non_smoothed_column_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0dbf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum_inclusion_fr_Hz\n",
    "# curr_active_pipeline.minimum_inclusion_fr_Hz\n",
    "curr_active_pipeline.get_all_parameters()\n",
    "override_parameters_flat_keypaths_dict = {'rank_order_shuffle_analysis.included_qclu_values': included_qclu_values, 'rank_order_shuffle_analysis.minimum_inclusion_fr_Hz': minimum_inclusion_fr_Hz}\n",
    "curr_active_pipeline.update_parameters(override_parameters_flat_keypaths_dict=override_parameters_flat_keypaths_dict)\n",
    "curr_active_pipeline.apply_changed_parameters(minimum_inclusion_fr_Hz=2, included_qclu_values=[[1, 2, 4, 6, 7, 9], is_dry_run=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b86366",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6de103",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_inclusion_fr_Hz = 2.0\n",
    "included_qclu_values = [1, 2, 4, 6, 7, 9]\n",
    "\n",
    "(dependent_validators, provided_global_keys), old_new_values_change_dict = curr_active_pipeline.apply_changed_parameters(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, included_qclu_values=included_qclu_values,\n",
    "                                                                                                                        is_dry_run=False)\n",
    "old_new_values_change_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d021ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_thresh=False\n",
    "should_include_filter_excluded_spikes=True\n",
    "if speed_thresh and (not should_include_filter_excluded_spikes):\n",
    "    spk_pos_, spk_t_ = global_pf1D.run_spk_pos, global_pf1D.run_spk_t # TODO: these don't exist\n",
    "else:\n",
    "    spk_pos_, spk_t_ = global_pf1D.spk_pos, global_pf1D.spk_t\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# spk_t_\n",
    "# spk_pos_\n",
    "global_pos = deepcopy(global_session.position)\n",
    "pos_df: pd.DataFrame = global_pos.adding_hairy_curve_normal_dir_columns()\n",
    "global_spikes_df: pd.DataFrame = get_proper_global_spikes_df(curr_active_pipeline)\n",
    "global_spikes_df = global_spikes_df.spikes.interpolate_spike_positions(pos_df['t'], pos_df['x'], pos_df['y'], **{k:pos_df[k].to_numpy() for k in ['normal_dir_unit_t', 'normal_dir_unit_x']})\n",
    "global_spikes_df\n",
    "\n",
    "# global_pf1D.ratemap_spiketrains = global_pf1D._peak_frate_filter_function(spk_t)\n",
    "# global_pf1D.ratemap_spiketrains_pos = global_pf1D._peak_frate_filter_function(spk_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc1a516",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_replay_stats_df[neuron_replay_stats_df['aclu'] == 55]\n",
    "curr_active_pipeline.sess.spikes_df.spikes.neuron_ids\n",
    "global_session.spikes_df.spikes.neuron_ids\n",
    "\n",
    "global_spikes_df.spikes.neuron_ids\n",
    "global_spikes_df = \n",
    "short_LR_session.spikes_df.spikes.neuron_ids\n",
    "short_RL_session.spikes_df.spikes.neuron_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acd174c",
   "metadata": {
    "tags": [
     "2025-07-23",
     "run-group-publication",
     "batchphojonathanfigureshelper"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import PhoJonathanPlotHelpers\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import BatchPhoJonathanFiguresHelper\n",
    "from pyphocorehelpers.DataStructure.RenderPlots.MatplotLibRenderPlots import FigureCollector\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PhoPublicationFigureHelper\n",
    "from neuropy.analyses.placefields import PfnDMixin\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "## Get global 'jonathan_firing_rate_analysis' results:\n",
    "curr_jonathan_firing_rate_analysis = curr_active_pipeline.global_computation_results.computed_data['jonathan_firing_rate_analysis']\n",
    "neuron_replay_stats_df, rdf, aclu_to_idx, irdf = curr_jonathan_firing_rate_analysis.neuron_replay_stats_df, curr_jonathan_firing_rate_analysis.rdf.rdf, curr_jonathan_firing_rate_analysis.rdf.aclu_to_idx, curr_jonathan_firing_rate_analysis.irdf.irdf\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Batch Output of Figures                                                                                              #\n",
    "# ==================================================================================================================== #\n",
    "## 🗨️🟢 2022-11-05 - Pho-Jonathan Batch Outputs of Firing Rate Figures\n",
    "short_only_df = neuron_replay_stats_df[neuron_replay_stats_df.track_membership == SplitPartitionMembership.RIGHT_ONLY]\n",
    "short_only_aclus = short_only_df.index.values.tolist()\n",
    "long_only_df = neuron_replay_stats_df[neuron_replay_stats_df.track_membership == SplitPartitionMembership.LEFT_ONLY]\n",
    "long_only_aclus = long_only_df.index.values.tolist()\n",
    "shared_df = neuron_replay_stats_df[neuron_replay_stats_df.track_membership == SplitPartitionMembership.SHARED]\n",
    "shared_aclus = shared_df.index.values.tolist()\n",
    "print(f'shared_aclus: {shared_aclus}')\n",
    "print(f'long_only_aclus: {long_only_aclus}')\n",
    "print(f'short_only_aclus: {short_only_aclus}')\n",
    "\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'    \n",
    "## MODE: this mode creates a special folder to contain the outputs for this session.\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Output Figures to File                                                                                               #\n",
    "# ==================================================================================================================== #\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-BatchPhoJonathanFiguresHelper.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "prepare_for_publication: bool = True\n",
    "# prepare_for_publication: bool = False\n",
    "display_context = curr_active_pipeline.get_session_context()\n",
    "\n",
    "figsize = (6.5, 4)\n",
    "if prepare_for_publication:\n",
    "    from neuropy.utils.matplotlib_helpers import find_first_available_matplotlib_font_name\n",
    "\n",
    "    found_matplotlib_font_name: str = find_first_available_matplotlib_font_name(desired_fonts_list=['Arial'])\n",
    "    assert found_matplotlib_font_name, f\"found_matplotlib_font_name: {found_matplotlib_font_name} Arial was not found!\"\n",
    "else:\n",
    "    found_matplotlib_font_name = None\n",
    "\n",
    "_rc_context_kwargs = {'savefig.transparent': True, 'ps.fonttype': 42, 'pdf.fonttype': 42, }\n",
    "if prepare_for_publication:\n",
    "    assert found_matplotlib_font_name is not None\n",
    "    _rc_context_kwargs.update(PhoPublicationFigureHelper.rc_context_kwargs(prepare_for_publication=prepare_for_publication, **{'figure.dpi': '100', 'figure.frameon': False, 'figure.figsize': figsize, 'font.family': found_matplotlib_font_name})) # , 'figure.constrained_layout.use': (constrained_layout or False)\n",
    "\n",
    "with mpl.rc_context(_rc_context_kwargs): # 'figure.dpi': '220', 'figure.figsize': (10, 4), \n",
    "    # Create a FigureCollector instance\n",
    "    with FigureCollector(name='BatchPhoJonathanFiguresHelper', base_context=display_context) as collector:\n",
    "\n",
    "        active_out_figures_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, n_max_page_rows=1, write_vector_format=True, write_png=False, disable_top_row=True, split_by_short_long_shared=False, show_only_refined_cells=True)\n",
    "                \n",
    "        # for a_ctxt, a_matlab_render_plots_obj in active_out_figures_dict.items():\n",
    "        #     collector.post_hoc_append(figures=a_matlab_render_plots_obj.figures, axes=a_matlab_render_plots_obj.axes, contexts=[a_ctxt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26df7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3c878f",
   "metadata": {},
   "source": [
    "#### Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6595b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps).trimmed_to_non_overlapping() \n",
    "global_laps_epochs_df = global_laps.to_dataframe()\n",
    "_out_ripple_rasters: RankOrderRastersDebugger = RankOrderRastersDebugger.init_rank_order_debugger(global_spikes_df, deepcopy(global_laps_epochs_df),\n",
    "                                                                                                track_templates, None,\n",
    "                                                                                                None, None,\n",
    "                                                                                                dock_add_locations = dict(zip(('long_LR', 'long_RL', 'short_LR', 'short_RL'), (['right'], ['right'], ['right'], ['right']))),\n",
    "                                                                                                )\n",
    "_out_ripple_rasters.set_top_info_bar_visibility(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87275307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import fig_remapping_cells\n",
    "\n",
    "a_fig_collector = fig_remapping_cells(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8833fd9",
   "metadata": {},
   "source": [
    "## Pseudo2D Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed34de9",
   "metadata": {
    "tags": [
     "2025-08-22_binbybindecodingdebugger"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.Extensions.pyqtgraph_helpers import LayoutScrollability, pyqtplot_build_image_bounds_extent\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.TemplateDebugger import BaseTemplateDebuggingMixin, build_pf1D_heatmap_with_labels_and_peaks, TrackTemplates\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.BinByBinDecodingDebugger import BinByBinDecodingDebugger \n",
    "\n",
    "# Example usage:\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps).trimmed_to_non_overlapping() \n",
    "global_laps_epochs_df = global_laps.to_dataframe()\n",
    "# global_laps_epochs_df\n",
    "\n",
    "## INPUTS: \n",
    "time_bin_size: float = 0.050\n",
    "# time_bin_size: float = 0.500\n",
    "a_lap_id: int = 37\n",
    "a_decoder_name = 'long_RL'\n",
    "epoch_id_col_name = 'lap_id'\n",
    "## COMPUTED: \n",
    "a_decoder_idx: int = track_templates.get_decoder_names().index(a_decoder_name)\n",
    "# a_decoder = deepcopy(track_templates.long_LR_decoder)\n",
    "a_decoder = deepcopy(track_templates.get_decoders()[a_decoder_idx])\n",
    "# (_out_decoded_time_bin_edges, _out_decoded_unit_specific_time_binned_spike_counts, _out_decoded_active_unit_lists, _out_decoded_active_p_x_given_n, _out_decoded_active_plots_data) = BinByBinDecodingDebugger.build_spike_counts_and_decoder_outputs(a_decoder=a_decoder, epochs_df=global_laps_epochs_df, spikes_df=global_spikes_df, epoch_id_col_name=epoch_id_col_name, time_bin_size=time_bin_size)\n",
    "# win, out_pf1D_decoder_template_objects, (_out_decoded_active_plots, _out_decoded_active_plots_data) = BinByBinDecodingDebugger.build_time_binned_decoder_debug_plots(a_decoder=a_decoder, an_epoch_id=a_lap_id, _out_decoded_time_bin_edges=_out_decoded_time_bin_edges, _out_decoded_active_p_x_given_n=_out_decoded_active_p_x_given_n,\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  _out_decoded_active_unit_lists=_out_decoded_active_unit_lists, _out_decoded_active_plots_data=_out_decoded_active_plots_data, debug_print=True)\n",
    "\n",
    "## All-in-one mode:\n",
    "# win, out_pf1D_decoder_template_objects, (_out_decoded_active_plots, _out_decoded_active_plots_data) = BinByBinDecodingDebugger.plot_bin_by_bin_decoding_example(curr_active_pipeline=curr_active_pipeline, a_decoder=a_decoder, time_bin_size=time_bin_size, an_epoch_id=a_lap_id)\n",
    "bin_by_bin_debugger = BinByBinDecodingDebugger.plot_bin_by_bin_decoding_example(curr_active_pipeline=curr_active_pipeline, a_decoder=a_decoder, time_bin_size=time_bin_size, an_epoch_id=a_lap_id)\n",
    "# bin_by_bin_debugger: BinByBinDecodingDebugger = BinByBinDecodingDebugger.init_from_builder_classmethod(win=win, pf1D_decoder_template_objects=out_pf1D_decoder_template_objects)\n",
    "\n",
    "print(f\"Returned window: {bin_by_bin_debugger.ui.win}\")\n",
    "# print(f\"Returned decoder objects: {out_pf1D_decoder_template_objects}\")\n",
    "bin_by_bin_debugger.ui.win.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c162c5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'], computation_kwargs_list=[{'time_bin_size': time_bin_size, 'should_disable_cache': False}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "## get the result data:\n",
    "## Uses the `global_computation_results.computed_data['DirectionalDecodersDecoded']`\n",
    "directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "pseudo2D_decoder: BasePositionDecoder = directional_decoders_decode_result.pseudo2D_decoder\n",
    "all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "a_continuously_decoded_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict.get(time_bin_size, None)\n",
    "info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca63410",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_directional_pf1D_Decoder_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536c1cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: pseudo2D_decoder\n",
    "bin_by_bin_debugger = BinByBinDecodingDebugger.plot_bin_by_bin_decoding_example(curr_active_pipeline=curr_active_pipeline, a_decoder=pseudo2D_decoder, time_bin_size=time_bin_size, an_epoch_id=a_lap_id)\n",
    "# bin_by_bin_debugger: BinByBinDecodingDebugger = BinByBinDecodingDebugger.init_from_builder_classmethod(win=win, pf1D_decoder_template_objects=out_pf1D_decoder_template_objects)\n",
    "\n",
    "print(f\"Returned window: {bin_by_bin_debugger.ui.win}\")\n",
    "# print(f\"Returned decoder objects: {out_pf1D_decoder_template_objects}\")\n",
    "bin_by_bin_debugger.ui.win.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad77fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.TemplateDebugger import TemplateDebugger\n",
    "\n",
    "_out = TemplateDebugger.init_templates_debugger(track_templates) # , included_any_context_neuron_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510f5b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_templates.get_decoders()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62482c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(_out_decoded_active_plots_data.keys()) # looks like a separate entry for each time bin? Weird\n",
    "# list(_out_decoded_active_plots.keys()) # looks like a single entry with its key being this epoch_id?\n",
    "\n",
    "active_plot_data = bin_by_bin_debugger.plot_data._out_decoded_active_plots_data[37]\n",
    "active_plot_data\n",
    "# bin_by_bin_debugger.plot_data.pf1D_decoder_template_objects\n",
    "\n",
    "\n",
    "# _out_decoded_active_plots_data[1]\n",
    "## recursive time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4039f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_plot_data.data_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f86663",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_time_bin_render_plots = bin_by_bin_debugger.per_time_bin_render_plots\n",
    "per_time_bin_render_plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41718ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf1D_decoder_template_objects =  bin_by_bin_debugger.plot_data.pf1D_decoder_template_objects\n",
    "pf1D_decoder_template_objects[0] # BaseTemplateDebuggingMixin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5d0652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, an_obj in enumerate(out_pf1D_decoder_template_objects):\n",
    "for i, an_obj in enumerate(bin_by_bin_debugger.plot_data.pf1D_decoder_template_objects):\n",
    "    a_plot_item, an_image_item = an_obj.plots.pf1D_heatmap\n",
    "    # an_image_item # pg.ImageItem\n",
    "    a_plot_item: pg.PlotItem = a_plot_item\n",
    "    a_plot_item.getViewBox().viewRange() # [[-982.817266187045, 403.2776978417262], [-1.129145764281552, 2.1291457642815517]]\n",
    "    # (a_decoder.xbin[0], a_decoder.xbin[-1])\n",
    "    a_plot_item.setRange(xRange=(a_decoder.xbin[0], a_decoder.xbin[-1]))\n",
    "\n",
    "\n",
    "# [[-165.22507509844218, 328.9511350154895], [-1.2271993262886023, 2.227199326288602]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36df533",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_bounds_extent, x_range, y_range = pyqtplot_build_image_bounds_extent(xbin_edges, ybin_edges, margin=0.0, debug_print=debug_print)\n",
    "curr_plot.hideButtons()\n",
    "img_item = pg.ImageItem(image=image, levels=(0,1))\n",
    "curr_plot.addItem(img_item, defaultPadding=0.0)\n",
    "img_item.setImage(image, rect=image_bounds_extent, autoLevels=False)\n",
    "img_item.setLookupTable(cmap.getLookupTable(nPts=256), update=False)\n",
    "curr_plot.setRange(xRange=x_range, yRange=y_range, padding=0.0, update=False, disableAutoRange=True)\n",
    "curr_plot.setLimits(xMin=x_range[0], xMax=x_range[-1], yMin=y_range[0], yMax=y_range[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc01304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.DataStructure.RenderPlots.PyqtgraphRenderPlots import PyqtgraphRenderPlots\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.BinByBinDecodingDebugger import BinByBinDebuggingData, BinByBinDecodingDebugger\n",
    "\n",
    "\n",
    "neuron_IDs = deepcopy(a_decoder.neuron_IDs)\n",
    "global_spikes_df = get_proper_global_spikes_df(curr_active_pipeline).spikes.sliced_by_neuron_id(neuron_IDs) ## only get the relevant spikes\n",
    "## OUTPUTS: neuron_IDs, global_spikes_df, active_window_time_bins\n",
    "active_2d_plot = spike_raster_window.spike_raster_plt_2d\n",
    "active_spikes_window = active_2d_plot.spikes_window\n",
    "\n",
    "if isinstance(a_decoded_result, SingleEpochDecodedResult):\n",
    "    single_continuous_result = a_decoded_result ## already have this\n",
    "    decoding_time_bin_size: float = single_continuous_result.time_bin_container.edge_info.step\n",
    "else:\n",
    "    ## extract it\n",
    "    single_continuous_result: SingleEpochDecodedResult = a_decoded_result.get_result_for_epoch(0) # SingleEpochDecodedResult            \n",
    "    decoding_time_bin_size: float = a_decoded_result.decoding_time_bin_size\n",
    "\n",
    "\n",
    "# decoding_bins_epochs_df: pd.DataFrame = single_continuous_result.build_pseudo_epochs_df_from_decoding_bins().epochs.get_valid_df()\n",
    "bin_by_bin_data: BinByBinDebuggingData = BinByBinDebuggingData.init_from_single_continuous_result(a_decoder=a_decoder, global_spikes_df=global_spikes_df, single_continuous_result=single_continuous_result, decoding_time_bin_size=decoding_time_bin_size, n_max_debugged_time_bins=n_max_debugged_time_bins)\n",
    "## OUTPUTS: bin_by_bin_data\n",
    "\n",
    "## INPUTS: active_spikes_window, global_spikes_df, decoding_bins_epochs_df\n",
    "## Slice to current window:\n",
    "active_window_t_start, active_window_t_end = active_spikes_window.active_time_window\n",
    "print(f'active_window_t_start: {active_window_t_start}, active_window_t_end: {active_window_t_end}')\n",
    "active_global_spikes_df, active_window_decoded_epochs_df, active_epoch_active_aclu_spike_counts_list, (active_window_slice_idxs, active_window_time_bin_edges, active_p_x_given_n) = bin_by_bin_data.sliced_to_current_window(active_window_t_start, active_window_t_end)\n",
    "\n",
    "## OUTPUTS: active_window_slice_idxs, active_window_time_bin_edges, active_p_x_given_n\n",
    "\n",
    "## OUTPUTS: active_global_spikes_df, active_window_decoded_epochs_df, active_epoch_active_aclu_spike_counts_list\n",
    "\n",
    "## INPUTS: neuron_IDs, (active_global_spikes_df, active_window_decoded_epochs_df, active_aclu_spike_counts_dict_list)\n",
    "## INPUTS: active_window_slice_idxs, active_window_time_bin_edges, active_p_x_given_n\n",
    "plots_container = PyqtgraphRenderPlots(name=f'PhoTest_{name_suffix}', root_plot=None) # Create a new one\n",
    "plots_data = RenderPlotsData(name=f'epoch[{name_suffix}]', spikes_df=active_global_spikes_df, a_decoder=a_decoder, active_aclus=neuron_IDs, bin_by_bin_data=bin_by_bin_data)\n",
    "win, out_pf1D_decoder_template_objects, (plots_container, plots_data) = BinByBinDecodingDebugger._perform_build_time_binned_decoder_debug_plots(a_decoder=a_decoder, time_bin_edges=active_window_time_bin_edges, p_x_given_n=active_p_x_given_n, active_epoch_active_aclu_spike_counts_list=active_epoch_active_aclu_spike_counts_list,\n",
    "                                                                                                                            plots_data=plots_data, plots_container=plots_container,\n",
    "                                                                                                                            debug_print=False, name_suffix=name_suffix)\n",
    "bin_by_bin_debugger: BinByBinDecodingDebugger = BinByBinDecodingDebugger.init_from_builder_classmethod(win=win, pf1D_decoder_template_objects=out_pf1D_decoder_template_objects, plots_container=plots_container, plot_data=plots_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff24133e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125508a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345ec76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_cm_x_grid_bin_bounds\n",
    "\n",
    "global_session.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e03666",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pf1D_decoder_template_objects[0].plots_data.spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe2e4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lap_specific_spikes_df = _out_decoded_active_plots_data[a_lap_id].spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1529c71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = dict()\n",
    "_out['_display_directional_merged_pfs'] = curr_active_pipeline.display(display_function='_display_directional_merged_pfs', active_session_configuration_context=None) # _display_directional_merged_pfs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece249c2",
   "metadata": {},
   "source": [
    "n_epoch_time_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721d7f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "win.nextRow()\n",
    "lbl = win.addLabel(text='HUGE', colspan=n_epoch_time_bins) # , row=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a0506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the span to cover all columns in the row\n",
    "win.ci.layout.setRowStretchFactor(win.ci.rowCount() - 1, 1)  # Adjust the stretch factor for the new row\n",
    "win.ci.layout.setColumnStretchFactor(0, n_epoch_time_bins)   # Ensure it spans all columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f91cc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "spanning_plot2 = win.addPlot(title=\"Spanning Plot3\", row=1, rowspan=1, col=0, colspan=n_epoch_time_bins)  # Add the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7a808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spanning_plot2.setTitle(\"Spanning Plot - Covers Entire Width\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f611651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the span to cover all columns in the row\n",
    "win.ci.layout.setRowStretchFactor(win.ci.rowCount() - 1, 1)  # Adjust the stretch factor for the new row\n",
    "win.ci.layout.setColumnStretchFactor(0, n_epoch_time_bins)   # Ensure it spans all columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cae0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.decoder_difference import display_predicted_position_difference\n",
    "\n",
    "active_computed_data = curr_active_pipeline.computation_results[global_epoch_name]\n",
    "active_resampled_pos_df = active_computed_data.extended_stats.time_binned_position_df.copy() # active_computed_data.extended_stats.time_binned_position_df  # 1717 rows × 16 columns\n",
    "active_resampled_measured_positions = active_resampled_pos_df[['x','y']].to_numpy() # The measured positions resampled (interpolated) at the window centers. \n",
    "display_predicted_position_difference(active_one_step_decoder, active_two_step_decoder, active_resampled_measured_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd6298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(p_x_given_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1738f798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.TemplateDebugger import BaseTemplateDebuggingMixin, build_pf1D_heatmap_with_labels_and_peaks, TrackTemplates\n",
    "\n",
    "_obj = BaseTemplateDebuggingMixin.init_from_decoder(a_decoder=a_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe064948",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "curr_img, out_colors_heatmap_image_matrix = build_pf1D_heatmap_with_labels_and_peaks(pf1D_decoder=a_decoder, visible_aclus=active_bin_aclus, plot_item=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c18797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.TemplateDebugger import TemplateDebugger\n",
    "\n",
    "_out_TemplateDebugger: TemplateDebugger = TemplateDebugger.init_templates_debugger(track_templates) # , included_any_context_neuron_ids\n",
    "\n",
    "# _out_ui.root_dockAreaWindow\n",
    "# _out_ui.dock_widgets[a_decoder_name]\n",
    "\n",
    "## Plots:\n",
    "# _out_plots.pf1D_heatmaps[a_decoder_name] = visualize_heatmap_pyqtgraph(curr_curves, title=title_str, show_value_labels=False, show_xticks=False, show_yticks=False, show_colorbar=False, win=None, defer_show=True) # Sort to match first decoder (long_LR)\n",
    "# Adds aclu text labels with appropriate colors to y-axis: uses `sorted_shared_sort_neuron_IDs`:\n",
    "# curr_win, curr_img = _out_plots.pf1D_heatmaps[a_decoder_name] # win, img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eecf66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: \n",
    "a_decoder_aclu_to_color_map = deepcopy(_out_TemplateDebugger.plots_data['sort_helper_neuron_id_to_neuron_colors_dicts'][a_decoder_idx])\n",
    "a_decoder_aclu_to_color_map\n",
    "# _out_TemplateDebugger.plots_data['out_colors_heatmap_image_matrix_dicts'][a_decoder_idx]\n",
    "an_img_extents = deepcopy(_out_TemplateDebugger.plots_data['active_pfs_img_extents_dict'])[a_decoder_name] # [0.0, 0, 289.2117008543986, 35.0]\n",
    "an_img_extents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0aa9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out_TemplateDebugger.params\n",
    "# _out_TemplateDebugger.plots_data.data_keys\n",
    "\n",
    "a_decoder_name\n",
    "\n",
    "\n",
    "a_decoder_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd155ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd6e7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import easy_independent_decoding\n",
    "\n",
    "\n",
    "time_bin_size: float = 0.500 # 500ms\n",
    "t_start = 0.0\n",
    "t_end = 2093.8978568242164\n",
    "_decoded_pos_outputs, (unit_specific_time_binned_spike_counts, time_bin_edges, spikes_df) = easy_independent_decoding(long_LR_decoder, spikes_df=spikes_df, time_bin_size=time_bin_size, t_start=t_start, t_end=t_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9e1715",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_template_debugger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9851ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_t_bin_idx: int = 0\n",
    "# active_aclus_list = _out_decoded_active_unit_lists[a_row.lap_id][a_t_bin_idx]\n",
    "\n",
    "_out_TemplateDebugger.update_cell_emphasis(solo_emphasized_aclus=active_bin_aclus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4173061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_TemplateDebugger.pf1D_heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b761e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.indexing_helpers import compute_paginated_grid_config\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.pyqtplot_common import pyqtplot_common_setup\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.Extensions.pyqtgraph_helpers import LayoutScrollability, pyqtplot_build_image_bounds_extent, set_small_title\n",
    "from neuropy.utils.matplotlib_helpers import _scale_current_placefield_to_acceptable_range, _build_neuron_identity_label # for display_all_pf_2D_pyqtgraph_binned_image_rendering\n",
    "from pyphocorehelpers.gui.Qt.color_helpers import ColormapHelpers\n",
    "\n",
    "class HeatmapLayout(pg.QtWidgets.QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Create layout\n",
    "        layout = pg.QtWidgets.QVBoxLayout(self)\n",
    "        layout.setContentsMargins(0, 0, 0, 0)\n",
    "        layout.setSpacing(0)\n",
    "        \n",
    "        # Top row: variable number of heatmaps\n",
    "        self.top_row = pg.GraphicsLayoutWidget()\n",
    "        self.top_row.setContentsMargins(0, 0, 0, 0)\n",
    "        self.top_plots = []\n",
    "        layout.addWidget(self.top_row)\n",
    "\n",
    "        # Bottom row: single heatmap\n",
    "        self.bottom_row = pg.GraphicsLayoutWidget()\n",
    "        self.bottom_row.setContentsMargins(0, 0, 0, 0)\n",
    "        self.bottom_plot = self.bottom_row.addPlot()\n",
    "        self.bottom_plot.setContentsMargins(0, 0, 0, 0)\n",
    "        self.bottom_img = pg.ImageItem()\n",
    "        self.bottom_plot.addItem(self.bottom_img)\n",
    "        layout.addWidget(self.bottom_row)\n",
    "        \n",
    "        # Style plots\n",
    "        for p in [self.bottom_plot]:\n",
    "            p.showAxis('left', True)\n",
    "            p.showAxis('bottom', True)\n",
    "            p.getAxis('left').setLabel(\"Y-Axis\")\n",
    "            p.getAxis('bottom').setLabel(\"X-Axis\")\n",
    "            p.setContentsMargins(0, 0, 0, 0)\n",
    "            p.setDefaultPadding(0)\n",
    "            \n",
    "\n",
    "    def update_top_heatmaps(self, data_list):\n",
    "        self.top_row.clear()\n",
    "        self.top_plots = []\n",
    "        for data in data_list:\n",
    "            plot = self.top_row.addPlot()\n",
    "            plot.setContentsMargins(0, 0, 0, 0)\n",
    "            plot.setDefaultPadding(0)\n",
    "            img = pg.ImageItem(data)\n",
    "            plot.addItem(img)\n",
    "            plot.showAxis('left', True)\n",
    "            plot.getAxis('left').setLabel(\"Y-Axis\")\n",
    "            plot.hideAxis('bottom')\n",
    "            self.top_plots.append(plot)\n",
    "            self.top_row.nextRow()\n",
    "\n",
    "    def update_bottom_heatmap(self, data):\n",
    "        self.bottom_img.setImage(data)\n",
    "\n",
    "## Testing\n",
    "window = pg.QtWidgets.QMainWindow()\n",
    "widget = HeatmapLayout()\n",
    "\n",
    "# Example data\n",
    "top_data_list = [np.random.rand(10, 10), np.random.rand(15, 10)]\n",
    "bottom_data = np.random.rand(20, 20)\n",
    "\n",
    "widget.update_top_heatmaps(top_data_list)\n",
    "widget.update_bottom_heatmap(bottom_data)\n",
    "\n",
    "window.setCentralWidget(widget)\n",
    "window.resize(800, 600)\n",
    "window.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99251ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parent_root_widget = None\n",
    "root_render_widget = None\n",
    "# Need to go from (n_epochs, n_neurons, n_pos_bins) -> (n_neurons, n_xbins, n_ybins)\n",
    "n_epochs, n_neurons, n_pos_bins = np.shape(z_scored_tuning_map_matrix)\n",
    "images = z_scored_tuning_map_matrix.transpose(1, 2, 0) # (71, 57, 22)\n",
    "xbin_edges=active_one_step_decoder.xbin\n",
    "assert (len(xbin_edges)-1) == n_pos_bins, f\"n_pos_bins: {n_pos_bins}, len(xbin_edges): {len(xbin_edges)} \"\n",
    "# ybin_edges=active_one_step_decoder.ybin\n",
    "ybin_edges = np.arange(n_epochs+1) - 0.5 # correct ybin_edges are n_epochs\n",
    "root_render_widget, parent_root_widget, app = pyqtplot_common_setup(f'TrialByTrialActivityArray: {np.shape(images)}', app=app, parent_root_widget=parent_root_widget, root_render_widget=root_render_widget) ## 🚧 TODO: BUG: this makes a new QMainWindow to hold this item, which is inappropriate if it's to be rendered as a child of another control\n",
    "\n",
    "pg.setConfigOptions(imageAxisOrder='col-major') # this causes the placefields to be rendered horizontally, like they were in _temp_pyqtplot_plot_image_array\n",
    "\n",
    "\n",
    "\n",
    "## build pg.GraphicsLayoutWidget(...) required to hold the decoding preview\n",
    "root = pg.GraphicsLayoutWidget(title='Decoding Example')\n",
    "\n",
    "\n",
    "root.addItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b18f74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.SpecificComputationValidation import SpecificComputationValidator\n",
    "\n",
    "def _build_default_required_computation_keys_computation_validator_fn_factory():\n",
    "    def _subfn(curr_active_pipeline, computation_filter_name='maze'):\n",
    "        has_all_required_local_keys: bool = np.all(np.isin((a_fn_callable.input_requires or []),  list(curr_active_pipeline.computation_results[computation_filter_name].computed_data.keys())))\n",
    "        has_all_required_global_keys: bool = np.all(np.isin((a_fn_callable.requires_global_keys or []),  list(curr_active_pipeline.global_computation_results.computed_data.keys())))\n",
    "        has_all_required_keys: bool = (has_all_required_local_keys and has_all_required_global_keys)\n",
    "        return has_all_required_keys\n",
    "    return _subfn\n",
    "\n",
    "\n",
    "should_use_nice_display_names: bool = False\n",
    "display_function_items = widget.get_display_function_items()\n",
    "display_fn_validators_dict = {}\n",
    "\n",
    "for a_fcn_name, a_disp_fn_item in display_function_items.items():\n",
    "    # extract the info from the function:\n",
    "    # if hasattr(a_fcn, 'short_name') and a_fcn.short_name is not None:\n",
    "    #     active_name = a_fcn.short_name or a_fcn_name\n",
    "    # else:\n",
    "    #     active_name = a_fcn_name\n",
    "\n",
    "    # active_name: str = a_disp_fn_item.name\n",
    "    if should_use_nice_display_names:\n",
    "        active_name: str = a_disp_fn_item.best_display_name\n",
    "    else:\n",
    "        active_name: str = a_disp_fn_item.name # function name\n",
    "\n",
    "    a_fn_callable = a_disp_fn_item.fn_callable\n",
    "\n",
    "    if ((not hasattr(a_fn_callable, 'validate_computation_test')) or (a_fn_callable.validate_computation_test is None)):\n",
    "        a_fn_callable.validate_computation_test = _build_default_required_computation_keys_computation_validator_fn_factory()\n",
    "\n",
    "    display_fn_validators_dict[a_fcn_name] = SpecificComputationValidator.init_from_decorated_fn(a_fn_callable)\n",
    "    # a_disp_fn_item\n",
    "    # a_fn_handle = widget.curr_active_pipeline.plot.__getattr__(a_disp_fn_item.name)\n",
    "    # a_fn_handle\n",
    "\n",
    "    # a_validate_computation_test = lambda curr_active_pipeline, computation_filter_name='maze': (curr_active_pipeline.computation_results[computation_filter_name].computed_data['pf1D_Decoder'], curr_active_pipeline.computation_results[computation_filter_name].computed_data['pf2D_Decoder'])\n",
    "\n",
    "\n",
    "# display_function_items\n",
    "# a_fn_handle.\n",
    "display_fn_validators_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3bbc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "display_fn_validators_dict = {}\n",
    "\n",
    "\n",
    "{k:SpecificComputationValidator.init_from_decorated_fn(v) for k,v in self.registered_merged_computation_function_dict.items() if hasattr(v, 'validate_computation_test') and (v.validate_computation_test is not None)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d2c89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.computation_results['maze_any'].computed_data\n",
    "\n",
    "_out = curr_active_pipeline.display('_display_plot_marginal_1D_most_likely_position_comparisons', active_session_configuration_context='maze_any', most_likely_positions_mode='standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0170fae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out = dict()\n",
    "# _out['_display_1d_placefield_occupancy'] = curr_active_pipeline.display('_display_1d_placefield_occupancy') # _display_1d_placefield_occupancy\n",
    "\n",
    "# _out = dict()\n",
    "# _out['_display_1d_placefield_occupancy'] = curr_active_pipeline.display(display_function='_display_1d_placefield_occupancy', active_session_configuration_context='kdiba_gor01_one_2006-6-09_1-22-43_maze_any_any') # _display_1d_placefield_occupancy\n",
    "\n",
    "_out = dict()\n",
    "_out['_display_1d_placefield_occupancy'] = curr_active_pipeline.display(display_function='_display_1d_placefield_occupancy', active_session_configuration_context=IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43',filter_name='maze1_any',lap_dir='any'), plot_pos_bin_axes=False) # _display_1d_placefield_occupancy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce055b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsWidgets.EpochsEditorItem import EpochsEditor # perform_plot_laps_diagnoser\n",
    "\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_epoch_context, short_epoch_context, global_epoch_context = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_epoch_name, short_epoch_name, global_epoch_name)]\n",
    "long_epoch_obj, short_epoch_obj = [Epoch(curr_active_pipeline.sess.epochs.to_dataframe().epochs.label_slice(an_epoch_name.removesuffix('_any'))) for an_epoch_name in [long_epoch_name, short_epoch_name]] #TODO 2023-11-10 20:41: - [ ] Issue with getting actual Epochs from sess.epochs for directional laps: emerges because long_epoch_name: 'maze1_any' and the actual epoch label in curr_active_pipeline.sess.epochs is 'maze1' without the '_any' part.\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "\n",
    "# sess = curr_active_pipeline.sess\n",
    "sess = global_session\n",
    "\n",
    "# pos_df = sess.compute_position_laps() # ensures the laps are computed if they need to be:\n",
    "position_obj = deepcopy(sess.position)\n",
    "position_obj.compute_higher_order_derivatives()\n",
    "pos_df = position_obj.compute_smoothed_position_info(N=20) ## Smooth the velocity curve to apply meaningful logic to it\n",
    "pos_df = position_obj.to_dataframe()\n",
    "# Drop rows with missing data in columns: 't', 'velocity_x_smooth' and 2 other columns. This occurs from smoothing\n",
    "pos_df = pos_df.dropna(subset=['t', 'x_smooth', 'velocity_x_smooth', 'acceleration_x_smooth']).reset_index(drop=True)\n",
    "curr_laps_df = sess.laps.to_dataframe()\n",
    "curr_laps_df\n",
    "epochs_editor = EpochsEditor.init_laps_diagnoser(pos_df, curr_laps_df, include_velocity=True, include_accel=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1b2f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show step-by-step how the decoder works\n",
    "\n",
    "## Show pseudo2D merged placefields:\n",
    "_out = dict()\n",
    "_out['_display_directional_merged_pfs'] = curr_active_pipeline.display(display_function='_display_directional_merged_pfs', active_session_configuration_context=None) # _display_directional_merged_pfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bc2059",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsResults\n",
    "\n",
    "all_neuron_stats_table: pd.DataFrame = AcrossSessionsResults.build_neuron_identities_df_for_CSV(curr_active_pipeline=curr_active_pipeline)\n",
    "all_neuron_stats_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6c97ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.sess.neurons\n",
    "\n",
    "# co_filter_epochs_and_spikes("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed02317",
   "metadata": {},
   "source": [
    "### <a id='toc7_1_1_'></a>[2025-01-20 - Decoding step-by-step](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7d8dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import get_proper_global_spikes_df\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import easy_independent_decoding\n",
    "\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "all_directional_pf1D_Decoder: BasePositionDecoder = deepcopy(directional_merged_decoders_result.all_directional_pf1D_Decoder) # all-directions\n",
    "# directional_merged_decoders_result\n",
    "\n",
    "# a_1D_decoder: PfND = directional_merged_decoders_result.all_directional_decoder_dict['long_LR']\n",
    "\n",
    "long_LR_decoder: BasePositionDecoder = deepcopy(track_templates.long_LR_decoder)\n",
    "\n",
    "# ratemap: Ratemap = all_directional_pf1D_Decoder.ratemap\n",
    "\n",
    "## Pass in epochs to decode, for example, the laps\n",
    "laps = deepcopy(curr_active_pipeline.sess.laps)\n",
    "\n",
    "spikes_df: pd.DataFrame = deepcopy(curr_active_pipeline.sess.spikes_df)\n",
    "# spikes_df: pd.DataFrame = get_proper_global_spikes_df(curr_active_pipeline)\n",
    "# spikes_df = spikes_df.spikes.sliced_by_neuron_id(all_directional_pf1D_Decoder.neuron_IDs)\n",
    "# spikes_df\n",
    "\n",
    "## Given a list of discrete, equally-sized `time_bin_edges`, and a `spikes_df` pd.DataFrame of neuron spike times:\n",
    "\n",
    "## use the column 'aclu', which contains a distinct unit ID\n",
    "\n",
    "## count up the number of spikes occuring for each neuron (aclu-value) in each time bin, according to the column 't_rel_seconds' and collect the result in a numpy matrix `unit_specific_time_binned_spike_counts`\n",
    "\n",
    "\n",
    "# _ratemap\n",
    "# neuron_ids = deepcopy(spikes_df.spikes.neuron_ids) # array([ 5, 10, 14, 15, 24, 25, 26, 31, 32, 33, 41, 49, 50, 51, 55, 58, 64, 69, 70, 73, 74, 75, 76, 78, 82, 83, 85, 86, 90, 92, 93, 96])\n",
    "# array([  3,   4,   5,   7,   9,  10,  11,  14,  15,  16,  17,  21,  24,  25,  26,  31,  32,  33,  34,  35,  36,  37,  41,  45,  48,  49,  50,  51,  53,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  66,  67,  68,  69,  70,  71,  73,  74,  75,  76,  78,  82,  83,  84,  85,  86,  88,  89,  90,  92,  93,  96,  98, 100, 102, 107, 108])\n",
    "# neuron_ids\n",
    "# neuron_IDs = deepcopy(all_directional_pf1D_Decoder.neuron_IDs) # array([  2,   5,   8,  10,  14,  15,  23,  24,  25,  26,  31,  32,  33,  41,  49,  50,  51,  55,  58,  64,  69,  70,  73,  74,  75,  76,  78,  82,  83,  85,  86,  90,  92,  93,  96, 109])\n",
    "# neuron_IDs\n",
    "\n",
    "neuron_IDs = deepcopy(long_LR_decoder.neuron_IDs) # array([  2,   5,   8,  10,  14,  15,  23,  24,  25,  26,  31,  32,  33,  41,  49,  50,  51,  55,  58,  64,  69,  70,  73,  74,  75,  76,  78,  82,  83,  85,  86,  90,  92,  93,  96, 109])\n",
    "neuron_IDs\n",
    "\n",
    "# all_directional_pf1D_Decoder.slic\n",
    "spikes_df = spikes_df.spikes.sliced_by_neuron_id(neuron_IDs) ## filter everything down\n",
    "# all_directional_pf1D_Decoder.pf.spikes_df = deepcopy(spikes_df)\n",
    "## Need to update .pf._filtered_spikes_df now:\n",
    "\n",
    "# all_directional_pf1D_Decoder = all_directional_pf1D_Decoder.get_by_id(ids=neuron_IDs, defer_compute_all=True)\n",
    "# all_directional_pf1D_Decoder\n",
    "\n",
    "# ratemap = ratemap.get_by_id(ids=neuron_IDs)\n",
    "# all_directional_pf1D_Decoder._ratemap = ratemap\n",
    "# all_directional_pf1D_Decoder.compute()\n",
    "# ratemap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3b046d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.filtered_epochs\n",
    "time_bin_size: float = 0.025\n",
    "t_start = 0.0\n",
    "t_end = 2093.8978568242164\n",
    "time_bin_edges: NDArray = np.arange(t_start, t_end + time_bin_size, time_bin_size)\n",
    "# time_bin_edges\n",
    "unique_units = np.unique(spikes_df['aclu']) # sorted\n",
    "unit_specific_time_binned_spike_counts: NDArray = np.array([\n",
    "    np.histogram(spikes_df.loc[spikes_df['aclu'] == unit, 't_rel_seconds'], bins=time_bin_edges)[0]\n",
    "    for unit in unique_units\n",
    "])\n",
    "unit_specific_time_binned_spike_counts\n",
    " \n",
    "## OUTPUT: time_bin_edges, unit_specific_time_binned_spike_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a7916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## `easy_independent_decoding`\n",
    "_decoded_pos_outputs, (unit_specific_time_binned_spike_counts, time_bin_edges, spikes_df) = easy_independent_decoding(long_LR_decoder, spikes_df=spikes_df, time_bin_size=time_bin_size, t_start=t_start, t_end=t_end)\n",
    "most_likely_positions, p_x_given_n, most_likely_position_indicies, flat_outputs_container = _decoded_pos_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1b3216",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_x_given_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809362d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(most_likely_positions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2a6c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "_decoded_pos_outputs = long_LR_decoder.decode(unit_specific_time_binned_spike_counts=unit_specific_time_binned_spike_counts, time_bin_size=time_bin_size, output_flat_versions=True, debug_print=True)\n",
    "# _decoded_pos_outputs = all_directional_pf1D_Decoder.decode(unit_specific_time_binned_spike_counts=unit_specific_time_binned_spike_counts, time_bin_size=0.020, output_flat_versions=True, debug_print=True)\n",
    "_decoded_pos_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbae7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_directional_pf1D_Decoder.neuron_IDs # array([  2,   5,   8,  10,  14,  15,  23,  24,  25,  26,  31,  32,  33,  41,  49,  50,  51,  55,  58,  64,  69,  70,  73,  74,  75,  76,  78,  82,  83,  85,  86,  90,  92,  93,  96, 109])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ee5251",
   "metadata": {},
   "outputs": [],
   "source": [
    "_decoded_pos_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c71ddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.laps import Laps\n",
    "\n",
    "\n",
    "curr_laps_df = Laps._compute_lap_dir_from_smoothed_velocity(laps_df=curr_laps_df, global_session=global_session, replace_existing=True)\n",
    "curr_laps_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd23d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_editor.plots.lap_epoch_widgets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe294f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.get_session_context()\n",
    "\n",
    "# Context(format_name= 'kdiba', animal= 'gor01', exper_name= 'one', session_name= '2006-6-09_1-22-43')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56697b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_df = deepcopy(epochs_editor.get_user_labeled_epochs_df())\n",
    "laps_df\n",
    "laps_df.to_clipboard(sep=',', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341aaedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop the first two laps:\n",
    "laps_df = laps_df[laps_df['lap_id'] > 2].reset_index(drop=True)\n",
    "laps_df\n",
    "## re-index\n",
    "laps_df['lap_id'] = laps_df.index\n",
    "laps_df['label'] = laps_df.index\n",
    "laps_df.to_clipboard(sep=',', excel=False)\n",
    "# laps_df[['start', 'stop', 'lap_dir']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad33e3c",
   "metadata": {
    "tags": [
     "active-2025-01-13"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import override_laps\n",
    "\n",
    "override_laps_df: Optional[pd.DataFrame] = UserAnnotationsManager.get_hardcoded_laps_override_dict().get(curr_active_pipeline.get_session_context(), None)\n",
    "if override_laps_df is not None:\n",
    "    print(f'overriding laps....')\n",
    "    display(override_laps_df)\n",
    "    override_laps(curr_active_pipeline, override_laps_df=override_laps_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ea0059",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacing_computation_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff3fcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "override_laps_df\n",
    "# override_laps_obj.filtered_by_lap_flat_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c601c54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_filtered_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b80e699",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.replace_session_laps_with_estimates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2482b0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.plotting.placemaps import plot_placefield_occupancy\n",
    "\n",
    "plot_placefield_occupancy(global_pf1D, plot_pos_bin_axes=True)\n",
    "# global_pf1D.plot_occupancy(plot_pos_bin_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2808c7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to separate out the main-track vs.the platforms so that I can impose continuity constraints (for filtering replays via step-sizes) only on the bins of the main track.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd9d391",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.epochs\n",
    "# global_session.epochs\n",
    "# long_session.epochs\n",
    "# short_session.epochs\n",
    "## find first lap\n",
    "global_laps\n",
    "\n",
    "# curr_active_pipeline.sess.position.to_dataframe()\n",
    "long_session.position.to_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca411f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "active_sess_config = deepcopy(curr_active_pipeline.active_sess_config)\n",
    "# absolute_start_timestamp: float = active_sess_config.absolute_start_timestamp\n",
    "loaded_track_limits = active_sess_config.loaded_track_limits # x_midpoint, \n",
    "loaded_track_limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d8bd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "(first_valid_pos_time, last_valid_pos_time) = curr_active_pipeline.find_first_and_last_valid_position_times()\n",
    "first_valid_pos_time, last_valid_pos_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f464ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.get_all_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e68bec8",
   "metadata": {
    "tags": [
     "active",
     "great"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.plotting.figure import pretty_plot\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.placefield import plot_1d_placecell_validations\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.placefield import plot_single_cell_1D_placecell_validation\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.placefield import _subfn_plot_pf1D_placefield\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import test_plotRaw_v_time\n",
    "\n",
    "\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "\n",
    "\n",
    "# global_session.config.plotting_config\n",
    "active_config = deepcopy(curr_active_pipeline.active_configs[global_epoch_name])\n",
    "active_pf1D = deepcopy(global_pf1D)\n",
    "\n",
    "fig = plt.figure(figsize=(23, 9.7), clear=True, num='test_plotRaw_v_time')\n",
    "# Need axes:\n",
    "# Layout Subplots in Figure:\n",
    "gs = fig.add_gridspec(1, 8)\n",
    "gs.update(wspace=0, hspace=0.05) # set the spacing between axes. # `wspace=0`` is responsible for sticking the pf and the activity axes together with no spacing\n",
    "ax_activity_v_time = fig.add_subplot(gs[0, :-1]) # all except the last element are the trajectory over time\n",
    "ax_pf_tuning_curve = fig.add_subplot(gs[0, -1], sharey=ax_activity_v_time) # The last element is the tuning curve\n",
    "# if should_include_labels:\n",
    "    # ax_pf_tuning_curve.set_title('Normalized Placefield', fontsize='14')\n",
    "ax_pf_tuning_curve.set_xticklabels([])\n",
    "ax_pf_tuning_curve.set_yticklabels([])\n",
    "\n",
    "\n",
    "cellind: int = 2\n",
    "\n",
    "kwargs = {}\n",
    "# jitter the curve_value for each spike based on the time it occured along the curve:\n",
    "spikes_color_RGB = kwargs.get('spikes_color', (0, 0, 0))\n",
    "spikes_alpha = kwargs.get('spikes_alpha', 0.8)\n",
    "# print(f'spikes_color: {spikes_color_RGB}')\n",
    "should_plot_bins_grid = kwargs.get('should_plot_bins_grid', False)\n",
    "\n",
    "should_include_trajectory = kwargs.get('should_include_trajectory', True) # whether the plot should include \n",
    "should_include_labels = kwargs.get('should_include_labels', True) # whether the plot should include text labels, like the title, axes labels, etc\n",
    "should_include_plotRaw_v_time_spikes = kwargs.get('should_include_spikes', True) # whether the plot should include plotRaw_v_time-spikes, should be set to False to plot completely with the new all spikes mode\n",
    "use_filtered_positions: bool = kwargs.pop('use_filtered_positions', False)\n",
    "\n",
    "# position_plot_kwargs = {'color': '#393939c8', 'linewidth': 1.0, 'zorder':5} | kwargs.get('position_plot_kwargs', {}) # passed into `active_epoch_placefields1D.plotRaw_v_time`\n",
    "position_plot_kwargs = {'color': '#757575c8', 'linewidth': 1.0, 'zorder':5} | kwargs.get('position_plot_kwargs', {}) # passed into `active_epoch_placefields1D.plotRaw_v_time`\n",
    "\n",
    "\n",
    "# _out = test_plotRaw_v_time(active_pf1D=active_pf1D, cellind=cellind)\n",
    "# spike_plot_kwargs = {'linestyle':'none', 'markersize':5.0, 'marker': '.', 'markerfacecolor':spikes_color_RGB, 'markeredgecolor':spikes_color_RGB, 'zorder':10} ## OLDER\n",
    "spike_plot_kwargs = {'zorder':10} ## OLDER\n",
    "\n",
    "\n",
    "# active_pf1D.plotRaw_v_time(cellind, ax=ax_activity_v_time, spikes_alpha=spikes_alpha,\n",
    "# \tposition_plot_kwargs=position_plot_kwargs,\n",
    "# \tspike_plot_kwargs=spike_plot_kwargs,\n",
    "# \tshould_include_labels=should_include_labels, should_include_trajectory=should_include_trajectory, should_include_spikes=should_include_plotRaw_v_time_spikes,\n",
    "# \tuse_filtered_positions=use_filtered_positions,\n",
    "# ) # , spikes_color=spikes_color, spikes_alpha=spikes_alpha\n",
    "\n",
    "_out = test_plotRaw_v_time(active_pf1D=active_pf1D, cellind=cellind, ax=ax_activity_v_time, spikes_alpha=spikes_alpha,\n",
    "    position_plot_kwargs=position_plot_kwargs,\n",
    "    spike_plot_kwargs=spike_plot_kwargs,\n",
    "    should_include_labels=should_include_labels, should_include_trajectory=should_include_trajectory, should_include_spikes=should_include_plotRaw_v_time_spikes,\n",
    "    use_filtered_positions=use_filtered_positions,\n",
    ")\n",
    "\n",
    "_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be863cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_out = _subfn_plot_pf1D_placefield(active_epoch_placefields1D=active_pf1D, placefield_cell_index=cellind,\n",
    "                                ax_activity_v_time=ax_activity_v_time, ax_pf_tuning_curve=ax_pf_tuning_curve, pf_tuning_curve_ax_position='right')\n",
    "_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b30c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as itt\n",
    "from mpl_multitab import MplMultiTab\n",
    "\n",
    "n_cells = active_placefields1D.ratemap.n_neurons\n",
    "out_figures_list = []\n",
    "out_axes_list = []\n",
    "\n",
    "if should_save:\n",
    "    curr_parent_out_path = plotting_config.active_output_parent_dir.joinpath('1d Placecell Validation')\n",
    "    curr_parent_out_path.mkdir(parents=True, exist_ok=True)        \n",
    "    \n",
    "# Tabbed Matplotlib Figure Mode:\n",
    "ui = MplMultiTab(title='plot_1d_placecell_validations')\n",
    "\n",
    "\n",
    "for a_decoder_name, a_decoder in track_templates.get_decoders_dict().items():\n",
    "    print(f'a_decoder_name: {a_decoder}')\n",
    "    curr_pf1D = a_decoder.pf\n",
    "    curr_pf1D.    \n",
    "\n",
    "    fig = ui.add_tab(f'Dataset {c.upper()}', f'Observation {m}')\n",
    "    ax = fig.subplots()\n",
    "    \n",
    "\n",
    "\n",
    "for i in np.arange(n_cells):\n",
    "    curr_cell_id = active_placefields1D.cell_ids[i]\n",
    "    # fig = ui.add_tab(f'Dataset {modifier_string}', f'Cell {curr_cell_id}') # Tabbed mode only\n",
    "    fig = ui.add_tab(f'Cell{curr_cell_id}')\n",
    "\n",
    "    fig, axs = plot_single_cell_1D_placecell_validation(active_placefields1D, i, extant_fig=fig, **(plot_kwargs or {}))\n",
    "    out_figures_list.append(fig)\n",
    "    out_axes_list.append(axs)\n",
    "\n",
    "# once done, save out as specified\n",
    "common_basename = active_placefields1D.str_for_filename(prefix_string=modifier_string)\n",
    "if should_save:\n",
    "    common_basename = active_placefields1D.str_for_filename(prefix_string=modifier_string)\n",
    "    if save_mode == 'separate_files':\n",
    "        # make a subdirectory for this run (with these parameters and such)\n",
    "        curr_specific_parent_out_path = curr_parent_out_path.joinpath(common_basename)\n",
    "        curr_specific_parent_out_path.mkdir(parents=True, exist_ok=True)\n",
    "        print(f'Attempting to write {n_cells} separate figures to {str(curr_specific_parent_out_path)}')\n",
    "        for i in np.arange(n_cells):\n",
    "            print('Saving figure {} of {}...'.format(i, n_cells))\n",
    "            curr_cell_id = active_placefields1D.cell_ids[i]\n",
    "            fig = out_figures_list[i]\n",
    "            # curr_cell_filename = 'pf1D-' + modifier_string + _filename_for_placefield(active_placefields1D, curr_cell_id) + '.png'\n",
    "            curr_cell_basename = '-'.join([common_basename, f'cell_{curr_cell_id:02d}'])\n",
    "            # add the file extension\n",
    "            curr_cell_filename = f'{curr_cell_basename}.png'\n",
    "            active_pf_curr_cell_output_filepath = curr_specific_parent_out_path.joinpath(curr_cell_filename)\n",
    "            fig.savefig(active_pf_curr_cell_output_filepath)\n",
    "    elif save_mode == 'pdf':\n",
    "        print('saving multipage pdf...')\n",
    "        curr_cell_basename = common_basename\n",
    "        # add the file extension\n",
    "        curr_cell_filename = f'{curr_cell_basename}-multipage_pdf.pdf'\n",
    "        pdf_save_path = curr_parent_out_path.joinpath(curr_cell_filename)\n",
    "        save_to_multipage_pdf(out_figures_list, save_file_path=pdf_save_path)\n",
    "    else:\n",
    "        raise ValueError\n",
    "    print('\\t done.')\n",
    "\n",
    "\n",
    "# ui.show() # Tabbed mode only\n",
    "_final_out = MatplotlibRenderPlots(name=f'{common_basename}', figures=out_figures_list, axes=out_axes_list, ui=ui)\n",
    "## OUTPUT: _final_out\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38ee8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_pf1D.run_spk_pos\n",
    "active_pf1D.spk_pos\n",
    "active_pf1D.run_spk_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c8e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_pf1D.ratemap_spiketrains\n",
    "active_pf1D.ratemap_spiketrains_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d290ccab",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = plot_1d_placecell_validations(active_pf1D, active_config.plotting_config, modifier_string='lap_only', should_save=False)\n",
    "# _out = curr_active_pipeline.display('_display_1d_placefield_validations', 'maze_any')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f853e158",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out.ui.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71088cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib_configuration_update(\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e362334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with matplotlib_interactivity(is_interactive=True):\n",
    "_out.figures[0].show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc6123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qclu_included_aclus = curr_active_pipeline.determine_good_aclus_by_qclu(included_qclu_values=[1,2,4,9])\n",
    "qclu_included_aclus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9e4db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_neuron_ids_list = [a_decoder.pf.ratemap.neuron_ids for a_decoder in (long_LR_decoder, long_RL_decoder, short_LR_decoder, short_RL_decoder)]\n",
    "original_neuron_ids_list = [a_decoder.pf.ratemap.neuron_ids for a_decoder in track_templates.get_decoders_dict().values()]\n",
    "original_neuron_ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9a96b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_names = track_templates.get_decoder_names() # ('long_LR', 'long_RL', 'short_LR', 'short_RL')\n",
    "decoder_names = TrackTemplates.get_decoder_names() # ('long_LR', 'long_RL', 'short_LR', 'short_RL')\n",
    "\n",
    "link = #00fff7\n",
    "link_visited = #ffaaff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a46a4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_print = True\n",
    "## INPUTS: included_qclu_values\n",
    "included_qclu_values = [1, 2]\n",
    "\n",
    "# modified_neuron_ids_dict = track_templates.determine_decoder_aclus_filtered_by_qclu(included_qclu_values=included_qclu_values)\n",
    "\n",
    "# filtered_track_templates = track_templates.filtered_by_frate_and_qclu(minimum_inclusion_fr_Hz=None, included_qclu_values=None)\n",
    "# filtered_track_templates = track_templates.filtered_by_frate_and_qclu(included_qclu_values=included_qclu_values)\n",
    "filtered_track_templates = track_templates.filtered_by_frate_and_qclu(minimum_inclusion_fr_Hz=5.0, included_qclu_values=[1, 2])\n",
    "\n",
    "# modified_neuron_ids_dict\n",
    "filtered_track_templates.decoder_neuron_IDs_list\n",
    "_out = dict()\n",
    "_out['_display_short_long_firing_rate_index_comparison'] = curr_active_pipeline.display(display_function='_display_short_long_firing_rate_index_comparison', active_session_configuration_context=None) # _display_short_long_firing_rate_index_comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a1ed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_included_aclus_dict = {}\n",
    "# for a_decoder in track_templates.get_decoders_dict().values():\n",
    "    # a_decoder.pf.spikes_df\n",
    "for a_decoder_name, a_decoder in track_templates.get_decoders_dict().items():\n",
    "    neuron_identities: pd.DataFrame = deepcopy(a_decoder.pf.filtered_spikes_df).spikes.extract_unique_neuron_identities()\n",
    "    if debug_print:\n",
    "        print(f\"original {len(neuron_identities)}\")\n",
    "    filtered_neuron_identities: pd.DataFrame = neuron_identities[neuron_identities.neuron_type == NeuronType.PYRAMIDAL]\n",
    "    if debug_print:\n",
    "        print(f\"post PYRAMIDAL filtering {len(filtered_neuron_identities)}\")\n",
    "    filtered_neuron_identities = filtered_neuron_identities[['aclu', 'shank', 'cluster', 'qclu']]\n",
    "    filtered_neuron_identities = filtered_neuron_identities[np.isin(filtered_neuron_identities.qclu, included_qclu_values)] # drop [6, 7], which are said to have double fields - 80 remain\n",
    "    if debug_print:\n",
    "        print(f\"post (qclu != [6, 7]) filtering {len(filtered_neuron_identities)}\")\n",
    "    # filtered_neuron_identities\n",
    "    final_included_aclus = filtered_neuron_identities['aclu'].to_numpy()\n",
    "    final_included_aclus_dict[a_decoder_name] = final_included_aclus.tolist()\n",
    "\n",
    "\n",
    "final_included_aclus_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543a7317",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display_output_history_list\n",
    "curr_active_pipeline.display_output_last_added_context\n",
    "curr_active_pipeline.last_added_display_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd79d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_templates.any_decoder_neuron_IDs\n",
    "track_templates.decoder_neuron_IDs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acad4458",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650eea58",
   "metadata": {
    "tags": [
     "all",
     "spike_raster_window",
     "display",
     "gui",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import Spike2DRaster\n",
    "from pyphoplacecellanalysis.GUI.Qt.SpikeRasterWindows.Spike3DRasterWindowWidget import Spike3DRasterWindowWidget\n",
    "from pyphoplacecellanalysis.GUI.Qt.PlaybackControls.Spike3DRasterBottomPlaybackControlBarWidget import Spike3DRasterBottomPlaybackControlBar\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import SynchronizedPlotMode\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.spike_raster_widgets import _setup_spike_raster_window_for_debugging\n",
    "\n",
    "# For PlotWidget\n",
    "pg.setConfigOptions(useOpenGL=True)\n",
    "\n",
    "# curr_active_pipeline.reload_default_display_functions()\n",
    "# Gets the existing SpikeRasterWindow or creates a new one if one doesn't already exist:\n",
    "spike_raster_window, (active_2d_plot, active_3d_plot, main_graphics_layout_widget, main_plot_widget, background_static_scroll_plot_widget) = Spike3DRasterWindowWidget.find_or_create_if_needed(curr_active_pipeline, force_create_new=True, use_docked_pyqtgraph_plots=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f87367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.SpikeRasterWindows.Spike3DRasterWindowWidget import Spike3DRasterWindowWidget\n",
    "# active_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.plot._display_spike_rasters_pyqtplot_2D(**kwargs).values()\n",
    "\n",
    "\n",
    "active_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.display('_display_spike_rasters_pyqtplot_2D', active_session_configuration_context='maze_any')\n",
    "# active_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.dsiplay('_display_spike_rasters_window')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2bce24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.SpikeRasterWindows.Spike3DRasterWindowWidget import Spike3DRasterWindowWidget\n",
    "\n",
    "# spike_raster_window, (active_2d_plot, active_3d_plot, main_graphics_layout_widget, main_plot_widget, background_static_scroll_plot_widget) = Spike3DRasterWindowWidget.find_or_create_if_needed(curr_active_pipeline, force_create_new=False)\n",
    "spike_raster_window, (active_2d_plot, active_3d_plot, *_out_args) = Spike3DRasterWindowWidget.find_or_create_if_needed(curr_active_pipeline, force_create_new=False)\n",
    "\n",
    "active_2d_plot\n",
    "active_3d_plot\n",
    "spike_raster_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcd6c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_2d_plot.find_matplotlib_render_plot_widget('interval_overview')\n",
    "intervals_overview_dock, intervals_overview_time_sync_pyqtgraph_widget = active_2d_plot.find_dock_item_tuple(identifier='interval_overview')\n",
    "# root_graphics_layout_widget = active_2d_plot.ui.matplotlib_view_widgets[name].getRootGraphicsLayoutWidget()\n",
    "# plot_item = active_2d_plot.ui.matplotlib_view_widgets[name].getRootPlotItem()\n",
    "intervals_overview_root_graphics_layout_widget = intervals_overview_time_sync_pyqtgraph_widget.getRootGraphicsLayoutWidget()\n",
    "intervals_overview_plot_item = intervals_overview_time_sync_pyqtgraph_widget.getRootPlotItem()\n",
    "\n",
    "\n",
    "# intervals_overview_plot_item.set\n",
    "# intervals_plot_item.setXRange(self.spikes_window.active_window_start_time, self.spikes_window.active_window_end_time, padding=0)\n",
    "\n",
    "intervals_overview_plot_item.setXRange(active_2d_plot.spikes_window.total_data_start_time, active_2d_plot.spikes_window.total_data_end_time, padding=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0c8093",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_overview_plot_item.setClipToView(True) # Usually default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac0b331",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.get_leaf_only_flat_dock_identifiers_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd7284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_docked_pyqtgraph_plots_mode: bool = spike_raster_window.params.use_docked_pyqtgraph_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a46242",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_global_menus_actionsDict, global_flat_action_dict, _all_outputs_dict = _setup_spike_raster_window_for_debugging(spike_raster_window, wants_docked_raster_window_track=True, enable_interval_overview_track=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39cfd03",
   "metadata": {
    "tags": [
     "run-group-mergedcolorplot",
     "run-spike_raster_window_test"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import Spike2DRaster\n",
    "from pyphoplacecellanalysis.GUI.Qt.SpikeRasterWindows.Spike3DRasterWindowWidget import Spike3DRasterWindowWidget\n",
    "from pyphoplacecellanalysis.GUI.Qt.PlaybackControls.Spike3DRasterBottomPlaybackControlBarWidget import Spike3DRasterBottomPlaybackControlBar\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import SynchronizedPlotMode\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.spike_raster_widgets import _setup_spike_raster_window_for_debugging\n",
    "\n",
    "# For PlotWidget\n",
    "pg.setConfigOptions(useOpenGL=True)\n",
    "# pg.setConfigOptions(useOpenGL=False)\n",
    "\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-Spike3DRasterWindowWidget.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "# Gets the existing SpikeRasterWindow or creates a new one if one doesn't already exist:\n",
    "spike_raster_window, (active_2d_plot, active_3d_plot, _all_outputs_dict) = Spike3DRasterWindowWidget.find_or_create_if_needed(curr_active_pipeline, force_create_new=True,\n",
    "    wants_docked_raster_window_track=True, enable_interval_overview_track=True, allow_replace_hardcoded_main_plots_with_tracks=True,\n",
    ")\n",
    "main_graphics_layout_widget = _all_outputs_dict['main_graphics_layout_widget'] \n",
    "main_plot_widget = _all_outputs_dict['main_plot_widget']\n",
    "background_static_scroll_plot_widget = _all_outputs_dict['background_static_scroll_plot_widget']\n",
    "\n",
    "all_global_menus_actionsDict = _all_outputs_dict['all_global_menus_actionsDict']\n",
    "global_flat_action_dict = _all_outputs_dict['global_flat_action_dict']\n",
    "# all_global_menus_actionsDict, global_flat_action_dict, _all_outputs_dict = _setup_spike_raster_window_for_debugging(spike_raster_window, wants_docked_raster_window_track=True, enable_interval_overview_track=True, allow_replace_hardcoded_main_plots_with_tracks=False)\n",
    "# all_global_menus_actionsDict, global_flat_action_dict, _all_outputs_dict = _setup_spike_raster_window_for_debugging(spike_raster_window, wants_docked_raster_window_track=True, enable_interval_overview_track=True, allow_replace_hardcoded_main_plots_with_tracks=False)\n",
    "\n",
    "# # preview_overview_scatter_plot: pg.ScatterPlotItem  = active_2d_plot.plots.preview_overview_scatter_plot # ScatterPlotItem \n",
    "# # preview_overview_scatter_plot.setDownsampling(auto=True, method='subsample', dsRate=10)\n",
    "# main_graphics_layout_widget: pg.GraphicsLayoutWidget = active_2d_plot.ui.main_graphics_layout_widget\n",
    "# wrapper_layout: pg.QtWidgets.QVBoxLayout = active_2d_plot.ui.wrapper_layout\n",
    "# main_content_splitter = active_2d_plot.ui.main_content_splitter # QSplitter\n",
    "# layout = active_2d_plot.ui.layout\n",
    "# background_static_scroll_window_plot = active_2d_plot.plots.background_static_scroll_window_plot # PlotItem\n",
    "# main_plot_widget = active_2d_plot.plots.main_plot_widget # PlotItem\n",
    "# active_window_container_layout = active_2d_plot.ui.active_window_container_layout # GraphicsLayout, first item of `main_graphics_layout_widget` -- just the active raster window I think, there is a strange black space above it\n",
    "# bottom_bar: Spike3DRasterBottomPlaybackControlBar = spike_raster_window.bottom_playback_control_bar_widget\n",
    "# # bottom_bar.log_print('test manual log entry')\n",
    "# bottom_bar.add_log_line('test manual log entry')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceacbe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.PlaybackControls.Spike3DRasterBottomPlaybackControlBarWidget import Spike3DRasterBottomPlaybackControlBar, SpikeRasterBottomFrameControlsMixin\n",
    "\n",
    "\n",
    "# active_2d_plot\n",
    "bottom_playback_control_bar_widget: Spike3DRasterBottomPlaybackControlBar = spike_raster_window.bottom_playback_control_bar_widget\n",
    "bottom_playback_control_bar_widget\n",
    "\n",
    "btnToogleTimeEdit: pg.QtWidgets.QToolButton = bottom_playback_control_bar_widget.ui.btnEditNumberField_Toggle\n",
    "btnToogleTimeEdit.setChecked(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ed0bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.on_crosshair_trace_toggled()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49d207c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e79a760",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.layout_dockGroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7009ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "# decoding_time_bin_size = 0.025\n",
    "# filter_epochs_decoder_result, active_filter_epochs, default_figure_name = long_results['specific_epochs_decoding'][('Ripples', decoding_time_bin_size)]\n",
    "\n",
    "_out = dict()\n",
    "_out['_display_plot_decoded_epoch_slices'] = curr_active_pipeline.display(display_function='_display_plot_decoded_epoch_slices', active_session_configuration_context=IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43',filter_name='maze2_any',lap_dir='any'), filter_epochs='replay') # _display_plot_decoded_epoch_slices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e54270",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import _build_additional_window_menus\n",
    "## Build the additional menus:\n",
    "output_references = _build_additional_window_menus(spike_raster_window, owning_pipeline_reference=curr_active_pipeline, computation_result, active_display_fn_identifying_ctx) ## the menus on the other hand take the entire pipeline, because they might need that valuable DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38054838",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recompute the one and two-step decoding computations continuously\n",
    "\n",
    "# ['_perform_position_decoding_computation', '_perform_two_step_position_decoding_computation']\n",
    "# ['position_decoding', 'position_decoding_two_step']\n",
    "\n",
    "debug_print: bool = False\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_perform_position_decoding_computation', '_perform_two_step_position_decoding_computation'],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t  computation_kwargs_list=[{'override_decoding_time_bin_size': 0.025, 'debug_print': debug_print}, {'debug_print': debug_print}],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t  enabled_filter_names=None, fail_on_exception=True, debug_print=debug_print)\n",
    "\n",
    "active_one_step_decoder = curr_active_pipeline.computation_results[active_config_name].computed_data.get('pf2D_Decoder', None)\n",
    "\n",
    "\n",
    "assert active_one_step_decoder is not None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b8665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_one_step_decoder.flat_p_x_given_n.shape # (472, 66151)\n",
    "np.shape(active_one_step_decoder.p_x_given_n) # (59, 8, 66151)\n",
    "np.shape(active_one_step_decoder.P_x) # (472, 1)\n",
    "active_one_step_decoder.original_position_data_shape # (59, 8)\n",
    "active_one_step_decoder.flat_position_size # 472\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e690d756",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_perform_two_step_position_decoding_computation'],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t  computation_kwargs_list=[{'ndim': 2, 'debug_print': debug_print}],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t  enabled_filter_names=None, fail_on_exception=True, debug_print=debug_print)\n",
    "\n",
    "active_two_step_decoder = curr_active_pipeline.computation_results[active_config_name].computed_data.get('pf2D_TwoStepDecoder', None)\n",
    "assert active_two_step_decoder is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb672a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_one_step_decoder.xbin\n",
    "active_one_step_decoder.ybin\n",
    "\n",
    "active_two_step_decoder.xbin\n",
    "active_two_step_decoder.ybin\n",
    "\n",
    "# active_two_step_decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a82d026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import AddNewDecodedPosition_MatplotlibPlotCommand, AddNewLongShortDecodedEpochSlices_MatplotlibPlotCommand, AddNewTrackTemplatesDecodedEpochSlicesRows_MatplotlibPlotCommand # for add matplotlib plot action\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import AddNewDirectionalDecodedEpochs_MatplotlibPlotCommand, AddNewDecodedPosteriors_MatplotlibPlotCommand, AddNewDecodedEpochMarginal_MatplotlibPlotCommand\n",
    "from pyphoplacecellanalysis.GUI.Qt.Menus.SpecificMenus.CreateLinkedWidget_MenuProvider import CreateNewTimeSynchronizedPlotterCommand, CreateNewTimeSynchronizedCombinedPlotterCommand\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.TimeSynchronizedPositionDecoderPlotter import TimeSynchronizedPositionDecoderPlotter\n",
    "\n",
    "active_config_name = None # kwargs.get('active_config_name', None)\n",
    "active_config_name = global_any_name\n",
    "active_context = None\n",
    "display_output = {}\n",
    "active_pf_2D_dt = curr_active_pipeline.computation_results[active_config_name].computed_data.get('pf2D_dt', None)\n",
    "active_one_step_decoder = curr_active_pipeline.computation_results[active_config_name].computed_data.get('pf2D_Decoder', None)\n",
    "active_two_step_decoder = curr_active_pipeline.computation_results[active_config_name].computed_data.get('pf2D_TwoStepDecoder', None)\n",
    "_out = CreateNewTimeSynchronizedPlotterCommand(spike_raster_window, active_pf_2D_dt=active_pf_2D_dt, plotter_type='decoder', curr_active_pipeline=curr_active_pipeline, active_context=active_context, active_config_name=active_config_name, display_output=display_output, action_identifier='actionTimeSynchronizedDecoderPlotter')\n",
    "_out.execute()\n",
    "a_plotter_obj, _a_conn = display_output['synchronizedPlotter_decoder']\n",
    "active_ax = a_plotter_obj.ui.root_plot\n",
    "a_plotter_obj: TimeSynchronizedPositionDecoderPlotter = a_plotter_obj # TimeSynchronizedPositionDecoderPlotter \n",
    "(long_rects_outputs, short_rects_outputs) = a_plotter_obj.add_track_shapes()\n",
    "a_plotter_obj.update(t=active_2d_plot.active_window_start_time, defer_render=False)\n",
    "\n",
    "## OUTPUTS: active_ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fd0483",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_one_step_decoder.xbin\n",
    "active_one_step_decoder.ybin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ea8f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_plotter_obj.params.x_range\n",
    "a_plotter_obj.params.y_range\n",
    "a_plotter_obj.params.image_bounds_extent # [0.0, 86.33093525179856, 287.7697841726619, 115.10791366906471]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e38ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import LinearTrackDimensions, test_LinearTrackDimensions_2D_pyqtgraph\n",
    "\n",
    "long_track_dims = LinearTrackDimensions(track_length=170.0)\n",
    "short_track_dims = LinearTrackDimensions(track_length=100.0)\n",
    "\n",
    "app, w, cw, (ax0, ax1), (long_track_dims, long_rect_items, long_rects), (short_track_dims, short_rect_items, short_rects) = test_LinearTrackDimensions_2D_pyqtgraph(long_track_dims, short_track_dims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ae2b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import LinearTrackInstance\n",
    "from neuropy.utils.mixins.dict_representable import overriding_dict_with\n",
    "\n",
    "loaded_track_limits = {'long_xlim': np.array([59.0774, 228.69]),\n",
    "    'long_unit_xlim': np.array([0.205294, 0.794698]),\n",
    "    'short_xlim': np.array([94.0156, 193.757]),\n",
    "    'short_unit_xlim': np.array([0.326704, 0.673304]),\n",
    "    'long_ylim': np.array([138.164, 146.12]),\n",
    "    'long_unit_ylim': np.array([0.48012, 0.507766]),\n",
    "    'short_ylim': np.array([138.021, 146.263]),\n",
    "    'short_unit_ylim': np.array([0.479622, 0.508264]),\n",
    "}\n",
    "\n",
    "## INPUTS: active_ax\n",
    "\n",
    "long_track_inst, short_track_inst = LinearTrackInstance.init_LS_tracks_from_loaded_track_limits(loaded_track_limits=loaded_track_limits)\n",
    "# long_rects_outputs, short_rects_outputs = \n",
    "# long_track_inst\n",
    "# # Centered above and below the y=0.0 line:\n",
    "# long_offset = (long_track_inst.grid_bin_bounds.center_point[0], 0.75)\n",
    "# short_offset = (short_track_inst.grid_bin_bounds.center_point[0], -0.75)\n",
    "\n",
    "# active_ax = a_plotter_obj.ui.root_plot\n",
    "\n",
    "\n",
    "# long_track_combined_collection, long_rect_items, long_rects = long_track_inst.plot_rects(active_ax)\n",
    "# short_track_combined_collection, short_rect_items, short_rects = short_track_inst.plot_rects(active_ax)\n",
    "\n",
    "# long_epoch_matplotlib_config = long_short_display_config_manager.long_epoch_config.as_matplotlib_kwargs()\n",
    "# long_kwargs = deepcopy(long_epoch_matplotlib_config)\n",
    "long_kwargs = dict(edgecolor='#0000FFFF', facecolor=\"#0000FFB7\")\n",
    "# long_kwargs = dict(edgecolor='#000000ff', facecolor='#000000ff')\n",
    "# long_rects_outputs = long_track_inst.plot_rects(active_ax, offset=long_offset, matplotlib_rect_kwargs_override=overriding_dict_with(lhs_dict=long_kwargs, **dict(linewidth=2, zorder=-99)))\n",
    "long_rects_outputs = long_track_inst.plot_rects(active_ax, matplotlib_rect_kwargs_override=overriding_dict_with(lhs_dict=long_kwargs, **dict(linewidth=2, zorder=-99)))\n",
    "\n",
    "# short_epoch_matplotlib_config = long_short_display_config_manager.short_epoch_config.as_matplotlib_kwargs()\n",
    "# short_kwargs = deepcopy(short_epoch_matplotlib_config)\n",
    "short_kwargs = dict(edgecolor='#FF0000FF', facecolor=\"#FF0000B7\")\n",
    "# short_kwargs = dict(edgecolor='#000000ff', facecolor='#000000ff')\n",
    "# short_rects_outputs = short_track_inst.plot_rects(active_ax, offset=short_offset, matplotlib_rect_kwargs_override=overriding_dict_with(lhs_dict=short_kwargs, **dict(linewidth=2, zorder=-99)))\n",
    "short_rects_outputs = short_track_inst.plot_rects(active_ax, matplotlib_rect_kwargs_override=overriding_dict_with(lhs_dict=short_kwargs, **dict(linewidth=2, zorder=-99)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11968a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.Mixins.InteractivePlotterMixins import InteractivePyvistaPlotter_PointAndPathPlottingMixin\n",
    "from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.InteractivePlaceCellDataExplorer import InteractivePlaceCellDataExplorer\n",
    "\n",
    "_out = dict()\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out['_display_3d_interactive_spike_and_behavior_browser'] = curr_active_pipeline.display(display_function='_display_3d_interactive_spike_and_behavior_browser', active_session_configuration_context=IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19',filter_name='maze_any',lap_dir='any')) # _display_3d_interactive_spike_and_behavior_browser\n",
    "_out['_display_3d_interactive_spike_and_behavior_browser']\n",
    "ipspikesDataExplorer = _out['_display_3d_interactive_spike_and_behavior_browser']['ipspikesDataExplorer']\n",
    "p = _out['_display_3d_interactive_spike_and_behavior_browser']['plotter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40395133",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipspikesDataExplorer.animal_current_location_point ## actor\n",
    "ipspikesDataExplorer.plots_data['animal_current_location_point']\n",
    "ipspikesDataExplorer.plots['animal_current_location_point']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06df5a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipspikesDataExplorer.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af35fc52",
   "metadata": {},
   "source": [
    "## Adding Grid_bin_bound position validations as tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff98bb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_man = curr_active_pipeline.get_output_manager()\n",
    "fig_man.get_figure_output_parent_and_basename(final_context=curr_active_pipeline.get_session_context(), make_folder_if_needed=False)\n",
    "\n",
    "# FileOutputManager(figure_output_location=<FigureOutputLocation.DAILY_PROGRAMMATIC_OUTPUT_FOLDER: 'daily_programmatic_output_folder'>, context_to_path_mode=<ContextToPathMode.HIERARCHY_UNIQUE: 'hierarchy_unique'>, override_output_parent_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efd0cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import SynchronizedPlotMode\n",
    "\n",
    "## Add to timeline\n",
    "active_2d_plot: Spike2DRaster = active_2d_plot\n",
    "\n",
    "\n",
    "_bounds_validation_track_axs = {}\n",
    "a_dock_identifier: str = 'BoundsValidation_x'\n",
    "_bounds_validation_track_axs[a_dock_identifier] = active_2d_plot.add_new_matplotlib_render_plot_widget(name=a_dock_identifier, sync_mode=SynchronizedPlotMode.TO_GLOBAL_DATA)[2][0]\n",
    "\n",
    "a_dock_identifier: str = 'BoundsValidation_y'\n",
    "_bounds_validation_track_axs[a_dock_identifier] = active_2d_plot.add_new_matplotlib_render_plot_widget(name=a_dock_identifier, sync_mode=SynchronizedPlotMode.TO_GLOBAL_DATA)[2][0]\n",
    "_bounds_validation_track_axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa3dcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, ax in _bounds_validation_track_axs.items():\n",
    "\tax.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2a0dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_out = dict()\n",
    "_out['_display_grid_bin_bounds_validation_x'] = curr_active_pipeline.display(display_function='_display_grid_bin_bounds_validation', active_session_configuration_context=None, is_x_axis=True, ax=_bounds_validation_track_axs['BoundsValidation_x']) # _display_grid_bin_bounds_validation\n",
    "_out['_display_grid_bin_bounds_validation_y'] = curr_active_pipeline.display(display_function='_display_grid_bin_bounds_validation', active_session_configuration_context=None, is_x_axis=False, ax=_bounds_validation_track_axs['BoundsValidation_y']) # _display_grid_bin_bounds_validation\n",
    "\n",
    "## sync only after so the grid_bin_bounds lines extend across the whole thing\n",
    "active_2d_plot.sync_matplotlib_render_plot_widget('BoundsValidation_x', sync_mode=SynchronizedPlotMode.TO_WINDOW)\n",
    "active_2d_plot.sync_matplotlib_render_plot_widget('BoundsValidation_y', sync_mode=SynchronizedPlotMode.TO_WINDOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1ba555",
   "metadata": {},
   "source": [
    "## Other from pre-2025-07-02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b952fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_rects_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fe14e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_one_step_decoder.P_x.shape # active_one_step_decoder.P_x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f12a92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_plotter_obj.params.image_bounds_extent\n",
    "a_plotter_obj.params.x_range\n",
    "a_plotter_obj.params.y_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bee998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_plotter_obj.params.posterior_variable_to_render = 'p_x_given_n'\n",
    "a_plotter_obj.posterior_variable_to_render = 'p_x_given_n_and_x_prev'\n",
    "a_plotter_obj.update(t=active_2d_plot.active_window_start_time, defer_render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfc5daa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf50adb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.params.enable_non_marginalized_raw_result = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7bcfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_plotter_obj.time_window_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca93e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.active_window_start_time\n",
    "# active_2d_plot.animation_active_time_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc81db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "on_window_changed(self, start_t, end_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab851679",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca040e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_flat_action_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6a535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: global_flat_action_dict\n",
    "\n",
    "menu_commands = [\n",
    "    # 'AddTimeCurves.Position', ## 2025-03-11 02:32 Running this too soon after launching the window causes weird black bars on the top and bottom of the window\n",
    "    'AddTimeCurves.ThetaPhase',\n",
    "    # 'DockedWidgets.LongShortDecodedEpochsDockedMatplotlibView',\n",
    "    # 'DockedWidgets.DirectionalDecodedEpochsDockedMatplotlibView',\n",
    "    # 'DockedWidgets.TrackTemplatesDecodedEpochsDockedMatplotlibView',\n",
    "    # 'DockedWidgets.Pseudo2DDecodedEpochsDockedMatplotlibView', # [/c:/Users/pho/repos/Spike3DWorkEnv/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/Qt/Menus/SpecificMenus/DockedWidgets_MenuProvider.py:141](vscode://file/c:/Users/pho/repos/Spike3DWorkEnv/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/Qt/Menus/SpecificMenus/DockedWidgets_MenuProvider.py:141)`'actionPseudo2DDecodedEpochsDockedMatplotlibView': AddNewDecodedPosteriors_MatplotlibPlotCommand`\n",
    "    #  'DockedWidgets.ContinuousPseudo2DDecodedMarginalsDockedMatplotlibView',\n",
    "]\n",
    "# menu_commands = ['actionPseudo2DDecodedEpochsDockedMatplotlibView', 'actionContinuousPseudo2DDecodedMarginalsDockedMatplotlibView'] # , 'AddTimeIntervals.SessionEpochs'\n",
    "\n",
    "# Run after a 0.5 second delay\n",
    "for a_command in menu_commands:\n",
    "    # all_global_menus_actionsDict[a_command].trigger()\n",
    "    global_flat_action_dict[a_command].trigger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce46022",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.clear_all_3D_time_curves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b6ad1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.update_3D_time_curves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17552aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_time_curves_datasource = active_2d_plot.params.time_curves_datasource\n",
    "active_time_curves_datasource.merge(on='t', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac52164",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.plots.time_curves['default_plot_datasource.y position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1a31e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_plot_item = list(active_2d_plot.plots.time_curves.values())[0]\n",
    "\n",
    "## override theta phase pen:\n",
    "## firing statistics to bins instead of boolean masking by those meeting criteria\n",
    "spikes_df: pd.DataFrame = get_proper_global_spikes_df(curr_active_pipeline)\n",
    "theta_phase_radians = spikes_df['theta_phase_radians'].to_numpy()\n",
    "\n",
    "\n",
    "cmap = pg.colormap.get('CET-C2s') # rainbow\n",
    "\n",
    "# Example 1: Gradient pen\n",
    "# cmap = pg.colormap.get('CET-L17') # prepare a linear color map\n",
    "# cmap.reverse()                    # reverse it to put light colors at the top \n",
    "pen = cmap.getPen(span=(0.0, (2.0*np.pi)), width=5) # gradient from blue (y=0) to white (y=1)\n",
    "# plot a curve drawn with a pen colored according to y value:\n",
    "curve1 = pg.PlotDataItem(y=y_data1, pen=pen)\n",
    "\n",
    "\n",
    "theta_cmap = cmap.map(theta_phase_radians, mode='qcolor') # List[QColor]\n",
    "theta_cmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997b5694",
   "metadata": {},
   "outputs": [],
   "source": [
    "pen = pg.mkPen(theta_cmap, width=2)\n",
    "\n",
    "# for i in range(len(x)-1):\n",
    "#     t = i/(len(x)-1)\n",
    "#     pen = pg.mkPen(cmap.map(t, mode='qcolor'), width=2)    \n",
    "    \n",
    "# pen = pg.mkPen(\n",
    "#     color='red',           # Color: string, tuple (R,G,B), or QColor\n",
    "#     width=2,              # Line width in pixels\n",
    "#     style=QtCore.Qt.DashLine,  # Line style: SolidLine, DashLine, DotLine, etc.\n",
    "#     cosmetic=True,        # Whether line width scales with zoom\n",
    "#     capStyle=QtCore.Qt.RoundCap,  # End cap style\n",
    "#     joinStyle=QtCore.Qt.RoundJoin  # Join style for corners\n",
    "# )\n",
    "a_plot_item.setPen(pen)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f08cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = pg.mkQApp()\n",
    "w = pg.PlotWidget()\n",
    "\n",
    "x = np.linspace(0, 10, 200)\n",
    "y = np.sin(x)                       # or any “value” array\n",
    "cmap = pg.colormap.get('CET-C2s')       # rainbow\n",
    "\n",
    "for i in range(len(x)-1):\n",
    "    t = i/(len(x)-1)\n",
    "    pen = pg.mkPen(cmap.map(t, mode='qcolor'), width=2)\n",
    "    w.plot(x[i:i+2], y[i:i+2], pen=pen)\n",
    "\n",
    "w.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0101d1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import FixedCustomColormaps\n",
    "\n",
    "# active_cmap = FixedCustomColormaps.get_custom_greyscale_with_low_values_dropped_cmap(low_value_cutoff=0.01, full_opacity_threshold=0.25, invert_for_black_bg=True)\n",
    "active_cmap = FixedCustomColormaps.get_custom_greyscale_with_low_values_dropped_cmap(low_value_cutoff=0.01, full_opacity_threshold=0.25, invert_for_black_bg=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742ae0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_2d_plot.dock_manager_widget\n",
    "active_dockGroup_dock_dict = active_2d_plot.get_dockGroup_dock_dict()\n",
    "# active_dockGroup_dock_dict['ContinuousDecode_ - t_bin_size: 0.025']\n",
    "\n",
    "active_dockGroup_dock_dict['ContinuousDecode_ - t_bin_size: 0.025']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e4e5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_2d_plot.root_window.ui.menus.global_window_menus.docked_widgets\n",
    "\n",
    "active_2d_plot.ui.menus.global_window_menus.docked_widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3832eac4",
   "metadata": {},
   "source": [
    "#### Testing a Matplotlib-backed widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada6c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.PyqtgraphTimeSynchronizedWidget import PyqtgraphTimeSynchronizedWidget  \n",
    "\n",
    "active_2d_plot: Spike2DRaster = active_2d_plot  \n",
    "\n",
    "\n",
    "a_dock_id: str = 'ContinuousDecode_long_LR - t_bin_size: 0.025'\n",
    "# a_dock, widget = active_2d_plot.find_dock_item_tuple(identifier='ContinuousDecode_long_LR')\n",
    "# a_dock, widget = active_2d_plot.find_dock_item_tuple(identifier='ContinuousDecode_long_RL')\n",
    "a_dock, widget = active_2d_plot.find_dock_item_tuple(identifier=a_dock_id)\n",
    "# widget.plots\n",
    "# widget.plots_data\n",
    "# img.set_cmap('viridis')  # or any \n",
    "an_ax = widget.ax\n",
    "# widget\n",
    "an_ax.set_facecolor('black')  # Set axes background to black\n",
    "# an_ax.set_facecolor('white')  # Set axes background to white\n",
    "\n",
    "\n",
    "# img.set_cmap('viridis')  # or any valid colormap name\n",
    "# widget.getRootPlotItem().setXRange(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time, padding=0) ## global frame  \n",
    "# widget.update(None)  \n",
    "\n",
    "im_posterior_x = widget.plots.im_posterior_x\n",
    "# im_posterior_x.set_cmap(active_cmap)  # or any valid colormap name\n",
    "# widget.update()\n",
    "# widget\n",
    "# plt.draw()\n",
    "im_posterior_x # AxesImage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff5bcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.PyqtgraphTimeSynchronizedWidget import PyqtgraphTimeSynchronizedWidget  \n",
    "\n",
    "active_2d_plot: Spike2DRaster = active_2d_plot  \n",
    "\n",
    "\n",
    "a_dock_id: str = 'ContinuousDecode_long_LR - t_bin_size: 0.025'\n",
    "# a_dock_id: str = 'marginal_over_track_ID_ContinuousDecode - t_bin_size: 0.025'\n",
    "# a_dock, widget = active_2d_plot.find_dock_item_tuple(identifier='ContinuousDecode_long_LR')\n",
    "# a_dock, widget = active_2d_plot.find_dock_item_tuple(identifier='ContinuousDecode_long_RL')\n",
    "a_dock, widget = active_2d_plot.find_dock_item_tuple(identifier=a_dock_id)\n",
    "# widget.plots\n",
    "# widget.plots_data\n",
    "# img.set_cmap('viridis')  # or any \n",
    "an_ax = widget.ax\n",
    "# widget\n",
    "an_ax.set_facecolor('black')  # Set axes background to black\n",
    "# an_ax.set_facecolor('white')  # Set axes background to white\n",
    "\n",
    "\n",
    "# img.set_cmap('viridis')  # or any valid colormap name\n",
    "# widget.getRootPlotItem().setXRange(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time, padding=0) ## global frame  \n",
    "# widget.update(None)  \n",
    "\n",
    "im_posterior_x = widget.plots.im_posterior_x\n",
    "# im_posterior_x.set_cmap(active_cmap)  # or any valid colormap name\n",
    "# widget.update()\n",
    "# widget\n",
    "# plt.draw()\n",
    "im_posterior_x # AxesImage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdca1c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_posterior_x.get_extent() # [-2.84147705365001e-15, 1458.5500000000002, 0.0, 287.7697841726619]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bbad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.temporal_axis_length\n",
    "active_2d_plot.active_time_window\n",
    "\n",
    "np.diff(active_2d_plot.active_time_window)\n",
    "\n",
    "active_2d_plot.active_window_duration\n",
    "active_2d_plot.render_window_duration\n",
    "(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e063fd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "widget.plots\n",
    "# widget.plots_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e86d20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images = an_ax.get_images()\n",
    "images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884493a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_img = images[0]\n",
    "an_img\n",
    "an_img.set_cmap(active_cmap)  # or any valid colormap name\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5599478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import FigureToImageHelpers\n",
    "\n",
    "## INPUTS: im_posterior_x\n",
    "relative_data_output_parent_folder = Path('data').resolve()\n",
    "Assert.path_exists(relative_data_output_parent_folder)\n",
    "\n",
    "output_pdf_path: Path = relative_data_output_parent_folder.joinpath('timeline_exported.pdf')\n",
    "# FigureToImageHelpers.export_axesimage_to_paged_pdf(ax_image=im_posterior_x, x_extent=(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time), chunk_width=active_2d_plot.active_window_duration, output_pdf_path=output_pdf_path, figsize=(8, 11), dpi=150, override_cmap=None, debug_max_num_pages=5)\n",
    "FigureToImageHelpers.export_wrapped_axesimage_to_paged_pdf(ax_image=im_posterior_x, x_extent=(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time), chunk_width=active_2d_plot.active_window_duration, output_pdf_path=output_pdf_path, figsize=(8, 11), dpi=150,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\trows_per_page=5, debug_max_num_pages=25,\t\t    \n",
    "                                                # rows_per_page=15, debug_max_num_pages=3,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e5764e",
   "metadata": {},
   "source": [
    "#### Testing multiple matplotlib tracks at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74cc8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "\n",
    "formatted_title_strings_dict = DisplayColorsEnum.get_matplotlib_formatted_title_dict()\n",
    "decoder_names_list: List[str] = list(formatted_title_strings_dict.keys())\n",
    "\n",
    "## get the whole stack\n",
    "active_dockGroup_dock_dict = active_2d_plot.get_dockGroup_dock_dict()\n",
    "_curr_active_dock_group = active_dockGroup_dock_dict['ContinuousDecode_ - t_bin_size: 0.025'] # {'long_LR': 'Long◀', 'long_RL': 'Long▶', 'short_LR': 'Short◀', 'short_RL': 'Short▶'}\n",
    "_curr_decoders_dock_item_names_list: List[str] = [v.name() for v in _curr_active_dock_group] # ['ContinuousDecode_long_LR - t_bin_size: 0.025', 'ContinuousDecode_long_RL - t_bin_size: 0.025', 'ContinuousDecode_short_LR - t_bin_size: 0.025', 'ContinuousDecode_short_RL - t_bin_size: 0.025']\n",
    "im_posterior_x_stack = [v.widgets[0].plots.im_posterior_x for v in _curr_active_dock_group]\n",
    "\n",
    "_curr_decoder_name_to_decoders_dock_item_name_map = {}\n",
    "_remaining_dock_names = set(_curr_decoders_dock_item_names_list)\n",
    "\n",
    "# _curr_decoders_dock_item_names_list\n",
    "for a_decoder_name in decoder_names_list:\n",
    "\tfor a_dock_name in _remaining_dock_names: #_curr_decoders_dock_item_names_list:\n",
    "\t\tif (a_decoder_name in a_dock_name):\n",
    "\t\t\t_curr_decoder_name_to_decoders_dock_item_name_map[a_decoder_name] = a_dock_name\n",
    "\t\t\t_remaining_dock_names.remove(a_dock_name)\n",
    "\t\t\tbreak\n",
    "\n",
    "assert len(_curr_decoder_name_to_decoders_dock_item_name_map) == len(decoder_names_list), f\"decoder_names_list: {decoder_names_list} != list(_curr_decoder_name_to_decoders_dock_item_name_map.keys()): {_curr_decoder_name_to_decoders_dock_item_name_map}\"\n",
    "track_labels: List[str] = [formatted_title_strings_dict[a_decoder_name] for a_decoder_name, a_dock_name in _curr_decoder_name_to_decoders_dock_item_name_map.items()]\n",
    "track_labels\n",
    "\n",
    "## OUTPUTS: im_posterior_x_stack, track_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539e49a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "[im_posterior_x.get_extent() for im_posterior_x in im_posterior_x_stack]\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ff81d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import FigureToImageHelpers\n",
    "\n",
    "relative_data_output_parent_folder = Path('data').resolve()\n",
    "Assert.path_exists(relative_data_output_parent_folder)\n",
    "\n",
    "## INPUTS: im_posterior_x_stack, track_labels, \n",
    "output_pdf_path: Path = relative_data_output_parent_folder.joinpath('timeline_exported_stack.pdf')\n",
    "FigureToImageHelpers.export_wrapped_axesimage_to_paged_pdf(ax_image=im_posterior_x_stack, x_extent=(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time), chunk_width=active_2d_plot.active_window_duration, output_pdf_path=output_pdf_path, figsize=(8, 11), dpi=150,\n",
    "        \t\t\t\t\t\t\t\t\t\t\t\trows_per_page=5, debug_max_num_pages=3,\t\t    \n",
    "                                                        # rows_per_page=15, debug_max_num_pages=3,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\ttrack_labels=track_labels,\n",
    "                                                    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f627f6ab",
   "metadata": {},
   "source": [
    "## Export ALL tracks (both plotting backends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed13086",
   "metadata": {
    "tags": [
     "2025-08-22",
     "2025-08-22_full_spikeraster2d_tracks_to_paged_pdf"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.PyqtgraphTimeSynchronizedWidget import PyqtgraphTimeSynchronizedWidget\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.MatplotlibTimeSynchronizedWidget import MatplotlibTimeSynchronizedWidget\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.image as mimage\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import FigureToImageHelpers\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "\n",
    "relative_data_output_parent_folder = Path('data').resolve()\n",
    "Assert.path_exists(relative_data_output_parent_folder)\n",
    "\n",
    "## INPUTS: im_posterior_x_stack, track_labels, \n",
    "output_pdf_path: Path = relative_data_output_parent_folder.joinpath('all_timeline_tracks_exported_stack.pdf')\n",
    "\n",
    "included_track_dock_identifiers = [\n",
    "\t# 'interval_overview',\n",
    "    'intervals',\n",
    "    # 'rasters[raster_overview]',\n",
    "    'rasters[raster_window]',\n",
    "     'new_curves_separate_plot',\n",
    "    # 'ContinuousDecode_long_LR - t_bin_size: 0.025',\n",
    "    # 'ContinuousDecode_long_RL - t_bin_size: 0.025',\n",
    "    # 'ContinuousDecode_short_LR - t_bin_size: 0.025',\n",
    "    # 'ContinuousDecode_short_RL - t_bin_size: 0.025',\n",
    "    # 'marginal_over_track_ID_ContinuousDecode - t_bin_size: 0.025',\n",
    "\n",
    " 'ContinuousDecode_long_LR - t_bin_size: 0.05',\n",
    " 'ContinuousDecode_long_RL - t_bin_size: 0.05',\n",
    " 'ContinuousDecode_short_LR - t_bin_size: 0.05',\n",
    " 'ContinuousDecode_short_RL - t_bin_size: 0.05',\n",
    " 'marginal_over_track_ID_ContinuousDecode - t_bin_size: 0.05'\n",
    "        \n",
    "\n",
    "\t]\n",
    "\n",
    "# included_track_dock_identifiers_to_track_labels_dict = {\n",
    "# \t# 'interval_overview',\n",
    "#     'intervals':'intervals',\n",
    "#     # 'rasters[raster_overview]',\n",
    "#     'rasters[raster_window]':'spikes',\n",
    "#      'new_curves_separate_plot':'pos',\n",
    "#     # 'ContinuousDecode_long_LR - t_bin_size: 0.025',Assert\n",
    "#     # 'ContinuousDecode_long_RL - t_bin_size: 0.025',\n",
    "#     # 'ContinuousDecode_short_LR - t_bin_size: 0.025',\n",
    "#     # 'ContinuousDecode_short_RL - t_bin_size: 0.025',\n",
    "#     # 'marginal_over_track_ID_ContinuousDecode - t_bin_size: 0.025',\n",
    "#     'ContinuousDecode_long_LR - t_bin_size: 0.05': 'Long <',\n",
    "#     'ContinuousDecode_long_RL - t_bin_size: 0.05': 'Long >',\n",
    "#     'ContinuousDecode_short_LR - t_bin_size: 0.05': 'Short <',\n",
    "#     'ContinuousDecode_short_RL - t_bin_size: 0.05': 'Short >',\n",
    "#     'marginal_over_track_ID_ContinuousDecode - t_bin_size: 0.05': 'marginal[track]'\n",
    "# \t}\n",
    "\n",
    "# track_labels: List[str] = list(included_track_dock_identifiers_to_track_labels_dict.values())\n",
    "track_labels = None\n",
    "saved_output_pdf_path = FigureToImageHelpers.export_wrapped_tracks_to_paged_df(active_2d_plot, output_pdf_path=output_pdf_path, included_track_dock_identifiers=included_track_dock_identifiers, track_labels=track_labels, debug_max_num_pages=25)\n",
    "\n",
    "## OUTPUTS: output_pdf_path, included_track_dock_identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533750f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "\n",
    "formatted_title_strings_dict = DisplayColorsEnum.get_matplotlib_formatted_title_dict()\n",
    "decoder_names_list: List[str] = list(formatted_title_strings_dict.keys())\n",
    "\n",
    "## get the whole stack\n",
    "# active_dockGroup_dock_dict = active_2d_plot.get_dockGroup_dock_dict()\n",
    "# _curr_active_dock_group = active_dockGroup_dock_dict['ContinuousDecode_ - t_bin_size: 0.025'] # {'long_LR': 'Long◀', 'long_RL': 'Long▶', 'short_LR': 'Short◀', 'short_RL': 'Short▶'}\n",
    "# _curr_decoders_dock_item_names_list: List[str] = [v.name() for v in _curr_active_dock_group] # ['ContinuousDecode_long_LR - t_bin_size: 0.025', 'ContinuousDecode_long_RL - t_bin_size: 0.025', 'ContinuousDecode_short_LR - t_bin_size: 0.025', 'ContinuousDecode_short_RL - t_bin_size: 0.025']\n",
    "_curr_decoders_dock_item_names_list: List[str] = deepcopy(included_track_dock_identifiers)\n",
    "_curr_decoders_dock_item_names_list\n",
    "\n",
    "_curr_decoder_name_to_decoders_dock_item_name_map = {}\n",
    "_remaining_dock_names = set(_curr_decoders_dock_item_names_list)\n",
    "\n",
    "# _curr_decoders_dock_item_names_list\n",
    "for a_decoder_name in decoder_names_list:\n",
    "\tfor a_dock_name in _remaining_dock_names: #_curr_decoders_dock_item_names_list:\n",
    "\t\tif (a_decoder_name in a_dock_name):\n",
    "\t\t\t_curr_decoder_name_to_decoders_dock_item_name_map[a_decoder_name] = a_dock_name\n",
    "\t\t\t_remaining_dock_names.remove(a_dock_name)\n",
    "\t\t\tbreak\n",
    "\n",
    "assert len(_curr_decoder_name_to_decoders_dock_item_name_map) == len(decoder_names_list), f\"decoder_names_list: {decoder_names_list} != list(_curr_decoder_name_to_decoders_dock_item_name_map.keys()): {_curr_decoder_name_to_decoders_dock_item_name_map}\"\n",
    "track_labels: List[str] = [formatted_title_strings_dict[a_decoder_name] for a_decoder_name, a_dock_name in _curr_decoder_name_to_decoders_dock_item_name_map.items()]\n",
    "track_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eadce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491fd1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.dock_manager_widget.get_leaf_only_flat_dock_identifiers_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de7f70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_heterogeneous_stack, normalized_track_heights, included_track_dock_identifiers = FigureToImageHelpers.perform_export_wrapped_tracks_to_paged_df(active_2d_plot, included_track_dock_identifiers=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf75bd1",
   "metadata": {},
   "source": [
    "#### Testing multiple matplotlib tracks at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c154b0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatted_title_strings_dict = DisplayColorsEnum.get_matplotlib_formatted_title_dict()\n",
    "# decoder_names_list: List[str] = list(formatted_title_strings_dict.keys())\n",
    "\n",
    "# ## get the whole stack\n",
    "# active_dockGroup_dock_dict = active_2d_plot.get_dockGroup_dock_dict()\n",
    "# _curr_active_dock_group = active_dockGroup_dock_dict['ContinuousDecode_ - t_bin_size: 0.025'] # {'long_LR': 'Long◀', 'long_RL': 'Long▶', 'short_LR': 'Short◀', 'short_RL': 'Short▶'}\n",
    "# _curr_decoders_dock_item_names_list: List[str] = [v.name() for v in _curr_active_dock_group] # ['ContinuousDecode_long_LR - t_bin_size: 0.025', 'ContinuousDecode_long_RL - t_bin_size: 0.025', 'ContinuousDecode_short_LR - t_bin_size: 0.025', 'ContinuousDecode_short_RL - t_bin_size: 0.025']\n",
    "# im_posterior_x_stack = [v.widgets[0].plots.im_posterior_x for v in _curr_active_dock_group]\n",
    "\n",
    "# _curr_decoder_name_to_decoders_dock_item_name_map = {}\n",
    "# _remaining_dock_names = set(_curr_decoders_dock_item_names_list)\n",
    "\n",
    "# # _curr_decoders_dock_item_names_list\n",
    "# for a_decoder_name in decoder_names_list:\n",
    "# \tfor a_dock_name in _remaining_dock_names: #_curr_decoders_dock_item_names_list:\n",
    "# \t\tif (a_decoder_name in a_dock_name):\n",
    "# \t\t\t_curr_decoder_name_to_decoders_dock_item_name_map[a_decoder_name] = a_dock_name\n",
    "# \t\t\t_remaining_dock_names.remove(a_dock_name)\n",
    "# \t\t\tbreak\n",
    "\n",
    "# assert len(_curr_decoder_name_to_decoders_dock_item_name_map) == len(decoder_names_list), f\"decoder_names_list: {decoder_names_list} != list(_curr_decoder_name_to_decoders_dock_item_name_map.keys()): {_curr_decoder_name_to_decoders_dock_item_name_map}\"\n",
    "# track_labels: List[str] = [formatted_title_strings_dict[a_decoder_name] for a_decoder_name, a_dock_name in _curr_decoder_name_to_decoders_dock_item_name_map.items()]\n",
    "# track_labels\n",
    "\n",
    "## OUTPUTS: im_posterior_x_stack, track_labels\n",
    "FigureToImageHelpers.export_wrapped_axesimage_to_paged_pdf(ax_image=found_matplotlib_stack, x_extent=(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time), chunk_width=active_2d_plot.active_window_duration, output_pdf_path=output_pdf_path, figsize=(8, 11), dpi=150,\n",
    "        \t\t\t\t\t\t\t\t\t\t\t\trows_per_page=5, debug_max_num_pages=3,\t\t    \n",
    "                                                        # rows_per_page=15, debug_max_num_pages=3,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t# track_labels=track_labels,\n",
    "                                                    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd517b3",
   "metadata": {},
   "source": [
    "## All/General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55614526",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e715bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: found_heterogeneous_stack\n",
    "FigureToImageHelpers.export_wrapped_tracks_to_paged_pdf(tracks=found_heterogeneous_stack, x_extent=(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time), chunk_width=active_2d_plot.active_window_duration, output_pdf_path=output_pdf_path, figsize=(8, 11), dpi=150,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\trows_per_page=5, debug_max_num_pages=2,\t\t    \n",
    "                                                # rows_per_page=15, debug_max_num_pages=3,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tnormalized_track_heights = normalized_track_heights,\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a758a321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfa3cffa",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cb96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.SpecificDockWidgetManipulatingMixin import SpecificDockWidgetManipulatingMixin\n",
    "\n",
    "\n",
    "\n",
    "## measured positions\n",
    "## INPUTS: curr_active_pipeline, an_ax, \n",
    "measured_position_df: pd.DataFrame = deepcopy(curr_active_pipeline.sess.position.to_dataframe())\n",
    "\n",
    "widget.plots_data.measured_position_df = None\n",
    "widget.plots.measured_position_artists = None\n",
    "if measured_position_df is not None:\n",
    "    widget.plots_data.measured_position_df = measured_position_df\n",
    "    _out_artists = SpecificDockWidgetManipulatingMixin._perform_overlay_measured_position(matplotlib_fig_axes=[an_ax], measured_position_df=measured_position_df)\n",
    "    widget.plots.measured_position_artists = _out_artists\n",
    "    widget.draw() # alternative to accessing through full path?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d493184",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.dock_manager_widget.get_leaf_only_flat_dock_identifiers_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9a8974",
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_window = spike_raster_window.spikes_window # SpikesDataframeWindow; pyphoplacecellanalysis.General.Model.TimeWindow.TimeWindow\n",
    "spikes_window.update_window_start_end(451.8908457518555, 451.9895490613999) ## Works but does not trigger refresh/update of the window. The changes are reflected as soon as you try to scroll at all though.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c6ec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a203ce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_commands = ['AddTimeIntervals.Replays', 'AddTimeIntervals.Laps', 'AddTimeIntervals.SessionEpochs'] # , 'AddTimeIntervals.SessionEpochs', 'AddTimeIntervals.PBEs', 'AddTimeIntervals.Ripples',\n",
    "for a_command in menu_commands:\n",
    "    assert a_command in global_flat_action_dict, f\"a_command: '{a_command}' is not present in global_flat_action_dict: {list(global_flat_action_dict.keys())}\"\n",
    "    # add_renderables_menu[a_command].trigger()\n",
    "    global_flat_action_dict[a_command].trigger()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f895e3",
   "metadata": {},
   "source": [
    "main_content_splitter (QSplitter)\n",
    "\tmain_graphics_layout_widget (CustomGraphicsLayoutWidget)\n",
    "\t\tqt_scrollarea_hcontainer (QWidget)\n",
    "\t\t\tUnnamed (QScrollBar)\n",
    "\t\tqt_scrollarea_vcontainer (QWidget)\n",
    "\t\t\tUnnamed (QScrollBar)\n",
    "\t\tUnnamed (QOpenGLWidget)\n",
    "\twrapper_widget (QWidget)\n",
    "\t\tdynamic_docked_widget_container (NestedDockAreaWidget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbac1ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "from PyQt5.QtWidgets import QAbstractScrollArea\n",
    "from PyQt5.QtWidgets import QSizePolicy\n",
    "\n",
    "from pyphoplacecellanalysis.General.Mixins.DisplayHelpers import debug_widget_geometry\n",
    "from pyphocorehelpers.gui.Qt.TopLevelWindowHelper import print_widget_hierarchy\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.spike_raster_widgets import _get_required_static_layout_height\n",
    "\n",
    "main_graphics_layout_widget: pg.GraphicsLayoutWidget = active_2d_plot.ui.main_graphics_layout_widget\n",
    "wrapper_layout: pg.QtWidgets.QVBoxLayout = active_2d_plot.ui.wrapper_layout\n",
    "main_content_splitter = active_2d_plot.ui.main_content_splitter # QSplitter\n",
    "\n",
    "## Tracks\n",
    "dynamic_docked_widget_container = active_2d_plot.ui.dynamic_docked_widget_container\n",
    "dynamic_docked_widget_container_parent_wrapper = dynamic_docked_widget_container.parentWidget() # 'wrapper_widget'\n",
    "\n",
    "## Hard-coded\n",
    "layout = active_2d_plot.ui.layout\n",
    "background_static_scroll_window_plot = active_2d_plot.plots.background_static_scroll_window_plot # PlotItem\n",
    "\n",
    "main_plot_widget = active_2d_plot.plots.main_plot_widget # PlotItem\n",
    "\n",
    "root_layout: pg.GraphicsLayout = active_2d_plot.plots.background_static_scroll_window_plot.parentWidget()\n",
    "static_children_bounding_rect = root_layout.childrenBoundingRect() # QRectF\n",
    "required_static_children_bounding_rect_height: float = static_children_bounding_rect.height()\n",
    "required_static_children_bounding_rect_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d567bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_2d_plot.ui.dynamic_docked_widget_container\n",
    "# dynamic_docked_widget_container.parent().objectName()\n",
    "# dynamic_docked_widget_container.parentWidget().objectName()\n",
    "\n",
    "debug_widget_geometry(dynamic_docked_widget_container, widget_name='dynamic_docked_widget_container')\n",
    "debug_widget_geometry(dynamic_docked_widget_container_parent_wrapper, widget_name='dynamic_docked_widget_container_parent_wrapper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81954f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_docked_widget_container_parent_wrapper.setSizePolicy(QtGui.QSizePolicy.Expanding, QtGui.QSizePolicy.Expanding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eccdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.spike_raster_widgets import _get_required_static_layout_height\n",
    "\n",
    "required_static_children_bounding_rect_height: float = _get_required_static_layout_height(active_2d_plot=active_2d_plot)\n",
    "print(f'required_static_children_bounding_rect_height: {required_static_children_bounding_rect_height}')\n",
    "main_graphics_layout_widget.setMaximumHeight(required_static_children_bounding_rect_height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd68cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_widget_geometry(main_graphics_layout_widget, widget_name='main_graphics_layout_widget')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ed1a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_widget_hierarchy(main_graphics_layout_widget)\n",
    "\n",
    "# PyQt5.QtCore.QRect(0, 221, 1855, 640)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f0cb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.spike_raster_widgets import _get_required_static_layout_height\n",
    "\n",
    "main_graphics_layout_widget.setSizeAdjustPolicy(QAbstractScrollArea.SizeAdjustPolicy.AdjustToContentsOnFirstShow)                    \n",
    "required_static_children_bounding_rect_height: float = _get_required_static_layout_height(active_2d_plot=active_2d_plot)\n",
    "print(f'required_static_children_bounding_rect_height: {required_static_children_bounding_rect_height}')\n",
    "# main_graphics_layout_widget.setMaximumHeight(required_static_children_bounding_rect_height)\n",
    "\n",
    "# main_graphics_layout_widget.resize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60210451",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_widget_hierarchy(active_2d_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ebf4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.print_helpers import strip_type_str_to_classname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e035fa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5.QtWidgets import QOpenGLWidget\n",
    "\n",
    "main_graphics_layout_widget.childrenRect()\n",
    "\n",
    "open_gl_widget: QOpenGLWidget = main_graphics_layout_widget.children()[-1]\n",
    "open_gl_widget.childrenRect()\n",
    "open_gl_widget.contentsRect()\n",
    "# open_gl_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54c3c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_layout: pg.GraphicsLayout = main_plot_widget.parentWidget()\n",
    "main_layout\n",
    "# main_plot_widget.parent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8fb146",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_layout.childrenBoundingRect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd819d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_layout.parentWidget().parentWidget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d433e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_widget_geometry(main_plot_widget)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fe9c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5.QtWidgets import QAbstractScrollArea\n",
    "from PyQt5.QtWidgets import QSizePolicy\n",
    "\n",
    "main_graphics_layout_widget.setSizeAdjustPolicy(QAbstractScrollArea.SizeAdjustPolicy.AdjustToContentsOnFirstShow)\n",
    "# main_graphics_layout_widget.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Preferred)\n",
    "# main_graphics_layout_widget.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Preferred)\n",
    "main_graphics_layout_widget.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bbe298",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_layout: pg.GraphicsLayout = active_2d_plot.plots.background_static_scroll_window_plot.parentWidget()\n",
    "static_children_bounding_rect = root_layout.childrenBoundingRect() # QRectF\n",
    "required_static_children_bounding_rect_height: float = static_children_bounding_rect.height()\n",
    "\n",
    "main_graphics_layout_widget.setMaximumHeight(required_static_children_bounding_rect_height)\n",
    "# main_graphics_layout_widget.setMaximumSize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5378254",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_docked_widget_container_parent_wrapper.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)\n",
    "dynamic_docked_widget_container.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b41680",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_static_scroll_plot_widget = active_2d_plot.plots.get('background_static_scroll_plot_widget', None) # PlotItem\n",
    "if background_static_scroll_plot_widget is not None:\n",
    "    background_static_scroll_plot_widget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009e00df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "background_static_scroll_window_plot = active_2d_plot.plots.get('background_static_scroll_window_plot', None) # PlotItem\n",
    "if background_static_scroll_window_plot is not None:\n",
    "    # background_static_scroll_window_plot # PlotItem\n",
    "    plot_data_item.setDownsampling(auto=True, ds=1, mode='subsample')\n",
    "    plot_data_item.setClipToView(True)\n",
    "    \n",
    "    # background_static_scroll_window_plot.setClipToView(True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cddd357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# background_static_scroll_window_plot.parent()\n",
    "background_static_scroll_window_plot.dataItems[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577cbb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_overview_scatter_plot = active_2d_plot.plots.get('preview_overview_scatter_plot', None) # ScatterPlotItem\n",
    "preview_overview_scatter_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d975c61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "debug_widget_geometry(preview_overview_scatter_plot, widget_name='preview_overview_scatter_plot')\n",
    "print_widget_hierarchy(preview_overview_scatter_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1525b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "main_plot_widget.scatterPlot().setClipToView(True) # Usually default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6932cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "main_content_splitter.size()\n",
    "main_content_splitter.sizes()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e19af68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.gui.Qt.TopLevelWindowHelper import print_widget_hierarchy\n",
    "\n",
    "print_widget_hierarchy(main_content_splitter, indent_level_chars='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9950a936",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_static_children_bounding_rect_height: float = _get_required_static_layout_height(active_2d_plot=active_2d_plot)\n",
    "main_graphics_layout_widget.setMaximumHeight(required_static_children_bounding_rect_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac259d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: main_content_splitter\n",
    "\n",
    "original_sizes = np.array(main_content_splitter.sizes())\n",
    "original_sizes\n",
    "\n",
    "## INPUTS: required_static_children_bounding_rect_height\n",
    "extra_v_height = (original_sizes[-1] - required_static_children_bounding_rect_height)\n",
    "extra_v_height\n",
    "\n",
    "desired_sizes = deepcopy(original_sizes)\n",
    "desired_sizes[-1] = required_static_children_bounding_rect_height\n",
    "desired_sizes[0] = desired_sizes[0] + extra_v_height\n",
    "\n",
    "assert np.sum(desired_sizes) == np.sum(original_sizes)\n",
    "\n",
    "\n",
    "main_content_splitter.setSizes(desired_sizes.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655af96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_content_splitter.children()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed1caa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import Spike2DRaster\n",
    "from pyphoplacecellanalysis.GUI.Qt.SpikeRasterWindows.Spike3DRasterWindowWidget import Spike3DRasterWindowWidget\n",
    "from pyphoplacecellanalysis.GUI.Qt.PlaybackControls.Spike3DRasterBottomPlaybackControlBarWidget import Spike3DRasterBottomPlaybackControlBar\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import SynchronizedPlotMode\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.spike_raster_widgets import _setup_spike_raster_window_for_debugging\n",
    "\n",
    "all_global_menus_actionsDict, global_flat_action_dict, _all_outputs_dict = _setup_spike_raster_window_for_debugging(spike_raster_window, wants_docked_raster_window_track=True, enable_interval_overview_track=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f18a66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61246c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import SynchronizedPlotMode\n",
    "\n",
    "\n",
    "with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-prepare_pyqtgraph_rasterPlot_track_with_sync.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "    # _raster_overview_tracks_out_dict = active_2d_plot.prepare_pyqtgraph_rasterPlot_track(name_modifier_suffix='raster_overview', should_link_to_main_plot_widget=False, sync_mode=SynchronizedPlotMode.TO_GLOBAL_DATA, downsampling_rate=5)\n",
    "    _raster_overview_tracks_out_dict = active_2d_plot.prepare_pyqtgraph_rasterPlot_track(name_modifier_suffix='raster_overview', should_link_to_main_plot_widget=False, sync_mode=SynchronizedPlotMode.NO_SYNC, downsampling_rate=5)\n",
    "    raster_overview_dock_config, raster_overview_time_sync_pyqtgraph_widget, raster_overview_root_graphics_layout_widget, raster_overview_plot_item, raster_overview_display_outputs_tuple = _raster_overview_tracks_out_dict['rasters[raster_overview]']\n",
    "    active_2d_plot.sync_matplotlib_render_plot_widget('rasters[raster_overview]', sync_mode=SynchronizedPlotMode.NO_SYNC) # disable continued sync\n",
    "    \n",
    "    # _all_outputs_dict['_raster_tracks_out_dict'] = _raster_tracks_out_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87237fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a623c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.sync_matplotlib_render_plot_widget('rasters[raster_overview]', sync_mode=SynchronizedPlotMode.TO_GLOBAL_DATA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fdfc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(_raster_overview_tracks_out_dict.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d47ca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_overview_dock_config, raster_overview_time_sync_pyqtgraph_widget, raster_overview_root_graphics_layout_widget, raster_overview_plot_item, raster_overview_display_outputs_tuple = _raster_overview_tracks_out_dict['raster_overview']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9223c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add scroller:\n",
    "\n",
    "def _add_scroll_region(active_2d_plot, parent_plot, clipItem=None, should_connect=False):\n",
    "    \"\"\" adds the scroll region control to the specified raster plot\n",
    "    \n",
    "    scroll_window_region, _conn = _add_scroll_region(active_2d_plot, parent_plot=background_static_scroll_window_plot, clipItem=active_2d_plot.plots.preview_overview_scatter_plot)\n",
    "    \n",
    "    active_2d_plot.ui.scroll_window_region = scroll_window_region\n",
    "    \"\"\"\n",
    "    from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsObjects.CustomLinearRegionItem import CustomLinearRegionItem\n",
    "    if clipItem is None:\n",
    "        clipItem = active_2d_plot.plots.preview_overview_scatter_plot\n",
    "        \n",
    "    # linear_region_display_kwargs = dict(pen=pg.mkPen('#ffffff'), brush=pg.mkBrush('#f004'), hoverBrush=pg.mkBrush('#fff4'), hoverPen=pg.mkPen('#f00'))\n",
    "    # linear_region_display_kwargs = dict(pen=pg.mkPen('#1d0000f8', width=2), brush=pg.mkBrush('#00000090'), hoverBrush=pg.mkBrush('#fff40090'), hoverPen=pg.mkPen('#f00000ff', width=2.5))\n",
    "    # linear_region_display_kwargs = dict(pen=pg.mkPen('#1d0000f8'), brush=pg.mkBrush('#ffffff90'), hoverBrush=pg.mkBrush('#fff40090'), hoverPen=pg.mkPen('#fffffff4'))\n",
    "    linear_region_display_kwargs = dict(pen=pg.mkPen('#ffffffe2', width=1.0), brush=pg.mkBrush('#ffffff90'), hoverBrush=pg.mkBrush('#fff40090'), hoverPen=pg.mkPen('#ff0505f4', width=1.5))\n",
    "\n",
    "\t# Add the linear region overlay:\n",
    "    scroll_window_region = CustomLinearRegionItem(**linear_region_display_kwargs, clipItem=clipItem) # bound the LinearRegionItem to the plotted data\n",
    "    scroll_window_region.setObjectName('scroll_window_region')\n",
    "    scroll_window_region.setZValue(10)\n",
    "    \n",
    "    ## Set position from spikes_window:\n",
    "    confirmed_valid_window_start_t = active_2d_plot.spikes_window.total_data_start_time\n",
    "    if (active_2d_plot.spikes_window.window_duration == 0.0):\n",
    "        # invalid window length, just choose something reasonable the user can grab, say 5% of the total window data\n",
    "        total_data_duration = active_2d_plot.spikes_window.total_data_end_time - active_2d_plot.spikes_window.total_data_start_time\n",
    "        reasonable_active_window_duration = float(total_data_duration) * 0.05 # 5%\n",
    "        ## UGHH, it works but please note that the final window is actually going to be MORE than 5% of the total data duration because of the temporal_zoom_factor > 1.0. \n",
    "    else:\n",
    "        reasonable_active_window_duration = float(active_2d_plot.spikes_window.window_duration)        \n",
    "    # Compute the final reasonable window end_t:\n",
    "    confirmed_valid_window_end_t = confirmed_valid_window_start_t + reasonable_active_window_duration\n",
    "        \n",
    "    scroll_window_region.setRegion([confirmed_valid_window_start_t, confirmed_valid_window_end_t]) # adjust scroll control\n",
    "    \n",
    "    # Add the LinearRegionItem to the ViewBox, but tell the ViewBox to exclude this item when doing auto-range calculations.\n",
    "    parent_plot.addItem(scroll_window_region, ignoreBounds=True)\n",
    "    if should_connect:\n",
    "        _conn = scroll_window_region.sigRegionChanged.connect(active_2d_plot._Render2DScrollWindowPlot_on_linear_region_item_update)\n",
    "    else:\n",
    "        _conn = None\n",
    "        \n",
    "    return scroll_window_region, _conn\n",
    "\n",
    "\n",
    "# scroll_window_region, _conn = _add_scroll_region(active_2d_plot=active_2d_plot, parent_plot=background_static_scroll_window_plot, clipItem=active_2d_plot.plots.preview_overview_scatter_plot)\n",
    "\n",
    "scroll_window_region, _conn = _add_scroll_region(active_2d_plot=active_2d_plot, parent_plot=raster_overview_plot_item, clipItem=raster_overview_plot_item)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42f2298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scroll_window_region.remove()\n",
    "\n",
    "\n",
    "raster_overview_plot_item.removeItem(scroll_window_region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993a507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scroll_window_region.sigRegionChanged.disconnect(_conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd43fc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## teardown `background_static_scroll_window_plot`\n",
    "background_static_scroll_window_plot.hide()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c0c871",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.ui.scroll_window_region.disconnect()\n",
    "active_2d_plot.ui.scroll_window_region.hide()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b577453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOPS BETTER START COOKING'243_22562_220-pycharm-support-libs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0b3b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_plot_widget = _all_outputs_dict.get('main_plot_widget', None)\n",
    "if main_plot_widget is not None:\n",
    "    main_plot_widget.hide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a28499",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_window_container_layout = _all_outputs_dict.get('active_window_container_layout', None)\n",
    "if active_window_container_layout is not None:\n",
    "    active_window_container_layout.setVisible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c186676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_static_scroll_window_plot = _all_outputs_dict.get('background_static_scroll_window_plot', None)\n",
    "background_static_scroll_window_plot.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5f9dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_global_menus_actionsDict, global_flat_action_dict = spike_raster_window.build_all_menus_actions_dict()\n",
    "global_flat_action_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48715b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.decod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2bc7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add Renderables ____________________________________________________________________________________________________ #\n",
    "# add_renderables_menu = active_2d_plot.ui.menus.custom_context_menus.add_renderables[0].programmatic_actions_dict\n",
    "menu_commands = ['AddTimeIntervals.Replays', 'AddTimeIntervals.Laps', 'AddTimeIntervals.SessionEpochs'] # , 'AddTimeIntervals.SessionEpochs', 'AddTimeIntervals.PBEs', 'AddTimeIntervals.Ripples',\n",
    "for a_command in menu_commands:\n",
    "    assert a_command in global_flat_action_dict, f\"a_command: '{a_command}' is not present in global_flat_action_dict: {list(global_flat_action_dict.keys())}\"\n",
    "    # add_renderables_menu[a_command].trigger()\n",
    "    global_flat_action_dict[a_command].trigger()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae14b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feb774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccad938",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(spike_raster_window.spike_raster_plt_2d.params.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743a2479",
   "metadata": {},
   "outputs": [],
   "source": [
    "_raster_tracks_out_dict = active_2d_plot.prepare_pyqtgraph_rasterPlot_track(name_modifier_suffix='raster_window', should_link_to_main_plot_widget=False, )\n",
    "dock_config, time_sync_pyqtgraph_widget, raster_root_graphics_layout_widget, raster_plot_item, rasters_display_outputs_tuple = list(_raster_tracks_out_dict.values())[0]\n",
    "an_app, a_win, a_plots, a_plots_data = rasters_display_outputs_tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae4fada",
   "metadata": {},
   "outputs": [],
   "source": [
    "_interval_tracks_out_dict = active_2d_plot.prepare_pyqtgraph_intervalPlot_tracks(enable_interval_overview_track=True, should_remove_all_and_re_add=True, should_link_to_main_plot_widget=False)\n",
    "interval_window_dock_config, intervals_dock, intervals_time_sync_pyqtgraph_widget, intervals_root_graphics_layout_widget, intervals_plot_item = _interval_tracks_out_dict['intervals']\n",
    "if 'interval_overview' in _interval_tracks_out_dict:\n",
    "    interval_overview_window_dock_config, intervals_overview_dock, intervals_overview_time_sync_pyqtgraph_widget, intervals_overview_root_graphics_layout_widget, intervals_overview_plot_item = _interval_tracks_out_dict['interval_overview']\n",
    "    intervals_overview_plot_item.setXRange(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time, padding=0) ## global frame\n",
    "    # intervals_overview_time_sync_pyqtgraph_widget.setMaximumHeight(39)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f2fcb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a016e6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_dock.setMaximumHeight(39)\n",
    "intervals_overview_dock.setMaximumHeight(39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b35efdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_time_sync_pyqtgraph_widget.setMaximumHeight(39)\n",
    "intervals_overview_time_sync_pyqtgraph_widget.setMaximumHeight(39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e413f522",
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_window = spike_raster_window.spikes_window # SpikesDataframeWindow; pyphoplacecellanalysis.General.Model.TimeWindow.TimeWindow\n",
    "spikes_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aded71e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.total_data_start_time\n",
    "spike_raster_window.total_data_end_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51bfa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.total_data_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2d9eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setXLink\n",
    "# a_win # CustomGraphicsLayoutWidget \n",
    "# time_sync_pyqtgraph_widget # PyqtgraphTimeSynchronizedWidget \n",
    "# raster_plot_item\n",
    "\n",
    "### Zoom to entire data time range:\n",
    "# active_2d_plot\n",
    "raster_plot_item.setXLink(None)\n",
    "raster_plot_item.setXRange(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time, padding=0) ## global frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c754c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_dock_ids_list = active_2d_plot.get_group_only_flat_dock_identifiers_list()\n",
    "leaf_dock_ids_list = active_2d_plot.get_leaf_only_flat_dock_identifiers_list()\n",
    "group_dock_ids_list\n",
    "\n",
    "\n",
    "group_dock_raw_identifiers_list = [v.lstrip('GROUP[').rstrip(']') for v in group_dock_ids_list] # 'GROUP[ContinuousDecode_0.03]' -> 'ContinuousDecode_0.03'\n",
    "group_dock_raw_identifiers_list\n",
    "# spike_raster_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb984228",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_group_container_id: str = group_dock_ids_list[0] # 'GROUP[ContinuousDecode_0.03]'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e70360",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dock_items_dict: Dict[str, List[Dock]] = active_2d_plot.get_dockGroup_dock_dict()\n",
    "grouped_dock_items_dict\n",
    "\n",
    "# {'ContinuousDecode_ - t_bin_size: 0.025': [<Dock ContinuousDecode_long_LR - t_bin_size: 0.025 (65, 200)>,\n",
    "#   <Dock ContinuousDecode_long_RL - t_bin_size: 0.025 (65, 200)>,\n",
    "#   <Dock ContinuousDecode_short_LR - t_bin_size: 0.025 (65, 200)>,\n",
    "#   <Dock ContinuousDecode_short_RL - t_bin_size: 0.025 (65, 200)>],\n",
    "#  'ContinuousDecode_0.03': [<Dock DirectionalDecodersDecoded[long_LR]0.03 (65, 200)>,\n",
    "#   <Dock DirectionalDecodersDecoded[long_RL]0.03 (65, 200)>,\n",
    "#   <Dock DirectionalDecodersDecoded[short_LR]0.03 (65, 200)>,\n",
    "#   <Dock DirectionalDecodersDecoded[short_RL]0.03 (65, 200)>]}\n",
    "\n",
    "a_group_container_id: str = group_dock_ids_list[0]\n",
    "a_group_id: str = group_dock_raw_identifiers_list[0]\n",
    "flat_group_dockitems_list: List[Dock] = grouped_dock_items_dict[a_group_id]\n",
    "flat_group_dockitems_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba94a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup children:\n",
    "for a_dock in flat_group_dockitems_list:\n",
    "    # a_dock_identifier: str = a_dock.name()\n",
    "    # ## format nested child docks:\n",
    "    # a_dock.config.showCloseButton = False\n",
    "    # a_dock.config.showCollapseButton = False\n",
    "    # a_dock.config.showGroupButton = False\n",
    "    # a_dock.config.corner_radius='0px'\n",
    "    # a_dock.updateStyle()\n",
    "    active_2d_plot.dock_manager_widget.displayDockArea.addDock(dock=a_dock) ## move the dock items as children to the new container\n",
    "    # active_2d_plot.displayDockArea.moveDock(\n",
    "    # nested_dynamic_docked_widget_container.displayDockArea.addDock(dock=a_dock) ## move the dock items as children to the new container\n",
    "    \n",
    "## remove the group\n",
    "active_2d_plot.dock_manager_widget.remove_display_dock(identifier=a_group_container_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d570e8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.dock_manager_widget.unwrap_docks_in_nested_dock_area(dock_group_name='ContinuousDecode_0.03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fa4144",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dock all Grouped results from `'DockedWidgets.Pseudo2DDecodedEpochsDockedMatplotlibView'`\n",
    "## INPUTS: active_2d_plot\n",
    "nested_dock_items, nested_dynamic_docked_widget_container_widgets = active_2d_plot.ui.dynamic_docked_widget_container.layout_dockGroups()\n",
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()\n",
    "## OUTPUTS: nested_dock_items, nested_dynamic_docked_widget_container_widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8362a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import add_continuous_decoded_posterior\n",
    "\n",
    "(nested_dock_items, nested_dynamic_docked_widget_container_widgets), (a_continuously_decoded_dict, pseudo2D_decoder, all_directional_pf1D_Decoder_dict) = add_continuous_decoded_posterior(spike_raster_window=spike_raster_window, curr_active_pipeline=curr_active_pipeline, desired_time_bin_size=0.05, debug_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ecdee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967df72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Increase the window duration centered\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import plot_attached_BinByBinDecodingDebugger\n",
    "\n",
    "## INPUTS: a_decoder, a_decoded_result\n",
    "win, out_pf1D_decoder_template_objects, (plots_container, plots_data), _on_update_fcn = plot_attached_BinByBinDecodingDebugger(spike_raster_window, curr_active_pipeline, a_decoder=a_decoder, a_decoded_result=a_decoded_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998e7411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62a8afa",
   "metadata": {
    "tags": [
     "active-2025-02-25",
     "active-2025-08-22"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import plot_attached_BinByBinDecodingDebugger\n",
    "## Plot one of the continuous results for the most recently computed time_bin_size:\n",
    "\n",
    "\n",
    "# all_directional_pf1D_Decoder_dict\n",
    "# a_decoder_name: str = 'long'\n",
    "# a_decoder = results1D.decoders[a_decoder_name]\n",
    "# a_decoded_result = results1D.continuous_results[a_decoder_name]\n",
    "\n",
    "# a_decoder_name: str = 'long_LR'\n",
    "\n",
    "\n",
    "# a_decoder_name: str = 'short_LR'\n",
    "a_decoder_name: str = 'short_RL'\n",
    "a_decoder = all_directional_pf1D_Decoder_dict[a_decoder_name]\n",
    "a_decoded_result = a_continuously_decoded_dict[a_decoder_name]\n",
    "\n",
    "## INPUTS: a_decoder, a_decoded_result\n",
    "bin_by_bin_debugger, win, out_pf1D_decoder_template_objects, (plots_container, plots_data), _on_update_fcn = plot_attached_BinByBinDecodingDebugger(spike_raster_window, curr_active_pipeline, a_decoder=a_decoder, a_decoded_result=a_decoded_result, n_max_debugged_time_bins=50, name_suffix=a_decoder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc325a45",
   "metadata": {
    "tags": [
     "2025-08-22_binbybindecodingdebugger"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import plot_attached_BinByBinDecodingDebugger\n",
    "\n",
    "## all four decoders at once:\n",
    "collected_binByBin = {}\n",
    "collected_binByBin_debuggers: Dict[str, BinByBinDecodingDebugger] = {}\n",
    "## INPUTS: all_directional_pf1D_Decoder_dict, a_continuously_decoded_dict, spike_raster_window\n",
    "for a_decoder_name, a_decoder in all_directional_pf1D_Decoder_dict.items():\n",
    "    a_decoded_result = a_continuously_decoded_dict[a_decoder_name]\n",
    "    ## INPUTS: a_decoder, a_decoded_result\n",
    "    collected_binByBin[a_decoder_name] = plot_attached_BinByBinDecodingDebugger(spike_raster_window, curr_active_pipeline, a_decoder=a_decoder, a_decoded_result=a_decoded_result, n_max_debugged_time_bins=50, name_suffix=a_decoder_name)\n",
    "    # bin_by_bin_debugger, win, out_pf1D_decoder_template_objects, (plots_container, plots_data), _on_update_fcn = collected_binByBin[a_decoder_name] ## unpack like this\n",
    "    collected_binByBin_debuggers[a_decoder_name] = collected_binByBin[a_decoder_name][0] ## only get the debugger\n",
    "\n",
    "\n",
    "from pyphocorehelpers.gui.Qt.widget_positioning_helpers import WidgetPositioningHelpers\n",
    "\n",
    "should_position_reference_win: bool = False\n",
    "\n",
    "_prev_debugger = None\n",
    "for a_decoder_name, a_binBybin_debugger in collected_binByBin_debuggers.items():\n",
    "    a_binBybin_debugger_win = a_binBybin_debugger.ui.win\n",
    "    if _prev_debugger is None:\n",
    "        if should_position_reference_win:\n",
    "            # WidgetPositioningHelpers.move_widget_to_screen_top_left(a_binBybin_debugger_win, screen_index=1)\n",
    "            WidgetPositioningHelpers.move_widget_to_top_left_corner(a_binBybin_debugger_win)\n",
    "    else:\n",
    "        WidgetPositioningHelpers.align_window_edges(_prev_debugger, a_binBybin_debugger_win)\n",
    "        \n",
    "    _prev_debugger = a_binBybin_debugger_win\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4425f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "align_window_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249451da",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out = dict()\n",
    "_out['_display_measured_vs_decoded_occupancy_distributions'] = curr_active_pipeline.display(display_function='_display_measured_vs_decoded_occupancy_distributions', active_session_configuration_context=None) # _display_measured_vs_decoded_occupancy_distributions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a20a893",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_main_raster_plot: bool = (active_2d_plot.plots.main_plot_widget is not None)\n",
    "_raster_tracks_out_dict = active_2d_plot.prepare_pyqtgraph_rasterPlot_track(name_modifier_suffix='raster_window', should_link_to_main_plot_widget=has_main_raster_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcbc56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.External.pyqtgraph.dockarea.Dock import Dock, DockDisplayConfig\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import FigureWidgetDockDisplayConfig\n",
    "\n",
    "flat_dock_item_tuple_dict: Dict[str, Tuple] = active_2d_plot.get_flat_dock_item_tuple_dict()\n",
    "group_only_flat_dockwidgets_dict = {k:a_widget for k, (a_dock, a_widget) in flat_dock_item_tuple_dict.items() if ('GROUP' == a_dock.config.additional_metadata.get('type', 'LEAF')) }\n",
    "leaf_only_flat_dockwidgets_dict = {k:a_widget for k, (a_dock, a_widget) in flat_dock_item_tuple_dict.items() if ('LEAF' == a_dock.config.additional_metadata.get('type', 'LEAF')) }\n",
    "group_only_flat_dockwidgets_dict\n",
    "leaf_only_flat_dockwidgets_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea403e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "active_2d_plot.get_flat_dockitems_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff28fdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import AddNewDecodedPosteriors_MatplotlibPlotCommand\n",
    "from pyphoplacecellanalysis.External.pyqtgraph.dockarea.Dock import Dock, DockDisplayConfig\n",
    "\n",
    "flat_dock_item_tuple_dict: Dict[str, Tuple] = active_2d_plot.get_flat_dock_item_tuple_dict()\n",
    "flat_dock_item_tuple_dict\n",
    "\n",
    "# flat_docks_dict = {k:a_dock for k, (a_dock, a_widget) in flat_dock_item_tuple_dict.items() if ('ContinuousDecode_ - t_bin_size: 0.025' in a_dock.config.dock_group_names) }\n",
    "flat_dockwidgets_dict = {k:a_widget for k, (a_dock, a_widget) in flat_dock_item_tuple_dict.items() if ('ContinuousDecode_ - t_bin_size: 0.025' in a_dock.config.dock_group_names) }\n",
    "flat_dockwidgets_dict\n",
    "\n",
    "# flat_dock_item_tuple_dict = {k:a_widget if a_dock.grou for k, (a_dock, a_widget) in flat_dock_item_tuple_dict.items()}\n",
    "\n",
    "# flat_dockwidgets_list = active_2d_plot.get_flat_widgets_list()\n",
    "# flat_dockwidgets_list\n",
    "# active_2d_plot.get_dock_groups()\n",
    "\n",
    "_all_tracks_out_artists = {}\n",
    "for k, a_widget in flat_dockwidgets_dict.items():\n",
    "    _out_artists = AddNewDecodedPosteriors_MatplotlibPlotCommand._perform_overlay_measured_position(identifier_name=k, widget=a_widget, matplotlib_fig=a_widget.fig, matplotlib_fig_axes=a_widget.axes, measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()))\n",
    "    _all_tracks_out_artists[k] = _out_artists\n",
    "    a_widget.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8fc993",
   "metadata": {},
   "outputs": [],
   "source": [
    "_all_tracks_out_artists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8580701",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, a_widget in flat_dockwidgets_dict.items():\n",
    "    a_widget.plots.measured_position_artists = _all_tracks_out_artists[k]\n",
    "    \n",
    "    # a_widget.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21b7f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_playback_control_bar_widget = spike_raster_window.bottom_playback_control_bar_widget # Spike3DRasterBottomPlaybackControlBar \n",
    "comboActiveJumpTargetSeries = bottom_playback_control_bar_widget.ui.comboActiveJumpTargetSeries # QComboBox \n",
    "comboActiveJumpTargetSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd1d42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Dock all Grouped results from `'DockedWidgets.Pseudo2DDecodedEpochsDockedMatplotlibView'`\n",
    "## INPUTS: active_2d_plot\n",
    "nested_dock_items, nested_dynamic_docked_widget_container_widgets = active_2d_plot.ui.dynamic_docked_widget_container.layout_dockGroups()\n",
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()\n",
    "## OUTPUTS: nested_dock_items, nested_dynamic_docked_widget_container_widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191b20f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()\n",
    "grouped_dock_items_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8084d27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.ui.dynamic_docked_widget_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53ed9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.NestedDockAreaWidget import NestedDockAreaWidget\n",
    "\n",
    "dock_manager_widget: NestedDockAreaWidget = active_2d_plot.dock_manager_widget\n",
    "grouped_dock_items_dict = dock_manager_widget.get_dockGroup_dock_dict()\n",
    "grouped_dock_items_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3ee32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dock_items_dict = active_2d_plot.dock_manager_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c521a076",
   "metadata": {},
   "outputs": [],
   "source": [
    "comboActiveJumpTargetSeries.setCurrentText('Laps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5ebfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.Specific2DRenderTimeEpochs import General2DRenderTimeEpochs, Replays_2DRenderTimeEpochs, Ripples_2DRenderTimeEpochs, SessionEpochs2DRenderTimeEpochs, PBE_2DRenderTimeEpochs, Laps2DRenderTimeEpochs, SpikeBurstIntervals_2DRenderTimeEpochs, NewNonPBE_2DRenderTimeEpochs # Time Intervals/Epochs\n",
    "\n",
    "background_static_scroll_window_plot = active_2d_plot.plots.background_static_scroll_window_plot # PlotItem\n",
    "main_plot_widget = active_2d_plot.plots.main_plot_widget # PlotItem\n",
    "\n",
    "for an_interval_rendering_plot in active_2d_plot.interval_rendering_plots:\n",
    "    _out = NewNonPBE_2DRenderTimeEpochs.add_render_time_epochs(curr_sess=curr_active_pipeline.sess.non_pbe, destination_plot=an_interval_rendering_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f45c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.params.debug_print = True\n",
    "spike_raster_window.enable_debug_print = True\n",
    "active_2d_plot.params.debug_print = True\n",
    "# active_2d_plot.debug_print = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44790f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.on_crosshair_trace_toggled()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61371822",
   "metadata": {},
   "outputs": [],
   "source": [
    "extant_conn = spike_raster_window.ui.additional_connections.get('spike_3d_to_2d_window_crosshair_connection', None)\n",
    "extant_conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7200fc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.ui.left_side_bar_connections = spike_raster_window.SpikeRasterLeftSidebarControlsMixin_connectSignals(spike_raster_window.ui.leftSideToolbarWidget)\n",
    "spike_raster_window.ui.left_side_bar_connections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0491ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fix window title to display the session context post-hoc\n",
    "desired_window_title: str = curr_active_pipeline.get_complete_session_identifier_string() # 'kdiba_gor01_two_2006-6-07_16-40-19__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 8, 9]-frateThresh_5.0'\n",
    "spike_raster_window.window().setWindowTitle(desired_window_title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b12684",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.params.is_crosshair_trace_enabled = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c0c6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_crosshairs to `active_2d_plot`\n",
    "active_time_sync_pyqtgraph_widgets: Dict[str, PyqtgraphTimeSynchronizedWidget] = {identifier:active_matplotlib_view_widget for identifier, active_matplotlib_view_widget in active_2d_plot.ui.matplotlib_view_widgets.items() if active_matplotlib_view_widget.is_pyqtgraph_based()}\n",
    "active_time_sync_pyqtgraph_widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da93cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_name, a_time_sync_widget in active_2d_plot.ui.matplotlib_view_widgets.items():\n",
    "    print(f'a_name: {a_name}')\n",
    "    # a_time_sync_widget.plots_data\n",
    "    a_time_sync_widget.plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da376422",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_side_bar_controls = spike_raster_window.ui.leftSideToolbarWidget\n",
    "left_side_bar_controls.enable_debug_print = True\n",
    "left_side_bar_controls.enable_debug_print\n",
    "\n",
    "wants_crosshair_trace_visible: bool = left_side_bar_controls.ui.btnToggleCrosshairTrace.isChecked()\n",
    "wants_crosshair_trace_visible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd204351",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_side_bar_controls.ui.btnToggleCrosshairTrace.setChecked(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56703de",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_side_bar_controls.crosshair_trace_button_Toggled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd315de",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_side_bar_controls = spike_raster_window.ui.leftSideToolbarWidget\n",
    "left_side_bar_controls.crosshair_trace_time = \"test\"\n",
    "\n",
    "left_side_bar_controls.ui.lblCrosshairTraceStaticLabel.setVisible(True)\n",
    "left_side_bar_controls.ui.lblCrosshairTraceValue.setVisible(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d4effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.PyqtgraphTimeSynchronizedWidget import PyqtgraphTimeSynchronizedWidget\n",
    "\n",
    "def on_crosshair_updated_signal(self, name, trace_value):\n",
    "    print(f'on_crosshair_updated_signal(self: {self}, name: \"{name}\", trace_value: \"{trace_value}\")')\n",
    "    left_side_bar_controls = spike_raster_window.ui.leftSideToolbarWidget\n",
    "    left_side_bar_controls.crosshair_trace_time = trace_value\n",
    "    \n",
    "    # self.ui.lblCrosshairTraceStaticLabel.setVisible(True)\n",
    "    # self.ui.lblCrosshairTraceValue.setVisible(True)\n",
    "\n",
    "\n",
    "for a_name, a_time_sync_widget in active_2d_plot.ui.matplotlib_view_widgets.items():\n",
    "    print(f'a_name: {a_name}')\n",
    "    try:\n",
    "        a_time_sync_widget.update_crosshair_trace(wants_crosshairs_trace=True)\n",
    "        a_time_sync_widget.sigCrosshairsUpdated.connect(on_crosshair_updated_signal)\n",
    "    except KeyError as e:\n",
    "        # KeyError: 'connections'\n",
    "        print(f'\\tfailed.')\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6843c773",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_time_sync_pyqtgraph_widgets['new_curves_separate_plot'].update_crosshair_trace(wants_crosshairs_trace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76ab4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277a736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4254723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(spike_raster_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05d7666",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.plots.main_plot_widget\n",
    "\n",
    "main_plot_widget = active_2d_plot.plots.main_plot_widget # PlotItem\n",
    "main_plot_widget.setMinimumHeight(20.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9cf1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_window_container_layout\n",
    "# main_graphics_layout_widget.ci # GraphicsLayout\n",
    "main_graphics_layout_widget.ci.childItems()\n",
    "# main_graphics_layout_widget.setHidden(True) ## hides too much\n",
    "main_graphics_layout_widget.setHidden(False)\n",
    "\n",
    "# main_graphics_layout_widget\n",
    "\n",
    "active_window_container_layout.setBorder(pg.mkPen('yellow', width=4.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7399378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_window_container_layout.allChildItems()\n",
    "active_window_container_layout.setPreferredHeight(200.0)\n",
    "active_window_container_layout.setMaximumHeight(800.0)\n",
    "active_window_container_layout.setSpacing(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a6aaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set stretch factors to control priority\n",
    "main_graphics_layout_widget.ci.layout.setRowStretchFactor(0, 400)  # Plot1: lowest priority\n",
    "main_graphics_layout_widget.ci.layout.setRowStretchFactor(1, 2)  # Plot2: mid priority\n",
    "main_graphics_layout_widget.ci.layout.setRowStretchFactor(2, 2)  # Plot3: highest priority\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5f61dd",
   "metadata": {
    "tags": [
     "_perform_plot_multi_decoder_meas_pred_position_track",
     "active-2025-01-16"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalDecodersContinuouslyDecodedResult\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import SynchronizedPlotMode\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_1D_most_likely_position_comparsions\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DecoderIdentityColors\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_plot_multi_decoder_meas_pred_position_track\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "\n",
    "## Build the new dock track:\n",
    "dock_identifier: str = 'Continuous Decoding Performance'\n",
    "ts_widget, fig, ax, dDisplayItem = active_2d_plot.add_new_matplotlib_render_plot_widget(name=dock_identifier)\n",
    "\n",
    "## Get the needed data:\n",
    "directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "previously_decoded_keys: List[float] = list(continuously_decoded_result_cache_dict.keys()) # [0.03333]\n",
    "print(F'previously_decoded time_bin_sizes: {previously_decoded_keys}')\n",
    "\n",
    "time_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\n",
    "print(f'time_bin_size: {time_bin_size}')\n",
    "continuously_decoded_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_decode_result.most_recent_continuously_decoded_dict\n",
    "all_directional_continuously_decoded_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = {k:v for k, v in (continuously_decoded_dict or {}).items() if k in TrackTemplates.get_decoder_names()} ## what is plotted in the `f'{a_decoder_name}_ContinuousDecode'` rows by `AddNewDirectionalDecodedEpochs_MatplotlibPlotCommand`\n",
    "## OUT: all_directional_continuously_decoded_dict\n",
    "## Draw the position meas/decoded on the plot widget\n",
    "## INPUT: fig, ax_list, all_directional_continuously_decoded_dict, track_templates\n",
    "\n",
    "_out_artists =  _perform_plot_multi_decoder_meas_pred_position_track(curr_active_pipeline, fig, ax_list, desired_time_bin_size=1.0, enable_flat_line_drawing=True)\n",
    "\n",
    "## sync up the widgets\n",
    "active_2d_plot.sync_matplotlib_render_plot_widget(dock_identifier, sync_mode=SynchronizedPlotMode.TO_WINDOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b589d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Need to figure out what the heck is going on, why are they all decoding to the same position?\n",
    "curr_active_pipeline.find_validators_providing_results(probe_provided_result_keys=['DirectionalDecodersDecoded'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb84d393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders'] # uses `DirectionalMergedDecoders`.\n",
    "\n",
    "# all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_merged_decoders_result.all_directional_decoder_dict # This does not work, because the values in the returned dictionary are PfND, not 1D decoders\n",
    "all_directional_pf1D_Decoder_value = directional_merged_decoders_result.all_directional_pf1D_Decoder\n",
    "\n",
    "pseudo2D_decoder: BasePositionDecoder = all_directional_pf1D_Decoder_value\n",
    "pseudo2D_decoder.xbin_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6256a7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder2D_result: DecodedFilterEpochsResult = continuously_decoded_dict['pseudo2D']\n",
    "decoder2D_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcd9f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder2D_result.filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a618e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_name:types.DecoderName = 'long_LR'\n",
    "\n",
    "\n",
    "result: DecodedFilterEpochsResult = all_directional_continuously_decoded_dict[decoder_name]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5477803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.binning_helpers import BinningContainer\n",
    "\n",
    "time_binning_container: BinningContainer = result.time_bin_containers[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd34e905",
   "metadata": {},
   "outputs": [],
   "source": [
    "marginals_out = result.compute_marginals()\n",
    "marginals_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677f13f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_x_given_n = result.p_x_given_n_list[0]\n",
    "p_x_given_n.shape # (63, 36101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1dbc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow, LayoutScrollability\n",
    "\n",
    "out = BasicBinnedImageRenderingWindow(p_x_given_n.T, xbins=time_binning_container.centers, ybins=pseudo2D_decoder.xbin_centers, name='p_x_given_n', title=\"Continuously Decoded Position Posterior\", variable_label='p_x_given_n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38325e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df['truth_decoder_name'] = pos_df['truth_decoder_name'].fillna('')\n",
    "pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bed9c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_color_dict: Dict[types.DecoderName, str] = DecoderIdentityColors.build_decoder_color_dict()\n",
    "\n",
    "decoded_pos_line_kwargs = dict(lw=1.0, color='gray', alpha=0.8, marker='+', markersize=6, animated=False)\n",
    "inactive_decoded_pos_line_kwargs = dict(lw=0.3, alpha=0.2, marker='.', markersize=2, animated=False)\n",
    "active_decoded_pos_line_kwargs = dict(lw=1.0, alpha=0.8, marker='+', markersize=6, animated=False)\n",
    "\n",
    "\n",
    "_out_data = {}\n",
    "_out_data_plot_kwargs = {}\n",
    "# curr_active_pipeline.global_computation_results.t\n",
    "for a_decoder_name, a_decoder in track_templates.get_decoders_dict().items():\n",
    "    a_continuously_decoded_result = all_directional_continuously_decoded_dict[a_decoder_name]\n",
    "    a_decoder_color = decoder_color_dict[a_decoder_name]\n",
    "    \n",
    "    assert len(a_continuously_decoded_result.p_x_given_n_list) == 1\n",
    "    p_x_given_n = a_continuously_decoded_result.p_x_given_n_list[0]\n",
    "    # p_x_given_n = a_continuously_decoded_result.p_x_given_n_list[0]['p_x_given_n']\n",
    "    time_bin_containers = a_continuously_decoded_result.time_bin_containers[0]\n",
    "    time_window_centers = time_bin_containers.centers\n",
    "    # p_x_given_n.shape # (62, 4, 209389)\n",
    "    a_marginal_x = a_continuously_decoded_result.marginal_x_list[0]\n",
    "    # active_time_window_variable = a_decoder.active_time_window_centers\n",
    "    active_time_window_variable = time_window_centers\n",
    "    active_most_likely_positions_x = a_marginal_x['most_likely_positions_1D'] # a_decoder.most_likely_positions[:,0].T\n",
    "    _out_data[a_decoder_name] = pd.DataFrame({'t': time_window_centers, 'x': active_most_likely_positions_x, 'binned_time': np.arange(len(time_window_centers))})\n",
    "    _out_data[a_decoder_name] = _out_data[a_decoder_name].position.adding_lap_info(laps_df=laps_df, inplace=False)\n",
    "    _out_data[a_decoder_name] = _out_data[a_decoder_name].time_point_event.adding_true_decoder_identifier(t_start=t_start, t_delta=t_delta, t_end=t_end) ## ensures ['maze_id', 'is_LR_dir']\n",
    "    _out_data[a_decoder_name]['is_active_decoder_time'] = (_out_data[a_decoder_name]['truth_decoder_name'].fillna('', inplace=False) == a_decoder_name)\n",
    "\n",
    "    # is_active_decoder_time = (_out_data[a_decoder_name]['truth_decoder_name'] == a_decoder_name)\n",
    "    active_decoder_time_points = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] == a_decoder_name]['t'].to_numpy()\n",
    "    active_decoder_most_likely_positions_x = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] == a_decoder_name]['x'].to_numpy()\n",
    "    active_decoder_inactive_time_points = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] != a_decoder_name]['t'].to_numpy()\n",
    "    active_decoder_inactive_most_likely_positions_x = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] != a_decoder_name]['x'].to_numpy()\n",
    "    ## could fill y with np.nan instead of getting shorter?\n",
    "    _out_data_plot_kwargs[a_decoder_name] = (dict(x=active_decoder_time_points, y=active_decoder_most_likely_positions_x, color=a_decoder_color, **active_decoded_pos_line_kwargs), dict(x=active_decoder_inactive_time_points, y=active_decoder_inactive_most_likely_positions_x, color=a_decoder_color, **inactive_decoded_pos_line_kwargs))\n",
    "\n",
    "_out_data_plot_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8972db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out_data[a_decoder_name] = _out_data[a_decoder_name].position.adding_lap_info(laps_df=laps_df, inplace=False)\n",
    "# _out_data[a_decoder_name] = _out_data[a_decoder_name].time_point_event.adding_true_decoder_identifier(t_start=t_start, t_delta=t_delta, t_end=t_end) ## ensures ['maze_id', 'is_LR_dir']\n",
    "\n",
    "# is_active_decoder_time = (_out_data[a_decoder_name]['truth_decoder_name'] == a_decoder_name)\n",
    "active_decoder_time_points = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] == a_decoder_name]['t'].to_numpy()\n",
    "active_decoder_most_likely_positions_x = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] == a_decoder_name]['x'].to_numpy()\n",
    "active_decoder_inactive_time_points = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] != a_decoder_name]['t'].to_numpy()\n",
    "active_decoder_inactive_most_likely_positions_x = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] != a_decoder_name]['x'].to_numpy()\n",
    "\n",
    "_out_data[a_decoder_name] = ((active_decoder_time_points, active_decoder_most_likely_positions_x), (active_decoder_inactive_time_points, active_decoder_inactive_most_likely_positions_x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dd7358",
   "metadata": {},
   "outputs": [],
   "source": [
    "partitioned_dfs = partition_df_dict(pos_df, partitionColumn='truth_decoder_name')\n",
    "\n",
    "a_decoder_name: str = 'short_LR'\n",
    "a_binned_time_grouped_df = partitioned_dfs[a_decoder_name].groupby('binned_time', axis='index', dropna=True)\n",
    "a_binned_time_grouped_df = a_binned_time_grouped_df.median().dropna(axis='index', subset=['x']) ## without the `.dropna(axis='index', subset=['x'])` part it gets an exhaustive df for all possible values of 'binned_time', even those not listed\n",
    "\n",
    "a_matching_binned_times = a_binned_time_grouped_df.reset_index(drop=False)['binned_time']\n",
    "a_matching_binned_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f61fd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "## split into two dfs for each decoder -- the supported and the unsupported\n",
    "partition\n",
    "\n",
    "PandasHelpers.safe_pandas_get_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f2e753",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df.dropna(axis='index', subset=['lap', 'truth_decoder_name'], inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604e0329",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_df: pd.DataFrame = global_laps_obj.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990b67c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import find_epochs_overlapping_other_epochs\n",
    "\n",
    "## INPUTS: global_laps\n",
    "_out_split_pseudo2D_posteriors_dict = {}\n",
    "_out_split_pseudo2D_out_dict = {}\n",
    "pre_filtered_col_names = ['pre_filtered_most_likely_position_indicies', 'pre_filtered_most_likely_position'] # 'pre_filtered_time_bin_containers', 'pre_filtered_p_x_given_n', \n",
    "post_filtered_col_names = [a_col_name.removeprefix('pre_filtered_') for a_col_name in pre_filtered_col_names] # ['time_bin_containers', 'most_likely_position_indicies', 'most_likely_position']\n",
    "print(post_filtered_col_names)\n",
    "for a_time_bin_size, pseudo2D_decoder_continuously_decoded_result in continuously_decoded_pseudo2D_decoder_dict.items():\n",
    "    print(f'a_time_bin_size: {a_time_bin_size}')\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size] = {'pre_filtered_p_x_given_n': None, 'pre_filtered_time_bin_containers': None, 'pre_filtered_most_likely_position_indicies': None, 'pre_filtered_most_likely_position': None, \n",
    "                                                     'is_timebin_included': None, 'p_x_given_n': None} # , 'time_window_centers': None\n",
    "    # pseudo2D_decoder_continuously_decoded_result: DecodedFilterEpochsResult = continuously_decoded_dict.get('pseudo2D', None)\n",
    "    assert len(pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list) == 1\n",
    "    p_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0]\n",
    "    # p_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0]['p_x_given_n']\n",
    "    time_bin_containers = pseudo2D_decoder_continuously_decoded_result.time_bin_containers[0]\n",
    "    # time_window_centers = time_bin_containers.centers\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position_indicies'] = deepcopy(pseudo2D_decoder_continuously_decoded_result.most_likely_position_indicies_list[0])\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position'] = deepcopy(pseudo2D_decoder_continuously_decoded_result.most_likely_positions_list[0])\n",
    "    ## INPUTS: time_bin_containers, global_laps\n",
    "    left_edges = deepcopy(time_bin_containers.left_edges)\n",
    "    right_edges = deepcopy(time_bin_containers.right_edges)\n",
    "    continuous_time_binned_computation_epochs_df: pd.DataFrame = pd.DataFrame({'start': left_edges, 'stop': right_edges, 'label': np.arange(len(left_edges))})\n",
    "    is_timebin_included: NDArray = find_epochs_overlapping_other_epochs(epochs_df=continuous_time_binned_computation_epochs_df, epochs_df_required_to_overlap=deepcopy(global_laps))\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_p_x_given_n'] = p_x_given_n\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_time_bin_containers'] = time_bin_containers\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['is_timebin_included'] = is_timebin_included\n",
    "    # continuous_time_binned_computation_epochs_df['is_in_laps'] = is_timebin_included\n",
    "    ## filter by whether it's included or not:\n",
    "    p_x_given_n = p_x_given_n[:, :, is_timebin_included]\n",
    "    # time_window_centers = \n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['p_x_given_n'] = p_x_given_n\n",
    "    # _out_split_pseudo2D_out_dict[a_time_bin_size]['time_window_centers'] = time_window_centers[is_timebin_included]\n",
    "    # p_x_given_n.shape # (62, 4, 209389)\n",
    "\n",
    "    ## Split across the 2nd axis to make 1D posteriors that can be displayed in separate dock rows:\n",
    "    assert p_x_given_n.shape[1] == 4, f\"expected the 4 pseudo-y bins for the decoder in p_x_given_n.shape[1]. but found p_x_given_n.shape: {p_x_given_n.shape}\"\n",
    "    # split_pseudo2D_posteriors_dict = {k:np.squeeze(p_x_given_n[:, i, :]) for i, k in enumerate(('long_LR', 'long_RL', 'short_LR', 'short_RL'))}\n",
    "    _out_split_pseudo2D_posteriors_dict[a_time_bin_size] = deepcopy(p_x_given_n)\n",
    "    \n",
    "    # for a_col_name in pre_filtered_col_names:\n",
    "    #     filtered_col_name = a_col_name.removeprefix('pre_filtered_')\n",
    "    #     print(f'a_col_name: {a_col_name}, filtered_col_name: {filtered_col_name}, shape: {np.shape(_out_split_pseudo2D_out_dict[a_time_bin_size][a_col_name])}')\n",
    "    #     _out_split_pseudo2D_out_dict[a_time_bin_size][filtered_col_name] = _out_split_pseudo2D_out_dict[a_time_bin_size][a_col_name][is_timebin_included, :]\n",
    "        \n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['most_likely_position_indicies'] = _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position_indicies'][:, is_timebin_included]\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['most_likely_position'] = _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position'][is_timebin_included, :]\n",
    "    \n",
    "\n",
    "p_x_given_n.shape # (n_position_bins, n_decoding_models, n_time_bins) - (57, 4, 29951)\n",
    "\n",
    "## OUTPUTS: _out_split_pseudo2D_posteriors_dict, _out_split_pseudo2D_out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d25155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_most_likely_position_comparsions\n",
    "\n",
    "# fig, axs = plot_most_likely_position_comparsions(pho_custom_decoder, axs=ax, sess.position.to_dataframe())\n",
    "fig, axs = plot_most_likely_position_comparsions(computation_result.computed_data['pf2D_Decoder'], computation_result.sess.position.to_dataframe(), **overriding_dict_with(lhs_dict={'show_posterior':True, 'show_one_step_most_likely_positions_plots':True}, **kwargs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0cf8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93036009",
   "metadata": {},
   "source": [
    "### <a id='toc7_1_2_'></a>[🔝 Dock Track Widgets](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67f05bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.add_new_embedded_pyqtgraph_render_plot_widget("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f78e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_main_raster_plot = False\n",
    "_interval_tracks_out_dict = active_2d_plot.prepare_pyqtgraph_intervalPlot_tracks(enable_interval_overview_track=False, should_link_to_main_plot_widget=has_main_raster_plot)\n",
    "interval_window_dock_config, interval_dock_item, intervals_time_sync_pyqtgraph_widget, intervals_root_graphics_layout_widget, intervals_plot_item = _interval_tracks_out_dict['intervals']\n",
    "# dock_config, interval_overview_dock_item, intervals_overview_time_sync_pyqtgraph_widget, intervals_overview_root_graphics_layout_widget, intervals_overview_plot_item = _interval_tracks_out_dict['interval_overview']\n",
    "interval_window_dock_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2042a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_dock_item.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cc9d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_dock_item.setMaximumHeight(89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9865df",
   "metadata": {},
   "outputs": [],
   "source": [
    "_interval_tracks_out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4637029",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.dock_manager_widget.add_display_dock("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9f3acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.get_flat_dockitems_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f946a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.layout_dockGroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb8dc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.get_group_only_flat_dock_identifiers_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d822fa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.get_leaf_only_flat_dock_identifiers_list()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd739ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_dock in active_2d_plot.get_flat_dockitems_list():\n",
    "    a_dock.showTitleBar()\n",
    "    # a_dock.updateStyle()\n",
    "    a_dock.config\n",
    "    a_dock.setOrientation('horizontal', force=True)\n",
    "    a_dock.updateStyle()\n",
    "    a_dock.update() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f51940",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dock Tree Widget should register with `dock_manager_widget` (DynamicDockDisplayAreaContentMixin) so that it recieves and issues updates when dock items are added/changed/closed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fc1767",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import DockDisplayColors, CustomDockDisplayConfig\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.NestedDockAreaWidget import NestedDockAreaWidget\n",
    "\n",
    "name='group_dock_widget'\n",
    "dockSize=(500,50*4)\n",
    "dockAddLocationOpts=['bottom']\n",
    "\n",
    "display_config = CustomDockDisplayConfig(showCloseButton=True, showCollapseButton=True, showGroupButton=True, orientation='horizontal')\n",
    "## Add the container to hold dynamic matplotlib plot widgets:\n",
    "nested_dynamic_docked_widget_container = NestedDockAreaWidget()\n",
    "nested_dynamic_docked_widget_container.setObjectName(\"nested_dynamic_docked_widget_container\")\n",
    "nested_dynamic_docked_widget_container.setSizePolicy(pg.QtGui.QSizePolicy.Expanding, pg.QtGui.QSizePolicy.Preferred)\n",
    "nested_dynamic_docked_widget_container.setMinimumHeight(40)\n",
    "nested_dynamic_docked_widget_container.setContentsMargins(0, 0, 0, 0)\n",
    "_, dDisplayItem = active_2d_plot.ui.dynamic_docked_widget_container.add_display_dock(name, dockSize=dockSize, display_config=display_config, widget=nested_dynamic_docked_widget_container, dockAddLocationOpts=dockAddLocationOpts, autoOrientation=False)\n",
    "dDisplayItem.setOrientation('horizontal', force=True)\n",
    "dDisplayItem.updateStyle()\n",
    "dDisplayItem.update() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0aea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_docked_widget_container: NestedDockAreaWidget  = active_2d_plot.ui.dynamic_docked_widget_container\n",
    "# dynamic_docked_widget_container.dynamic_display_dict\n",
    "\n",
    "name_list = ['intervals', 'rasters[raster_window]', 'new_curves_separate_plot']\n",
    "for a_name in name_list:\n",
    "    a_dock = dynamic_docked_widget_container.find_display_dock(a_name)\n",
    "    a_dock\n",
    "    a_dock.hideTitleBar()\n",
    "    # a_dock.labelHidden = True\n",
    "    a_dock.updateStyle()\n",
    "    \n",
    "\n",
    "\n",
    "# dynamic_docked_widget_container.find_display_dock('intervals').hideTitleBar()\n",
    "# dynamic_docked_widget_container.find_display_dock('rasters[raster_window]').hideTitleBar()\n",
    "# dynamic_docked_widget_container.find_display_dock('new_curves_separate_plot').hideTitleBar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9939b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_print_dock_sizes(active_2d_plot):\n",
    "    \"\"\" prints the size variables for each Dock item \n",
    "    \"\"\"\n",
    "    from pyphoplacecellanalysis.General.Mixins.DisplayHelpers import debug_widget_geometry\n",
    "\n",
    "    flat_dockitems_list = active_2d_plot.ui.dynamic_docked_widget_container.get_flat_dockitems_list()\n",
    "    for a_dock in flat_dockitems_list:\n",
    "        print(f'a_dock: {a_dock}')\n",
    "        debug_widget_geometry(a_dock)\n",
    "        \n",
    "    print('\\tdone.')\n",
    "        \n",
    "\n",
    "debug_print_dock_sizes(active_2d_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c932dcce",
   "metadata": {
    "tags": [
     "dock-widgets"
    ]
   },
   "outputs": [],
   "source": [
    "flat_widgets_list = active_2d_plot.ui.dynamic_docked_widget_container.get_flat_widgets_list()\n",
    "flat_dockitems_list = active_2d_plot.ui.dynamic_docked_widget_container.get_flat_dockitems_list()\n",
    "flat_dock_identifiers_list = active_2d_plot.ui.dynamic_docked_widget_container.get_flat_dock_identifiers_list()\n",
    "# flat_dockitems_list\n",
    "flat_dock_identifiers_list\n",
    "# flat_widgets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03657d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "rasters_dock = active_2d_plot.ui.dynamic_docked_widget_container.find_display_dock('rasters[raster_window]')\n",
    "rasters_dock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98199475",
   "metadata": {},
   "outputs": [],
   "source": [
    "rasters_dock.stretch()\n",
    "rasters_dock.setStretch(y=240)\n",
    "rasters_dock.stretch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4405ffad",
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_dock_items = {}\n",
    "nested_dynamic_docked_widget_container_widgets = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fd4da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()\n",
    "# flat_widgets_list = active_2d_plot.ui.dynamic_docked_widget_container.get_flat_widgets_list()\n",
    "# dock_group_name: str = 'ContinuousDecode_ - t_bin_size: 0.025'\n",
    "dock_group_name: str = 'ContinuousDecode_ - t_bin_size: 0.05'\n",
    "flat_group_dockitems_list = grouped_dock_items_dict[dock_group_name]\n",
    "dDisplayItem, nested_dynamic_docked_widget_container = active_2d_plot.ui.dynamic_docked_widget_container.build_wrapping_nested_dock_area(flat_group_dockitems_list, dock_group_name=dock_group_name)\n",
    "nested_dock_items[dock_group_name] = dDisplayItem\n",
    "nested_dynamic_docked_widget_container_widgets[dock_group_name] = nested_dynamic_docked_widget_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432310ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: active_2d_plot\n",
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()\n",
    "nested_dock_items = {}\n",
    "nested_dynamic_docked_widget_container_widgets = {}\n",
    "for dock_group_name, flat_group_dockitems_list in grouped_dock_items_dict.items():\n",
    "    dDisplayItem, nested_dynamic_docked_widget_container = active_2d_plot.ui.dynamic_docked_widget_container.build_wrapping_nested_dock_area(flat_group_dockitems_list, dock_group_name=dock_group_name)\n",
    "    nested_dock_items[dock_group_name] = dDisplayItem\n",
    "    nested_dynamic_docked_widget_container_widgets[dock_group_name] = nested_dynamic_docked_widget_container\n",
    "\n",
    "## OUTPUTS: nested_dock_items, nested_dynamic_docked_widget_container_widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d095b42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_wrapping_nested_dock_area\n",
    "\n",
    "dynamic_docked_widget_container = active_2d_plot.ui.dynamic_docked_widget_container # NestedDockAreaWidget \n",
    "dynamic_docked_widget_container.build_wrapping_nested_dock_area(f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0f9b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_crosshairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85366f3c",
   "metadata": {},
   "source": [
    "## <a id='toc7_2_'></a>[2025-02-17 - Dock Item \"Track\" sizing](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f80e740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.NestedDockAreaWidget import NestedDockAreaWidget\n",
    "\n",
    "dock_manager_widget: NestedDockAreaWidget  = active_2d_plot.dock_manager_widget\n",
    "dock_manager_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7954acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()\n",
    "grouped_dock_items_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbc4bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_dock_items, nested_dynamic_docked_widget_container_widgets = dock_manager_widget.layout_dockGroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9b64d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dock_manager_widget.get_flat_dockitems_list()\n",
    "\n",
    "flat_dockitems_list = dock_manager_widget.get_flat_dockitems_list() ## get the non-grouped dockitems\n",
    "flat_dockitems_list\n",
    "# flat_dockitems_list[0].widgets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497f2289",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dock: Dock = flat_dockitems_list[-1]\n",
    "a_dock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9496b8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_dock_stretch_sizes_list = [a_dock.stretch() for a_dock in flat_dockitems_list] # [(500, 40), (500, 50), (65, 200), (65, 200), (65, 200), (65, 200), (500, 321), (500, 25)]\n",
    "flat_dock_stretch_sizes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d0b1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_dock_stretch_sizes = np.array(flat_dock_stretch_sizes_list)\n",
    "total_height: float = np.sum(flat_dock_stretch_sizes, axis=0)[-1] ## total height of all docks\n",
    "total_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c6c246",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_dock_configs_list = [a_dock.config for a_dock in flat_dockitems_list]\n",
    "flat_dock_configs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dad856",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dock: Dock = flat_dockitems_list[0]\n",
    "a_dock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71138bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_keys_if_possible(curr_key='dynamic_display_dict', curr_value=dock_manager_widget.dynamic_display_dict, max_depth=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb42af97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.External.pyqtgraph.dockarea.Dock import Dock, DockDisplayConfig, DockLabel\n",
    "\n",
    "print(f'active_2d_plot.get_leaf_only_flat_dock_identifiers_list(): {active_2d_plot.get_leaf_only_flat_dock_identifiers_list()}')\n",
    "leaf_only_flat_docks_dict: Dict[str, Dock] = {k:active_2d_plot.find_display_dock(k) for k in active_2d_plot.get_leaf_only_flat_dock_identifiers_list()}\n",
    "print(f'leaf_only_flat_docks_dict: {leaf_only_flat_docks_dict}')\n",
    "\n",
    "leaf_only_flat_docks_geometry_size_list = [(a_dock.width(), a_dock.height()) for k, a_dock in leaf_only_flat_docks_dict.items()] # [(1855, 69), (1855, 69), (1855, 71), (1855, 71), (1855, 71), (1855, 73), (1855, 64), (1855, 85), (1855, 30)]\n",
    "leaf_only_flat_docks_geometry_sizes = np.vstack(leaf_only_flat_docks_geometry_size_list)\n",
    "leaf_only_flat_docks_geometry_sizes\n",
    "\n",
    "\n",
    "single_track_height_unit: int = 30 ## how tall a single track height unit is, determining the minimum height of a track\n",
    "\n",
    "\n",
    "total_leaf_only_flat_docks_geometry_size = np.sum(leaf_only_flat_docks_geometry_sizes, axis=0)\n",
    "total_leaf_only_flat_docks_geometry_size\n",
    "\n",
    "leaf_only_flat_docks_stretch_list = [a_dock.stretch() for k, a_dock in leaf_only_flat_docks_dict.items()] # [(500, 40), (500, 50), (65, 200), (65, 200), (65, 200), (65, 200), (10, 4), (10, 4), (10, 1)]\n",
    "leaf_only_flat_docks_stretchs = np.vstack(leaf_only_flat_docks_stretch_list)\n",
    "leaf_only_flat_docks_stretchs\n",
    "\n",
    "# leaf_only_flat_docks_dict\n",
    "\n",
    "# active_2d_plot.get_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb50aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_only_flat_docks_dict['intervals'].setStretch(x=10, y=4)\n",
    "\n",
    "leaf_only_flat_docks_dict['new_curves_separate_plot'].setStretch(x=10, y=4)\n",
    "for a_name in ['ContinuousDecode_long_LR - t_bin_size: 0.025', 'ContinuousDecode_long_RL - t_bin_size: 0.025', 'ContinuousDecode_short_LR - t_bin_size: 0.025', 'ContinuousDecode_short_RL - t_bin_size: 0.025']:\n",
    "\tleaf_only_flat_docks_dict[a_name].setStretch(x=10, y=4)\n",
    "\tleaf_only_flat_docks_dict[a_name].setMinimumHeight(30)  # Set a smaller minimum height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591bd986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.External.pyqtgraph.dockarea.Dock import debug_widget_geometry\n",
    "\n",
    "# active_2d_plot.get_leaf_only_flat_dock_identifiers_list()\n",
    "\n",
    "dock_items_dict = {k:v[-1] for k, v in output_dict.items()}\n",
    "# dock_items_dict = {k:v[-1] for k, v in MASKED_output_dict.items()}\n",
    "dock_items_dict\n",
    "\n",
    "a_dock_item = dock_items_dict['PBE_marginal_over_track_ID']\n",
    "a_dock_item.setStretch(x=10, y=1)  # Same larger height stretch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b0acc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for k, v in dock_items_dict.items():\n",
    "    print(f'k: {k}')\n",
    "    # debug_widget_geometry(v, widget_name=k)\n",
    "    # Allow one dock to be smaller than its minimum size hint\n",
    "    v.widgetArea.setMinimumHeight(30)  # Set a smaller minimum height\n",
    "    \n",
    "    v.debug_print(widget_name=k)\n",
    "    # Assuming you have three docks\n",
    "    # v.stretch()  # Small height stretch\n",
    "\n",
    "    # smallDock.setStretch(x=10, y=1)  # Small height stretch\n",
    "    # tallDock1.setStretch(x=10, y=3)  # Larger height stretch\n",
    "    # tallDock2.setStretch(x=10, y=3)  # Same larger height stretch\n",
    "\n",
    "    # v.label.debug_print(label_name=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3fe261",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.dissolve_all_dockGroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db33f073",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.layout_dockGroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c45eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dock_items_dict: Dict[str, List[Dock]] = active_2d_plot.get_dockGroup_dock_dict()\n",
    "grouped_dock_items_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693f5fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.dock_manager_widget.nested_dock_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9046712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a_group_id, a_group_dock in active_2d_plot.dock_manager_widget.nested_dock_items.items():\n",
    "# \ta_group_container_id: str = f'GROUP[{a_group_id}]'\n",
    "# \tdel active_2d_plot.dock_manager_widget.nested_dock_items[a_group_id]\n",
    "\t\n",
    "# active_2d_plot.dock_manager_widget.nested_dock_items.clear()\n",
    "active_2d_plot.dock_manager_widget.nested_dock_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99688c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_dock_ids_list = active_2d_plot.get_group_only_flat_dock_identifiers_list()\n",
    "group_dock_ids_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14beb813",
   "metadata": {},
   "source": [
    "## 🎯🔜 Adjust SpikeRaster2D default plot sizings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184de423",
   "metadata": {
    "tags": [
     "2025-05-12"
    ]
   },
   "outputs": [],
   "source": [
    "## extract the components so the `background_static_scroll_window_plot` scroll bar is the right size:\n",
    "active_2d_plot = spike_raster_window.spike_raster_plt_2d\n",
    "preview_overview_scatter_plot: pg.ScatterPlotItem  = active_2d_plot.plots.preview_overview_scatter_plot # ScatterPlotItem\n",
    "# preview_overview_scatter_plot.setDownsampling(auto=True, method='subsample', dsRate=10)\n",
    "main_graphics_layout_widget: pg.GraphicsLayoutWidget = active_2d_plot.ui.main_graphics_layout_widget\n",
    "wrapper_layout: pg.QtWidgets.QVBoxLayout = active_2d_plot.ui.wrapper_layout\n",
    "main_content_splitter = active_2d_plot.ui.main_content_splitter # QSplitter\n",
    "active_window_container_layout = active_2d_plot.ui.active_window_container_layout\n",
    "layout = active_2d_plot.ui.layout\n",
    "\n",
    "has_main_raster_plot: bool = (active_2d_plot.plots.main_plot_widget is not None)\n",
    "if has_main_raster_plot:\n",
    "    main_plot_widget = active_2d_plot.plots.main_plot_widget # PlotItem\n",
    "    main_plot_widget.setMinimumHeight(20.0)\n",
    "else:\n",
    "    active_window_container_layout.setVisible(False)\n",
    "\n",
    "background_static_scroll_window_plot = active_2d_plot.plots.background_static_scroll_window_plot # PlotItem\n",
    "background_static_scroll_window_plot.setMinimumHeight(50.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a139fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_plot_widget.size()\n",
    "main_plot_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee18a487",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_plot_widget.hide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dc5dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_static_scroll_window_plot.size()\n",
    "background_static_scroll_window_plot.setMaximumHeight(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ce21ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "_raster_tracks_out_dict = active_2d_plot.prepare_pyqtgraph_rasterPlot_track(name_modifier_suffix='raster_window', should_link_to_main_plot_widget=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6059b40a",
   "metadata": {},
   "source": [
    "#### <a id='toc7_2_1_1_'></a>[Spike3DRasterWindow - Right Sidebar Widgets](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eff235",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.on_update_right_sidebar_visible_interval_info_tables()\n",
    "spike_raster_window.build_dock_area_managing_tree_widget()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9d696e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.EpochRenderConfigWidget.EpochRenderConfigWidget import EpochRenderConfigWidget, EpochRenderConfigsListWidget\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import DockDisplayColors, CustomDockDisplayConfig\n",
    "\n",
    "an_epochs_display_list_widget: EpochRenderConfigsListWidget = spike_raster_window.build_epoch_intervals_visual_configs_widget()\n",
    "an_epochs_display_list_widget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549f454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_raster_plot.ui.epochs_render_configs_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa59d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.build_neuron_visual_configs_widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3738059c",
   "metadata": {},
   "source": [
    "## <a id='toc7_3_'></a>[💯 2025-01-22 - Add Selection Widget for SpikeRaster3DWindow](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bb8383",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_plt_2d: Spike2DRaster = spike_raster_window.spike_raster_plt_2d\n",
    "a_range_selection_widget, range_selection_root_graphics_layout_widget, range_selection_plot_item, range_selection_dDisplayItem = spike_raster_plt_2d.add_new_embedded_pyqtgraph_render_plot_widget(name='range_selection_capture_widget', dockSize=(500,25))\n",
    "range_selection_dDisplayItem.setMaximumHeight(25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c1edcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attrs import define, field, Factory\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsObjects.CustomInfiniteLine import CustomInfiniteLine\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsObjects.CustomLinearRegionItem import CustomLinearRegionItem\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsObjects.CustomIntervalRectsItem import CustomIntervalRectsItem\n",
    "\n",
    "\n",
    "@define(slots=False)\n",
    "class UserTimelineSelections:\n",
    "    point_selections: List[pg.TargetItem] = field(default=Factory(list))\n",
    "    line_selections: List[CustomInfiniteLine] = field(default=Factory(list))\n",
    "    range_selections: List[CustomLinearRegionItem] = field(default=Factory(list))\n",
    "    \n",
    "\n",
    "selections: UserTimelineSelections = UserTimelineSelections()\n",
    "selections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be99f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QMainWindow, QVBoxLayout, QWidget\n",
    "import pyqtgraph as pg\n",
    "\n",
    "@function_attributes(short_name=None, tags=['pyqtgraph', 'selection', 'interactive'], input_requires=[], output_provides=[], uses=[], used_by=[], creation_date='2025-06-16 10:26', related_items=[])\n",
    "class PlotWithSelection(pg.PlotWidget):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        # Initialize variables to track the selection\n",
    "        self.start_pos = None\n",
    "        self.end_pos = None\n",
    "        self.is_selecting = False\n",
    "        \n",
    "        # Disable default panning\n",
    "        self.setMouseTracking(True)\n",
    "        self.plotItem.vb.setMouseEnabled(x=False, y=False)  # Disable default panning/zooming\n",
    "\n",
    "    def mousePressEvent(self, event):\n",
    "        if event.button() == Qt.LeftButton:\n",
    "            # Get the position where the mouse was clicked\n",
    "            pos = self.plotItem.vb.mapSceneToView(event.pos())\n",
    "            self.start_pos = pos.x()\n",
    "            self.is_selecting = True\n",
    "        else:\n",
    "            super().mousePressEvent(event)\n",
    "\n",
    "    def mouseMoveEvent(self, event):\n",
    "        if self.is_selecting:\n",
    "            # Update the end position while dragging\n",
    "            pos = self.plotItem.vb.mapSceneToView(event.pos())\n",
    "            self.end_pos = pos.x()\n",
    "            self.update_selection()\n",
    "        else:\n",
    "            super().mouseMoveEvent(event)\n",
    "\n",
    "    def mouseReleaseEvent(self, event):\n",
    "        if event.button() == Qt.LeftButton and self.is_selecting:\n",
    "            # Get the final position where the mouse was released\n",
    "            pos = self.plotItem.vb.mapSceneToView(event.pos())\n",
    "            self.end_pos = pos.x()\n",
    "\n",
    "            # Ensure that the start and end positions are valid\n",
    "            if self.start_pos is not None and self.end_pos is not None:\n",
    "                # Create a new LinearRegionItem\n",
    "                region = pg.LinearRegionItem(values=(min(self.start_pos, self.end_pos), max(self.start_pos, self.end_pos)))\n",
    "                self.addItem(region)\n",
    "\n",
    "            # Reset the selection state\n",
    "            self.start_pos = None\n",
    "            self.end_pos = None\n",
    "            self.is_selecting = False\n",
    "        else:\n",
    "            super().mouseReleaseEvent(event)\n",
    "\n",
    "    def update_selection(self):\n",
    "        # Optionally, you can draw a temporary selection line here\n",
    "        pass\n",
    "\n",
    "# Example usage\n",
    "win = QMainWindow()\n",
    "central_widget = QWidget()\n",
    "layout = QVBoxLayout(central_widget)\n",
    "\n",
    "plot_widget = PlotWithSelection()\n",
    "plot_widget.plot([1, 5, 2, 4, 3], pen='r')  # Example data\n",
    "\n",
    "layout.addWidget(plot_widget)\n",
    "win.setCentralWidget(central_widget)\n",
    "win.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599e7a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_selection_plot_item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ded6097",
   "metadata": {},
   "source": [
    "### 2025-06-16 - Matplotlib `SpanSelector` approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c613cd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.widgets import SpanSelector\n",
    "\n",
    "dock_titles = ['ContinuousDecode_long_LR - t_bin_size: 0.025', 'ContinuousDecode_long_RL - t_bin_size: 0.025', 'ContinuousDecode_short_LR - t_bin_size: 0.025', 'ContinuousDecode_short_RL - t_bin_size: 0.025']\n",
    "for a_dock_title in dock_titles:\n",
    "    a_dock, widget = active_2d_plot.find_dock_item_tuple(identifier=a_dock_title)\n",
    "    # widget.plots_data\n",
    "    widget.params.user_selections = [] ## empty selections to start\n",
    "    widget.ui.span_selector = None\n",
    "    widget.ui.span_selector_fn = None\n",
    "\n",
    "    def onselect(xmin, xmax):\n",
    "        \"\"\" captures: widget, y, line2, ax2, fig, \n",
    "        \"\"\"\n",
    "        indmin, indmax = np.searchsorted(widget.plots_data.time_window_centers, (xmin, xmax))\n",
    "        indmax = min(len(widget.plots_data.time_window_centers) - 1, indmax)\n",
    "        region_x = widget.plots_data.time_window_centers[indmin:indmax]\n",
    "        # region_y = widget.plots_data.xbin[indmin:indmax]\n",
    "        if len(region_x) >= 2:\n",
    "            widget.params.user_selections.append(region_x)            \n",
    "            # line2.set_data(region_x, region_y)\n",
    "            # ax2.set_xlim(region_x[0], region_x[-1])\n",
    "            # ax2.set_ylim(region_y.min(), region_y.max())\n",
    "            # fig.canvas.draw_idle()\n",
    "            \n",
    "    widget.ui.span_selector_fn = onselect\n",
    "\n",
    "    widget.ui.span_selector = SpanSelector(\n",
    "        widget.ax,\n",
    "        widget.ui.span_selector_fn,\n",
    "        \"horizontal\",\n",
    "        useblit=True,\n",
    "        props=dict(alpha=0.5, facecolor=\"tab:blue\"),\n",
    "        interactive=True,\n",
    "        drag_from_anywhere=True\n",
    "    )\n",
    "    # Set useblit=True on most backends for enhanced performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94b0209",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dock, widget = active_2d_plot.find_dock_item_tuple(identifier='ContinuousDecode_long_RL - t_bin_size: 0.025')\n",
    "\n",
    "# widget.plots_data.xbin\n",
    "# widget.plots_data.time_\n",
    "widget.params.user_selections # [array([548.812, 548.838, 548.862, 548.888]), array([549.062, 549.088, 549.112, 549.138]), array([548.213, 548.237, 548.263, 548.288])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fcda63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [array([548.812, 548.838, 548.862, 548.888]), array([549.062, 549.088, 549.112, 549.138]), array([548.213, 548.237, 548.263, 548.288])]\n",
    "# 5 skip bins\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316fdc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.widgets import SpanSelector\n",
    "\n",
    "\n",
    "# class StatefulSpanSelector(SpanSelector):\n",
    "#     \"\"\" a version of MAtplotlib's SpanSelector widget that contains its selection state, callback function, and related information to provide a more object-oriented approach\n",
    "#     \"\"\"\n",
    "#     def onselect(self, xmin, xmax):\n",
    "#         indmin, indmax = np.searchsorted(x, (xmin, xmax))\n",
    "#         indmax = min(len(x) - 1, indmax)\n",
    "\n",
    "#         region_x = x[indmin:indmax]\n",
    "#         region_y = y[indmin:indmax]\n",
    "\n",
    "#         if len(region_x) >= 2:\n",
    "#             line2.set_data(region_x, region_y)\n",
    "#             ax2.set_xlim(region_x[0], region_x[-1])\n",
    "#             ax2.set_ylim(region_y.min(), region_y.max())\n",
    "#             fig.canvas.draw_idle()\n",
    "\n",
    "\n",
    "\n",
    "# Fixing random state for reproducibility\n",
    "np.random.seed(19680801)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(8, 6))\n",
    "\n",
    "x = np.arange(0.0, 5.0, 0.01)\n",
    "y = np.sin(2 * np.pi * x) + 0.5 * np.random.randn(len(x))\n",
    "\n",
    "ax1.plot(x, y)\n",
    "ax1.set_ylim(-2, 2)\n",
    "ax1.set_title('Press left mouse button and drag '\n",
    "              'to select a region in the top graph')\n",
    "\n",
    "line2, = ax2.plot([], [])\n",
    "\n",
    "\n",
    "def onselect(xmin, xmax):\n",
    "    \"\"\" captures: x, y, line2, ax2, fig, \n",
    "    \"\"\"\n",
    "    indmin, indmax = np.searchsorted(x, (xmin, xmax))\n",
    "    indmax = min(len(x) - 1, indmax)\n",
    "\n",
    "    region_x = x[indmin:indmax]\n",
    "    region_y = y[indmin:indmax]\n",
    "\n",
    "    if len(region_x) >= 2:\n",
    "        line2.set_data(region_x, region_y)\n",
    "        ax2.set_xlim(region_x[0], region_x[-1])\n",
    "        ax2.set_ylim(region_y.min(), region_y.max())\n",
    "        fig.canvas.draw_idle()\n",
    "        \n",
    "\n",
    "\n",
    "span = SpanSelector(\n",
    "    ax1,\n",
    "    onselect,\n",
    "    \"horizontal\",\n",
    "    useblit=True,\n",
    "    props=dict(alpha=0.5, facecolor=\"tab:blue\"),\n",
    "    interactive=True,\n",
    "    drag_from_anywhere=True\n",
    ")\n",
    "# Set useblit=True on most backends for enhanced performance.\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8736da11",
   "metadata": {},
   "source": [
    "# <a id='toc10_'></a>[Other Misc Plotting Stuff](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521bba12",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.plot._display_directional_template_debugger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb5ba90",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_template_debugger')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e9208a",
   "metadata": {},
   "source": [
    "### <a id='toc10_1_1_'></a>[Resume display stuff](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50f2ef8",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from flexitext import flexitext\n",
    "from neuropy.utils.matplotlib_helpers import FormattedFigureText, FigureMargins ## flexitext version\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out = curr_active_pipeline.display('_display_directional_track_template_pf1Ds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d2b444",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# _restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080c1041",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_two_step_decoder_prediction_error_2D', global_epoch_context, variable_name='p_x_given_n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e05b045",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_plot_most_likely_position_comparisons', global_epoch_context) # , variable_name='p_x_given_n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddebd9e",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_laps_overview')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d805c37",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_laps_overview')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3c3cea",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "'_display_directional_laps_overview'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb98e796",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# '_display_directional_merged_pfs'\n",
    "_out = curr_active_pipeline.display('_display_directional_merged_pfs', plot_all_directions=False, plot_long_directional=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47076a61",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "'_display_1d_placefield_occupancy'\n",
    "'_display_placemaps_pyqtplot_2D'\n",
    " '_display_2d_placefield_occupancy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481df233",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_2d_placefield_occupancy', global_any_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694d0a20",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_grid_bin_bounds_validation')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fbe6ee",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "_out = curr_active_pipeline.display('_display_running_and_replay_speeds_over_time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58951b11",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.utils.matplotlib_helpers import add_rectangular_selector, add_range_selector\n",
    "\n",
    "\n",
    "# epoch_name = global_any_name\n",
    "epoch_name = short_epoch_name\n",
    "computation_result = curr_active_pipeline.computation_results[epoch_name]\n",
    "grid_bin_bounds = computation_result.computation_config['pf_params'].grid_bin_bounds\n",
    "epoch_context = curr_active_pipeline.filtered_contexts[epoch_name]\n",
    "print(grid_bin_bounds)     \n",
    "fig, ax = computation_result.computed_data.pf2D.plot_occupancy(identifier_details_list=[epoch_name], active_context=epoch_context) \n",
    "\n",
    "# rect_selector, set_extents, reset_extents = add_rectangular_selector(fig, ax, initial_selection=grid_bin_bounds) # (24.82, 257.88), (125.52, 149.19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada4720b",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import add_vertical_track_bounds_lines\n",
    "\n",
    "grid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\n",
    "long_track_line_collection, short_track_line_collection = add_vertical_track_bounds_lines(grid_bin_bounds=grid_bin_bounds, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b862a66",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.peak_location_representing import compute_placefield_center_of_mass_positions\n",
    "\n",
    "\n",
    "epoch_name = global_any_name\n",
    "computation_result = curr_active_pipeline.computation_results[epoch_name]\n",
    "grid_bin_bounds = deepcopy(computation_result.computation_config['pf_params'].grid_bin_bounds)\n",
    "epoch_context = curr_active_pipeline.filtered_contexts[epoch_name]\n",
    "\n",
    "grid_bin_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65654f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5905e90b",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "grid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\n",
    "grid_bin_bounds\n",
    "long_pf2D.xbin\n",
    "long_pf2D.ybin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befc3d1d",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "occupancy = deepcopy(long_pf2D.occupancy) # occupancy.shape # (60, 15)\n",
    "xbin = deepcopy(long_pf2D.xbin)\n",
    "ybin = deepcopy(long_pf2D.ybin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0416d4",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from scipy import ndimage # used for `compute_placefield_center_of_masses`\n",
    "from neuropy.utils.mixins.peak_location_representing import compute_occupancy_center_of_mass_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6352663",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "occupancy_x_center_dict = {k:compute_occupancy_center_of_mass_positions(v.pf.occupancy, xbin=v.pf.xbin, ybin=v.pf.ybin).item() for k, v in track_templates.get_decoders_dict().items()}\n",
    "occupancy_x_center_dict # {'long_LR': 162.99271603199625, 'long_RL': 112.79866056603696, 'short_LR': 138.45611791646, 'short_RL': 130.78889937230684}\n",
    "\n",
    "occupancy_mask_x_center_dict = {k:compute_occupancy_center_of_mass_positions(v.pf.visited_occupancy_mask, xbin=v.pf.xbin, ybin=v.pf.ybin).item() for k, v in track_templates.get_decoders_dict().items()}\n",
    "occupancy_mask_x_center_dict # {'long_LR': 135.66781520875904, 'long_RL': 130.0042755113645, 'short_LR': 133.77996864296085, 'short_RL': 143.21920147195175}\n",
    "\n",
    "\n",
    "# {k:compute_occupancy_center_of_mass_positions(v.pf.occupancy, xbin=v.pf.xbin, ybin=v.pf.ybin).item() for k, v in track_templates.get_decoders_dict().items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb029d8",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "occupancy = deepcopy(long_pf2D.occupancy) # occupancy.shape # (60, 15)\n",
    "xbin = deepcopy(long_pf2D.xbin)\n",
    "ybin = deepcopy(long_pf2D.ybin)\n",
    "\n",
    "# masked_nonzero_occupancy = deepcopy(long_pf2D.nan_never_visited_occupancy)\n",
    "\n",
    "masked_nonzero_occupancy = deepcopy(long_pf2D.visited_occupancy_mask)\n",
    "\n",
    "# occupancy_CoM_positions = compute_occupancy_center_of_mass_positions(occupancy, xbin=long_pf2D.xbin, ybin=long_pf2D.ybin)\n",
    "occupancy_CoM_positions = compute_occupancy_center_of_mass_positions(masked_nonzero_occupancy, xbin=long_pf2D.xbin, ybin=long_pf2D.ybin) # array([127.704, 145.63])\n",
    "occupancy_CoM_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097c3b06",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "long_pf2D.nan_never_visited_occupancy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4caa06",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_display_function_docs_dict# '_display_grid_bin_bounds_validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f963a7",
   "metadata": {
    "tags": [
     "all",
     "2025-01-23"
    ]
   },
   "outputs": [],
   "source": [
    "## Extracting on 2024-02-06 to display the LR/RL directions instead of the All/Long/Short pfs:\n",
    "def _display_directional_merged_pfs(owning_pipeline_reference, global_computation_results, computation_results, active_configs, include_includelist=None, save_figure=True, included_any_context_neuron_ids=None,\n",
    "                                    plot_all_directions=True, plot_long_directional=False, plot_short_directional=False, **kwargs):\n",
    "    \"\"\" Plots the merged pseduo-2D pfs/ratemaps. Plots: All-Directions, Long-Directional, Short-Directional in seperate windows. \n",
    "    \n",
    "    History: this is the Post 2022-10-22 display_all_pf_2D_pyqtgraph_binned_image_rendering-based method:\n",
    "    \"\"\"\n",
    "    from pyphoplacecellanalysis.Pho2D.PyQtPlots.plot_placefields import pyqtplot_plot_image_array, display_all_pf_2D_pyqtgraph_binned_image_rendering\n",
    "    from pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow \n",
    "    from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import LayoutScrollability\n",
    "\n",
    "    defer_render = kwargs.pop('defer_render', False)\n",
    "    directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "    active_merged_pf_plots_data_dict = {} #empty dict\n",
    "    \n",
    "    if plot_all_directions:\n",
    "        active_merged_pf_plots_data_dict[owning_pipeline_reference.build_display_context_for_session(track_config='All-Directions', display_fn_name='display_all_pf_2D_pyqtgraph_binned_image_rendering')] = directional_merged_decoders_result.all_directional_pf1D_Decoder.pf # all-directions\n",
    "    if plot_long_directional:\n",
    "        active_merged_pf_plots_data_dict[owning_pipeline_reference.build_display_context_for_session(track_config='Long-Directional', display_fn_name='display_all_pf_2D_pyqtgraph_binned_image_rendering')] = directional_merged_decoders_result.long_directional_pf1D_Decoder.pf # Long-only\n",
    "    if plot_short_directional:\n",
    "        active_merged_pf_plots_data_dict[owning_pipeline_reference.build_display_context_for_session(track_config='Short-Directional', display_fn_name='display_all_pf_2D_pyqtgraph_binned_image_rendering')] = directional_merged_decoders_result.short_directional_pf1D_Decoder.pf # Short-only\n",
    "\n",
    "    out_plots_dict = {}\n",
    "    \n",
    "    for active_context, active_pf_2D in active_merged_pf_plots_data_dict.items():\n",
    "        # figure_format_config = {} # empty dict for config\n",
    "        neuron_values = deepcopy(active_pf_2D.peak_tuning_curve_center_of_mass_bin_coordinates)\n",
    "        sort_indices = np.lexsort((neuron_values[:, 1], neuron_values[:, 0]))\n",
    "        figure_format_config = {'scrollability_mode': LayoutScrollability.NON_SCROLLABLE, 'included_unit_indicies': sort_indices} # kwargs # kwargs as default figure_format_config\n",
    "        out_all_pf_2D_pyqtgraph_binned_image_fig: BasicBinnedImageRenderingWindow  = display_all_pf_2D_pyqtgraph_binned_image_rendering(active_pf_2D, figure_format_config) # output is BasicBinnedImageRenderingWindow\n",
    "    \n",
    "        # Set the window title from the context\n",
    "        out_all_pf_2D_pyqtgraph_binned_image_fig.setWindowTitle(f'{active_context.get_description()}')\n",
    "        out_plots_dict[active_context] = out_all_pf_2D_pyqtgraph_binned_image_fig\n",
    "\n",
    "        # Tries to update the display of the item:\n",
    "        names_list = [v for v in list(out_all_pf_2D_pyqtgraph_binned_image_fig.plots.keys()) if v not in ('name', 'context')]\n",
    "        for a_name in names_list:\n",
    "            # Adjust the size of the text for the item by passing formatted text\n",
    "            a_plot: pg.PlotItem = out_all_pf_2D_pyqtgraph_binned_image_fig.plots[a_name].mainPlotItem # PlotItem \n",
    "            # no clue why 2 is a good value for this...\n",
    "            a_plot.titleLabel.setMaximumHeight(2)\n",
    "            a_plot.layout.setRowFixedHeight(0, 2)\n",
    "            a_plot.layout.setRowFixedHeight(1, 10)\n",
    "            plot_viewbox = a_plot.getViewBox()\n",
    "            # plot_viewbox.setMinimumHeight(200)  # Set a reasonable minimum height\n",
    "            plot_viewbox.setMaximumHeight(15)  # Set a fixed height to prevent stretching\n",
    "            plot_viewbox.setBorder(None)  # Remove the border\n",
    "            plot_viewbox.setBackgroundColor(None)\n",
    "                        \n",
    "            # # Add a spacer at the bottom\n",
    "            # spacer = pg.QtWidgets.QGraphicsWidget()\n",
    "            # spacer.setSizePolicy(pg.QtWidgets.QSizePolicy.Expanding, pg.QtWidgets.QSizePolicy.Expanding)  # Flexible spacer\n",
    "            # # Add the spacer to the layout\n",
    "            # row_count = a_plot.layout.rowCount()  # Get current row count\n",
    "            # a_plot.layout.addItem(spacer, row_count, 0, 1, a_plot.layout.columnCount())  # Add spacer to the last row\n",
    "            \n",
    "\n",
    "        if not defer_render:\n",
    "            out_all_pf_2D_pyqtgraph_binned_image_fig.show()\n",
    "\n",
    "    return out_plots_dict\n",
    "\n",
    "\n",
    "out_plots_dict = _display_directional_merged_pfs(curr_active_pipeline, curr_active_pipeline.global_computation_results, computation_results=None, active_configs=None, include_includelist=None, save_figure=True, included_any_context_neuron_ids=None,\n",
    "                                    plot_all_directions=True, plot_long_directional=False, plot_short_directional=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15824da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_all_pf_2D_pyqtgraph_binned_image_fig: BasicBinnedImageRenderingWindow = list(out_plots_dict.values())[0]\n",
    "# Tries to update the display of the item:\n",
    "names_list = [v for v in list(out_all_pf_2D_pyqtgraph_binned_image_fig.plots.keys()) if v not in ('name', 'context')]\n",
    "for a_name in names_list:\n",
    "    # Adjust the size of the text for the item by passing formatted text\n",
    "    a_plot: pg.PlotItem = out_all_pf_2D_pyqtgraph_binned_image_fig.plots[a_name].mainPlotItem # PlotItem \n",
    "    # no clue why 2 is a good value for this...\n",
    "    a_plot.titleLabel.setMaximumHeight(2)\n",
    "    a_plot.layout.setRowFixedHeight(0, 2)\n",
    "    a_plot.getViewBox().setBorder(None)  # Remove the border\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c38fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_plot.layoutDirection()\n",
    "a_plot.layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f36e973",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyphocorehelpers.gui.Qt.color_helpers import ColormapHelpers\n",
    "        \n",
    "ColormapHelpers.mpl_to_pg_colormap(color_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf715bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_pf2D = directional_merged_decoders_result.all_directional_pf1D_Decoder.pf # all-directions\n",
    "active_pf2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054feb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.shape()\n",
    "\n",
    "neuron_values = deepcopy(active_pf2D.peak_tuning_curve_center_of_mass_bin_coordinates)\n",
    "\n",
    "sort_indices = np.lexsort((neuron_values[:, 1], neuron_values[:, 0]))\n",
    "sort_indices\n",
    "\n",
    "neuron_values[sort_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfeb03c",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "# _out = curr_active_pipeline.display('_display_directional_merged_pfs', plot_all_directions=True, plot_long_directional=False, plot_short_directional=False)\n",
    "_out = curr_active_pipeline.display('_display_directional_merged_pf_decoded_epochs') # scrollable_figure=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb499f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_merged_pf_decoded_epochs_marginals') # scrollable_figure=True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cce23e",
   "metadata": {},
   "source": [
    "# <a id='toc21_'></a>[✅ `batch_user_completion_helpers` Batch Computation Testing](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ecbe84",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_2_'></a>[Call `export_rank_order_results_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22800b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import export_rank_order_results_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "# additional_session_context = None\n",
    "# try:\n",
    "#     if custom_suffix is not None:\n",
    "#         additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "#         print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "# except NameError as err:\n",
    "#     additional_session_context = None\n",
    "#     print(f'NO CUSTOM SUFFIX.')    \n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | export_rank_order_results_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                # # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None)\n",
    "                                                should_save_pkl=True, should_save_CSV=True,\n",
    "                                                )\n",
    "\n",
    "\n",
    "callback_outputs = _across_session_results_extended_dict['export_rank_order_results_completion_function']\n",
    "merged_complete_ripple_epoch_stats_df_output_path = callback_outputs['merged_complete_ripple_epoch_stats_df_output_path']\n",
    "minimum_inclusion_fr_Hz = callback_outputs['minimum_inclusion_fr_Hz']\n",
    "included_qclu_values = callback_outputs['included_qclu_values']\n",
    "print(f'merged_complete_ripple_epoch_stats_df_output_path: {merged_complete_ripple_epoch_stats_df_output_path}') # \"2024-11-15_Lab-2006-6-09_1-22-43_merged_complete_epoch_stats_df.csv\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251738a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "34757ebd",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_3_'></a>[Call `compute_and_export_session_wcorr_shuffles_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf5cc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_session_wcorr_shuffles_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "# additional_session_context = None\n",
    "# try:\n",
    "#     if custom_suffix is not None:\n",
    "#         additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "#         print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "# except NameError as err:\n",
    "#     additional_session_context = None\n",
    "#     print(f'NO CUSTOM SUFFIX.')    \n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_session_wcorr_shuffles_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                # # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None)\n",
    "                                                )\n",
    "\n",
    "\n",
    "callback_outputs = _across_session_results_extended_dict['compute_and_export_session_wcorr_shuffles_completion_function']\n",
    "wcorr_shuffles_data_output_filepath = callback_outputs['wcorr_shuffles_data_output_filepath']\n",
    "standalone_MAT_filepath = callback_outputs['standalone_MAT_filepath']\n",
    "ripple_WCorrShuffle_df_export_CSV_path = callback_outputs['ripple_WCorrShuffle_df_export_CSV_path']\n",
    "print(f'wcorr_shuffles_data_output_filepath: {wcorr_shuffles_data_output_filepath}') # \"2024-11-15_Lab-2006-6-09_1-22-43_merged_complete_epoch_stats_df.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5693589d",
   "metadata": {},
   "source": [
    "### Call `compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fd5080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _subfn_compute_complete_df_metrics\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "try:\n",
    "    if _across_session_results_extended_dict is not None:\n",
    "        pass\n",
    "    else:\n",
    "        _across_session_results_extended_dict = {}\n",
    "except NameError as err:\n",
    "    _across_session_results_extended_dict = {}\n",
    "    \n",
    "additional_session_context = None\n",
    "try:\n",
    "    if custom_suffix is not None:\n",
    "        additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "        print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "except NameError as err:\n",
    "    additional_session_context = None\n",
    "    print(f'NO CUSTOM SUFFIX.')    \n",
    "\n",
    "# ripple_decoding_time_bin_size_override = 0.058\n",
    "ripple_decoding_time_bin_size_override = 0.025\n",
    "laps_decoding_time_bin_size_override = 0.025\n",
    "# ripple_decoding_time_bin_size_override = 0.050\n",
    "# laps_decoding_time_bin_size_override = 0.050\n",
    "\n",
    "needs_recompute_heuristics = True\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                ripple_decoding_time_bin_size_override=ripple_decoding_time_bin_size_override,\n",
    "                                                laps_decoding_time_bin_size_override=laps_decoding_time_bin_size_override,\n",
    "                                                needs_recompute_heuristics=needs_recompute_heuristics, allow_append_to_session_h5_file=False, save_hdf=True, force_recompute_all_decoding=True, \n",
    "                                                )\n",
    "\n",
    "callback_outputs = _across_session_results_extended_dict['compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function']\n",
    "ripple_decoding_time_bin_size_override = callback_outputs['ripple_decoding_time_bin_size_override']\n",
    "print(f'ripple_decoding_time_bin_size_override: {ripple_decoding_time_bin_size_override}')\n",
    "output_csv_paths = callback_outputs['output_csv_paths']\n",
    "print(f'output_csv_paths: {output_csv_paths}')\n",
    "output_hdf_paths = callback_outputs['output_hdf_paths']\n",
    "print(f'output_hdf_paths: {output_hdf_paths}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c82f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benedict import benedict\n",
    "\n",
    "_across_session_results_extended_dict = benedict(_across_session_results_extended_dict)\n",
    "out_ripple_all_scores_merged_df_csv = Path(_across_session_results_extended_dict['compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function.output_csv_paths.ripple_all_scores_merged_df']).resolve()\n",
    "Assert.path_exists(out_ripple_all_scores_merged_df_csv)\n",
    "\n",
    "out_ripple_all_scores_merged_df_csv.parent\n",
    "'C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2025-03-08_Apogee-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 8, 9]-frateThresh_5.0-(ripple_all_scores_merged_df)_tbin-0.025.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286f1cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_across_session_results_extended_dict['compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8daa277",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_ripple_all_scores_merged_hdf5_files = [Path(v).resolve() for v in _across_session_results_extended_dict['compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function.output_hdf_paths']]\n",
    "Assert.path_exists(out_ripple_all_scores_merged_hdf5_files[0])\n",
    "print(f'out_ripple_all_scores_merged_hdf5_files[0]: \"{out_ripple_all_scores_merged_hdf5_files[0].as_posix()}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101d7d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_path = '/home/halechr/FastData/collected_outputs/2024-11-22_Lab-kdiba_gor01_one_2006-6-12_15-55-31__withNormalComputedReplays-qclu_[1, 2]-frateThresh_5.0-(ripple_all_scores_merged_df)_tbin-0.025.csv'\n",
    "csv_path = '/home/halechr/FastData/collected_outputs/2024-11-22_Lab-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0-(ripple_all_scores_merged_df)_tbin-0.016.csv'\n",
    "test_df = pd.read_csv(csv_path)\n",
    "test_df\n",
    "\n",
    "\n",
    "test_df[np.logical_not(test_df['short_best_jump'].isnull())]['short_best_jump']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121efeb3",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_5_'></a>[Call `perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5732d32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _subfn_compute_complete_df_metrics\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "return_full_decoding_results: bool = True\n",
    "save_hdf: bool = True\n",
    "save_csvs:bool = True\n",
    "# _across_session_results_extended_dict = {}\n",
    "\n",
    "try:\n",
    "    if _across_session_results_extended_dict is not None:\n",
    "        pass\n",
    "    else:\n",
    "        _across_session_results_extended_dict = {}\n",
    "except NameError as err:\n",
    "    _across_session_results_extended_dict = {}\n",
    "    \n",
    "additional_session_context = None\n",
    "try:\n",
    "    if custom_suffix is not None:\n",
    "        additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "        print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "except NameError as err:\n",
    "    additional_session_context = None\n",
    "    print(f'NO CUSTOM SUFFIX.')\n",
    "\n",
    "# %pdb on\n",
    "## Combine the output of `perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function` into two dataframes for the laps, one per-epoch and one per-time-bin\n",
    "# desired_shared_decoding_time_bin_sizes = np.linspace(start=0.030, stop=0.5, num=10)\n",
    "# desired_shared_decoding_time_bin_sizes = np.linspace(start=0.005, stop=0.03, num=10)\n",
    "# _across_session_results_extended_dict = _across_session_results_extended_dict | perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function(a_dummy, None,\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\tcurr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\tacross_session_results_extended_dict=_across_session_results_extended_dict, save_hdf=save_hdf, return_full_decoding_results=return_full_decoding_results,\n",
    "#                                                 desired_shared_decoding_time_bin_sizes=desired_shared_decoding_time_bin_sizes,\n",
    "#                                                 )\n",
    "\n",
    "# desired_laps_decoding_time_bin_size = [None] # doesn't work\n",
    "# desired_laps_decoding_time_bin_size = [1.5] # large so it doesn't take long\n",
    "# desired_ripple_decoding_time_bin_size = [0.010, 0.020]\n",
    "# desired_ripple_decoding_time_bin_size = [0.010, 0.020, 0.025]\n",
    "\n",
    "# desired_shared_decoding_time_bin_sizes = np.array([0.025, 0.030, 0.044, 0.050, 0.058, 0.072, 0.086, 0.100])\n",
    "# desired_shared_decoding_time_bin_sizes = np.array([0.025, 0.030, 0.044, 0.050, 0.058,])\n",
    "# desired_shared_decoding_time_bin_sizes = np.array([0.010, 0.025, 0.058,])\n",
    "desired_shared_decoding_time_bin_sizes = np.array([0.025, 0.050,])\n",
    "# desired_shared_decoding_time_bin_sizes = np.array([0.058,])\n",
    "# custom_all_param_sweep_options, param_sweep_option_n_values = parameter_sweeps(desired_laps_decoding_time_bin_size=desired_laps_decoding_time_bin_size,\n",
    "#                                                                                 desired_ripple_decoding_time_bin_size=desired_ripple_decoding_time_bin_size,\n",
    "#                                                                         use_single_time_bin_per_epoch=[False],\n",
    "#                                                                         minimum_event_duration=[desired_ripple_decoding_time_bin_size[-1]])\n",
    "\n",
    "# Shared time bin sizes\n",
    "custom_all_param_sweep_options, param_sweep_option_n_values = parameter_sweeps(desired_shared_decoding_time_bin_size=desired_shared_decoding_time_bin_sizes, use_single_time_bin_per_epoch=[False], minimum_event_duration=[desired_shared_decoding_time_bin_sizes[-1]]) # with Ripples\n",
    "\n",
    "\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict, save_hdf=save_hdf, save_csvs=save_csvs, return_full_decoding_results=return_full_decoding_results,\n",
    "                                                # desired_shared_decoding_time_bin_sizes = np.linspace(start=0.030, stop=0.5, num=4),\n",
    "                                                custom_all_param_sweep_options=custom_all_param_sweep_options, # directly provide the parameter sweeps\n",
    "                                                # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None)\n",
    "                                                additional_session_context = None,\n",
    "                                                )\n",
    "\n",
    "\n",
    "if return_full_decoding_results:\n",
    "    # with `return_full_decoding_results == True`\n",
    "    out_path, output_laps_decoding_accuracy_results_df, output_extracted_result_tuples, combined_multi_timebin_outputs_tuple, output_full_directional_merged_decoders_result, output_directional_decoders_epochs_decode_results_dict, output_saved_individual_sweep_files_dict = _across_session_results_extended_dict['perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function']\n",
    "    # validate the result:\n",
    "    {k:v.all_directional_laps_filter_epochs_decoder_result.decoding_time_bin_size for k,v in output_full_directional_merged_decoders_result.items()}\n",
    "    # assert np.all([np.isclose(dict(k)['desired_shared_decoding_time_bin_size'], v.all_directional_laps_filter_epochs_decoder_result.decoding_time_bin_size) for k,v in output_full_directional_merged_decoders_result.items()]), f\"the desired time_bin_size in the parameters should match the one used that will appear in the decoded result\"\n",
    "\n",
    "else:\n",
    "    # with `return_full_decoding_results == False`\n",
    "    out_path, output_laps_decoding_accuracy_results_df, output_extracted_result_tuples, combined_multi_timebin_outputs_tuple, output_saved_individual_sweep_files_dict = _across_session_results_extended_dict['perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function']\n",
    "    output_full_directional_merged_decoders_result = None\n",
    "\n",
    "\n",
    "(several_time_bin_sizes_laps_df, laps_out_path, several_time_bin_sizes_time_bin_laps_df, laps_time_bin_marginals_out_path), (several_time_bin_sizes_ripple_df, ripple_out_path, several_time_bin_sizes_time_bin_ripple_df, ripple_time_bin_marginals_out_path) = combined_multi_timebin_outputs_tuple\n",
    "\n",
    "#  exported files: {'laps_out_path': WindowsPath('K:/scratch/collected_outputs/2024-09-27-kdiba_gor01_two_2006-6-07_16-40-19_None-(laps_marginals_df).csv'), 'laps_time_bin_marginals_out_path': WindowsPath('K:/scratch/collected_outputs/2024-09-27-kdiba_gor01_two_2006-6-07_16-40-19_None-(laps_time_bin_marginals_df).csv'), 'ripple_out_path': WindowsPath('K:/scratch/collected_outputs/2024-09-27-kdiba_gor01_two_2006-6-07_16-40-19_None-(ripple_marginals_df).csv'), 'ripple_time_bin_marginals_out_path': WindowsPath('K:/scratch/collected_outputs/2024-09-27-kdiba_gor01_two_2006-6-07_16-40-19_None-(ripple_time_bin_marginals_df).csv')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fc9d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.get_all_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc64a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_saved_individual_sweep_files_dict\n",
    "# combined_multi_timebin_outputs_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcd8258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import DisplaySpecifyingIdentifyingContext, CollisionOutcome\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Computation import PipelineWithComputedPipelineStageMixin\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Computation import session_context_filename_formatting_fn\n",
    "from pyphocorehelpers.print_helpers import get_now_day_str, get_now_rounded_time_str\n",
    "\n",
    "curr_active_pipeline.session_name\n",
    "# complete_session_context, (curr_session_context,  additional_session_context) = curr_active_pipeline.get_complete_session_context(parts_separator='_')\n",
    "\n",
    "# complete_session_context.get_description(separator='|') # 'kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays_qclu_[1, 2, 4, 6, 7, 9]_frateThresh_5.0'\n",
    "# complete_session_context.get_specific_purpose_description(specific_purpose='filename_formatting') # 'kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays_qclu_[1, 2, 4, 6, 7, 9]_frateThresh_5.0'\n",
    "# curr_active_pipeline.get_complete_session_identifier_string(parts_separator='_', sub_parts_separator='|') # 'kdiba-gor01-one-2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0'\n",
    "curr_active_pipeline.get_complete_session_identifier_string(parts_separator='_', custom_parameter_keyvalue_parts_separator='-', session_identity_parts_separator='_')\n",
    "\n",
    "# \"kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_1.0\"\n",
    "\n",
    "out_path, out_filename, out_basename = curr_active_pipeline.build_complete_session_identifier_filename_string(output_date_str=None, data_identifier_str=\"(ripple_WCorrShuffle_df)\", parent_output_path=None, out_extension='.csv', extra_parts=None, ensure_no_duplicate_parts=False)\n",
    "out_filename # '2024-11-19_0148AM-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0-(ripple_WCorrShuffle_df).csv'\n",
    "# out_path, out_filename, out_basename = curr_active_pipeline.build_complete_session_identifier_filename_string(output_date_str=get_now_rounded_time_str(), data_identifier_str=\"(ripple_WCorrShuffle_df)\", parent_output_path=None, out_extension='.csv', extra_parts=None, ensure_no_duplicate_parts=False)\n",
    "# out_path, out_filename, out_basename = curr_active_pipeline.build_complete_session_identifier_filename_string(data_identifier_str=\"(ripple_WCorrShuffle_df)\", parent_output_path=None, out_extension='.csv', extra_parts=None, ensure_no_duplicate_parts=True)\n",
    "out_path, out_filename, out_basename = curr_active_pipeline.build_complete_session_identifier_filename_string(data_identifier_str=\"(ripple_WCorrShuffle_df)\", parent_output_path=None, out_extension='.csv', suffix_string='_tbin-0.025')\n",
    "out_filename  # '2024-11-19_0148AM-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0-(ripple_WCorrShuffle_df)_tbin-0.025.csv'\n",
    "\n",
    "# \"2024-11-18_1020PM-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_1.0-(ripple_WCorrShuffle_df)_tbin-0.025.csv\"\n",
    "# \"2024-11-19_0125AM-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0-(ripple_WCorrShuffle_df).csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8b1579",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_session_context.get_raw_identifying_context()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a21cabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_session_context\n",
    "\n",
    "# ['format_name', 'animal', 'exper_name', 'session_name']\n",
    "curr_session_context.get_description()\n",
    "curr_session_context.get_specific_purpose_description(specific_purpose='filename_formatting')\n",
    "\n",
    "curr_session_context.to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82ac92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_test_complete_session_context: DisplaySpecifyingIdentifyingContext = DisplaySpecifyingIdentifyingContext.init_from_context(a_context=curr_active_pipeline.get_session_context(), \n",
    "        specific_purpose_display_dict={'filename_formatting': session_context_filename_formatting_fn,},\n",
    "        #  display_dict={'epochs_source': lambda k, v: to_filename_conversion_dict[v],\n",
    "        #         'included_qclu_values': lambda k, v: f\"qclu_{v}\",\n",
    "        #         'minimum_inclusion_fr_Hz': lambda k, v: f\"frateThresh_{v:.1f}\",\n",
    "        # },\n",
    "    )\n",
    "_test_complete_session_context\n",
    "_test_complete_session_context.get_description()\n",
    "_test_complete_session_context.get_specific_purpose_description(specific_purpose='filename_formatting')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ef185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "additional_session_context.get_description()\n",
    "additional_session_context.get_specific_purpose_description(specific_purpose='filename_formatting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c4da3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _test_complete_session_context: DisplaySpecifyingIdentifyingContext = curr_session_context.adding_context(collision_prefix='_additional', strategy=CollisionOutcome.FAIL_IF_DIFFERENT, **additional_session_context.to_dict())\n",
    "_test_complete_session_context: DisplaySpecifyingIdentifyingContext = curr_session_context.adding_context(collision_prefix='_additional', strategy=CollisionOutcome.FAIL_IF_DIFFERENT, **additional_session_context.get_raw_identifying_context().to_dict())\n",
    "\n",
    "\n",
    "_test_complete_session_context\n",
    "_test_complete_session_context.get_description()\n",
    "_test_complete_session_context.get_specific_purpose_description(specific_purpose='filename_formatting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5026a5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.get_complete_session_identifier_string(parts_separator='_')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14a1e08",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_6_'></a>[Call `compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb60e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import DisplaySpecifyingIdentifyingContext, IdentifyingContext\n",
    "# from pyphoplacecellanalysis.General.Pipeline.Stages.Computation import PipelineWithComputedPipelineStageMixin\n",
    "\n",
    "complete_session_context, (session_context, additional_session_context) = curr_active_pipeline.get_complete_session_context()\n",
    "session_context\n",
    "additional_session_context\n",
    "complete_session_context\n",
    "\n",
    "\n",
    "session_context.get_description()\n",
    "additional_session_context.get_description()\n",
    "complete_session_context.get_description()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0d9a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_session_context.get_specific_purpose_description(specific_purpose='filename_formatting') # additional_session_context.get_specific_purpose_description(specific_purpose='filename_formatting')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76164cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_session_context.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e58214",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_session_context.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c303453",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_session_context.get_specific_purpose_description(specific_purpose='filename_formatting') # '-_withNormalComputedReplays-frateThresh_5.0-qclu_[1, 2, 4, 6, 7, 9]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9185d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_session_context.get_description() # 'kdiba_gor01_two_2006-6-12_16-53-46__withNormalComputedReplays_qclu_[1, 2, 4, 6, 7, 9]_frateThresh_5.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a789e08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_context = complete_session_context\n",
    "active_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc10c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "active_context.get_description()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497465d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "# return_full_decoding_results: bool = True\n",
    "# save_hdf: bool = True\n",
    "# save_csvs:bool = True\n",
    "\n",
    "try:\n",
    "    _across_session_results_extended_dict\n",
    "except NameError as e:\n",
    "    _across_session_results_extended_dict = {} # initialize\n",
    "\n",
    "additional_session_context = None\n",
    "try:\n",
    "    if custom_suffix is not None:\n",
    "        additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "        print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "except NameError as err:\n",
    "    additional_session_context = None\n",
    "    print(f'NO CUSTOM SUFFIX.')    \n",
    "    \n",
    "rank_order_results = curr_active_pipeline.global_computation_results.computed_data.get('RankOrder', None)\n",
    "if rank_order_results is not None:\n",
    "    minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "else:        \n",
    "    ## get from parameters:\n",
    "    minimum_inclusion_fr_Hz: float = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.included_qclu_values\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict, included_qclu_values=included_qclu_values, minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, drop_previous_result_and_compute_fresh=True, num_wcorr_shuffles=1024,\n",
    "                                                # # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None)\n",
    "                                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb49fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function' in _across_session_results_extended_dict\n",
    "compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_output = deepcopy(_across_session_results_extended_dict['compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function'])\n",
    "# compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_output\n",
    "callback_outputs = deepcopy(_across_session_results_extended_dict['compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function'])\n",
    "\n",
    "custom_suffix = callback_outputs['custom_suffix']\n",
    "replay_epoch_variations = callback_outputs['replay_epoch_variations']\n",
    "replay_epoch_outputs = callback_outputs['replay_epoch_outputs']\n",
    "\n",
    "replay_epoch_name = 'normal_computed'\n",
    "a_replay_epoch_variation: Epoch = replay_epoch_variations[replay_epoch_name]\n",
    "a_replay_epoch_outputs = replay_epoch_outputs[replay_epoch_name]\n",
    "\n",
    "## Unpack `a_replay_epoch_outputs`\n",
    "exported_evt_file_path = a_replay_epoch_outputs['exported_evt_file_path']\n",
    "did_change = a_replay_epoch_outputs['did_change']\n",
    "custom_save_filenames = a_replay_epoch_outputs['custom_save_filenames']\n",
    "custom_save_filepaths = a_replay_epoch_outputs['custom_save_filepaths']\n",
    "custom_suffix = a_replay_epoch_outputs['custom_suffix']\n",
    "wcorr_ripple_shuffle_all_df = a_replay_epoch_outputs['wcorr_ripple_shuffle_all_df']\n",
    "all_shuffles_only_best_decoder_wcorr_df = a_replay_epoch_outputs['all_shuffles_only_best_decoder_wcorr_df']\n",
    "standalone_pkl_filepath = a_replay_epoch_outputs['standalone_pkl_filepath']\n",
    "standalone_mat_filepath = a_replay_epoch_outputs['standalone_mat_filepath']\n",
    "active_context = a_replay_epoch_outputs['active_context']\n",
    "export_files_dict = a_replay_epoch_outputs['export_files_dict']\n",
    "# params_description_str = a_replay_epoch_outputs['params_description_str']\n",
    "# footer_annotation_text = a_replay_epoch_outputs['footer_annotation_text']\n",
    "# out_hist_fig_result = a_replay_epoch_outputs['out_hist_fig_result']\n",
    "\n",
    "\n",
    "custom_save_filenames\n",
    "custom_save_filepaths\n",
    "export_files_dict\n",
    "# print_keys_if_possible('callback_outputs', compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_output, max_depth=3)\n",
    "# a_replay_epoch_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d41b45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_strs = []\n",
    "for k, v in a_replay_epoch_outputs.items():\n",
    "    code_strs.append(f\"{k} = a_replay_epoch_outputs['{k}']\")\n",
    "\n",
    "print('\\n'.join(code_strs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6d6e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_output['export_files_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8beeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_epoch_outputs = deepcopy(compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_output['replay_epoch_outputs'])\n",
    "# replay_epoch_outputs\n",
    "\n",
    "normal_computed_replay_epoch_outputs = replay_epoch_outputs['normal_computed']\n",
    "normal_computed_replay_epoch_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a3bfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(replay_epoch_outputs.keys())\n",
    "\n",
    "export_files_dict = normal_computed_replay_epoch_outputs['export_files_dict']\n",
    "export_files_dict\n",
    "\n",
    "export_file_path_ripple_WCorrShuffle_df = export_files_dict['ripple_WCorrShuffle_df'] # 'W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-11-18_1020PM-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_1.0-(ripple_WCorrShuffle_df)_tbin-0.025.csv'\n",
    "export_file_path_ripple_WCorrShuffle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a46edd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_save_filepaths = normal_computed_replay_epoch_outputs['custom_save_filepaths'] ## these seem to be misnamed AND redundant\n",
    "custom_save_filepaths\n",
    "\n",
    "ripple_csv_out_path = custom_save_filepaths['ripple_csv_out_path'] # 'K:/scratch/collected_outputs/2024-11-18-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_1.0_withNormalComputedReplays-frateThresh_1.0-qclu_[1, 2, 4, 6, 7, 9]-(ripple_marginals_df).csv'\n",
    "ripple_csv_out_path\n",
    "\n",
    "ripple_csv_time_bin_marginals = custom_save_filepaths['ripple_csv_time_bin_marginals'] # 'K:/scratch/collected_outputs/2024-11-18-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_1.0_withNormalComputedReplays-frateThresh_1.0-qclu_[1, 2, 4, 6, 7, 9]-(ripple_time_bin_marginals_df).csv'\n",
    "ripple_csv_time_bin_marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3ec874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa0cd606",
   "metadata": {},
   "source": [
    "### Call `compute_and_export_session_instantaneous_spike_rates_completion_function`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95af845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_session_instantaneous_spike_rates_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "return_full_decoding_results: bool = True\n",
    "save_hdf: bool = True\n",
    "save_pickle:bool = True\n",
    "# save_FAT_csv:bool = True\n",
    "# save_hdf: bool = False\n",
    "# save_pickle:bool = False\n",
    "save_FAT_csv:bool = False\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "# instantaneous_time_bin_size_seconds_list:List[float] = [0.001, 0.010, 0.020, 0.050, 200.00, 1000.0] # \n",
    "\n",
    "instantaneous_time_bin_size_seconds_list:List[float] = [0.001, 1000.0] # \n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_session_instantaneous_spike_rates_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict, instantaneous_time_bin_size_seconds_list=instantaneous_time_bin_size_seconds_list,\n",
    "                                                # # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None)\n",
    "\t\t\t\t\t\t\t\t\t\t\t\tsave_hdf=save_hdf, save_pickle=save_pickle, save_FAT_csv=save_FAT_csv,\n",
    "                                                )\n",
    "\n",
    "# 4.5 mins for [0.001, 0.010, 0.020, 0.050, 200.00, 1000.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85514518",
   "metadata": {},
   "outputs": [],
   "source": [
    "_across_session_results_extended_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df6d7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_fr_comps: InstantaneousSpikeRateGroupsComputation = _across_session_results_extended_dict['compute_and_export_session_instantaneous_spike_rates_completion_function']['recomputed_inst_fr_time_bin_dict'][1000.0]['inst_fr_comps']\n",
    "inst_fr_comps.get_summary_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fdfae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inst_fr_comps.get_summary_dataframe()[inst_fr_comps.get_summary_dataframe()['aclu'] == 11]\n",
    "\n",
    "inst_fr_comps.get_summary_dataframe()[inst_fr_comps.get_summary_dataframe()['active_set_membership'] == 'LxC']\n",
    "inst_fr_comps.get_summary_dataframe()[inst_fr_comps.get_summary_dataframe()['active_set_membership'] == 'SxC']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0400fcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import get_proper_global_spikes_df\n",
    "\n",
    "spikes_df = get_proper_global_spikes_df(curr_active_pipeline)\n",
    "spikes_df.spikes.neuron_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31de77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_df = get_proper_global_spikes_df(curr_active_pipeline, minimum_inclusion_fr_Hz=0.0)\n",
    "spikes_df.spikes.neuron_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab77985",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_fr_comps_1ms: InstantaneousSpikeRateGroupsComputation = _across_session_results_extended_dict['compute_and_export_session_instantaneous_spike_rates_completion_function']['recomputed_inst_fr_time_bin_dict'][0.001]['inst_fr_comps']\n",
    "inst_fr_comps_1ms.get_summary_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d246ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_fr_comps_1ms.LxC_aclus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b16f586",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_fr_comps_1ms_summary_df: pd.DataFrame = inst_fr_comps_1ms.get_summary_dataframe()\n",
    "\n",
    "inst_fr_comps_1ms_summary_df[inst_fr_comps_1ms_summary_df['aclu'] == 3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f31f0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_fr_comps_1000s: InstantaneousSpikeRateGroupsComputation = _across_session_results_extended_dict['compute_and_export_session_instantaneous_spike_rates_completion_function']['recomputed_inst_fr_time_bin_dict'][1000.0]['inst_fr_comps']\n",
    "inst_fr_comps_1000s_summary_df: pd.DataFrame = inst_fr_comps_1000s.get_summary_dataframe()\n",
    "inst_fr_comps_1000s_summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1670a3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_fr_comps_1000s_summary_df[inst_fr_comps_1000s_summary_df['aclu'] == 29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12796f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_fr_comps_200s: InstantaneousSpikeRateGroupsComputation = _across_session_results_extended_dict['compute_and_export_session_instantaneous_spike_rates_completion_function']['recomputed_inst_fr_time_bin_dict'][0.020]['inst_fr_comps']\n",
    "inst_fr_comps_200s.get_summary_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3f496b",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_7_'></a>[Call `compute_and_export_session_trial_by_trial_performance_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be44b166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_session_trial_by_trial_performance_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "from pyphoplacecellanalysis.Analysis.reliability import TrialByTrialActivity\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrialByTrialActivityResult\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "return_full_decoding_results: bool = True\n",
    "save_hdf: bool = True\n",
    "save_csvs:bool = True\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "additional_session_context = None\n",
    "try:\n",
    "    if custom_suffix is not None:\n",
    "        additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "        print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "except NameError as err:\n",
    "    additional_session_context = None\n",
    "    print(f'NO CUSTOM SUFFIX.')    \n",
    "    \n",
    "# active_laps_decoding_time_bin_size: float = 0.025\n",
    "active_laps_decoding_time_bin_size: float = 0.050\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_session_trial_by_trial_performance_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict, active_laps_decoding_time_bin_size=active_laps_decoding_time_bin_size,\n",
    "                                                # # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None)\n",
    "                                                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81c7c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_spikes_df = get_proper_global_spikes_df(curr_active_pipeline)\n",
    "global_spikes_df.spikes.neuron_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d29faa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "any_decoder_neuron_IDs: NDArray = deepcopy(track_templates.any_decoder_neuron_IDs)\n",
    "any_decoder_neuron_IDs\n",
    "\n",
    "track_templates.decoder_neuron_IDs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e427751",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_outputs = _across_session_results_extended_dict['compute_and_export_session_trial_by_trial_performance_completion_function']\n",
    "a_trial_by_trial_result: TrialByTrialActivityResult = callback_outputs['a_trial_by_trial_result']\n",
    "stability_df: pd.DataFrame = deepcopy(callback_outputs['stability_df'])\n",
    "subset_neuron_IDs_dict = callback_outputs['subset_neuron_IDs_dict']\n",
    "subset_decode_results_dict = callback_outputs['subset_decode_results_dict']\n",
    "subset_decode_results_track_id_correct_performance_dict = callback_outputs['subset_decode_results_track_id_correct_performance_dict']\n",
    "directional_active_lap_pf_results_dicts: Dict[types.DecoderName, TrialByTrialActivity] = a_trial_by_trial_result.directional_active_lap_pf_results_dicts\n",
    "_out_subset_decode_results_track_id_correct_performance_dict = callback_outputs['subset_decode_results_track_id_correct_performance_dict']\n",
    "_out_subset_decode_results_dict = callback_outputs['subset_decode_results_dict']\n",
    "neuron_group_split_stability_dfs_tuple = callback_outputs['neuron_group_split_stability_dfs_tuple']\n",
    "neuron_group_split_stability_aclus_tuple = callback_outputs['neuron_group_split_stability_aclus_tuple']\n",
    "\n",
    "appearing_stability_df, disappearing_stability_df, appearing_or_disappearing_stability_df, stable_both_stability_df, stable_neither_stability_df, stable_long_stability_df, stable_short_stability_df = neuron_group_split_stability_dfs_tuple\n",
    "appearing_aclus, disappearing_aclus, appearing_or_disappearing_aclus, stable_both_aclus, stable_neither_aclus, stable_long_aclus, stable_short_aclus = neuron_group_split_stability_aclus_tuple\n",
    "# (complete_decoded_context_correctness_tuple, laps_marginals_df, all_directional_pf1D_Decoder, all_test_epochs_df, test_all_directional_decoder_result, all_directional_laps_filter_epochs_decoder_result, _out_separate_decoder_results)  = _out_subset_decode_results_dict['any_decoder'] ## get the result for all cells\n",
    "# filtered_laps_time_bin_marginals_df: pd.DataFrame = callback_outputs['subset_decode_results_time_bin_marginals_df_dict']['filtered_laps_time_bin_marginals_df']\n",
    "# active_results: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy({k:v.decoder_result for k, v in _out_separate_decoder_results[0].items()})\n",
    "# active_results: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy({k:v for k, v in _out_separate_decoder_results[1].items()})\n",
    "# filtered_laps_time_bin_marginals_df\n",
    "stability_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b802f7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.reliability import TrialByTrialActivity\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrialByTrialActivityResult\n",
    "\n",
    "# _out = a_trial_by_trial_result.plot_napari_trial_by_trial_correlation_matrix()\n",
    "_out = TrialByTrialActivity.plot_napari_trial_by_trial_correlation_matrix(directional_active_lap_pf_results_dicts=a_trial_by_trial_result.directional_active_lap_pf_results_dicts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0fabfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoder_name: str = 'long_RL'\n",
    "a_result: TrialByTrialActivity = a_trial_by_trial_result.directional_active_lap_pf_results_dicts[a_decoder_name]\n",
    "## Find the point where the trial-to-trial correlation (stability) exceeds a requirement for 3 successive laps (allowing for LR/RL only firing)\n",
    "C_trial_by_trial_correlation_matrix: NDArray[ND.Shape[\"N_ACLUS, N_EPOCHS, N_EPOCHS\"], Any] = a_result.C_trial_by_trial_correlation_matrix\n",
    "z_scored_tuning_map_matrix: NDArray[ND.Shape[\"N_TRIALS, N_ACLUS, N_XBINS\"], Any] = a_result.z_scored_tuning_map_matrix\n",
    "aclu_to_matrix_IDX_map = deepcopy(a_result.aclu_to_matrix_IDX_map)\n",
    "\n",
    "# C_trial_by_trial_correlation_matrix\n",
    "z_scored_tuning_map_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe8be12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0dc0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(C_trial_by_trial_correlation_matrix) # (103, 22, 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca09e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = 0.7\n",
    "aclu: int = 8\n",
    "\n",
    "given_aclu_C_trial_by_trial_correlation_matrix = np.squeeze(deepcopy(C_trial_by_trial_correlation_matrix[aclu, :, :]))\n",
    "np.shape(given_aclu_C_trial_by_trial_correlation_matrix)\n",
    "given_aclu_C_trial_by_trial_correlation_matrix\n",
    "arr = (given_aclu_C_trial_by_trial_correlation_matrix >= criteria)\n",
    "arr\n",
    "# idx = np.where(arr[:-1] & arr[1:])[0][0]  # first repeated True start index\n",
    "idx = np.where(np.any(arr[..., :-1] & arr[..., 1:], axis=0))[0]\n",
    "idx.shape ## (440,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df114533",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_context = curr_active_pipeline.get_session_context()\n",
    "stability_df = stability_df.neuron_identity.make_neuron_indexed_df_global(session_context, add_expanded_session_context_keys=True, add_extended_aclu_identity_columns=True)\n",
    "stability_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0413e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_trial_by_trial_result.stability_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55079e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_trial_by_trial_activity_result: TrialByTrialActivityResult = curr_active_pipeline.global_computation_results.computed_data.get('TrialByTrialActivity', None)\n",
    "directional_trial_by_trial_activity_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d617b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_trial_by_trial_activity_result.stability_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaffd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge Stability info into neurons CSV\n",
    "\n",
    "## INPUTS: stability_df\n",
    "\n",
    "## Prepare stability_df:\n",
    "# stability_df = stability_df.rename(columns={'stability_stability_class':'stability_class'}, inplace=False)\n",
    "stability_df = deepcopy(stability_df).add_prefix('stability_').rename(columns={'stability_stability_class':'stability_class', 'stability_aclu':'aclu'}, inplace=False) ## add the 'stability_' prefix to all columns, then fixed the doublely named one and the aclu column\n",
    "\n",
    "all_neuron_stats_table: pd.DataFrame = AcrossSessionsResults.build_neuron_identities_df_for_CSV(curr_active_pipeline=curr_active_pipeline)\n",
    "\n",
    "initial_num_rows: int = len(all_neuron_stats_table)\n",
    "\n",
    "all_neuron_stats_table: pd.DataFrame = deepcopy(all_neuron_stats_table)\n",
    "\n",
    "## OUTPUTS: stability_df\n",
    "## merge in `stability_df`'s unique columns on 'aclu'. Note that 'stability_df' has way more cells than 'all_neuron_stats_table' which I believe are confined to just the place cells\n",
    "all_neuron_stats_table = pd.merge(all_neuron_stats_table, stability_df[['aclu'] + [col for col in stability_df.columns if col not in all_neuron_stats_table.columns and col != 'aclu']], on='aclu')\n",
    "\n",
    "## check\n",
    "# assert len(all_neuron_stats_table) == initial_num_rows, f\"initial_num_rows: {initial_num_rows}, len(all_neuron_stats_table): {len(all_neuron_stats_table)}\"\n",
    "if len(all_neuron_stats_table) != initial_num_rows:\n",
    "    print(f\"WARNING: initial_num_rows: {initial_num_rows}, len(all_neuron_stats_table): {len(all_neuron_stats_table)}\")\n",
    "    \n",
    "## OUTPUTS: all_neuron_stats_table\n",
    "all_neuron_stats_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eae7ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "display('appearing cells')\n",
    "appearing_stability_df\n",
    "display('disappearing cells')\n",
    "disappearing_stability_df\n",
    "# stable_neither_stability_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f77f778",
   "metadata": {},
   "outputs": [],
   "source": [
    "display('stable_neither cells')\n",
    "stable_neither_stability_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc8296d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stable_both_stability_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0d1a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "stability_df: pd.DataFrame = a_trial_by_trial_result.get_stability_df()\n",
    "stability_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791e4988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7a1cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_trial_by_trial_result.any_decoder_neuron_IDs ## 55 is missing :[ ~~ 2025-07-31 10:40 YAY They're all there!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373ccd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pho_jupyter_preview_widget\n",
    "# from pyphocorehelpers.pho_jupyter_preview_widget.ipython_helpers import PreviewWidgetMagics\n",
    "from pyphocorehelpers.pho_jupyter_preview_widget.display_helpers import array_repr_with_graphical_preview\n",
    "\n",
    "# # # Register the magic\n",
    "# ip.register_magics(PreviewWidgetMagics)\n",
    "\n",
    "# %config_ndarray_preview width=500\n",
    "\n",
    "# # Register the custom display function for NumPy arrays\n",
    "# ip.display_formatter.formatters['text/html'].for_type(np.ndarray, lambda arr: array_preview_with_graphical_shape_repr_html(arr))\n",
    "# ip = array_repr_with_graphical_shape(ip=ip)\n",
    "# ip = array_repr_with_graphical_preview(ip=ip)\n",
    "# ip = dataframe_show_more_button(ip=ip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dcdbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_trial_by_trial_result.directional_lap_epochs_dict\n",
    "# a_dir_lap_result = a_trial_by_trial_result.directional_active_lap_pf_results_dicts['long_LR']\n",
    "\n",
    "# a_decoder_name = 'long_LR'\n",
    "# a_decoder_name = 'long_RL'\n",
    "# a_decoder_name = 'short_LR'\n",
    "a_decoder_name = 'short_RL'\n",
    "\n",
    "a_dir_lap_result = a_trial_by_trial_result.directional_active_lap_pf_results_dicts[a_decoder_name]\n",
    "C_trial_by_trial_correlation_matrix: NDArray[ND.Shape[\"N_ACLUS, N_EPOCHS, N_EPOCHS\"], Any] = a_dir_lap_result.C_trial_by_trial_correlation_matrix\n",
    "C_trial_by_trial_correlation_matrix\n",
    "z_scored_tuning_map_matrix: NDArray[ND.Shape[\"N_EPOCHS, N_ACLUS, N_POS_BINS\"], Any] = a_dir_lap_result.z_scored_tuning_map_matrix\n",
    "# z_scored_tuning_map_matrix\n",
    "\n",
    "an_aclu = 55\n",
    "# an_aclu = 69\n",
    "# a_dir_lap_result.aclu_to_matrix_IDX_map\n",
    "# a_dir_lap_result.aclu_to_matrix_IDX_map[an_aclu]\n",
    "\n",
    "a_cell_C_trial_by_trial_correlation_matrix: NDArray[ND.Shape[\"N_EPOCHS, N_EPOCHS\"], Any] = C_trial_by_trial_correlation_matrix[a_dir_lap_result.aclu_to_matrix_IDX_map[an_aclu], :, :]\n",
    "a_cell_z_scored_tuning_map_matrix: NDArray[ND.Shape[\"N_EPOCHS, N_POS_BINS\"], Any] = z_scored_tuning_map_matrix[:, a_dir_lap_result.aclu_to_matrix_IDX_map[an_aclu], :]\n",
    "\n",
    "\n",
    "render_scrollable_colored_table(a_cell_C_trial_by_trial_correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae3c5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "render_scrollable_colored_table(a_cell_z_scored_tuning_map_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a95b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aTbyT:TrialByTrialActivity = a_trial_by_trial_result.directional_active_lap_pf_results_dicts['long_LR']\n",
    "aTbyT.C_trial_by_trial_correlation_matrix.shape # (40, 21, 21)\n",
    "aTbyT.z_scored_tuning_map_matrix.shape # (21, 40, 57) (n_epochs, n_neurons, n_pos_bins)\n",
    "\n",
    "(directional_viewer, directional_image_layer_dict, custom_direction_split_layers_dict) = aTbyT.plot_napari_trial_by_trial_correlation_matrix(directional_active_lap_pf_results_dicts=a_trial_by_trial_result.directional_active_lap_pf_results_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15090732",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_trial_by_trial_correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3305a31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a_trial_by_trial_result.any_decoder_neuron_IDs)\n",
    "a_trial_by_trial_result.any_decoder_neuron_IDs[37] # 58\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bbad28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directional_viewer.Config()\n",
    "directional_viewer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276588e6",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_8_'></a>[Call `compute_and_export_cell_first_spikes_characteristics_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a69538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_cell_first_spikes_characteristics_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "try:\n",
    "    _across_session_results_extended_dict\n",
    "except NameError as e:\n",
    "    _across_session_results_extended_dict = {} # initialize\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_cell_first_spikes_characteristics_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                # # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None)\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855bd06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import figures_plot_cell_first_spikes_characteristics_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "try:\n",
    "    _across_session_results_extended_dict\n",
    "except NameError as e:\n",
    "    _across_session_results_extended_dict = {} # initialize\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | figures_plot_cell_first_spikes_characteristics_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                # # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None),\n",
    "                                                later_appearing_cell_lap_start_id=4,\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4624b606",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_9_'></a>[Call `kdiba_session_post_fixup_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef1b68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyphoplacecellanalysis.General.type_aliases as types\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import PostHocPipelineFixup, kdiba_session_post_fixup_completion_function, SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "# additional_session_context = None\n",
    "# try:\n",
    "#     if custom_suffix is not None:\n",
    "#         additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "#         print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "# except NameError as err:\n",
    "#     additional_session_context = None\n",
    "#     print(f'NO CUSTOM SUFFIX.')    \n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | kdiba_session_post_fixup_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                force_recompute=False, is_dry_run=False,\n",
    "                                                )\n",
    "\n",
    "\n",
    "# callback_outputs = _across_session_results_extended_dict['kdiba_session_post_fixup_completion_function'] # 'PostHocPipelineFixup'\n",
    "# loaded_track_limits = callback_outputs['loaded_track_limits']\n",
    "# a_config_dict = callback_outputs['a_config_dict']\n",
    "# print(f'loaded_track_limits: {loaded_track_limits}') \n",
    "    \n",
    "\n",
    "#  'computation_results[\"maze_any\"]': False, 'filtered_sessions[\"maze1_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze1_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze1_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze1_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze2_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze2_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze2_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze2_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze1_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_even\"].config.pix2cm': False, 'filtered_sessions[\"maze1_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.grid_bin': True, 'filtered_sessions[\"maze1_even\"].config.track_start_t': True, 'filtered_sessions[\"maze1_even\"].config.track_end_t': True, 'filtered_sessions[\"maze2_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_even\"].config.pix2cm': False, 'filtered_sessions[\"maze2_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.grid_bin': True, 'filtered_sessions[\"maze2_even\"].config.track_start_t': True, 'filtered_sessions[\"maze2_even\"].config.track_end_t': True, 'filtered_sessions[\"maze_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze_even\"].config.pix2cm': False, 'filtered_sessions[\"maze_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.grid_bin': True, 'filtered_sessions[\"maze_even\"].config.track_start_t': True, 'filtered_sessions[\"maze_even\"].config.track_end_t': True, 'filtered_sessions[\"maze1_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_any\"].config.pix2cm': False, 'filtered_sessions[\"maze1_any\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.grid_bin': True, 'filtered_sessions[\"maze1_any\"].config.track_start_t': True, 'filtered_sessions[\"maze1_any\"].config.track_end_t': True, 'filtered_sessions[\"maze2_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_any\"].config.pix2cm': False, 'filtered_sessions[\"maze2_any\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.grid_bin': True, 'filtered_sessions[\"maze2_any\"].config.track_start_t': True, 'filtered_sessions[\"maze2_any\"].config.track_end_t': True, 'filtered_sessions[\"maze_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze_any\"].config.pix2cm': False, 'filtered_sessions[\"maze_any\"].config.real_unit_grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.real_cm_grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.grid_bin': True, 'filtered_sessions[\"maze_any\"].config.track_start_t': False, 'filtered_sessions[\"maze_any\"].config.track_end_t': False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdfd908",
   "metadata": {},
   "outputs": [],
   "source": [
    "_across_session_results_extended_dict\n",
    "\n",
    "# 'filtered_sessions[\"maze1_odd\"].loaded_track_limits': False,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.pix2cm': False,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.real_unit_grid_bin_bounds': True,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.real_cm_grid_bin_bounds': True,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.grid_bin_bounds': True,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.grid_bin': True,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.track_start_t': True,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.track_end_t': True,\n",
    "\n",
    "['real_unit_grid_bin_bounds', 'real_cm_grid_bin_bounds', 'grid_bin_bounds', 'grid_bin', 'track_start_t', 'track_end_t']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c43d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.filtered_sessions[\"maze1_odd\"].config.real_unit_grid_bin_bounds\n",
    "curr_active_pipeline.filtered_sessions[\"maze_even\"].config.grid_bin_bounds\n",
    "curr_active_pipeline.filtered_sessions[\"maze1_odd\"].config.grid_bin_bounds\n",
    "curr_active_pipeline.filtered_sessions[\"maze1_odd\"].config.loaded_track_limits\n",
    "curr_active_pipeline.filtered_sessions[\"maze1_odd\"].config.track_start_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650ee1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.filtered_sessions['maze1_even'].config.real_unit_grid_bin_bounds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a3bd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# extended_computations_include_includelist=['ratemap_peaks_prominence2d', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring',] # do only specified\n",
    "computation_functions_name_includelist = ['_perform_baseline_placefield_computation', '_perform_time_dependent_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_time_dependent_pf_sequential_surprise_computation_perform_two_step_position_decoding_computation']\n",
    " #['rank_order_shuffle_analysis', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'ratemap_peaks_prominence2d', ] # do only specified\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=computation_functions_name_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=False, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=True)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963bf33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_include_function_names # {'_perform_pf_find_ratemap_peaks_computation': False, '_perform_time_dependent_pf_sequential_surprise_computation_perform_two_step_position_decoding_computation': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3d93e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=computation_functions_name_includelist, computation_kwargs_list=None, enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b70e5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# curr_active_pipeline.perform_computations(computation_functions_name_includelist=computation_functions_name_includelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2bc08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# curr_active_pipeline.active_configs # Dict[types.FilterContextName, InteractivePlaceCellConfig]\n",
    "# curr_active_pipeline.computation_results # Dict[types.FilterContextName, ComputationResult]\n",
    "\n",
    "# curr_active_pipeline.computation_results['maze1_odd'].computation_config # DynamicContainer\n",
    "# curr_active_pipeline.computation_results['maze1_odd'].computation_config.pf_params # PlacefieldComputationParameters\n",
    "\n",
    "\n",
    "grid_bin_bounds = deepcopy(curr_active_pipeline.computation_results['maze1_odd'].computation_config.pf_params.grid_bin_bounds) # ((0.0, 287.7697841726619), (115.10791366906477, 172.66187050359713))\n",
    "\n",
    "grid_bin = deepcopy(curr_active_pipeline.computation_results['maze1_odd'].computation_config.pf_params.grid_bin) # (3.8054171165052444, 1.4477079927649104)\n",
    "\n",
    "grid_bin_bounds\n",
    "# long_any_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98c40c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'DirectionalDecodersEpochsEvaluations' via compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05538438",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1885e4bc",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_10_'></a>[Call `generalized_decode_epochs_dict_and_export_results_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a876004",
   "metadata": {
    "tags": [
     "run-2025-04-11_full-session_marginals",
     "run-group-transition-matricies"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext, DisplaySpecifyingIdentifyingContext, set_context_print_options\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "\n",
    "# Usage example:\n",
    "reset_printer = set_context_print_options(include_property_names=True)\n",
    "\n",
    "# Later to restore default behavior:\n",
    "# reset_printer()\n",
    "\n",
    "import pyphoplacecellanalysis.General.type_aliases as types\n",
    "from neuropy.utils.mixins.binning_helpers import BinningContainer, BinningInfo\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import generalized_decode_epochs_dict_and_export_results_completion_function, SimpleBatchComputationDummy\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult #, KnownNamedDecoderTrainedComputeEpochsType, KnownNamedDecodingEpochsType, MaskedTimeBinFillType, DataTimeGrain, GenericResultTupleIndexType\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "\n",
    "# epochs_decoding_time_bin_size: float = 0.025\n",
    "# epochs_decoding_time_bin_size: float = 0.050\n",
    "epochs_decoding_time_bin_size: float = 0.060\n",
    "\n",
    "## Settings:\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-generalized_decode_epochs_dict_and_export_results_completion_function.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | generalized_decode_epochs_dict_and_export_results_completion_function(a_dummy, None,\n",
    "                                                    curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                    across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                    # force_recompute=True,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tforce_recompute=False,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tepochs_decoding_time_bin_size=epochs_decoding_time_bin_size,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\texport_pkl=True,\n",
    "                                                )\n",
    "\n",
    "callback_outputs = _across_session_results_extended_dict['generalized_decode_epochs_dict_and_export_results_completion_function'] # 'PostHocPipelineFixup'\n",
    "a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult = callback_outputs['a_new_fully_generic_result']\n",
    "csv_save_paths_dict: Dict[str, Path] = callback_outputs['csv_save_paths_dict']\n",
    "a_new_fully_generic_result\n",
    "\n",
    "# a_config_dict = callback_outputs['a_config_dict']\n",
    "# print(f'loaded_track_limits: {loaded_track_limits}') \n",
    "\n",
    "## OUTPUTS: a_new_fully_generic_result\n",
    " \n",
    "#  'computation_results[\"maze_any\"]': False, 'filtered_sessions[\"maze1_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze1_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze1_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze1_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze2_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze2_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze2_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze2_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze1_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_even\"].config.pix2cm': False, 'filtered_sessions[\"maze1_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.grid_bin': True, 'filtered_sessions[\"maze1_even\"].config.track_start_t': True, 'filtered_sessions[\"maze1_even\"].config.track_end_t': True, 'filtered_sessions[\"maze2_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_even\"].config.pix2cm': False, 'filtered_sessions[\"maze2_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.grid_bin': True, 'filtered_sessions[\"maze2_even\"].config.track_start_t': True, 'filtered_sessions[\"maze2_even\"].config.track_end_t': True, 'filtered_sessions[\"maze_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze_even\"].config.pix2cm': False, 'filtered_sessions[\"maze_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.grid_bin': True, 'filtered_sessions[\"maze_even\"].config.track_start_t': True, 'filtered_sessions[\"maze_even\"].config.track_end_t': True, 'filtered_sessions[\"maze1_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_any\"].config.pix2cm': False, 'filtered_sessions[\"maze1_any\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.grid_bin': True, 'filtered_sessions[\"maze1_any\"].config.track_start_t': True, 'filtered_sessions[\"maze1_any\"].config.track_end_t': True, 'filtered_sessions[\"maze2_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_any\"].config.pix2cm': False, 'filtered_sessions[\"maze2_any\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.grid_bin': True, 'filtered_sessions[\"maze2_any\"].config.track_start_t': True, 'filtered_sessions[\"maze2_any\"].config.track_end_t': True, 'filtered_sessions[\"maze_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze_any\"].config.pix2cm': False, 'filtered_sessions[\"maze_any\"].config.real_unit_grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.real_cm_grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.grid_bin': True, 'filtered_sessions[\"maze_any\"].config.track_start_t': False, 'filtered_sessions[\"maze_any\"].config.track_end_t': False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7665c5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_new_fully_generic_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8078d4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult, SingleEpochDecodedResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import ContextToPathMode\n",
    "\n",
    "save_path = Path('output/newest_all_decoded_epoch_posteriors.h5').resolve()\n",
    "_parent_save_context: IdentifyingContext = curr_active_pipeline.build_display_context_for_session('save_decoded_posteriors_to_HDF5')\n",
    "\n",
    "output_man = curr_active_pipeline.get_output_manager(context_to_path_mode=ContextToPathMode.GLOBAL_UNIQUE, override_output_parent_path=collected_outputs_path)\n",
    "# save_path: Path = output_man.get_figure_save_file_path(final_context=_parent_save_context).with_suffix('.h5')\n",
    "print(f'_parent_save_context: {_parent_save_context}')\n",
    "print(f'save_path: \"{save_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81816cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)\n",
    "\n",
    "pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict\n",
    "decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict\n",
    "\n",
    "out_contexts = PosteriorExporting.perform_save_all_decoded_posteriors_to_HDF5(decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict, _save_context=_parent_save_context, save_path=save_path)\n",
    "out_contexts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03669b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "\n",
    "## Exports: \"2024-11-26_Lab-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0-(decoded_posteriors).h5\"\n",
    "allow_append_to_session_h5_file: bool = True\n",
    "print(f'save_hdf == True, so exporting posteriors to HDF file...')\n",
    "# parent_output_path = self.collected_outputs_path.resolve()\n",
    "save_path: Path = PosteriorExporting.build_custom_export_to_h5_path(curr_active_pipeline, output_date_str=None, data_identifier_str='(decoded_posteriors)', a_tbin_size=directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size, parent_output_path=collected_outputs_path.resolve())\n",
    "save_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1285ba00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = Path(f'output/{BATCH_DATE_TO_USE}_newest_all_decoded_epoch_posteriors.h5').resolve()\n",
    "complete_session_context, (session_context, additional_session_context) = curr_active_pipeline.get_complete_session_context()\n",
    "_, _, custom_suffix = curr_active_pipeline.get_custom_pipeline_filenames_from_parameters()\n",
    "custom_params_hdf_key: str = custom_suffix.strip('_') # strip leading/trailing underscores\n",
    "# _parent_save_context: IdentifyingContext = curr_active_pipeline.build_display_context_for_session('save_decoded_posteriors_to_HDF5', custom_suffix=custom_suffix)\n",
    "_parent_save_context: DisplaySpecifyingIdentifyingContext = deepcopy(session_context).overwriting_context(custom_suffix=custom_params_hdf_key, display_fn_name='save_decoded_posteriors_to_HDF5')\n",
    "# _parent_save_context: DisplaySpecifyingIdentifyingContext = complete_session_context.overwriting_context(display_fn_name='save_decoded_posteriors_to_HDF5')\n",
    "_parent_save_context.display_dict = {\n",
    "    'custom_suffix': lambda k, v: f\"{v}\", # just include the name\n",
    "    'display_fn_name': lambda k, v: f\"{v}\", # just include the name\n",
    "}\n",
    "out_contexts, _flat_all_HDF5_out_paths = PosteriorExporting.perform_save_all_decoded_posteriors_to_HDF5(decoder_laps_filter_epochs_decoder_result_dict=None,\n",
    "                                                                            decoder_ripple_filter_epochs_decoder_result_dict=deepcopy(directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict),\n",
    "                                                                            _save_context=_parent_save_context.get_raw_identifying_context(), save_path=save_path, should_overwrite_extant_file=(not allow_append_to_session_h5_file))\n",
    "\n",
    "_flat_all_HDF5_out_paths = list(dict.fromkeys([v.as_posix() for v in _flat_all_HDF5_out_paths]).keys())\n",
    "# _output_HDF5_paths_info_str: str = '\\n'.join([f'\"{file_uri_from_path(a_path)}\"' for a_path in _flat_all_HDF5_out_paths])\n",
    "_output_HDF5_paths_info_str: str = '\\n'.join([f'\"{a_path}\"' for a_path in _flat_all_HDF5_out_paths])\n",
    "# print(f'\\t\\t\\tHDF5 Paths: {_flat_all_HDF5_out_paths}\\n')\n",
    "print(f'\\t\\t\\tHDF5 Paths: {_output_HDF5_paths_info_str}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b74e164",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO 🚧 2025-03-11 13:01: - [ ] Allow overriding qclu and inclusion_fr values, see other user function\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "a_new_fully_generic_result = a_new_fully_generic_result.adding_directional_pseudo2D_decoder_results_filtered_by_spikes_per_t_bin_masked(directional_merged_decoders_result=directional_merged_decoders_result) # , spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773b4b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_context = IdentifyingContext(pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='ignore', data_grain='per_time_bin')\n",
    "# search_context = IdentifyingContext(pfND_ndim=2, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='ignore', data_grain='per_time_bin')\n",
    "a_ctxt, a_result, a_decoder, _ = a_new_fully_generic_result.get_results_matching_contexts(context_query=search_context, return_multiple_matches=False, debug_print=True)\n",
    "a_ctxt\n",
    "a_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204f9aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_result.build_per_time_bin_marginals_df()\n",
    "# type(a_result)\n",
    "\n",
    "\n",
    "a_directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = deepcopy(directional_merged_decoders_result)\n",
    "\n",
    "a_directional_merged_decoders_result.ripple_time_bin_marginals_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4d37a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import DecodingResultND\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import ComputeGlobalEpochBase\n",
    "\n",
    "a_new_global_epoch_base_obj: ComputeGlobalEpochBase = ComputeGlobalEpochBase.init_from_pipeline(curr_active_pipeline=curr_active_pipeline)\n",
    "results1D, results2D = ComputeGlobalEpochBase.compute_all(curr_active_pipeline, single_global_epoch=a_new_global_epoch_base_obj.single_global_epoch_df,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   epochs_decoding_time_bin_size=0.025,\n",
    "                                                        #    frame_divide_bin_size=0.50,\n",
    "                                                           frame_divide_bin_size=10.00,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   compute_1D=False, compute_2D=True)\n",
    "results2D\n",
    "## 7.5m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1424139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BasePositionDecoder\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import SingleEpochDecodedResult\n",
    "\n",
    "## INPUTS: results2D\n",
    "global_pos_df: pd.DataFrame = deepcopy(results2D.pos_df) # computation_result.sess.position.to_dataframe()\n",
    "a_new_global2D_decoder: BasePositionDecoder = deepcopy(results2D.a_new_global2D_decoder)\n",
    "a_result2D: DecodedFilterEpochsResult = deepcopy(results2D.a_result2D)\n",
    "active_two_step_result, _OLD_two_step_decoder_result = BasePositionDecoder.perform_compute_two_step_decoder(active_decoder=a_new_global2D_decoder, active_one_step_result=a_result2D, pos_df=global_pos_df)\n",
    "# two_step_decoder_result\n",
    "active_two_step_result\n",
    "\n",
    "## OUTPUTS: active_two_step_result: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cfeed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_result2D: DecodedFilterEpochsResult = deepcopy(results2D.a_result2D)\n",
    "masked_a_result2D, _mask_index_tuple = a_result2D.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), min_num_spikes_per_bin_to_be_considered_active=5, min_num_unique_active_neurons_per_time_bin=1, masked_bin_fill_mode='ignore')\n",
    "# masked_a_result2D, _mask_index_tuple = a_result2D.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), min_num_spikes_per_bin_to_be_considered_active=5, min_num_unique_active_neurons_per_time_bin=1, masked_bin_fill_mode='nan_filled')\n",
    "# masked_a_result2D, _mask_index_tuple = a_result2D.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), min_num_spikes_per_bin_to_be_considered_active=5, min_num_unique_active_neurons_per_time_bin=1, masked_bin_fill_mode='last_valid')\n",
    "a_result2D = masked_a_result2D ## overwrite a_result2D\n",
    "## get 1D marginals to compare to 1D decoder:\n",
    "n_timebins, flat_time_bin_containers, timebins_p_x_given_n = a_result2D.flatten()\n",
    "flat_time_window_centers = np.hstack([v.centers for v in flat_time_bin_containers])\n",
    "timebins_marginal_x_p_x_given_n: NDArray = np.concatenate([a_marginal_x['p_x_given_n'] for a_marginal_x in masked_a_result2D.marginal_x_list], axis=-1) # (59, 83756) - (n_x_bins, n_flat_t_bins)\n",
    "assert np.shape(timebins_marginal_x_p_x_given_n)[-1] == n_timebins, f\"timebins_marginal_x_p_x_given_n.shape: {np.shape(timebins_marginal_x_p_x_given_n)}'s last dimension should equal n_timebins: {n_timebins}\"\n",
    "assert len(flat_time_window_centers) == n_timebins, f\"len(flat_time_window_centers): {len(flat_time_window_centers)} should equal n_timebins: {n_timebins}\"\n",
    "\n",
    "## OUTPUTS: flat_time_window_centers, timebins_marginal_x_p_x_given_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7863e0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import DockDisplayColors, CustomDockDisplayConfig\n",
    "\n",
    "## INPUTS: active_2d_plot\n",
    "\n",
    "## Do separately for the long/short epochs instead of using the global decoder built across all data:\n",
    "# masked_bin_fill_mode = 'ignore'\n",
    "masked_bin_fill_mode = 'nan_filled'\n",
    "# masked_bin_fill_mode = 'last_valid'\n",
    "_mask_kwargs = dict(min_num_spikes_per_bin_to_be_considered_active=2, min_num_unique_active_neurons_per_time_bin=1, masked_bin_fill_mode=masked_bin_fill_mode)\n",
    "\n",
    "for a_track_length in ['long', 'short']:\n",
    "    a_decoder: BasePositionDecoder = results2D.decoders[a_track_length]\n",
    "    a_result2D: DecodedFilterEpochsResult = deepcopy(results2D.continuous_results[a_track_length])\n",
    "    masked_a_result2D, _mask_index_tuple = a_result2D.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), **_mask_kwargs)\n",
    "    a_result2D = masked_a_result2D ## overwrite a_result2D\n",
    "    ## get 1D marginals to compare to 1D decoder:\n",
    "    n_timebins, flat_time_bin_containers, timebins_p_x_given_n = a_result2D.flatten()\n",
    "    flat_time_window_centers: NDArray = np.hstack([v.centers for v in flat_time_bin_containers])\n",
    "    timebins_marginal_x_p_x_given_n: NDArray = np.concatenate([a_marginal_x['p_x_given_n'] for a_marginal_x in masked_a_result2D.marginal_x_list], axis=-1) # (59, 83756) - (n_x_bins, n_flat_t_bins)\n",
    "    assert np.shape(timebins_marginal_x_p_x_given_n)[-1] == n_timebins, f\"timebins_marginal_x_p_x_given_n.shape: {np.shape(timebins_marginal_x_p_x_given_n)}'s last dimension should equal n_timebins: {n_timebins}\"\n",
    "    assert len(flat_time_window_centers) == n_timebins, f\"len(flat_time_window_centers): {len(flat_time_window_centers)} should equal n_timebins: {n_timebins}\"\n",
    "\n",
    "    ## OUTPUTS: flat_time_window_centers, timebins_marginal_x_p_x_given_n\n",
    "    ## INPUTS: flat_time_window_centers, timebins_marginal_x_p_x_given_n, a_new_global2D_decoder, global_pos_df\n",
    "    active_time_bin_size: float = a_result2D.decoding_time_bin_size\n",
    "    info_string: str = f'{active_time_bin_size:.3f}'\n",
    "    dock_group_sep_character: str = '_'\n",
    "    showCloseButton = True\n",
    "    _common_dock_config_kwargs = {'dock_group_names': [dock_group_sep_character.join([f'Result2D_MarginalX', info_string])], 'showCloseButton': showCloseButton, 'showTimelineSyncModeButton': True}\n",
    "\n",
    "    # dock_configs: Dict[str, CustomDockDisplayConfig] = {k:deepcopy(CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_global_dock_colors, **_common_dock_config_kwargs)) for k in unique_decoder_names}\n",
    "    # dock_configs: Dict[str, CustomDockDisplayConfig] = {k:deepcopy(CustomDockDisplayConfig(custom_get_colors_callback_fn=DockDisplayColors.get_random_dock_colors_for_key_fn(key=k), **_common_dock_config_kwargs)) for k in unique_decoder_names}\n",
    "    # pf1D_Decoder_dict = {k:deepcopy(v) for k, v in a_decoder.items() if k in unique_decoder_names}\n",
    "    # pf1D_Decoder_dict = {k:deepcopy(a_decoder) for k in unique_decoder_names} ## this is dumb, but it provides xlims!\n",
    "    # output_dict = active_2d_plot.add_docked_decoded_results_dict_tracks(name=f'LapsDecode', a_decoded_result_dict=a_pseudo2D_split_to_1D_continuous_results_dict, dock_configs=dock_configs,\n",
    "    #                                                                                             pf1D_Decoder_dict=pf1D_Decoder_dict,\n",
    "    #                                                                                             measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "    #                                                                                             extended_dock_title_info=info_string)\n",
    "\n",
    "\n",
    "    # # pf1D_Decoder_dict = {k:deepcopy(v) for k, v in a_decoder.items() if k in unique_decoder_names\n",
    "    key_name: str = f'Result2D_MarginalX[{a_track_length}]'\n",
    "    ## a_1D_continuous_decoded_result: SingleEpochDecodedResult\n",
    "    a_dock_config = CustomDockDisplayConfig(custom_get_colors_callback_fn=DockDisplayColors.get_random_dock_colors_for_key_fn(key=key_name), **_common_dock_config_kwargs)\n",
    "    # a_1D_decoder: BasePositionDecoder = pf1D_Decoder_dict[a_decoder_name]\n",
    "    # add_docked_decoded_posterior_track(name=name, time_window_centers=a_1D_decoded_result.time_bin_container.centers, a_1D_posterior=a_1D_decoded_result.p_x_given_n, xbin=xbin, measured_position_df=measured_position_df, **kwargs)\n",
    "    # _out_tuple = active_2d_plot.add_docked_decoded_posterior_track_from_result(name=f'{name}[{a_decoder_name}]', a_dock_config=a_dock_config, a_1D_decoded_result=a_1D_decoded_result,\n",
    "    #                                                                                         xbin = deepcopy(a_1D_decoder.xbin), measured_position_df=deepcopy(measured_position_df), **kwargs) # , should_defer_render=False\n",
    "\n",
    "    _out_tuple = active_2d_plot.add_docked_decoded_posterior_track(name=key_name, a_dock_config=a_dock_config, time_window_centers=flat_time_window_centers, a_1D_posterior=timebins_marginal_x_p_x_given_n,\n",
    "                                                                                            xbin = deepcopy(a_new_global2D_decoder.xbin), measured_position_df=deepcopy(global_pos_df)) # , should_defer_render=False\n",
    "    identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = _out_tuple\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59283a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import DockDisplayColors, CustomDockDisplayConfig\n",
    "\n",
    "## INPUTS: flat_time_window_centers, timebins_marginal_x_p_x_given_n, a_new_global2D_decoder, global_pos_df\n",
    "active_time_bin_size: float = a_result2D.decoding_time_bin_size\n",
    "info_string: str = f'{active_time_bin_size:.3f}'\n",
    "dock_group_sep_character: str = '_'\n",
    "showCloseButton = True\n",
    "_common_dock_config_kwargs = {'dock_group_names': [dock_group_sep_character.join([f'Result2D_MarginalX', info_string])], 'showCloseButton': showCloseButton, 'showTimelineSyncModeButton': True}\n",
    "\n",
    "# dock_configs: Dict[str, CustomDockDisplayConfig] = {k:deepcopy(CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_global_dock_colors, **_common_dock_config_kwargs)) for k in unique_decoder_names}\n",
    "# dock_configs: Dict[str, CustomDockDisplayConfig] = {k:deepcopy(CustomDockDisplayConfig(custom_get_colors_callback_fn=DockDisplayColors.get_random_dock_colors_for_key_fn(key=k), **_common_dock_config_kwargs)) for k in unique_decoder_names}\n",
    "# pf1D_Decoder_dict = {k:deepcopy(v) for k, v in a_decoder.items() if k in unique_decoder_names}\n",
    "# pf1D_Decoder_dict = {k:deepcopy(a_decoder) for k in unique_decoder_names} ## this is dumb, but it provides xlims!\n",
    "# output_dict = active_2d_plot.add_docked_decoded_results_dict_tracks(name=f'LapsDecode', a_decoded_result_dict=a_pseudo2D_split_to_1D_continuous_results_dict, dock_configs=dock_configs,\n",
    "#                                                                                             pf1D_Decoder_dict=pf1D_Decoder_dict,\n",
    "#                                                                                             measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "#                                                                                             extended_dock_title_info=info_string)\n",
    "\n",
    "\n",
    "# # pf1D_Decoder_dict = {k:deepcopy(v) for k, v in a_decoder.items() if k in unique_decoder_names\n",
    "key_name: str = f'Result2D_MarginalX[{a_track_length}]'\n",
    "## a_1D_continuous_decoded_result: SingleEpochDecodedResult\n",
    "a_dock_config = CustomDockDisplayConfig(custom_get_colors_callback_fn=DockDisplayColors.get_random_dock_colors_for_key_fn(key=key_name), **_common_dock_config_kwargs)\n",
    "# a_1D_decoder: BasePositionDecoder = pf1D_Decoder_dict[a_decoder_name]\n",
    "# add_docked_decoded_posterior_track(name=name, time_window_centers=a_1D_decoded_result.time_bin_container.centers, a_1D_posterior=a_1D_decoded_result.p_x_given_n, xbin=xbin, measured_position_df=measured_position_df, **kwargs)\n",
    "# _out_tuple = active_2d_plot.add_docked_decoded_posterior_track_from_result(name=f'{name}[{a_decoder_name}]', a_dock_config=a_dock_config, a_1D_decoded_result=a_1D_decoded_result,\n",
    "#                                                                                         xbin = deepcopy(a_1D_decoder.xbin), measured_position_df=deepcopy(measured_position_df), **kwargs) # , should_defer_render=False\n",
    "\n",
    "_out_tuple = active_2d_plot.add_docked_decoded_posterior_track(name=key_name, a_dock_config=a_dock_config, time_window_centers=flat_time_window_centers, a_1D_posterior=timebins_marginal_x_p_x_given_n,\n",
    "                                                                                        xbin = deepcopy(a_new_global2D_decoder.xbin), measured_position_df=deepcopy(global_pos_df)) # , should_defer_render=False\n",
    "\n",
    "\n",
    "identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = _out_tuple\n",
    "# ## Add `a_decoded_result` to the plots_data\n",
    "# widget.plots_data.a_decoded_result = a_1D_decoded_result\n",
    "# widget.plots_data.a_decoder = deepcopy(a_1D_decoder)\n",
    "# output_dict[a_decoder_name] = (identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem) ## add again\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a177899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_result2D.marginal_x_list\n",
    "(epochs_directional_marginals_tuple, epochs_track_identity_marginals_tuple, epochs_non_marginalized_decoder_marginals_tuple), epochs_marginals_df = a_result2D.compute_marginals(additional_transfer_column_names=['start','stop','label','duration','lap_id','lap_dir'])\n",
    "epochs_directional_marginals, epochs_directional_all_epoch_bins_marginal, epochs_most_likely_direction_from_decoder, epochs_is_most_likely_direction_LR_dir  = epochs_directional_marginals_tuple\n",
    "epochs_track_identity_marginals, epochs_track_identity_all_epoch_bins_marginal, epochs_most_likely_track_identity_from_decoder, epochs_is_most_likely_track_identity_Long = epochs_track_identity_marginals_tuple\n",
    "non_marginalized_decoder_marginals, non_marginalized_decoder_all_epoch_bins_marginal, most_likely_decoder_idxs, non_marginalized_decoder_all_epoch_bins_decoder_probs_df = epochs_non_marginalized_decoder_marginals_tuple\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0a80c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export to images output folder:\n",
    "from pyphocorehelpers.plotting.media_output_helpers import save_array_as_image, save_array_as_video\n",
    "\n",
    "# image, out_path = save_array_as_image(timebins_p_x_given_n, desired_height=512, desired_width=None, skip_img_normalization=True, out_path='')\n",
    "# image\n",
    "\n",
    "timebins_p_x_given_n_for_video = deepcopy(timebins_p_x_given_n) # timebins_p_x_given_n.shape: (59, 8, 83756) - (n_x_bins, n_y_bins, n_t_bins)\n",
    "timebins_p_x_given_n_for_video = timebins_p_x_given_n_for_video.transpose((2, 1, 0)) # (n_frames, n_height_bins, n_width_bins)\n",
    "video_out_path = save_array_as_video(array=timebins_p_x_given_n_for_video, video_filename='output/videos/2025-06-30_global2D_decoder.avi', isColor=False)\n",
    "print(f'video_out_path: {video_out_path}')\n",
    "reveal_in_system_file_manager(video_out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb9668",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timebins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9099e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_export_path = Path('data').resolve()\n",
    "\n",
    "an_export_basepath = parent_export_path.joinpath(f'{BATCH_DATE_TO_USE}_{epochs_decoding_time_bin_size}_results2D')\n",
    "out_PKL_export_path: Path = an_export_basepath.with_suffix('.pkl').resolve()\n",
    "out_HDF5_export_path: Path = an_export_basepath.with_suffix('.hdf').resolve()\n",
    "\n",
    "print(f'out_PKL_export_path: {out_PKL_export_path}')\n",
    "results2D.save(pkl_output_path=out_PKL_export_path)\n",
    "\n",
    "\n",
    "# print(f'out_HDF5_export_path: {out_HDF5_export_path}')\n",
    "# active_two_step_result: DecodedFilterEpochsResult = active_two_step_result\n",
    "# active_two_step_result.to_hdf(out_HDF5_export_path, key='active_two_step_result')\n",
    "# out_HDF5_export_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb72536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_export_path = Path('data').resolve()\n",
    "\n",
    "a_new_active_two_step_result_export_basepath = parent_export_path.joinpath(f'{BATCH_DATE_TO_USE}_{epochs_decoding_time_bin_size}_active_two_step_result')\n",
    "# a_new_fully_generic_result_HDF5_export_path: Path = a_new_fully_generic_result_export_basepath.with_suffix('.h5').resolve()\n",
    "# a_new_fully_generic_result.to_hdf(file_path=a_new_fully_generic_result_HDF5_export_path, key='a_new_fully_generic_result', debug_print=True, OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True) # , OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True\n",
    "\n",
    "# out_PKL_export_path: Path = a_new_active_two_step_result_export_basepath.with_suffix('.pkl').resolve()\n",
    "out_HDF5_export_path: Path = a_new_active_two_step_result_export_basepath.with_suffix('.hdf').resolve()\n",
    "\n",
    "# print(f'out_PKL_export_path: {out_PKL_export_path}')\n",
    "# a_new_fully_generic_result.save(pkl_output_path=out_PKL_export_path)\n",
    "\n",
    "print(f'out_HDF5_export_path: {out_HDF5_export_path}')\n",
    "active_two_step_result: DecodedFilterEpochsResult = active_two_step_result\n",
    "active_two_step_result.to_hdf(out_HDF5_export_path, key='active_two_step_result')\n",
    "out_HDF5_export_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45966b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_export_path = Path('data').resolve()\n",
    "\n",
    "a_new_fully_generic_result_export_basepath = parent_export_path.joinpath(f'{BATCH_DATE_TO_USE}_{epochs_decoding_time_bin_size}_a_new_fully_generic_result')\n",
    "# a_new_fully_generic_result_HDF5_export_path: Path = a_new_fully_generic_result_export_basepath.with_suffix('.h5').resolve()\n",
    "# a_new_fully_generic_result.to_hdf(file_path=a_new_fully_generic_result_HDF5_export_path, key='a_new_fully_generic_result', debug_print=True, OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True) # , OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True\n",
    "\n",
    "out_PKL_export_path: Path = a_new_fully_generic_result_export_basepath.with_suffix('.pkl').resolve()\n",
    "# out_HDF5_export_path: Path = a_new_fully_generic_result_export_basepath.with_suffix('.hdf').resolve()\n",
    "\n",
    "# print(f'out_PKL_export_path: {out_PKL_export_path}')\n",
    "a_new_fully_generic_result.save(pkl_output_path=out_PKL_export_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f924bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import LinearTrackInstance, _perform_plot_matplotlib_2D_tracks\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.mixins.decoder_plotting_mixins import DecodedTrajectoryMatplotlibPlotter\n",
    "from neuropy.utils.matplotlib_helpers import perform_update_title_subtitle\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.mixins.decoder_plotting_mixins import multi_DecodedTrajectoryMatplotlibPlotter_side_by_side\n",
    "\n",
    "n_axes: int = 10\n",
    "posterior_masking_value: float = 0.02 # for 2D\n",
    "a_decoded_traj_plotter, (fig, axs, decoded_epochs_pages) = multi_DecodedTrajectoryMatplotlibPlotter_side_by_side(a_result2D=results2D.a_result2D, a_new_global_decoder2D=results2D.a_new_global2D_decoder,\n",
    "                                                                                                                global_session=global_session, n_axes=n_axes, posterior_masking_value=posterior_masking_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f63c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_keys_if_possible('a_result2D', a_result2D, max_depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd837ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_keys_if_possible('a_result2D', a_result2D, max_depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c85d700",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_step_decoder_result['all_scaling_factors_k'] = Zhang_Two_Step.compute_scaling_factor_k(prev_one_step_bayesian_decoder.flat_p_x_given_n)\n",
    "_perform_two_step_position_decoding_computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bc6a92",
   "metadata": {
    "tags": [
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "# Save To pickle:\n",
    "## INPUTS: a_new_fully_generic_result\n",
    "# BATCH_DATE_TO_USE: str = f'2025-04-11_Apogee'\n",
    "# BATCH_DATE_TO_USE: str = f'2025-04-11_GL_{epochs_decoding_time_bin_size}'\n",
    "\n",
    "# parent_export_path = Path('/home/halechr/repos/Spike3D/data').resolve()\n",
    "parent_export_path = Path('data').resolve()\n",
    "\n",
    "a_new_fully_generic_result_export_basepath = parent_export_path.joinpath(f'{BATCH_DATE_TO_USE}_{epochs_decoding_time_bin_size}_a_new_fully_generic_result')\n",
    "# a_new_fully_generic_result_HDF5_export_path: Path = a_new_fully_generic_result_export_basepath.with_suffix('.h5').resolve()\n",
    "# a_new_fully_generic_result.to_hdf(file_path=a_new_fully_generic_result_HDF5_export_path, key='a_new_fully_generic_result', debug_print=True, OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True) # , OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True\n",
    "\n",
    "out_PKL_export_path: Path = a_new_fully_generic_result_export_basepath.with_suffix('.pkl').resolve()\n",
    "print(f'out_PKL_export_path: {out_PKL_export_path}')\n",
    "a_new_fully_generic_result.save(pkl_output_path=out_PKL_export_path)\n",
    "# \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca9a6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyphoplacecellanalysis.General.type_aliases as types\n",
    "from neuropy.utils.mixins.binning_helpers import BinningContainer, BinningInfo\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import generalized_decode_epochs_dict_and_export_results_completion_function, SimpleBatchComputationDummy\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult #, KnownNamedDecoderTrainedComputeEpochsType, KnownNamedDecodingEpochsType, MaskedTimeBinFillType, DataTimeGrain, GenericResultTupleIndexType\n",
    "\n",
    "## Load from previous pickle:\n",
    "# input_path = Path(f'/home/halechr/repos/Spike3D/data/2025-04-11_Apogee_a_new_fully_generic_result.pkl').resolve()\n",
    "input_path = Path(f'data/2025-04-11_Apogee_a_new_fully_generic_result.pkl').resolve()\n",
    "Assert.path_exists(input_path)\n",
    "a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult = GenericDecoderDictDecodedEpochsDictResult.from_file(pkl_path=input_path)\n",
    "a_new_fully_generic_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532ec01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.time_slicing import TimeColumnAliasesProtocol\n",
    "\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "epochs_decoding_time_bin_size = 0.025\n",
    "# epochs_decoding_time_bin_size = 0.050\n",
    "\n",
    "## ensure all optional fields are present before output:\n",
    "# Add the maze_id to the active_filter_epochs so we can see how properties change as a function of which track the replay event occured on:\n",
    "for k in list(a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict.keys()):\n",
    "    a_df = a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict[k]\n",
    "    ## note in per-epoch mode we use the start of the epoch (because for example laps are long and we want to see as soon as it starts) but for time bins we use the center time.\n",
    "    time_column_name: str = TimeColumnAliasesProtocol.find_first_extant_suitable_columns_name(a_df, col_connonical_name='t', required_columns_synonym_dict={\"t\":{'t_bin_center', 'lap_start_t', 'ripple_start_t', 'epoch_start_t'}}, should_raise_exception_on_fail=True)\n",
    "    assert time_column_name in a_df\n",
    "    a_df['delta_aligned_start_t'] = a_df[time_column_name] - t_delta ## subtract off t_delta\n",
    "    a_df = a_df.across_session_identity.add_session_df_columns(session_name=session_name, time_bin_size=epochs_decoding_time_bin_size, curr_session_t_delta=t_delta, time_col=time_column_name)\n",
    "    a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict[k] = a_df\n",
    "    # display(a_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64837420",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export to CSVs:\n",
    "csv_save_paths = {}\n",
    "active_export_parent_output_path = a_dummy.collected_outputs_path.resolve()\n",
    "# Assert.path_exists(parent_output_path)\n",
    "\n",
    "## INPUTS: collected_outputs_path\n",
    "decoding_time_bin_size: float = epochs_decoding_time_bin_size\n",
    "\n",
    "complete_session_context, (session_context, additional_session_context) = curr_active_pipeline.get_complete_session_context()\n",
    "active_context = complete_session_context ## This context isn't enough! Easiest to build using `curr_active_pipeline` directly.\n",
    "\n",
    "def _subfn_custom_export_df_to_csv(export_df: pd.DataFrame, data_identifier_str: str = f'(laps_marginals_df)', parent_output_path: Path=None):\n",
    "    \"\"\" captures CURR_BATCH_DATE_TO_USE, `curr_active_pipeline`\n",
    "    \"\"\"\n",
    "    output_date_str: str = get_now_rounded_time_str(rounded_minutes=10)\n",
    "    out_path, out_filename, out_basename = curr_active_pipeline.build_complete_session_identifier_filename_string(output_date_str=output_date_str, data_identifier_str=data_identifier_str, parent_output_path=parent_output_path, out_extension='.csv')\n",
    "    export_df.to_csv(out_path)\n",
    "    return out_path \n",
    "\n",
    "\n",
    "custom_export_df_to_csv_fn = _subfn_custom_export_df_to_csv\n",
    "\n",
    "\n",
    "# build_complete_session_identifier_filename_string\n",
    "\n",
    "\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "earliest_delta_aligned_t_start, t_delta, latest_delta_aligned_t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "# tbin_values_dict={'laps': decoding_time_bin_size, 'pbe': decoding_time_bin_size, 'non_pbe': decoding_time_bin_size, 'FAT': decoding_time_bin_size}\n",
    "\n",
    "# csv_save_paths_dict = GenericDecoderDictDecodedEpochsDictResult._perform_export_dfs_dict_to_csvs(extracted_dfs_dict=a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict,\n",
    "csv_save_paths_dict = a_new_fully_generic_result.export_csvs(\n",
    "                                        parent_output_path=active_export_parent_output_path.resolve(),\n",
    "                                        active_context=active_context, session_name=session_name, #curr_active_pipeline=curr_active_pipeline,\n",
    "                                        decoding_time_bin_size=decoding_time_bin_size,\n",
    "                                        curr_session_t_delta=t_delta, \n",
    "                                        custom_export_df_to_csv_fn=custom_export_df_to_csv_fn,\n",
    "                                        )\n",
    "\n",
    "print(f'csv_save_paths_dict: {csv_save_paths_dict}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1269a3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_new_fully_generic_result.get_matching_contexts(IdentifyingContext(), return_multiple_matches=True, ) ## this only returns 3 results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97171718",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get old results\n",
    "# decoder_laps_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict)\n",
    "# all_directional_ripple_filter_epochs_decoder_result: DecodedFilterEpochsResult = directional_merged_decoders_result.laps_all_epoch_bins_marginals_df\n",
    "# decoder_laps_filter_epochs_decoder_result_dict.compute_marginals()\n",
    "laps_all_epoch_bins_marginals_df = deepcopy(directional_merged_decoders_result.laps_all_epoch_bins_marginals_df)\n",
    "laps_all_epoch_bins_marginals_df\n",
    "\n",
    "\n",
    "# active_marginals=ripple_track_identity_marginals, columns=['P_LR', 'P_RL']\n",
    "# active_marginals=ripple_track_identity_marginals, columns=['P_Long', 'P_Short']\n",
    "# _build_multiple_per_time_bin_marginals(a_decoder_result=decoder_laps_filter_epochs_decoder_result_dict, active_marginals_tuple=(laps_directional_all_epoch_bins_marginal, laps_track_identity_all_epoch_bins_marginal), columns_tuple=(['P_LR', 'P_RL'], ['P_Long', 'P_Short']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d1bf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get new results\n",
    "best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_matching_contexts(context_query=IdentifyingContext(trained_compute_epochs='laps', time_bin_size=0.025, known_named_decoding_epochs_type='laps', decoder_identifier='pseudo2D', masked_time_bin_fill_type='ignore'), debug_print=True, return_multiple_matches=False)\n",
    "\n",
    "## Plot them against each other for comparison\n",
    "a_decoded_marginal_posterior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3de43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_result.decoding_time_bin_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7788f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_laps_filter_epochs_decoder_result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff79ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "\n",
    "curr_active_pipeline.reload_default_computation_functions()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552cdd7d",
   "metadata": {},
   "source": [
    "### Call `compute_and_export_session_extended_placefield_peak_information_completion_function`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f93d69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext, DisplaySpecifyingIdentifyingContext, set_context_print_options\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "\n",
    "# Usage example:\n",
    "reset_printer = set_context_print_options(include_property_names=True)\n",
    "\n",
    "# Later to restore default behavior:\n",
    "# reset_printer()\n",
    "\n",
    "import pyphoplacecellanalysis.General.type_aliases as types\n",
    "from neuropy.utils.mixins.binning_helpers import BinningContainer, BinningInfo\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_session_extended_placefield_peak_information_completion_function, SimpleBatchComputationDummy\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult #, KnownNamedDecoderTrainedComputeEpochsType, KnownNamedDecodingEpochsType, MaskedTimeBinFillType, DataTimeGrain, GenericResultTupleIndexType\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-compute_and_export_session_extended_placefield_peak_information_completion_function.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_session_extended_placefield_peak_information_completion_function(a_dummy, None,\n",
    "                                                    curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                    across_session_results_extended_dict=_across_session_results_extended_dict, save_csv=True, save_json=False\n",
    "                                                )\n",
    "\n",
    "callback_outputs = _across_session_results_extended_dict['compute_and_export_session_extended_placefield_peak_information_completion_function'] # 'PostHocPipelineFixup'\n",
    "csv_output_path: str = callback_outputs['csv_output_path']\n",
    "csv_output_path\n",
    "\n",
    "# a_config_dict = callback_outputs['a_config_dict']\n",
    "# print(f'loaded_track_limits: {loaded_track_limits}') \n",
    "\n",
    "## OUTPUTS: a_new_fully_generic_result\n",
    " \n",
    "#  'computation_results[\"maze_any\"]': False, 'filtered_sessions[\"maze1_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze1_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze1_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze1_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze2_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze2_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze2_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze2_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze1_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_even\"].config.pix2cm': False, 'filtered_sessions[\"maze1_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.grid_bin': True, 'filtered_sessions[\"maze1_even\"].config.track_start_t': True, 'filtered_sessions[\"maze1_even\"].config.track_end_t': True, 'filtered_sessions[\"maze2_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_even\"].config.pix2cm': False, 'filtered_sessions[\"maze2_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.grid_bin': True, 'filtered_sessions[\"maze2_even\"].config.track_start_t': True, 'filtered_sessions[\"maze2_even\"].config.track_end_t': True, 'filtered_sessions[\"maze_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze_even\"].config.pix2cm': False, 'filtered_sessions[\"maze_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.grid_bin': True, 'filtered_sessions[\"maze_even\"].config.track_start_t': True, 'filtered_sessions[\"maze_even\"].config.track_end_t': True, 'filtered_sessions[\"maze1_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_any\"].config.pix2cm': False, 'filtered_sessions[\"maze1_any\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.grid_bin': True, 'filtered_sessions[\"maze1_any\"].config.track_start_t': True, 'filtered_sessions[\"maze1_any\"].config.track_end_t': True, 'filtered_sessions[\"maze2_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_any\"].config.pix2cm': False, 'filtered_sessions[\"maze2_any\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.grid_bin': True, 'filtered_sessions[\"maze2_any\"].config.track_start_t': True, 'filtered_sessions[\"maze2_any\"].config.track_end_t': True, 'filtered_sessions[\"maze_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze_any\"].config.pix2cm': False, 'filtered_sessions[\"maze_any\"].config.real_unit_grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.real_cm_grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.grid_bin': True, 'filtered_sessions[\"maze_any\"].config.track_start_t': False, 'filtered_sessions[\"maze_any\"].config.track_end_t': False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd91f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save To pickle:\n",
    "## INPUTS: a_new_fully_generic_result\n",
    "# BATCH_DATE_TO_USE: str = f'2025-04-11_Apogee'\n",
    "# BATCH_DATE_TO_USE: str = f'2025-04-11_GL_{epochs_decoding_time_bin_size}'\n",
    "\n",
    "# parent_export_path = Path('/home/halechr/repos/Spike3D/data').resolve()\n",
    "parent_export_path = Path('data').resolve()\n",
    "\n",
    "a_new_fully_generic_result_export_basepath = parent_export_path.joinpath(f'{BATCH_DATE_TO_USE}_{epochs_decoding_time_bin_size}_a_new_fully_generic_result')\n",
    "# a_new_fully_generic_result_HDF5_export_path: Path = a_new_fully_generic_result_export_basepath.with_suffix('.h5').resolve()\n",
    "# a_new_fully_generic_result.to_hdf(file_path=a_new_fully_generic_result_HDF5_export_path, key='a_new_fully_generic_result', debug_print=True, OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True) # , OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True\n",
    "\n",
    "out_PKL_export_path: Path = a_new_fully_generic_result_export_basepath.with_suffix('.pkl').resolve()\n",
    "print(f'out_PKL_export_path: {out_PKL_export_path}')\n",
    "a_new_fully_generic_result.save(pkl_output_path=out_PKL_export_path)\n",
    "# \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d523ee",
   "metadata": {},
   "source": [
    "# 2025-06-05 - Theta Phase Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859549d4",
   "metadata": {
    "tags": [
     "2025-06-05_thetaphaseanalysis"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.TimeCurves.SpecificTimeCurves import PositionRenderTimeCurves, ConfigurableRenderTimeCurves, ThetaPhaseRenderTimeCurves\n",
    "\n",
    "\n",
    "def circular_diff(angles):\n",
    "    \"\"\"\n",
    "    Calculate circular difference for angular data.\n",
    "    Handles wrap-around at 2π.\n",
    "    \"\"\"\n",
    "    diff = np.diff(angles)\n",
    "    # Wrap differences to [-π, π]\n",
    "    diff = (diff + np.pi) % (2 * np.pi) - np.pi\n",
    "    return np.abs(diff)\n",
    "\n",
    "\n",
    "## firing statistics to bins instead of boolean masking by those meeting criteria\n",
    "spikes_df: pd.DataFrame = get_proper_global_spikes_df(curr_active_pipeline)\n",
    "spikes_df['accel'] = spikes_df['speed'].diff().abs() / spikes_df['t_rel_seconds'].diff()\n",
    "spikes_df['theta_phase_radians_per_sec'] = spikes_df['theta_phase_radians'].diff().abs() / spikes_df['t_rel_seconds'].diff()\n",
    "\n",
    "# Handle circular statistics for theta phase\n",
    "theta_phase_circular_diff = circular_diff(spikes_df['theta_phase_radians'].to_numpy())\n",
    "time_diff = spikes_df['t_rel_seconds'].diff().iloc[1:].to_numpy()  # Skip first NaN\n",
    "spikes_df['theta_phase_radians_per_sec'] = np.concatenate([[np.nan], theta_phase_circular_diff / time_diff])\n",
    "\n",
    "\n",
    "theta_phase_radians = spikes_df['theta_phase_radians'].to_numpy()\n",
    "spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41f9fe9",
   "metadata": {
    "tags": [
     "2025-05-27_theta-phase-added",
     "2025-06-05_thetaphaseanalysis"
    ]
   },
   "outputs": [],
   "source": [
    "# active_2d_plot.get_leaf_only_flat_dock_identifiers_list()\n",
    "a_time_sync_pyqtgraph_widget, root_graphics_layout_widget, plot_item, dDisplayItem = active_2d_plot.add_new_embedded_pyqtgraph_render_plot_widget(name='thetaPhase', dockSize=(1, 4), sync_mode=SynchronizedPlotMode.TO_WINDOW)\n",
    "theta_phase_line_actor = plot_item.plot(spikes_df['t_rel_seconds'].to_numpy(), spikes_df['theta_phase_radians'].to_numpy(), pen='#FFFFFF', symbolBrush='#FFFFFF', symbolPen='#FFFFFF', symbol='o', symbolSize=2, name=\"theta_phase\")\n",
    "# theta_phase_line_actor = plot_item.scatterPlot(spikes_df['t_rel_seconds'].to_nump+y(), spikes_df['theta_phase_radians'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb3fb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "spikes_df.plot.scatter(x='speed', y='theta_phase_radians', title='Speed v. Theta Phase')\n",
    "# .corrcoef(\n",
    "spikes_df[['speed','theta_phase_radians']].corr(method='pearson')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2407cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUITS: spikes_df\n",
    "spikes_df.plot.scatter(x='x', y='theta_phase_radians_per_sec', title='x (pos) v. Theta-freq (rad/sec)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf0dbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUITS: spikes_df\n",
    "spikes_df.plot.scatter(x='speed', y='theta_phase_radians_per_sec', title='Speed v. Theta-freq (rad/sec)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dd4756",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## INPUITS: spikes_df\n",
    "spikes_df.plot.scatter(x='accel', y='theta_phase_radians_per_sec', title='Accel v. Theta-freq (rad/sec)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ff4de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spikes_df[['x','theta_phase_radians']].corr(method='pearson')\n",
    "# spikes_df[['speed','theta_phase_radians']].corr(method='pearson')\n",
    "# spikes_df[['accel','theta_phase_radians']].corr(method='pearson')\n",
    "\n",
    "filtered_spikes_df = deepcopy(spikes_df)\n",
    "filtered_spikes_df = filtered_spikes_df.dropna(how='any', subset=['x', 'speed', 'accel', 'theta_phase_radians_per_sec']) \n",
    "filtered_spikes_df\n",
    "np.corrcoef(filtered_spikes_df['x'].dropna().to_numpy(), filtered_spikes_df['theta_phase_radians_per_sec'].to_numpy())[1, 0]\n",
    "np.corrcoef(filtered_spikes_df['speed'].dropna().to_numpy(), filtered_spikes_df['theta_phase_radians_per_sec'].to_numpy())[1, 0]\n",
    "np.corrcoef(filtered_spikes_df['accel'].dropna().to_numpy(), filtered_spikes_df['theta_phase_radians_per_sec'].to_numpy())[1, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4d6290",
   "metadata": {},
   "outputs": [],
   "source": [
    "x: -0.01011012051718423\n",
    "speed: 0.06179871169990722\n",
    "accel: 0.01011012051718423"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f1a8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.clear_all_3D_time_curves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062d587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.params.time_curves_datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0168c821",
   "metadata": {
    "tags": [
     "2025-06-05_thetaphaseanalysis"
    ]
   },
   "outputs": [],
   "source": [
    "_out = PositionRenderTimeCurves.add_render_time_curves(curr_sess=global_session, destination_plot=active_2d_plot)\n",
    "_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d5149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out.active_data_column_names\n",
    "_out.df\n",
    "_out._data_series_specs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcff71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.params.use_docked_pyqtgraph_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed012e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_docked_pyqtgraph_plots: bool = active_2d_plot.params.use_docked_pyqtgraph_plots\n",
    "use_docked_pyqtgraph_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f57ef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.ui.main_time_curves_view_widget # PlotItem \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed7fcaf",
   "metadata": {
    "tags": [
     "2025-06-05_thetaphaseanalysis"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c806e672",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9738b9d5",
   "metadata": {
    "tags": [
     "2025-06-05_thetaphaseanalysis"
    ]
   },
   "outputs": [],
   "source": [
    "a_widget.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e065c5",
   "metadata": {
    "tags": [
     "2025-06-05_thetaphaseanalysis"
    ]
   },
   "outputs": [],
   "source": [
    "spikes_df['t_rel_seconds'].to_numpy(), spikes_df['theta_phase_radians'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2aa502",
   "metadata": {
    "tags": [
     "2025-06-05_thetaphaseanalysis"
    ]
   },
   "outputs": [],
   "source": [
    "# 'theta_phase_radians'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1beeb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "# %aimport pyphoplacecellanalysis.Analysis.Decoder.context_dependent\n",
    "\n",
    "## Get a specific context to plot: \n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=2, decoder_identifier='long_LR', time_bin_size=0.025, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore')\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', time_bin_size=0.025, known_named_decoding_epochs_type='pbe') # , decoder_identifier='long_LR', masked_time_bin_fill_type='ignore', pfND_ndim=2\n",
    "\n",
    "best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, debug_print=True)\n",
    "print(f'best_matching_context: {best_matching_context}')\n",
    "# a_decoded_marginal_posterior_df\n",
    "## OUTPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder\n",
    "a_decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19730492",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "\n",
    "a_new_fully_generic_result = a_new_fully_generic_result.compute_continuous_fn(curr_active_pipeline=curr_active_pipeline, debug_print=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ba7dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(a_new_fully_generic_result.decoders.keys())\n",
    "\n",
    "\n",
    "search_context = IdentifyingContext(pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global') # , data_grain= 'per_time_bin -- not really relevant: ['masked_time_bin_fill_type', 'known_named_decoding_epochs_type', 'data_grain']\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=search_context, return_multiple_matches=True, debug_print=True)\n",
    "# a_context, a_result, a_decoder, _ = a_new_fully_generic_result.get_results_matching_contexts(context_query=search_context, return_multiple_matches=False, debug_print=True)\n",
    "# a_decoder\n",
    "flat_context_list\n",
    "# flat_decoder_context_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef17ee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get a specific context to plot:\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='long_LR', time_bin_size=0.025, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore')\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore') # , decoder_identifier='long_LR'\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, known_named_decoding_epochs_type='laps') # , masked_time_bin_fill_type='ignore', decoder_identifier='long_LR'\n",
    "\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', time_bin_size=0.025) # , known_named_decoding_epochs_type='laps'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "flat_context_list\n",
    "## OUTPUTS: flat_context_list: List[IdentifyingContext], flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict\n",
    "## OUTPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e64168",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', time_bin_size=0.025) # , known_named_decoding_epochs_type='laps'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "flat_context_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5977a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import build_single_plotly_marginal_scatter_and_hist_over_time\n",
    "\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "epochs_decoding_time_bin_size: float = 0.025\n",
    "\n",
    "#INPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder\n",
    "_flat_out_figs_dict = {}\n",
    "\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "flat_context_list\n",
    "\n",
    "for a_ctxt, a_decoded_marginal_posterior_df in flat_decoded_marginal_posterior_df_context_dict.items():\n",
    "    print(a_ctxt)\n",
    "    \n",
    "    # Add the maze_id to the active_filter_epochs so we can see how properties change as a function of which track the replay event occured on:\n",
    "    a_decoded_marginal_posterior_df = a_decoded_marginal_posterior_df.across_session_identity.add_session_df_columns(session_name=session_name, time_bin_size=epochs_decoding_time_bin_size, curr_session_t_delta=t_delta) # , time_col='t'\n",
    "        \n",
    "    a_fig, a_figure_context = build_single_plotly_marginal_scatter_and_hist_over_time(a_decoded_posterior_df=a_decoded_marginal_posterior_df, a_target_context=a_ctxt)\n",
    "    a_fig = a_fig.update_layout(height=300, margin=dict(t=20, b=0),  # Set top and bottom margins to 0\n",
    "                        )  # Set your desired height\n",
    "    _flat_out_figs_dict[a_figure_context] = a_fig\n",
    "\n",
    "    a_fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eac0c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _plot_plotly_stack_marginal_scatter_and_hist_over_time\n",
    "\n",
    "\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "epochs_decoding_time_bin_size: float = 0.025\n",
    "\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type='laps', data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "_flat_out_figs_dict = _plot_plotly_stack_marginal_scatter_and_hist_over_time(flat_decoded_marginal_posterior_df_context_dict=flat_decoded_marginal_posterior_df_context_dict, session_name=session_name, t_delta=t_delta, epochs_decoding_time_bin_size=epochs_decoding_time_bin_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307e4bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='non_pbe', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type='pbe', data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "_flat_out_figs_dict = _plot_plotly_stack_marginal_scatter_and_hist_over_time(flat_decoded_marginal_posterior_df_context_dict=flat_decoded_marginal_posterior_df_context_dict, session_name=session_name, t_delta=t_delta, epochs_decoding_time_bin_size=epochs_decoding_time_bin_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ff5846",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ensure all optional fields are present before output:\n",
    "# Add the maze_id to the active_filter_epochs so we can see how properties change as a function of which track the replay event occured on:\n",
    "for k in list(a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict.keys()):\n",
    "    a_df = a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict[k]\n",
    "    ## note in per-epoch mode we use the start of the epoch (because for example laps are long and we want to see as soon as it starts) but for time bins we use the center time.\n",
    "    time_column_name: str = TimeColumnAliasesProtocol.find_first_extant_suitable_columns_name(a_df, col_connonical_name='t', required_columns_synonym_dict={\"t\":{'t_bin_center', 'lap_start_t', 'ripple_start_t', 'epoch_start_t'}}, should_raise_exception_on_fail=True)\n",
    "    assert time_column_name in a_df\n",
    "    a_df['delta_aligned_start_t'] = a_df[time_column_name] - t_delta ## subtract off t_delta\n",
    "    a_df = a_df.across_session_identity.add_session_df_columns(session_name=session_name, time_bin_size=epochs_decoding_time_bin_size, curr_session_t_delta=t_delta, time_col=time_column_name)\n",
    "    a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict[k] = a_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4819748",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='non_pbe', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size= 0.025, data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps', known_named_decoding_epochs_type='pbe'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "_flat_out_figs_dict = _plot_plotly_stack_marginal_scatter_and_hist_over_time(flat_decoded_marginal_posterior_df_context_dict=flat_decoded_marginal_posterior_df_context_dict, session_name=session_name, t_delta=t_delta, epochs_decoding_time_bin_size=epochs_decoding_time_bin_size)\n",
    "# flat_decoded_marginal_posterior_df_context_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61b7ea0",
   "metadata": {},
   "source": [
    "#### 🟢🟢⚓🟢🟢 Add to SpikeRaster2D as tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fd2c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot = spike_raster_window.spike_raster_plt_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1b9486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=0.025, masked_time_bin_fill_type='last_valid', data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps'\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=0.025, masked_time_bin_fill_type='ignore', data_grain='per_time_bin', known_named_decoding_epochs_type= 'global') # , known_named_decoding_epochs_type='laps'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "# print(f'flat_context_list: {flat_context_list}')\n",
    "flat_decoded_marginal_posterior_df_context_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963dd30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, DockDisplayColors\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "\n",
    "\n",
    "# search_context = IdentifyingContext(pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global') # , data_grain= 'per_time_bin -- not really relevant: ['masked_time_bin_fill_type', 'known_named_decoding_epochs_type', 'data_grain']\n",
    "# flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=search_context, return_multiple_matches=True, debug_print=True)\n",
    "# # a_context, a_result, a_decoder, _ = a_new_fully_generic_result.get_results_matching_contexts(context_query=search_context, return_multiple_matches=False, debug_print=True)\n",
    "# # a_decoder\n",
    "# flat_context_list\n",
    "# flat_decoder_context_dict\n",
    "\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=0.025, masked_time_bin_fill_type='ignore', data_grain='per_time_bin', known_named_decoding_epochs_type= 'global') # , known_named_decoding_epochs_type='laps'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "# print(f'flat_context_list: {flat_context_list}')\n",
    "flat_decoded_marginal_posterior_df_context_dict\n",
    "\n",
    "unique_decoder_names_map: Dict = {'laps': ['long_LR', 'long_RL', 'short_LR', 'short_RL'], 'non_pbe': ['long', 'short']}\n",
    "\n",
    "\n",
    "for a_ctxt, a_result in flat_result_context_dict.items():\n",
    "    ## INPUTS: laps_pseudo2D_continuous_specific_decoded_result: DecodedFilterEpochsResult\n",
    "    a_decoder = flat_decoder_context_dict[a_ctxt]\n",
    "    \n",
    "    unique_decoder_names = unique_decoder_names_map[a_ctxt.get('trained_compute_epochs', None)] # ['long', 'short']\n",
    "    unique_decoder_names = [f\"{a_ctxt}[{k}]\" for k in unique_decoder_names]\n",
    "    \n",
    "    a_pseudo2D_split_to_1D_continuous_results_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = a_result.split_pseudo2D_result_to_1D_result(pseudo2D_decoder_names_list=unique_decoder_names)    \n",
    "    a_pseudo2D_split_to_1D_continuous_results_dict = {k:v for k, (_o, v) in zip(unique_decoder_names, a_pseudo2D_split_to_1D_continuous_results_dict.items())} ## change to the long unique indicies so they match the decoders\n",
    "    \n",
    "    # a_pseudo2D_split_to_1D_continuous_results_dict\n",
    "    \n",
    "    active_time_bin_size: float = a_result.decoding_time_bin_size\n",
    "    info_string: str = f'{active_time_bin_size:.3f}'\n",
    "    dock_group_sep_character: str = '_'\n",
    "    showCloseButton = True\n",
    "    _common_dock_config_kwargs = {'dock_group_names': [dock_group_sep_character.join([f'LapsDecode', info_string])], 'showCloseButton': showCloseButton, 'showTimelineSyncModeButton': True}\n",
    "\n",
    "    # dock_configs: Dict[str, CustomDockDisplayConfig] = {k:deepcopy(CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_global_dock_colors, **_common_dock_config_kwargs)) for k in unique_decoder_names}\n",
    "    dock_configs: Dict[str, CustomDockDisplayConfig] = {k:deepcopy(CustomDockDisplayConfig(custom_get_colors_callback_fn=DockDisplayColors.get_random_dock_colors_for_key_fn(key=k), **_common_dock_config_kwargs)) for k in unique_decoder_names}\n",
    "    \n",
    "    # flat_decoder_context_dict\n",
    "\n",
    "    # pf1D_Decoder_dict = {k:deepcopy(v) for k, v in a_decoder.items() if k in unique_decoder_names}\n",
    "\n",
    "    pf1D_Decoder_dict = {k:deepcopy(a_decoder) for k in unique_decoder_names} ## this is dumb, but it provides xlims!\n",
    "\n",
    "    output_dict = active_2d_plot.add_docked_decoded_results_dict_tracks(name=f'LapsDecode', a_decoded_result_dict=a_pseudo2D_split_to_1D_continuous_results_dict, dock_configs=dock_configs,\n",
    "                                                                                                pf1D_Decoder_dict=pf1D_Decoder_dict,\n",
    "                                                                                                measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "                                                                                                extended_dock_title_info=info_string)\n",
    "\n",
    "\n",
    "    # # pf1D_Decoder_dict = {k:deepcopy(v) for k, v in a_decoder.items() if k in unique_decoder_names}\n",
    "\n",
    "    # ## a_1D_continuous_decoded_result: SingleEpochDecodedResult\n",
    "    # a_dock_config = dock_configs[a_decoder_name]\n",
    "    # a_1D_decoder: BasePositionDecoder = pf1D_Decoder_dict[a_decoder_name]\n",
    "    # _out_tuple = self.add_docked_decoded_posterior_track_from_result(name=f'{name}[{a_decoder_name}]', a_dock_config=a_dock_config, a_1D_decoded_result=a_1D_decoded_result,\n",
    "    #                                                                                         xbin = deepcopy(a_1D_decoder.xbin), measured_position_df=deepcopy(measured_position_df), **kwargs) # , should_defer_render=False\n",
    "    # identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = _out_tuple\n",
    "    # ## Add `a_decoded_result` to the plots_data\n",
    "    # widget.plots_data.a_decoded_result = a_1D_decoded_result\n",
    "    # widget.plots_data.a_decoder = deepcopy(a_1D_decoder)\n",
    "    # output_dict[a_decoder_name] = (identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem) ## add again\n",
    "\n",
    "\n",
    "# output_dict = active_2d_plot.add_docked_decoded_results_dict_tracks(name=f'LapsDecode', a_decoded_result_dict=a_pseudo2D_split_to_1D_continuous_results_dict, dock_configs=dock_configs, pf1D_Decoder_dict=flat_decoder_context_dict,\n",
    "#                                                                                             measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "#                                                                                             extended_dock_title_info=info_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f0c8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dock_item.sigToggleTimelineSyncModeClicked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31e8981",
   "metadata": {},
   "outputs": [],
   "source": [
    "dock_item.sigToggleTimelineSyncModeClicked.disconnect(_conn)\n",
    "dock_item.sigToggleTimelineSyncModeClicked.disconnect_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bd65ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.sync_matplotlib_render_plot_widget(identifier_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfc623b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, DockDisplayColors\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import SynchronizedPlotMode\n",
    "\n",
    "# epochs_decoding_time_bin_size: float = 0.025\n",
    "epochs_decoding_time_bin_size: float = 0.050\n",
    "# # search_context = IdentifyingContext(pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type= 'nan_filled') # , data_grain= 'per_time_bin -- not really relevant: ['masked_time_bin_fill_type', 'known_named_decoding_epochs_type', 'data_grain']\n",
    "# search_context = IdentifyingContext(pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type= 'ignore')\n",
    "# flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=search_context, return_multiple_matches=True, debug_print=True)\n",
    "# # a_context, a_result, a_decoder, _ = a_new_fully_generic_result.get_results_matching_contexts(context_query=search_context, return_multiple_matches=False, debug_print=True)\n",
    "# # a_decoder\n",
    "# # flat_context_list\n",
    "# flat_decoded_marginal_posterior_df_context_dict\n",
    "\n",
    "for a_ctxt, a_df in flat_decoded_marginal_posterior_df_context_dict.items():\n",
    "    time_bin_size = epochs_decoding_time_bin_size\n",
    "    info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "    plot_row_identifier: str = a_ctxt.get_description(subset_includelist=['known_named_decoding_epochs_type', 'masked_time_bin_fill_type'], include_property_names=True, key_value_separator=':', separator='|', replace_separator_in_property_names='-')\n",
    "    a_time_window_centers = a_df['t_bin_center'].to_numpy() \n",
    "    a_1D_posterior = a_df[['P_Long', 'P_Short']].to_numpy().T\n",
    "\n",
    "    identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dock_item = active_2d_plot.add_docked_marginal_track(name=plot_row_identifier, time_window_centers=a_time_window_centers, a_1D_posterior=a_1D_posterior, extended_dock_title_info=info_string, sync_mode=SynchronizedPlotMode.TO_GLOBAL_DATA)\n",
    "    active_2d_plot.sync_matplotlib_render_plot_widget(identifier=identifier_name, sync_mode=SynchronizedPlotMode.TO_GLOBAL_DATA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdabf069",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.sync_matplotlib_render_plot_widget(identifier=identifier_name, sync_mode=SynchronizedPlotMode.TO_GLOBAL_DATA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa923b9e",
   "metadata": {},
   "source": [
    "### Figures via `figures_plot_generalized_decode_epochs_dict_and_export_results_completion_function`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841dac84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.indexing_helpers import flatten_dict\n",
    "from benedict import benedict\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import figures_plot_generalized_decode_epochs_dict_and_export_results_completion_function, SimpleBatchComputationDummy\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult #, KnownNamedDecoderTrainedComputeEpochsType, KnownNamedDecodingEpochsType, MaskedTimeBinFillType, DataTimeGrain, GenericResultTupleIndexType\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "## Settings:\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "complete_session_context, (session_context, additional_session_context) = curr_active_pipeline.get_complete_session_context()\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | figures_plot_generalized_decode_epochs_dict_and_export_results_completion_function(a_dummy, None,\n",
    "                                                    curr_session_context=complete_session_context,\n",
    "                                                    curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                    across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                    # extreme_threshold=0.5, opacity_max=0.7, thickness_ramping_multiplier=35,\n",
    "                                                    # extreme_threshold=0.8, opacity_max=0.7, thickness_ramping_multiplier=100,\n",
    "                                                    # extreme_threshold=0.5, included_figures_names=['_display_decoded_trackID_marginal_hairy_position'],\n",
    "                                                    # included_figures_names=['_display_generalized_decoded_yellow_blue_marginal_epochs'],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tincluded_figures_names=['_render_export_all_time_tracks'],\n",
    "                                                    # included_figures_names=['_display_generalized_decoded_yellow_blue_marginal_epochs', '_display_decoded_trackID_marginal_hairy_position', '_display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay'],\n",
    "                                                    # included_figures_names=['_display_directional_merged_pf_decoded_stacked_epoch_slices', '_display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay'],\n",
    "                                                )\n",
    "\n",
    "# _across_session_results_extended_dict\n",
    "\n",
    "# 7m 17s\n",
    "\n",
    "\n",
    "## INPUTS: out_custom_formats_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85a9a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# _flattened_paths_dict = {} ## Outputs:\n",
    "# _out_dict = _across_session_results_extended_dict.get('figures_plot_generalized_decode_epochs_dict_and_export_results_completion_function', {}).get('_display_directional_merged_pf_decoded_stacked_epoch_slices', {}) \n",
    "_out_dict = _across_session_results_extended_dict.get('figures_plot_generalized_decode_epochs_dict_and_export_results_completion_function', {}).get('_render_export_all_time_tracks', {}) \n",
    "_out_dict\n",
    "\n",
    "# out_custom_formats_dict = _out_dict['out_custom_formats_dict']\n",
    "## UPDATES: out_custom_formats_dict\n",
    "# out_custom_formats_dict.merge(_out_dict['out_custom_formats_dict'])\n",
    "# save_paths_dict.merge(_out_dict.get('out_paths', {}))\n",
    "# out_custom_formats_dict\n",
    "\n",
    "# print_keys_if_possible('_out_dict', _out_dict, max_depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b3284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.SpecificComputationValidation import DependencyGraph, SpecificComputationValidator, SpecificComputationResultsSpecification\n",
    "# from pyphoplacecellanalysis.General.Model.SpecificComputationValidation import plan_computation_execution\n",
    "\n",
    "# # _comp_specifiers_dict: Dict[str, SpecificComputationValidator] = curr_active_pipeline.get_merged_computation_function_validators()\n",
    "# # validators = deepcopy(_comp_specifiers_dict) # { ... }  # Your validators here\n",
    "# # print(validators)\n",
    "# # graph = DependencyGraph(validators)\n",
    "\n",
    "# # Get the execution plan for a specific computation\n",
    "# computation_plan = plan_computation_execution(curr_active_pipeline, ['directional_decoders_decode_continuous'], debug_print=True)\n",
    "\n",
    "# # Print the execution order\n",
    "# print(\"Functions to execute in order:\")\n",
    "# for i, func_name in enumerate(computation_plan['execution_order']):\n",
    "#     print(f\"{i+1}. {func_name}\")\n",
    "\n",
    "\n",
    "# owning_pipeline_reference.stage.resolve_and_execute_full_required_computation_plan(computation_functions_name_includelist=['directional_decoders_decode_continuous'],\n",
    "#                                         computation_kwargs_list=[{'time_bin_size': time_bin_size, 'should_disable_cache':False}], \n",
    "#                                         enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75be131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: computation_kwargs_list=[{'num_shuffles': 100, 'skip_laps': False, 'minimum_inclusion_fr_Hz':2.0, 'included_qclu_values':[1,2,4,5,6,7]}]\n",
    "computation_kwargs_list=[{'num_shuffles': 100, 'skip_laps': False, 'minimum_inclusion_fr_Hz':2.0, 'included_qclu_values':[1,2,4,5,6,7]}]\n",
    "\n",
    "\n",
    "## Resolve all required pre-req dependencies to execute this function:\n",
    "ordered_required_dependent_computation_fn_names: List[str] = DependencyGraph.resolve_computation_dependencies(curr_active_pipeline, ['directional_decoders_decode_continuous'])\n",
    "# ordered_computation_functions # ['_split_to_directional_laps', '_build_merged_directional_placefields', '_decode_continuous_using_directional_decoders']\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=ordered_required_dependent_computation_fn_names, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=False, force_recompute_override_computations_includelist=[], debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "\n",
    "## OUTPUTS: needs_computation_output_dict\n",
    "if len(remaining_include_function_names) > 0:\n",
    "\tprint(f'have {len(remaining_include_function_names)} functions to compute: {remaining_include_function_names}')\n",
    "\tcurr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=remaining_include_function_names, computation_kwargs_list=computation_kwargs_list, enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "else:\n",
    "\tprint(f'not computations required, have all required keys!')\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6625e5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "active_computation_functions = self.find_registered_computation_functions(computation_functions_name_includelist, search_mode=FunctionsSearchMode.ANY) # find_registered_computation_functions is a pipeline.stage property\n",
    "contains_any_global_functions = np.any([v.is_global for v in active_computation_functions])\n",
    "## INPUTS: computation_kwargs_list=[{'num_shuffles': 100, 'skip_laps': False, 'minimum_inclusion_fr_Hz':2.0, 'included_qclu_values':[1,2,4,5,6,7]}]\n",
    "computation_kwargs_list=[{'num_shuffles': 100, 'skip_laps': False, 'minimum_inclusion_fr_Hz':2.0, 'included_qclu_values':[1,2,4,5,6,7]}]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09bc311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_computed_results_output_list\n",
    "remaining_include_function_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f70cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the execution order\n",
    "print(\"Functions to execute in order:\")\n",
    "for i, func_name in enumerate(computation_plan['execution_order']):\n",
    "    print(f\"{i+1}. {func_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365ee233",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# required_global_computation_results = ['EpochComputations', 'EpochComputations']\n",
    "\n",
    "\n",
    "## Does this not perform the required pre-req computations if they're missing? For example this function requires: `requires_global_keys=['DirectionalLaps', 'DirectionalMergedDecoders']`, so does it do those if they're missing, or not because they aren't in the computations list?\n",
    "owning_pipeline_reference.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'],\n",
    "                                        computation_kwargs_list=[{'time_bin_size': time_bin_size, 'should_disable_cache':False}], \n",
    "                                        enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b53706f",
   "metadata": {},
   "source": [
    "### Fig4 - Replay Examples - \n",
    "`K:\\scratch\\collected_outputs\\figures\\_temp_individual_posteriors\\2025-07-23\\gor01_one_2006-6-09_1-22-43\\ripple\\combined\\viridis_shared_norm`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1c7e7a",
   "metadata": {},
   "source": [
    "Relies heavily on `PosteriorExporting.post_export_build_combined_images`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048c713f",
   "metadata": {
    "tags": [
     "2025-07-23",
     "run-group-publication",
     "2025-07-25"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import figures_plot_generalized_decode_epochs_dict_and_export_results_completion_function, SimpleBatchComputationDummy\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult #, KnownNamedDecoderTrainedComputeEpochsType, KnownNamedDecodingEpochsType, MaskedTimeBinFillType, DataTimeGrain, GenericResultTupleIndexType\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "## Settings:\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "complete_session_context, (session_context, additional_session_context) = curr_active_pipeline.get_complete_session_context()\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | figures_plot_generalized_decode_epochs_dict_and_export_results_completion_function(a_dummy, None,\n",
    "                                                    curr_session_context=complete_session_context,\n",
    "                                                    curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                    across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                    # extreme_threshold=0.5, opacity_max=0.7, thickness_ramping_multiplier=35,\n",
    "                                                    # extreme_threshold=0.8, opacity_max=0.7, thickness_ramping_multiplier=100,\n",
    "                                                    # extreme_threshold=0.5, included_figures_names=['_display_decoded_trackID_marginal_hairy_position'],\n",
    "                                                    included_figures_names=['_display_trial_to_trial_reliability'],\n",
    "                                                    # included_figures_names=['_display_generalized_decoded_yellow_blue_marginal_epochs', '_display_decoded_trackID_marginal_hairy_position', '_display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay'],\n",
    "                                                    # included_figures_names=['_display_directional_merged_pf_decoded_stacked_epoch_slices', '_display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay'],\n",
    "                                                )\n",
    "\n",
    "# _across_session_results_extended_dict\n",
    "\n",
    "# 7m 17s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9910893",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"K:\\scratch\\collected_outputs\\figures\\_temp_individual_posteriors\\2025-08-13\\gor01_one_2006-6-09_1-22-43\\ripple\\combined\\greyscale\\mergedG_ripple[1].png\"\n",
    "\"K:\\scratch\\collected_outputs\\figures\\_temp_individual_posteriors\\2025-08-13\\gor01_one_2006-6-09_1-22-43\\ripple\\combined\\greyscale_shared_norm\\mergedG_ripple[1].png\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f0f35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_across_session_results_extended_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f011fdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.indexing_helpers import flatten_dict\n",
    "from benedict import benedict\n",
    "\n",
    "## INPUTS: out_custom_formats_dict\n",
    "\n",
    "# _flattened_paths_dict = {} ## Outputs:\n",
    "\n",
    "# _out_dict = _across_session_results_extended_dict.get('figures_plot_generalized_decode_epochs_dict_and_export_results_completion_function', {}).get('_display_directional_merged_pf_decoded_stacked_epoch_slices', {}) \n",
    "_out_dict = _across_session_results_extended_dict.get('figures_plot_generalized_decode_epochs_dict_and_export_results_completion_function', {}).get('_display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay', {}) \n",
    "\n",
    "# _out_dict\n",
    "\n",
    "out_custom_formats_dict = _out_dict['out_custom_formats_dict']\n",
    "## UPDATES: out_custom_formats_dict\n",
    "# out_custom_formats_dict.merge(_out_dict['out_custom_formats_dict'])\n",
    "# save_paths_dict.merge(_out_dict.get('out_paths', {}))\n",
    "# out_custom_formats_dict\n",
    "\n",
    "# print_keys_if_possible('_out_dict', _out_dict, max_depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e316e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_keys_if_possible('out_custom_formats_dict', out_custom_formats_dict, max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26828c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_merge_layout_dict = [['greyscale'],\n",
    "    ['greyscale_shared_norm'],\n",
    "    # ['psuedo2D_ignore/raw_rgba'], ## Implicitly always appends the pseudo2D_ignore/raw_rgba image at the bottom row\n",
    "]\n",
    "\n",
    "\n",
    "# custom_merge_layout_dict = [['greyscale', 'greyscale_shared_norm'],\n",
    "#     # ['psuedo2D_ignore/raw_rgba'], ## Implicitly always appends the pseudo2D_ignore/raw_rgba image at the bottom row\n",
    "# ]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebac89b1",
   "metadata": {
    "tags": [
     "2025-08-13",
     "posterior-export"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "\n",
    "_out_final_merged_image_save_paths, _out_final_merged_images = PosteriorExporting.post_export_build_combined_images(out_custom_formats_dict=out_custom_formats_dict, custom_merge_layout_dict=custom_merge_layout_dict,\n",
    "                                                                                                                    epoch_name_list = ['ripple'],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# included_epoch_idxs=None,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# included_epoch_idxs=[4],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t#  included_epoch_idxs=np.arange(4,10),\n",
    "                                                                                                                    progress_print=True)\n",
    "_out_final_merged_image_save_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c688f43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_final_merged_image_save_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872d1799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d3570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "export_paths = _out_dict['export_paths']\n",
    "save_paths_dict = benedict(_out_dict.get('export_paths', {}))\n",
    "parent_specific_session_output_folder = _out_dict['parent_specific_session_output_folder']\n",
    "\n",
    "# save_paths_dict = _out_dict.get('out_paths', {})\n",
    "# for epoch_name, a_variant_paths_dict in save_paths_dict.items():\n",
    "# \t## loop over all variants:\n",
    "#     for a_variant_name, a_path in a_variant_paths_dict.items():\n",
    "#         if a_path is not None:\n",
    "#             _curr_key = f\"{epoch_name}.{a_variant_name}\"\n",
    "#             _flattened_paths_dict[_curr_key] = a_path\n",
    "\n",
    "\n",
    "# _flattened_paths_dict\n",
    "\n",
    "# {'laps.psuedo2D_nan_filled': Path('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/array_to_images/2025-05-16/gor01_one_2006-6-08_14-26-15_trackID_weighted_position_posterior/laps/psuedo2D_nan_filled'),\n",
    "#  'ripple.psuedo2D_nan_filled': Path('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/array_to_images/2025-05-16/gor01_one_2006-6-08_14-26-15_trackID_weighted_position_posterior/ripple/psuedo2D_nan_filled')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d173192",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.image_helpers import ImageHelpers\n",
    "from pyphocorehelpers.plotting.media_output_helpers import vertical_image_stack, horizontal_image_stack, image_grid # used in `_subfn_build_combined_output_images`\n",
    "\n",
    "def build_horizontally_concatenated_images_from_export_folder(image_folder_path: Path, image_glob: str = \"*.png\", x_padding: int = 2, canvas_image_node_scale: float=None, max_num_to_add: int = 1000, combined_img_padding=4, combined_img_separator_color=None, debug_print = False):\n",
    "    \"\"\" Adds the images matching the glob in the `image_folder_path` to the canvas, or creates a new canvas, as needed\n",
    "    \n",
    "    Usage:\n",
    "    \n",
    "        img_export_folder = Path('K:/scratch/collected_outputs/figures/_temp_individual_posteriors/2025-06-03/gor01_two_2006-6-12_16-53-46/ripple/combined/multi').resolve()\n",
    "        Assert.path_exists(img_export_folder)\n",
    "        _img_path, _single_epoch_combined_img = build_horizontally_concatenated_images_from_export_folder(image_folder_path=img_export_folder, image_glob=\"p_x_given_n*.png\",\n",
    "                                                                                                        #    combined_img_padding=8, combined_img_separator_color='#1eff00',\n",
    "                                                                                                        combined_img_padding=8, combined_img_separator_color='#061304',\n",
    "                                                                                                        )\n",
    "        _img_path\n",
    "\n",
    "    \"\"\"\n",
    "    from pyphocorehelpers.image_helpers import ImageHelpers\n",
    "    from pyphocorehelpers.plotting.media_output_helpers import vertical_image_stack, horizontal_image_stack, image_grid # used in `_subfn_build_combined_output_images`\n",
    "    \n",
    "\n",
    "    def _subfn_get_img_obsidian_global_unique_name(an_img_path: Path) -> str:    \n",
    "        \"\"\" from my personal export path conventions, builds a globally unique image name (which has to be the case for a canvas)\"\"\"\n",
    "        \n",
    "        img_path_name_parts = an_img_path.parts\n",
    "        date_part_index = next((i for i, part in enumerate(img_path_name_parts) if re.match(r'^\\d{4}-\\d{2}-\\d{2}', part)), None)\n",
    "        session_part_index: int = date_part_index + 1\n",
    "        img_out_context_parts: List[str] = img_path_name_parts[session_part_index:] # ('gor01_two_2006-6-07_16-40-19_normal_computed_[1, 2]_5.0', 'ripple', 'psuedo2D_nan_filled', 'raw_rgba', 'p_x_given_n[9].png')\n",
    "        return '-'.join(img_out_context_parts) # 'gor01_two_2006-6-07_16-40-19_normal_computed_[1, 2]_5.0-ripple-psuedo2D_nan_filled-raw_rgba-p_x_given_n[9].png'\n",
    "\n",
    "\n",
    "    # ==================================================================================================================================================================================================================================================================================== #\n",
    "    # BEGIN FUNCTION BODY                                                                                                                                                                                                                                                                  #\n",
    "    # ==================================================================================================================================================================================================================================================================================== #\n",
    "    images_dict: Dict = ImageHelpers.load_png_images_pathlib(image_folder_path, image_glob=image_glob)\n",
    "    n_images: int = len(images_dict)\n",
    "    # Print the loaded images\n",
    "    print(f\"Loaded {len(images_dict)} PNG images from '{image_folder_path}'.\")\n",
    "\n",
    "    _output_combined_dir = image_folder_path # joinpath(joined_export_folder_name, custom_export_format_series_name).resolve()\n",
    "    # _output_combined_dir.mkdir(parents=True, exist_ok=True)\n",
    "    _output_combined_image_save_dirs = []\n",
    "\n",
    "    n_added: int = 0\n",
    "    \n",
    "    # text_node = TextNode(x=initial_x, y=initial_y, width=200, height=100, text=f\"#{image_group_name}\")\n",
    "    # target_canvas.add_node(text_node)\n",
    "    flat_image_list = []\n",
    "    if canvas_image_node_scale is None:\n",
    "        canvas_image_node_scale = 1.0\n",
    "        \n",
    "    image_sizes = np.vstack([(int(round(canvas_image_node_scale * float(an_img.size[0]))), int(round(canvas_image_node_scale * float(an_img.size[1])))) for i, (img_name, an_img) in enumerate(images_dict.items())]) # (n_images, 2)\n",
    "    # if debug_print:\n",
    "    #     print(f'image_sizes: {np.shape(image_sizes)}, max_img_sizes: {np.max(image_sizes, axis=0)}')\n",
    "\n",
    "    # total_grouped_image_size = np.sum(image_sizes, axis=0)\n",
    "    \n",
    "    if debug_print:\n",
    "        print(f'max_img_sizes: {np.max(image_sizes, axis=0)}')\n",
    "\n",
    "    total_grouped_image_size = (np.sum(image_sizes[:, 0], axis=0), np.max(image_sizes[:, 1], axis=0))  ## since being stacked horizontally, use the sum of the widths, but the max of the heights\n",
    "    total_grouped_images_padding = (int(round(float(x_padding)*float(n_images-1))), 0)\n",
    "\n",
    "    group_padding = np.array((50, 30))\n",
    "    total_group_size = total_grouped_image_size + np.array(total_grouped_images_padding) + (2 * group_padding)\n",
    "    # group_offset = np.array((initial_x, initial_y)) - group_padding\n",
    "        \n",
    "    a_found_filename: Optional[str] = None\n",
    "    for i, (img_name, an_img) in enumerate(images_dict.items()):\n",
    "        if i < max_num_to_add:\n",
    "            an_img_path: Path = image_folder_path.joinpath(f'{img_name}.png')\n",
    "            assert an_img_path.exists(), f\"an_img_path: {an_img_path} does not exist\"        \n",
    "            if a_found_filename is None:\n",
    "                a_found_filename = deepcopy(an_img_path.stem)\n",
    "            # global_unique_image_filename: str = f\"{_subfn_get_img_obsidian_global_unique_name(an_img_path=an_img_path)}\"\n",
    "            an_img_width, an_img_height = an_img.size            \n",
    "            if canvas_image_node_scale is not None:\n",
    "                an_img_width = int(round(canvas_image_node_scale * float(an_img_width)))\n",
    "                an_img_height = int(round(canvas_image_node_scale * float(an_img_height)))\n",
    "            # node_url_str: str = vault_relative_image_dir_filepath\n",
    "            # node_url_str: str = an_img_vault_filepath.relative_to(obsidian_vault_root_path).as_posix()\n",
    "            # file_node = FileNode(x=initial_x, y=initial_y, width=an_img_width, height=an_img_height, file=node_url_str)\n",
    "            # target_canvas.add_node(file_node)\n",
    "            flat_image_list.append(an_img)\n",
    "            # initial_x = initial_x + an_img_width + x_padding\n",
    "            n_added = n_added + 1\n",
    "            \n",
    "        else:\n",
    "            # print(f'skipping because max_num_to_add: {max_num_to_add}')\n",
    "            pass\n",
    "        \n",
    "    # END for i, (img_name, an_i...\n",
    "    print(f'added {n_added} images to canvas.')\n",
    "    \n",
    "    ## OUTPUT: flat_image_list\n",
    "    \n",
    "    _single_epoch_combined_img = horizontal_image_stack(flat_image_list, padding=combined_img_padding, separator_color=combined_img_separator_color)\n",
    "    _single_epoch_combined_img\n",
    "    \n",
    "    ## Save the image:\n",
    "    _img_path = _output_combined_dir.joinpath(f'merged_{a_found_filename}.png').resolve()\n",
    "    _single_epoch_combined_img.save(_img_path)\n",
    "    # _output_combined_image_save_dirs.append(_img_path)\n",
    "\n",
    "    return _img_path, _single_epoch_combined_img\n",
    "\n",
    "\n",
    "img_export_folder = Path('K:/scratch/collected_outputs/figures/_temp_individual_posteriors/2025-06-03/gor01_two_2006-6-12_16-53-46/ripple/combined/multi').resolve()\n",
    "Assert.path_exists(img_export_folder)\n",
    "_img_path, _single_epoch_combined_img = build_horizontally_concatenated_images_from_export_folder(image_folder_path=img_export_folder, image_glob=\"p_x_given_n*.png\",\n",
    "                                                                                                #    combined_img_padding=8, combined_img_separator_color='#1eff00',\n",
    "                                                                                                   combined_img_padding=8, combined_img_separator_color='#061304',\n",
    "                                                                                                   )\n",
    "_img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c86190",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# _flattened_paths_dict = {} ## Outputs:\n",
    "\n",
    "_out_dict = _across_session_results_extended_dict.get('figures_plot_generalized_decode_epochs_dict_and_export_results_completion_function', {}).get('_display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay', {}) # FigureCollector \n",
    "save_paths_dict = _out_dict.get('out_paths', {})\n",
    "out_custom_formats_dict = _out_dict['out_custom_formats_dict']\n",
    "\n",
    "# out_custom_formats_dict = benedict(_out_dict['out_custom_formats_dict'])\n",
    "parent_output_folder = _out_dict['parent_output_folder']\n",
    "_parent_save_context = _out_dict['parent_save_context']\n",
    "\n",
    "parent_output_folder\n",
    "_parent_save_context\n",
    "\n",
    "_specific_session_output_folder = _out_dict['parent_specific_session_output_folder']\n",
    "_specific_session_output_folder\n",
    "# {'laps.psuedo2D_nan_filled': Path('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/array_to_images/2025-05-16/gor01_one_2006-6-08_14-26-15_trackID_weighted_position_posterior/laps/psuedo2D_nan_filled'),\n",
    "#  'ripple.psuedo2D_nan_filled': Path('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/array_to_images/2025-05-16/gor01_one_2006-6-08_14-26-15_trackID_weighted_position_posterior/ripple/psuedo2D_nan_filled')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd430d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "\n",
    "out_custom_formats_dict = _out_dict.get('out_custom_formats_dict', None)\n",
    "if out_custom_formats_dict is not None:\n",
    "    _out_final_merged_image_save_paths, _out_final_merged_images = PosteriorExporting.post_export_build_combined_images(out_custom_formats_dict=out_custom_formats_dict)\n",
    "    _out_dict['final_merged_image_save_paths'] = deepcopy(_out_final_merged_image_save_paths)\n",
    "    # across_session_results_extended_dict['figures_plot_generalized_decode_epochs_dict_and_export_results_completion_function'].update({\n",
    "    #     '_display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay': _out,\n",
    "    # })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fda2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_dict['final_merged_image_save_paths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b417db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_custom_formats_dict = benedict(out_custom_formats_dict)\n",
    "\n",
    "save_paths_dict.keypaths()\n",
    "save_paths_dict.flatten(separator='|')\n",
    "# list(out_custom_formats_dict.keys())\n",
    "# out_custom_formats_dict.keypaths()\n",
    "# out_custom_formats_dict.merge()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cf4e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_custom_formats_dict['ripple'].keypaths()\n",
    "\n",
    "active_decoder_names = ['long_LR', 'long_RL', 'short_LR', 'short_RL', 'psuedo2D_ignore']\n",
    "out_custom_formats_dict['ripple.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70609d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.plotting.media_output_helpers import vertical_image_stack, horizontal_image_stack, image_grid\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "\n",
    "_out_final_merged_image_save_paths, _out_final_merged_images = PosteriorExporting.post_export_build_combined_images(out_custom_formats_dict=out_cusstom_formats_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e39fa1f",
   "metadata": {},
   "source": [
    "### Export to image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31ee8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.data_exporting import HeatmapExportConfig\n",
    "from benedict import benedict\n",
    "\n",
    "# Run an export function again _______________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________ #\n",
    "pseudo2D_split_to_1D_custom_export_formats: Dict[str, HeatmapExportConfig] = {\n",
    "    # 'greyscale_shared_norm': HeatmapExportConfig.init_greyscale(desired_height=desired_height, post_render_image_functions_builder_fn=ImagePostRenderFunctionSets._build_no_op_image_export_functions_dict),\n",
    "    'viridis_shared_norm': HeatmapExportConfig(colormap='viridis', vmin=0.0, vmax=1.0, export_kind=HeatmapExportKind.COLORMAPPED, desired_height=desired_height, post_render_image_functions_builder_fn=ImagePostRenderFunctionSets._build_no_op_image_export_functions_dict),\n",
    "}\n",
    "\n",
    "\n",
    "pseudo2D_split_to_1D_out_paths, pseudo2D_split_to_1D_out_custom_formats_dict = PosteriorExporting.perform_export_all_decoded_posteriors_as_images(decoder_laps_filter_epochs_decoder_result_dict=None,\n",
    "                                                                                                            decoder_ripple_filter_epochs_decoder_result_dict=a_pseudo2D_split_to_1D_continuous_results_dict, ## just the ripples\n",
    "                                                                                                        _save_context=_parent_save_context, parent_output_folder=_specific_session_output_folder,\n",
    "                                                                                                        desired_height=desired_height, custom_export_formats=pseudo2D_split_to_1D_custom_export_formats, combined_img_padding=6, combined_img_separator_color=(0, 0, 0, 0))\n",
    "if not isinstance(graphics_output_dict['out_paths'], benedict):\n",
    "    graphics_output_dict['out_paths'] = benedict(graphics_output_dict['out_paths']) # 'out_paths': out_paths\n",
    "# graphics_output_dict['out_paths'].merge(pseudo2D_split_to_1D_out_paths)\n",
    "graphics_output_dict['out_paths'].merge({k:v for k, v in pseudo2D_split_to_1D_out_paths.items() if (v is not None)})\n",
    "\n",
    "if not isinstance(graphics_output_dict['out_custom_formats_dict'], benedict):\n",
    "    graphics_output_dict['out_custom_formats_dict'] = benedict(graphics_output_dict['out_custom_formats_dict']) # 'out_paths': out_paths\n",
    "# graphics_output_dict['out_custom_formats_dict'].merge(pseudo2D_split_to_1D_out_custom_formats_dict)\n",
    "graphics_output_dict['out_custom_formats_dict'].merge({k:v for k, v in pseudo2D_split_to_1D_out_custom_formats_dict.items() if (v is not None)})\n",
    "\n",
    "# print(f'\\tout_paths: {pseudo2D_split_to_1D_out_paths}')\n",
    "print(f'done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b704eaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo2D_split_to_1D_out_paths = benedict(pseudo2D_split_to_1D_out_paths)\n",
    "pseudo2D_split_to_1D_out_custom_formats_dict = benedict(pseudo2D_split_to_1D_out_custom_formats_dict)\n",
    "# pseudo2D_split_to_1D_out_paths\n",
    "pseudo2D_split_to_1D_out_custom_formats_dict.keypaths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9767c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo2D_split_to_1D_out_custom_formats_dict['laps/long_LR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1e68a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo2D_split_to_1D_out_custom_formats_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbee9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.plotting.media_output_helpers import vertical_image_stack, horizontal_image_stack, image_grid\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "\n",
    "_out_final_merged_image_save_paths, _out_final_merged_images = PosteriorExporting.post_export_build_combined_images(pseudo2D_split_to_1D_out_custom_formats_dict)\n",
    "_out_final_merged_image_save_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f6be07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "an_active_img.reduce(factor=(4, 1)) ## scale image down by 1/4 in height but leave the original width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960a6580",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_posterior_saved_path\n",
    "merged_dir\n",
    "a_merged_posterior_export_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e86294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_final_merged_image_save_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b2a66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_final_merged_images[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837c717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_paths_dict.keypaths()\n",
    "save_paths_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22507ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_custom_formats_dict.keypaths()\n",
    "# out_custom_formats_dict.flatten()\n",
    "# out_custom_formats_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b414b333",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c014e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_paths = benedict(_out_dict['export_paths'])\n",
    "flat_export_paths = export_paths.flatten(separator='|')\n",
    "flat_export_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9f4712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d631bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_generalized_decoded_yellow_blue_marginal_epochs', curr_active_pipeline.get_session_context(), defer_render=True, save_figure=True, is_dark_mode=False) # , override_fig_man=custom_fig_man\n",
    "collector = _out['collector'] # FigureCollector \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62b582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "\n",
    "_out = curr_active_pipeline.display('_display_decoded_trackID_marginal_hairy_position', curr_active_pipeline.get_session_context(), defer_render=False, save_figure=False,\n",
    "\t\t\t\t\t\t\t\t\t#  extreme_threshold=0.5, \n",
    "                                    # opacity_max=0.7, thickness_ramping_multiplier=35,\n",
    "\t\t\t\t\t\t\t\t\textreme_threshold=0.8, opacity_max=0.7, thickness_ramping_multiplier=50,\n",
    "                                    #  prob_to_thickness_ramping_function= lambda p: max(0.0, (p - 0.5) * 15),\n",
    "                                    #  extreme_threshold=0.9, prob_to_thickness_ramping_function= lambda p: 6.0, ## constant for all probabilities\n",
    "\t\t\t\t\t\t\t\t\t#  extreme_threshold=0.1, prob_to_thickness_ramping_function= lambda p: (5.0 * p), \n",
    "\t\t\t\t\t\t\t\t\t#  ax = \n",
    "\t\t\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t\t\t ) # , override_fig_man=custom_fig_man\n",
    "collector = _out['collector'] # FigureCollector \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0a34b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3361b476",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed96530e",
   "metadata": {},
   "source": [
    "### Figures via `figures_plot_generalized_decode_epochs_dict_and_export_results_completion_function`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcece57",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_10_'></a>[Call `export_session_h5_file_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e847ed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyphoplacecellanalysis.General.type_aliases as types\n",
    "from neuropy.utils.mixins.binning_helpers import BinningContainer, BinningInfo\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import export_session_h5_file_completion_function, SimpleBatchComputationDummy\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult #, KnownNamedDecoderTrainedComputeEpochsType, KnownNamedDecodingEpochsType, MaskedTimeBinFillType, DataTimeGrain, GenericResultTupleIndexType\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | export_session_h5_file_completion_function(a_dummy, None,\n",
    "                                                    curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                    across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tshould_write_pipeline_h5=False, should_write_posterior_h5=True)\n",
    "\n",
    "callback_outputs = _across_session_results_extended_dict['export_session_h5_file_completion_function']\n",
    "posteriors_save_path: Path = callback_outputs.get('posteriors_h5', None)\n",
    "if posteriors_save_path is not None:\n",
    "\tposteriors_save_path\n",
    "# hdf5_output_path: Dict[str, Path] = callback_outputs['hdf5_output_path']\n",
    "# Assert.path_exists(hdf5_output_path)\n",
    "# hdf5_output_path\n",
    "# \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e2705a",
   "metadata": {},
   "source": [
    "# <a id='toc24_'></a>[2025-03-04 - Final Histogram](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7a94ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benedict import benedict\n",
    "filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict = benedict(a_general_decoder_dict_decoded_epochs_dict_result.filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict)\n",
    "filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict.keypaths() # ['laps', 'laps.ignore', 'laps.last_valid', 'laps.nan_filled', 'non_pbe', 'non_pbe.ignore', 'non_pbe.last_valid', 'non_pbe.nan_filled', 'pbe', 'pbe.ignore', 'pbe.last_valid', 'pbe.nan_filled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cb49e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "template: str = 'plotly_dark' # set plotl template\n",
    "pio.templates.default = template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed73ff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_export_path = Path(r'K:\\scratch\\output').resolve()\n",
    "non_pbe_marginals_PKL_export_path: Path = non_pbe_marginals_export_basepath.with_suffix('.pkl').resolve()\n",
    "a_general_decoder_dict_decoded_epochs_dict_result.save(pkl_output_path=non_pbe_marginals_PKL_export_path)\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26590c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_a_general_decoder_dict_decoded_epochs_dict_result: GeneralDecoderDictDecodedEpochsDictResult =  GeneralDecoderDictDecodedEpochsDictResult.from_file(pkl_path=non_pbe_marginals_PKL_export_path)\n",
    "loaded_a_general_decoder_dict_decoded_epochs_dict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fde2b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_pbe_marginals_export_basepath = parent_export_path.joinpath(f'{BATCH_DATE_TO_USE}_non_pbe_marginals_export')\n",
    "non_pbe_marginals_HDF5_export_path: Path = non_pbe_marginals_export_basepath.with_suffix('.h5').resolve()\n",
    "a_general_decoder_dict_decoded_epochs_dict_result.to_hdf(file_path=non_pbe_marginals_HDF5_export_path, key='a_general_decoder_dict_decoded_epochs_dict_result', debug_print=True) # , OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c933ae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: a_new_fully_generic_result\n",
    "BATCH_DATE_TO_USE: str = f'2025-04-11_Apogee'\n",
    "\n",
    "# parent_export_path = Path('/home/halechr/repos/Spike3D/data').resolve()\n",
    "parent_export_path = Path('data').resolve()\n",
    "\n",
    "a_new_fully_generic_result_export_basepath = parent_export_path.joinpath(f'{BATCH_DATE_TO_USE}_a_new_fully_generic_result')\n",
    "# a_new_fully_generic_result_HDF5_export_path: Path = a_new_fully_generic_result_export_basepath.with_suffix('.h5').resolve()\n",
    "# a_new_fully_generic_result.to_hdf(file_path=a_new_fully_generic_result_HDF5_export_path, key='a_new_fully_generic_result', debug_print=True, OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True) # , OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True\n",
    "\n",
    "out_PKL_export_path: Path = a_new_fully_generic_result_export_basepath.with_suffix('.pkl').resolve()\n",
    "print(f'out_PKL_export_path: {out_PKL_export_path}')\n",
    "a_new_fully_generic_result.save(pkl_output_path=out_PKL_export_path)\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a003258",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loaded_a_general_decoder_dict_decoded_epochs_dict_result: GeneralDecoderDictDecodedEpochsDictResult =  GeneralDecoderDictDecodedEpochsDictResult.from_file(pkl_path=out_PKL_export_path)\n",
    "loaded_a_general_decoder_dict_decoded_epochs_dict_result\n",
    "non_pbe_marginals_export_basepath = parent_export_path.joinpath(f'{BATCH_DATE_TO_USE}_non_pbe_marginals_export')\n",
    "non_pbe_marginals_HDF5_export_path: Path = non_pbe_marginals_export_basepath.with_suffix('.h5').resolve()\n",
    "a_general_decoder_dict_decoded_epochs_dict_result.to_hdf(file_path=non_pbe_marginals_HDF5_export_path, key='a_general_decoder_dict_decoded_epochs_dict_result', debug_print=True) # , OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02555045",
   "metadata": {},
   "outputs": [],
   "source": [
    "## OUTPUTS: flat_context_list: List[IdentifyingContext], flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict\n",
    "## OUTPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc27e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute and plot the new tracks:\n",
    "# non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict, non_PBE_marginal_over_track_ID, (time_bin_containers, time_window_centers) = nonPBE_results._build_merged_joint_placefields_and_decode(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)))\n",
    "unique_added_track_identifiers = nonPBE_results.add_to_SpikeRaster2D_tracks(active_2d_plot=active_2d_plot, non_PBE_all_directional_pf1D_Decoder=non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result=pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict=continuous_decoded_results_dict, non_PBE_marginal_over_track_ID=non_PBE_marginal_over_track_ID, time_window_centers=time_window_centers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8a218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.enable_interaction_events_debug_print = True\n",
    "spike_raster_window.enable_debug_print = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645e0aa6",
   "metadata": {
    "tags": [
     "active-2025-03-11"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import build_single_plotly_marginal_scatter_and_hist_over_time\n",
    "\n",
    "#INPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder\n",
    "_flat_out_figs_dict = {}\n",
    "a_fig, a_figure_context = build_single_plotly_marginal_scatter_and_hist_over_time(a_decoded_posterior_df=a_decoded_marginal_posterior_df, a_target_context=a_target_context)\n",
    "_flat_out_figs_dict[a_figure_context] = a_fig\n",
    "\n",
    "a_fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d39b4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoded_marginal_posterior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69dd71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = a_general_decoder_dict_decoded_epochs_dict_result.build_plotly_marginal_scatter_and_hist_over_time()\n",
    "\n",
    "# _flat_out_figs_dict = a_general_decoder_dict_decoded_epochs_dict_result.build_plotly_marginal_scatter_and_hist_over_time(debug_print=False)\n",
    "\n",
    "# display(list(_flat_out_figs_dict.values())[0])\n",
    "\n",
    "# Display all figures in the dictionary\n",
    "for fig in _flat_out_figs_dict.values():\n",
    "    display(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33e4ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_pre_post_delta_scatter\n",
    "## INPUTS: a_general_decoder_dict_decoded_epochs_dict_result\n",
    "\n",
    "histogram_bins: int = 25\n",
    "debug_print = False\n",
    "# 'masked_laps': 'Laps (Masked)', 'masked_laps': 'Laps (Nan-masked)')\n",
    "# masked_bin_fill_modes: ['ignore', 'last_valid', 'nan_filled', 'dropped']\n",
    "\n",
    "_flat_out_figs_dict = {}\n",
    "\n",
    "for a_known_decoded_epochs_type, a_decoded_posterior_dfs_dict in a_general_decoder_dict_decoded_epochs_dict_result.filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict.items():\n",
    "    if debug_print:\n",
    "        print(f'a_known_decoded_epochs_type: \"{a_known_decoded_epochs_type}\"')\n",
    "    for masking_bin_fill_mode, a_decoded_posterior_df in a_decoded_posterior_dfs_dict.items():\n",
    "        if debug_print:\n",
    "            print(f'\\tmasking_bin_fill_mode: \"{masking_bin_fill_mode}\"')\n",
    "        plot_row_identifier: str = f'{a_known_decoded_epochs_type.capitalize()} - {masking_bin_fill_mode.capitalize()} decoder' # should be like 'Laps (Masked) from Non-PBE decoder'\n",
    "        \n",
    "        fig, figure_context = plotly_pre_post_delta_scatter(data_results_df=deepcopy(a_decoded_posterior_df), out_scatter_fig=None, \n",
    "                                        histogram_variable_name='P_Short', hist_kwargs=dict(), histogram_bins=histogram_bins,\n",
    "                                        common_plot_kwargs=dict(),\n",
    "                                        px_scatter_kwargs = dict(x='delta_aligned_start_t', y='P_Short', title=plot_row_identifier))\n",
    "        _flat_out_figs_dict[figure_context] = fig\n",
    "        \n",
    "# ['laps', 'non_PBE']\n",
    "# ['a', 'masked', 'dropping_masked']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b1d063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(list(_flat_out_figs_dict.values())[0])\n",
    "\n",
    "# # Display all figures in the dictionary\n",
    "# for fig in _flat_out_figs_dict.values():\n",
    "#     display(fig)\n",
    "\n",
    "from pyphoplacecellanalysis.External.pyqtgraph.Qt import QtWidgets\n",
    "from pyphoplacecellanalysis.External.pyqtgraph.dockarea import DockArea, Dock\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.PlotlyFigurePyQtWidget import PlotlyDockContainer, PlotlyWidget\n",
    "\n",
    "## INPUTS: _flat_out_figs_dict\n",
    "# Create the container\n",
    "container: PlotlyDockContainer = PlotlyDockContainer()\n",
    "# Display all figures in the dictionary\n",
    "for a_fig_context, fig in _flat_out_figs_dict.items():\n",
    "    container.add_figure(fig, name=f\"{a_fig_context}\", position='bottom')\n",
    "\n",
    "# Show the container\n",
    "container.resize(1200, 800)\n",
    "container.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d06c39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bf036ef",
   "metadata": {},
   "source": [
    "### <a id='toc24_1_1_'></a>[Plotting Tracks on Spike2DRaster](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b821068",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Never used: all at once:\n",
    "a_dock_config = None\n",
    "_out_tuple = active_2d_plot.add_docked_decoded_posterior_track_from_result(name=f'laps_pseudo2D_continuous_specific_decoded_result', a_dock_config=a_dock_config, a_1D_decoded_result=laps_pseudo2D_continuous_specific_decoded_result,\n",
    "                                                                                xbin = deepcopy(non_PBE_all_directional_pf1D_Decoder.xbin), measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "                                                                                extended_dock_title_info='test')\n",
    "active_2d_plot.sync_matplotlib_render_plot_widget(identifier=identifier_name, sync_mode=SynchronizedPlotMode.TO_GLOBAL_DATA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb37b1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, DockDisplayColors\n",
    "\n",
    "active_time_bin_size: float = pseudo2D_continuous_specific_decoded_result.decoding_time_bin_size\n",
    "info_string: str = f'{active_time_bin_size:.3f}'\n",
    "dock_group_sep_character: str = '_'\n",
    "showCloseButton = True\n",
    "_common_dock_config_kwargs = {'dock_group_names': [dock_group_sep_character.join([f'LapsDecode', info_string])], 'showCloseButton': showCloseButton}\n",
    "dock_configs: Dict[str, CustomDockDisplayConfig] = dict(zip(unique_decoder_names,\n",
    "                        (CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_long_dock_colors, **_common_dock_config_kwargs),\n",
    "                        CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_short_dock_colors, **_common_dock_config_kwargs))))\n",
    "                        \n",
    "\n",
    "pf1D_Decoder_dict = {k:deepcopy(v) for k, v in results1D.decoders.items() if k in unique_decoder_names}\n",
    "\n",
    "output_dict = active_2d_plot.add_docked_decoded_results_dict_tracks(name=f'LapsDecode', a_decoded_result_dict=laps_pseudo2D_split_to_1D_continuous_results_dict, dock_configs=dock_configs, pf1D_Decoder_dict=pf1D_Decoder_dict,\n",
    "                                                                                            measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "                                                                                            extended_dock_title_info=info_string, dockSize=(10, 4))\n",
    "\n",
    "a_dock_config = CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_global_dock_colors, **_common_dock_config_kwargs)\n",
    "marginal_y_p_x_given_n_list = [deepcopy(v.p_x_given_n) for v in laps_pseudo2D_continuous_specific_decoded_result.marginal_y_list]\n",
    "_out_tuple = active_2d_plot.add_docked_decoded_posterior_slices_track(name=f'PBE_marginal_over_track_ID', a_dock_config=a_dock_config,\n",
    "                                                                                slices_time_window_centers=laps_pseudo2D_continuous_specific_decoded_result.time_window_centers, slices_posteriors=marginal_y_p_x_given_n_list,\n",
    "                                                                                xbin=None, xbin_labels=unique_decoder_names, measured_position_df=None, extended_dock_title_info=info_string, posterior_heatmap_imshow_kwargs=dict(), dockSize=(10, 1))\n",
    "output_dict['PBE_marginal_over_track_ID'] = _out_tuple\n",
    "# active_2d_plot.layout_dockGroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44547381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "\n",
    "## INPUTS: masked_laps_pseudo2D_split_to_1D_continuous_results_dict, masked_laps_pseudo2D_continuous_specific_decoded_result\n",
    "_common_dock_config_kwargs = {'dock_group_names': [dock_group_sep_character.join([f'MASKED_LapsDecode', info_string])], 'showCloseButton': showCloseButton}\n",
    "masked_dock_configs: Dict[str, CustomDockDisplayConfig] = dict(zip(unique_decoder_names,\n",
    "                        (CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_long_dock_colors, **_common_dock_config_kwargs),\n",
    "                        CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_short_dock_colors, **_common_dock_config_kwargs))))\n",
    "                        \n",
    "\n",
    "pf1D_Decoder_dict = {k:deepcopy(v) for k, v in results1D.decoders.items() if k in unique_decoder_names}\n",
    "\n",
    "MASKED_output_dict = active_2d_plot.add_docked_decoded_results_dict_tracks(name=f'MASKED_LapsDecode', a_decoded_result_dict=masked_laps_pseudo2D_split_to_1D_continuous_results_dict, dock_configs=masked_dock_configs, pf1D_Decoder_dict=pf1D_Decoder_dict,\n",
    "                                                                                            measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "                                                                                            extended_dock_title_info=info_string, dockSize=(10, 4))\n",
    "\n",
    "a_dock_config = CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_global_dock_colors, **_common_dock_config_kwargs)\n",
    "marginal_y_p_x_given_n_list = [deepcopy(v.p_x_given_n) for v in masked_laps_pseudo2D_continuous_specific_decoded_result.marginal_y_list]\n",
    "_masked_out_tuple = active_2d_plot.add_docked_decoded_posterior_slices_track(name=f'MASKED_PBE_marginal_over_track_ID', a_dock_config=a_dock_config,\n",
    "                                                                                slices_time_window_centers=masked_laps_pseudo2D_continuous_specific_decoded_result.time_window_centers, slices_posteriors=marginal_y_p_x_given_n_list,\n",
    "                                                                                xbin=None, xbin_labels=unique_decoder_names, measured_position_df=None, extended_dock_title_info=info_string, posterior_heatmap_imshow_kwargs=dict(), dockSize=(10, 1))\n",
    "MASKED_output_dict['MASKED_PBE_marginal_over_track_ID'] = _masked_out_tuple\n",
    "# active_2d_plot.layout_dockGroups()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7abd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flat_time_window_centers, flat_marginal_y_p_x_given_n = laps_pseudo2D_continuous_specific_decoded_result.get_pseudo2D_result_to_pseudo2D_marginalization_result(pseudo2D_decoder_names_list=unique_decoder_names) ## this is wrong\n",
    "time_bin_size = epochs_decoding_time_bin_size\n",
    "info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "# identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dock_item = active_2d_plot.add_docked_marginal_track(name='non-PBE_marginal_over_track_ID',\n",
    "#                                                                                         time_window_centers=flat_time_window_centers, a_1D_posterior=flat_marginal_y_p_x_given_n, extended_dock_title_info=info_string)\n",
    "\n",
    "marginal_y_p_x_given_n_list = [deepcopy(v.p_x_given_n) for v in laps_pseudo2D_continuous_specific_decoded_result.marginal_y_list]\n",
    "_out_tuple = active_2d_plot.add_docked_decoded_posterior_slices_track(name=f'PBE_marginal_over_track_ID', a_dock_config=None,\n",
    "                                                                                slices_time_window_centers=laps_pseudo2D_continuous_specific_decoded_result.time_window_centers, slices_posteriors=marginal_y_p_x_given_n_list,\n",
    "                                                                                xbin=None, measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "                                                                                extended_dock_title_info=info_string, posterior_heatmap_imshow_kwargs=dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05b98bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_pseudo2D_continuous_specific_decoded_result.p_x_given_n_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcb7eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timebins, flat_time_bin_containers, timebins_p_x_given_n = laps_pseudo2D_continuous_specific_decoded_result.flatten()\n",
    "\n",
    "desired_total_n_timebins, updated_is_masked_bin, updated_time_bin_containers, updated_timebins_p_x_given_n = laps_pseudo2D_continuous_specific_decoded_result.flatten_to_masked_values()\n",
    "\n",
    "# flat_time_bin_containers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e43cb3",
   "metadata": {},
   "source": [
    "### <a id='toc24_1_2_'></a>[Plotting Histograms Directly](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff6b535",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot: directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_pre_post_delta_scatter\n",
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import plot_histograms\n",
    "\n",
    "## INPUTS: masked_pseudo2D_continuous_specific_decoded_result\n",
    "masked_pseudo2D_continuous_specific_decoded_result = deepcopy(masked_pseudo2D_continuous_specific_decoded_result)\n",
    "ripple_weighted_corr_merged_df\n",
    "\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "## INPUTS: track_marginal_posterior_df\n",
    "\n",
    "# You can use it like this:\n",
    "_out0: \"MatplotlibRenderPlots\" = plot_histograms(data_type='Laps', session_spec='1 Session', data_results_df=track_marginal_posterior_df, time_bin_duration_str=\"25 ms\")\n",
    "# _out1: \"MatplotlibRenderPlots\" = plot_histograms(data_type='Ripples', session_spec='All Sessions', data_results_df=all_sessions_ripple_time_bin_df, time_bin_duration_str=\"75 ms\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01af1de8",
   "metadata": {},
   "source": [
    "# 'DirectionalDecodersEpochsEvaluations' Manipulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20af0225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "\n",
    "if ('DirectionalDecodersEpochsEvaluations' in curr_active_pipeline.global_computation_results.computed_data) and (curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations'] is not None):\n",
    "    directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "    directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)\n",
    "\n",
    "    ## UNPACK HERE via direct property access:\n",
    "    pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "    ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "    laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "    print(f'{pos_bin_size = }, {ripple_decoding_time_bin_size = }, {laps_decoding_time_bin_size = }') # pos_bin_size = 3.8054171165052444, ripple_decoding_time_bin_size = 0.025, laps_decoding_time_bin_size = 0.2\n",
    "    decoder_laps_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict\n",
    "    decoder_ripple_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict\n",
    "    decoder_laps_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_df_dict\n",
    "    decoder_ripple_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_df_dict\n",
    "\n",
    "    # New items:\n",
    "    decoder_laps_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_extras_dict\n",
    "    decoder_ripple_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_extras_dict\n",
    "\n",
    "    # Weighted correlations:\n",
    "    laps_weighted_corr_merged_df = directional_decoders_epochs_decode_result.laps_weighted_corr_merged_df\n",
    "    ripple_weighted_corr_merged_df = directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "    decoder_laps_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_laps_weighted_corr_df_dict\n",
    "    decoder_ripple_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict\n",
    "\n",
    "    # Pearson's correlations:\n",
    "    laps_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.laps_simple_pf_pearson_merged_df\n",
    "    ripple_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603edd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_session_name: str = curr_active_pipeline.session_name # '2006-6-08_14-26-15'\n",
    "CURR_BATCH_OUTPUT_PREFIX: str = f\"{BATCH_DATE_TO_USE}-{curr_session_name}\"\n",
    "print(f'CURR_BATCH_OUTPUT_PREFIX: {CURR_BATCH_OUTPUT_PREFIX}')\n",
    "\n",
    "# active_context = curr_active_pipeline.get_session_context().adding_context_if_missing(custom_\n",
    "\n",
    "# session_name: str = curr_active_pipeline.session_name\n",
    "\n",
    "active_context = curr_active_pipeline.get_session_context()\n",
    "session_name: str = f\"{curr_active_pipeline.session_name}{custom_suffix}\" ## appending this here is a hack, but it makes the correct filename\n",
    "active_context = active_context.adding_context_if_missing(suffix=custom_suffix)\n",
    "session_ctxt_key:str = active_context.get_description(separator='|', subset_includelist=(IdentifyingContext._get_session_context_keys() + ['suffix']))\n",
    "\n",
    "earliest_delta_aligned_t_start, t_delta, latest_delta_aligned_t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "active_context\n",
    "session_ctxt_key\n",
    "# Shifts the absolute times to delta-relative values, as would be needed to draw on a 'delta_aligned_start_t' axis:\n",
    "delta_relative_t_start, delta_relative_t_delta, delta_relative_t_end = np.array([earliest_delta_aligned_t_start, t_delta, latest_delta_aligned_t_end]) - t_delta\n",
    "# decoder_user_selected_epoch_times_dict, any_good_selected_epoch_times = DecoderDecodedEpochsResult.load_user_selected_epoch_times(curr_active_pipeline)\n",
    "# any_good_selected_epoch_indicies = filtered_ripple_simple_pf_pearson_merged_df.epochs.matching_epoch_times_slice(any_good_selected_epoch_times)\n",
    "# df = filter_epochs_dfs_by_annotation_times(curr_active_pipeline, any_good_selected_epoch_times, ripple_decoding_time_bin_size=ripple_decoding_time_bin_size, filtered_ripple_simple_pf_pearson_merged_df, ripple_weighted_corr_merged_df)\n",
    "# df\n",
    "\n",
    "# collected_outputs_path = self.collected_outputs_path.resolve()\n",
    "\n",
    "collected_outputs_path = collected_outputs_path.resolve()\n",
    "\n",
    "## Export CSVs:\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d550bf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "def _update_ripple_df(a_ripple_df):\n",
    "    \"\"\" captures: session_name, t_start, t_delta, t_end, ripple_decoding_time_bin_size \"\"\"\n",
    "    if ('time_bin_size' not in a_ripple_df.columns) and (ripple_decoding_time_bin_size is not None):\n",
    "        ## add the column\n",
    "        a_ripple_df['time_bin_size'] = ripple_decoding_time_bin_size\n",
    "    # Add the maze_id to the active_filter_epochs so we can see how properties change as a function of which track the replay event occured on:\n",
    "    a_ripple_df = DecoderDecodedEpochsResult.add_session_df_columns(a_ripple_df, session_name=session_name, time_bin_size=None, t_start=t_start, curr_session_t_delta=t_delta, t_end=t_end, time_col='ripple_start_t')\n",
    "    return a_ripple_df\n",
    "\n",
    "directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df = _update_ripple_df(directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df)\n",
    "directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df = _update_ripple_df(directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df)\n",
    "    \n",
    "ripple_weighted_corr_merged_df = directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "ripple_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df\n",
    "\n",
    "## UPDATES: directional_decoders_epochs_decode_result\n",
    "## OUTPUTS: ripple_simple_pf_pearson_merged_df, ripple_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127cd14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_simple_pf_pearson_merged_df\n",
    "ripple_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec606dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "# directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict # vector for each decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161d321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_pseudo2D_continuous_specific_decoded_result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fa02d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot: directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_pre_post_delta_scatter\n",
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import plot_histograms\n",
    "\n",
    "## INPUTS: masked_pseudo2D_continuous_specific_decoded_result\n",
    "masked_pseudo2D_continuous_specific_decoded_result = deepcopy(masked_pseudo2D_continuous_specific_decoded_result)\n",
    "ripple_weighted_corr_merged_df\n",
    "\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "# You can use it like this:\n",
    "_out0: \"MatplotlibRenderPlots\" = plot_histograms(data_type='Continuous', session_spec='1 Session', data_results_df=masked_pseudo2D_continuous_specific_decoded_result, time_bin_duration_str=\"25 ms\")\n",
    "# _out1: \"MatplotlibRenderPlots\" = plot_histograms(data_type='Ripples', session_spec='All Sessions', data_results_df=all_sessions_ripple_time_bin_df, time_bin_duration_str=\"75 ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e17e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram_bins = 'auto'\n",
    "histogram_bins: int = 25\n",
    "\n",
    "# ripple_weighted_corr_merged_df = ripple_weighted_corr_merged_df[['P_Short','delta_aligned_start_t', 'time_bin_size']]\n",
    "ripple_weighted_corr_merged_df = ripple_weighted_corr_merged_df[['P_Short','delta_aligned_start_t', 'time_bin_size']]\n",
    "new_ripple_fig, new_ripple_fig_context = plotly_pre_post_delta_scatter(data_results_df=ripple_weighted_corr_merged_df, out_scatter_fig=None, histogram_bins=histogram_bins,\n",
    "                                                                        px_scatter_kwargs=dict(title='Ripple'), histogram_variable_name='P_Short')\n",
    "\n",
    "# new_laps_fig = new_laps_fig.update_layout(fig_size_kwargs, \n",
    "#     xaxis_title=\"X Axis Title\",\n",
    "#     yaxis_title=\"Y Axis Title\",\n",
    "#     legend_title=\"Legend Title\",\n",
    "#     font=dict(\n",
    "#         family=\"Courier New, monospace\",\n",
    "#         size=18,\n",
    "#         color=\"RebeccaPurple\"\n",
    "#     ),\n",
    "# )\n",
    "# Update x-axis labels\n",
    "# new_laps_fig.update_xaxes(title_text=\"Num Time Bins\", row=1, col=1)\n",
    "# new_laps_fig.update_xaxes(title_text=\"Delta-aligned Event Time (seconds)\", row=1, col=2)\n",
    "# new_laps_fig.update_xaxes(title_text=\"Num Time Bins\", row=1, col=3)\n",
    "\n",
    "\n",
    "_extras_output_dict = {}\n",
    "_extras_output_dict[\"y_mid_line\"] = new_ripple_fig.add_hline(y=0.5, line=dict(color=\"rgba(0.8,0.8,0.8,.75)\", width=2), row='all', col='all')\n",
    "\n",
    "new_ripple_fig\n",
    "\n",
    "\n",
    "\n",
    "# # Update layout to add a title to the legend\n",
    "# new_fig_ripples.update_layout(\n",
    "#     legend_title_text='Is User Selected'  # Add a title to the legend\n",
    "# )\n",
    "\n",
    "# fig_to_clipboard(new_fig_ripples, **fig_size_kwargs)\n",
    "\n",
    "# new_laps_fig_context: IdentifyingContext = new_laps_fig_context.adding_context_if_missing(epoch='withNewKamranExportedReplays', num_sessions=num_sessions, plot_type='scatter+hist', comparison='pre-post-delta', variable_name=variable_name)\n",
    "# figure_out_paths = save_plotly(a_fig=new_laps_fig, a_fig_context=new_laps_fig_context)\n",
    "# new_laps_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59a55fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_PBE_marginal_over_track_ID # (2, 44887) - which track it's using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a48222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import find_epochs_overlapping_other_epochs\n",
    "\n",
    "# INPUTS: track_marginal_posterior_df\n",
    "\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "global_session = curr_active_pipeline.filtered_sessions[global_epoch_name]\n",
    "\n",
    "# global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps) # .trimmed_to_non_overlapping()\n",
    "global_laps_epochs_df = global_laps.to_dataframe()\n",
    "# active_test_epochs_df: pd.DataFrame = deepcopy(global_laps_epochs_df)\n",
    "global_laps_epochs_df\n",
    "\n",
    "\n",
    "# global_laps_epochs_df\n",
    "is_included: NDArray = find_epochs_overlapping_other_epochs(epochs_df=track_marginal_posterior_df, epochs_df_required_to_overlap=deepcopy(global_laps_epochs_df))\n",
    "track_marginal_posterior_df['is_in_laps'] = is_included\n",
    "track_marginal_posterior_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ad6c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_PBE_marginal_over_track_ID.shape # (2, 44887) - which track it's using\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01fe90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window_centers.shape # (44887,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9176dca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build into a marginal df like `all_sessions_laps_df`:\n",
    "track_marginal_posterior_df : pd.DataFrame = pd.DataFrame({'t':deepcopy(time_window_centers), 'P_Long': np.squeeze(non_PBE_marginal_over_track_ID[0, :]), 'P_Short': np.squeeze(non_PBE_marginal_over_track_ID[1, :]), 'time_bin_size': pseudo2D_continuous_specific_decoded_result.decoding_time_bin_size})\n",
    "track_marginal_posterior_df['delta_aligned_start_t'] = track_marginal_posterior_df['t'] - t_delta ## subtract off t_delta\n",
    "track_marginal_posterior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af44479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "template: str = 'plotly_dark' # set plotl template\n",
    "pio.templates.default = template\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_pre_post_delta_scatter\n",
    "\n",
    "\n",
    "histogram_bins: int = 25\n",
    "\n",
    "# new_laps_fig = plotly_pre_post_delta_scatter(data_results_df=deepcopy(all_sessions_laps_df), out_scatter_fig=fig_laps, histogram_bins=histogram_bins, px_scatter_kwargs = dict(title='Laps'))\n",
    "fig, figure_context = plotly_pre_post_delta_scatter(data_results_df=deepcopy(track_marginal_posterior_df)[['delta_aligned_start_t', 'P_Long', 'time_bin_size']], out_scatter_fig=None, histogram_bins=histogram_bins, px_scatter_kwargs = dict(title='Continuous'))\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3b13c7",
   "metadata": {},
   "source": [
    "### <a id='toc25_1_1_'></a>[🚧🔜 2025-02-26 -  Plot 1D pseudo2D Continuous Decodings and their marginals over TrackID on SpikeRaster2D track - uses `AddNewDecodedPosteriors_MatplotlibPlotCommand.prepare_and_perform_custom_decoder_decoded_epochs(...)`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9569f931",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_bin_size = epochs_decoding_time_bin_size\n",
    "info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dock_item = active_2d_plot.add_docked_marginal_track(name='non-PBE_marginal_over_track_ID',\n",
    "                                                                                        time_window_centers=time_window_centers, a_1D_posterior=non_PBE_marginal_over_track_ID, extended_dock_title_info=info_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfd6308",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_decoded_results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94401b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AddNewDecodedEpochMarginal_MatplotlibPlotCommand._perform_add_new_decoded_posterior_marginal_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4f1cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dock all Grouped results from `'DockedWidgets.Pseudo2DDecodedEpochsDockedMatplotlibView'`\n",
    "## INPUTS: active_2d_plot\n",
    "nested_dock_items, nested_dynamic_docked_widget_container_widgets = active_2d_plot.ui.dynamic_docked_widget_container.layout_dockGroups()\n",
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e99ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d58a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_ax.remove(line_measured_position)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6931df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_results = curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['non_PBE_epochs_results'], computation_kwargs_list=[dict(epochs_decoding_time_bin_size=0.025, frame_divide_bin_size=5.0, compute_1D=True, compute_2D=False, drop_previous_result_and_compute_fresh=True, skip_training_test_split=False)],\n",
    "                                                                                                                                            enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3232a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['non_PBE_epochs_results'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb2b869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs_decoding_time_bin_size = 0.050\n",
    "# subdivide_bin_size = 0.250\n",
    "\n",
    "epochs_decoding_time_bin_size = 1.0\n",
    "subdivide_bin_size = 1.0\n",
    "\n",
    "_out_results = curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['non_PBE_epochs_results'], computation_kwargs_list=[dict(epochs_decoding_time_bin_size=epochs_decoding_time_bin_size, frame_divide_bin_size=subdivide_bin_size, compute_1D=True, compute_2D=True, drop_previous_result_and_compute_fresh=False)],\n",
    "                                                                                                                                            enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b103e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [np.shape(v) for v in a_result.p_x_given_n_list]\n",
    "\n",
    "np.sum([np.prod(np.shape(v)) for v in a_result.p_x_given_n_list])\n",
    "\n",
    "# np.vstack([np.shape(v) for v in a_result.p_x_given_n_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464af0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData, loadData\n",
    "\n",
    "# output_save_parent_path: Path = Path(r\"C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\data\").resolve()\n",
    "output_save_parent_path: Path = curr_active_pipeline.get_output_path().resolve()\n",
    "# hdf5_output_path: Path = curr_active_pipeline.get_output_path().joinpath('2025-02-14_results_nonPBEDecoding_2D.h5')\n",
    "# pkl_output_path: Path = output_save_parent_path.joinpath('2025-02-18_results_EpochComputations_nonPBEDecoding.pkl')\n",
    "pkl_output_path: Path = output_save_parent_path.joinpath('2025-02-20_results_EpochComputations_nonPBEDecoding.pkl')\n",
    "print(f'pkl_output_path: \"{pkl_output_path}\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5d8014",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "saveData(pkl_output_path, nonPBE_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad5e355",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load from pickle:\n",
    "print(f'pkl_output_path: {pkl_output_path}')\n",
    "nonPBE_results = loadData(pkl_path=pkl_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b617c11",
   "metadata": {},
   "source": [
    "## <a id='toc32_2_'></a>[Get 1D representations of the Pseudo2D track (4 decoders) so they can be plotted on seperate tracks and bin-debugged independently.](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b821104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "\n",
    "epochs_decoding_time_bin_size: float = 0.050\n",
    "\n",
    "# output_dict = active_2d_plot.compute_if_needed_and_add_continuous_decoded_posterior(curr_active_pipeline=curr_active_pipeline, desired_time_bin_size=0.025, debug_print=True)\n",
    "output_dict = active_2d_plot.compute_if_needed_and_add_continuous_decoded_posterior(curr_active_pipeline=curr_active_pipeline, desired_time_bin_size=epochs_decoding_time_bin_size, debug_print=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2e7918",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d23c891",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "\n",
    "\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "directional_merged_decoders_result.laps_all_epoch_bins_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d035e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "\n",
    "\n",
    "# epochs_decoding_time_bin_size: float = 0.025\n",
    "\n",
    "## get the result data:\n",
    "try:\n",
    "    ## Uses the `global_computation_results.computed_data['DirectionalDecodersDecoded']`\n",
    "    directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "    # pseudo2D_decoder: BasePositionDecoder = directional_decoders_decode_result.pseudo2D_decoder\n",
    "    all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "    a_continuously_decoded_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_decode_result.continuously_decoded_result_cache_dict.get(epochs_decoding_time_bin_size, None)\n",
    "    all_time_bin_sizes_output_dict: Dict[float, Dict[types.DecoderName, SingleEpochDecodedResult]] = directional_decoders_decode_result.split_pseudo2D_continuous_result_to_1D_continuous_result()\n",
    "    a_split_pseudo2D_continuous_result_to_1D_continuous_result_dict: Dict[types.DecoderName, SingleEpochDecodedResult] = all_time_bin_sizes_output_dict.get(epochs_decoding_time_bin_size, None)\n",
    "    \n",
    "    assert a_continuously_decoded_dict is not None, f\"a_continuously_decoded_dict is None even after recomputing!\"\n",
    "    assert a_split_pseudo2D_continuous_result_to_1D_continuous_result_dict is not None, f\"a_split_pseudo2D_continuous_result_to_1D_continuous_result_dict is None even after recomputing!\"\n",
    "    info_string: str = f\" - t_bin_size: {epochs_decoding_time_bin_size:.3f}\"\n",
    "    \n",
    "    _a_continuously_decoded_pseudo2D_result: DecodedFilterEpochsResult = deepcopy(a_continuously_decoded_dict['pseudo2D'])\n",
    "    assert _a_continuously_decoded_pseudo2D_result is not None\n",
    "    all_time_bin_decoded_pseudo2D_result: SingleEpochDecodedResult = _a_continuously_decoded_pseudo2D_result.get_result_for_epoch(0)\n",
    "\n",
    "\n",
    "except (KeyError, AttributeError) as e:\n",
    "    # KeyError: 'DirectionalDecodersDecoded'\n",
    "    print(f'add_all_computed_time_bin_sizes_pseudo2D_decoder_decoded_epochs(...) failed to add any tracks, perhaps because the pipeline is missing any computed \"DirectionalDecodersDecoded\" global results. Error: \"{e}\". Skipping.')\n",
    "    a_continuously_decoded_dict = None\n",
    "    pseudo2D_decoder = None        \n",
    "    pass\n",
    "\n",
    "except Exception as e:\n",
    "    raise\n",
    "\n",
    "\n",
    "## OUTPUTS: all_time_bin_decoded_pseudo2D_result\n",
    "np.shape(all_time_bin_decoded_pseudo2D_result.p_x_given_n) # (59, 4, 34744)\n",
    "\n",
    "marginal_x = deepcopy(all_time_bin_decoded_pseudo2D_result.marginal_x['p_x_given_n'])\n",
    "marginal_y = deepcopy(all_time_bin_decoded_pseudo2D_result.marginal_y['p_x_given_n'])\n",
    "\n",
    "\n",
    "np.shape(marginal_x) # (59, 34744)\n",
    "np.shape(marginal_y) # (4, 34744) -- marginalization of position bins\n",
    "\n",
    "\n",
    "## OUTPUTS: a_continuously_decoded_dict, a_split_pseudo2D_continuous_result_to_1D_continuous_result_dict\n",
    "# a_continuously_decoded_pseudo2D_result.build_per_time_bin_marginals_df(active_marginals_tuple=(laps_directional_all_epoch_bins_marginal, laps_track_identity_all_epoch_bins_marginal), columns_tuple=(['P_LR', 'P_RL'], ['P_Long', 'P_Short']))\n",
    "\n",
    "\n",
    "# a_split_pseudo2D_continuous_result_to_1D_continuous_result_dict\n",
    "all_time_bin_decoded_pseudo2D_result.time_bin_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95ec3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame('t': all_time_bin_decoded_pseudo2D_result.time_bin_edges.to_numpy(), })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d672dc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: all_time_bin_decoded_pseudo2D_result\n",
    "\n",
    "unique_decoder_names = ['long_LR', 'long_RL', 'short_LR', 'short_RL']\n",
    "# unique_decoder_names = ['long', 'short']\n",
    "\n",
    "# a_pseudo2D_split_to_1D_continuous_results_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = all_time_bin_decoded_pseudo2D_result.split_pseudo2D_result_to_1D_result(pseudo2D_decoder_names_list=unique_decoder_names)\n",
    "a_non_PBE_marginal_over_track_ID, a_non_PBE_marginal_over_track_ID_posterior_df = DirectionalPseudo2DDecodersResult.build_generalized_non_marginalized_raw_posteriors(_a_continuously_decoded_pseudo2D_result, unique_decoder_names=unique_decoder_names) #[0]['p_x_given_n']\n",
    "\n",
    "a_non_PBE_marginal_over_track_ID_posterior_df['t_bin_center'] = a_non_PBE_marginal_over_track_ID_posterior_df['t']\n",
    "## Add the combined columns:\n",
    "### TrackID:\n",
    "a_non_PBE_marginal_over_track_ID_posterior_df['P_Long'] = (a_non_PBE_marginal_over_track_ID_posterior_df['P_Long_lr'] + a_non_PBE_marginal_over_track_ID_posterior_df['P_Long_rl'])\n",
    "a_non_PBE_marginal_over_track_ID_posterior_df['P_Short'] = (a_non_PBE_marginal_over_track_ID_posterior_df['P_Short_lr'] + a_non_PBE_marginal_over_track_ID_posterior_df['P_Short_rl'])\n",
    "### Direction:\n",
    "a_non_PBE_marginal_over_track_ID_posterior_df['P_LR'] = (a_non_PBE_marginal_over_track_ID_posterior_df['P_Long_lr'] + a_non_PBE_marginal_over_track_ID_posterior_df['P_Short_lr'])\n",
    "a_non_PBE_marginal_over_track_ID_posterior_df['P_RL'] = (a_non_PBE_marginal_over_track_ID_posterior_df['P_Long_rl'] + a_non_PBE_marginal_over_track_ID_posterior_df['P_Short_rl'])\n",
    "\n",
    "a_non_PBE_marginal_over_track_ID_posterior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53513e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ctxt = IdentifyingContext()\n",
    "\n",
    "a_df = deepcopy(a_non_PBE_marginal_over_track_ID_posterior_df)\n",
    "## INPUTS: a_df\n",
    "\n",
    "time_bin_size = epochs_decoding_time_bin_size\n",
    "info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "plot_row_identifier: str = a_ctxt.get_description(subset_includelist=['known_named_decoding_epochs_type', 'masked_time_bin_fill_type'], include_property_names=True, key_value_separator=':', separator='|', replace_separator_in_property_names='-')\n",
    "a_time_window_centers = a_df['t_bin_center'].to_numpy() \n",
    "a_1D_posterior = a_df[['P_Long', 'P_Short']].to_numpy().T\n",
    "\n",
    "identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dock_item = active_2d_plot.add_docked_marginal_track(name=plot_row_identifier, time_window_centers=a_time_window_centers, a_1D_posterior=a_1D_posterior, extended_dock_title_info=info_string)\n",
    "_all_tracks_out_artists[identifier_name] = widget\n",
    "matplotlib_fig_axes[0].set_xlim(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time)\n",
    "widget.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474d2414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae4b6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalDecodersContinuouslyDecodedResult, DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import SingleEpochDecodedResult\n",
    "\n",
    "## INPUTS: laps_pseudo2D_continuous_specific_decoded_result: DecodedFilterEpochsResult\n",
    "unique_decoder_names = ['long', 'short']\n",
    "laps_pseudo2D_split_to_1D_continuous_results_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = laps_pseudo2D_continuous_specific_decoded_result.split_pseudo2D_result_to_1D_result(pseudo2D_decoder_names_list=unique_decoder_names)\n",
    "masked_laps_pseudo2D_split_to_1D_continuous_results_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = masked_laps_pseudo2D_continuous_specific_decoded_result.split_pseudo2D_result_to_1D_result(pseudo2D_decoder_names_list=unique_decoder_names)\n",
    "\n",
    "# OUTPUTS: laps_pseudo2D_split_to_1D_continuous_results_dict, masked_laps_pseudo2D_split_to_1D_continuous_results_dict\n",
    "\n",
    "# active_marginals=ripple_track_identity_marginals, columns=['P_LR', 'P_RL'] \n",
    "# active_marginals=ripple_track_identity_marginals, columns=['P_Long', 'P_Short']\n",
    "# laps_track_identity_all_epoch_bins_marginal\n",
    "\n",
    "## INPUTS: laps_pseudo2D_continuous_specific_decoded_result: DecodedFilterEpochsResult\n",
    "flat_time_window_centers, flat_marginal_y_p_x_given_n = laps_pseudo2D_continuous_specific_decoded_result.get_pseudo2D_result_to_pseudo2D_marginalization_result(pseudo2D_decoder_names_list=unique_decoder_names)\n",
    "flat_marginal_y_p_x_given_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904527b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_all_tracks_out_artists = {}\n",
    "for a_ctxt, a_df in flat_decoded_marginal_posterior_df_context_dict.items():\n",
    "    time_bin_size = epochs_decoding_time_bin_size\n",
    "    info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "    plot_row_identifier: str = a_ctxt.get_description(subset_includelist=['known_named_decoding_epochs_type', 'masked_time_bin_fill_type'], include_property_names=True, key_value_separator=':', separator='|', replace_separator_in_property_names='-')\n",
    "    a_time_window_centers = a_df['t_bin_center'].to_numpy() \n",
    "    a_1D_posterior = a_df[['P_Long', 'P_Short']].to_numpy().T\n",
    "\n",
    "    identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dock_item = active_2d_plot.add_docked_marginal_track(name=plot_row_identifier, time_window_centers=a_time_window_centers, a_1D_posterior=a_1D_posterior, extended_dock_title_info=info_string)\n",
    "    _all_tracks_out_artists[identifier_name] = widget\n",
    "    intervals_overview_plot_item.setXRange(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time, padding=0) ## global frame\n",
    "    matplotlib_fig_axes[0].set_xlim(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time)\n",
    "    widget.draw()\n",
    "\n",
    "\n",
    "## Make a new matplotlib figure (in a new window) that contains a copy of `matplotlib_fig_axes` inserted \n",
    "\n",
    "\n",
    "\n",
    "# active_2d_plot.add_docked_marginal_track("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3c784d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.indexing_helpers import get_dict_subset\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalDecodersContinuouslyDecodedResult, DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import SingleEpochDecodedResult\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, DockDisplayColors\n",
    "\n",
    "debug_print = True\n",
    "\n",
    "## Uses the `global_computation_results.computed_data['DirectionalDecodersDecoded']`\n",
    "directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "pseudo2D_decoder: BasePositionDecoder = directional_decoders_decode_result.pseudo2D_decoder  # merged pseudo2D decoder\n",
    "all_directional_pf1D_Decoder_dict: Dict[types.DecoderName, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict ## separate 1D decoders\n",
    "\n",
    "continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "\n",
    "\n",
    "all_time_bin_sizes_output_dict: Dict[float, Dict[types.DecoderName, SingleEpochDecodedResult]] = directional_decoders_decode_result.split_pseudo2D_continuous_result_to_1D_continuous_result()\n",
    "## OUTPUTS: all_directional_pf1D_Decoder_dict, all_time_bin_sizes_output_dict, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50c1170",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uses `AddNewDecodedPosteriors_MatplotlibPlotCommand._perform_add_new_decoded_posterior_row(...)` to build the 4 tracks from the split result:\n",
    "# active_2d_plot.add_new_embedded_pyqtgraph_render_plot_widget(\n",
    "\"\"\"\n",
    "add_new_matplotlib_render_plot_widget\n",
    "add_new_matplotlib_render_plot_widget\n",
    "add_new_embedded_pyqtgraph_render_plot_widget\n",
    "\"\"\"\n",
    "## INPUTS: all_time_bin_sizes_output_dict\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import AddNewDecodedPosteriors_MatplotlibPlotCommand\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, DockDisplayColors\n",
    "\n",
    "## plot only a single time bin for now:\n",
    "cached_decoded_time_bin_size_list = list(all_time_bin_sizes_output_dict.keys())\n",
    "assert len(cached_decoded_time_bin_size_list) > 0\n",
    "active_time_bin_size: float = cached_decoded_time_bin_size_list[0]\n",
    "info_string: str = f'{active_time_bin_size:.2f}'\n",
    "## one for each of the four decoders:\n",
    "a_split_pseudo2D_continuous_result_to_1D_continuous_result_dict: Dict[types.DecoderName, SingleEpochDecodedResult] = all_time_bin_sizes_output_dict[active_time_bin_size]\n",
    "dock_group_sep_character: str = '_'\n",
    "showCloseButton = True\n",
    "_common_dock_config_kwargs = {'dock_group_names': [dock_group_sep_character.join([f'ContinuousDecode', info_string])], 'showCloseButton': showCloseButton}\n",
    "dock_configs = dict(zip(('long_LR', 'long_RL', 'short_LR', 'short_RL'),\n",
    "\t\t\t\t\t\t(CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Laps.get_LR_dock_colors, **_common_dock_config_kwargs),\n",
    "                        CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Laps.get_RL_dock_colors, **_common_dock_config_kwargs),\n",
    "                        CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Laps.get_LR_dock_colors, **_common_dock_config_kwargs),\n",
    "                        CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Laps.get_RL_dock_colors, **_common_dock_config_kwargs))))\n",
    "\n",
    "\n",
    "## all at once:\n",
    "output_dict = active_2d_plot.add_docked_decoded_results_dict_tracks(name=f'DirectionalDecodersDecoded', a_decoded_result_dict=a_split_pseudo2D_continuous_result_to_1D_continuous_result_dict, dock_configs=dock_configs, pf1D_Decoder_dict=all_directional_pf1D_Decoder_dict,\n",
    "                                                                                            measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "                                                                                            extended_dock_title_info=info_string)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6828e1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Need all_directional_pf1D_Decoder_dict\n",
    "output_dict = {}\n",
    "for a_decoder_name, a_1D_continuous_decoded_result in a_split_pseudo2D_continuous_result_to_1D_continuous_result_dict.items():\n",
    "    ## a_1D_continuous_decoded_result: SingleEpochDecodedResult\n",
    "    a_dock_config = dock_configs[a_decoder_name]\n",
    "    a_1D_decoder: BasePositionDecoder = all_directional_pf1D_Decoder_dict[a_decoder_name]\n",
    "    # _out_tuple = AddNewDecodedPosteriors_MatplotlibPlotCommand._perform_add_new_decoded_posterior_row(curr_active_pipeline=curr_active_pipeline, active_2d_plot=active_2d_plot, a_dock_config=a_dock_config, a_decoder_name=a_decoder_name, a_position_decoder=a_1D_decoder,\n",
    "    #                                                             time_window_centers=a_1D_continuous_decoded_result.time_bin_container.centers, a_1D_posterior=a_1D_continuous_decoded_result.p_x_given_n, extended_dock_title_info=info_string)\n",
    "    _out_tuple = active_2d_plot.add_docked_decoded_posterior_track(name=f'DirectionalDecodersDecoded[{a_decoder_name}]', a_dock_config=a_dock_config,\n",
    "                                                                                            time_window_centers=a_1D_continuous_decoded_result.time_bin_container.centers, a_1D_posterior=a_1D_continuous_decoded_result.p_x_given_n,\n",
    "                                                                                            xbin = deepcopy(a_1D_decoder.xbin), measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "                                                                                            extended_dock_title_info=info_string)\n",
    "\n",
    "    identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = _out_tuple\n",
    "    ## Add `a_decoded_result` to the plots_data\n",
    "    widget.plots_data.a_decoded_result = a_1D_continuous_decoded_result\n",
    "    widget.plots_data.a_decoder = deepcopy(a_1D_decoder)\n",
    "    output_dict[a_decoder_name] = _out_tuple\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56538c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_decoder_name, an_out_tuple in output_dict.items():\n",
    "    identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = an_out_tuple\n",
    "    print(f'a_decoder_name: {a_decoder_name} -- identifier_name: \"{identifier_name}\"')\n",
    "\n",
    "    # dDisplayItem.orientation\n",
    "    dDisplayItem.autoOrient = False\n",
    "    # dDisplayItem.setOrientation('horizontal', force=True)\n",
    "    dDisplayItem.setOrientation('vertical', force=True)\n",
    "    dDisplayItem.label.relayout_text()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f833550",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_decoder_name, an_out_tuple in output_dict.items():\n",
    "    identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = an_out_tuple\n",
    "    print(f'a_decoder_name: {a_decoder_name} -- identifier_name: \"{identifier_name}\"')\n",
    "    # widget.plots_data.data_keys\n",
    "    widget.plots_data.a_decoded_result = a_1D_continuous_decoded_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450d37f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import plot_attached_BinByBinDecodingDebugger\n",
    "\n",
    "a_decoder_name: types.DecoderName = 'long_LR'\n",
    "identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = output_dict[a_decoder_name]\n",
    "a_1D_continuous_decoded_result = widget.plots_data.a_decoded_result\n",
    "a_decoder = widget.plots_data.a_decoder\n",
    "## INPUTS: a_decoder, a_decoded_result\n",
    "win, out_pf1D_decoder_template_objects, (plots_container, plots_data), _on_update_fcn = plot_attached_BinByBinDecodingDebugger(spike_raster_window, curr_active_pipeline, a_decoder=a_decoder, a_decoded_result=a_1D_continuous_decoded_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b217f221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_1D_continuous_decoded_result.epoch_info_tuple\n",
    "a_1D_continuous_decoded_result.time_bin_container.center_info.step\n",
    "a_1D_continuous_decoded_result.time_bin_container.edge_info.step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c4a72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, CustomCyclicColorsDockDisplayConfig, NamedColorScheme\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import new_plot_raster_plot #, NewSimpleRaster, paired_separately_sort_neurons\n",
    "\n",
    "_raster_tracks_out_dict = {}\n",
    "## Enables creating a new pyqtgraph-based track to display the intervals/epochs\n",
    "dock_config = CustomCyclicColorsDockDisplayConfig(named_color_scheme=NamedColorScheme.grey, showCloseButton=True, showCollapseButton=False, showGroupButton=False, corner_radius=\"0px\", hideTitleBar=True)\n",
    "name = f'rasters[{name_modifier_suffix}]'\n",
    "time_sync_pyqtgraph_widget, raster_root_graphics_layout_widget, raster_plot_item, raster_dock = self.add_new_embedded_pyqtgraph_render_plot_widget(name=name, dockSize=(500, 120), display_config=dock_config)\n",
    "\n",
    "if raster_plot_item not in self.params.custom_interval_rendering_plots:\n",
    "    self.params.custom_interval_rendering_plots.append(raster_plot_item) ## this signals that it should recieve updates for its intervals somewhere else\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15a97f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# all_time_bin_sizes_output_dict = {'non_marginalized_raw_result': [], 'marginal_over_direction': [], 'marginal_over_track_ID': []}\n",
    "# flat_all_time_bin_sizes_output_tuples_list: List[Tuple] = []\n",
    "\n",
    "for time_bin_size, a_continuously_decoded_dict in continuously_decoded_result_cache_dict.items():\n",
    "    ## Each iteration here adds 4 more tracks -- one for each decoding context\n",
    "    \n",
    "    # a_continuously_decoded_dict: Dict[str, DecodedFilterEpochsResult]\n",
    "    if debug_print:\n",
    "        print(f'time_bin_size: {time_bin_size}')\n",
    "\n",
    "    info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "    \n",
    "    ## Uses the `global_computation_results.computed_data['DirectionalDecodersDecoded']`\n",
    "    # all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "    # continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "\n",
    "    continuously_decoded_dict = a_continuously_decoded_dict\n",
    "    \n",
    "\n",
    "    # continuously_decoded_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(directional_decoders_decode_result.most_recent_continuously_decoded_dict)\n",
    "    assert continuously_decoded_dict is not None\n",
    "\n",
    "    ## Get the separate 1D results, these are ready-to-go:\n",
    "    all_directional_pf1D_Decoder_continuous_results_dict: Dict[types.DecoderName, SingleEpochDecodedResult] = {k:v.get_result_for_epoch(0) for k, v in get_dict_subset(continuously_decoded_dict, subset_includelist=None, subset_excludelist=['pseudo2D']).items()}\n",
    "    \n",
    "\n",
    "    ## Extract the Pseudo2D results as separate 1D tracks\n",
    "    ## INPUTS: most_recent_continuously_decoded_dict: Dict[str, DecodedFilterEpochsResult], info_string\n",
    "    \n",
    "    # all_directional_continuously_decoded_dict = most_recent_continuously_decoded_dict or {}\n",
    "    pseudo2D_decoder_continuously_decoded_result: DecodedFilterEpochsResult = continuously_decoded_dict.get('pseudo2D', None)\n",
    "    assert len(pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list) == 1\n",
    "    single_pseudo2D_decoder_continuously_decoded_result: SingleEpochDecodedResult = pseudo2D_decoder_continuously_decoded_result.get_result_for_epoch(0)\n",
    "    \n",
    "\n",
    "    p_x_given_n = single_pseudo2D_decoder_continuously_decoded_result.p_x_given_n ## continuous -- meaning single epoch\n",
    "    # p_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0]['p_x_given_n']\n",
    "    time_bin_container = single_pseudo2D_decoder_continuously_decoded_result.time_bin_container\n",
    "    time_window_centers = time_bin_container.centers\n",
    "    \n",
    "\n",
    "    # p_x_given_n.shape # (62, 4, 209389)\n",
    "\n",
    "    ## Split across the 2nd axis to make 1D posteriors that can be displayed in separate dock rows:\n",
    "    assert p_x_given_n.shape[1] == 4, f\"expected the 4 pseudo-y bins for the decoder in p_x_given_n.shape[1]. but found p_x_given_n.shape: {p_x_given_n.shape}\"\n",
    "    split_pseudo2D_posteriors_dict = {k:np.squeeze(p_x_given_n[:, i, :]) for i, k in enumerate(('long_LR', 'long_RL', 'short_LR', 'short_RL'))}\n",
    "\n",
    "    # Need all_directional_pf1D_Decoder_dict\n",
    "    output_dict = {}\n",
    "    output_pseudo2D_split_to_1D_continuous_results_dict: Dict[types.DecoderName, SingleEpochDecodedResult] = {}\n",
    "\n",
    "    # for a_decoder_name, a_1D_posterior in split_pseudo2D_posteriors_dict.items():\n",
    "    for i, a_decoder_name in enumerate(('long_LR', 'long_RL', 'short_LR', 'short_RL')):\n",
    "        ## make separate `SingleEpochDecodedResult` objects\n",
    "        \n",
    "        # all_directional_pf1D_Decoder_continuous_results_dict\n",
    "        output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name] = deepcopy(single_pseudo2D_decoder_continuously_decoded_result) ## copy the whole pseudo2D result\n",
    "        # output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].p_x_given_n = a_1D_posterior ## or could squish them here\n",
    "        output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].p_x_given_n = np.squeeze(output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].p_x_given_n[:, i, :]) ## or could squish them here\n",
    "        \n",
    "        # _out_tuple = dict(a_decoder_name=a_decoder_name, a_position_decoder=pseudo2D_decoder, time_window_centers=time_window_centers, a_1D_posterior=a_1D_posterior)\n",
    "        # identifier_name, widget, matplotlib_fig, matplotlib_fig_axes = _out_tuple\n",
    "        # output_dict[a_decoder_name] = _out_tuple\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## OUTPUTS: all_directional_pf1D_Decoder_dict: Dict[types.DecoderName, BasePositionDecoder], all_directional_pf1D_Decoder_continuous_results_dict: Dict[types.DecoderName, SingleEpochDecodedResult]\n",
    "## OUTPUTS: pseudo2D_decoder: BasePositionDecoder, single_pseudo2D_decoder_continuously_decoded_result: SingleEpochDecodedResult, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea54c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].p_x_given_n.shape\n",
    "# output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].most_likely_positions\n",
    "\n",
    "# output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name]._test_find_fields_by_shape_metadata()\n",
    "\n",
    "## Marginals are wrong afterwards, and most-likely positions have too many dimensions\n",
    "\n",
    "\n",
    "# pseudo2D_decoder_continuously_decoded_result.perform_compute_marginals\n",
    "output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].most_likely_positions\n",
    "output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].marginal_x\n",
    "\n",
    "output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].marginal_x['p_x_given_n'].shape ## these are okay, (n_x_bins, n_t_bins)\n",
    "output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].marginal_y['p_x_given_n'].shape ## these are bad, (n_decoder_names, n_t_bins)\n",
    "\n",
    "\n",
    "output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].most_likely_positions["
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522aab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo2D_decoder_continuously_decoded_result.pos_bin_edges\n",
    "pseudo2D_decoder_continuously_decoded_result.n_pos_bins\n",
    "continuously_decoded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566c4c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_bin_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1687f8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_pseudo2D_decoder_continuously_decoded_result.to_hdf(\n",
    "import h5py\n",
    "\n",
    "hdf5_output_path: Path = curr_active_pipeline.get_output_path().joinpath('test_data.h5')\n",
    "with h5py.File(hdf5_output_path, 'w') as f: ## open the path as a HDF5 file handle:\n",
    "    single_pseudo2D_decoder_continuously_decoded_result.to_hdf(f, key='single_pseudo2D_decoder_continuously_decoded_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5b63de",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_pseudo2D_decoder_continuously_decoded_result\n",
    "single_pseudo2D_decoder_continuously_decoded_result.marginal_y['p_x_given_n'].shape\n",
    "single_pseudo2D_decoder_continuously_decoded_result.marginal_x['p_x_given_n'].shape\n",
    "\n",
    "\n",
    "\n",
    "# single_pseudo2D_decoder_continuously_decoded_result.epoch_info_tuple\n",
    "single_pseudo2D_decoder_continuously_decoded_result.p_x_given_n.shape # (59, 4, 69487)\n",
    "# single_pseudo2D_decoder_continuously_decoded_result.get_posterior_as_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66ce480",
   "metadata": {},
   "source": [
    "# <a id='toc34_'></a>[General Decoding Record with Frozen Decoding Parameters Tuples](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0889b292",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dict of decoding results, where the decoders used for decoding are built from: nonPBE_Long, nonPBE_Short, Laps_LongLR, Laps_LongRL, Laps_ShortLR, Laps_ShortRL\n",
    "## qclu, frHz\n",
    "# All Decoders should be continuous (decoding the entire session as a single epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e6797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import EpochsAccessor, Epoch, ensure_dataframe, ensure_Epoch\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import EpochComputationFunctions, EpochComputationsComputationsContainer, DecodingResultND, Compute_NonPBE_Epochs, KnownFilterEpochs\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import GeneralDecoderDictDecodedEpochsDictResult, GenericResultTupleIndexType, KnownNamedDecodingEpochsType, MaskedTimeBinFillType\n",
    "\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "\n",
    "## Unpack from pipeline:\n",
    "nonPBE_results: EpochComputationsComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['EpochComputations']\n",
    "a_new_NonPBE_Epochs_obj: Compute_NonPBE_Epochs = nonPBE_results.a_new_NonPBE_Epochs_obj\n",
    "results1D: DecodingResultND = nonPBE_results.results1D\n",
    "results2D: DecodingResultND = nonPBE_results.results2D\n",
    "\n",
    "epochs_decoding_time_bin_size = nonPBE_results.epochs_decoding_time_bin_size\n",
    "frame_divide_bin_size = nonPBE_results.frame_divide_bin_size\n",
    "\n",
    "print(f'{epochs_decoding_time_bin_size = }, {frame_divide_bin_size = }')\n",
    "\n",
    "assert (results1D is not None)\n",
    "# assert (results2D is not None)\n",
    "\n",
    "## New computed properties:\n",
    "a_general_decoder_dict_decoded_epochs_dict_result: GeneralDecoderDictDecodedEpochsDictResult = nonPBE_results.a_general_decoder_dict_decoded_epochs_dict_result ## get the pre-decoded result\n",
    "a_general_decoder_dict_decoded_epochs_dict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098dbf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# 2025-02-20 20:06 New `nonPBE_results._build_merged_joint_placefields_and_decode` method                              #\n",
    "# ==================================================================================================================== #\n",
    "non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict, non_PBE_marginal_over_track_ID, (time_bin_containers, time_window_centers, track_marginal_posterior_df) = nonPBE_results._build_merged_joint_placefields_and_decode(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)))\n",
    "masked_pseudo2D_continuous_specific_decoded_result, _mask_index_tuple = pseudo2D_continuous_specific_decoded_result.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)))\n",
    "## OUTPUTS: pseudo2D_continuous_specific_decoded_result, non_PBE_marginal_over_track_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1ffbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'DirectionalMergedDecoders' in curr_active_pipeline.global_computation_results.computed_data:\n",
    "    # DirectionalMergedDecoders: Get the result after computation:\n",
    "    directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "    a_new_fully_generic_result = a_new_fully_generic_result.adding_directional_pseudo2D_decoder_results_filtered_by_spikes_per_t_bin_masked(directional_merged_decoders_result=directional_merged_decoders_result)\n",
    "else:\n",
    "    print('WARN: missing \"DirectionalMergedDecoders\" global result. Skipping.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f11aef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.get_complete_session_context()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37a4b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict, non_PBE_marginal_over_track_ID, (time_bin_containers, time_window_centers, track_marginal_posterior_df), masked_pseudo2D_continuous_specific_decoded_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf7487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_attributes(short_name=None, tags=['WORKING'], input_requires=[], output_provides=[], uses=[], used_by=[], creation_date='2025-03-04 11:36', related_items=[])\n",
    "def add_decoded_posterior_row(active_2d_plot, identifier_name: str, a_decoder: BasePositionDecoder, a_decoded_result: DecodedFilterEpochsResult, extended_dock_title_info: Optional[str]=None):\n",
    "    \"\"\" adds a new decoder track to the active_2d_plot \n",
    "    \"\"\"\n",
    "    from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import SynchronizedPlotMode\n",
    "    from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_1D_most_likely_position_comparsions\n",
    "    from neuropy.utils.matplotlib_helpers import get_heatmap_cmap\n",
    "    from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import FixedCustomColormaps\n",
    "    from pyphocorehelpers.gui.Qt.color_helpers import ColormapHelpers\n",
    "\n",
    "    ## ✅ Add a new row for each of the four 1D directional decoders:\n",
    "    # identifier_name: str = f'ContinuousDecode_{a_decoder_name}'\n",
    "    if extended_dock_title_info is not None:\n",
    "        identifier_name += extended_dock_title_info ## add extra info like the time_bin_size in ms\n",
    "    # print(f'identifier_name: {identifier_name}')\n",
    "\n",
    "    # print(f'identifier_name: {identifier_name}')\n",
    "    widget, matplotlib_fig, matplotlib_fig_axes, dock_item = active_2d_plot.add_new_matplotlib_render_plot_widget(name=identifier_name, dockSize=(65, 200), display_config=None, sync_mode=SynchronizedPlotMode.TO_WINDOW)\n",
    "    an_ax = matplotlib_fig_axes[0]\n",
    "\n",
    "    active_decoder = deepcopy(a_decoder)\n",
    "    assert a_decoded_result is not None, f\"a_decoded_result should not be None anymore.\"\n",
    "\n",
    "    if a_decoded_result is not None:\n",
    "        active_result = deepcopy(a_decoded_result) # already decoded\n",
    "        assert (active_result.num_filter_epochs == 1), f\"currently only supports decoded results (DecodedFilterEpochsResult) computed with a single epoch for all time bins, but active_result.num_filter_epochs: {active_result.num_filter_epochs}\"\n",
    "        active_marginals = active_result.marginal_x_list[0]\n",
    "    else:\n",
    "        # no previously decoded result, fallback to the decoder's internal properties        \n",
    "        active_marginals = active_decoder.marginal.x\n",
    "        \n",
    "\n",
    "    variable_name='x'\n",
    "    active_bins = deepcopy(active_decoder.xbin)\n",
    "    time_window_centers = deepcopy(active_result.time_bin_containers[0].centers)\n",
    "    # active_most_likely_positions = active_marginals.most_likely_positions_1D # Raw decoded positions\n",
    "    active_most_likely_positions = None\n",
    "    active_posterior = active_marginals.p_x_given_n\n",
    "\n",
    "    # active_posterior = deepcopy(a_1D_posterior)\n",
    "    \n",
    "    # most_likely_positions_mode: 'standard'|'corrected'\n",
    "    # fig, curr_ax = curr_active_pipeline.display('_display_plot_marginal_1D_most_likely_position_comparisons', _active_config_name, variable_name='x', most_likely_positions_mode='corrected', ax=an_ax) # ax=active_2d_plot.ui.matplotlib_view_widget.ax\n",
    "    posterior_heatmap_imshow_kwargs = dict(\n",
    "        cmap = get_heatmap_cmap(cmap='viridis', bad_color='black', under_color='white', over_color='red'),\n",
    "    )\n",
    "\n",
    "    measured_position_df = None # Note: for some reason setting `measured_position_df` to anything other than None here messes up the plotting entirely. Set it to None now, and if we want measured positions plot them after\n",
    "    ## Actual plotting portion:\n",
    "    fig, an_ax = plot_1D_most_likely_position_comparsions(measured_position_df=None, time_window_centers=time_window_centers, xbin=active_bins,\n",
    "                                                            posterior=active_posterior,\n",
    "                                                            active_most_likely_positions_1D=active_most_likely_positions,\n",
    "                                                            ax=an_ax, variable_name=variable_name, debug_print=True, enable_flat_line_drawing=False,\n",
    "                                                            posterior_heatmap_imshow_kwargs=posterior_heatmap_imshow_kwargs)\n",
    "\n",
    "\n",
    "\n",
    "    widget.plots_data.active_decoder = active_decoder\n",
    "    widget.plots_data.a_decoded_result = a_decoded_result\n",
    "\n",
    "    # active_bins = active_decoder.xbin\n",
    "\n",
    "    # # active_most_likely_positions = active_marginals.most_likely_positions_1D # Raw decoded positions\n",
    "    # active_most_likely_positions = None\n",
    "    # active_posterior = active_marginals.p_x_given_n\n",
    "    return widget, matplotlib_fig, an_ax, dock_item\n",
    "\n",
    "\n",
    "add_decoded_posterior_row(active_2d_plot, identifier_name=f'Masked Non-PBE Pseudo2D', a_decoder=deepcopy(non_PBE_all_directional_pf1D_Decoder), a_decoded_result=masked_pseudo2D_continuous_specific_decoded_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb796232",
   "metadata": {},
   "source": [
    "# <a id='toc36_'></a>[2025-03-11 Apply the masking strategy introduced with the non-PBE epoch analyses on the other `DecodedFilterEpochsResult`s produced by the lap-constructed decoders (TrackTemplates)](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342da66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from neuropy.core.epoch import ensure_dataframe, ensure_Epoch\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring\n",
    "from neuropy.utils.result_context import DisplaySpecifyingIdentifyingContext\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import EpochFilteringMode, _compute_proper_filter_epochs\n",
    "\n",
    "KnownNamedDecoderTrainedComputeEpochsType = Literal['laps', 'non_pbe']\n",
    "# nonPBE_results = non\n",
    "\n",
    "filtered_epochs_df = None\n",
    "\n",
    "## INPUTS: curr_active_pipeline, track_templates, a_decoded_filter_epochs_decoder_result_dict\n",
    "\n",
    "## INPUTS: directional_decoders_epochs_decode_result, filtered_epochs_df\n",
    "\n",
    "\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = deepcopy(curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']) ## GENERAL\n",
    "# a_new_fully_generic_result = _subfn_add_spikes_per_t_bin_masked_variants(a_new_fully_generic_result, directional_decoders_epochs_decode_result=directional_decoders_epochs_decode_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ba386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict, non_PBE_marginal_over_track_ID, (time_bin_containers, time_window_centers, track_marginal_posterior_df) = nonPBE_results._build_merged_joint_placefields_and_decode(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)))\n",
    "masked_pseudo2D_continuous_specific_decoded_result, _mask_index_tuple = pseudo2D_continuous_specific_decoded_result.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)))\n",
    "# (all_time_bin_indicies, last_valid_indicies) = _mask_index_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5739b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from typing import Literal\n",
    "# Define a type that can only be one of these specific strings\n",
    "KnownNamedDecodingEpochsType = Literal['laps', 'replay', 'ripple', 'pbe', 'non_pbe']\n",
    "# Define a type that can only be one of these specific strings\n",
    "MaskedTimeBinFillType = Literal['ignore', 'last_valid', 'nan_filled', 'dropped'] ## used in `DecodedFilterEpochsResult.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(...)` to specify how invalid bins (due to too few spikes) are treated.\n",
    "\n",
    "GenericResultTupleIndexType: TypeAlias = IdentifyingContext # an template/stand-in variable that aims to abstract away the unique-hashable index of a single result computed with a given set of parameters. Not yet fully implemented 2025-03-09 17:50 \n",
    "\n",
    "test_identifier: IdentifyingContext = IdentifyingContext(known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='last_valid')\n",
    "\n",
    "test_identifier.get_description(include_property_names=True, separator=\"|\", key_value_separator=':') # , replace_separator_in_property_names='|'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828384eb",
   "metadata": {
    "tags": [
     "active-2025-03-11"
    ]
   },
   "outputs": [],
   "source": [
    "## OUTPUTS:\n",
    "# a_new_fully_generic_result\n",
    "\n",
    "for a_context, a_marginal_df in a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict.items():\n",
    "    param_sep_str: str = '¦'\n",
    "    # param_sep_str: str = ''\n",
    "    # param_sep_str: str = ' ⁖'\n",
    "    key_val_sep_str: str = ':'\n",
    "    a_ctxt_str: str = a_context.get_description(separator=param_sep_str, replace_separator_in_property_names='_', include_property_names=True, key_value_separator=key_val_sep_str)\n",
    "    # a_ctxt_str: str = a_context.get_initialization_code_string()\n",
    "    print(f'a_context: \"<{a_ctxt_str}>\" - np.shape(a_marginal_df): {np.shape(a_marginal_df)}')\n",
    "    \n",
    "\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:laps¦masked_time_bin_fill_type:ignore\" - np.shape(a_marginal_df): (14350, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:laps¦masked_time_bin_fill_type:last_valid\" - np.shape(a_marginal_df): (14350, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:laps¦masked_time_bin_fill_type:nan_filled\" - np.shape(a_marginal_df): (14350, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:pbe¦masked_time_bin_fill_type:ignore\" - np.shape(a_marginal_df): (1569, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:pbe¦masked_time_bin_fill_type:last_valid\" - np.shape(a_marginal_df): (1569, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:pbe¦masked_time_bin_fill_type:nan_filled\" - np.shape(a_marginal_df): (1569, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:non_pbe¦masked_time_bin_fill_type:ignore\" - np.shape(a_marginal_df): (43377, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:non_pbe¦masked_time_bin_fill_type:last_valid\" - np.shape(a_marginal_df): (43377, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:non_pbe¦masked_time_bin_fill_type:nan_filled\" - np.shape(a_marginal_df): (43377, 9)\n",
    "# a_context: \"trained_compute_epochs:laps¦pfND_ndim:1¦decoder_identifier:pseudo2D¦time_bin_size:0.025¦known_named_decoding_epochs_type:laps¦masked_time_bin_fill_type:ignore¦data_grain:per_time_bin\" - np.shape(a_marginal_df): (14350, 15)\n",
    "# a_context: \"trained_compute_epochs:laps¦pfND_ndim:1¦decoder_identifier:pseudo2D¦time_bin_size:0.025¦known_named_decoding_epochs_type:laps¦masked_time_bin_fill_type:ignore¦data_grain:per_epoch\" - np.shape(a_marginal_df): (74, 6)\n",
    "# a_context: \"trained_compute_epochs:laps¦pfND_ndim:1¦decoder_identifier:pseudo2D¦time_bin_size:0.025¦known_named_decoding_epochs_type:pbe¦masked_time_bin_fill_type:ignore¦data_grain:per_time_bin\" - np.shape(a_marginal_df): (1165, 15)\n",
    "# a_context: \"trained_compute_epochs:laps¦pfND_ndim:1¦decoder_identifier:pseudo2D¦time_bin_size:0.025¦known_named_decoding_epochs_type:pbe¦masked_time_bin_fill_type:ignore¦data_grain:per_epoch\" - np.shape(a_marginal_df): (133, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188ef752",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a_new_fully_generic_result.filter_epochs_pseudo2D_continuous_specific_decoded_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38476959",
   "metadata": {},
   "source": [
    "##### <a id='toc36_1_1_1_1_'></a>[2025-03-11 11:13 not sure if this is the old version or if it adds something to the `a_new_fully_generic_result`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f9ccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Common/shared for all decoded epochs:\n",
    "unique_decoder_names = ['long', 'short']\n",
    "non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict, non_PBE_marginal_over_track_ID, (time_bin_containers, time_window_centers, track_marginal_posterior_df) = nonPBE_results._build_merged_joint_placefields_and_decode(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline))) # , filter_epochs=deepcopy(global_any_laps_epochs_obj)\n",
    "\n",
    "## from dict of filter_epochs to decode:\n",
    "global_replays_df: pd.DataFrame = TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].replay))\n",
    "filter_epochs_to_decode_dict: Dict[KnownNamedDecodingEpochsType, Epoch] = {'laps': ensure_Epoch(deepcopy(global_any_laps_epochs_obj)),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   'pbe': ensure_Epoch(deepcopy(global_session.pbe.get_non_overlapping())),\n",
    "\t\t\t\t\t\t\t\t#  'ripple': ensure_Epoch(deepcopy(global_session.ripple)),\n",
    "\t\t\t\t\t\t\t\t#   'replay': ensure_Epoch(deepcopy(global_replays_df)),\n",
    "\t\t\t\t\t\t\t\t  'non_pbe': ensure_Epoch(deepcopy(global_session.non_pbe)),\n",
    "\t\t\t\t\t\t\t\t  }\n",
    "# filter_epochs_to_decode_dict\n",
    "\n",
    "## Perform the decoding and masking as needed for invalid bins:\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "a_general_decoder_dict_decoded_epochs_dict_result: GeneralDecoderDictDecodedEpochsDictResult = EpochComputationsComputationsContainer._build_output_decoded_posteriors(non_PBE_all_directional_pf1D_Decoder=non_PBE_all_directional_pf1D_Decoder, # pseudo2D_continuous_specific_decoded_result=pseudo2D_continuous_specific_decoded_result,\n",
    "    filter_epochs_to_decode_dict=filter_epochs_to_decode_dict,\n",
    "    unique_decoder_names=unique_decoder_names, spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), epochs_decoding_time_bin_size=epochs_decoding_time_bin_size,\n",
    "    session_name=session_name, t_start=t_start, t_delta=t_delta, t_end=t_end,\n",
    ")\n",
    "\n",
    "\n",
    "## OUTPUTS: filter_epochs_pseudo2D_continuous_specific_decoded_result, filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict\n",
    "# 58sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d05ac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# filter_epochs_pseudo2D_continuous_specific_decoded_result, filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict\n",
    "retro_general_decoder_dict_decoded_epochs_dict_result: GeneralDecoderDictDecodedEpochsDictResult = EpochComputationsComputationsContainer._build_output_decoded_posteriors(non_PBE_all_directional_pf1D_Decoder=non_PBE_all_directional_pf1D_Decoder, # pseudo2D_continuous_specific_decoded_result=pseudo2D_continuous_specific_decoded_result,\n",
    "    filter_epochs_to_decode_dict=filter_epochs_to_decode_dict,\n",
    "    unique_decoder_names=unique_decoder_names, spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), epochs_decoding_time_bin_size=epochs_decoding_time_bin_size,\n",
    "    session_name=session_name, t_start=t_start, t_delta=t_delta, t_end=t_end,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021b0ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try fresh 2025-03-11-style decoding of the TrackTemplates:\n",
    "global_session = curr_active_pipeline.filtered_sessions[global_epoch_name]\n",
    "\n",
    "## from dict of filter_epochs to decode:\n",
    "global_replays_df: pd.DataFrame = TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(deepcopy(global_session.replay))\n",
    "global_any_laps_epochs_obj = curr_active_pipeline.computation_results[global_epoch_name].computation_config.pf_params.computation_epochs # global_session.get\n",
    "filter_epochs_to_decode_dict: Dict[KnownNamedDecodingEpochsType, Epoch] = {'laps': ensure_Epoch(deepcopy(global_any_laps_epochs_obj)),\n",
    "                                                                        'pbe': ensure_Epoch(deepcopy(global_session.pbe.get_non_overlapping())),\n",
    "                                #  'ripple': ensure_Epoch(deepcopy(global_session.ripple)),\n",
    "                                #   'replay': ensure_Epoch(deepcopy(global_replays_df)),\n",
    "                                'non_pbe': ensure_Epoch(deepcopy(global_session.non_pbe)),\n",
    "                                }\n",
    "# filter_epochs_to_decode_dict\n",
    "\n",
    "## constrain all epochs to be at least two decoding time bins long, or drop them entirely:\n",
    "filter_epochs_to_decode_dict = {k:_compute_proper_filter_epochs(epochs_df=v, desired_decoding_time_bin_size=epochs_decoding_time_bin_size, minimum_event_duration=(2.0 * epochs_decoding_time_bin_size), mode=EpochFilteringMode.DropShorter)[0] for k, v in filter_epochs_to_decode_dict.items()} # `[0]` gets just the dataframe, as in DropShorter mode the time_bin_size is unchanged\n",
    "\n",
    "## Perform the decoding and masking as needed for invalid bins:\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6a401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_decoders_epochs_decode_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41fef63",
   "metadata": {},
   "source": [
    "# 2025-03-24 Get the old result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8652f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = deepcopy(curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']) ## GENERAL\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = deepcopy(curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders'])\n",
    "spikes_df = deepcopy(get_proper_global_spikes_df(curr_active_pipeline))\n",
    "\n",
    "laps_all_epoch_bins_marginals_df: pd.DataFrame = deepcopy(directional_merged_decoders_result.laps_all_epoch_bins_marginals_df)\n",
    "laps_time_bin_marginals_df: pd.DataFrame = deepcopy(directional_merged_decoders_result.laps_time_bin_marginals_df)\n",
    "laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf31bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "laps_time_bin_marginals_df = laps_time_bin_marginals_df.across_session_identity.add_session_df_columns(session_name=session_name, time_bin_size=0.025, t_start=t_start, curr_session_t_delta=t_delta, t_end=t_end)\n",
    "laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03d3caf",
   "metadata": {},
   "source": [
    "# 2025-03-24 11:19 TimeBinAggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36957842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "\n",
    "# INPUT: a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult \n",
    "a_new_fully_generic_result.get_matching_contexts(context_query=IdentifyingContext(data_grain= 'per_epoch'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a5eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_new_fully_generic_result.get_matching_contexts(context_query=IdentifyingContext())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f289430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "a_new_fully_generic_result.get_matching_contexts(context_query=IdentifyingContext(trained_compute_epochs='laps', decoder_identifier='pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type='laps',\n",
    "    masked_time_bin_fill_type='ignore',\n",
    "    # masked_time_bin_fill_type='dropped',\n",
    "    data_grain= 'per_time_bin'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51118ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get all non-global, `data_grain= 'per_time_bin'`\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=IdentifyingContext(trained_compute_epochs='laps', decoder_identifier='pseudo2D', time_bin_size=0.025,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t known_named_decoding_epochs_type=['pbe', 'laps'],\n",
    "    masked_time_bin_fill_type='ignore',\n",
    "    # masked_time_bin_fill_type='dropped',\n",
    "    data_grain= 'per_time_bin'))        \n",
    "        \n",
    "flat_decoded_marginal_posterior_df_context_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8390426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_matching_context, a_result, a_decoder, a_decoded_time_bin_marginal_posterior_df = a_new_fully_generic_result.get_results_matching_contexts(context_query=IdentifyingContext(trained_compute_epochs='laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'global', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'), return_multiple_matches=False)\n",
    "best_matching_context, a_result, a_decoder, a_decoded_time_bin_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=IdentifyingContext(trained_compute_epochs='laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type='laps',\n",
    "    masked_time_bin_fill_type='ignore',\n",
    "    # masked_time_bin_fill_type='dropped',\n",
    "    data_grain= 'per_time_bin'))\n",
    "\n",
    "a_decoded_time_bin_marginal_posterior_df\n",
    "\n",
    "## OUTPUTS: a_decoded_time_bin_marginal_posterior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592a128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_matching_context, a_result, a_decoder, a_decoded_time_bin_marginal_posterior_df = a_new_fully_generic_result.get_results_matching_contexts(context_query=IdentifyingContext(trained_compute_epochs='laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'global', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'), return_multiple_matches=False)\n",
    "best_matching_context, a_result, a_decoder, a_decoded_time_bin_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=IdentifyingContext(trained_compute_epochs='laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type='pbe',\n",
    "    masked_time_bin_fill_type='ignore',\n",
    "    # masked_time_bin_fill_type='dropped',\n",
    "    data_grain= 'per_time_bin'))\n",
    "\n",
    "a_decoded_time_bin_marginal_posterior_df\n",
    "\n",
    "## OUTPUTS: a_decoded_time_bin_marginal_posterior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729d8a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(list(a_decoded_time_bin_marginal_posterior_df.columns)) # ['P_LR', 'P_RL', 'P_Long', 'P_Short', 'long_LR', 'long_RL', 'short_LR', 'short_RL', 'result_t_bin_idx', 'epoch_df_idx', 'parent_epoch_label', 'label', 'start', 't_bin_center', 'stop', 'delta_aligned_start_t', 'session_name', 'time_bin_size', 'pre_post_delta_category', 'trained_compute_epochs', 'pfND_ndim', 'decoder_identifier', 'known_named_decoding_epochs_type', 'masked_time_bin_fill_type', 'data_grain', 'is_t_bin_center_fake', 'rolling_avg_P_Short', 'mean_P_Short']\n",
    "broken_columns_dict = {IdentifyingContext(known_named_decoding_epochs_type= 'global', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'): ['result_t_bin_idx', 'epoch_df_idx', 'parent_epoch_label'],\n",
    "                      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses.time_bin_aggregation import TimeBinAggregation\n",
    "\n",
    "## INPUTS: a_decoded_time_bin_marginal_posterior_df\n",
    "\n",
    "n_rolling_avg_window_tbins: int = 3\n",
    "# Create a copy to avoid modifying the original\n",
    "result_df = a_decoded_time_bin_marginal_posterior_df.copy()\n",
    "epoch_partitioned_dfs_dict = a_decoded_time_bin_marginal_posterior_df.pho.partition_df_dict(partitionColumn='parent_epoch_label')\n",
    "\n",
    "# Process each partition\n",
    "for k, df in epoch_partitioned_dfs_dict.items():\n",
    "    rolling_avg = TimeBinAggregation.ToPerEpoch.peak_rolling_avg(df=df, column='P_Short', window=n_rolling_avg_window_tbins)    \n",
    "    # Calculate the mean of P_Short for this group\n",
    "    mean_p_short = TimeBinAggregation.ToPerEpoch.mean(df=df, column='P_Short')\n",
    "\n",
    "    # Get indices from this partition\n",
    "    indices = df.index\n",
    "    # Assign the result to the corresponding rows in the result dataframe\n",
    "    result_df.loc[indices, 'rolling_avg_P_Short'] = rolling_avg\n",
    "    result_df.loc[indices, 'mean_P_Short'] = mean_p_short  # Same mean value for all rows in group\n",
    "    \n",
    "    # result_df.loc[indices\n",
    "\n",
    "## OUTPUTS: result_df\n",
    "\n",
    "a_decoded_time_bin_marginal_posterior_df = deepcopy(result_df)\n",
    "a_decoded_time_bin_marginal_posterior_df\n",
    "\n",
    "# Then keep only the first entry for each 'parent_epoch_label'\n",
    "a_decoded_per_epoch_marginals_df = a_decoded_time_bin_marginal_posterior_df.groupby('parent_epoch_label').first().reset_index()\n",
    "a_decoded_per_epoch_marginals_df\n",
    "\n",
    "## OUTPUTS: a_decoded_time_bin_marginal_posterior_df, a_decoded_per_epoch_marginals_df\n",
    "## Columns of interest: 'rolling_avg_P_Short'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bc734a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses.time_bin_aggregation import TimeBinAggregation\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "\n",
    "a_decoded_per_epoch_marginals_df, a_decoded_time_bin_marginal_posterior_df = GenericDecoderDictDecodedEpochsDictResult._perform_per_epoch_time_bin_aggregation(a_decoded_time_bin_marginal_posterior_df=a_decoded_time_bin_marginal_posterior_df, probabilitY_column_to_aggregate='P_Short', n_rolling_avg_window_tbins=3)\n",
    "\n",
    "a_decoded_time_bin_marginal_posterior_df\n",
    "a_decoded_per_epoch_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae48cb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext, CollisionOutcome\n",
    "from neuropy.analyses.time_bin_aggregation import TimeBinAggregation\n",
    "\n",
    "## get all non-global, `data_grain= 'per_time_bin'`\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=IdentifyingContext(trained_compute_epochs='laps', decoder_identifier='pseudo2D', time_bin_size=0.025,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t known_named_decoding_epochs_type=['pbe', 'laps'],\n",
    "    masked_time_bin_fill_type=('ignore', 'dropped'),\n",
    "    # masked_time_bin_fill_type='dropped',\n",
    "    data_grain= 'per_time_bin'))        \n",
    "\n",
    "\n",
    "\n",
    "_newly_updated_values_tuple = a_new_fully_generic_result.compute_all_per_epoch_aggregations_from_per_time_bin_results(flat_decoded_marginal_posterior_df_context_dict=flat_decoded_marginal_posterior_df_context_dict)\n",
    "per_time_bin_to_per_epoch_context_map_dict, flat_decoded_marginal_posterior_df_per_epoch_marginals_df_context_dict, flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict = _newly_updated_values_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fdc5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if TimeBinAggegreations are performed:\n",
    "per_time_bin_flat_context_list, per_time_bin_flat_result_context_dict, per_time_bin_flat_decoder_context_dict, per_time_bin_flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=IdentifyingContext(trained_compute_epochs='laps', decoder_identifier='pseudo2D', known_named_decoding_epochs_type=['pbe', 'laps'], data_grain= 'per_time_bin'))        \n",
    "per_time_bin_keys = list(per_time_bin_flat_decoded_marginal_posterior_df_context_dict.keys())\n",
    "\n",
    "## get all non-global, `data_grain= 'per_time_bin'`\n",
    "per_epoch_flat_context_list, per_epoch_flat_result_context_dict, per_epoch_flat_decoder_context_dict, per_epoch_flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=IdentifyingContext(trained_compute_epochs='laps', decoder_identifier='pseudo2D', known_named_decoding_epochs_type=['pbe', 'laps'], data_grain= 'per_epoch'))        \n",
    "per_epoch_keys = list(per_epoch_flat_decoded_marginal_posterior_df_context_dict.keys())\n",
    "len(per_time_bin_keys) == len(per_epoch_keys)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5a33a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## INPUTS: flat_decoded_marginal_posterior_df_context_dict\n",
    "per_time_bin_to_per_epoch_context_map_dict = {}\n",
    "flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict = {}\n",
    "flat_decoded_marginal_posterior_df_per_epoch_marginals_df_context_dict = {}\n",
    "for a_per_time_bin_ctxt, a_decoded_time_bin_marginal_posterior_df in flat_decoded_marginal_posterior_df_context_dict.items():\n",
    "    a_decoded_per_epoch_marginals_df, a_decoded_time_bin_marginal_posterior_df = GenericDecoderDictDecodedEpochsDictResult._perform_per_epoch_time_bin_aggregation(a_decoded_time_bin_marginal_posterior_df=a_decoded_time_bin_marginal_posterior_df, probabilitY_column_to_aggregate='P_Short', n_rolling_avg_window_tbins=3)\n",
    "    a_per_epoch_ctxt = TimeBinAggregation.ToPerEpoch.get_per_epoch_ctxt_from_per_time_bin_ctxt(a_per_time_bin_ctxt=a_per_time_bin_ctxt)\n",
    "    per_time_bin_to_per_epoch_context_map_dict[a_per_time_bin_ctxt] = a_per_epoch_ctxt\n",
    "    flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict[a_per_time_bin_ctxt] = deepcopy(a_decoded_time_bin_marginal_posterior_df)\n",
    "    flat_decoded_marginal_posterior_df_per_epoch_marginals_df_context_dict[a_per_epoch_ctxt] = a_decoded_per_epoch_marginals_df\n",
    "\n",
    "\n",
    "## OUTPUTS: per_time_bin_to_per_epoch_context_map_dict, flat_decoded_marginal_posterior_df_per_epoch_marginals_df_context_dict, flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict\n",
    "flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict\n",
    "flat_decoded_marginal_posterior_df_per_epoch_marginals_df_context_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f9ca7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: per_time_bin_to_per_epoch_context_map_dict, flat_decoded_marginal_posterior_df_per_epoch_marginals_df_context_dict, flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict\n",
    "# flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict\n",
    "# flat_decoded_marginal_posterior_df_per_epoch_marginals_df_context_dict\n",
    "\n",
    "for a_per_time_bin_ctxt, a_decoded_time_bin_marginal_posterior_df in flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict.items():\n",
    "    a_per_epoch_ctxt = per_time_bin_to_per_epoch_context_map_dict[a_per_time_bin_ctxt]\n",
    "    a_decoded_time_bin_marginal_posterior_df = flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict[a_per_time_bin_ctxt]\n",
    "    a_decoded_per_epoch_marginals_df = flat_decoded_marginal_posterior_df_per_epoch_marginals_df_context_dict[a_per_epoch_ctxt]\n",
    "    a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict[a_per_time_bin_ctxt] = a_decoded_time_bin_marginal_posterior_df\n",
    "    a_best_matching_context, a_result, a_decoder, a_decoded_time_bin_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(a_per_time_bin_ctxt)\n",
    "    # a_best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_matching_context(a_per_time_bin_ctxt, return_multiple_matches=False)\n",
    "    # a_result\n",
    "    print(f'updating: \"{a_per_epoch_ctxt}\"')\n",
    "    print(f\"\\tWARN: TODO 2025-04-07 19:22: - [ ] a_result is wrong, it's the per-time-bin version not the per-epoch version\") #TODO 2025-04-07 19:22: - [ ] a_result is wrong, it's the per-time-bin version not the per-epoch version\n",
    "\n",
    "    ## need to get updated a_decoder, a_result\n",
    "    \n",
    "    # a_dropping_masked_pseudo2D_continuous_specific_decoded_result, _dropping_mask_index_tuple = a_result.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(spikes_df=deepcopy(spikes_df), masked_bin_fill_mode=a_masked_bin_fill_mode) ## Masks the low-firing bins so they don't confound the analysis.\n",
    "    # ## Computes marginals for `dropping_masked_laps_pseudo2D_continuous_specific_decoded_result`\n",
    "    # a_dropping_masked_decoded_marginal_posterior_df = DirectionalPseudo2DDecodersResult.perform_compute_specific_marginals(a_result=a_dropping_masked_pseudo2D_continuous_specific_decoded_result, marginal_context=a_masked_updated_context)\n",
    "    a_new_fully_generic_result.updating_results_for_context(new_context=a_per_epoch_ctxt, a_result=deepcopy(a_result), a_decoder=deepcopy(a_decoder), a_decoded_marginal_posterior_df=deepcopy(a_decoded_per_epoch_marginals_df)) ## update using the result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd3ce45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a_new_fully_generic_result.updating_results_for_context(new_context=a_masked_updated_context, a_result=deepcopy(a_dropping_masked_pseudo2D_continuous_specific_decoded_result), a_decoder=deepcopy(a_decoder), a_decoded_marginal_posterior_df=deepcopy(a_dropping_masked_decoded_marginal_posterior_df)) ## update using the result\n",
    "\n",
    "\n",
    "## INPUTS: a_new_fully_generic_result\n",
    "base_contexts_list = [IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=time_bin_size, known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='ignore', data_grain='per_time_bin'),\n",
    "                    IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=time_bin_size, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore', data_grain='per_time_bin'),\n",
    "                    IdentifyingContext(trained_compute_epochs='non_pbe', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=time_bin_size, known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='ignore', data_grain='per_time_bin'),\n",
    "                    IdentifyingContext(trained_compute_epochs='non_pbe', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=time_bin_size, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore', data_grain='per_time_bin')]\n",
    "masked_contexts_dict = {}\n",
    "\n",
    "for a_base_context in base_contexts_list:\n",
    "\n",
    "    a_best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_matching_contexts(a_base_context, return_multiple_matches=False)\n",
    "    ## `a_decoder` is None for some reason?`\n",
    "    ## INPUTS: a_result, masked_bin_fill_mode\n",
    "    a_masked_updated_context: IdentifyingContext = deepcopy(a_best_matching_context).overwriting_context(masked_time_bin_fill_type=a_masked_bin_fill_mode, data_grain='per_time_bin')\n",
    "    masked_contexts_dict[a_base_context] = a_masked_updated_context\n",
    "    if debug_print:\n",
    "        print(f'a_masked_updated_context: {a_masked_updated_context}')\n",
    "    \n",
    "    ## MASKED with NaNs (no backfill):\n",
    "    a_dropping_masked_pseudo2D_continuous_specific_decoded_result, _dropping_mask_index_tuple = a_result.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(spikes_df=deepcopy(spikes_df), masked_bin_fill_mode=a_masked_bin_fill_mode) ## Masks the low-firing bins so they don't confound the analysis.\n",
    "    ## Computes marginals for `dropping_masked_laps_pseudo2D_continuous_specific_decoded_result`\n",
    "    a_dropping_masked_decoded_marginal_posterior_df = DirectionalPseudo2DDecodersResult.perform_compute_specific_marginals(a_result=a_dropping_masked_pseudo2D_continuous_specific_decoded_result, marginal_context=a_masked_updated_context)\n",
    "    a_new_fully_generic_result.updating_results_for_context(new_context=a_masked_updated_context, a_result=deepcopy(a_dropping_masked_pseudo2D_continuous_specific_decoded_result), a_decoder=deepcopy(a_decoder), a_decoded_marginal_posterior_df=deepcopy(a_dropping_masked_decoded_marginal_posterior_df)) ## update using the result\n",
    "    \n",
    "## OUTPUTS: masked_contexts_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4273d42a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c76f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import build_single_plotly_marginal_scatter_and_hist_over_time\n",
    "\n",
    "## INPUTS: a_decoded_time_bin_marginal_posterior_df\n",
    "#INPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder\n",
    "_flat_out_figs_dict = {}\n",
    "# a_target_context = curr_active_pipeline.build_display_context_for_filtered_session(filtered_session_name='maze_any', display_fn_name='DirectionalMergedDecoders')\n",
    "a_target_context = curr_active_pipeline.build_display_context_for_session(display_fn_name='a_decoded_time_bin_marginal_posterior_df', time_bin_size=0.025)\n",
    "a_fig, a_figure_context = build_single_plotly_marginal_scatter_and_hist_over_time(a_decoded_posterior_df=a_decoded_time_bin_marginal_posterior_df, a_target_context=a_target_context, y='P_Short')\n",
    "_flat_out_figs_dict[a_figure_context] = a_fig\n",
    "\n",
    "a_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d75da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import build_single_plotly_marginal_scatter_and_hist_over_time\n",
    "\n",
    "## INPUTS: a_decoded_per_epoch_marginals_df\n",
    "#INPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder\n",
    "y_var_name: str = 'rolling_avg_P_Short'\n",
    "_flat_out_figs_dict = {}\n",
    "# a_target_context = curr_active_pipeline.build_display_context_for_filtered_session(filtered_session_name='maze_any', display_fn_name='DirectionalMergedDecoders')\n",
    "a_target_context = curr_active_pipeline.build_display_context_for_session(display_fn_name='a_decoded_per_epoch_marginals_df', time_bin_size=0.025)\n",
    "a_fig, a_figure_context = build_single_plotly_marginal_scatter_and_hist_over_time(a_decoded_posterior_df=a_decoded_per_epoch_marginals_df, a_target_context=a_target_context, y=y_var_name)\n",
    "_flat_out_figs_dict[a_figure_context] = a_fig\n",
    "\n",
    "a_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ce3de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder\n",
    "_flat_out_figs_dict = {}\n",
    "# a_target_context = curr_active_pipeline.build_display_context_for_filtered_session(filtered_session_name='maze_any', display_fn_name='DirectionalMergedDecoders')\n",
    "a_target_context = curr_active_pipeline.build_display_context_for_session(display_fn_name='laps_per_epoch_marginals_df', time_bin_size=0.025)\n",
    "a_fig, a_figure_context = build_single_plotly_marginal_scatter_and_hist_over_time(a_decoded_posterior_df=laps_per_epoch_marginals_df, a_target_context=a_target_context)\n",
    "_flat_out_figs_dict[a_figure_context] = a_fig\n",
    "\n",
    "a_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a467e0bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca9e4656",
   "metadata": {},
   "source": [
    "# 2025-04-11 - Full-session decoded marginal outputs as yellow-blue plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421fcd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _plot_all_time_decoded_marginal_figures\n",
    "\n",
    "\n",
    "## INPUTS: a_new_fully_generic_result\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='nan_filled', data_grain='per_time_bin')\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='ignore', data_grain='per_time_bin')\n",
    "best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=a_target_context, debug_print=False)\n",
    "epochs_decoding_time_bin_size = best_matching_context.get('time_bin_size', None)\n",
    "assert epochs_decoding_time_bin_size is not None\n",
    "\n",
    "## INPUTS: spike_raster_window, active_2d_plot\n",
    "_all_tracks_active_out_figure_paths, _all_tracks_out_artists, _all_tracks_out_axes = _plot_all_time_decoded_marginal_figures(curr_active_pipeline=curr_active_pipeline, best_matching_context=best_matching_context, a_decoded_marginal_posterior_df=a_decoded_marginal_posterior_df, spike_raster_window=spike_raster_window, active_2d_plot=active_2d_plot, epochs_decoding_time_bin_size=epochs_decoding_time_bin_size)\n",
    "_all_tracks_active_out_figure_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d24974",
   "metadata": {},
   "source": [
    "# 🔶 2025-01-15 - Lap Transition Matrix Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b1c34e",
   "metadata": {
    "tags": [
     "run-group-transition-matricies"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import TransitionMatrixComputations\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalDecodersContinuouslyDecodedResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import plot_blocked_transition_matrix\n",
    "from neuropy.utils.matplotlib_helpers import perform_update_title_subtitle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import _perform_plot_P_Context_State_Transition_Matrix, _perform_plot_position_Transition_Matrix\n",
    "\n",
    "# desired_time_bin_size = 0.050 # 50ms\n",
    "desired_time_bin_size = 0.025 # 25ms\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'], computation_kwargs_list=[{'time_bin_size': desired_time_bin_size, 'should_disable_cache': False}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "\n",
    "\n",
    "## Uses the `global_computation_results.computed_data['DirectionalDecodersDecoded']`\n",
    "directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "# all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "pseudo2D_decoder: BasePositionDecoder = directional_decoders_decode_result.pseudo2D_decoder\n",
    "\n",
    "# all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "continuously_decoded_pseudo2D_decoder_dict = directional_decoders_decode_result.continuously_decoded_pseudo2D_decoder_dict\n",
    "# continuously_decoded_result_cache_dict\n",
    "continuously_decoded_pseudo2D_decoder_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab688a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import EpochComputationFunctions, EpochComputationsComputationsContainer\n",
    "from neuropy.utils.mixins.binning_helpers import BinningContainer, BinningInfo\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import complete_all_transition_matricies, build_transition_matricies\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import split_transition_matricies_results_pre_post_delta_category\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import LongShortTrackDataframeAccessor\n",
    "\n",
    "valid_EpochComputations_result: EpochComputationsComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['EpochComputations']\n",
    "a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult = valid_EpochComputations_result.a_generic_decoder_dict_decoded_epochs_dict_result\n",
    "\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.050, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore') # , decoder_identifier='long_LR'\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore', data_grain='per_epoch') # , time_bin_size=0.050, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore', decoder_identifier='long_LR'\n",
    "\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='ignore', data_grain='per_epoch') ## Laps\n",
    "# any_matching_contexts_list, result_context_dict, decoder_context_dict, decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context)\n",
    "\n",
    "# common_constraint_dict = dict(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, masked_time_bin_fill_type='ignore')\n",
    "# common_constraint_dict = dict(trained_compute_epochs='laps', time_bin_size=0.025, masked_time_bin_fill_type='nan_filled') # , pfND_ndim=1\n",
    "common_constraint_dict = dict(trained_compute_epochs='laps', time_bin_size=0.060, masked_time_bin_fill_type='nan_filled')\n",
    "\n",
    "## Laps context:\n",
    "a_laps_target_context: IdentifyingContext = IdentifyingContext(known_named_decoding_epochs_type='laps', **common_constraint_dict, data_grain='per_epoch') ## Laps\n",
    "laps_target_context_results = complete_all_transition_matricies(a_new_fully_generic_result=a_new_fully_generic_result, a_target_context=a_laps_target_context)\n",
    "laps_matched_result_tuple_context_dict, (laps_time_bin_container_context_dict, laps_position_transition_matrix_context_dict, laps_context_state_transition_matrix_context_dict, laps_combined_transition_matrix_context_dict), (laps_mean_context_state_transition_matrix_context_dict, laps_mean_position_transition_matrix_context_dict) = laps_target_context_results\n",
    "# a_best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = out_matched_result_tuple_context_dict[a_ctxt]\n",
    "a_laps_best_matching_context, a_laps_result, a_laps_decoder, a_laps_decoded_marginal_posterior_df = list(laps_matched_result_tuple_context_dict.values())[0] # [-1]\n",
    "\n",
    "## PBEs context:\n",
    "a_PBEs_target_context: IdentifyingContext = IdentifyingContext(known_named_decoding_epochs_type='pbe', **common_constraint_dict, data_grain='per_epoch') ## Laps\n",
    "pbes_target_context_results = complete_all_transition_matricies(a_new_fully_generic_result=a_new_fully_generic_result, a_target_context=a_PBEs_target_context)\n",
    "pbes_matched_result_tuple_context_dict, (pbes_time_bin_container_context_dict, pbes_position_transition_matrix_context_dict, pbes_context_state_transition_matrix_context_dict, pbes_combined_transition_matrix_context_dict), (pbes_mean_context_state_transition_matrix_context_dict, pbes_mean_position_transition_matrix_context_dict) = pbes_target_context_results\n",
    "a_pbes_best_matching_context, a_pbes_result, a_pbes_decoder, a_pbes_decoded_marginal_posterior_df = list(pbes_matched_result_tuple_context_dict.values())[0] # [-1] # pbes_matched_result_tuple_context_dict[a_PBEs_target_context]\n",
    "## INPUTS: laps_context_state_transition_matrix_context_dict\n",
    "out_context_state_transition_matrix_context_dict = deepcopy(laps_context_state_transition_matrix_context_dict)\n",
    "out_matched_result_tuple_context_dict = deepcopy(laps_matched_result_tuple_context_dict)\n",
    "\n",
    "an_out_best_matching_context, an_out_result, an_out_decoder, an_out_decoded_marginal_posterior_df = list(out_matched_result_tuple_context_dict.values())[0] # [-1]\n",
    "a_context_state_transition_matrix_list: List[NDArray] = list(out_context_state_transition_matrix_context_dict.values())[0]\n",
    "\n",
    "## INPUTS: an_out_decoded_marginal_posterior_df, a_context_state_transition_matrix_list\n",
    "a_mean_context_state_transition_matrix_dict = split_transition_matricies_results_pre_post_delta_category(an_out_decoded_marginal_posterior_df=an_out_decoded_marginal_posterior_df, a_context_state_transition_matrix_list=a_context_state_transition_matrix_list)\n",
    "a_mean_context_state_transition_matrix_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66cab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_laps_decoder: BasePositionDecoder = deepcopy(a_laps_decoder)\n",
    "a_laps_decoder.pf.plot_occupancy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4337b537",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.plotting.placemaps import plot_placefield_occupancy, perform_plot_occupancy\n",
    "\n",
    "valid_EpochComputations_result: EpochComputationsComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['EpochComputations']\n",
    "a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult = valid_EpochComputations_result.a_generic_decoder_dict_decoded_epochs_dict_result\n",
    "\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.050, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore') # , decoder_identifier='long_LR'\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore', data_grain='per_epoch') # , time_bin_size=0.050, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore', decoder_identifier='long_LR'\n",
    "\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='ignore', data_grain='per_epoch') ## Laps\n",
    "# any_matching_contexts_list, result_context_dict, decoder_context_dict, decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context)\n",
    "\n",
    "# common_constraint_dict = dict(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, masked_time_bin_fill_type='ignore')\n",
    "# common_constraint_dict = dict(trained_compute_epochs='laps', time_bin_size=0.060, masked_time_bin_fill_type='nan_filled') # , pfND_ndim=1\n",
    "common_constraint_dict = dict(trained_compute_epochs='laps', time_bin_size=0.060, masked_time_bin_fill_type='dropped')\n",
    "\n",
    "## Laps context:\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(known_named_decoding_epochs_type='laps', data_grain='per_time_bin', **common_constraint_dict) ## Laps , data_grain='per_epoch'\n",
    "best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=a_target_context)\n",
    "\n",
    "# ## Global context:\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(known_named_decoding_epochs_type='global', data_grain='per_time_bin', **common_constraint_dict) ## Laps , data_grain='per_epoch'\n",
    "# best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=a_target_context)\n",
    "\n",
    "\n",
    "a_decoded_marginal_posterior_df\n",
    "# # a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=0.025, masked_time_bin_fill_type='last_valid', data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps'\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=0.025, masked_time_bin_fill_type='ignore', data_grain='per_time_bin', known_named_decoding_epochs_type= 'global') # , known_named_decoding_epochs_type='laps'\n",
    "# flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "# # print(f'flat_context_list: {flat_context_list}')\n",
    "# flat_decoded_marginal_posterior_df_context_dict\n",
    "\n",
    "\n",
    "# best_matching_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f679eaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import determine_percent_correctly_decoded_contexts\n",
    "## find the number of correctly decoded components:\n",
    "# worse_percent_correct, (percent_correct_pre, n_correct_pre, n_total_pre), (percent_correct_post, n_correct_post, n_total_post) = determine_percent_correctly_decoded_contexts(curr_active_pipeline)\n",
    "_output_worse_percent_correct_dict = {}\n",
    "_output_dict = determine_percent_correctly_decoded_contexts(curr_active_pipeline)\n",
    "for a_ctxt, a_num_counts_tuple in _output_dict.items():\n",
    "    worse_percent_correct, (percent_correct_pre, n_correct_pre, n_total_pre), (percent_correct_post, n_correct_post, n_total_post) = a_num_counts_tuple\n",
    "    _output_worse_percent_correct_dict[a_ctxt] = worse_percent_correct\n",
    "\n",
    "_output_worse_percent_correct_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a3070e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_result: DecodedFilterEpochsResult = continuously_decoded_pseudo2D_decoder_dict[0.050]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d0e184",
   "metadata": {},
   "source": [
    "## 2025-05-15 - Decoded vs Measured Occupancy\n",
    "- [ ] wrap in normal matplotlib-specific decoration/output code to add session_name footer, enable saving to file, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3bf977",
   "metadata": {
    "tags": [
     "2025-05-15_decoded_vs_measured_occupancy"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.print_helpers import BaseFieldPrintingReprMixin\n",
    "from pyphocorehelpers.DataStructure.RenderPlots.MatplotLibRenderPlots import FigureCollector\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import MeasuredVsDecodedOccupancy\n",
    "\n",
    "# MeasuredVsDecodedOccupancy._display_measured_vs_decoded_occupancy_distributions(owning_pipeline_reference=curr_active_pipeline, \n",
    "\n",
    "# _display_measured_vs_decoded_occupancy_distributions\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "_out = curr_active_pipeline.display('_display_measured_vs_decoded_occupancy_distributions',\n",
    "\t\t\t\t\t\t\t\t\t#  size=[6.5, 2], dpi=100,\n",
    "\t\t\t\t\t\t\t\t\tsize=[3.5, 2], dpi=100,\n",
    "\t\t\t\t\t\t\t\t\tprepare_for_publication=False,\n",
    "\t\t\t\t\t\t\t\t\t# prepare_for_publication=True,\n",
    "\t\t\t\t\t\t\t\t\t )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2d9163",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.plotting.media_output_helpers import PDFHelpers\n",
    "\n",
    "\n",
    "## INPUT: `_out`\n",
    "fig_5_save_paths = _out['save_paths']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5ca2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "figure5_final_out_path: Path = fig_5_save_paths[0]\n",
    "curr_stem = figure5_final_out_path.stem.strip('_laps_Laps') # 'meas_v_decoded_occupancy_0•05_2•0_[1, 2, 4, 6, 7, 8, 9]_laps_Laps'\n",
    "curr_stem = f\"{curr_stem}_MERGED\" # 'meas_v_decoded_occupancy_0•05_2•0_[1, 2, 4, 6, 7, 8, 9]'\n",
    "figure5_final_out_path = figure5_final_out_path.with_stem(curr_stem) # 'ProgrammaticDisplayFunctionTesting/2025-08-21/kdiba/gor01/two/2006-6-12_16-53-46/meas_v_decoded_occupancy_0•05_2•0_[1, 2, 4, 6, 7, 8, 9]_MERGED.pdf'\n",
    "figure5_final_out_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfdc362",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure5_final_out_path.with_stem('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4504feb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PDFHelpers.concatenate_pdfs_vertically(fig_5_save_paths, figure5_final_out_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f521f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b6445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.plotting.media_output_helpers import PDFHelpers\n",
    "\n",
    "## INPUTS: _out['collector'].figures\n",
    "publication_figures_export_folder = find_first_extant_path([Path(\"E:/Dropbox (Personal)/Active/Kamran Diba Lab/Pho-Kamran-Meetings/Pho Diba Paper 2023/Figures/UneditedSources\").resolve(),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Path(r\"E:/Dropbox (Personal)/Active/Kamran Diba Lab/Pho-Kamran-Meetings/2025-07-03 - EXPORTS FOR PUBLICATION\").resolve(), # APOGEEe\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tPath('/media/halechr/MAX/cloud/University of Michigan Dropbox/Pho Hale/Pho-Kamran-Meetings/2025-07-03 - EXPORTS FOR PUBLICATION').resolve(), # LAB\n",
    "])\n",
    "print(f'publication_figures_export_folder: \"{publication_figures_export_folder.as_posix()}\"')\n",
    "\n",
    "fig5_export_folder = publication_figures_export_folder.joinpath(\"Figure 5 - Measured v Decoded Occupancy\").resolve()\n",
    "fig5_export_folder.mkdir(exist_ok=True)\n",
    "Assert.path_exists(fig5_export_folder)\n",
    "fig5_export_folder_temp = fig5_export_folder.joinpath('_TEMP').resolve()\n",
    "fig5_export_folder_temp.mkdir(exist_ok=True)\n",
    "figure5_final_out_path: Path = fig5_export_folder.joinpath('figure5_MERGED_ALL.pdf')\n",
    "\n",
    "## INPUT: `_out`\n",
    "fig_5_save_paths = _out['save_paths']\n",
    "PDFHelpers.concatenate_pdfs_vertically(fig_5_save_paths, figure5_final_out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53536a0b",
   "metadata": {},
   "source": [
    "## try across-session output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83afa438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _helper_add_interpolated_position_columns_to_decoded_result_df\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import EpochComputationsComputationsContainer\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalLapsResult, TrackTemplates\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import MeasuredVsDecodedOccupancy\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PhoPublicationFigureHelper\n",
    "\n",
    "kwargs = {}\n",
    "dpi = 100\n",
    "display_fn_name: str = 'meas_v_decoded_occupancy' # same as \"short_name\"\n",
    "\n",
    "export_dpi_multiplier: float = kwargs.pop('export_dpi_multiplier', 2.0)\n",
    "export_dpi: int = int(np.ceil(dpi * export_dpi_multiplier))\n",
    "\n",
    "# ==================================================================================================================================================================================================================================================================================== #\n",
    "# BEGIN FUNCTION BODY                                                                                                                                                                                                                                                                  #\n",
    "# ==================================================================================================================================================================================================================================================================================== #\n",
    "\n",
    "## Unpack from pipeline:\n",
    "valid_EpochComputations_result: EpochComputationsComputationsContainer =  curr_active_pipeline.global_computation_results.computed_data['EpochComputations'] # owning_pipeline_reference.global_computation_results.computed_data['EpochComputations']\n",
    "assert valid_EpochComputations_result is not None\n",
    "epochs_decoding_time_bin_size: float = valid_EpochComputations_result.epochs_decoding_time_bin_size ## just get the standard size. Currently assuming all things are the same size!\n",
    "print(f'\\tepochs_decoding_time_bin_size: {epochs_decoding_time_bin_size}')\n",
    "assert epochs_decoding_time_bin_size == valid_EpochComputations_result.epochs_decoding_time_bin_size, f\"\\tERROR: nonPBE_results.epochs_decoding_time_bin_size: {valid_EpochComputations_result.epochs_decoding_time_bin_size} != epochs_decoding_time_bin_size: {epochs_decoding_time_bin_size}\"\n",
    "a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult = valid_EpochComputations_result.a_generic_decoder_dict_decoded_epochs_dict_result ## get existing\n",
    "\n",
    "## INPUTS: a_new_fully_generic_result\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='nan_filled', data_grain='per_time_bin')\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='ignore', data_grain='per_time_bin')\n",
    "best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=a_target_context, debug_print=False)\n",
    "epochs_decoding_time_bin_size = best_matching_context.get('time_bin_size', None)\n",
    "assert epochs_decoding_time_bin_size is not None\n",
    "\n",
    "## Get the needed data:\n",
    "\n",
    "## get from parameters:\n",
    "minimum_inclusion_fr_Hz: float = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.minimum_inclusion_fr_Hz\n",
    "included_qclu_values: List[int] = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.included_qclu_values\n",
    "\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, included_qclu_values=included_qclu_values) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\n",
    "\n",
    "# common_constraint_dict = dict(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, masked_time_bin_fill_type='ignore')\n",
    "common_constraint_dict = dict(trained_compute_epochs='laps', time_bin_size=epochs_decoding_time_bin_size, masked_time_bin_fill_type='nan_filled') # , pfND_ndim=1\n",
    "\n",
    "## OUTPUTS: a_decoded_marginal_posterior_df\n",
    "\n",
    "complete_session_context, (session_context, additional_session_context) = curr_active_pipeline.get_complete_session_context()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4a8406",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_session_context.get_description_as_session_global_uid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9c71a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import _get_custom_suffix_for_filename_from_computation_metadata\n",
    "from pyphocorehelpers.Filesystem.path_helpers import sanitize_filename_for_Windows\n",
    "\n",
    "complete_session_context, (session_context, additional_session_context) = curr_active_pipeline.get_complete_session_context()\n",
    "custom_suffix: str = _get_custom_suffix_for_filename_from_computation_metadata(use_concise_formatting=True, **additional_session_context.to_dict()).removeprefix('-')\n",
    "full_custom_suffix: str = '_'.join([session_context.get_description(separator='_'), custom_suffix]) # 'kdiba_gor01_two_2006-6-12_16-53-46__withNormalComputedReplays-qclu_1246789-frateThresh_2.0'\n",
    "full_custom_suffix\n",
    "original_proposed_filename: str = f'output/2025-08-21_{full_custom_suffix}_a_new_fully_generic_result.pkl'\n",
    "good_filename: str = sanitize_filename_for_Windows(original_proposed_filename)\n",
    "test_a_new_fully_generic_result_path = Path(good_filename)\n",
    "# a_new_fully_generic_result.to_hdf(test_a_new_fully_generic_result_path, key=complete_session_context.get_description_as_session_global_uid(), enable_hdf_testing_mode=True, OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True)\n",
    "\n",
    "a_new_fully_generic_result.save(pkl_output_path=test_a_new_fully_generic_result_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75adb632",
   "metadata": {},
   "source": [
    "## ⚓🎯 2025-05-15 - Within-epoch transition and run-length sequence analyis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00371dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import WithinEpochTimeBinDynamics, TimeBinCategorization\n",
    "\n",
    "\n",
    "sequence_dwell_epochs_df = WithinEpochTimeBinDynamics.analyze_subsequence_temporal_dynamics(curr_active_pipeline, time_bin_size=0.025)\n",
    "# sequence_dwell_epochs_df = WithinEpochTimeBinDynamics.analyze_subsequence_temporal_dynamics(curr_active_pipeline, time_bin_size=0.050)\n",
    "# int_column_names = [k for k in sequence_dwell_epochs_df.columns if k.startswith('n_')]\n",
    "\n",
    "# sequence_dwell_epochs_df.infer_objects()\n",
    "sequence_dwell_epochs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ba557a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(sequence_dwell_epochs_df.columns)) # ['epoch_start_t', 'epoch_end_t', 'epoch_label', 'pre_post_delta_category', 'pre_post_delta_id', 'delta_aligned_start_t', 'n_t_bins', 'n_transitions', 'mean_len.pLONG', 'mean_len.pSHORT', 'mean_len.MIXED', 'var_len.pLONG', 'var_len.pSHORT', 'var_len.MIXED', 'n_bins.pLONG', 'n_bins.pSHORT', 'n_bins.MIXED', 'lengths', 'bins_ratio.pLONG', 'bins_ratio.pSHORT', 'bins_ratio.MIXED']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0d796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_post_split_sequence_dwell_epochs_df_dict = sequence_dwell_epochs_df.pho.partition_df_dict('pre_post_delta_category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232c86a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_post_split_sequence_dwell_epochs_df_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1307d2d3",
   "metadata": {},
   "source": [
    "I have a df `sequence_dwell_epochs_df` with many numeric columns that I want to compare histograms for, based on their category in column 'pre_post_delta_category' (with a histogram plotted for each value in this column, for each variable)\n",
    "\n",
    "numeric_col_of_interest_names = ['n_t_bins', 'n_transitions', 'mean_len.pLONG', 'mean_len.pSHORT', 'mean_len.MIXED', 'var_len.pLONG', 'var_len.pSHORT', 'var_len.MIXED', 'n_bins.pLONG', 'n_bins.pSHORT', 'n_bins.MIXED', 'bins_ratio.pLONG', 'bins_ratio.pSHORT', 'bins_ratio.MIXED']\n",
    "\n",
    "write valid python code to plot a stack of these histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9695fc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "numeric_col_of_interest_names = ['n_t_bins', 'n_transitions', 'mean_len.pLONG', 'mean_len.pSHORT', 'mean_len.MIXED', 'var_len.pLONG', 'var_len.pSHORT', 'var_len.MIXED', 'n_bins.pLONG', 'n_bins.pSHORT', 'n_bins.MIXED', 'bins_ratio.pLONG', 'bins_ratio.pSHORT', 'bins_ratio.MIXED']\n",
    "\n",
    "cols=numeric_col_of_interest_names\n",
    "cats=sequence_dwell_epochs_df['pre_post_delta_category'].dropna().unique()\n",
    "fig, axes=plt.subplots(len(cols),1,figsize=(8,2*len(cols)), num='temporal_decoding_dynamics_within_bins', clear=True)\n",
    "\n",
    "for ax, col in zip(axes,cols):\n",
    "    for cat in cats:\n",
    "        ax.hist(sequence_dwell_epochs_df.loc[sequence_dwell_epochs_df['pre_post_delta_category']==cat,col].dropna(), \n",
    "                alpha=0.5,label=cat, bins=25)\n",
    "    ax.set_title(col)\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3573ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# render_scrollable_colored_table_from_dataframe(sequence_dwell_epochs_df, cmap_name='plasma', max_height=500, width='80%') # , cmap_name=cmap_name, max_height=max_height, width=width, **kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2c6523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch_split_df_dict    \n",
    "\n",
    "results\n",
    "\n",
    "# epoch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7c3549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "from scipy.stats import mannwhitneyu, poisson, fisher_exact\n",
    "\n",
    "def compare_epoch_dynamics(cond1: List[Dict], cond2: List[Dict]) -> Dict:\n",
    "    \"\"\"\n",
    "    Given two lists of analyze_epoch_dynamics outputs (one per condition),\n",
    "    computes:\n",
    "      - mean±sem of n_transitions\n",
    "      - Mann–Whitney U test on n_transitions\n",
    "      - pooled dwell times per state and MWU test per state\n",
    "    Returns dict with stats.\n",
    "    \"\"\"\n",
    "    def sem(x): return np.std(x, ddof=1)/np.sqrt(len(x))\n",
    "    \n",
    "    # extract transitions\n",
    "    t1 = np.array([e['transitions'] for e in cond1])\n",
    "    t2 = np.array([e['transitions'] for e in cond2])\n",
    "    \n",
    "    # extract dwell times per state\n",
    "    def gather(cond, state):\n",
    "        return np.concatenate([e['subsequences'][state] for e in cond]) or np.array([])\n",
    "    stats = {'transitions': {\n",
    "                 'cond1_mean_sem': (t1.mean(), sem(t1)),\n",
    "                 'cond2_mean_sem': (t2.mean(), sem(t2)),\n",
    "                 'mw_u': mannwhitneyu(t1, t2, alternative='two-sided').statistic,\n",
    "                 'mw_p': mannwhitneyu(t1, t2, alternative='two-sided').pvalue\n",
    "             }}\n",
    "    \n",
    "    for state in ['pure.Long','pure.Short','mixed']:\n",
    "        d1 = gather(cond1, state)\n",
    "        d2 = gather(cond2, state)\n",
    "        u, p = mannwhitneyu(d1, d2, alternative='two-sided')\n",
    "        stats[state] = {\n",
    "            'cond1_n': len(d1), 'cond2_n': len(d2),\n",
    "            'cond1_mean_sem': (d1.mean() if d1.size else np.nan, sem(d1) if d1.size>1 else np.nan),\n",
    "            'cond2_mean_sem': (d2.mean() if d2.size else np.nan, sem(d2) if d2.size>1 else np.nan),\n",
    "            'mw_u': u, 'mw_p': p\n",
    "        }\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80999256",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_result['parent_epoch_label']\n",
    "\n",
    "a_decoded_marginal_posterior_df\n",
    "P_Long_df = a_decoded_marginal_posterior_df[['start', 'stop', 'P_Long']]\n",
    "P_Long_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46a5fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = analyze_epoch_dynamics(p_long=p_long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44323891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0bfebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b85914ba",
   "metadata": {},
   "source": [
    "## -[ ] Lap Transition Matrix vs. PBEs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09796af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_time_bin_container.centers\n",
    "a_time_bin_container.left_edges\n",
    "a_time_bin_container.right_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7458e721",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_context_state_transition_matrix: NDArray = np.stack(out_context_state_transition_matrix_context_dict[a_ctxt]) # np.stack(out_context_state_transition_matrix_context_dict[a_ctxt]).shape\n",
    "a_mean_context_state_transition_matrix: NDArray = np.nanmean(a_context_state_transition_matrix, axis=0) #.shape (4, 4)\n",
    "a_mean_context_state_transition_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312814dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs_decoding_time_bin_size: float = 0.025\n",
    "epochs_decoding_time_bin_size: float = 0.025\n",
    "\n",
    "_all_tracks_out_artists = {}\n",
    "for a_ctxt, a_df in flat_decoded_marginal_posterior_df_context_dict.items():\n",
    "    time_bin_size = epochs_decoding_time_bin_size\n",
    "    info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "    plot_row_identifier: str = a_ctxt.get_description(subset_includelist=['known_named_decoding_epochs_type', 'masked_time_bin_fill_type'], include_property_names=True, key_value_separator=':', separator='|', replace_separator_in_property_names='-')\n",
    "    a_time_window_centers = a_df['t_bin_center'].to_numpy() \n",
    "    a_1D_posterior = a_df[['P_Long', 'P_Short']].to_numpy().T\n",
    "\n",
    "    identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dock_item = active_2d_plot.add_docked_marginal_track(name=plot_row_identifier, time_window_centers=a_time_window_centers, a_1D_posterior=a_1D_posterior, extended_dock_title_info=info_string)\n",
    "    _all_tracks_out_artists[identifier_name] = widget\n",
    "    intervals_overview_plot_item.setXRange(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time, padding=0) ## global frame\n",
    "    matplotlib_fig_axes[0].set_xlim(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time)\n",
    "    widget.draw()\n",
    "\n",
    "\n",
    "## Make a new matplotlib figure (in a new window) that contains a copy of `matplotlib_fig_axes` inserted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58d8df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _perform_compute_transition_matrix(continuously_decoded_pseudo2D_decoder_dict):\n",
    "    \"\"\" Computes the context state transition matrix from the continuous posteriors\n",
    "    \n",
    "    Usage:\n",
    "    \n",
    "    ## Uses the `global_computation_results.computed_data['DirectionalDecodersDecoded']`\n",
    "    directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "    # all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "    pseudo2D_decoder: BasePositionDecoder = directional_decoders_decode_result.pseudo2D_decoder\n",
    "\n",
    "    # all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "    continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "    continuously_decoded_pseudo2D_decoder_dict = directional_decoders_decode_result.continuously_decoded_pseudo2D_decoder_dict\n",
    "    # continuously_decoded_result_cache_dict\n",
    "    continuously_decoded_pseudo2D_decoder_dict\n",
    "\n",
    "    output_transition_matrix_dict = _perform_compute_transition_matrix(continuously_decoded_pseudo2D_decoder_dict=continuously_decoded_pseudo2D_decoder_dict)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    output_transition_matrix_dict = {}\n",
    "    \n",
    "    for a_time_bin_size, a_pseudo2D_decoder_continuously_decoded_result in continuously_decoded_pseudo2D_decoder_dict.items():\n",
    "        print(f'a_time_bin_size: {a_time_bin_size}')\n",
    "        # a_pseudo2D_decoder_continuously_decoded_result.active_filter_epochs\n",
    "        assert len(a_pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list) == 1\n",
    "        a_p_x_given_n = deepcopy(a_pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0])\n",
    "        ## OUTPUTS: a_p_x_given_n\n",
    "        \n",
    "        ## INPUTS: a_p_x_given_n\n",
    "        n_position_bins, n_decoding_models, n_time_bins = a_p_x_given_n.shape\n",
    "        \n",
    "        # 1. Determine the most likely model for each time bin\n",
    "        sum_over_positions = a_p_x_given_n.sum(axis=0)  # (n_decoding_models, n_time_bins)\n",
    "        best_model_each_bin = sum_over_positions.argmax(axis=0)  # (n_time_bins,)\n",
    "        print(f'best_model_each_bin.shape: {np.shape(best_model_each_bin)}')\n",
    "        # sum_over_positions.shape # (4, n_time_bins)\n",
    "        \n",
    "        sum_over_positions.shape\n",
    "        \n",
    "        # 2. Determine the most likely position for each time bin (conditional on chosen model)\n",
    "        best_position_each_bin = np.array([\n",
    "            p_x_given_n[:, best_model_each_bin[t], t].argmax()\n",
    "            for t in range(n_time_bins)\n",
    "        ])\n",
    "\n",
    "        print(f'best_position_each_bin: {np.shape(best_position_each_bin)}')\n",
    "        \n",
    "        # 2. Determine the most likely position for each time bin (conditional on chosen model)\n",
    "        a_model_p_x_given_n = np.array([\n",
    "            sum_over_positions[best_model_each_bin[t], t] / np.sum(sum_over_positions[:, t])\n",
    "            for t in range(n_time_bins)\n",
    "        ])\n",
    "\n",
    "\n",
    "        marginal_p_x_given_n_over_positions = deepcopy(sum_over_positions).T\n",
    "        print(f'marginal_p_x_given_n_over_positions: {np.shape(marginal_p_x_given_n_over_positions)}')\n",
    "        # marginal_p_x_given_n_over_positions = marginal_p_x_given_n_over_positions / np.nansum(marginal_p_x_given_n_over_positions, axis=-1, keepdims=True)\n",
    "        # marginal_p_x_given_n_over_positions\n",
    "        \n",
    "        # # Verify normalization (should be very close to 1.0 for all rows)\n",
    "        # verification = np.sum(marginal_p_x_given_n_over_positions, axis=-1)\n",
    "        # print(f\"Normalized sums: min={verification.min()}, max={verification.max()}\")\n",
    "\n",
    "\n",
    "        # Check for zeros or NaNs before normalization\n",
    "        sum_before_norm = np.nansum(marginal_p_x_given_n_over_positions, axis=-1, keepdims=True)\n",
    "        print(f\"Before normalization - min sum: {np.min(sum_before_norm)}, has NaNs: {np.isnan(sum_before_norm).any()}\")\n",
    "\n",
    "        # Safe normalization with handling for zeros\n",
    "        # Replace zeros with ones in the denominator to avoid division by zero\n",
    "        safe_sums = np.where(sum_before_norm == 0, 1.0, sum_before_norm)\n",
    "        marginal_p_x_given_n_over_positions = marginal_p_x_given_n_over_positions / safe_sums\n",
    "\n",
    "        # For rows that summed to zero, set all values to equal probabilities (e.g., 1/n)\n",
    "        zero_sum_rows = (sum_before_norm == 0).squeeze()\n",
    "        if np.any(zero_sum_rows):\n",
    "            n_models = marginal_p_x_given_n_over_positions.shape[-1]\n",
    "            equal_probs = np.ones(n_models) / n_models\n",
    "            # Apply equal probabilities to rows with zero sums\n",
    "            if zero_sum_rows.ndim > 0:  # If it's not a scalar\n",
    "                marginal_p_x_given_n_over_positions[zero_sum_rows] = equal_probs\n",
    "            else:\n",
    "                # Handle the case where there's only one row\n",
    "                marginal_p_x_given_n_over_positions[:] = equal_probs\n",
    "\n",
    "        # Verify normalization\n",
    "        verification = np.sum(marginal_p_x_given_n_over_positions, axis=-1)\n",
    "        print(f\"Normalized sums: min={verification.min()}, max={verification.max()}, has NaNs: {np.isnan(verification).any()}\")\n",
    "\n",
    "\n",
    "        ## OUTPUTS: marginal_p_x_given_n_over_positions (normalized)\n",
    "\n",
    "        # best_model_each_bin\n",
    "        # a_model_p_x_given_n = sum_over_positions[np.squeeze(best_model_each_bin), :]\n",
    "        # a_model_p_x_given_n.shape\n",
    "        # a_model_p_x_given_n\n",
    "        # transition_matrix: NDArray = TransitionMatrixComputations.estimate_transition_matrix_weighted_avg(state_probs=best_model_each_bin)\n",
    "        transition_matrix: NDArray = TransitionMatrixComputations.estimate_transition_matrix_weighted_avg(state_probs=marginal_p_x_given_n_over_positions)\n",
    "        \n",
    "        output_transition_matrix_dict[a_time_bin_size] = transition_matrix\n",
    "        # A_position, A_model, A_combined = TransitionMatrixComputations.build_position_by_decoder_transition_matrix(a_p_x_given_n)\n",
    "\n",
    "        # len(A_position)\n",
    "        # A_position[0].shape\n",
    "        # A_position[1].shape\n",
    "        # A_combined.shape\n",
    "        # A_model.shape\n",
    "        \n",
    "        ## Plotting:\n",
    "        # # plt.figure(figsize=(8,6)); sns.heatmap(A_big, cmap='viridis'); plt.title(\"Transition Matrix A_big\"); plt.show()\n",
    "        # plt.figure(figsize=(8,6)); sns.heatmap(A_position, cmap='viridis'); plt.title(\"Transition Matrix A_position\"); plt.show()\n",
    "        # plt.figure(figsize=(8,6)); sns.heatmap(A_model, cmap='viridis'); plt.title(\"Transition Matrix A_model\"); plt.show()\n",
    "\n",
    "        # plot_blocked_transition_matrix(A_combined, n_position_bins, n_decoding_models)\n",
    "\n",
    "    return output_transition_matrix_dict\n",
    "\n",
    "\n",
    "output_transition_matrix_dict = _perform_compute_transition_matrix(continuously_decoded_pseudo2D_decoder_dict=continuously_decoded_pseudo2D_decoder_dict)\n",
    "output_transition_matrix_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3740ad1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6)); sns.heatmap(output_transition_matrix_dict[0.05], cmap='viridis'); plt.title(\"Transition Matrix P_Context State\"); \n",
    "plt.xlabel('P[t+1]')\n",
    "plt.ylabel('P[t]')\n",
    "state_labels = ['Long_LR', 'Long_RL', 'Short_LR', 'Short_RL']\n",
    "plt.xticks(ticks=(np.arange(len(state_labels))+0.5), labels=state_labels)\n",
    "plt.yticks(ticks=(np.arange(len(state_labels))+0.5), labels=state_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b4ae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('P[t+1]')\n",
    "plt.ylabel('P[t]')\n",
    "\n",
    "state_labels = ['Long_LR', 'Long_RL', 'Short_LR', 'Short_RL']\n",
    "plt.xticks(ticks=(np.arange(len(state_labels))+0.5), labels=state_labels)\n",
    "plt.yticks(ticks=(np.arange(len(state_labels))+0.5), labels=state_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bd10f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "global_session = curr_active_pipeline.filtered_sessions[global_epoch_name]\n",
    "\n",
    "# global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps) # .trimmed_to_non_overlapping()\n",
    "global_laps_epochs_df = global_laps.to_dataframe()\n",
    "# active_test_epochs_df: pd.DataFrame = deepcopy(global_laps_epochs_df)\n",
    "global_laps_epochs_df\n",
    "debug_print = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fcdcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import find_epochs_overlapping_other_epochs\n",
    "\n",
    "## INPUTS: global_laps, continuously_decoded_pseudo2D_decoder_dict\n",
    "_out_split_pseudo2D_posteriors_dict = {}\n",
    "_out_split_pseudo2D_out_dict = {}\n",
    "pre_filtered_col_names = ['pre_filtered_most_likely_position_indicies', 'pre_filtered_most_likely_position'] # 'pre_filtered_time_bin_containers', 'pre_filtered_p_x_given_n', \n",
    "post_filtered_col_names = [a_col_name.removeprefix('pre_filtered_') for a_col_name in pre_filtered_col_names] # ['time_bin_containers', 'most_likely_position_indicies', 'most_likely_position']\n",
    "print(post_filtered_col_names)\n",
    "for a_time_bin_size, pseudo2D_decoder_continuously_decoded_result in continuously_decoded_pseudo2D_decoder_dict.items():\n",
    "    print(f'a_time_bin_size: {a_time_bin_size}')\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size] = {'pre_filtered_p_x_given_n': None, 'pre_filtered_time_bin_containers': None, 'pre_filtered_most_likely_position_indicies': None, 'pre_filtered_most_likely_position': None, \n",
    "                                                     'is_timebin_included': None, 'p_x_given_n': None} # , 'time_window_centers': None\n",
    "    # pseudo2D_decoder_continuously_decoded_result: DecodedFilterEpochsResult = continuously_decoded_dict.get('pseudo2D', None)\n",
    "    assert len(pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list) == 1\n",
    "    p_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0]\n",
    "    # p_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0]['p_x_given_n']\n",
    "    time_bin_containers = pseudo2D_decoder_continuously_decoded_result.time_bin_containers[0]\n",
    "    # time_window_centers = time_bin_containers.centers\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position_indicies'] = deepcopy(pseudo2D_decoder_continuously_decoded_result.most_likely_position_indicies_list[0])\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position'] = deepcopy(pseudo2D_decoder_continuously_decoded_result.most_likely_positions_list[0])\n",
    "    ## INPUTS: time_bin_containers, global_laps\n",
    "    left_edges = deepcopy(time_bin_containers.left_edges)\n",
    "    right_edges = deepcopy(time_bin_containers.right_edges)\n",
    "    continuous_time_binned_computation_epochs_df: pd.DataFrame = pd.DataFrame({'start': left_edges, 'stop': right_edges, 'label': np.arange(len(left_edges))})\n",
    "    is_timebin_included: NDArray = find_epochs_overlapping_other_epochs(epochs_df=continuous_time_binned_computation_epochs_df, epochs_df_required_to_overlap=deepcopy(global_laps))\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_p_x_given_n'] = p_x_given_n\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_time_bin_containers'] = time_bin_containers\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['is_timebin_included'] = is_timebin_included\n",
    "    continuous_time_binned_computation_epochs_df['is_in_laps'] = is_timebin_included\n",
    "    ## filter by whether it's included or not:\n",
    "    p_x_given_n = p_x_given_n[:, :, is_timebin_included]\n",
    "    # time_window_centers = \n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['p_x_given_n'] = p_x_given_n\n",
    "    # _out_split_pseudo2D_out_dict[a_time_bin_size]['time_window_centers'] = time_window_centers[is_timebin_included]\n",
    "    # p_x_given_n.shape # (62, 4, 209389)\n",
    "\n",
    "    ## Split across the 2nd axis to make 1D posteriors that can be displayed in separate dock rows:\n",
    "    assert p_x_given_n.shape[1] == 4, f\"expected the 4 pseudo-y bins for the decoder in p_x_given_n.shape[1]. but found p_x_given_n.shape: {p_x_given_n.shape}\"\n",
    "    # split_pseudo2D_posteriors_dict = {k:np.squeeze(p_x_given_n[:, i, :]) for i, k in enumerate(('long_LR', 'long_RL', 'short_LR', 'short_RL'))}\n",
    "    _out_split_pseudo2D_posteriors_dict[a_time_bin_size] = deepcopy(p_x_given_n)\n",
    "    \n",
    "    # for a_col_name in pre_filtered_col_names:\n",
    "    #     filtered_col_name = a_col_name.removeprefix('pre_filtered_')\n",
    "    #     print(f'a_col_name: {a_col_name}, filtered_col_name: {filtered_col_name}, shape: {np.shape(_out_split_pseudo2D_out_dict[a_time_bin_size][a_col_name])}')\n",
    "    #     _out_split_pseudo2D_out_dict[a_time_bin_size][filtered_col_name] = _out_split_pseudo2D_out_dict[a_time_bin_size][a_col_name][is_timebin_included, :]\n",
    "        \n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['most_likely_position_indicies'] = _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position_indicies'][:, is_timebin_included]\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['most_likely_position'] = _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position'][is_timebin_included, :]\n",
    "    \n",
    "\n",
    "p_x_given_n.shape # (n_position_bins, n_decoding_models, n_time_bins) - (57, 4, 29951)\n",
    "\n",
    "## OUTPUTS: _out_split_pseudo2D_posteriors_dict, _out_split_pseudo2D_out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e652de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo2D_decoder_continuously_decoded_result.most_likely_position_indicies_list[0].shape # (2, 6948)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69a7e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_split_pseudo2D_out_dict_p_x_given_x = {k:v['pre_filtered_p_x_given_n'] for k, v in _out_split_pseudo2D_out_dict.items()}\n",
    "_out_split_pseudo2D_out_dict_p_x_given_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d83ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_time_binned_computation_epochs_df = continuous_time_binned_computation_epochs_df[continuous_time_binned_computation_epochs_df['is_in_laps']].drop(columns=['is_in_laps'])\n",
    "continuous_time_binned_computation_epochs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b84b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import build_position_by_decoder_transition_matrix, plot_blocked_transition_matrix\n",
    "from neuropy.utils.matplotlib_helpers import perform_update_title_subtitle\n",
    "\n",
    "## INPUTS: _out_split_pseudo2D_posteriors_dict\n",
    "# a_time_bin_size: float = 0.025\n",
    "a_time_bin_size: float = 0.050\n",
    "# a_time_bin_size: float = 0.058\n",
    "# a_time_bin_size: float = 0.250\n",
    "# a_time_bin_size: float = 0.500\n",
    "# a_time_bin_size: float = 0.750\n",
    "\n",
    "print(f'{list(_out_split_pseudo2D_posteriors_dict.keys())}')\n",
    "\n",
    "p_x_given_n = _out_split_pseudo2D_posteriors_dict[a_time_bin_size]\n",
    "is_timebin_included = _out_split_pseudo2D_out_dict[a_time_bin_size]['is_timebin_included']\n",
    "pre_filtered_p_x_given_n = _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_p_x_given_n']\n",
    "pre_filtered_time_bin_containers = _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_time_bin_containers']\n",
    "pre_filtered_most_likely_position_indicies = _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position_indicies']\n",
    "most_likely_position_indicies = _out_split_pseudo2D_out_dict[a_time_bin_size]['most_likely_position_indicies']\n",
    "\n",
    "\n",
    "did_change = np.diff(is_timebin_included, n=1)\n",
    "split_indicies = np.where(did_change)[0] + 1 # the +1 compensates for the 0-based nature of the indicies, indicating we want to split BEFORE the specified index\n",
    "\n",
    "# lap_split_p_x_given_n_list = np.split(p_x_given_n, split_indicies, axis=-1) # split along the time-bin axis (-1)\n",
    "lap_split_p_x_given_n_list: List[NDArray] = np.split(pre_filtered_p_x_given_n, split_indicies, axis=-1) # split along the time-bin axis (-1)\n",
    "# lap_split_p_x_given_n_list\n",
    "\n",
    "pre_filtered_most_likely_position_indicies_x = np.squeeze(pre_filtered_most_likely_position_indicies[0, :])\n",
    "most_likely_position_indicies_x = np.squeeze(most_likely_position_indicies[0, :])\n",
    "# most_likely_position_indicies_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7fa3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6)); sns.histplot(pre_filtered_most_likely_position_indicies_x); perform_update_title_subtitle(title_string=f\"hist: pre_filtered_most_likely_position_indicies_x - t_bin: {a_time_bin_size}\"); plt.show();\n",
    "plt.figure(figsize=(8,6)); sns.histplot(most_likely_position_indicies_x); perform_update_title_subtitle(title_string=f\"hist: most_likely_position_indicies_x - t_bin: {a_time_bin_size}\"); plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3aa025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13514771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1441d2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: p_x_given_n\n",
    "n_position_bins, n_decoding_models, n_time_bins = p_x_given_n.shape\n",
    "\n",
    "out_tuples = [build_position_by_decoder_transition_matrix(a_p_x_given_n) for a_p_x_given_n in lap_split_p_x_given_n_list]\n",
    "\n",
    "A_position = [v[0] for i, v in enumerate(out_tuples) if (i % 2 == 1)]\n",
    "A_model = [v[1] for i, v in enumerate(out_tuples) if (i % 2 == 1)]\n",
    "A_big = [v[2] for i, v in enumerate(out_tuples) if (i % 2 == 1)]\n",
    "\n",
    "len(A_position)\n",
    "A_position[0].shape\n",
    "A_position[1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8802e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import TransitionMatrixComputations\n",
    "\n",
    "# Visualization ______________________________________________________________________________________________________ #\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow, LayoutScrollability\n",
    "\n",
    "binned_x_transition_matrix_higher_order_list_dict: Dict[types.DecoderName, NDArray] = track_templates.compute_decoder_transition_matricies(n_powers=3)\n",
    "out = TransitionMatrixComputations.plot_transition_matricies(decoders_dict=track_templates.get_decoders_dict(), binned_x_transition_matrix_higher_order_list_dict=binned_x_transition_matrix_higher_order_list_dict)\n",
    "# out\n",
    "\n",
    "\n",
    "# binned_x_transition_matrix_higher_order_list_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92be3631",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_position_overall = np.sum(np.stack(A_position), axis=0) #.shape # (81, 57, 57)\n",
    "# A_position_overall.shape\n",
    "plt.figure(figsize=(8,6)); sns.heatmap(A_position_overall, cmap='viridis'); perform_update_title_subtitle(title_string=f\"Transition Matrix A_position_overall - t_bin: {a_time_bin_size}\"); plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55148899",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(A_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92508cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example data: linear array\n",
    "# data = [np.random.rand(10, 10) for _ in range(12)]  # 12 heatmaps of size 10x10\n",
    "data = A_position[:20]\n",
    "columns = 5  # Number of columns in the grid\n",
    "\n",
    "# Compute grid dimensions\n",
    "rows = -(-len(data) // columns)  # Ceiling division for number of rows\n",
    "print(f'rows: {rows}, columns: {columns}')\n",
    "\n",
    "# Plot the grid\n",
    "fig, axes = plt.subplots(rows, columns, figsize=(15, 3 * rows))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < len(data):\n",
    "        heatmap = data[i]\n",
    "        # im = ax.imshow(heatmap, cmap='viridis')\n",
    "        sns.heatmap(heatmap, cmap='viridis', ax=ax) ## position\n",
    "        ax.set_title(f\"Heatmap {i + 1}\")\n",
    "    else:\n",
    "        ax.axis('off')  # Turn off unused axes\n",
    "\n",
    "# fig.colorbar(im, ax=axes, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5830bd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\"D\" is E\"pic\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00295aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_position, A_model, A_big = build_position_by_decoder_transition_matrix(p_x_given_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447625fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# plt.figure(figsize=(8,6)); sns.heatmap(A_big, cmap='viridis'); plt.title(\"Transition Matrix A_big\"); plt.show()\n",
    "plt.figure(figsize=(8,6)); sns.heatmap(A_position, cmap='viridis'); perform_update_title_subtitle(title_string=f\"Transition Matrix A_position - t_bin: {a_time_bin_size}\"); plt.show(); \n",
    "plt.figure(figsize=(8,6)); sns.heatmap(A_model, cmap='viridis'); perform_update_title_subtitle(title_string=f\"Transition Matrix A_model - t_bin: {a_time_bin_size}\"); plt.show()\n",
    "\n",
    "_out = plot_blocked_transition_matrix(A_big, n_position_bins, n_decoding_models, extra_title_suffix=f' - t_bin: {a_time_bin_size}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0065a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuously_decoded_result_cache_dict[0.025]['pseudo2D'] # DecodedFilterEpochsResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed315063",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import EpochComputationFunctions, EpochComputationsComputationsContainer\n",
    "\n",
    "\n",
    "valid_EpochComputations_result: EpochComputationsComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['EpochComputations']\n",
    "a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult = valid_EpochComputations_result.a_generic_decoder_dict_decoded_epochs_dict_result\n",
    "\n",
    "# common_constraint_dict = dict(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, masked_time_bin_fill_type='ignore')\n",
    "common_constraint_dict = dict(trained_compute_epochs='laps', time_bin_size=0.025, masked_time_bin_fill_type='nan_filled') # , pfND_ndim=1\n",
    "\n",
    "# common_constraint_dict.update(data_grain='per_epoch')\n",
    "common_constraint_dict.update(data_grain='per_t_bin')\n",
    "\n",
    "## Laps context:\n",
    "a_laps_target_context: IdentifyingContext = IdentifyingContext(known_named_decoding_epochs_type='laps', **common_constraint_dict) ## Laps\n",
    "a_laps_best_matching_context, a_laps_result, a_laps_decoder, a_laps_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=a_laps_target_context)\n",
    "# laps_matched_result_tuple_context_dict, (laps_time_bin_container_context_dict, laps_position_transition_matrix_context_dict, laps_context_state_transition_matrix_context_dict, laps_combined_transition_matrix_context_dict), (laps_mean_context_state_transition_matrix_context_dict, laps_mean_position_transition_matrix_context_dict) = laps_target_context_results\n",
    "# a_best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = out_matched_result_tuple_context_dict[a_ctxt]\n",
    "# a_laps_best_matching_context, a_laps_result, a_laps_decoder, a_laps_decoded_marginal_posterior_df = list(laps_matched_result_tuple_context_dict.values())[0] # [-1]\n",
    "\n",
    "## PBEs context:\n",
    "a_PBEs_target_context: IdentifyingContext = IdentifyingContext(known_named_decoding_epochs_type='pbe', **common_constraint_dict) ## PBEs\n",
    "a_pbes_best_matching_context, a_pbes_result, a_pbes_decoder, a_pbes_decoded_marginal_posterior_df  = a_new_fully_generic_result.get_results_best_matching_context(context_query=a_PBEs_target_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89a9ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_pbes_decoded_marginal_posterior_df\n",
    "\n",
    "pre_post_delta_a_laps_decoded_marginal_posterior_df_dict = a_pbes_decoded_marginal_posterior_df.pho.partition_df_dict('pre_post_delta_category') # pre_post_delta_category\n",
    "pre_post_delta_a_laps_decoded_marginal_posterior_df_dict['pre-delta']\n",
    "pre_post_delta_a_laps_decoded_marginal_posterior_df_dict['post-delta']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aec3e1",
   "metadata": {},
   "source": [
    "# 2025-04-29 - Simple P(Long) (joint) over position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf1aa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import EpochComputationFunctions, EpochComputationsComputationsContainer\n",
    "from neuropy.utils.mixins.binning_helpers import BinningContainer, BinningInfo\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import complete_all_transition_matricies, build_transition_matricies\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import split_transition_matricies_results_pre_post_delta_category\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import LongShortTrackDataframeAccessor\n",
    "\n",
    "valid_EpochComputations_result: EpochComputationsComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['EpochComputations']\n",
    "a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult = valid_EpochComputations_result.a_generic_decoder_dict_decoded_epochs_dict_result\n",
    "\n",
    "\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.050, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore') # , decoder_identifier='long_LR'\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore', data_grain='per_epoch') # , time_bin_size=0.050, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore', decoder_identifier='long_LR'\n",
    "\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='ignore', data_grain='per_epoch') ## Laps\n",
    "# any_matching_contexts_list, result_context_dict, decoder_context_dict, decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context)\n",
    "\n",
    "# common_constraint_dict = dict(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, masked_time_bin_fill_type='ignore')\n",
    "common_constraint_dict = dict(trained_compute_epochs='laps', time_bin_size=0.050, masked_time_bin_fill_type='nan_filled') # , pfND_ndim=1\n",
    "\n",
    "# common_constraint_dict.update(data_grain='per_epoch')\n",
    "common_constraint_dict.update(data_grain='per_t_bin')\n",
    "\n",
    "## Laps context:\n",
    "a_laps_target_context: IdentifyingContext = IdentifyingContext(known_named_decoding_epochs_type='laps', **common_constraint_dict) ## Laps\n",
    "laps_target_context_results = complete_all_transition_matricies(a_new_fully_generic_result=a_new_fully_generic_result, a_target_context=a_laps_target_context)\n",
    "laps_matched_result_tuple_context_dict, (laps_time_bin_container_context_dict, laps_position_transition_matrix_context_dict, laps_context_state_transition_matrix_context_dict, laps_combined_transition_matrix_context_dict), (laps_mean_context_state_transition_matrix_context_dict, laps_mean_position_transition_matrix_context_dict) = laps_target_context_results\n",
    "# a_best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = out_matched_result_tuple_context_dict[a_ctxt]\n",
    "a_laps_best_matching_context, a_laps_result, a_laps_decoder, a_laps_decoded_marginal_posterior_df = list(laps_matched_result_tuple_context_dict.values())[0] # [-1]\n",
    "\n",
    "## PBEs context:\n",
    "a_PBEs_target_context: IdentifyingContext = IdentifyingContext(known_named_decoding_epochs_type='pbe', **common_constraint_dict) ## Laps\n",
    "pbes_target_context_results = complete_all_transition_matricies(a_new_fully_generic_result=a_new_fully_generic_result, a_target_context=a_PBEs_target_context)\n",
    "pbes_matched_result_tuple_context_dict, (pbes_time_bin_container_context_dict, pbes_position_transition_matrix_context_dict, pbes_context_state_transition_matrix_context_dict, pbes_combined_transition_matrix_context_dict), (pbes_mean_context_state_transition_matrix_context_dict, pbes_mean_position_transition_matrix_context_dict) = pbes_target_context_results\n",
    "a_pbes_best_matching_context, a_pbes_result, a_pbes_decoder, a_pbes_decoded_marginal_posterior_df = list(pbes_matched_result_tuple_context_dict.values())[0] # [-1] # pbes_matched_result_tuple_context_dict[a_PBEs_target_context]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a40bdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_post_delta_a_laps_decoded_marginal_posterior_df_dict = a_laps_decoded_marginal_posterior_df.pho.partition_df_dict('pre_post_delta_category') # pre_post_delta_category\n",
    "# pre_post_delta_a_laps_decoded_marginal_posterior_df_dict = a_pbes_decoded_marginal_posterior_df.pho.partition_df_dict('pre_post_delta_category') # pre_post_delta_category\n",
    "# pre_post_delta_a_laps_decoded_marginal_posterior_df_dict['pre-delta']\n",
    "# pre_post_delta_a_laps_decoded_marginal_posterior_df_dict['post-delta']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f621b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = pre_post_delta_a_laps_decoded_marginal_posterior_df_dict['pre-delta'].plot.scatter(x='t_bin_center', y='P_Short')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fdfa19",
   "metadata": {},
   "source": [
    "## 2025-05-01 - Get Pre/Post Delta Split Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d818e15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import LongShortTrackDataframeAccessor\n",
    "from typing import Dict, List, Tuple, Optional, Callable, Union, Any, TypeVar\n",
    "from typing_extensions import TypeAlias\n",
    "import nptyping as ND\n",
    "from nptyping import NDArray\n",
    "# import neuropy.utils.type_aliases as types\n",
    "import pyphoplacecellanalysis.General.type_aliases as types\n",
    "from neuropy.utils.mixins.time_slicing import TimeColumnAliasesProtocol\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import build_decoder_prob_as_a_function_of_position\n",
    "\n",
    "## INPUTS: a_laps_decoder, a_laps_result, a_pbes_result\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "epochs_result_dict: Dict[types.KnownNamedDecodingEpochsType, DecodedFilterEpochsResult] = {'laps': deepcopy(a_laps_result),\n",
    "\t\t\t\t\t  'pbe': deepcopy(a_pbes_result),\n",
    "}\n",
    "# epochs_result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f4bc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "fig, ax_dict, epoch_name_by_pre_post_delta_category_output_dict_dict, epoch_name_by_probability_values_output_dict_dict = build_decoder_prob_as_a_function_of_position(epochs_result_dict=epochs_result_dict, xbin_centers=deepcopy(a_laps_decoder.xbin_centers), t_delta=t_delta, grid_bin_bounds=deepcopy(a_laps_decoder.pf.config.grid_bin_bounds), is_split_by_all_decoders=True,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   display_context=curr_active_pipeline.build_display_context_for_session('decoded_prob_as_fn_of_pos'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dc58c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_dict, epoch_name_by_pre_post_delta_category_output_dict_dict, epoch_name_by_probability_values_output_dict_dict = build_decoder_prob_as_a_function_of_position(epochs_result_dict=epochs_result_dict, xbin_centers=deepcopy(a_laps_decoder.xbin_centers), t_delta=t_delta, grid_bin_bounds=deepcopy(a_laps_decoder.pf.config.grid_bin_bounds), is_split_by_all_decoders=False,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   display_context=curr_active_pipeline.build_display_context_for_session('decoded_prob_as_fn_of_pos'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aa6bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_name_by_probability_values_output_dict_dict['laps']['long']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4efd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ndarray_preview height=500, width=None, include_plaintext_repr=False, include_shape=False, horizontal_layout=True\n",
    "# %%ndarray_preview height=500, width=200, include_plaintext_repr=False, include_shape=False, horizontal_layout=True\n",
    "# summary_values_dict['all'].shape # .shape (59, 4, 1349)  (n_pos_bins, 4, n_t_bins)\n",
    "# np.nansum(summary_values_dict['all'], axis=0) # .shape (4, n_t_bins)\n",
    "\n",
    "full_joint_p = deepcopy(summary_values_dict['all']) # .shape (n_pos_bins, 4, n_t_bins)\n",
    "full_joint_p = np.nan_to_num(full_joint_p, copy=True, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "full_joint_p\n",
    "\n",
    "any_decoder_p = np.nansum(full_joint_p, axis=1) # .shape (n_pos_bins, n_t_bins)\n",
    "any_decoder_p = np.nan_to_num(any_decoder_p, copy=True, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "any_decoder_p\n",
    "\n",
    "any_decoder_all_t_bins_p = np.nansum(any_decoder_p, axis=-1) # .shape (n_pos_bins)\n",
    "any_decoder_all_t_bins_p = np.nan_to_num(any_decoder_all_t_bins_p, copy=True, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "any_decoder_all_t_bins_p\n",
    "\n",
    "# summary_values_dict['all'][:,:,4]\n",
    "\n",
    "# np.nansum(summary_values_dict['all'][:,:,4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bf8330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any_decoder_p\n",
    "\n",
    "single_decoder_p = full_joint_p[:, 0, :] / any_decoder_p # .shape (n_pos_bins, n_t_bins)\n",
    "single_decoder_p = np.nan_to_num(single_decoder_p, copy=True, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "single_decoder_p = single_decoder_p / np.nansum(single_decoder_p, axis=0) # all positions should normalize to 1.0\n",
    "single_decoder_p = np.nan_to_num(single_decoder_p, copy=True, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "single_decoder_p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dbd0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nansum(single_decoder_p, axis=-1)\n",
    "np.nansum(single_decoder_p, axis=0) # all positions should normalize to 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903e39e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "any_decoder_p = np.nan_to_num(any_decoder_p, copy=True, nan=0.0, posinf=1.0, neginf=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94176f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ndarray_preview height=500, width=None, include_plaintext_repr=False, include_shape=False, horizontal_layout=True\n",
    "\n",
    "np.nansum(summary_values_dict['all'], axis=-1) # .shape (59, 4) (n_pos_bins, 4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19747dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "summary_values_dict['long'].shape # .shape (n_pos_bins, n_t_bins)\n",
    "\n",
    "\n",
    "# np.nansum(summary_values_dict['long'], axis=0) # .shape (n_t_bins)\n",
    "np.nansum(summary_values_dict['long'], axis=1) # .shape (n_pos_bins)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e05f166",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_laps_decoder.xbin_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216f7766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_bin_bounds\n",
    "# long_results.pf1D.config.grid_bin_bounds\n",
    "\n",
    "a_laps_decoder.pf.config.grid_bin_bounds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e02152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: a_laps_decoded_marginal_posterior_df\n",
    "# a_laps_decoded_marginal_posterior_df\n",
    "a_laps_decoded_marginal_posterior_df\n",
    "a_laps_decoded_marginal_posterior_df = LongShortTrackDataframeAccessor.add_pre_post_delta_category_column_if_needed(epochs_df=a_laps_decoded_marginal_posterior_df, t_delta=t_delta, start_time_col_name='lap_start_t')\n",
    "a_laps_decoded_marginal_posterior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27cd6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS\n",
    "Assert.same_length(an_out_result.filter_epochs, an_out_result.p_x_given_n_list)\n",
    "# an_out_result.filter_epochs\n",
    "len(an_out_result.p_x_given_n_list)\n",
    "\n",
    "pre_post_delta_a_laps_decoded_marginal_posterior_df_dict = a_laps_decoded_marginal_posterior_df.pho.partition_df_dict('pre_post_delta_category') # pre_post_delta_category\n",
    "# pre_post_delta_a_laps_decoded_marginal_posterior_df_dict['pre-delta']\n",
    "# pre_post_delta_a_laps_decoded_marginal_posterior_df_dict['post-delta']\n",
    "\n",
    "an_out_result_dict: Dict[str, DecodedFilterEpochsResult] = {'pre-delta': an_out_result.filtered_by_epoch_times(pre_post_delta_a_laps_decoded_marginal_posterior_df_dict['pre-delta']['lap_start_t']),\n",
    "\t\t\t\t\t  'post-delta': an_out_result.filtered_by_epoch_times(pre_post_delta_a_laps_decoded_marginal_posterior_df_dict['post-delta']['lap_start_t']),\n",
    "}\n",
    "an_out_result_dict['pre-delta']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc3e75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import plot_linearized_position_probability\n",
    "\n",
    "# Example usage\n",
    "# fig, prob_values = plot_linearized_position_probability(an_out_result)\n",
    "\n",
    "fig1, ax1, prob_values1 = plot_linearized_position_probability(an_out_result=an_out_result_dict['pre_delta'], figure_title='pre-delta Linearized Position Probability')\n",
    "fig2, ax2, prob_values2 = plot_linearized_position_probability(an_out_result=an_out_result_dict['post_delta'], figure_title='post-delta Linearized Position Probability', ax=ax1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e773f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [v['p_x_given_n'].shape for v in an_out_result.marginal_x_list]\n",
    "# [v.shape for v in an_out_result.p_x_given_n_list]\n",
    "\n",
    "SUMMRY_WUMY = np.squeeze(np.hstack([np.squeeze(v[:,0,:]) for v in an_out_result.p_x_given_n_list])) + np.squeeze(np.hstack([np.squeeze(v[:,1,:]) for v in an_out_result.p_x_given_n_list]))\n",
    "gay_GARRAYU = np.nansum(SUMMRY_WUMY, axis=-1)\n",
    "NORMY_WARMY = np.nansum(gay_GARRAYU)\n",
    "gay_GARRAYU = gay_GARRAYU / NORMY_WARMY\n",
    "gay_GARRAYU\n",
    "\n",
    "\n",
    "plt.figure(num='INNOPCUOUS FIGHURE')\n",
    "plt.scatter(x=np.arange(len(gay_GARRAYU)), y=gay_GARRAYU)\n",
    "plt.ylabel('P(LONG)')\n",
    "plt.xlabel('Position <linearized>')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303c3e45",
   "metadata": {},
   "source": [
    "#### Pre 2025-05-01 Simple way of doing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1846ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.stack(an_out_result.p_x_given_n_list, axis=1)\n",
    "# np.hstack(an_out_result.p_x_given_n_list)\n",
    "\n",
    "    # an_out_result.p_x_given_n_lis\n",
    "\n",
    "gay_GARRAYU=np.nansum(np.hstack([v['p_x_given_n'] for v in an_out_result.marginal_x_list]), axis=-1)\n",
    "NORMY_WARMY = np.nansum(gay_GARRAYU)\n",
    "gay_GARRAYU = gay_GARRAYU / NORMY_WARMY\n",
    "\n",
    "\n",
    "plt.figure(num='PUPPY FIGHURE')\n",
    "plt.scatter(x=np.arange(len(gay_GARRAYU)), y=gay_GARRAYU)\n",
    "plt.ylabel('P(LONG)')\n",
    "plt.xlabel('Position <linearized>')\n",
    "\n",
    "\n",
    "# np.nansum(, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaccf1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import _perform_plot_P_Context_State_Transition_Matrix, _perform_plot_position_Transition_Matrix\n",
    "\n",
    "## INPUTS: laps_context_state_transition_matrix_context_dict\n",
    "# out_transition_matrix_context_dict = deepcopy(pbes_context_state_transition_matrix_context_dict)\n",
    "out_transition_matrix_context_dict = deepcopy(pbes_position_transition_matrix_context_dict)\n",
    "out_matched_result_tuple_context_dict = deepcopy(pbes_matched_result_tuple_context_dict)\n",
    "\n",
    "an_out_best_matching_context, an_out_result, an_out_decoder, an_out_decoded_marginal_posterior_df = list(out_matched_result_tuple_context_dict.values())[0] # [-1]\n",
    "a_transition_matrix_list: List[NDArray] = list(out_transition_matrix_context_dict.values())[0]\n",
    "\n",
    "## INPUTS: an_out_decoded_marginal_posterior_df, a_context_state_transition_matrix_list\n",
    "# 2024-03-04 - Filter out the epochs based on the criteria:\n",
    "# _, _, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "# filtered_epochs_df, active_spikes_df = filter_and_update_epochs_and_spikes(curr_active_pipeline, global_epoch_name, track_templates, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1)\n",
    "# filtered_valid_epoch_times = filtered_epochs_df[['start', 'stop']].to_numpy()\n",
    "# required_min_percentage_of_active_cells: float = 0.333333 # 20% of active cells\n",
    "# active_min_num_unique_aclu_inclusions_requirement: int = track_templates.min_num_unique_aclu_inclusions_requirement(curr_active_pipeline, required_min_percentage_of_active_cells=required_min_percentage_of_active_cells)\n",
    "# Update epochs and spikes\n",
    "# an_out_decoded_marginal_posterior_df, active_spikes_df = co_filter_epochs_and_spikes(active_spikes_df=active_spikes_df, active_epochs_df=an_out_decoded_marginal_posterior_df, included_aclus=track_templates.any_decoder_neuron_IDs, min_num_unique_aclu_inclusions=active_min_num_unique_aclu_inclusions_requirement, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1, add_unique_aclus_list_column=False, drop_non_epoch_spikes=True)\n",
    "# pbes_mean_context_state_transition_matrix_dict = split_transition_matricies_results_pre_post_delta_category(an_out_decoded_marginal_posterior_df=an_out_decoded_marginal_posterior_df, a_context_state_transition_matrix_list=a_transition_matrix_list)\n",
    "\n",
    "\n",
    "pbes_mean_context_state_transition_matrix_dict = split_transition_matricies_results_pre_post_delta_category(an_out_decoded_marginal_posterior_df=an_out_decoded_marginal_posterior_df, a_context_state_transition_matrix_list=list(deepcopy(pbes_context_state_transition_matrix_context_dict).values())[0])\n",
    "pbes_mean_position_transition_matrix_dict = split_transition_matricies_results_pre_post_delta_category(an_out_decoded_marginal_posterior_df=an_out_decoded_marginal_posterior_df, a_context_state_transition_matrix_list=list(deepcopy(pbes_position_transition_matrix_context_dict).values())[0])\n",
    "\n",
    "pbes_mean_context_state_transition_matrix_dict\n",
    "pbes_mean_position_transition_matrix_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da7552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import _perform_plot_P_Context_State_Transition_Matrix, _perform_plot_position_Transition_Matrix\n",
    "\n",
    "\n",
    "for pre_post_delta_value, a_mean_context_state_transition_matrix in pbes_mean_context_state_transition_matrix_dict.items():\n",
    "    # _perform_plot_P_Context_State_Transition_Matrix(context_state_transition_matrix=a_mean_context_state_transition_matrix, num=f'laps')\n",
    "    _perform_plot_P_Context_State_Transition_Matrix(context_state_transition_matrix=a_mean_context_state_transition_matrix, num=f'PBEs: Context ({pre_post_delta_value})')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9e865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pre_post_delta_value, a_mean_position_transition_matrix in pbes_mean_position_transition_matrix_dict.items():\n",
    "    # _perform_plot_P_Context_State_Transition_Matrix(context_state_transition_matrix=a_mean_context_state_transition_matrix, num=f'laps')\n",
    "    _perform_plot_position_Transition_Matrix(a_position_transition_matrix=a_mean_position_transition_matrix, num=f'PBEs: Positions ({pre_post_delta_value})')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9c7980",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert 'pre_post_delta_category' in an_out_decoded_marginal_posterior_df\n",
    "is_pre_delta = (an_out_decoded_marginal_posterior_df['pre_post_delta_category'] == 'pre-delta')\n",
    "\n",
    "a_context_state_transition_matrix: NDArray = np.stack(a_context_state_transition_matrix_list) # np.stack(out_context_state_transition_matrix_context_dict[a_ctxt]).shape\n",
    "\n",
    "## split on first index:\n",
    "a_context_state_transition_matrix_dict = {'pre-delta': a_context_state_transition_matrix[is_pre_delta], 'post-delta': a_context_state_transition_matrix[np.logical_not(is_pre_delta)]}\n",
    "a_mean_context_state_transition_matrix_dict = {k:np.nanmean(v, axis=0) for k, v in a_context_state_transition_matrix_dict.items()}\n",
    "\n",
    "# np.shape(a_context_state_transition_matrix) # (84, 4, 4) - (n_epochs, n_states, n_states)\n",
    "# a_mean_context_state_transition_matrix: NDArray = np.nanmean(a_context_state_transition_matrix, axis=0) #.shape (4, 4)\n",
    "# a_mean_context_state_transition_matrix\n",
    "a_mean_context_state_transition_matrix_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c28ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_pbes_decoded_marginal_posterior_df[a_pbes_decoded_marginal_posterior_df['pre_post_delta_category'] == 'pre-delta'] # (partitionColumn='pre_post_delta_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92968ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(laps_matched_result_tuple_context_dict.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96268dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_laps_decoded_marginal_posterior_df\n",
    "a_pbes_best_matching_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a869e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_mean_context_state_transition_matrix_context_dict[a_laps_best_matching_context]\n",
    "laps_mean_position_transition_matrix_context_dict[a_laps_best_matching_context]\n",
    "\n",
    "pbes_mean_context_state_transition_matrix_context_dict[a_pbes_best_matching_context]\n",
    "pbes_mean_position_transition_matrix_context_dict[a_pbes_best_matching_context]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa45f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_mean_context_state_transition_matrix_context_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea666e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import _perform_plot_P_Context_State_Transition_Matrix, _perform_plot_position_Transition_Matrix\n",
    "\n",
    "_perform_plot_P_Context_State_Transition_Matrix(context_state_transition_matrix=laps_mean_context_state_transition_matrix_context_dict[a_laps_best_matching_context], num='laps')\n",
    "_perform_plot_P_Context_State_Transition_Matrix(context_state_transition_matrix=pbes_mean_context_state_transition_matrix_context_dict[a_pbes_best_matching_context], num='PBEs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a3036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import _perform_plot_P_Context_State_Transition_Matrix, _perform_plot_position_Transition_Matrix\n",
    "\n",
    "_perform_plot_position_Transition_Matrix(a_position_transition_matrix=laps_mean_position_transition_matrix_context_dict[a_laps_best_matching_context], num='laps')\n",
    "_perform_plot_position_Transition_Matrix(a_position_transition_matrix=pbes_mean_position_transition_matrix_context_dict[a_pbes_best_matching_context], num='PBEs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a3258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# plt.figure(figsize=(8,6)); sns.heatmap(A_big, cmap='viridis'); plt.title(\"Transition Matrix A_big\"); plt.show()\n",
    "# plt.figure(figsize=(8,6)); sns.heatmap(A_position, cmap='viridis'); perform_update_title_subtitle(title_string=f\"Transition Matrix A_position - t_bin: {a_time_bin_size}\"); plt.show(); \n",
    "# plt.figure(figsize=(8,6)); sns.heatmap(A_model, cmap='viridis'); perform_update_title_subtitle(title_string=f\"Transition Matrix A_model - t_bin: {a_time_bin_size}\"); plt.show()\n",
    "\n",
    "n_position_bins = 59\n",
    "n_decoding_models = 4\n",
    "_out = plot_blocked_transition_matrix(pbes_mean_position_transition_matrix_context_dict[a_pbes_best_matching_context], n_position_bins, n_decoding_models, extra_title_suffix=f' - t_bin: {a_time_bin_size}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7d6da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "FAT_df: pd.DataFrame = deepcopy(a_new_fully_generic_result.single_FAT_df)\n",
    "# len(all_contexts)\n",
    "FAT_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1589048",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# all_contexts\n",
    "unique_values_dict = FAT_df.neuropy.get_column_unique_values_dict(columns_include_subset=['trained_compute_epochs', 'known_named_decoding_epochs_type', 'masked_time_bin_fill_type', 'data_grain', 'decoding_time_bin_size']) # , 'masked_time_bin_fill_type'\n",
    "unique_values_dict\n",
    "\n",
    "# [Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'non_pbe_endcaps', masked_time_bin_fill_type= 'dropped', data_grain= 'per_time_bin', decoding_time_bin_size= 0.025),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_epoch'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'non_pbe', masked_time_bin_fill_type= 'last_valid'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'pbe'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'non_pbe'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'dropped', data_grain= 'per_time_bin'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'dropped', data_grain= 'per_time_bin'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_epoch'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'nan_filled'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'non_pbe_endcaps', masked_time_bin_fill_type= 'last_valid', data_grain= 'per_time_bin', decoding_time_bin_size= 0.025),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'dropped', data_grain= 'per_epoch'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'ignore'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_time_bin'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'ignore'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'non_pbe_endcaps', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin', decoding_time_bin_size= 0.025),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'last_valid'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'nan_filled'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'non_pbe', masked_time_bin_fill_type= 'nan_filled'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'global', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_time_bin'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'non_pbe_endcaps', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_time_bin', decoding_time_bin_size= 0.025),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'ignore', data_grain= 'per_epoch'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'non_pbe', masked_time_bin_fill_type= 'ignore'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'last_valid'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore', data_grain= 'per_epoch'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'dropped', data_grain= 'per_time_bin'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'laps'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'dropped', data_grain= 'per_epoch'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'nan_filled'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'dropped', data_grain= 'per_time_bin'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'nan_filled'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'global', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_time_bin')]\n",
    "\n",
    "possible_unique_values_dict = {'trained_compute_epochs': ['non_pbe', 'laps'],\n",
    " 'known_named_decoding_epochs_type': ['laps', 'pbe', 'non_pbe', 'global', 'non_pbe_endcaps'],\n",
    " 'masked_time_bin_fill_type': ['ignore', 'last_valid', 'nan_filled', 'dropped'],\n",
    " 'data_grain': ['per_time_bin', 'per_epoch'],\n",
    " 'decoding_time_bin_size': [0.025]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d746d004",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.050, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore') # , decoder_identifier='long_LR'\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore', data_grain='per_epoch') # , time_bin_size=0.050, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore', decoder_identifier='long_LR'\n",
    "\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='ignore', data_grain='per_epoch') ## Laps\n",
    "# any_matching_contexts_list, result_context_dict, decoder_context_dict, decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context)\n",
    "\n",
    "# common_constraint_dict = dict(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, masked_time_bin_fill_type='ignore')\n",
    "common_constraint_dict = dict(trained_compute_epochs='laps', time_bin_size=0.025, masked_time_bin_fill_type='nan_filled') # , pfND_ndim=1\n",
    "\n",
    "\n",
    "## Laps context:\n",
    "a_laps_target_context: IdentifyingContext = IdentifyingContext(known_named_decoding_epochs_type='laps', **common_constraint_dict, data_grain='per_epoch') ## Laps\n",
    "laps_target_context_results = complete_all_transition_matricies(a_new_fully_generic_result=a_new_fully_generic_result, a_target_context=a_laps_target_context)\n",
    "laps_matched_result_tuple_context_dict, (laps_time_bin_container_context_dict, laps_position_transition_matrix_context_dict, laps_context_state_transition_matrix_context_dict, laps_combined_transition_matrix_context_dict), (laps_mean_context_state_transition_matrix_context_dict, laps_mean_position_transition_matrix_context_dict) = laps_target_context_results\n",
    "# a_best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = out_matched_result_tuple_context_dict[a_ctxt]\n",
    "a_laps_best_matching_context, a_laps_result, a_laps_decoder, a_laps_decoded_marginal_posterior_df = list(laps_matched_result_tuple_context_dict.values())[0] # [-1]\n",
    "\n",
    "## PBEs context:\n",
    "a_PBEs_target_context: IdentifyingContext = IdentifyingContext(known_named_decoding_epochs_type='pbe', **common_constraint_dict, data_grain='per_epoch') ## Laps\n",
    "pbes_target_context_results = complete_all_transition_matricies(a_new_fully_generic_result=a_new_fully_generic_result, a_target_context=a_PBEs_target_context)\n",
    "pbes_matched_result_tuple_context_dict, (pbes_time_bin_container_context_dict, pbes_position_transition_matrix_context_dict, pbes_context_state_transition_matrix_context_dict, pbes_combined_transition_matrix_context_dict), (pbes_mean_context_state_transition_matrix_context_dict, pbes_mean_position_transition_matrix_context_dict) = pbes_target_context_results\n",
    "a_pbes_best_matching_context, a_pbes_result, a_pbes_decoder, a_pbes_decoded_marginal_posterior_df = list(pbes_matched_result_tuple_context_dict.values())[0] # [-1] # pbes_matched_result_tuple_context_dict[a_PBEs_target_context]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bb3795",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values_dict = FAT_df.neuropy.get_column_unique_values_dict(columns_include_subset=['custom_replay_name', 'included_qclu_values', 'minimum_inclusion_fr_Hz', 'time_bin_size']) # , 'masked_time_bin_fill_type'\n",
    "unique_values_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f75ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0fe9b90",
   "metadata": {},
   "source": [
    "# 2025-05-04 - Add interpolated position to any decoded result df with (P_Long, P_Short, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40962ef9",
   "metadata": {},
   "source": [
    "### Active manual adding of position columns to obtained global result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a360cd",
   "metadata": {
    "tags": [
     "active-2025-05-05"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _helper_add_interpolated_position_columns_to_decoded_result_df\n",
    "# from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import _perform_plot_hairy_overlayed_position\n",
    "\n",
    "## INPUTS: a_new_fully_generic_result\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='nan_filled', data_grain='per_time_bin')\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='ignore', data_grain='per_time_bin')\n",
    "best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=a_target_context, debug_print=False)\n",
    "## OUTPUTS: a_result, a_decoder, a_decoded_marginal_posterior_df\n",
    "## INPUTS: curr_active_pipeline, a_result, a_decoder, a_decoded_marginal_posterior_df\n",
    "global_measured_position_df: pd.DataFrame = deepcopy(curr_active_pipeline.sess.position.to_dataframe())\n",
    "a_decoded_marginal_posterior_df: pd.DataFrame = _helper_add_interpolated_position_columns_to_decoded_result_df(a_result=a_result, a_decoder=a_decoder, a_decoded_marginal_posterior_df=a_decoded_marginal_posterior_df,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  global_measured_position_df=global_measured_position_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c843f5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _helper_add_interpolated_position_columns_to_decoded_result_df\n",
    "# from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import _perform_plot_hairy_overlayed_position\n",
    "\n",
    "\n",
    "\n",
    "## INPUTS: a_new_fully_generic_result\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='nan_filled', data_grain='per_time_bin')\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type='ignore', data_grain='per_time_bin') # , known_named_decoding_epochs_type='global'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True)\n",
    "\n",
    "# flat_context_list\n",
    "flat_decoded_marginal_posterior_df_context_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2338f685",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=a_target_context, debug_print=False)\n",
    "## OUTPUTS: a_result, a_decoder, a_decoded_marginal_posterior_df\n",
    "## INPUTS: curr_active_pipeline, a_result, a_decoder, a_decoded_marginal_posterior_df\n",
    "global_measured_position_df: pd.DataFrame = deepcopy(curr_active_pipeline.sess.position.to_dataframe())\n",
    "a_decoded_marginal_posterior_df: pd.DataFrame = _helper_add_interpolated_position_columns_to_decoded_result_df(a_result=a_result, a_decoder=a_decoder, a_decoded_marginal_posterior_df=a_decoded_marginal_posterior_df,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  global_measured_position_df=global_measured_position_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d68ac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## now check the histogram for `a_decoded_marginal_posterior_df`\n",
    "a_decoded_marginal_posterior_df: pd.DataFrame = a_decoded_marginal_posterior_df\n",
    "a_decoded_marginal_posterior_df\n",
    "# a_decoded_marginal_posterior_df['binned_x_meas'].hist()\n",
    "a_decoded_marginal_posterior_df.to_csv('output/2025-05-05_decoded_marginal_posterior_df_with_meas_pos.csv')\n",
    "\n",
    "## OUTPUTS: a_decoded_marginal_posterior_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8625601",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c1ef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _helper_add_interpolated_position_columns_to_decoded_result_df\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import _perform_plot_hairy_overlayed_position\n",
    "from neuropy.utils.matplotlib_helpers import draw_epoch_regions\n",
    "\n",
    "## INPUTS: a_decoded_marginal_posterior_df\n",
    "\n",
    "# ## plot the basic lap-positions (measured) over time figure:\n",
    "# _out = dict()\n",
    "# _out['_display_grid_bin_bounds_validation'] = curr_active_pipeline.display(display_function='_display_grid_bin_bounds_validation', active_session_configuration_context=None, include_includelist=[], save_figure=False) # _display_grid_bin_bounds_validation\n",
    "# fig = _out['_display_grid_bin_bounds_validation'].figures[0]\n",
    "# out_axes_list =_out['_display_grid_bin_bounds_validation'].axes\n",
    "# out_plot_data =_out['_display_grid_bin_bounds_validation'].plot_data\n",
    "# ## get the lines2D object to turn off the default position lines:\n",
    "# position_lines_2D = out_plot_data['position_lines_2D']\n",
    "# ## hide all inactive lines:\n",
    "# for a_line in position_lines_2D:\n",
    "#     a_line.set_visible(False)\n",
    "\n",
    "# ax = out_axes_list[0]\n",
    "\n",
    "\n",
    "ax = None\n",
    "    \n",
    "an_pos_line_artist, df_viz = _perform_plot_hairy_overlayed_position(df=deepcopy(a_decoded_marginal_posterior_df), ax=ax, extreme_threshold=0.7) # , thickness_ramping_multiplier=5\n",
    "# df_viz\n",
    "# _out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b126a652",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_pos_line_artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad91da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add epoch indicators:\n",
    "\n",
    "## INPUTS: ax\n",
    "\n",
    "from neuropy.utils.matplotlib_helpers import draw_epoch_regions\n",
    "\n",
    "# epochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, defer_render=False, debug_print=False)\n",
    "# epochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.laps, ax, defer_render=False, debug_print=True)\n",
    "\n",
    "y_height_fraction: float = 0.05\n",
    "n_epoch_types: int = 3\n",
    "relative_y_positions_list = [((float(i)*y_height_fraction), (float(i+1)*y_height_fraction)) for i in np.arange(n_epoch_types)]  # [(0.0, 0.05), (0.05, 0.1), (0.1, 0.15000000000000002)]\n",
    "relative_y_positions_list\n",
    "\n",
    "# relative_y_positions_list = [(0.1, 0.15), (0.15, 0.2)]\n",
    "\n",
    "\n",
    "# relative_y_positions_list = [(0.0, 0.2)]\n",
    "\n",
    "# relative_y_positions=[[0.0, 0.05], [0.05, 0.10], \n",
    "epoch_collection_artists_list_dict = {}\n",
    "\n",
    "common_kwargs = dict(alpha=0.2, linewidths=None)\n",
    "# epochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, facecolor=('red','cyan'), edgecolors=None, labels_kwargs={'y_offset': -0.05, 'size': 14}, **common_kwargs, relative_y_positions=relative_y_positions_list[0], defer_render=True, debug_print=False)\n",
    "# laps_epochs_collection, laps_epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.laps.as_epoch_obj(), ax, facecolor='red', edgecolors='black', labels_kwargs={'y_offset': -16.0, 'size':8}, **common_kwargs, relative_y_positions=relative_y_positions_list[0], defer_render=True, debug_print=False)\n",
    "# replays_epochs_collection, replays_epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.pbe, ax, facecolor='orange', edgecolors=None, labels_kwargs=None, **common_kwargs, relative_y_positions=relative_y_positions_list[0], defer_render=False, debug_print=False)\n",
    "\n",
    "# # epochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, facecolor=('red','cyan'), edgecolors=None, **common_kwargs, relative_y_positions=relative_y_positions_list[0], defer_render=True, debug_print=False)\n",
    "# epoch_collection_artists_list_dict['laps'] = draw_epoch_regions(curr_active_pipeline.sess.laps.as_epoch_obj(), ax, facecolor='red', edgecolors='black', **common_kwargs, relative_y_positions=relative_y_positions_list[0], defer_render=False, debug_print=True)\n",
    "# # epoch_collection_artists_list_dict['replays'] = draw_epoch_regions(curr_active_pipeline.sess.pbe, ax, facecolor='purple', edgecolors=None, **common_kwargs, relative_y_positions=relative_y_positions_list[1], defer_render=False, debug_print=False)\n",
    "\n",
    "\n",
    "# epoch_collection_artists_list_dict['delta'] = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, facecolor=('red','cyan'), edgecolors=None, **common_kwargs, defer_render=False, debug_print=True)\n",
    "epoch_collection_artists_list_dict['laps'] = draw_epoch_regions(curr_active_pipeline.sess.laps.as_epoch_obj(), ax, facecolor='red', edgecolors=None, **common_kwargs, defer_render=False, debug_print=True)\n",
    "epoch_collection_artists_list_dict['replays'] = draw_epoch_regions(curr_active_pipeline.sess.pbe, ax, facecolor='purple', edgecolors=None, **common_kwargs, defer_render=False, debug_print=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aa7934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_all_epoch_artists(epoch_collection_artists_list_dict):\n",
    "    for a_name, a_list in epoch_collection_artists_list_dict.items():\n",
    "        for an_item in a_list:\n",
    "            if an_item is not None:\n",
    "                an_item.remove() ## remove the artist\n",
    "    epoch_collection_artists_list_dict = {} ## clear\n",
    "    return epoch_collection_artists_list_dict\n",
    "\n",
    "\n",
    "epoch_collection_artists_list_dict = remove_all_epoch_artists(epoch_collection_artists_list_dict=epoch_collection_artists_list_dict)\n",
    "\n",
    "\n",
    "# laps_epochs_collection.remove()\n",
    "# laps_epoch_labels.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd57669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, facecolor=[(255, 0, 0), (0, 255, 0)], edgecolors=(0,0,0), labels_kwargs={'y_offset': -16.0, 'size':8, 'rotation':90}, defer_render=False, debug_print=False)\n",
    "\n",
    "epochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, facecolor=[(255, 0, 0), (0, 255, 0)], edgecolors=(0,0,0), labels_kwargs={'y_offset': -16.0, 'size':8, 'rotation':90}, defer_render=False, debug_print=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d8e569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs_collection.remove()\n",
    "# epoch_labels.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a187527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.plotting.hairy_lines_plot import HairyLinePlot\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out = curr_active_pipeline.display(display_function='_display_decoded_trackID_marginal_hairy_position', active_session_configuration_context=None, include_includelist=[], save_figure=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8286a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz[['P_Long', 'P_Short']].sum(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d66e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(a_decoded_marginal_posterior_df_viz) - 1):\n",
    "    row0 = a_decoded_marginal_posterior_df_viz.iloc[i]\n",
    "    row1 = a_decoded_marginal_posterior_df_viz.iloc[i + 1]\n",
    "    if row0['P_Long'] > 0.9 and row1['P_Long'] > 0.9:\n",
    "        ax.plot([row0['t'], row1['t']], [row0['x_meas'], row1['x_meas']],\n",
    "                color=(1, 0, 0, min(row0['P_Long_Opacity'], row1['P_Long_Opacity'])),\n",
    "                linewidth=max(row0['P_Long_Score'], row1['P_Long_Score']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952b9ec8",
   "metadata": {},
   "source": [
    "# 2025-05-04 - Posterior Example Images Export to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25144acd",
   "metadata": {
    "tags": [
     "posterior-export"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from pyphocorehelpers.plotting.media_output_helpers import ImageOperationsAndEffects\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out_paths = curr_active_pipeline.display('_display_directional_merged_pf_decoded_stacked_epoch_slices')\n",
    "_out_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681e725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.assertion_helpers import Assert\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import HeatmapExportConfig, PosteriorExporting\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd08158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a_params_kwargs = {}\n",
    "display_context = curr_active_pipeline.build_display_context_for_session(display_fn_name='trackID_weighted_position_posterior')\n",
    "_out = curr_active_pipeline.display('_display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay', display_context, defer_render=True, save_figure=True,\n",
    "                                    # override_fig_man=custom_fig_man, \n",
    "                                    parent_output_folder=custom_figure_output_path,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bfe9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out['out_paths']\n",
    "\n",
    "# {'laps': {'psuedo2D_ignore': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/array_to_images/2025-05-30/gor01_one_2006-6-12_15-55-31_trackID_weighted_position_posterior/laps/psuedo2D_ignore'),\n",
    "#   'psuedo2D_nan_filled': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/array_to_images/2025-05-30/gor01_one_2006-6-12_15-55-31_trackID_weighted_position_posterior/laps/psuedo2D_nan_filled')},\n",
    "#  'ripple': {'psuedo2D_ignore': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/array_to_images/2025-05-30/gor01_one_2006-6-12_15-55-31_trackID_weighted_position_posterior/ripple/psuedo2D_ignore'),\n",
    "#   'psuedo2D_nan_filled': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/array_to_images/2025-05-30/gor01_one_2006-6-12_15-55-31_trackID_weighted_position_posterior/ripple/psuedo2D_nan_filled')}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4db4eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_parent_save_paths = _out['flat_parent_save_paths']\n",
    "flat_parent_save_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550217b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out['flat_merged_image_paths']\n",
    "_out['parent_output_folder']\n",
    "flat_parent_save_paths = _out['flat_parent_save_paths']\n",
    "flat_parent_save_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d5931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_path in flat_parent_save_paths:\n",
    "    # file_uri_from_path(a_path)\n",
    "    fullwidth_path_widget(a_path=a_path, file_name_label=\"epoch_specific_folder:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6ca625",
   "metadata": {
    "tags": [
     "heu"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _plot_heuristic_evaluation_epochs\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_filter_replay_epochs\n",
    "\n",
    "force_refilter = False\n",
    "# force_refilter = True\n",
    "\n",
    "needs_refilter = False\n",
    "try:\n",
    "    filtered_decoder_filter_epochs_decoder_result_dict\n",
    "    filtered_epochs_df\n",
    "    filtered_ripple_all_epoch_bins_marginals_df\n",
    "    if filtered_decoder_filter_epochs_decoder_result_dict is not None:\n",
    "        needs_refilter = False\n",
    "except NameError:\n",
    "    needs_refilter = True\n",
    "    \n",
    "if needs_refilter or force_refilter:\n",
    "    filtered_epochs_df, filtered_decoder_filter_epochs_decoder_result_dict, filtered_ripple_all_epoch_bins_marginals_df = _perform_filter_replay_epochs(curr_active_pipeline, global_epoch_name, track_templates, decoder_ripple_filter_epochs_decoder_result_dict, ripple_all_epoch_bins_marginals_df, ripple_decoding_time_bin_size=ripple_decoding_time_bin_size, should_only_include_user_selected_epochs=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2146f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)\n",
    "# for k, v in filtered_decoder_filter_epochs_decoder_result_dict.items():\n",
    "# \tdirectional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc5b1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _plot_heuristic_evaluation_epochs\n",
    "\n",
    "\n",
    "# filtered_epochs_df\n",
    "# filtered_ripple_all_epoch_bins_marginals_df\n",
    "\n",
    "## 1m 38s\n",
    "\n",
    "ripple_merged_complete_epoch_stats_df['is_valid_epoch'] = True\n",
    "## INPUTS: curr_active_pipeline, track_templates, filtered_decoder_filter_epochs_decoder_result_dict, ripple_merged_complete_epoch_stats_df\n",
    "app, (high_heuristic_paginated_multi_decoder_decoded_epochs_window, high_heuristic_pagination_controller_dict), (low_heuristic_paginated_multi_decoder_decoded_epochs_window, low_heuristic_pagination_controller_dict) = _plot_heuristic_evaluation_epochs(curr_active_pipeline, track_templates, filtered_decoder_filter_epochs_decoder_result_dict, ripple_merged_complete_epoch_stats_df=ripple_merged_complete_epoch_stats_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dc8bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.RankOrderRastersDebugger import RankOrderRastersDebugger\n",
    "\n",
    "__out_ripple_rasters, update_attached_raster_viewer_epoch_callback = paginated_multi_decoder_decoded_epochs_window.build_attached_raster_viewer_widget(track_templates=track_templates, active_spikes_df=active_spikes_df, filtered_epochs_df=long_like_during_post_delta_only_filter_epochs_df) # Long-like-during-post-delta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45522cb0",
   "metadata": {},
   "source": [
    "# <a id='toc12_'></a>[🖼️🎨`PhoPaginatedMultiDecoderDecodedEpochsWindow.plot_full_paginated_decoded_epochs_window(..)` combined windows](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1add4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neuropy.core.epoch import ensure_dataframe\n",
    "# from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import PhoPaginatedMultiDecoderDecodedEpochsWindow, DecodedEpochSlicesPaginatedFigureController, EpochSelectionsObject, ClickActionCallbacks\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import co_filter_epochs_and_spikes, get_proper_global_spikes_df\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.TemplateDebugger import TemplateDebugger\n",
    "\n",
    "# from neuropy.utils.matplotlib_helpers import get_heatmap_cmap\n",
    "# from pyphocorehelpers.gui.Qt.color_helpers import ColormapHelpers, ColorFormatConverter\n",
    "# from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import FixedCustomColormaps\n",
    "# from pyphoplacecellanalysis.GUI.Qt.Widgets.ThinButtonBar.ThinButtonBarWidget import ThinButtonBarWidget\n",
    "# from pyphoplacecellanalysis.GUI.Qt.Widgets.PaginationCtrl.PaginationControlWidget import PaginationControlWidget, PaginationControlWidgetState\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from pyphoplacecellanalysis.Resources import GuiResources, ActionIcons, silx_resources_rc\n",
    "from neuropy.utils.indexing_helpers import flatten, NumpyHelpers, PandasHelpers\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicThresholdFiltering\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _plot_heuristic_evaluation_epochs\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_filter_replay_epochs\n",
    "\n",
    "\n",
    "should_only_include_user_selected_epochs = False\n",
    "# should_only_include_user_selected_epochs = True\n",
    "\n",
    "# required_min_percentage_of_active_cells: float = 0.33333333 ## default\n",
    "required_min_percentage_of_active_cells: float = 0.20 # min_num_unique_aclu_inclusions: 10\n",
    "\n",
    "force_refilter = False\n",
    "# force_refilter = True\n",
    "\n",
    "needs_refilter = False\n",
    "try:\n",
    "    filtered_decoder_filter_epochs_decoder_result_dict\n",
    "    filtered_epochs_df\n",
    "    filtered_ripple_all_epoch_bins_marginals_df\n",
    "    if filtered_decoder_filter_epochs_decoder_result_dict is not None:\n",
    "        needs_refilter = False\n",
    "except NameError:\n",
    "    needs_refilter = True\n",
    "    \n",
    "if needs_refilter or force_refilter:\n",
    "    filtered_epochs_df, filtered_decoder_filter_epochs_decoder_result_dict, filtered_ripple_all_epoch_bins_marginals_df = _perform_filter_replay_epochs(curr_active_pipeline, global_epoch_name, track_templates, decoder_ripple_filter_epochs_decoder_result_dict, ripple_all_epoch_bins_marginals_df, ripple_decoding_time_bin_size=ripple_decoding_time_bin_size, should_only_include_user_selected_epochs=should_only_include_user_selected_epochs)\n",
    "\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "# directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=required_min_percentage_of_active_cells, debug_print=False) # min_num_unique_aclu_inclusions: 16 seems too high\n",
    "directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=required_min_percentage_of_active_cells, debug_print=False) # min_num_unique_aclu_inclusions: 16 seems too high\n",
    "\n",
    "# for k, v in filtered_decoder_filter_epochs_decoder_result_dict.items():\n",
    "# \tdirectional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=required_min_percentage_of_active_cells, debug_print=False)\n",
    "\n",
    "\n",
    "## INPUTS: directional_decoders_epochs_decode_result, filtered_epochs_df\n",
    "decoder_ripple_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "unfiltered_epochs_df = deepcopy(decoder_ripple_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)\n",
    "filtered_decoder_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(filtered_epochs_df[['start', 'stop']].to_numpy()) for a_name, a_result in decoder_ripple_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "\n",
    "ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "print(f'{pos_bin_size = }, {ripple_decoding_time_bin_size = }')\n",
    "\n",
    "## OUTPUTS: unfiltered_epochs_df, decoder_ripple_filter_epochs_decoder_result_dict\n",
    "## OUTPUTS: filtered_epochs_df, filtered_decoder_filter_epochs_decoder_result_dict\n",
    "\n",
    "# posterior_heatmap_imshow_kwargs = {'cmap': orange_posterior_cmap}\n",
    "\n",
    "## pos_bin_size = 4.877453969028168, ripple_decoding_time_bin_size = 0.016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174b423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directional_decoders_evaluate_epochs\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_evaluate_epochs'], computation_kwargs_list=[{'should_skip_radon_transform': False}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8bba6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unfiltered_epochs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43059e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import FixedCustomColormaps\n",
    "\n",
    "## INPUTS: included_ripple_start_times\n",
    "# 1D_search (only for start times):\n",
    "# matching_specific_start_ts_only_filtered_decoder_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(included_ripple_start_times) for a_name, a_result in filtered_decoder_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "# matching_specific_start_ts_only_filtered_decoder_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:deepcopy(a_result) for a_name, a_result in filtered_decoder_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "# # matching_specific_start_ts_only_filtered_decoder_filter_epochs_decoder_result_dict\n",
    "# matching_specific_start_ts_only_filter_epochs_df = deepcopy(matching_specific_start_ts_only_filtered_decoder_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)\n",
    "# matching_specific_start_ts_only_filter_epochs_df\n",
    "\n",
    "# # 2024-03-04 - Filter out the epochs based on the criteria:\n",
    "\n",
    "active_spikes_df = get_proper_global_spikes_df(curr_active_pipeline)\n",
    "# active_min_num_unique_aclu_inclusions_requirement: int = track_templates.min_num_unique_aclu_inclusions_requirement(curr_active_pipeline, required_min_percentage_of_active_cells=0.333333333)\n",
    "# matching_specific_start_ts_only_filter_epochs_df, active_spikes_df = co_filter_epochs_and_spikes(active_spikes_df=active_spikes_df, active_epochs_df=matching_specific_start_ts_only_filter_epochs_df, included_aclus=track_templates.any_decoder_neuron_IDs, min_num_unique_aclu_inclusions=active_min_num_unique_aclu_inclusions_requirement, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1, add_unique_aclus_list_column=True, drop_non_epoch_spikes=True)\n",
    "# filtered_epochs_ripple_simple_pf_pearson_merged_df, active_spikes_df = co_filter_epochs_and_spikes(active_spikes_df=active_spikes_df, active_epochs_df=ripple_simple_pf_pearson_merged_df, included_aclus=track_templates.any_decoder_neuron_IDs, min_num_unique_aclu_inclusions=active_min_num_unique_aclu_inclusions_requirement, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1, add_unique_aclus_list_column=True, drop_non_epoch_spikes=True)\n",
    "# matching_specific_start_ts_only_filter_epochs_df, active_spikes_df = co_filter_epochs_and_spikes(active_spikes_df=active_spikes_df, active_epochs_df=matching_specific_start_ts_only_filter_epochs_df, included_aclus=track_templates.any_decoder_neuron_IDs, min_num_unique_aclu_inclusions=active_min_num_unique_aclu_inclusions_requirement, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1, add_unique_aclus_list_column=True, drop_non_epoch_spikes=True)\n",
    "\n",
    "# filtered_epochs_ripple_simple_pf_pearson_merged_df\n",
    "\n",
    "# ## INPUTS: directional_decoders_epochs_decode_result, filtered_epochs_df\n",
    "# decoder_ripple_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "# unfiltered_epochs_df = deepcopy(decoder_ripple_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)\n",
    "# filtered_decoder_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(filtered_epochs_df[['start', 'stop']].to_numpy()) for a_name, a_result in decoder_ripple_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "\n",
    "## INPUTS: filtered_decoder_filter_epochs_decoder_result_dict\n",
    "\n",
    "pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "\n",
    "\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# BEGIN FCN BODY                                                                                                       #\n",
    "# ==================================================================================================================== #\n",
    "## INPUTS filtered_decoder_filter_epochs_decoder_result_dict\n",
    "# decoder_decoded_epochs_result_dict: generic\n",
    "active_cmap = FixedCustomColormaps.get_custom_greyscale_with_low_values_dropped_cmap(low_value_cutoff=0.01, full_opacity_threshold=0.25)\n",
    "\n",
    "# Replay/PBEs ________________________________________________________________________________________________________ #\n",
    "active_decoder_decoded_epochs_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(filtered_decoder_filter_epochs_decoder_result_dict)\n",
    "active_filter_epochs_df: pd.DataFrame = deepcopy(active_decoder_decoded_epochs_result_dict['long_LR'].filter_epochs) # deepcopy(matching_specific_start_ts_only_filter_epochs_df)\n",
    "epochs_name='ripple'\n",
    "title='Filtered PBEs'\n",
    "known_epochs_type = 'ripple'\n",
    "ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "active_decoding_time_bin_size: float = ripple_decoding_time_bin_size\n",
    "\n",
    "\n",
    "# # Laps _______________________________________________________________________________________________________________ #\n",
    "# ## INPUTS: decoder_laps_filter_epochs_decoder_result_dict, \n",
    "# active_decoder_decoded_epochs_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(decoder_laps_filter_epochs_decoder_result_dict)\n",
    "# active_filter_epochs_df: pd.DataFrame = deepcopy(active_decoder_decoded_epochs_result_dict['long_LR'].filter_epochs) # deepcopy(matching_specific_start_ts_only_filter_epochs_df)\n",
    "# epochs_name='laps'\n",
    "# title='Laps'\n",
    "# known_epochs_type = 'laps'\n",
    "# laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "# active_decoding_time_bin_size: float = laps_decoding_time_bin_size\n",
    "\n",
    "print(f'{pos_bin_size = }, {active_decoding_time_bin_size = }')\n",
    "## INPUTS: active_decoder_decoded_epochs_result_dict, active_filter_epochs_df, directional_decoders_epochs_decode_result, curr_active_pipeline, track_templates, active_spikes_df\n",
    "\n",
    "active_spikes_df = get_proper_global_spikes_df(curr_active_pipeline)\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations'] ## GENERAL\n",
    "(app, paginated_multi_decoder_decoded_epochs_window, pagination_controller_dict), ripple_rasters_plot_tuple, yellow_blue_trackID_marginals_plot_tuple = PhoPaginatedMultiDecoderDecodedEpochsWindow.plot_full_paginated_decoded_epochs_window(curr_active_pipeline=curr_active_pipeline, track_templates=track_templates, active_spikes_df=active_spikes_df,\n",
    "                                                                                                                                                                                                   active_decoder_decoded_epochs_result_dict=deepcopy(active_decoder_decoded_epochs_result_dict), # epochs_name='ripple',\n",
    "                                                                                                                                                                                                   directional_decoders_epochs_decode_result=deepcopy(directional_decoders_epochs_decode_result),\n",
    "                                                                                                                                                                                                   active_filter_epochs_df=active_filter_epochs_df, known_epochs_type=known_epochs_type, title=title,\n",
    "                                                                                                params_kwargs={'enable_per_epoch_action_buttons': False,\n",
    "                                                                                                    'skip_plotting_most_likely_positions': True, 'skip_plotting_measured_positions': True, \n",
    "                                                                                                    'enable_decoded_most_likely_position_curve': False, \n",
    "                                                                                                    'enable_decoded_sequence_and_heuristics_curve': True, 'show_pre_merged_debug_sequences': False, 'show_heuristic_criteria_filter_epoch_inclusion_status': True,\n",
    "                                                                                                     'enable_radon_transform_info': False, 'enable_weighted_correlation_info': True, 'enable_weighted_corr_data_provider_modify_axes_rect': False,\n",
    "                                                                                                    # 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': False,\n",
    "                                                                                                    # 'disable_y_label': True,\n",
    "                                                                                                    'isPaginatorControlWidgetBackedMode': True,\n",
    "                                                                                                    'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True,\n",
    "                                                                                                    # 'debug_print': True,\n",
    "                                                                                                    'max_subplots_per_page': 9,\n",
    "                                                                                                    # 'scrollable_figure': False,\n",
    "                                                                                                    'scrollable_figure': True,\n",
    "                                                                                                    # 'posterior_heatmap_imshow_kwargs': dict(vmin=0.0075),\n",
    "                                                                                                    'use_AnchoredCustomText': False,\n",
    "                                                                                                    'should_suppress_callback_exceptions': False,\n",
    "                                                                                                    # 'build_fn': 'insets_view',\n",
    "                                                                                                    'track_length_cm_dict': deepcopy(track_templates.get_track_length_dict()),\n",
    "                                                                                                    'posterior_heatmap_imshow_kwargs': dict(cmap=active_cmap), # , vmin=0.1, vmax=1.0\n",
    "                                                                                                    'data_overlay_heuristic_kwargs': dict(same_thresh_fraction_of_track=0.001, max_jump_distance_cm=360.0, max_ignore_bins=25),\n",
    "                                                                                                })\n",
    "attached_yellow_blue_marginals_viewer_widget: DecodedEpochSlicesPaginatedFigureController = paginated_multi_decoder_decoded_epochs_window.attached_yellow_blue_marginals_viewer_widget\n",
    "attached_ripple_rasters_widget: RankOrderRastersDebugger = paginated_multi_decoder_decoded_epochs_window.attached_ripple_rasters_widget\n",
    "attached_directional_template_pfs_debugger: TemplateDebugger = paginated_multi_decoder_decoded_epochs_window.attached_directional_template_pfs_debugger\n",
    "\n",
    "## OUTPUTS: directional_merged_decoders_result\n",
    "# user_interactivity_instructions_dict = {'left-click':'toggle is_good annotation', 'right-click':'select epoch row', 'MMB click':'get clicked time to clipboard'}\n",
    "# user_interactivity_instructions_message: str = ', '.join([f'{k}:{v}' for k, v in user_interactivity_instructions_dict.items()])\n",
    "# print(f'user_interactivity_instructions_message: \"{user_interactivity_instructions_message}\"')\n",
    "# paginated_multi_decoder_decoded_epochs_window.show_message(user_interactivity_instructions_message, durationMs=4000)\n",
    "\n",
    "# add_data_overlays(...): decoder_track_length is None so skipping heuristics plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f91bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paginated_multi_decoder_decoded_epochs_window.attached_yellow_blue_marginals_viewer_widget.plots_data.all_attributes # ['name', 'epoch_slices', 'global_pos_df', 'filter_epochs_decoder_result', 'active_marginal_fn', 'paginator', 'highlighted_epoch_time_bin_idx', 'decoded_position_curves_data', 'marginal_labels_data']\n",
    "\n",
    "filter_epochs_decoder_result: DecodedFilterEpochsResult = paginated_multi_decoder_decoded_epochs_window.attached_yellow_blue_marginals_viewer_widget.plots_data.filter_epochs_decoder_result\n",
    "filter_epochs_decoder_result.nbins\n",
    "filter_epochs: pd.DataFrame = deepcopy(filter_epochs_decoder_result.filter_epochs)\n",
    "filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4ae8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_epochs['n_time_bins'] = filter_epochs_decoder_result.nbins\n",
    "filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea0292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_epochs['est_n_t_bins'] = filter_epochs['duration'] / 0.025\n",
    "filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6f9c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_epochs[filter_epochs['label'] == '370']\n",
    "\n",
    "\n",
    "# filter_epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0155968",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_epochs[filter_epochs['start'] > 1505.164]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fea1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_add_data_overlays = paginated_multi_decoder_decoded_epochs_window.add_data_overlays()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a9c497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import SubsequencesPartitioningResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import DecodedSequenceAndHeuristicsPlotData\n",
    "\n",
    "decoded_sequence_and_heuristics_curves_data_dict: Dict[types.DecoderName, Dict[float, DecodedSequenceAndHeuristicsPlotData]] = paginated_multi_decoder_decoded_epochs_window.get_children_props(prop_path='plots_data.decoded_sequence_and_heuristics_curves_data')\n",
    "decoded_sequence_and_heuristics_partition_results_dict: Dict[types.DecoderName, Dict[float, SubsequencesPartitioningResult]] = {a_name:{k:v.partition_result for k, v in a_data_dict.items()} for a_name, a_data_dict in decoded_sequence_and_heuristics_curves_data_dict.items()}\n",
    "# decoded_sequence_and_heuristics_curves_data_dict\n",
    "decoded_sequence_and_heuristics_partition_results_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c285e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_sequence_and_heuristics_curves_data_dict ## OUTPUT\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb39e357",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.get_children_props(prop_path='params.data_overlay_heuristic_kwargs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046f2b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.set_children_props(prop_path='params.data_overlay_heuristic_kwargs', value=dict(same_thresh_fraction_of_track=0.005, max_jump_distance_cm=360.0, max_ignore_bins=22))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96b258c",
   "metadata": {},
   "source": [
    "## 2025-08-26 - Try Fourier Transform of Decoded Posterior for signal extraction/detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752b6f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fft import fft, fftfreq, fftshift # Using scipy.fft for convenience\n",
    "\n",
    "\n",
    "test_decoded_positions_dict = {'ascending_ramp': [192.659, 124.375, 99.9878, 75.6005, 70.7231, 192.659],\n",
    "                                'reversed_ramp': list(reversed([192.659, 124.375, 99.9878, 75.6005, 70.7231, 192.659])),\n",
    "\t\t\t\t\t\t\t   'scattered': [202.414, 114.62, 163.395, 192.659, 207.292, 2.43873, 2.43873, 197.537],\n",
    "                               'almost_flat': [217.047, 217.047, 236.557],\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for a_name, most_likely_decoded_positions in test_decoded_positions_dict.items():\n",
    "\n",
    "\n",
    "    n_t_bins: int = len(most_likely_decoded_positions)\n",
    "    # Compute the Discrete Fourier Transform of the signal\n",
    "    dft_signal = np.fft.fft(most_likely_decoded_positions)\n",
    "    frequencies = np.fft.fftfreq(n_t_bins, d=1)\n",
    "\n",
    "    fig = plt.figure(layout=\"constrained\", figsize=(8,4))\n",
    "    ax_dict = fig.subplot_mosaic(\n",
    "        [\n",
    "            [f\"ax_sig\", \"ax_fft\"],\n",
    "        ],\n",
    "        # set the height ratios between the rows\n",
    "        # height_ratios=[8, 1],\n",
    "        # height_ratios=[1, 1],\n",
    "        # set the width ratios between the columns\n",
    "        width_ratios=[1, 1],\n",
    "        sharey=False,\n",
    "        gridspec_kw=dict(wspace=0, hspace=0.15) # `wspace=0`` is responsible for sticking the pf and the activity axes together with no spacing\n",
    "    )\n",
    "\n",
    "    ax_dict['ax_sig'].stem(np.arange(n_t_bins), most_likely_decoded_positions)\n",
    "    \n",
    "    ax_dict['ax_sig'].set_xlabel(\"time bins\")\n",
    "    ax_dict['ax_sig'].set_ylabel(\"Most-likely Pos\")\n",
    "    ax_dict['ax_sig'].set_title(f\"Decoded Most-likely Pos: {a_name}\")\n",
    "\n",
    "    ax_dict['ax_fft'].stem(frequencies, np.abs(dft_signal))\n",
    "    plt.xlabel(\"Frequency\")\n",
    "    plt.ylabel(\"Magnitude\")\n",
    "    plt.title(f\"DFT Magnitude Spectrum: {a_name}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fee5b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.placefield import plot_placefield_tuning_curve\n",
    "\n",
    "example_pf1D_data = {'xbin_centers': np.array([31.0565, 34.8495, 38.6426, 42.4356, 46.2286, 50.0216, 53.8147, 57.6077, 61.4007, 65.1937, 68.9867, 72.7798, 76.5728, 80.3658, 84.1588, 87.9519, 91.7449, 95.5379, 99.3309, 103.124, 106.917, 110.71, 114.503, 118.296, 122.089, 125.882, 129.675, 133.468, 137.261, 141.054, 144.847, 148.64, 152.433, 156.226, 160.019, 163.812, 167.605, 171.398, 175.191, 178.984, 182.777, 186.57, 190.363, 194.157, 197.95, 201.743, 205.536, 209.329, 213.122, 216.915, 220.708, 224.501, 228.294, 232.087, 235.88, 239.673, 243.466, 247.259, 251.052, 254.845, 258.638, 262.431]),\n",
    " 'curr_cell_normalized_tuning_curve': np.array([5.92979e-05, 0.000150933, 0.00036895, 0.000736517, 0.00121915, 0.00173714, 0.0022042, 0.00252859, 0.0026496, 0.0027108, 0.00312627, 0.00423033, 0.00579314, 0.00709557, 0.00766535, 0.00789647, 0.00884807, 0.0115452, 0.0165549, 0.0238423, 0.0323681, 0.039895, 0.0442459, 0.0452642, 0.0449909, 0.0457691, 0.0485138, 0.0525281, 0.0562324, 0.0581433, 0.0575758, 0.0544383, 0.0486438, 0.0404683, 0.0315115, 0.0243731, 0.0207242, 0.0199181, 0.0197507, 0.0183449, 0.0153819, 0.0119837, 0.00951012, 0.00827676, 0.00740415, 0.00596512, 0.00396809, 0.00210018, 0.000875453, 0.000302685, 0.000153468, 0.00027615, 0.000667689, 0.00135676, 0.00224608, 0.00305331, 0.0034339, 0.0031979, 0.0024518, 0.00153458, 0.00079294, 0.000405152])}\n",
    "\n",
    "xbin_centers = example_pf1D_data['xbin_centers']\n",
    "curr_cell_normalized_tuning_curve = example_pf1D_data['curr_cell_normalized_tuning_curve']\n",
    "\n",
    "fig = plt.figure(layout=\"constrained\")\n",
    "ax_dict = fig.subplot_mosaic(\n",
    "    [\n",
    "        [\"ax_activity_v_time\", \"ax_pf_tuning_curve\"],\n",
    "    ],\n",
    "\t# set the height ratios between the rows\n",
    "    # height_ratios=[8, 1],\n",
    "    # height_ratios=[1, 1],\n",
    "    # set the width ratios between the columns\n",
    "    width_ratios=[8, 1],\n",
    "    sharey=True,\n",
    "    gridspec_kw=dict(wspace=0, hspace=0.15) # `wspace=0`` is responsible for sticking the pf and the activity axes together with no spacing\n",
    ")\n",
    "# hist_data = np.random.randn(1_500)\n",
    "# xbin_centers = np.arange(len(hist_data))+0.5\n",
    "\n",
    "ax_dict[\"ax_activity_v_time\"].plot([1, 2, 3, 3, 3, 2, 1, 0, 0, 0, 1, 2, 3, 3, 1, 2, 0, 0])\n",
    "ax_dict[\"ax_pf_tuning_curve\"] = plot_placefield_tuning_curve(xbin_centers, curr_cell_normalized_tuning_curve, ax_dict[\"ax_pf_tuning_curve\"], is_horizontal=True)\n",
    "# ax_dict[\"ax_pf_tuning_curve\"].hist(hist_data)\n",
    "ax_dict[\"ax_pf_tuning_curve\"].set_xticklabels([])\n",
    "ax_dict[\"ax_pf_tuning_curve\"].set_yticklabels([])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952d4716",
   "metadata": {},
   "source": [
    "# 🖼️ `export_current_epoch_marginal_and_raster_images` to export rasters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8838a34b",
   "metadata": {},
   "source": [
    "#### Batch (all) epochs export via `export_current_epoch_marginal_and_raster_images`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2a64ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import PhoPaginatedMultiDecoderDecodedEpochsWindow\n",
    "\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders'] # uses `DirectionalMergedDecoders`.\n",
    "\n",
    "# root_export_path: Path = Path(r\"/media/halechr/MAX/cloud/University of Michigan Dropbox/Pho Hale/Pho Diba Paper 2023/array_as_image\").resolve() # Lab\n",
    "# root_export_path: Path = Path(r'K:/scratch/collected_outputs/figures/array_as_image').resolve()\n",
    "\n",
    "root_export_path: Path = Path(r'K:/scratch/collected_figures/qclu_1246789/array_as_image').resolve()\n",
    "\n",
    "\n",
    "# root_export_path: Path = Path(r'C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\EXTERNAL\\Screenshots\\ProgrammaticDisplayFunctionTesting\\array_as_image').resolve()\n",
    "root_export_path.mkdir(exist_ok=True)\n",
    "Assert.path_exists(root_export_path)\n",
    "\n",
    "complete_session_context, (session_context, additional_session_context) = curr_active_pipeline.get_complete_session_context()\n",
    "_out_path_tuples_dict = paginated_multi_decoder_decoded_epochs_window.export_all_epoch_marginal_and_raster_images(directional_merged_decoders_result=directional_merged_decoders_result, root_export_path=root_export_path, active_context=complete_session_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541163df",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(_out_path_tuples_dict.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9019b4cd",
   "metadata": {},
   "source": [
    "#### Single epoch export via `export_current_epoch_marginal_and_raster_images`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58d46c3",
   "metadata": {
    "tags": [
     "2025-05-16_working-posterior-and-raster-stack-image-saving"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "\n",
    "## INPUTS: \n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders'] # uses `DirectionalMergedDecoders`.\n",
    "\n",
    "\n",
    "# root_export_path: Path = Path(r\"/media/halechr/MAX/cloud/University of Michigan Dropbox/Pho Hale/Pho Diba Paper 2023/array_as_image\").resolve() # Lab\n",
    "root_export_path: Path = Path(r'K:/scratch/collected_outputs/figures/array_as_image').resolve()\n",
    "# root_export_path: Path = Path(r'C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\EXTERNAL\\Screenshots\\ProgrammaticDisplayFunctionTesting\\array_as_image').resolve()\n",
    "root_export_path.mkdir(exist_ok=True)\n",
    "Assert.path_exists(root_export_path)\n",
    "\n",
    "complete_session_context, (session_context, additional_session_context) = curr_active_pipeline.get_complete_session_context()\n",
    "epoch_specific_folder, (out_image_save_tuple_dict, _out_rasters_save_paths, merged_img_save_path) = paginated_multi_decoder_decoded_epochs_window.export_current_epoch_marginal_and_raster_images(directional_merged_decoders_result=directional_merged_decoders_result, root_export_path=root_export_path, active_context=complete_session_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795876fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: paginated_multi_decoder_decoded_epochs_window\n",
    "attached_ripple_rasters_widget: RankOrderRastersDebugger = paginated_multi_decoder_decoded_epochs_window.attached_ripple_rasters_widget\n",
    "_out_ripple_rasters = paginated_multi_decoder_decoded_epochs_window\n",
    "epoch_specific_folder, (out_image_save_tuple_dict, _out_rasters_save_paths, merged_img_save_path) = PosteriorExporting._perform_export_current_epoch_marginal_and_raster_images(_out_ripple_rasters=_out_ripple_rasters, directional_merged_decoders_result=directional_merged_decoders_result, \n",
    "    filtered_decoder_filter_epochs_decoder_result_dict=decoder_ripple_filter_epochs_decoder_result_dict, epoch_id_identifier_str='ripple',\n",
    "    # filtered_decoder_filter_epochs_decoder_result_dict=decoder_laps_filter_epochs_decoder_result_dict, epoch_id_identifier_str='lap',\n",
    "    active_session_context=curr_context, \n",
    "    root_export_path = root_export_path,\n",
    ")\n",
    "\n",
    "file_uri_from_path(epoch_specific_folder)\n",
    "fullwidth_path_widget(a_path=epoch_specific_folder, file_name_label=\"epoch_specific_folder:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996c72e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders'] # uses `DirectionalMergedDecoders`.\n",
    "\n",
    "# root_export_path: Path = Path(r'C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\EXTERNAL\\Screenshots\\ProgrammaticDisplayFunctionTesting\\array_as_image').resolve()\n",
    "root_export_path: Path = Path(r'K:/scratch/collected_outputs/figures/array_as_image').resolve()\n",
    "root_export_path.mkdir(exist_ok=True)\n",
    "Assert.path_exists(root_export_path)\n",
    "\n",
    "complete_session_context, (session_context, additional_session_context) = curr_active_pipeline.get_complete_session_context()\n",
    "\n",
    "## INPUTS: paginated_multi_decoder_decoded_epochs_window\n",
    "attached_ripple_rasters_widget: RankOrderRastersDebugger = paginated_multi_decoder_decoded_epochs_window.attached_ripple_rasters_widget\n",
    "_out_ripple_rasters = paginated_multi_decoder_decoded_epochs_window\n",
    "epoch_specific_folder, (out_image_save_tuple_dict, _out_rasters_save_paths, merged_img_save_path) = PosteriorExporting._perform_export_current_epoch_marginal_and_raster_images(_out_ripple_rasters=attached_ripple_rasters_widget, directional_merged_decoders_result=directional_merged_decoders_result, \n",
    "    filtered_decoder_filter_epochs_decoder_result_dict=decoder_ripple_filter_epochs_decoder_result_dict, epoch_id_identifier_str='ripple',\n",
    "    # filtered_decoder_filter_epochs_decoder_result_dict=decoder_laps_filter_epochs_decoder_result_dict, epoch_id_identifier_str='lap',\n",
    "    active_session_context=complete_session_context, \n",
    "    root_export_path = root_export_path,\n",
    ")\n",
    "\n",
    "file_uri_from_path(epoch_specific_folder)\n",
    "fullwidth_path_widget(a_path=epoch_specific_folder, file_name_label=\"epoch_specific_folder:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7051885",
   "metadata": {},
   "source": [
    "### <a id='toc12_1_4_'></a>[2024-02-29 3pm - Get the active user-annotated epoch times from the `paginated_multi_decoder_decoded_epochs_window` and use these to filter `filtered_ripple_simple_pf_pearson_merged_df`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767317a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inputs: paginated_multi_decoder_decoded_epochs_window\n",
    "any_good_selected_epoch_times = deepcopy(paginated_multi_decoder_decoded_epochs_window.any_good_selected_epoch_times)\n",
    "any_good_selected_epoch_indicies = deepcopy(paginated_multi_decoder_decoded_epochs_window.find_data_indicies_from_epoch_times(paginated_multi_decoder_decoded_epochs_window.any_good_selected_epoch_times))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bc2a41",
   "metadata": {},
   "source": [
    "## <a id='toc12_2_'></a>[:✅:🎯 2024-09-27 - Test programmatic/background saving of stacked decoded epoch figures](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7d0436",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: filtered_epochs_df\n",
    "decoder_laps_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict)\n",
    "unfiltered_laps_epochs_df = deepcopy(decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)\n",
    "filtered_decoder_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(filtered_epochs_df[['start', 'stop']].to_numpy()) for a_name, a_result in decoder_ripple_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "\n",
    "laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "print(f'{pos_bin_size = }, {laps_decoding_time_bin_size = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae48eec3",
   "metadata": {
    "tags": [
     "good",
     "posterior-export",
     "batch",
     "2025-08-13"
    ]
   },
   "outputs": [],
   "source": [
    "# using: perform_export_all_decoded_posteriors_as_images\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import HeatmapExportConfig, PosteriorExporting\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import HeatmapExportKind\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import Assert\n",
    "\n",
    "## INPUTS:: filtered_decoder_filter_epochs_decoder_result_dict, long_like_during_post_delta_only_filter_epochs\n",
    "active_epochs_decoder_result_dict = deepcopy(filtered_decoder_filter_epochs_decoder_result_dict)\n",
    "parent_output_folder = Path('output/array_to_images').resolve()\n",
    "\n",
    "# active_epochs_decoder_result_dict = deepcopy(long_like_during_post_delta_only_filtered_decoder_filter_epochs_decoder_result_dict)\n",
    "# parent_output_folder = Path('output/long_like_during_post_delta').resolve()\n",
    "\n",
    "\n",
    "# active_epochs_decoder_result_dict = deepcopy(filtered_decoder_filter_epochs_decoder_result_dict)\n",
    "\n",
    "\n",
    "## Laps:\n",
    "active_epochs_decoder_result_dict = deepcopy(decoder_laps_filter_epochs_decoder_result_dict)\n",
    "\n",
    "\n",
    "\n",
    "parent_output_folder.mkdir(exist_ok=True)\n",
    "Assert.path_exists(parent_output_folder)\n",
    "posterior_out_folder = parent_output_folder.joinpath(DAY_DATE_TO_USE).resolve()\n",
    "posterior_out_folder.mkdir(parents=True, exist_ok=True)\n",
    "save_path = posterior_out_folder.resolve()\n",
    "_parent_save_context: IdentifyingContext = curr_active_pipeline.build_display_context_for_session('perform_export_all_decoded_posteriors_as_images')\n",
    "_specific_session_output_folder = save_path.joinpath(active_context.get_description(subset_excludelist=['format_name'])).resolve()\n",
    "_specific_session_output_folder.mkdir(parents=True, exist_ok=True)\n",
    "print(f'\\tspecific_session_output_folder: \"{_specific_session_output_folder}\"')\n",
    "\n",
    "custom_export_formats: Dict[str, HeatmapExportConfig] = {\n",
    "    'greyscale': HeatmapExportConfig.init_greyscale(desired_height=1200),\n",
    "    # 'color': HeatmapExportConfig.init_for_export_kind(export_kind=HeatmapExportKind.COLORMAPPED, colormap='Oranges', desired_height=1200),\n",
    "    # 'color': HeatmapExportConfig(colormap=additional_cmaps['long_LR']),\n",
    "    # 'color': HeatmapExportConfig(colormap=cmap1, desired_height=200),\n",
    "\t# 'raw_rgba': HeatmapExportConfig.init_for_export_kind(export_kind=HeatmapExportKind.RAW_RGBA, lower_bound_alpha=0.1, drop_below_threshold=1e-2, desired_height=1200),\n",
    "\t# 'raw_rgba': HeatmapExportConfig.init_for_export_kind(export_kind=HeatmapExportKind.RAW_RGBA, \n",
    "    #                                                     raw_RGBA_only_parameters = dict(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), xbin=deepcopy(a_decoder.xbin), lower_bound_alpha=0.1, drop_below_threshold=1e-2, t_bin_size=0.025),\n",
    "    #                                                     desired_height=1200),\n",
    "}\n",
    "# custom_export_formats = None\n",
    "\n",
    "\n",
    "# `raw_RGBA_only_parameters` dict with keys: ['spikes_df', 'xbin', 'lower_bound_alpha', 'drop_below_threshold', 't_bin_size']\n",
    "\n",
    "out_paths, out_custom_formats_dict = PosteriorExporting.perform_export_all_decoded_posteriors_as_images(decoder_laps_filter_epochs_decoder_result_dict=None, decoder_ripple_filter_epochs_decoder_result_dict=active_epochs_decoder_result_dict, ## for PBEs\n",
    "# out_paths, out_custom_formats_dict = PosteriorExporting.perform_export_all_decoded_posteriors_as_images(decoder_laps_filter_epochs_decoder_result_dict=deepcopy(decoder_laps_filter_epochs_decoder_result_dict), decoder_ripple_filter_epochs_decoder_result_dict=None, ## for laps\n",
    "                                                                                                            _save_context=_parent_save_context, parent_output_folder=_specific_session_output_folder,\n",
    "                                                                                                            desired_height=1200, custom_export_formats=custom_export_formats, combined_img_padding=6, combined_img_separator_color=(0, 0, 0, 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51933623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26558aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_uri_from_path(_specific_session_output_folder)\n",
    "fullwidth_path_widget(a_path=_specific_session_output_folder, file_name_label=\"epoch_specific_folder:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fcf49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_new_fully_generic_result.get_results_matching_contexts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58598b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['generalized_specific_epochs_decoding'],\n",
    "                        computation_kwargs_list=[{'epochs_decoding_time_bin_size': time_bin_size, 'drop_previous_result_and_compute_fresh': True, 'force_recompute': False}], \n",
    "                        enabled_filter_names=None, fail_on_exception=True, debug_print=False) \n",
    "\n",
    "# 11m 5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8607a51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# pbe_trained_decoder_search_context = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type=('ignore', 'nan_filled', 'dropped'), data_grain='per_time_bin') # , decoder_identifier='pseudo2D', data_grain= 'per_time_bin -- not really relevant: ['masked_time_bin_fill_type', 'known_named_decoding_epochs_type', 'data_grain']\n",
    "# laps_trained_decoder_search_context = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='dropped', data_grain='per_time_bin')\n",
    "pbe_trained_decoder_search_context = IdentifyingContext()\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=pbe_trained_decoder_search_context, return_multiple_matches=True, debug_print=False)\n",
    "flat_context_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0924b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "[Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_time_bin'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'nan_filled'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'dropped', data_grain= 'per_epoch'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'non_pbe_endcaps', masked_time_bin_fill_type= 'dropped', data_grain= 'per_time_bin', decoding_time_bin_size= 0.025),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'non_pbe', masked_time_bin_fill_type= 'last_valid'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'global', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'nan_filled'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'ignore'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'dropped', data_grain= 'per_time_bin'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'non_pbe_endcaps', masked_time_bin_fill_type= 'last_valid', data_grain= 'per_time_bin', decoding_time_bin_size= 0.025),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_epoch'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'global', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_time_bin'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'non_pbe_endcaps', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin', decoding_time_bin_size= 0.025),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'non_pbe', masked_time_bin_fill_type= 'ignore'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'non_pbe_endcaps', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_time_bin', decoding_time_bin_size= 0.025),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'ignore'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'last_valid'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'dropped', data_grain= 'per_epoch'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'laps'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'nan_filled'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'ignore', data_grain= 'per_epoch'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_time_bin'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'dropped', data_grain= 'per_time_bin'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'nan_filled'),\n",
    " Context(trained_compute_epochs= 'non_pbe', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'dropped', data_grain= 'per_time_bin'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_epoch'),\n",
    " Context(trained_compute_epochs= 'non_pbe', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore', data_grain= 'per_epoch'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'non_pbe', masked_time_bin_fill_type= 'nan_filled'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'non_pbe'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'pbe'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'dropped', data_grain= 'per_time_bin'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'last_valid')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2ceb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_epoch_specific_decoded_results1D_dict, continuous_specific_decoded_results1D_dict, new_decoder1D_dict, new_pf1Ds_dict = self.recompute(curr_active_pipeline=curr_active_pipeline, pfND_ndim=1, epochs_decoding_time_bin_size=epochs_decoding_time_bin_size, skip_training_test_split=skip_training_test_split)\n",
    "frame_divided_epochs_specific_decoded_results1D_dict = {a_name:a_new_decoder.decode_specific_epochs(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), filter_epochs=deepcopy(global_frame_divided_epochs_obj), decoding_time_bin_size=epochs_decoding_time_bin_size, debug_print=False) for a_name, a_new_decoder in new_decoder1D_dict.items()}\n",
    "results1D = DecodingResultND(ndim=1, \n",
    "    test_epoch_results=test_epoch_specific_decoded_results1D_dict, \n",
    "    continuous_results=continuous_specific_decoded_results1D_dict,\n",
    "    decoders=new_decoder1D_dict, pfs=new_pf1Ds_dict,\n",
    "    frame_divided_epochs_results=frame_divided_epochs_specific_decoded_results1D_dict, \n",
    "    frame_divided_epochs_df=deepcopy(global_frame_divided_epochs_df), pos_df=global_pos_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5807baf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get epochs to decode:\n",
    "\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "global_session = curr_active_pipeline.filtered_sessions[global_epoch_name]\n",
    "\n",
    "# global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "global_laps = ensure_Epoch(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps.to_dataframe())) # .trimmed_to_non_overlapping()\n",
    "global_PBEs = ensure_Epoch(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].pbe)) # .trimmed_to_non_overlapping()\n",
    "\n",
    "epochs_to_decode_dict: Dict = {'laps': global_laps, 'pbe': global_PBEs}\n",
    "## OUTPUTS: epochs_to_decode_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01da635",
   "metadata": {
    "tags": [
     "2025-05-30"
    ]
   },
   "outputs": [],
   "source": [
    "## INPUTS: curr_active_pipeline, epochs_decoding_time_bin_size, epochs_to_decode_dict, a_new_fully_generic_result\n",
    "\n",
    "## UPDATES: a_new_fully_generic_result\n",
    "\n",
    "decoders_dict: Dict[types.DecoderName, BasePositionDecoder] = deepcopy(track_templates.get_decoders_dict())\n",
    "laps_trained_decoder_search_context = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, masked_time_bin_fill_type='ignore', data_grain='per_time_bin') # , data_grain= 'per_time_bin -- not really relevant: ['masked_time_bin_fill_type', 'known_named_decoding_epochs_type', 'data_grain']\n",
    "\n",
    "## Can add:     known_named_decoding_epochs_type='laps', \n",
    "out_dict = {}\n",
    "\n",
    "for a_decoder_name, a_decoder in decoders_dict.items():\n",
    "    ## for each decoder\n",
    "    for an_epoch_to_decode_name, an_epochs_to_decode_obj in epochs_to_decode_dict.items():\n",
    "        ## for each epoch to decode\n",
    "        a_context: IdentifyingContext = deepcopy(laps_trained_decoder_search_context).overwriting_context(decoder_identifier=a_decoder_name, known_named_decoding_epochs_type=an_epoch_to_decode_name)        \n",
    "        a_result: DecodedFilterEpochsResult = a_decoder.decode_specific_epochs(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), filter_epochs=deepcopy(an_epochs_to_decode_obj), decoding_time_bin_size=epochs_decoding_time_bin_size, debug_print=False)\n",
    "        a_new_fully_generic_result.updating_results_for_context(new_context=a_context, a_result=a_result, a_decoder=deepcopy(a_decoder), a_decoded_marginal_posterior_df=None, an_epoch_to_decode=deepcopy(an_epochs_to_decode_obj)) ## update using the result\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b1a689",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict[a_context]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c6757c",
   "metadata": {},
   "source": [
    "# ❌ 2025-05-04 - 11am - New Overlayed plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8880f92f",
   "metadata": {
    "tags": [
     "run-group-mergedcolorplot"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _helper_add_interpolated_position_columns_to_decoded_result_df\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import MultiDecoderColorOverlayedPosteriors\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import EpochComputationFunctions, EpochComputationsComputationsContainer\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import SingleEpochDecodedResult\n",
    "\n",
    "\n",
    "valid_EpochComputations_result: EpochComputationsComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['EpochComputations']\n",
    "a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult = valid_EpochComputations_result.a_generic_decoder_dict_decoded_epochs_dict_result\n",
    "all_decoder_colors_dict = {'long': '#4169E1', 'short': '#DC143C', 'long_LR': '#4169E1', 'long_RL': '#607B00', 'short_LR': '#DC143C', 'short_RL': '#990099'} ## Just hardcoded version of `additional_cmap_names`\n",
    "\n",
    "## INPUTS: a_new_fully_generic_result\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='nan_filled', data_grain='per_time_bin')\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='ignore', data_grain='per_time_bin')\n",
    "best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=a_target_context, debug_print=False)\n",
    "## OUTPUTS: a_result, a_decoder, a_decoded_marginal_posterior_df\n",
    "## INPUTS: curr_active_pipeline, a_result, a_decoder, a_decoded_marginal_posterior_df\n",
    "global_measured_position_df: pd.DataFrame = deepcopy(curr_active_pipeline.sess.position.to_dataframe())\n",
    "a_decoded_marginal_posterior_df: pd.DataFrame = _helper_add_interpolated_position_columns_to_decoded_result_df(a_result=a_result, a_decoder=a_decoder, a_decoded_marginal_posterior_df=a_decoded_marginal_posterior_df, global_measured_position_df=global_measured_position_df)\n",
    "\n",
    "global_decoded_result: SingleEpochDecodedResult = a_result.get_result_for_epoch(0)\n",
    "p_x_given_n: NDArray[ND.Shape[\"N_POS_BINS, 4, N_TIME_BINS\"], np.floating] = deepcopy(global_decoded_result.p_x_given_n) # .shape # (59, 4, 69488)\n",
    "time_bin_centers: NDArray[ND.Shape[\"N_TIME_BINS\"], np.floating] = deepcopy(global_decoded_result.time_bin_container.centers)\n",
    "xbin: NDArray[ND.Shape[\"N_POS_BINS\"], np.floating] = deepcopy(a_decoder.xbin)\n",
    "\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-MultiDecoderColorOverlayedPosteriors.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "multi_decoder_color_overlay: MultiDecoderColorOverlayedPosteriors = MultiDecoderColorOverlayedPosteriors(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), p_x_given_n=p_x_given_n, time_bin_centers=time_bin_centers, xbin=xbin, lower_bound_alpha=0.0, drop_below_threshold=1e-3, t_bin_size=0.025)\n",
    "multi_decoder_color_overlay.compute_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a846a220",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = multi_decoder_color_overlay.add_tracks_to_spike_raster_window(active_2d_plot=active_2d_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77b4a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ccd339",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb62af58",
   "metadata": {},
   "source": [
    "# :🔝💯🟢🖼️ 2025-05-16 - Export Overlayed Plots for Pseudo2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ce6986",
   "metadata": {},
   "source": [
    "### Main Figure Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ef555b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'],\n",
    "                                                  # computation_kwargs_list=[{'time_bin_size': 0.016, 'should_disable_cache':False}], \n",
    "                                                  computation_kwargs_list=[{'time_bin_size': 0.025, 'should_disable_cache':False}], \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t#   computation_kwargs_list=[{'time_bin_size': 0.050, 'should_disable_cache':False}], \n",
    "                                                  # computation_kwargs_list=[{'time_bin_size': 0.058, 'should_disable_cache':False}], \n",
    "                                                  enabled_filter_names=None, fail_on_exception=True, debug_print=True)\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'], computation_kwargs_list=[{'time_bin_size': 0.058}], #computation_kwargs_list=[{'time_bin_size': 0.025}], \n",
    "#                                                   enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0506efaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import EpochComputationDisplayFunctions\n",
    "import pyphoplacecellanalysis.General.type_aliases as types\n",
    "\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "\n",
    "time_bin_size: float = 0.025\n",
    "_out = EpochComputationDisplayFunctions._display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay(curr_active_pipeline, None, None, None, include_includelist=None, save_figure=True, parent_output_folder=collected_outputs_path, time_bin_size=time_bin_size)\n",
    "\n",
    "# curr_active_pipeline.plot\n",
    "# curr_active_pipeline.registered_display_function_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b2f7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization ______________________________________________________________________________________________________ #\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow, LayoutScrollability\n",
    "from pyphocorehelpers.plotting.media_output_helpers import vertical_image_stack, horizontal_image_stack, image_grid # used in `_subfn_build_combined_output_images`\n",
    "from pyphocorehelpers.image_helpers import ImageHelpers\n",
    "\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import HeatmapExportConfig, HeatmapExportKind\n",
    "\n",
    "out_paths: Dict[types.KnownNamedDecoderTrainedComputeEpochsType, Dict[types.DecoderName, Path]] = _out['out_paths']\n",
    "out_custom_formats_dict: Dict[types.KnownNamedDecodingEpochsType, Dict[types.DecoderName, Dict[str, List[HeatmapExportConfig]]]] = _out['out_custom_formats_dict']\n",
    "\n",
    "out_custom_formats_dict: Dict = _out['out_custom_formats_dict']\n",
    "\n",
    "# flat_imgs = []\n",
    "\n",
    "flat_imgs_dict: Dict[IdentifyingContext, List] = {}\n",
    "flat_merged_images = {}\n",
    "\n",
    "\n",
    "for a_series_name, v_dict in out_custom_formats_dict.items():\n",
    "    # a_series_name: ['laps', 'ripple']\n",
    "    for a_decoder_name, a_rendered_configs_dict in v_dict.items():\n",
    "        \n",
    "        for a_config_name, a_rendered_config_list in a_rendered_configs_dict.items():\n",
    "            # 'raw_rgba'\n",
    "            # print(a_rendered_config_list)\n",
    "            # len(a_rendered_config_list)\n",
    "            \n",
    "            a_ctxt = IdentifyingContext(series=a_series_name, decoder=a_decoder_name, config=a_config_name)\n",
    "            flat_imgs = []\n",
    "            \n",
    "            for i, a_config in enumerate(a_rendered_config_list):      \n",
    "                # posterior_save_path = a_config.posterior_saved_path\n",
    "                _posterior_image = a_config.posterior_saved_image\n",
    "                flat_imgs.append(_posterior_image)\n",
    "                \n",
    "                # print(F'a_rendered_config: {type(a_rendered_config)}')\n",
    "                # type(a_rendered_config_list[0])\n",
    "                # print(F'a_rendered_config: {list(a_rendered_config.keys())}')\n",
    "                # file_uri_from_path(a_path)\n",
    "                # fullwidth_path_widget(a_path=a_path, file_name_label=f\"{a_series_name}[{a_decoder_name}]:\")\n",
    "                # flat_img_out_paths.append(a_path)\n",
    "            ## END  for i, a_config in enum...\n",
    "            ## OUTPUTS: flat_imgs\n",
    "            _merged_img = horizontal_image_stack(flat_imgs, padding=10, separator_color='white')\n",
    "            flat_merged_images[a_series_name] = _merged_img\n",
    "            flat_imgs_dict[a_ctxt] = flat_imgs\n",
    "            \n",
    "\n",
    "# flat_img_out_paths\n",
    "flat_merged_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9328b4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_imgs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398079d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flat_merged_images['laps'].show()\n",
    "\n",
    "flat_merged_images['ripple'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fabb1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show output paths:\n",
    "\n",
    "flat_img_out_paths = []\n",
    "out_paths = deepcopy(_out['out_paths'])\n",
    "for a_series_name, v_dict in out_paths.items():\n",
    "    # a_series_name: ['laps', 'ripple']\n",
    "    for a_decoder_name, a_path in v_dict.items():\n",
    "        file_uri_from_path(a_path)\n",
    "        fullwidth_path_widget(a_path=a_path, file_name_label=f\"{a_series_name}[{a_decoder_name}]:\")\n",
    "        flat_img_out_paths.append(a_path)\n",
    "        \n",
    "flat_img_out_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c852e01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benedict import benedict\n",
    "\n",
    "out_custom_formats_dict = benedict(out_custom_formats_dict)\n",
    "out_custom_formats_dict.keypaths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee530a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = dict()\n",
    "_out['trackID_weighted_position_posterior'] = curr_active_pipeline.display(display_function='_display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay', active_session_configuration_context=None) # _display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d60a631",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# _out = curr_active_pipeline.display('_display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay')\n",
    "_out = curr_active_pipeline.display('trackID_weighted_position_posterior')\n",
    "\n",
    "# 'trackID_weighted_position_posterior'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e387d7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using: perform_export_all_decoded_posteriors_as_images\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import HeatmapExportConfig, PosteriorExporting\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import HeatmapExportKind\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import Assert\n",
    "\n",
    "## INPUTS:: filtered_decoder_filter_epochs_decoder_result_dict, long_like_during_post_delta_only_filter_epochs\n",
    "# active_epochs_decoder_result_dict = deepcopy(filtered_decoder_filter_epochs_decoder_result_dict)\n",
    "parent_output_folder = Path('output/array_to_images').resolve()\n",
    "\n",
    "## Build a makeshift dict with just the pseudo2D in it:\n",
    "## INPUTS:\n",
    "a_decoder = deepcopy(flat_decoder_context_dict[active_ctxts[0]])\n",
    "# a_decoder = deepcopy(a_laps_trained_decoder)\n",
    "\n",
    "## INPUTS: active_epochs_decoder_result_dict\n",
    "\n",
    "parent_output_folder.mkdir(exist_ok=True)\n",
    "Assert.path_exists(parent_output_folder)\n",
    "posterior_out_folder = parent_output_folder.joinpath(DAY_DATE_TO_USE).resolve()\n",
    "posterior_out_folder.mkdir(parents=True, exist_ok=True)\n",
    "save_path = posterior_out_folder.resolve()\n",
    "_parent_save_context: IdentifyingContext = curr_active_pipeline.build_display_context_for_session('perform_export_all_decoded_posteriors_as_images')\n",
    "_specific_session_output_folder = save_path.joinpath(active_context.get_description(subset_excludelist=['format_name'])).resolve()\n",
    "_specific_session_output_folder.mkdir(parents=True, exist_ok=True)\n",
    "print(f'\\tspecific_session_output_folder: \"{_specific_session_output_folder}\"')\n",
    "\n",
    "custom_export_formats: Dict[str, HeatmapExportConfig] = {\n",
    "\t# 'raw_rgba': HeatmapExportConfig.init_for_export_kind(export_kind=HeatmapExportKind.RAW_RGBA, lower_bound_alpha=0.1, drop_below_threshold=1e-2, desired_height=1200),\n",
    "\t'raw_rgba': HeatmapExportConfig.init_for_export_kind(export_kind=HeatmapExportKind.RAW_RGBA, \n",
    "                                                        raw_RGBA_only_parameters = dict(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), xbin=deepcopy(a_decoder.xbin), lower_bound_alpha=0.1, drop_below_threshold=1e-2, t_bin_size=0.025,  use_four_decoders_version=False),\n",
    "                                                        desired_height=1200),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\t# 'raw_rgba_four_decoders': HeatmapExportConfig.init_for_export_kind(export_kind=HeatmapExportKind.RAW_RGBA, \n",
    "    #                                                     raw_RGBA_only_parameters = dict(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), xbin=deepcopy(a_decoder.xbin), lower_bound_alpha=0.1, drop_below_threshold=1e-2, t_bin_size=0.025,  use_four_decoders_version=True),\n",
    "    #                                                     desired_height=1200),\n",
    "\n",
    "}\n",
    "# custom_export_formats = None\n",
    "\n",
    "out_paths, out_custom_formats_dict = PosteriorExporting.perform_export_all_decoded_posteriors_as_images(decoder_laps_filter_epochs_decoder_result_dict=decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict=decoder_ripple_filter_epochs_decoder_result_dict,\n",
    "# out_paths, out_custom_formats_dict = PosteriorExporting.perform_export_all_decoded_posteriors_as_images(decoder_laps_filter_epochs_decoder_result_dict=deepcopy(decoder_laps_filter_epochs_decoder_result_dict), decoder_ripple_filter_epochs_decoder_result_dict=None,\n",
    "                                                                                                            _save_context=_parent_save_context, parent_output_folder=_specific_session_output_folder,\n",
    "                                                                                                            desired_height=1200, custom_export_formats=custom_export_formats, combined_img_padding=6, combined_img_separator_color=(0, 0, 0, 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cde5cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_uri_from_path(_specific_session_output_folder)\n",
    "fullwidth_path_widget(a_path=_specific_session_output_folder, file_name_label=\"epoch_specific_folder:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a74abe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v_dict in out_paths.items():\n",
    "    for a_decoder_name, a_path in v_dict.items():\n",
    "        file_uri_from_path(a_path)\n",
    "        fullwidth_path_widget(a_path=a_path, file_name_label=f\"{k}[{a_decoder_name}]:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceec6d6",
   "metadata": {},
   "source": [
    "## 2025-05-19 - Re-loading the exported images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48521d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "from neuropy.utils.result_context import DisplaySpecifyingIdentifyingContext\n",
    "from pyphocorehelpers.assertion_helpers import Assert\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorPlottingDatasource, LoadedPosteriorContainer\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import H5FileAggregator\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "from neuropy.utils.result_context import DisplaySpecifyingIdentifyingContext\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import LoadedPosteriorContainer\n",
    "from neuropy.utils.indexing_helpers import flatten, flatten_dict\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionIdentityDataframeAccessor\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.computer_vision import ComputerVisionComputations\n",
    "\n",
    "# Visualization ______________________________________________________________________________________________________ #\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow, LayoutScrollability\n",
    "from pyphocorehelpers.plotting.media_output_helpers import vertical_image_stack, horizontal_image_stack, image_grid # used in `_subfn_build_combined_output_images`\n",
    "from pyphocorehelpers.image_helpers import ImageHelpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ab168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Using pathlib (more modern approach)\n",
    "\n",
    "# Example usage:\n",
    "a_path = flat_img_out_paths[0].joinpath('raw_rgba').resolve()\n",
    "Assert.path_exists(a_path)\n",
    "print(f'a_path: {a_path}')\n",
    "# parent_output_folder = Path('output/array_to_images').resolve()\n",
    "images_dict = ImageHelpers.load_png_images_pathlib(a_path)\n",
    "\n",
    "# Print the loaded images\n",
    "print(f\"Loaded {len(images_dict)} PNG images:\")\n",
    "# for name, img in images_dict.items():\n",
    "#     print(f\"{name}: {img.format}, {img.size}, {img.mode}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22664bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "\n",
    "# specific_epochs_posterior_out_folder = Path('outputs/arr_as_image').resolve()\n",
    "# Assert.path_exists(specific_epochs_posterior_out_folder)\n",
    "\n",
    "_single_epoch_combined_img = horizontal_image_stack(list(images_dict.values()), padding=4, separator_color='white')\n",
    "_single_epoch_combined_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17f3a95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83e1970",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "try:\n",
    "    for custom_export_format_series_name in list(out_custom_export_formats_results_dict[list(out_custom_export_formats_results_dict.keys())[0]].keys()):\n",
    "        _output_combined_dir, _output_combined_image_save_dirs = PosteriorExporting._subfn_build_combined_output_images(single_known_epoch_type_dict=out_custom_export_formats_results_dict, specific_epochs_posterior_out_folder=specific_epochs_posterior_out_folder,\n",
    "                                                                                                    known_epoch_type_name=epochs_name, custom_export_format_series_name=custom_export_format_series_name,\n",
    "                                                                                                    combined_img_padding=4, combined_img_separator_color=None)\n",
    "        \n",
    "except (AssertionError, ValueError) as e:\n",
    "    print(f'WARN: failed to merge images to combined images at the end with error: {e}')\n",
    "except Exception as e:\n",
    "    print(f'WARN: failed to merge images to combined images at the end with error: {e}')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948252f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v_dict in out_paths.items():\n",
    "    for a_decoder_name, a_path in v_dict.items():\n",
    "        file_uri_from_path(a_path)\n",
    "        fullwidth_path_widget(a_path=a_path, file_name_label=f\"{k}[{a_decoder_name}]:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0944bb",
   "metadata": {},
   "source": [
    "## 2025-05-19 - Heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc020b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring, HeuristicsResult\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import SerializationHelper_AllCustomDecodingResults, SerializationHelper_CustomDecodingResults\n",
    "from numpy import ma\n",
    "from neuropy.core.epoch import ensure_dataframe\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "\n",
    "## INPUTS: track_templates, a_decoded_filter_epochs_decoder_result_dict\n",
    "decoder_track_length_dict = track_templates.get_track_length_dict() # {'long_LR': 214.0, 'long_RL': 214.0, 'short_LR': 144.0, 'short_RL': 144.0}\n",
    "same_thresh_fraction_of_track: float = 0.05 ## up to 5.0% of the track\n",
    "same_thresh_cm: float = {k:(v * same_thresh_fraction_of_track) for k, v in decoder_track_length_dict.items()}\n",
    "a_same_thresh_cm: float = same_thresh_cm['long_LR']\n",
    "max_jump_distance_cm: float = 60.0\n",
    "print(f'a_same_thresh_cm: {a_same_thresh_cm}')\n",
    "print(f'max_jump_distance_cm: {max_jump_distance_cm}')\n",
    "# print(list(HeuristicReplayScoring.build_all_score_computations_fn_dict().keys())) # ['jump', 'max_jump_cm', 'max_jump_cm_per_sec', 'ratio_jump_valid_bins', 'travel', 'coverage', 'sequential_correlation', 'monotonicity_score', 'laplacian_smoothness']\n",
    "\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps'] # DirectionalLapsResult\n",
    "# a_name: str = 'long_LR'\n",
    "# a_directional_decoders_epochs_decode_result: DecodedFilterEpochsResult = a_decoded_filter_epochs_decoder_result_dict[a_name]\n",
    "\n",
    "## INPUTS: curr_active_pipeline, track_templates, a_decoded_filter_epochs_decoder_result_dict\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = deepcopy(curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']) ## GENERAL\n",
    "a_decoded_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "a_decoded_filter_epochs_decoder_result_dict, _out_new_scores, partition_result_dict = HeuristicReplayScoring.compute_all_heuristic_scores(track_templates=track_templates, a_decoded_filter_epochs_decoder_result_dict=a_decoded_filter_epochs_decoder_result_dict,\n",
    "                                                                                                                                            max_ignore_bins=2, same_thresh_cm=a_same_thresh_cm, max_jump_distance_cm=max_jump_distance_cm)\n",
    "# # a_decoded_filter_epochs_decoder_result_dict\n",
    "a_heuristics_result = HeuristicsResult(heuristic_scores_df_dict=_out_new_scores, partition_result_dict=partition_result_dict)\n",
    "\n",
    "directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict = deepcopy(a_decoded_filter_epochs_decoder_result_dict)\n",
    "# directional_decoders_epochs_decode_result.build_complete_all_scores_merged_df\n",
    "curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations'] = directional_decoders_epochs_decode_result ## MIGHT NEED SAVING\n",
    "print(f'PIPELINE MIGHT NEED SAVING')\n",
    "## INPUTS: curr_active_pipeline, track_templates, a_decoded_filter_epochs_decoder_result_dict\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = deepcopy(curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']) ## GENERAL\n",
    "## INPUTS: directional_decoders_epochs_decode_result, filtered_epochs_df\n",
    "\n",
    "decoder_ripple_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "unfiltered_epochs_df = deepcopy(decoder_ripple_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a0c9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "unfiltered_epochs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb89ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_epochs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed89365",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _plot_heuristic_evaluation_epochs\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_filter_replay_epochs\n",
    "\n",
    "# force_refilter = False\n",
    "force_refilter = True\n",
    "\n",
    "needs_refilter = False\n",
    "try:\n",
    "    filtered_decoder_filter_epochs_decoder_result_dict\n",
    "    filtered_epochs_df\n",
    "    filtered_ripple_all_epoch_bins_marginals_df\n",
    "    if filtered_decoder_filter_epochs_decoder_result_dict is not None:\n",
    "        needs_refilter = False\n",
    "except NameError:\n",
    "    needs_refilter = True\n",
    "    \n",
    "if needs_refilter or force_refilter:\n",
    "    filtered_epochs_df, filtered_decoder_filter_epochs_decoder_result_dict, filtered_ripple_all_epoch_bins_marginals_df = _perform_filter_replay_epochs(curr_active_pipeline, global_epoch_name, track_templates, decoder_ripple_filter_epochs_decoder_result_dict, ripple_all_epoch_bins_marginals_df, ripple_decoding_time_bin_size=ripple_decoding_time_bin_size, should_only_include_user_selected_epochs=True)\n",
    "\n",
    "## INPUTS: `filtered_epochs_df`\n",
    "if filtered_epochs_df is not None:\n",
    "    ## filter\n",
    "    filtered_decoder_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(filtered_epochs_df[['start', 'stop']].to_numpy()) for a_name, a_result in decoder_ripple_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "    high_heuristic_only_filtered_decoder_filter_epochs_decoder_result_dict = deepcopy(filtered_decoder_filter_epochs_decoder_result_dict)\n",
    "else:\n",
    "    filtered_decoder_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(unfiltered_epochs_df[['start', 'stop']].to_numpy()) for a_name, a_result in decoder_ripple_filter_epochs_decoder_result_dict.items()} # working unfiltered\n",
    "\n",
    "ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "print(f'{pos_bin_size = }, {ripple_decoding_time_bin_size = }')\n",
    "\n",
    "## OUTPUT: filtered_decoder_filter_epochs_decoder_result_dict, \n",
    "\n",
    "## 3m 2.2s\n",
    "# 59.1s\n",
    "\n",
    "# same_thresh_cm\n",
    "# a_result: DecodedFilterEpochsResult, an_epoch_idx: int, a_decoder_track_length: float, pos_bin_edges: NDArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fc5774",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_decoder_filter_epochs_decoder_result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c3f4fa",
   "metadata": {},
   "source": [
    "## <a id='toc11_2_'></a>[Find indicies that are included in `high_heuristic_only_filtered_decoder_filter_epochs_decoder_result_dict` from `filtered_decoder_filter_epochs_decoder_result_dict`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e894afe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: high_heuristic_only_filtered_decoder_filter_epochs_decoder_result_dict, filtered_decoder_filter_epochs_decoder_result_dict\n",
    "# INPUTS: included_heuristic_ripple_start_times, high_heuristic_only_filtered_decoder_filter_epochs_decoder_result_dict, excluded_heuristic_ripple_start_times, low_heuristic_only_filtered_decoder_filter_epochs_decoder_result_dict\n",
    "\n",
    "example_decoder_name = 'long_LR'\n",
    "all_epoch_result: DecodedFilterEpochsResult = deepcopy(filtered_decoder_filter_epochs_decoder_result_dict[example_decoder_name])\n",
    "all_filter_epochs_df: pd.DataFrame = deepcopy(all_epoch_result.filter_epochs)\n",
    "\n",
    "included_filter_epoch_result: DecodedFilterEpochsResult = deepcopy(high_heuristic_only_filtered_decoder_filter_epochs_decoder_result_dict[example_decoder_name])\n",
    "# included_filter_epoch_result: DecodedFilterEpochsResult = deepcopy(low_heuristic_only_filtered_decoder_filter_epochs_decoder_result_dict[example_decoder_name])\n",
    "\n",
    "included_filter_epochs_df: pd.DataFrame = deepcopy(included_filter_epoch_result.filter_epochs)\n",
    "included_filter_epochs_df\n",
    "\n",
    "# included_filter_epoch_times = included_filter_epochs_df[['start', 'stop']].to_numpy() # Both 'start', 'stop' column matching\n",
    "included_filter_epoch_times = included_filter_epochs_df['start'].to_numpy() # Both 'start', 'stop' column matching\n",
    "\n",
    "included_filter_epoch_times_to_all_epoch_index_map = included_filter_epoch_result.find_epoch_times_to_data_indicies_map(epoch_times=included_filter_epoch_times)\n",
    "included_filter_epoch_times_to_all_epoch_index_arr: NDArray = included_filter_epoch_result.find_data_indicies_from_epoch_times(epoch_times=included_filter_epoch_times)\n",
    "len(included_filter_epoch_times_to_all_epoch_index_arr)\n",
    "\n",
    "## OUTPUTS: all_filter_epochs_df, all_filter_epochs_df\n",
    "## OUTPUTS: included_filter_epoch_times_to_all_epoch_index_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f31556",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a12dd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = dict()\n",
    "\n",
    "included_filter_epochs_df: pd.DataFrame = deepcopy(high_heuristic_only_filtered_decoder_filter_epochs_decoder_result_dict[example_decoder_name].filter_epochs)\n",
    "included_filter_epochs_df\n",
    "_out['trackID_weighted_position_posterior'] = curr_active_pipeline.display(display_function='_display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay', active_session_configuration_context=None, time_bin_size=0.025,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t    filter_epochs_ripple_df=deepcopy(included_filter_epochs_df),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t) # _display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72824473",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out['trackID_weighted_position_posterior']['out_paths']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b4dfb5",
   "metadata": {},
   "source": [
    "## <a id='toc11_3_'></a>[Add the high-heuristic PBEs as an interval-rect dataseries to the continuous viewer](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b130769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: included_filter_epochs_df\n",
    "\n",
    "## Extract the specific results:\n",
    "# included_filter_epochs_df\n",
    "\n",
    "\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.Specific2DRenderTimeEpochs import General2DRenderTimeEpochs, inline_mkColor\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import Spike2DRaster\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.EpochRenderingMixin import EpochRenderingMixin, RenderedEpochsItemsContainer\n",
    "from pyphoplacecellanalysis.General.Model.Datasources.IntervalDatasource import IntervalsDatasource\n",
    "from neuropy.utils.mixins.time_slicing import TimeColumnAliasesProtocol\n",
    "\n",
    "## INTPUTS: bottom_y_min\n",
    "bottom_y_min, top_y_max = active_2d_plot.get_interval_y_extrema_locations()\n",
    "bottom_y_min, top_y_max\n",
    "interval_height: float = 0.9\n",
    "\n",
    "## Use the three dataframes as separate Epoch series:\n",
    "updated_epochs_dfs_dict = {\n",
    "    'HighHeuristic': included_filter_epochs_df,\n",
    "}\n",
    "\n",
    "updated_epochs_formatting_dict = {\n",
    "    # 'HighHeuristic':dict(y_location=-10.0, height=7.5, pen_color=inline_mkColor('green', 0.8), brush_color=inline_mkColor('green', 0.5)),\n",
    "        'HighHeuristic':dict(y_location=(bottom_y_min - interval_height), height=interval_height, pen_color=inline_mkColor('green', 0.8), brush_color=inline_mkColor('green', 0.5)),\n",
    "}\n",
    "\n",
    "# required_vertical_offsets, required_interval_heights = EpochRenderingMixin.build_stacked_epoch_layout([1.0], epoch_render_stack_height=40.0, interval_stack_location='below') # ratio of heights to each interval\n",
    "\n",
    "stacked_epoch_layout_dict = active_2d_plot.apply_relative_epoch_layout(rendered_interval_keys_to_adjust='HighHeuristic', desired_interval_heights=0.9, interval_stack_location='below')\n",
    "# stacked_epoch_layout_dict = {interval_key:dict(y_location=y_location, height=height) for interval_key, y_location, height in zip(list(updated_epochs_formatting_dict.keys()), required_vertical_offsets, required_interval_heights)} # Build a stacked_epoch_layout_dict to update the display\n",
    "# stacked_epoch_layout_dict # {'LapsAll': {'y_location': -3.6363636363636367, 'height': 3.6363636363636367}, 'LapsTrain': {'y_location': -21.818181818181817, 'height': 18.18181818181818}, 'LapsTest': {'y_location': -40.0, 'height': 18.18181818181818}}\n",
    "\n",
    "# replaces 'y_location', 'position' for each dict:\n",
    "updated_epochs_formatting_dict = {k:(v|stacked_epoch_layout_dict[k]) for k, v in updated_epochs_formatting_dict.items()}\n",
    "updated_epochs_formatting_dict\n",
    "\n",
    "# OUTPUTS: updated_epochs_dfs_dict, updated_epochs_formatting_dict\n",
    "## INPUTS: updated_epochs_dfs_dict\n",
    "updated_epochs_dfs_dict = {k:TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(df=v, required_columns_synonym_dict=IntervalsDatasource._time_column_name_synonyms) for k, v in updated_epochs_dfs_dict.items()}\n",
    "\n",
    "## Build interval datasources for them:\n",
    "updated_epochs_dfs_datasources_dict = {k:General2DRenderTimeEpochs.build_render_time_epochs_datasource(v) for k, v in updated_epochs_dfs_dict.items()}\n",
    "## INPUTS: active_2d_plot, train_test_split_laps_epochs_formatting_dict, train_test_split_laps_dfs_datasources_dict\n",
    "assert len(updated_epochs_formatting_dict) == len(updated_epochs_dfs_datasources_dict)\n",
    "for k, an_interval_ds in updated_epochs_dfs_datasources_dict.items():\n",
    "    an_interval_ds.update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, **(updated_epochs_formatting_dict[k] | kwargs)))\n",
    "\n",
    "## Full output: updated_epochs_dfs_datasources_dict\n",
    "# actually add the epochs:\n",
    "for k, an_interval_ds in updated_epochs_dfs_datasources_dict.items():\n",
    "    active_2d_plot.add_rendered_intervals(an_interval_ds, name=f'{k}', debug_print=False) # adds the interval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cbdf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_y_min, top_y_max = active_2d_plot.get_interval_y_extrema_locations()\n",
    "bottom_y_min, top_y_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656a01da",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.apply_relative_epoch_layout(rendered_interval_keys_to_adjust='HighHeuristic', desired_interval_heights=0.9, interval_stack_location='below')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70b1bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_series_positioning_dfs, all_series_compressed_positioning_dfs, all_series_compressed_positioning_update_dicts = active_2d_plot.recover_interval_datasources_update_dict_properties()\n",
    "# all_series_positioning_dfs\n",
    "all_series_compressed_positioning_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4253f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_flat_df = []\n",
    "for a_series_name, a_df in all_series_compressed_positioning_dfs.items():\n",
    "\ta_df['series_name'] = a_series_name\n",
    "\ta_df['series_idx'] = deepcopy(a_df.index)\n",
    "\ta_flat_df.append(a_df)\n",
    "\t\n",
    "\n",
    "a_flat_df: pd.DataFrame = pd.concat(a_flat_df, ignore_index=True)\n",
    "a_flat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f972e29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_flat_df['series_y_min'] = deepcopy(a_flat_df['series_vertical_offset'])\n",
    "a_flat_df['series_y_max'] = a_flat_df['series_y_min'] + a_flat_df['series_height']\n",
    "a_flat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eb0dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_y_min: float = a_flat_df['series_y_min'].min()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587d0b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_series_positioning_dfs, all_series_compressed_positioning_dfs, all_series_compressed_positioning_update_dicts = active_2d_plot.recover_interval_datasources_positioning_properties()\n",
    "# all_series_positioning_dfs\n",
    "all_series_compressed_positioning_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5cc920",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_series_positioning_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070d1bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_2d_plot.rendered_epochs\n",
    "curr_x_min, curr_x_max, curr_y_min, curr_y_max = active_2d_plot.get_render_intervals_plot_range()\n",
    "curr_x_min, curr_x_max, curr_y_min, curr_y_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94db2b0f",
   "metadata": {},
   "source": [
    "# TODONO - 2025-06-04 - Paper 2025 Figure Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37e253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.BatchCompletionHandler import BatchSessionCompletionHandler\n",
    "from neuropy.utils.matplotlib_helpers import matplotlib_file_only\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import main_complete_figure_generations\n",
    "\n",
    "\n",
    "# self.try_complete_figure_generation_to_file(curr_active_pipeline, enable_default_neptune_plots=self.should_generate_all_plots)\n",
    "fail_on_exception: bool = False\n",
    "enable_default_neptune_plots = False\n",
    "completed_good: bool = False\n",
    "\n",
    "try:\n",
    "    ## To file only:\n",
    "    with matplotlib_file_only():\n",
    "        # Perform non-interactive Matplotlib operations with 'AGG' backend\n",
    "        # neptuner = batch_perform_all_plots(curr_active_pipeline, enable_neptune=True, neptuner=None)\n",
    "        main_complete_figure_generations(curr_active_pipeline, enable_default_neptune_plots=enable_default_neptune_plots, save_figures_only=True, save_figure=True)\n",
    "\n",
    "    # IF thst's done, clear all the plots:\n",
    "    # from matplotlib import pyplot as plt\n",
    "    # plt.close('all') # this takes care of the matplotlib-backed figures.\n",
    "    curr_active_pipeline.clear_display_outputs()\n",
    "    curr_active_pipeline.clear_registered_output_files()\n",
    "    completed_good = True # completed successfully (without raising an error at least).\n",
    "\n",
    "except Exception as e:\n",
    "    completed_good =  False\n",
    "    raise\n",
    "    # exception_info = sys.exc_info()\n",
    "    # e = CapturedException(e, exception_info)\n",
    "    # print(f'main_complete_figure_generations failed with exception: {e}')\n",
    "    # if fail_on_exception:\n",
    "    #     raise e.exc\n",
    "\n",
    "\n",
    "\n",
    "## OUTPUTS: completed_good\n",
    "print(f'completed_good: {completed_good}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736407dd",
   "metadata": {},
   "source": [
    "# 2025-06-13 - ❌ Heuristic Scores used continuously as replay detection \n",
    "[/c:/Users/pho/repos/Spike3DWorkEnv/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/heuristic_replay_scoring.py:3187](vscode://file/c:/Users/pho/repos/Spike3DWorkEnv/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/heuristic_replay_scoring.py:3187)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ff32be",
   "metadata": {},
   "source": [
    "# 2025-07-08 - ❌ Quantitative LxC/SxC\n",
    "❌ - aborted after Kamran and I discussed and realized that hand-labeled LdC/SdC cells are very subjective and cannot be defined mathematically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d483de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# track_templates.get_decoder_aclu_peak_map_dict(peak_mode='peaks')\n",
    "\n",
    "# track_templates.long_LR_decoder.\n",
    "\n",
    "## Just needs laps\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps).trimmed_to_non_overlapping() \n",
    "global_laps_epochs_df = global_laps.to_dataframe()\n",
    "global_laps_epochs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300212ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# peaks_results_df: pd.DataFrame = track_templates.long_LR_decoder.get_tuning_curve_peak_df(peak_mode='peaks')\n",
    "\n",
    "\n",
    "# peaks_results_df: pd.DataFrame = track_templates.long_LR_decoder.pf.tuning_curves_dict\n",
    "\n",
    "\n",
    "filtered_spikes_df: pd.DataFrame = track_templates.long_LR_decoder.pf.filtered_spikes_df\n",
    "filtered_spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e211b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_counts_dict = {a_decoder_name:deepcopy(a_decoder.pf.filtered_spikes_df['aclu']).value_counts().to_dict() for a_decoder_name, a_decoder in track_templates.get_decoders_dict().items()}\n",
    "any_decoder_aclus_list = deepcopy(track_templates.any_decoder_neuron_IDs)\n",
    "any_decoder_aclus_list ## this somehow loses the short-only cells?!?! Such as [3, 4, 8, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d01cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import PhoJonathanPlotHelpers\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import BatchPhoJonathanFiguresHelper\n",
    "\n",
    "## Get global 'jonathan_firing_rate_analysis' results:\n",
    "curr_jonathan_firing_rate_analysis = curr_active_pipeline.global_computation_results.computed_data['jonathan_firing_rate_analysis']\n",
    "neuron_replay_stats_df, rdf, aclu_to_idx, irdf = curr_jonathan_firing_rate_analysis.neuron_replay_stats_df, curr_jonathan_firing_rate_analysis.rdf.rdf, curr_jonathan_firing_rate_analysis.rdf.aclu_to_idx, curr_jonathan_firing_rate_analysis.irdf.irdf\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Batch Output of Figures                                                                                              #\n",
    "# ==================================================================================================================== #\n",
    "## 🗨️🟢 2022-11-05 - Pho-Jonathan Batch Outputs of Firing Rate Figures\n",
    "short_only_df = neuron_replay_stats_df[neuron_replay_stats_df.track_membership == SplitPartitionMembership.RIGHT_ONLY]\n",
    "short_only_aclus = short_only_df.index.values.tolist()\n",
    "long_only_df = neuron_replay_stats_df[neuron_replay_stats_df.track_membership == SplitPartitionMembership.LEFT_ONLY]\n",
    "long_only_aclus = long_only_df.index.values.tolist()\n",
    "shared_df = neuron_replay_stats_df[neuron_replay_stats_df.track_membership == SplitPartitionMembership.SHARED]\n",
    "shared_aclus = shared_df.index.values.tolist()\n",
    "print(f'shared_aclus: {shared_aclus}')\n",
    "print(f'long_only_aclus: {long_only_aclus}')\n",
    "print(f'short_only_aclus: {short_only_aclus}')\n",
    "\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'    \n",
    "## MODE: this mode creates a special folder to contain the outputs for this session.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c54a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates\n",
    "\n",
    "decoders_total_num_spikes_df, (LxC_cells_df, SxC_cells_df) = TrackTemplates.perform_determine_quant_cell_eXclusivities(track_templates=track_templates)\n",
    "# decoders_total_num_spikes_df['aclu'] = decoders_total_num_spikes_df.index\n",
    "decoders_total_num_spikes_df: pd.DataFrame = deepcopy(decoders_total_num_spikes_df)\n",
    "# decoders_total_num_spikes_df = decoders_total_num_spikes_df.neuron_identity.make_neuron_indexed_df_global(curr_active_pipeline.get_session_context(), add_expanded_session_context_keys=False, add_extended_aclu_identity_columns=True)\n",
    "# decoders_total_num_spikes_df\n",
    "# LxC_cells_df, SxC_cells_df\n",
    "\n",
    "# print(decoders_total_num_spikes_df.columns.to_list()) # ['long_LR_n_spikes', 'long_RL_n_spikes', 'short_LR_n_spikes', 'short_RL_n_spikes', 'long_n_spikes', 'short_n_spikes', 'total_n_spikes', 'pct_long_n_spikes', 'pct_short_n_spikes', 'is_n_spikes_LxC', 'is_n_spikes_SxC']\n",
    "# ['long_LR_lap_dur', 'long_RL_lap_dur', 'short_LR_lap_dur', 'short_RL_lap_dur', 'long_lap_dur', 'short_lap_dur', 'total_lap_dur', 'long_fr_Hz', 'short_fr_Hz', 'total_fr_Hz', 'pct_long_fr_Hz', 'pct_short_fr_Hz', 'is_fr_Hz_LxC', 'is_fr_Hz_SxC']\n",
    "decoders_total_num_spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b229cc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoders_total_num_spikes_df[decoders_total_num_spikes_df['is_fr_Hz_LxC']]\n",
    "decoders_total_num_spikes_df[decoders_total_num_spikes_df['is_fr_Hz_SxC']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad25c9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_templates.long_LR_decoder.pf.epochs\n",
    "\n",
    "total_duration_dict = {k:deepcopy(v.pf.epochs.duration).sum() for k, v in track_templates.get_decoders_dict().items()}\n",
    "total_duration_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab36cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03f08bdd",
   "metadata": {},
   "source": [
    "# 2025-07-09 - Computation Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10755e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout, _master_params_dict = curr_active_pipeline.get_all_parameters(allow_update_global_computation_config=False, get_panel_gui_widget=True)\n",
    "layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60ee562",
   "metadata": {},
   "outputs": [],
   "source": [
    "_master_params_dict['preprocessing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b725c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.parameters import ParametersContainer\n",
    "\n",
    "# After user makes changes, get updated values:\n",
    "current_params = deepcopy(curr_active_pipeline.global_computation_results.computation_config.to_dict())\n",
    "current_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f9fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import ast\n",
    "\n",
    "# Create widgets\n",
    "minimum_fr_widget = widgets.IntText(\n",
    "    value=2,\n",
    "    description='Min FR (Hz):',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='200px')\n",
    ")\n",
    "\n",
    "qclu_text_widget = widgets.Text(\n",
    "    value='[1, 2, 4, 6, 7, 8, 9]',\n",
    "    description='QClu Values:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='300px')\n",
    ")\n",
    "\n",
    "# Button to get values\n",
    "get_values_button = widgets.Button(\n",
    "    description='Get Current Values',\n",
    "    button_style='info'\n",
    ")\n",
    "\n",
    "# Output area\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_button_click(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        \n",
    "        # Parse the qclu values from text\n",
    "        try:\n",
    "            qclu_values = ast.literal_eval(qclu_text_widget.value)\n",
    "            if not isinstance(qclu_values, list):\n",
    "                qclu_values = [qclu_values]\n",
    "        except:\n",
    "            print(\"Error: Invalid format for QClu Values. Please use format: [1, 2, 3, ...]\")\n",
    "            return\n",
    "            \n",
    "        values = {\n",
    "            'minimum_inclusion_fr_Hz': minimum_fr_widget.value,\n",
    "            'included_qclu_values': qclu_values\n",
    "        }\n",
    "        print(\"Selected values:\", values)\n",
    "\n",
    "get_values_button.on_click(on_button_click)\n",
    "\n",
    "# Display interface\n",
    "interface = widgets.VBox([\n",
    "    minimum_fr_widget,\n",
    "    qclu_text_widget,\n",
    "    get_values_button,\n",
    "    output\n",
    "])\n",
    "\n",
    "display(interface)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c586ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preprocessing_parameters: ParametersContainer = deepcopy(curr_active_pipeline.active_sess_config)\n",
    "preprocessing_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fdeaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\t\t\t\t\t\t\t\t\t\n",
    "# long_pf1D.config # {'speed_thresh': 10.0, 'grid_bin': (4.877453969028168, 14.388489208633093), 'grid_bin_bounds': ((0.0, 287.7697841726619), (86.33093525179856, 201.4388489208633)), 'smooth': (2.0, 2.0), 'frate_thresh': 1.0, 'is_directional': False}\n",
    "track_templates.long_LR_decoder.pf.config # {'speed_thresh': 10.0, 'grid_bin': (4.877453969028168, 14.388489208633093), 'grid_bin_bounds': ((0.0, 287.7697841726619), (86.33093525179856, 201.4388489208633)), 'smooth': (2.0, 2.0), 'frate_thresh': 1.0, 'is_directional': False}\n",
    "\n",
    "{'speed_thresh': 10.0, 'grid_bin': (4.877453969028168, 14.388489208633093), 'grid_bin_bounds': ((0.0, 287.7697841726619), (86.33093525179856, 201.4388489208633)), 'smooth': (2.0, 2.0), 'frate_thresh': 1.0, 'is_directional': False} ## Kamran used 1.44cm^2 Pseudo2D bins\n",
    "\n",
    "\n",
    "long_pf2D.config\n",
    "# [/c:/Users/pho/repos/Spike3DWorkEnv/NeuroPy/neuropy/core/session/Formats/BaseDataSessionFormats.py:279](vscode://file/c:/Users/pho/repos/Spike3DWorkEnv/NeuroPy/neuropy/core/session/Formats/BaseDataSessionFormats.py:279)\n",
    "# ```python\n",
    "# # From `core.session.Formats.BaseDataSessionFormats.build_default_computation_configs`\n",
    "# 'speed_thresh': 10.0, 'grid_bin': cls.compute_position_grid_bin_size(sess.position.x, sess.position.y, num_bins=(64, 64)), 'grid_bin_bounds': None, 'smooth': (2.0, 2.0), 'frate_thresh': 1.0, 'time_bin_size': 0.1, \n",
    "# ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2738436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import FigureOutputLocation, ContextToPathMode, FileOutputManager\n",
    "\n",
    "out_man: FileOutputManager = curr_active_pipeline.get_output_manager(figure_output_location=FigureOutputLocation.CUSTOM, context_to_path_mode=ContextToPathMode.GLOBAL_UNIQUE, override_output_parent_path=collected_outputs_path)\n",
    "\n",
    "\n",
    "# FileOutputManager(figure_output_location=figure_output_location, context_to_path_mode=context_to_path_mode, override_output_parent_path=override_output_parent_path)\n",
    "\n",
    "out_man"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae20f40d",
   "metadata": {},
   "source": [
    "# 2025-08-05 - SpareRunningSequenceScore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6a07b8",
   "metadata": {},
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import SpareRunningSequenceScore\n",
    "\n",
    "out_decoder_spare_scores, out_decoder_spare_scores_extras = SpareRunningSequenceScore.bowling_spare_integration(p_x_given_n=p_x_given_n)\n",
    "out_decoder_spare_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abdd6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import SpareRunningSequenceScore\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _helper_add_interpolated_position_columns_to_decoded_result_df\n",
    "\n",
    "## Run heuristic continuously to determine when to split sequences and thus where replays are\n",
    "\n",
    "valid_EpochComputations_result: EpochComputationsComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['EpochComputations']\n",
    "a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult = valid_EpochComputations_result.a_generic_decoder_dict_decoded_epochs_dict_result\n",
    "\n",
    "## INPUTS: a_new_fully_generic_result\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='nan_filled', data_grain='per_time_bin')\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='ignore', data_grain='per_time_bin')\n",
    "best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=a_target_context, debug_print=False)\n",
    "## OUTPUTS: a_result, a_decoder, a_decoded_marginal_posterior_df\n",
    "## INPUTS: curr_active_pipeline, a_result, a_decoder, a_decoded_marginal_posterior_df\n",
    "global_measured_position_df: pd.DataFrame = deepcopy(curr_active_pipeline.sess.position.to_dataframe())\n",
    "a_decoded_marginal_posterior_df: pd.DataFrame = _helper_add_interpolated_position_columns_to_decoded_result_df(a_result=a_result, a_decoder=a_decoder, a_decoded_marginal_posterior_df=a_decoded_marginal_posterior_df, global_measured_position_df=global_measured_position_df)\n",
    "\n",
    "global_decoded_result: SingleEpochDecodedResult = a_result.get_result_for_epoch(0)\n",
    "p_x_given_n: NDArray[ND.Shape[\"N_POS_BINS, 4, N_TIME_BINS\"], np.floating] = deepcopy(global_decoded_result.p_x_given_n) # .shape # (59, 4, 69488)\n",
    "time_bin_centers: NDArray[ND.Shape[\"N_TIME_BINS\"], np.floating] = deepcopy(global_decoded_result.time_bin_container.centers)\n",
    "time_bin_left_edges: NDArray[ND.Shape[\"N_TIME_BINS\"], np.floating] = deepcopy(global_decoded_result.time_bin_container.left_edges)\n",
    "time_bin_right_edges: NDArray[ND.Shape[\"N_TIME_BINS\"], np.floating] = deepcopy(global_decoded_result.time_bin_container.right_edges)\n",
    "time_bin_start_stops: NDArray[ND.Shape[\"N_TIME_BINS, 2\"], np.floating] = np.vstack((time_bin_left_edges, time_bin_right_edges)).T\n",
    "xbin: NDArray[ND.Shape[\"N_POS_BINS\"], np.floating] = deepcopy(a_decoder.xbin)\n",
    "\n",
    "## INPUTS: p_x_given_n\n",
    "out_decoder_spare_scores, out_decoder_spare_scores_extras = SpareRunningSequenceScore.bowling_spare_integration(p_x_given_n=p_x_given_n)\n",
    "# out_decoder_spare_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cec5eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_decoder_spare_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2678bfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoder_name: str = 'Long_LR'\n",
    "a_decoder_spare_scores = out_decoder_spare_scores[a_decoder_name] #['segement_lengths']\n",
    "a_decoder_spare_scores_extras = out_decoder_spare_scores_extras[a_decoder_name] #['segement_lengths']\n",
    "# a_decoder_spare_scores, a_decoder_spare_scores_extras\n",
    "\n",
    "a_segement_lengths = a_decoder_spare_scores_extras['segement_lengths']\n",
    "a_sign_change_indicies = a_decoder_spare_scores_extras['sign_change_indicies']\n",
    "# a_decoder_spare_scores\n",
    "\n",
    "a_time_bin_start_stops_segments = np.split(time_bin_start_stops, a_sign_change_indicies) ## split up the times by the split indicies to find the (start, stop) time for each segment period\n",
    "# a_time_bin_start_stops_segments\n",
    "\n",
    "## Get segment start/end times\n",
    "a_segment_start_stops = np.array([(v[0,0], v[-1,-1]) for v in a_time_bin_start_stops_segments]) # segement (start_t, end_t)\n",
    "a_segment_start_stops\n",
    "\n",
    "# time_bin_left_edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1be2c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a complete score dataframe from each segment start/stop times and the spare scores for each decoder:\n",
    "seg_df: pd.DataFrame = pd.DataFrame(time_bin_start_stops, columns=['t_start', 't_end'])\n",
    "for a_decoder_name, a_decoder_spare_scores in out_decoder_spare_scores.items():\n",
    "    a_decoder_spare_scores_extras = out_decoder_spare_scores_extras[a_decoder_name] ## get extras\n",
    "    seg_df[f\"{a_decoder_name}_spare_score\"] =  np.concatenate(a_decoder_spare_scores) # np.concatenate(a_decoder_spare_scores)}) # for each decoder, add the spare score\n",
    "    a_segement_lengths = a_decoder_spare_scores_extras['segement_lengths']\n",
    "    a_sign_change_indicies = a_decoder_spare_scores_extras['sign_change_indicies']\n",
    "    seg_df[f\"{a_decoder_name}_seg_IDX\"] = np.concatenate([np.repeat(seg_i, a_len) for seg_i, a_len in enumerate(a_segement_lengths)])\n",
    "    seg_df[f\"{a_decoder_name}_segment_length\"] = np.concatenate([np.repeat(a_len, a_len) for seg_i, a_len in enumerate(a_segement_lengths)])\n",
    "# seg_df.update({f\"{a_decoder_name}_spare_score\":np.concatenate(a_decoder_spare_scores) for a_decoder_name, a_decoder_spare_scores in out_decoder_spare_scores.items()},)\n",
    "seg_df\n",
    "\n",
    "## OUTPUTS: seg_df\n",
    "seg_df.columns.to_list() # ['t_start', 't_end', 'Long_LR_spare_score', 'Long_RL_spare_score', 'Short_LR_spare_score', 'Short_RL_spare_score']\n",
    "# [, 'Long_LR_seg_IDX', 'Long_LR_segment_length', 'Long_RL_seg_IDX', 'Long_RL_segment_length' 'Short_LR_seg_IDX', 'Short_LR_segment_length', 'Short_RL_seg_IDX', 'Short_RL_segment_length'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249410fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.PyqtgraphTimeSynchronizedWidget import PyqtgraphTimeSynchronizedWidget\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.MatplotlibTimeSynchronizedWidget import MatplotlibTimeSynchronizedWidget  \n",
    "\n",
    "# 'MenuCommand_display_plot_marginal_1D_most_likely_position_comparisons'\n",
    "identifier='MenuCommand_display_plot_marginal_1D_most_likely_position_comparisons'\n",
    "active_2d_plot: Spike2DRaster = active_2d_plot  \n",
    "a_dock = active_2d_plot.find_display_dock(identifier=identifier)  \n",
    "widget: MatplotlibTimeSynchronizedWidget  = a_dock.widgets[0]  \n",
    "## plot on axes:\n",
    "widget.ax.clear()  # clear the axes before plotting new data\n",
    "\n",
    "## INPUTS: seg_df\n",
    "seg_df.plot(x='t_start', y='Long_LR_spare_score', ax=widget.ax, label='Long LR Spare Score', color='blue')\n",
    "seg_df.plot(x='t_start', y='Long_RL_spare_score', ax=widget.ax, label='Long RL Spare Score', color='orange')\n",
    "seg_df.plot(x='t_start', y='Short_LR_spare_score', ax=widget.ax, label='Short LR Spare Score', color='green')\n",
    "seg_df.plot(x='t_start', y='Short_RL_spare_score', ax=widget.ax, label='Short RL Spare Score', color='red')\n",
    "\n",
    "widget.update()\n",
    "# widget.getRootPlotItem().setXRange(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time, padding=0) ## global frame  \n",
    "active_2d_plot.sync_matplotlib_render_plot_widget(identifier=identifier)  # sync the plot with the widget\n",
    "# widget.update(None) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2858a305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_decoder_spare_scores_extras['Long_LR'] #['segement_lengths']\n",
    "\n",
    "## Find sequences longer than fixed threshold\n",
    "sequence_length_threshold: int = 4\n",
    "\n",
    "is_segment_high_score = (a_segement_lengths >= sequence_length_threshold)\n",
    "# is_segment_high_score\n",
    "\n",
    "## INPUTS: a_time_bin_start_stops_segments\n",
    "assert len(is_segment_high_score) == len(a_time_bin_start_stops_segments), f\"len(is_segment_high_score): {len(is_segment_high_score)} does not equal len(a_time_bin_start_stops_segments): {a_time_bin_start_stops_segments}\"\n",
    "a_time_bin_start_stops_segments_high_score = [v for i, v in enumerate(a_time_bin_start_stops_segments) if is_segment_high_score[i]]\n",
    "a_segment_start_stops_high_score = [v for i, v in enumerate(a_segment_start_stops) if is_segment_high_score[i]]\n",
    "\n",
    "seg_df: pd.DataFrame = pd.DataFrame(a_segment_start_stops_high_score, columns=['t_start', 't_end'])\n",
    "seg_df\n",
    "\n",
    "# a_time_bin_start_stops_segments_high_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13648b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spare_seq_dfs_datasources_dict, spare_seq_dfs_dict = SpareRunningSequenceScore.add_spikeRaster2D_interval_rects(active_2d_plot, seg_df=seg_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2392143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_runs, (valid, counts), (P_diff, is_excessive_change_index, series_idx) = ContinuousHeuristicScoring.find_longest_run_of_non_excessive_diffs(active_most_likely_pos=active_most_likely_pos, time_window_centers=time_window_centers, max_jump_distance_cm=max_jump_distance_cm, max_ignore_bins=0,\n",
    "#                                                                                                                                                 # min_prefix_merge_seq_n_bins=20, min_suffix_merge_seq_n_bins=20,\n",
    "#                                                                                                                                                 min_prefix_merge_seq_n_bins=200, min_suffix_merge_seq_n_bins=200,\n",
    "#                                                                                                                                                 )\n",
    "\n",
    "# # records.append({\n",
    "# #     \"run_id\":       int(rid),\n",
    "# #     \"run_length\":   int(counts[rid]),    # number of diffs\n",
    "# #     \"pos_start\":    int(pos_start),\n",
    "# #     \"pos_end\":      int(pos_end),\n",
    "# #     't_start': float(time_window_centers[pos_start]),\n",
    "# #     't_end': float(time_window_centers[pos_end]),\n",
    "# #     \"positions\":    list(seg)            # store as list\n",
    "# # })\n",
    "\n",
    "# cont_heuristics_dfs_datasources_dict, cont_heuristics_dfs_dict = ContinuousHeuristicScoring.add_spikeRaster2D_interval_rects(active_2d_plot, df_runs=df_runs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b3ac5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a92df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "each_decoder_stack = np.vstack([v for k, v in out_decoder_spare_scores_extras.items()])\n",
    "\n",
    "\n",
    "# out_decoder_spare_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792347c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Plot histogram to find the thresholds we want to use to detect sequences\n",
    "for k, v in out_decoder_spare_scores_extras.items():\n",
    "    plt.hist(v['segement_lengths'], bins=30, edgecolor='black', alpha=0.5)\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d81681a",
   "metadata": {},
   "source": [
    "# 2025-08-26 - Lap Ground Truth Performance assessment to disqualify poor context decoding sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ce2f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import determine_percent_correctly_decoded_contexts\n",
    "\n",
    "## find the number of correctly decoded components:\n",
    "records_df: pd.DataFrame = determine_percent_correctly_decoded_contexts(curr_active_pipeline, time_bin_size=time_bin_size)\n",
    "records_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0628c862",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import LapDecodingGroundTruth\n",
    "# PhoJonathan Results:\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "jonathan_firing_rate_analysis_result = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis\n",
    "neuron_replay_stats_df, short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset = jonathan_firing_rate_analysis_result.get_cell_track_partitions(frs_index_inclusion_magnitude=0.2)\n",
    "\n",
    "# desired_laps_decoding_time_bin_size: float = 1.0\n",
    "desired_laps_decoding_time_bin_size: float = 0.6\n",
    "# included_neuron_ids_list = [short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset]\n",
    "included_neuron_ids_list = [None]\n",
    "\n",
    "_output_tuples_list = LapDecodingGroundTruth.perform_sweep_lap_groud_truth_performance_testing(curr_active_pipeline,\n",
    "                                                                        included_neuron_ids_list=included_neuron_ids_list,\n",
    "                                                                        desired_laps_decoding_time_bin_size=desired_laps_decoding_time_bin_size)\n",
    "\n",
    "percent_laps_correctness_df: pd.DataFrame = pd.DataFrame.from_records([complete_decoded_context_correctness_tuple.percent_correct_tuple for (a_directional_merged_decoders_result, result_laps_epochs_df, complete_decoded_context_correctness_tuple) in _output_tuples_list],\n",
    "                        columns=(\"track_ID_correct\", \"dir_correct\", \"complete_correct\"))\n",
    "percent_laps_correctness_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc0bbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(a_directional_merged_decoders_result, result_laps_epochs_df, complete_decoded_context_correctness_tuple) = _output_tuples_list[0]\n",
    "# result_laps_epochs_df\n",
    "# a_directional_merged_decoders_result.laps_track_identity_marginals_tuple\n",
    "# a_directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result.marginal_x_list\n",
    "# a_directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result.perform_compute_marginals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18340a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_new_fully_generic_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cf6ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import ensure_dataframe\n",
    "\n",
    "## INPUTS: directional_merged_decoders_result, curr_active_pipeline\n",
    "global_any_laps_epochs_obj = deepcopy(curr_active_pipeline.computation_results[global_any_name].computation_config.pf_params.computation_epochs) # global_any_name='maze_any' (? same as global_epoch_name?)\n",
    "global_any_laps_epochs_df = ensure_dataframe(global_any_laps_epochs_obj)    \n",
    "global_any_laps_epochs_df = global_any_laps_epochs_df.epochs.adding_maze_id_if_needed(t_start=t_start, t_delta=t_delta, t_end=t_end)\n",
    "global_any_laps_epochs_df = global_any_laps_epochs_df.laps_accessor.compute_lap_dir_from_net_displacement(global_session=deepcopy(global_session), replace_existing=True)\n",
    "\n",
    "result_laps_epochs_df: pd.DataFrame = directional_merged_decoders_result.add_groundtruth_information(curr_active_pipeline)\n",
    "result_laps_epochs_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f708c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    laps_directional_marginals, laps_directional_all_epoch_bins_marginal, laps_most_likely_direction_from_decoder, laps_is_most_likely_direction_LR_dir  = directional_merged_decoders_result.laps_directional_marginals_tuple\n",
    "    percent_laps_estimated_correctly = DirectionalPseudo2DDecodersResult.validate_lap_dir_estimations(curr_active_pipeline.sess, active_global_laps_df=global_any_laps_epochs_obj.to_dataframe(), laps_is_most_likely_direction_LR_dir=laps_is_most_likely_direction_LR_dir)\n",
    "    print(f'percent_laps_estimated_correctly: {percent_laps_estimated_correctly}')\n",
    "except (AssertionError, ValueError) as err:\n",
    "    print(F'fails due to some types thing?')\n",
    "    print(f'\\terr: {err}')\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1b3279",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_directional_all_epoch_bins_marginal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
