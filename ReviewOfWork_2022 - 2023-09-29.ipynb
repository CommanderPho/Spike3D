{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ce022a",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "# %load_ext viztracer\n",
    "# from viztracer import VizTracer\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "from copy import deepcopy\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "# pd.options.mode.dtype_backend = 'pyarrow' # use new pyarrow backend instead of numpy\n",
    "from attrs import define, field, fields, Factory\n",
    "import tables as tb\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Pho's Formatting Preferences\n",
    "from pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\n",
    "set_pho_preferences_concise()\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "# from neuropy import core\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.core.epoch import NamedTimerange, Epoch\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.utils.matplotlib_helpers import matplotlib_file_only, matplotlib_configuration, matplotlib_configuration_update\n",
    "from neuropy.core.neuron_identities import NeuronIdentityTable, neuronTypesList, neuronTypesEnum\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "from neuropy.core.neurons import NeuronType\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from neuropy.core.position import Position\n",
    "from neuropy.core.session.dataSession import DataSession\n",
    "from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent, PlacefieldSnapshot\n",
    "\n",
    "from pyphocorehelpers.print_helpers import print_object_memory_usage, print_dataframe_memory_usage, print_value_overview_only, DocumentationFilePrinter, print_keys_if_possible, generate_html_string, CapturedException\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_load_session, batch_extended_computations, batch_extended_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import _find_any_context_neurons\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchSessionCompletionHandler # for `post_compute_validate(...)`\n",
    "from neuropy.utils.mixins.AttrsClassHelpers import AttrsBasedClassHelperMixin, serialized_field, serialized_attribute_field, non_serialized_field\n",
    "from neuropy.utils.mixins.HDF5_representable import HDF_DeserializationMixin, post_deserialize, HDF_SerializationMixin, HDFMixin\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BasePositionDecoder\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsResults\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends # for `_perform_long_short_instantaneous_spike_rate_groups_analysis`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import SingleBarResult, InstantaneousSpikeRateGroupsComputation, TruncationCheckingResults # for `BatchSessionCompletionHandler`, `AcrossSessionsAggregator`\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import SplitPartitionMembership\n",
    "\n",
    "# Plotting\n",
    "# import pylustrator # customization of figures\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "# import pylustrator # call `pylustrator.start()` before creating your first figure in code.\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot, plot_raster_plot\n",
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import DataSeriesColorHelpers\n",
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import UnitColoringMode, DataSeriesColorHelpers\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import _build_default_tick, build_scatter_plot_kwargs\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.Render2DScrollWindowPlot import Render2DScrollWindowPlotMixin, ScatterItemData\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_extended_programmatic_figures, batch_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PAPER_FIGURE_figure_1_add_replay_epoch_rasters, PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_3, main_complete_figure_generations\n",
    "\n",
    "from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import *\n",
    "\n",
    "# Jupyter Widget Interactive\n",
    "from IPython.display import display\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import interactive_pipeline_widget, fullwidth_path_widget, interactive_pipeline_files\n",
    "\n",
    "global_data_root_parent_path = find_first_extant_path([Path(r'W:\\Data'), Path(r'/home/halechr/FastData'), Path(r'/media/MAX/Data'), Path(r'/Volumes/MoverNew/data'), Path(r'/home/halechr/turbo/Data')])\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1538e2a-4e39-4d11-90b5-a9fef9258058",
   "metadata": {
    "tags": [
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "source": [
    "# Load Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f917bad9-8fe7-4882-b83b-71cf878fffd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T16:05:43.785201Z",
     "start_time": "2023-07-29T16:05:34.880381100Z"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "load",
     "REQUIRED"
    ]
   },
   "outputs": [],
   "source": [
    "%pdb off\n",
    "# ==================================================================================================================== #\n",
    "# Load Data                                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "active_data_mode_name = 'kdiba'\n",
    "local_session_root_parent_context = IdentifyingContext(format_name=active_data_mode_name) # , animal_name='', configuration_name='one', session_name=a_sess.session_name\n",
    "local_session_root_parent_path = global_data_root_parent_path.joinpath('KDIBA')\n",
    "\n",
    "# [*] - indicates bad or session with a problem\n",
    "# 0, 1, 2, 3, 4, 5, 6, 7, [8], [9], 10, 11, [12], 13, 14, [15], [16], 17, \n",
    "# curr_context: IdentifyingContext = good_contexts_list[1] # select the session from all of the good sessions here.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15') # DONE. Very good. Many good Pfs, many good replays.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43') # DONE, might be the BEST SESSION, good example session with lots of place cells, clean replays, and clear bar graphs.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31') # DONE, Good Pfs but no good replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-13_14-42-6') # BAD, 2023-07-14, unsure why still.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19') # DONE, GREAT, both good Pfs and replays!\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25') # DONE, Added replay selections. Very \"jumpy\" between the starts and ends of the track.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40') # DONE, Added replay selections. A TON of putative replays in general, most bad, but some good.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46') # DONE, added replay selections. Very few (like 12) replays each.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-13_15-22-3') # DONE, Good Pfs, no good epochs.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30') # DONE, okay replays (selected)\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50') # DONE, very few replays (selected)\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-19_13-34-40') # BAD\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54') # DONE, one replay each (selected)\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3') # BAD, Good Pfs strangely despite horrible map, no good epochs\n",
    "curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-12_15-25-59') # BAD, No Epochs\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-16_18-47-52')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-17_12-52-15')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-25_13-20-55')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-28_12-38-13')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44') # DONE, good. Many good pfs, many good replays. Noticed very strange jumping off the track in the 3D behavior/spikes viewer. Is there something wrong with this session?\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0') # DONE, good?, replays selected, few\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25') # DONE, very few replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_12-15-3')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_22-4-5')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54') # DONE, replays selected, quite a few replays but few are very good.\n",
    "\n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25')\n",
    "\n",
    "local_session_parent_path: Path = local_session_root_parent_path.joinpath(curr_context.animal, curr_context.exper_name) # 'gor01', 'one' - probably not needed anymore\n",
    "basedir: Path = local_session_parent_path.joinpath(curr_context.session_name).resolve()\n",
    "print(f'basedir: {str(basedir)}')\n",
    "\n",
    "# Read if possible:\n",
    "saving_mode = PipelineSavingScheme.SKIP_SAVING\n",
    "force_reload = False\n",
    "\n",
    "# # # # # Force write:\n",
    "# saving_mode = PipelineSavingScheme.TEMP_THEN_OVERWRITE\n",
    "# saving_mode = PipelineSavingScheme.OVERWRITE_IN_PLACE\n",
    "# force_reload = True\n",
    "\n",
    "## TODO: if loading is not possible, we need to change the `saving_mode` so that the new results are properly saved.\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-full_session_LOO_decoding_analysis.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "# epoch_name_includelist = ['maze']\n",
    "epoch_name_includelist = None\n",
    "active_computation_functions_name_includelist=['pf_computation', 'pfdt_computation', 'firing_rate_trends',\n",
    "                                                'pf_dt_sequential_surprise', \n",
    "                                            #    'ratemap_peaks_prominence2d',\n",
    "                                                'position_decoding', 'position_decoding_two_step', \n",
    "                                               'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping',\n",
    "                                                # 'long_short_inst_spike_rate_groups',\n",
    "                                                'long_short_endcap_analysis']\n",
    "\n",
    "curr_active_pipeline: NeuropyPipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_includelist=epoch_name_includelist,\n",
    "                                        computation_functions_name_includelist=active_computation_functions_name_includelist,\n",
    "                                        saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                        skip_extended_batch_computations=True, debug_print=False, fail_on_exception=False) # , active_pickle_filename = 'loadedSessPickle_withParameters.pkl'\n",
    "\n",
    "if not force_reload: # not just force_reload, needs to recompute whenever the computation fails.\n",
    "    try:\n",
    "        curr_active_pipeline.load_pickled_global_computation_results()\n",
    "    except Exception as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'cannot load global results: {e}')\n",
    "        raise\n",
    "\n",
    "\n",
    "# 6m 1.1s\n",
    "# 12m 15.6s\n",
    "\n",
    "\n",
    "# try:\n",
    "## Post Compute Validate 2023-05-16:\n",
    "was_updated = BatchSessionCompletionHandler.post_compute_validate(curr_active_pipeline) ## TODO: need to potentially re-save if was_updated\n",
    "if was_updated:\n",
    "    try:\n",
    "        curr_active_pipeline.save_pipeline(saving_mode=saving_mode)\n",
    "    except Exception as e:\n",
    "        ## TODO: catch/log saving error and indicate that it isn't saved.\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'ERROR RE-SAVING PIPELINE after update. error: {e}')\n",
    "\n",
    "\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "extended_computations_include_includelist=['pf_computation', 'pfdt_computation', 'firing_rate_trends',\n",
    "    #'pf_dt_sequential_surprise',\n",
    "     #'ratemap_peaks_prominence2d',\n",
    "    'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping',\n",
    "    #  'long_short_inst_spike_rate_groups',\n",
    "    'long_short_endcap_analysis'\n",
    "] # do only specified\n",
    "force_recompute_global = force_reload\n",
    "# force_recompute_global = True\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True, force_recompute=force_recompute_global, debug_print=False)\n",
    "if (len(newly_computed_values) > 0):\n",
    "    print(f'newly_computed_values: {newly_computed_values}.')\n",
    "    if (saving_mode.value != 'skip_saving'):\n",
    "        print(f'Saving global results...')\n",
    "        try:\n",
    "            # curr_active_pipeline.global_computation_results.persist_time = datetime.now()\n",
    "            # Try to write out the global computation function results:\n",
    "            curr_active_pipeline.save_global_computation_results()\n",
    "        except Exception as e:\n",
    "            exception_info = sys.exc_info()\n",
    "            e = CapturedException(e, exception_info)\n",
    "            print(f'\\n\\n!!WARNING!!: saving the global results threw the exception: {e}')\n",
    "            print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "    else:\n",
    "        print(f'\\n\\n!!WARNING!!: changes to global results have been made but they will not be saved since saving_mode.value == \"skip_saving\"')\n",
    "        print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "else:\n",
    "    print(f'no changes in global results.')\n",
    "\n",
    "# except Exception as e:\n",
    "#     exception_info = sys.exc_info()\n",
    "#     e = CapturedException(e, exception_info)\n",
    "#     print(f'second half threw: {e}')\n",
    "\n",
    "\n",
    "# 4m 5.2s for inst fr computations\n",
    "# Jupyter Widget Interactive\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import interactive_pipeline_widget, fullwidth_path_widget, interactive_pipeline_files\n",
    "\n",
    "_pipeline_jupyter_widget = interactive_pipeline_widget(curr_active_pipeline=curr_active_pipeline)\n",
    "# display(_pipeline_jupyter_widget)\n",
    "_pipeline_jupyter_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce8eb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "if curr_active_pipeline.updated_since_last_pickle:\n",
    "\t_bak_saving_mode = saving_mode\n",
    "\n",
    "saving_mode = PipelineSavingScheme.TEMP_THEN_OVERWRITE\n",
    "try:\n",
    "\tcurr_active_pipeline.save_pipeline(saving_mode=saving_mode)\n",
    "\tcurr_active_pipeline.save_global_computation_results()\n",
    "\n",
    "except Exception as e:\n",
    "\t## TODO: catch/log saving error and indicate that it isn't saved.\n",
    "\texception_info = sys.exc_info()\n",
    "\te = CapturedException(e, exception_info)\n",
    "\tprint(f'ERROR RE-SAVING PIPELINE after update. error: {e}')\n",
    "finally:\n",
    "\tsaving_mode = _bak_saving_mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d17633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _require_pipeline_has_refined_pfs(curr_active_pipeline, frs_index_inclusion_magnitude:float=0.5):\n",
    "\t\"\"\" Refine the LxC/SxC designators using the firing rate index metric:\n",
    "\t\"\"\"\n",
    "\tjonathan_firing_rate_analysis_result: JonathanFiringRateAnalysisResult = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis\n",
    "\n",
    "\t## Get global `long_short_fr_indicies_analysis`:\n",
    "\tlong_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "\tlong_short_fr_indicies_df = long_short_fr_indicies_analysis_results['long_short_fr_indicies_df']\n",
    "\tjonathan_firing_rate_analysis_result.refine_exclusivity_by_inst_frs_index(long_short_fr_indicies_df, frs_index_inclusion_magnitude=frs_index_inclusion_magnitude)\n",
    "\n",
    "\n",
    "\n",
    "_require_pipeline_has_refined_pfs(curr_active_pipeline, frs_index_inclusion_magnitude=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d086ba68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b647dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.clear_display_outputs()\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac26b2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_global_computation_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3515eaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.Filesystem.metadata_helpers import FilesystemMetadata\n",
    "\n",
    "hdf5_output_path: Path = curr_active_pipeline.get_output_path().joinpath('pipeline_results.h5').resolve()\n",
    "print(f'pipeline hdf5_output_path: {hdf5_output_path}')\n",
    "\n",
    "\n",
    "# Only get files newer than date\n",
    "newest_file_to_overwrite_date = datetime.now() - timedelta(days=1) # don't overwrite any files more recent than 1 day ago\n",
    "if hdf5_output_path.exists() and (FilesystemMetadata.get_last_modified_time(hdf5_output_path)<=newest_file_to_overwrite_date):\n",
    "\t# file is folder than the date to overwrite, so overwrite it\n",
    "\tprint(f'OVERWRITING (or writing) the file {hdf5_output_path}!')\n",
    "else:\n",
    "\tprint(f'file {hdf5_output_path} is newer than the allowed overwrite date, so it will be skipped.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c850782f",
   "metadata": {},
   "source": [
    "# End Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dc7ae9",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "## long_short_decoding_analyses:\n",
    "curr_long_short_decoding_analyses = curr_active_pipeline.global_computation_results.computed_data['long_short_leave_one_out_decoding_analysis']\n",
    "long_one_step_decoder_1D, short_one_step_decoder_1D, long_replays, short_replays, global_replays, long_shared_aclus_only_decoder, short_shared_aclus_only_decoder, shared_aclus, long_short_pf_neurons_diff, n_neurons, long_results_obj, short_results_obj, is_global = curr_long_short_decoding_analyses.long_decoder, curr_long_short_decoding_analyses.short_decoder, curr_long_short_decoding_analyses.long_replays, curr_long_short_decoding_analyses.short_replays, curr_long_short_decoding_analyses.global_replays, curr_long_short_decoding_analyses.long_shared_aclus_only_decoder, curr_long_short_decoding_analyses.short_shared_aclus_only_decoder, curr_long_short_decoding_analyses.shared_aclus, curr_long_short_decoding_analyses.long_short_pf_neurons_diff, curr_long_short_decoding_analyses.n_neurons, curr_long_short_decoding_analyses.long_results_obj, curr_long_short_decoding_analyses.short_results_obj, curr_long_short_decoding_analyses.is_global \n",
    "\n",
    "# (long_one_step_decoder_1D, short_one_step_decoder_1D), (long_one_step_decoder_2D, short_one_step_decoder_2D) = compute_short_long_constrained_decoders(curr_active_pipeline, recalculate_anyway=True)\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_epoch_context, short_epoch_context, global_epoch_context = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_epoch_name, short_epoch_name, global_epoch_name)]\n",
    "long_epoch_obj, short_epoch_obj = [Epoch(curr_active_pipeline.sess.epochs.to_dataframe().epochs.label_slice(an_epoch_name)) for an_epoch_name in [long_epoch_name, short_epoch_name]]\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_computation_config, short_computation_config, global_computation_config = [curr_active_pipeline.computation_results[an_epoch_name]['computation_config'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "long_pf2D, short_pf2D, global_pf2D = long_results.pf2D, short_results.pf2D, global_results.pf2D\n",
    "decoding_time_bin_size = long_one_step_decoder_1D.time_bin_size # 1.0/30.0 # 0.03333333333333333\n",
    "\n",
    "## Get global `long_short_fr_indicies_analysis`:\n",
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "long_laps, long_replays, short_laps, short_replays, global_laps, global_replays = [long_short_fr_indicies_analysis_results[k] for k in ['long_laps', 'long_replays', 'short_laps', 'short_replays', 'global_laps', 'global_replays']]\n",
    "long_short_fr_indicies_df = long_short_fr_indicies_analysis_results['long_short_fr_indicies_df']\n",
    "\n",
    "## Get global 'long_short_post_decoding' results:\n",
    "curr_long_short_post_decoding = curr_active_pipeline.global_computation_results.computed_data['long_short_post_decoding']\n",
    "expected_v_observed_result, curr_long_short_rr = curr_long_short_post_decoding.expected_v_observed_result, curr_long_short_post_decoding.rate_remapping\n",
    "rate_remapping_df, high_remapping_cells_only = curr_long_short_rr.rr_df, curr_long_short_rr.high_only_rr_df\n",
    "Flat_epoch_time_bins_mean, Flat_decoder_time_bin_centers, num_neurons, num_timebins_in_epoch, num_total_flat_timebins, is_short_track_epoch, is_long_track_epoch, short_short_diff, long_long_diff = expected_v_observed_result.Flat_epoch_time_bins_mean, expected_v_observed_result.Flat_decoder_time_bin_centers, expected_v_observed_result.num_neurons, expected_v_observed_result.num_timebins_in_epoch, expected_v_observed_result.num_total_flat_timebins, expected_v_observed_result.is_short_track_epoch, expected_v_observed_result.is_long_track_epoch, expected_v_observed_result.short_short_diff, expected_v_observed_result.long_long_diff\n",
    "\n",
    "jonathan_firing_rate_analysis_result: JonathanFiringRateAnalysisResult = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis\n",
    "(epochs_df_L, epochs_df_S), (filter_epoch_spikes_df_L, filter_epoch_spikes_df_S), (good_example_epoch_indicies_L, good_example_epoch_indicies_S), (short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset), new_all_aclus_sort_indicies, assigning_epochs_obj = PAPER_FIGURE_figure_1_add_replay_epoch_rasters(curr_active_pipeline)\n",
    "neuron_replay_stats_df, short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset = jonathan_firing_rate_analysis_result.get_cell_track_partitions(frs_index_inclusion_magnitude=0.5)\n",
    "\n",
    "## Update long_exclusive/short_exclusive properties with `long_short_fr_indicies_df`\n",
    "# long_exclusive.refine_exclusivity_by_inst_frs_index(long_short_fr_indicies_df, frs_index_inclusion_magnitude=0.5)\n",
    "# short_exclusive.refine_exclusivity_by_inst_frs_index(long_short_fr_indicies_df, frs_index_inclusion_magnitude=0.5)\n",
    "\n",
    "# inst_spike_rate_groups_result: InstantaneousSpikeRateGroupsComputation = curr_active_pipeline.global_computation_results.computed_data.long_short_inst_spike_rate_groups\n",
    "# custom_InstSpikeRateTrends_df = inst_spike_rate_groups_result.all_incl_endPlatforms_InstSpikeRateTrends_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612d876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots, BatchPhoJonathanFiguresHelper\n",
    "\n",
    "fig_1c_figures_out_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, included_unit_neuron_IDs=XOR_subset.get_refined_track_exclusive_aclus(), n_max_page_rows=20, write_vector_format=False, write_png=False, show_only_refined_cells=True, disable_top_row=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5922fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## all cells:\n",
    "fig_1c_figures_all_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, included_unit_neuron_IDs=None, n_max_page_rows=20, write_vector_format=False, write_png=False, show_only_refined_cells=False, disable_top_row=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac53d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_replay_stats_df = jonathan_firing_rate_analysis_result.neuron_replay_stats_df.copy()\n",
    "\n",
    "np.sum(np.logical_xor(neuron_replay_stats_df['is_refined_LxC'], neuron_replay_stats_df['is_refined_SxC']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941cc7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.logical_and(neuron_replay_stats_df['is_refined_LxC'], neuron_replay_stats_df['is_refined_SxC']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0460c6e5",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "# uses global's 'extended_stats' results for relative entropy (surprise) analyses:\n",
    "\n",
    "import tables as tb\n",
    "\n",
    "\n",
    "# {\n",
    "# 't': Tuple[float, float],\n",
    "# 'snapshots': Tuple[PlacefieldSnapshot, PlacefieldSnapshot],\n",
    "# 'relative_entropy_result_dict': {\n",
    "# \t\t'long_short_rel_entr_curve': np.array,\n",
    "# \t\t...\n",
    "# \t\t'jensen_shannon_distance': np.array,\n",
    "# \t} # 5 items\n",
    "# } # 3 items\n",
    "# Dict[float, PlacefieldSnapshot]\n",
    "\n",
    "def relative_entropy_to_h5(global_results, file_path='output/test_relative_entropy_numpy_arrays.h5'):\n",
    "\tprint(f'relative_entropy_to_h5(...)')\n",
    "\n",
    "\tactive_extended_stats = global_results['extended_stats']\n",
    "\tactive_relative_entropy_results = active_extended_stats['pf_dt_sequential_surprise'] # DynamicParameters\n",
    "\tpost_update_times: np.ndarray = active_relative_entropy_results['post_update_times'] # (4152,) = (n_post_update_times,)\n",
    "\tsnapshot_differences_result_dict = active_relative_entropy_results['snapshot_differences_result_dict']\n",
    "\ttime_intervals: np.ndarray = active_relative_entropy_results['time_intervals']\n",
    "\tlong_short_rel_entr_curves_frames: np.ndarray = active_relative_entropy_results['long_short_rel_entr_curves_frames'] # (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "\tshort_long_rel_entr_curves_frames: np.ndarray = active_relative_entropy_results['short_long_rel_entr_curves_frames'] # (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "\tflat_relative_entropy_results: np.ndarray = active_relative_entropy_results['flat_relative_entropy_results'] # (149, 63) - (nSnapshots, nXbins)\n",
    "\tflat_jensen_shannon_distance_results: np.ndarray = active_relative_entropy_results['flat_jensen_shannon_distance_results'] # (149, 63) - (nSnapshots, nXbins)\n",
    "\tflat_jensen_shannon_distance_across_all_positions: np.ndarray = np.sum(np.abs(flat_jensen_shannon_distance_results), axis=1) # sum across all position bins # (4152,) - (nSnapshots)\n",
    "\tflat_surprise_across_all_positions: np.ndarray = np.sum(np.abs(flat_relative_entropy_results), axis=1) # sum across all position bins # (4152,) - (nSnapshots)\n",
    "\t\n",
    "\t# Create an HDF5 file\n",
    "\twith tb.open_file(file_path, mode=\"w\") as hdf5_file:\n",
    "\t\tprint(f'trying to write to \"{file_path}\"...')\n",
    "\t\t# Create groups for organization\n",
    "\t\troot = hdf5_file.root\n",
    "\t\tgroup = hdf5_file.create_group(root, 'relative_entropy_results')\n",
    "\t\t\n",
    "\t\t# Store np.ndarrays in the HDF5 file\n",
    "\t\thdf5_file.create_array(group, 'post_update_times', post_update_times)\n",
    "\t\thdf5_file.create_array(group, 'time_intervals', time_intervals)\n",
    "\t\thdf5_file.create_array(group, 'long_short_rel_entr_curves_frames', long_short_rel_entr_curves_frames)\n",
    "\t\thdf5_file.create_array(group, 'short_long_rel_entr_curves_frames', short_long_rel_entr_curves_frames)\n",
    "\t\thdf5_file.create_array(group, 'flat_relative_entropy_results', flat_relative_entropy_results)\n",
    "\t\thdf5_file.create_array(group, 'flat_jensen_shannon_distance_results', flat_jensen_shannon_distance_results)\n",
    "\t\thdf5_file.create_array(group, 'flat_jensen_shannon_distance_across_all_positions', flat_jensen_shannon_distance_across_all_positions)\n",
    "\t\thdf5_file.create_array(group, 'flat_surprise_across_all_positions', flat_surprise_across_all_positions)\n",
    "\t\n",
    "\tprint(f'\\t done!')\n",
    "\t\n",
    "\n",
    "relative_entropy_to_h5(global_results, file_path='output/test_relative_entropy_numpy_arrays.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c6b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.export_pipeline_to_h5()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbf2641",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_differences_result_dict\n",
    "\n",
    "flat_jensen_shannon_distance_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06537c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_relative_entropy_results\n",
    "# type(active_relative_entropy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd2f58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_replay_stats_df: pd.DataFrame = jonathan_firing_rate_analysis_result.neuron_replay_stats_df\n",
    "neuron_replay_stats_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d613474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test classifying various x-positions as belonging to outside the outside_maze, the track_endcaps, or the track_body\n",
    "from enum import Enum\n",
    "\n",
    "class TrackPositionClassification(Enum):\n",
    "    OUTSIDE_MAZE = \"outside_maze\"\n",
    "    TRACK_ENDCAPS = \"track_endcaps\"\n",
    "    TRACK_BODY = \"track_body\"\n",
    "\n",
    "\n",
    "neuron_replay_stats_df: pd.DataFrame = jonathan_firing_rate_analysis_result.neuron_replay_stats_df\n",
    "short_pf_peak_x = neuron_replay_stats_df.short_pf_peak_x\n",
    "long_pf_peak_x = neuron_replay_stats_df.long_pf_peak_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8b2a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_remapping_df[np.isin(rate_remapping_df.index, significant_distant_remapping_endcap_aclus)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51571ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_spike_rate_groups_result: InstantaneousSpikeRateGroupsComputation = curr_active_pipeline.global_computation_results.computed_data.long_short_inst_spike_rate_groups\n",
    "# custom_InstSpikeRateTrends_df = inst_spike_rate_groups_result.all_incl_endPlatforms_InstSpikeRateTrends_df\n",
    "# if not hasattr(inst_spike_rate_groups_result, 'all_incl_endPlatforms_InstSpikeRateTrends_df'):\n",
    "# \tinst_spike_rate_groups_result.all_incl_endPlatforms_InstSpikeRateTrends_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628c789f",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2023-09-14 - Find cells outside the bounds of the short track\n",
    "# Modifies the `jonathan_firing_rate_analysis_result.neuron_replay_stats_df` in-place instead of creating a copy:\n",
    "# neuron_replay_stats_df = deepcopy(jonathan_firing_rate_analysis_result.neuron_replay_stats_df)\n",
    "neuron_replay_stats_df: pd.DataFrame = jonathan_firing_rate_analysis_result.neuron_replay_stats_df\n",
    "# Extract the peaks of the long placefields to find ones that have peaks outside the boundaries\n",
    "# long_pf_peaks = neuron_replay_stats_df[neuron_replay_stats_df['has_long_pf']]['long_pf_peak_x'] - 150.0 # this shift of 150.0 is to center the midpoint of the track at 0. \n",
    "# # display(long_pf_peaks)\n",
    "# is_left_cap = (long_pf_peaks < -72.0)\n",
    "# is_right_cap = (long_pf_peaks > 72.0)\n",
    "# is_either_cap =  np.logical_or(is_left_cap, is_right_cap)\n",
    "\n",
    "# # Adds ['is_long_peak_left_cap', 'is_long_peak_right_cap', 'is_long_peak_either_cap'] columns: \n",
    "# neuron_replay_stats_df['is_long_peak_left_cap'] = False\n",
    "# neuron_replay_stats_df['is_long_peak_right_cap'] = False\n",
    "# neuron_replay_stats_df.loc[is_left_cap.index, 'is_long_peak_left_cap'] = is_left_cap # True\n",
    "# neuron_replay_stats_df.loc[is_right_cap.index, 'is_long_peak_right_cap'] = is_right_cap # True\n",
    "# neuron_replay_stats_df['is_long_peak_either_cap'] = np.logical_or(neuron_replay_stats_df['is_long_peak_left_cap'], neuron_replay_stats_df['is_long_peak_right_cap'])\n",
    "# adds ['LS_pf_peak_x_diff'] column\n",
    "# neuron_replay_stats_df['LS_pf_peak_x_diff'] = neuron_replay_stats_df['long_pf_peak_x'] - neuron_replay_stats_df['short_pf_peak_x']\n",
    "neuron_replay_stats_df.is_long_peak_either_cap\n",
    "\n",
    "## Extract just the endcap cells:\n",
    "cap_cells_df = neuron_replay_stats_df[np.logical_and(neuron_replay_stats_df['has_long_pf'], neuron_replay_stats_df['is_long_peak_either_cap'])]\n",
    "cap_aclus = cap_cells_df.index\n",
    "num_total_endcap_cells = len(cap_aclus)\n",
    "display(num_total_endcap_cells)\n",
    "\n",
    "# \"Disppearing\" cells fall below the 1Hz firing criteria on the short track:\n",
    "disappearing_endcap_cells_df = cap_cells_df[np.logical_not(cap_cells_df['has_short_pf'])]\n",
    "disappearing_endcap_aclus = disappearing_endcap_cells_df.index\n",
    "num_disappearing_endcap_cells = len(disappearing_endcap_aclus)\n",
    "print(f'num_disappearing_endcap_cells/num_total_endcap_cells: {num_disappearing_endcap_cells}/{num_total_endcap_cells}')\n",
    "\n",
    "non_disappearing_endcap_cells_df = cap_cells_df[cap_cells_df['has_short_pf']] # \"non_disappearing\" cells are those with a placefield on the short track as well\n",
    "num_non_disappearing_endcap_cells = len(non_disappearing_endcap_cells_df)\n",
    "print(f'num_non_disappearing_endcap_cells/num_total_endcap_cells: {num_non_disappearing_endcap_cells}/{num_total_endcap_cells}')\n",
    "\n",
    "# display(non_disappearing_endcap_cells_df)\n",
    "# non_disappearing_endcap_cells_df['LS_pf_peak_x_diff'] = non_disappearing_endcap_cells_df['long_pf_peak_x'] - non_disappearing_endcap_cells_df['short_pf_peak_x']\n",
    "# display(non_disappearing_endcap_cells_df)\n",
    "\n",
    "# Classify the non_disappearing cells into two groups:\n",
    "# 1. Those that exhibit significant remapping onto somewhere else on the track\n",
    "non_disappearing_endcap_cells_df['has_significant_distance_remapping'] = (np.abs(non_disappearing_endcap_cells_df['LS_pf_peak_x_diff']) >= 40.0) # The most a placefield could translate intwards would be (35 + (pf_width/2.0)) I think.\n",
    "num_significant_position_remappping_endcap_cells = len(non_disappearing_endcap_cells_df[non_disappearing_endcap_cells_df['has_significant_distance_remapping'] == True])\n",
    "print(f'num_significant_position_remappping_endcap_cells/num_non_disappearing_endcap_cells: {num_significant_position_remappping_endcap_cells}/{num_non_disappearing_endcap_cells}')\n",
    "\n",
    "# 2. Those that seem to remain where they were on the long track, perhaps being \"sampling-clipped\" or translated adjacent to the platform. These two subcases can be distinguished by a change in the placefield's length (truncated cells would be a fraction of the length, although might need to account for scaling with new track length)\n",
    "minorly_changed_endcap_cells_df = non_disappearing_endcap_cells_df[non_disappearing_endcap_cells_df['has_significant_distance_remapping'] == False]\n",
    "\n",
    "non_disappearing_endcap_cells_df\n",
    "# endcaps:\n",
    "significant_distant_remapping_endcap_aclus = non_disappearing_endcap_cells_df[non_disappearing_endcap_cells_df['has_significant_distance_remapping']].index.to_numpy() # Int64Index([3, 5, 7, 11, 14, 38, 41, 53, 57, 61, 62, 75, 78, 79, 82, 83, 85, 95, 98, 100, 102], dtype='int64')\n",
    "significant_distant_remapping_endcap_aclus\n",
    "minor_remapping_endcap_aclus = minorly_changed_endcap_cells_df.index.to_numpy()\n",
    "minor_remapping_endcap_aclus\n",
    "jonathan_firing_rate_analysis_result.neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568e1351",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_distant_remapping_endcap_df = jonathan_firing_rate_analysis_result.neuron_replay_stats_df[np.isin(jonathan_firing_rate_analysis_result.neuron_replay_stats_df.index, significant_distant_remapping_endcap_aclus)]\n",
    "significant_distant_remapping_endcap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8f1fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will these remapped cells be included in replays after the delta?\n",
    "num_short_replays = non_disappearing_endcap_cells_df['short_num_replays']\n",
    "short_replay_mean_fr_Hz = non_disappearing_endcap_cells_df['replay_diff']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcb50e6",
   "metadata": {},
   "source": [
    "## 2023-09-20 - Plot the significantly remapping cells using the lower-level `plot_short_v_long_pf1D_comparison` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebc2de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import plot_short_v_long_pf1D_comparison\n",
    "from neuropy.utils.matplotlib_helpers import perform_update_title_subtitle\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import add_vertical_track_bounds_lines, add_track_shapes\n",
    "from neuropy.plotting.ratemaps import plot_ratemap_1D\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import LongShortDisplayConfigManager\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "graphics_output_dict = {}\n",
    "active_context: IdentifyingContext = curr_active_pipeline.get_session_context()\n",
    "\n",
    "long_short_display_config_manager = LongShortDisplayConfigManager()\n",
    "long_epoch_config = long_short_display_config_manager.long_epoch_config.as_pyqtgraph_kwargs()\n",
    "short_epoch_config = long_short_display_config_manager.short_epoch_config.as_pyqtgraph_kwargs()\n",
    "\n",
    "long_epoch_matplotlib_config = long_short_display_config_manager.long_epoch_config.as_matplotlib_kwargs()\n",
    "short_epoch_matplotlib_config = long_short_display_config_manager.short_epoch_config.as_matplotlib_kwargs()\n",
    "\n",
    "shared_kwargs = dict(pad=1, cmap='hsv', active_context=curr_active_pipeline.get_session_context(), plot_zero_baselines=True, skip_figure_titles=True, use_flexitext_titles=True, flat_stack_mode=False)\n",
    "top_level_shared_kwargs = dict(should_plot_vertical_track_bounds_lines=True, sortby='peak_long')\n",
    "# top_level_shared_kwargs = dict(should_plot_vertical_track_bounds_lines=False, should_plot_linear_track_shapes=True) # Renders the linear track shape on the maze. Assumes `flat_stack_mode=True`\n",
    "\n",
    "\n",
    "# # flat_stack_mode: all placefields are stacked up (z-wise) on top of each other on a single axis with no offsets:\n",
    "# shared_kwargs = dict(pad=1, active_context=curr_active_pipeline.get_session_context(), plot_zero_baselines=True, skip_figure_titles=True, use_flexitext_titles=True, flat_stack_mode=True)\n",
    "# top_level_shared_kwargs = dict(should_plot_vertical_track_bounds_lines=False, should_plot_linear_track_shapes=True) # Renders the linear track shape on the maze. Assumes `flat_stack_mode=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec159e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023-09-21 - Plot All\n",
    "graphics_output_dict = graphics_output_dict | fig_remapping_cells(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfab342",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.suptitle('Translation Remapping Cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d9a3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_surprise_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d02c8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long_results = curr_active_pipeline.computation_results['maze1_PYR'].computed_data\n",
    "# short_results = curr_active_pipeline.computation_results['maze2_PYR'].computed_data\n",
    "# curr_any_context_neurons = _find_any_context_neurons(*[curr_active_pipeline.computation_results[k].computed_data.pf1D.ratemap.neuron_ids for k in ['maze1_PYR', 'maze2_PYR']])\n",
    "# (fig_long_pf_1D, ax_long_pf_1D, long_sort_ind, long_neurons_colors_array), (fig_short_pf_1D, ax_short_pf_1D, short_sort_ind, short_neurons_colors_array) = plot_short_v_long_pf1D_comparison(long_results, short_results, disappearing_endcap_aclus, reuse_axs_tuple=None, single_figure=True, shared_kwargs=shared_kwargs, title_string=\"Disappearing Cells\", subtitle_string=None, **top_level_shared_kwargs)\n",
    "graphics_output_dict['disappearing_endcap_aclus'] = curr_active_pipeline.display('_display_short_long_pf1D_comparison', curr_active_pipeline.get_session_context(), included_any_context_neuron_ids=disappearing_endcap_aclus, reuse_axs_tuple=None, single_figure=True, shared_kwargs=shared_kwargs, title_string=\"Disappearing Cells\", subtitle_string=None, **top_level_shared_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3500f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (fig_long_pf_1D, ax_long_pf_1D, long_sort_ind, long_neurons_colors_array), (fig_short_pf_1D, ax_short_pf_1D, short_sort_ind, short_neurons_colors_array) = plot_short_v_long_pf1D_comparison(long_results, short_results, significant_distant_remapping_endcap_aclus, reuse_axs_tuple=None, single_figure=True, shared_kwargs=shared_kwargs, title_string=\"Significant Distance Remapping Cells\", subtitle_string=\"1D Placefields\", **top_level_shared_kwargs)\n",
    "graphics_output_dict['significant_distant_remapping_endcap_aclus'] = curr_active_pipeline.display('_display_short_long_pf1D_comparison', curr_active_pipeline.get_session_context(), included_any_context_neuron_ids=significant_distant_remapping_endcap_aclus, reuse_axs_tuple=None, single_figure=True, shared_kwargs=shared_kwargs, title_string=\"Significant Distance Remapping Cells\", subtitle_string=\"1D Placefields\", **top_level_shared_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c7f4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (fig_long_pf_1D, ax_long_pf_1D, long_sort_ind, long_neurons_colors_array), (fig_short_pf_1D, ax_short_pf_1D, short_sort_ind, short_neurons_colors_array) = plot_short_v_long_pf1D_comparison(long_results, short_results, trivially_remapping_endcap_aclus, reuse_axs_tuple=None, single_figure=True, shared_kwargs=shared_kwargs, title_string=\"Trivially Remapping Cells\", subtitle_string=\"1D Placefields\", **top_level_shared_kwargs)\n",
    "graphics_output_dict['trivially_remapping_endcap_aclus'] = curr_active_pipeline.display('_display_short_long_pf1D_comparison', curr_active_pipeline.get_session_context(), included_any_context_neuron_ids=trivially_remapping_endcap_aclus, reuse_axs_tuple=None, single_figure=True, shared_kwargs=shared_kwargs, title_string=\"Trivially Remapping Cells\", subtitle_string=\"1D Placefields\", **top_level_shared_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744564fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2023-09-18 - Shows the cells that exhibit simple remapping after delta\n",
    "graphics_output_dict = curr_active_pipeline.display('_display_short_long_pf1D_comparison', curr_active_pipeline.get_session_context(), included_any_context_neuron_ids=None, reuse_axs_tuple=None, single_figure=True, shared_kwargs=shared_kwargs, **top_level_shared_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e11c5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import fig_example_nontopo_remap\n",
    "\n",
    "graphics_output_dict = fig_example_nontopo_remap(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be59d32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771e3b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.export_pipeline_to_h5('output/2023_09_26_new_pipeline_test.h5')\n",
    "# ERROR: encountered exception !! 'InstantaneousSpikeRateGroupsComputation' object has no attribute 'all_incl_endPlatforms_InstSpikeRateTrends_df' ::::: (<class 'AttributeError'>, AttributeError(\"'InstantaneousSpikeRateGroupsComputation' object has no attribute 'all_incl_endPlatforms_InstSpikeRateTrends_df'\"), <traceback object at 0x000001E5A3D3D040>) while trying to build the session HDF output.\n",
    "# AttributeError: 'SpikeRateTrends' object has no attribute 'included_neuron_ids'\n",
    "# _neuron_replay_stats_df - TypeError: Cannot serialize the column [track_membership] because its data contents are not [string] but [mixed] object dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aa0ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255ef3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "\n",
    "graphics_output_dict = curr_active_pipeline.display('_display_short_long_pf1D_scalar_overlap_comparison', active_identifying_session_ctx, save_figure=False)\n",
    "# fig, axs, plot_data = graphics_output_dict['fig'], graphics_output_dict['axs'], graphics_output_dict['plot_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e146d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ca625b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _display_long_short_expected_v_observed_firing_rate\n",
    "graphics_output_dict = curr_active_pipeline.display('_display_long_short_expected_v_observed_firing_rate', curr_active_pipeline.sess.get_context(), included_neuron_IDs=significant_distant_remapping_endcap_aclus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6bc6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_temp_force_recompute=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33d838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recompute 'long_short_fr_indicies_analyses'\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_extended_computations\n",
    "\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "\n",
    "# _temp_force_recompute=True\n",
    "_temp_force_recompute=False\n",
    "# extended_computations_include_includelist = ['_perform_time_dependent_placefield_computation', 'long_short_fr_indicies_analyses', 'pf_dt_sequential_surprise', 'short_long_pf_overlap_analyses'] # do only specifiedl\n",
    "extended_computations_include_includelist = ['jonathan_firing_rate_analysis', 'short_long_pf_overlap_analyses']\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True, force_recompute=_temp_force_recompute, debug_print=False)\n",
    "newly_computed_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed12881",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.rdf.rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab18fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.irdf.irdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a269239",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ad2b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2ce6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_long_short_fr_indicies_analysis_bak = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "\n",
    "curr_long_short_fr_indicies_analysis = curr_active_pipeline.global_computation_results.computed_data.pop('long_short_fr_indicies_analysis')\n",
    "\n",
    "print(list(curr_long_short_fr_indicies_analysis.keys())) # ['long_laps', 'long_replays', 'short_laps', 'short_replays', 'global_laps', 'global_replays', 'long_non_replays', 'short_non_replays', 'global_non_replays', 'long_mean_non_replays_frs', 'short_mean_non_replays_frs', 'long_mean_non_replays_all_frs', 'short_mean_non_replays_all_frs', 'non_replays_frs_index', 'long_mean_non_replays_all_inst_frs', 'short_mean_non_replays_all_inst_frs', 'non_replays_inst_frs_index', 'active_context']\n",
    "\n",
    "print_keys_if_possible('curr_long_short_fr_indicies_analysis', curr_long_short_fr_indicies_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6411650",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a621ba9",
   "metadata": {},
   "source": [
    "# 2023-09-12 - Assemble all neuron-level properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6554ac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import build_merged_neuron_firing_rate_indicies\n",
    "\n",
    "joined_neruon_fri_df = build_merged_neuron_firing_rate_indicies(curr_active_pipeline, enable_display_intermediate_results=False)\n",
    "joined_neruon_fri_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963c78c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(joined_neruon_fri_df.columns)) # ['aclu', 'lsfria_laps_frs_index', 'lsfria_laps_inst_frs_index', 'lsfria_replays_frs_index', 'lsfria_replays_inst_frs_index', 'lsfria_non_replays_frs_index', 'lsfria_non_replays_inst_frs_index', 'jfra_long_pf_peak_x', 'jfra_has_long_pf', 'jfra_short_pf_peak_x', 'jfra_has_short_pf', 'jfra_has_na', 'jfra_track_membership', 'jfra_long_non_replay_mean', 'jfra_short_non_replay_mean', 'jfra_non_replay_diff', 'jfra_long_replay_mean', 'jfra_short_replay_mean', 'jfra_replay_diff', 'jfra_long_mean', 'jfra_short_mean', 'jfra_mean_diff', 'jfra_neuron_IDX', 'jfra_num_replays', 'jfra_long_num_replays', 'jfra_short_num_replays', 'jfra_neuron_type', 'lspd_laps', 'lspd_replays', 'lspd_skew', 'lspd_max_axis_distance_from_center', 'lspd_distance_from_center', 'lspd_has_considerable_remapping']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bd0afa",
   "metadata": {},
   "source": [
    "# Computing consolidated `long_short_fr_indicies_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be486bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'long_short_fr_indicies_analysis'\n",
    "curr_long_short_fr_indicies_analysis = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "_curr_aclus = list(curr_long_short_fr_indicies_analysis['laps_frs_index'].keys()) # extract one set of keys for the aclus\n",
    "_curr_frs_indicies_dict = {k:v.values() for k,v in curr_long_short_fr_indicies_analysis.items() if k in ['laps_frs_index', 'laps_inst_frs_index', 'replays_frs_index', 'replays_inst_frs_index', 'non_replays_frs_index', 'non_replays_inst_frs_index']} # extract the values\n",
    "long_short_fr_indicies_df = pd.DataFrame(_curr_frs_indicies_dict, index=_curr_aclus)\n",
    "long_short_fr_indicies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cb7543",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_short_fr_indicies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca0c58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "curr_active_pipeline.perform_specific_computation('long_short_fr_indicies_analyses')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc450f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62734a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = long_short_fr_indicies_df.plot.scatter(x='non_replays_inst_frs_index' , y='replays_inst_frs_index', title='Replays v. Non-replay Firing Rate Index Comparison')\n",
    "# long_short_fr_indicies_df.plot.scatter(x='laps_inst_frs_index' , y='replays_inst_frs_index', title='Replays v. Laps Firing Rate Index Comparison', ax=ax)\n",
    "\n",
    "ax = long_short_fr_indicies_df.plot.scatter(x='non_replays_frs_index' , y='replays_frs_index', title='Replays v. Non-replay Firing Rate Index Comparison')\n",
    "long_short_fr_indicies_df.plot.scatter(x='laps_frs_index' , y='replays_frs_index', title='Replays v. Laps Firing Rate Index Comparison', ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8f1e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "# scatter_matrix(long_short_fr_indicies_df, figsize=(10, 10))\n",
    "scatter_matrix(joined_neruon_fri_df, figsize=(10, 10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07a9146",
   "metadata": {},
   "source": [
    "## Plots the RateRemappingFiringRateIndex Number Line Figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8a42fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Extract rr_* variables from rate_remapping_df\n",
    "# rr_aclus = rate_remapping_df.index.values\n",
    "# rr_laps, rr_replays, rr_skew, rr_neuron_type = [rate_remapping_df[n].values for n in ['laps', 'replays', 'skew', 'neuron_type']]\n",
    "\n",
    "\n",
    "## Extract rr_* variables from joined_neruon_fri_df\n",
    "rr_aclus = joined_neruon_fri_df.index.values\n",
    "rr_laps, rr_replays, rr_skew, rr_neuron_type = [joined_neruon_fri_df[n].values for n in ['lspd_laps', 'lspd_replays', 'lspd_skew', 'jfra_neuron_type']]\n",
    "\n",
    "## Display:\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import plot_rr_aclu\n",
    "n_debug_limit = 10\n",
    "fig, axs, sort_indicies = plot_rr_aclu([str(aclu) for aclu in rr_aclus[:n_debug_limit]], rr_laps=rr_laps[:n_debug_limit], rr_replays=rr_replays[:n_debug_limit], rr_neuron_types=rr_neuron_type[:n_debug_limit])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad336e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fri_index_dicts_list = [dict(x=rr_laps, marker=r'$\\theta$', markersize=10, color='black', label='rr_laps'),\n",
    "\tdict(x=rr_replays, marker='o', markersize=10, fillstyle='none', color='black', label='rr_replays'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc67e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Display Paginated multi-plot\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import plot_rr_aclu\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import RateRemappingPaginatedFigureController\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context()\n",
    "_out_rr_pagination_controller = RateRemappingPaginatedFigureController.init_from_rr_data(rr_aclus, rr_laps, rr_replays, rr_neuron_type, max_subplots_per_page=30, a_name='TestRateRemappingPaginatedFigureController', active_context=active_identifying_session_ctx)\n",
    "a_paginator = _out_rr_pagination_controller.plots_data.paginator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6768b355",
   "metadata": {},
   "source": [
    "# 2023-09-28 - InstFrRate-based classification of LxC and SxC\n",
    "2023-09-28 10:39am: We looked at the results and determined that it was much worse than the placefield critiera I had previously. This analysis should be used as a secondary refinement for the existing placefield-based LxC/SxC exclusion critiera. It includes information about non-lap endcap activity that the other analysis omits. Can be used with a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f368c7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the selected LxC/SxC cells cells on the PhoJonathan plots\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "refined_LxC_aclus = long_exclusive.get_refined_track_exclusive_aclus()\n",
    "print(f'refined_LxC_aclus: {refined_LxC_aclus}')\n",
    "if len(refined_LxC_aclus):\n",
    "\t_out_LxC = curr_active_pipeline.display('_display_batch_pho_jonathan_replay_firing_rate_comparison', n_max_plot_rows=10, save_figure=False, included_unit_neuron_IDs=refined_LxC_aclus) # , included_unit_neuron_IDs=[4, 58]\n",
    "\n",
    "refined_SxC_aclus = short_exclusive.get_refined_track_exclusive_aclus()\n",
    "print(f'refined_SxC_aclus: {refined_SxC_aclus}')\n",
    "if len(refined_SxC_aclus):\n",
    "\t_out_SxC = curr_active_pipeline.display('_display_batch_pho_jonathan_replay_firing_rate_comparison', n_max_plot_rows=10, save_figure=False, included_unit_neuron_IDs=refined_SxC_aclus) # , included_unit_neuron_IDs=[4, 58]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a08e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loaded_df = pd.read_csv(Path(r'W:\\Data\\neuron_replay_stats_table_2023-09-29-GL.csv'))\n",
    "loaded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f3cbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6aacae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import _fr_index\n",
    "instantaneous_time_bin_size_seconds = 0.1\n",
    "owning_pipeline_reference = curr_active_pipeline\n",
    "long_epoch_obj, short_epoch_obj = [Epoch(owning_pipeline_reference.sess.epochs.to_dataframe().epochs.label_slice(an_epoch_name)) for an_epoch_name in [long_epoch_name, short_epoch_name]]\n",
    "\n",
    "# non_running_periods = Epoch.from_PortionInterval(owning_pipeline_reference.sess.laps.as_epoch_obj().to_PortionInterval().complement())\n",
    "non_replay_periods: Epoch = Epoch(Epoch.from_PortionInterval(owning_pipeline_reference.sess.replay.epochs.to_PortionInterval().complement()).time_slice(t_start=long_epoch_obj.t_start, t_stop=short_epoch_obj.t_stop).to_dataframe()[:-1]) #[:-1] # any period except the replay ones, drop the infinite last entry\n",
    "long_only_non_replay_periods: Epoch  = non_replay_periods.time_slice(t_start=long_epoch_obj.t_start, t_stop=long_epoch_obj.t_stop) # any period except the replay ones\n",
    "short_only_non_replay_periods: Epoch  = non_replay_periods.time_slice(t_start=short_epoch_obj.t_start, t_stop=short_epoch_obj.t_stop) # any period except the replay ones\n",
    "\n",
    "# ~20sec computation\n",
    "long_custom_InstSpikeRateTrends: SpikeRateTrends = SpikeRateTrends.init_from_spikes_and_epochs(spikes_df=deepcopy(owning_pipeline_reference.sess.spikes_df),\n",
    "                                                                                        filter_epochs=long_only_non_replay_periods,\n",
    "                                                                                        #    included_neuron_ids=long_exclusive.track_exclusive_aclus,\n",
    "                                                                                        instantaneous_time_bin_size_seconds=instantaneous_time_bin_size_seconds)\n",
    "\n",
    "short_custom_InstSpikeRateTrends: SpikeRateTrends = SpikeRateTrends.init_from_spikes_and_epochs(spikes_df=deepcopy(owning_pipeline_reference.sess.spikes_df),\n",
    "                                                                                        filter_epochs=short_only_non_replay_periods,\n",
    "                                                                                        #    included_neuron_ids=long_exclusive.track_exclusive_aclus,\n",
    "                                                                                        instantaneous_time_bin_size_seconds=instantaneous_time_bin_size_seconds)\n",
    "\n",
    "# # Note custom_InstSpikeRateTrends is global, not really needed:\n",
    "# global_custom_InstSpikeRateTrends: SpikeRateTrends = SpikeRateTrends.init_from_spikes_and_epochs(spikes_df=deepcopy(owning_pipeline_reference.sess.spikes_df),\n",
    "#                                                                                            filter_epochs=non_replay_periods,\n",
    "#                                                                                         #    included_neuron_ids=long_exclusive.track_exclusive_aclus,\n",
    "#                                                                                            instantaneous_time_bin_size_seconds=instantaneous_time_bin_size_seconds)\n",
    "\n",
    "## Determine the included percentiles for `joined_neruon_fri_df`\n",
    "custom_InstSpikeRateTrends_df = pd.DataFrame({'aclu': long_custom_InstSpikeRateTrends.included_neuron_ids, 'long_inst_fr': long_custom_InstSpikeRateTrends.cell_agg_inst_fr_list, 'short_inst_fr': short_custom_InstSpikeRateTrends.cell_agg_inst_fr_list}) #\n",
    "# custom_InstSpikeRateTrends_df['global_inst_fr'] = global_custom_InstSpikeRateTrends.cell_agg_inst_fr_list\n",
    "\n",
    "# Compute the single-dimensional firing rate index for the custom epochs and add it as a column to the dataframe:\n",
    "custom_InstSpikeRateTrends_df['custom_frs_index'] = _fr_index(long_fr=long_custom_InstSpikeRateTrends.cell_agg_inst_fr_list, short_fr=short_custom_InstSpikeRateTrends.cell_agg_inst_fr_list)\n",
    "\n",
    "# # Calculate 10th and 90th percentiles\n",
    "# lower_bound = custom_InstSpikeRateTrends_df['custom_frs_index'].quantile(0.10)\n",
    "# upper_bound = custom_InstSpikeRateTrends_df['custom_frs_index'].quantile(0.90)\n",
    "\n",
    "# # Filter rows\n",
    "# bottom_10_percent = custom_InstSpikeRateTrends_df[custom_InstSpikeRateTrends_df['custom_frs_index'] <= lower_bound]\n",
    "# top_10_percent = custom_InstSpikeRateTrends_df[custom_InstSpikeRateTrends_df['custom_frs_index'] >= upper_bound]\n",
    "\n",
    "# # Extract the aclus from these rows:\n",
    "# LxC_10_percent_aclus = top_10_percent.aclu.to_numpy()\n",
    "# SxC_10_percent_aclus = bottom_10_percent.aclu.to_numpy()\n",
    "\n",
    "# print(f'LxC_10_percent_aclus: {LxC_10_percent_aclus}')\n",
    "# print(f'SxC_10_percent_aclus: {SxC_10_percent_aclus}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d053014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Really want to penalize for any firing on the opposite track."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51090828",
   "metadata": {},
   "source": [
    "# 2023-09-18 - Computation Validators and Computations as Needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f456395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.gui.Qt.TopLevelWindowHelper import TopLevelWindowHelper, print_widget_hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cbe228",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = pg.mkQApp()\n",
    "app\n",
    "app.topLevelWindows()\n",
    "\n",
    "top_level_windows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79502585",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_level_windows = TopLevelWindowHelper.top_level_windows(app, only_visible=True)\n",
    "top_level_windows # IndexedOrderedDict([('DockClassWindow', <PyQt5.QtGui.QWindow object at 0x000001F7383E9670>), ('qt_splithandle_Window', <PyQt5.QtGui.QWindow object at 0x000001F7383E9280>), ('PhoDockAreaContainingWindowClassWindow', <PyQt5.QtGui.QWindow object at 0x000001F7383E9550>), ('DockAreaClassWindow', <PyQt5.QtGui.QWindow object at 0x000001F7383E98B0>), ('VContainerClassWindow', <PyQt5.QtGui.QWindow object at 0x000001F7383E9430>), ('DockLabelClassWindow', <PyQt5.QtGui.QWindow object at 0x000001F7383D8AF0>), ('QWidgetClassWindow', <PyQt5.QtGui.QWindow object at 0x000001F7370CD280>), ('MainWindowClassWindow', <PyQt5.QtGui.QWindow object at 0x000001F7370CD160>), ('QFrameClassWindow', <PyQt5.QtGui.QWindow object at 0x000001F7370CD1F0>)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68e8968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Phodockareacontainingwindowclasswindow'\n",
    "\n",
    "for a_win_key, a_win in top_level_windows.items():\n",
    "\tprint(f'{a_win}')\n",
    "\t# print(f'\\t{a_win.title()}')\n",
    "\t# print(f'\\t{type(a_win)}')\n",
    "\tprint_widget_hierarchy(a_win, indent='\\t\\t')\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c90a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "searchType = 'PhoDockAreaContainingWindowClassWindow'\n",
    "top_level_windows_with_superclass_list = [a_widget for a_widget in top_level_windows if isinstance(a_widget, (searchType))]\n",
    "top_level_windows_with_superclass_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa48905",
   "metadata": {},
   "outputs": [],
   "source": [
    "'PhoDockAreaContainingWindowClassWindow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e518d238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_extended_computations\n",
    "\n",
    "curr_active_pipeline.reload_default_computation_functions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438fc995",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "extended_computations_include_includelist = ['pf_computation', 'pfdt_computation', 'long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding', \n",
    "    '_perform_time_dependent_pf_sequential_surprise_computation',\n",
    "     'long_short_rate_remapping',\n",
    "     'long_short_inst_spike_rate_groups'\n",
    "    ] # do only specifiedl , 'long_short_rate_remapping'\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True, force_recompute=False, debug_print=False)\n",
    "newly_computed_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bdf999",
   "metadata": {},
   "outputs": [],
   "source": [
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=['_perform_pf_find_ratemap_peaks_peak_prominence2d_computation'], included_computation_filter_names=['maze1', 'maze2', 'maze'], include_global_functions=True, fail_on_exception=True, progress_print=True, force_recompute=False, debug_print=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5f0719",
   "metadata": {},
   "outputs": [],
   "source": [
    "'_perform_long_short_endcap_analysis'\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=['_perform_long_short_endcap_analysis'], include_global_functions=True, fail_on_exception=True, progress_print=True, force_recompute=False, debug_print=False)\n",
    "newly_computed_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf82a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.updated_since_last_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0850fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "newly_computed_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68abe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "newly_computed_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec21cd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_remapping_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c131a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_remapping_df[['laps',\t'replays',\t'skew',\t'max_axis_distance_from_center', 'distance_from_center', 'has_considerable_remapping']] # drops ['neuron_type', 'render_color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce01cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.HDF5_representable import HDF_Converter\n",
    "\n",
    "file_path = 'output/test_rate_remapping_new.h5'\n",
    "\n",
    "session_context = curr_active_pipeline.get_session_context() \n",
    "session_group_key: str = \"/\" + session_context.get_description(separator=\"/\", include_property_names=False) # 'kdiba/gor01/one/2006-6-08_14-26-15'\n",
    "session_uid: str = session_context.get_description(separator=\"|\", include_property_names=False)\n",
    "## Global Computations\n",
    "a_global_computations_group_key: str = f\"{session_group_key}/global_computations\"\n",
    "with tb.open_file(file_path, mode='w') as f:\n",
    "    a_global_computations_group = f.create_group(session_group_key, 'global_computations', title='the result of computations that operate over many or all of the filters in the session.', createparents=True)\n",
    "\n",
    "\n",
    "# rate_remapping_df\n",
    "# rate_remapping_df = rate_remapping_df[['laps',\t'replays',\t'skew',\t'max_axis_distance_from_center',\t'distance_from_center', \t'has_considerable_remapping']]\n",
    "# # active_context = kwargs.pop('active_context', None) # TODO: requiring that the caller pass active_context isn't optimal\n",
    "# active_context = session_context\n",
    "# rate_remapping_df = HDF_Converter.prepare_neuron_indexed_dataframe_for_hdf(rate_remapping_df, active_context=active_context, aclu_column_name=None)\n",
    "# # rate_remapping_df.to_hdf(file_path, key=f'{key}/rate_remapping_df', format='table', data_columns=True)\n",
    "curr_long_short_rr.to_hdf(file_path, key=f'{a_global_computations_group_key}/rate_remapping', active_context=curr_active_pipeline.get_session_context())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e0b2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.global_computation_results_pickle_path\n",
    "# curr_active_pipeline.pickle_path\n",
    "curr_active_pipeline.get_output_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468420ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "outman = curr_active_pipeline.get_output_manager()\n",
    "figure_output_path = outman.get_figure_save_file_path(curr_active_pipeline.get_session_context(), make_folder_if_needed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9642b886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.placefield import plot_1d_placecell_validations\n",
    "\n",
    "# curr_active_pipeline.plotting_config\n",
    "active_session_configuration_name = global_epoch_name\n",
    "active_config = curr_active_pipeline.active_configs[active_session_configuration_name]\n",
    "\n",
    "_out = plot_1d_placecell_validations(global_pf1D, active_config.plotting_config, modifier_string='lap_only', should_save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ccae3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a95d130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out.figures[0].show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3086b2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.to_hdf('output/test_pipeline_fixed.h5', key='/')\n",
    "# TypeError: objects of type ``list`` are not supported in this context, sorry; supported objects are: NumPy array, record or scalar\n",
    "# for flattened_spike\n",
    "# .infer_objects()\n",
    "\n",
    "# curr_active_pipeline.export_pipeline_to_h5()\n",
    "# self.to_hdf(file_path=hdf5_output_path, key=\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f55395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.session.dataSession import DataSession\n",
    "\n",
    "## Test saaving sessions\n",
    "sess: DataSession = deepcopy(curr_active_pipeline.sess)\n",
    "sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fa4d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.to_hdf('output/test_sess.h5', key='/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64c4d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.laps\n",
    "# sess.ripples\n",
    "sess.pbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac39469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# historical_snapshots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e90ffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure pickling is okay with pf1D_dt\n",
    "global_pf1D_dt.to_hdf('output/test_global_pf1D_dt.h5', key='global_pf1D_dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4d25bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "override_pickle_path: Path = Path('output/test_pipeline.pkl').resolve()\n",
    "override_pickle_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21766da",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_extended_stats = curr_active_pipeline.computation_results['maze'].computed_data['extended_stats']\n",
    "active_extended_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fce55d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_relative_entropy_results = active_extended_stats['relative_entropy_analyses']\n",
    "post_update_times = active_relative_entropy_results['post_update_times']\n",
    "snapshot_differences_result_dict = active_relative_entropy_results['snapshot_differences_result_dict']\n",
    "time_intervals = active_relative_entropy_results['time_intervals']\n",
    "long_short_rel_entr_curves_frames = active_relative_entropy_results['long_short_rel_entr_curves_frames']\n",
    "short_long_rel_entr_curves_frames = active_relative_entropy_results['short_long_rel_entr_curves_frames']\n",
    "flat_relative_entropy_results = active_relative_entropy_results['flat_relative_entropy_results']\n",
    "flat_jensen_shannon_distance_results = active_relative_entropy_results['flat_jensen_shannon_distance_results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcce2c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(active_relative_entropy_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e84671f",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_pf1D_dt.plot_ratemaps_1D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fd7967",
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuronExtendedIdentityTuple(shank=10, cluster=10, id=87),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d527d34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(long_pf1D.included_neuron_IDs).index(87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c794035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_pf1D.plot_all(87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2842b293",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_pf1D.plotRaw_v_time(87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc03468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display('_display_batch_pho_jonathan_replay_firing_rate_comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a98c74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "PAPER_FIGURE_figure_3(curr_active_pipeline, defer_render=False, save_figure=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaef94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import SplitPartitionMembership\n",
    "from neuropy.core.neurons import NeuronType\n",
    "from neuropy.utils.mixins.HDF5_representable import HDF_Converter\n",
    "\n",
    "# Generate the unique aclus\n",
    "_neuron_replay_stats_df = deepcopy(jonathan_firing_rate_analysis_result.neuron_replay_stats_df)\n",
    "_neuron_replay_stats_df\n",
    "\n",
    "# _neuron_replay_stats_df = prepare_neuron_indexed_dataframe_for_hdf(_neuron_replay_stats_df, active_context=curr_active_pipeline.get_session_context(), aclu_column_name=None)\n",
    "\n",
    "\n",
    "_neuron_replay_stats_df = HDF_Converter.prepare_neuron_indexed_dataframe_for_hdf(_neuron_replay_stats_df, active_context=curr_active_pipeline.get_session_context(), aclu_column_name=None)\n",
    "\n",
    "\n",
    "\n",
    "# active_context = curr_active_pipeline.get_session_context()\n",
    "# sess_specific_aclus = list(_neuron_replay_stats_df.index.to_numpy())\n",
    "# session_ctxt_key:str = active_context.get_description(separator='|', subset_includelist=IdentifyingContext._get_session_context_keys())\n",
    "\n",
    "# # Adds column columns=['neuron_uid', 'session_uid', 'aclu']\n",
    "# _neuron_replay_stats_df['aclu'] = sess_specific_aclus # _neuron_replay_stats_df.index.to_numpy() # add explicit 'aclu' column from index\n",
    "# _neuron_replay_stats_df['session_uid'] = session_ctxt_key # add fixed 'session_uid' column \n",
    "# _neuron_replay_stats_df['neuron_uid'] = [f\"{session_ctxt_key}|{aclu}\" for aclu in sess_specific_aclus]\n",
    "_neuron_replay_stats_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a96980c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3725c6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# _out = curr_active_pipeline.last_added_display_output\n",
    "# Showing\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "_out = curr_active_pipeline.display('_display_long_short_expected_v_observed_firing_rate', max_num_rows=10)\n",
    "# a_fig = _out.figures[0]\n",
    "# a_fig.show()\n",
    "# .show()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bee8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_v_observed_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff1bc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_remapping_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfc81e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use the `long_short_decoding_analyses` global result to access `long_results_obj.active_filter_epochs`:\n",
    "curr_long_short_decoding_analyses = curr_active_pipeline.global_computation_results.computed_data['long_short_leave_one_out_decoding_analysis']\n",
    "long_one_step_decoder_1D, short_one_step_decoder_1D, long_replays, short_replays, global_replays, long_shared_aclus_only_decoder, short_shared_aclus_only_decoder, shared_aclus, long_short_pf_neurons_diff, n_neurons, long_results_obj, short_results_obj, is_global = curr_long_short_decoding_analyses.long_decoder, curr_long_short_decoding_analyses.short_decoder, curr_long_short_decoding_analyses.long_replays, curr_long_short_decoding_analyses.short_replays, curr_long_short_decoding_analyses.global_replays, curr_long_short_decoding_analyses.long_shared_aclus_only_decoder, curr_long_short_decoding_analyses.short_shared_aclus_only_decoder, curr_long_short_decoding_analyses.shared_aclus, curr_long_short_decoding_analyses.long_short_pf_neurons_diff, curr_long_short_decoding_analyses.n_neurons, curr_long_short_decoding_analyses.long_results_obj, curr_long_short_decoding_analyses.short_results_obj, curr_long_short_decoding_analyses.is_global\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e29b1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratemap\n",
    "# ratemap = deepcopy(long_pf1D.ratemap)\n",
    "\n",
    "ratemap: Ratemap = deepcopy(long_pf2D.ratemap)\n",
    "ratemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3eb175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot long|short firing rate index:\n",
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "x_frs_index, y_frs_index = long_short_fr_indicies_analysis_results['x_frs_index'], long_short_fr_indicies_analysis_results['y_frs_index'] # use the all_results_dict as the computed data value\n",
    "active_context = long_short_fr_indicies_analysis_results['active_context']\n",
    "\n",
    "# final_context = active_context.adding_context('display_fn', display_fn_name='display_long_short_laps')\n",
    "# fig = _plot_long_short_firing_rate_indicies(x_frs_index, y_frs_index, final_context, debug_print=debug_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf62bcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_short_fr_indicies_analysis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fe874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_test_file_path = Path(f'output/test_long_short_fr_indicies_analysis_results.h5').resolve()\n",
    "h5_test_file_path\n",
    "long_short_fr_indicies_analysis_results.to_hdf(h5_test_file_path, key='long_short_fr_indicies_analysis_results')\n",
    "\n",
    "# jonathan_firing_rate_analysis_result.is_hdf_serializable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887a4964",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "h5_test_file_path = Path(f'output/test_long_short_decoding_analyses.h5').resolve()\n",
    "h5_test_file_path\n",
    "curr_long_short_decoding_analyses.to_hdf(h5_test_file_path, key='long_short_decoding_analyses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5d993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import LeaveOneOutDecodingResult, LeaveOneOutDecodingAnalysisResult, TimebinnedNeuronActivity, _convert_dict_to_hdf_attrs_fn\n",
    "\n",
    "# curr_long_short_decoding_analyses.long_results_obj.new_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a593865",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f'type(curr_long_short_decoding_analyses.long_results_obj): {type(curr_long_short_decoding_analyses.long_results_obj)}')\n",
    "h5_test_file_path = Path(f'output/test_LeaveOneOutDecodingAnalysisResult.h5').resolve()\n",
    "curr_long_short_decoding_analyses.long_results_obj.to_hdf(h5_test_file_path, key='long_results_obj')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefe4a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_long_short_decoding_analyses.short_results_obj.to_hdf(h5_test_file_path, key='short_results_obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4985e323",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "_obj = deepcopy(curr_long_short_decoding_analyses.long_results_obj.timebinned_neuron_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10c1cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.hstack((_obj.active_IDXs, _obj.inactive_IDXs))\n",
    "\n",
    "[np.hstack((a_v, i_v)) for a_v, i_v in zip(_obj.active_IDXs, _obj.inactive_IDXs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90541e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TimebinnedNeuronActivity\n",
    "h5_test_file_path = Path(f'output/test_TimebinnedNeuronActivity.h5').resolve()\n",
    "curr_long_short_decoding_analyses.long_results_obj.timebinned_neuron_info.to_hdf(h5_test_file_path, key='timebinned_neuron_info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57c067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'type(curr_long_short_decoding_analyses.long_results_obj.new_result): {type(curr_long_short_decoding_analyses.long_results_obj.new_result)}')\n",
    "h5_test_file_path = Path(f'output/test_LeaveOneOutDecodingResult.h5').resolve()\n",
    "curr_long_short_decoding_analyses.long_results_obj.new_result.to_hdf(h5_test_file_path, key='new_result', file_mode='r+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564e4bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_long_short_decoding_analyses.short_results_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e98dfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.rdf.rdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a028cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import SplitPartitionMembership\n",
    "from neuropy.core.neurons import NeuronType\n",
    "\n",
    "jonathan_firing_rate_analysis_result.neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccf5fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "\n",
    "h5_test_file_path = Path(f'output/test_jonathan_firing_rate_analysis_result.h5').resolve()\n",
    "h5_test_file_path\n",
    "jonathan_firing_rate_analysis_result.to_hdf(h5_test_file_path, key='jonathan_firing_rate_analysis_result')\n",
    "\n",
    "# jonathan_firing_rate_analysis_result.is_hdf_serializable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4506ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "aclu_to_idx = jonathan_firing_rate_analysis_result.rdf.aclu_to_idx\n",
    "aclu_to_idx_df: pd.DataFrame = pd.DataFrame({'aclu': list(aclu_to_idx.keys()), 'fragile_linear_idx': list(aclu_to_idx.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a867b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I wanna look at the suprise metrics again please.\n",
    "\n",
    "# can align each of the sessions (across days) to the track transition point (the \"Delta\") as the zero.\n",
    "\n",
    "# print_keys_if_possible(\"global_computation_results\", curr_active_pipeline.global_computation_results, max_depth=2)\n",
    "\n",
    "# computed_data: pyphocorehelpers.DataStructure.dynamic_parameters.DynamicParameters\n",
    "# \t\t    jonathan_firing_rate_analysis: pyphocorehelpers.DataStructure.dynamic_parameters.DynamicParameters\n",
    "# \t\t    long_short_fr_indicies_analysis: pyphocorehelpers.DataStructure.dynamic_parameters.DynamicParameters\n",
    "# \t\t    long_short_leave_one_out_decoding_analysis: pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.LeaveOneOutDecodingAnalysis\n",
    "# \t\t    long_short_post_decoding: pyphocorehelpers.DataStructure.dynamic_parameters.DynamicParameters\n",
    "\n",
    "\n",
    "print_keys_if_possible(\"global_computation_results\", curr_active_pipeline.global_computation_results.computed_data, max_depth=3)\n",
    "\n",
    "# jonathan_firing_rate_analysis_result.rdf\n",
    "\n",
    "# long_short_leave_one_out_decoding_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d775a6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computed_data.long_short_fr_indicies_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e6c297",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computed_data.long_short_post_decoding.expected_v_observed_result\n",
    "# curr_active_pipeline.global_computation_results.computed_data.long_short_post_decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab6f97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed529276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterative partition\n",
    "curr_active_pipeline.global_computation_results.computed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1267131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computed_data.long_short_post_decoding.expected_v_observed_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511f54b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computed_data.long_short_post_decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f26386",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computed_data.long_short_post_decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccdbb13",
   "metadata": {
    "tags": [
     "NOW",
     "across_sessions",
     "table"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsResults, InstantaneousFiringRatesDataframeAccessor, InstantaneousSpikeRateGroupsComputation, trackMembershipTypesEnum, trackExclusiveToMembershipTypeDict, trackExclusiveToMembershipTypeReverseDict\n",
    "\n",
    "# ## Specify the output file:\n",
    "# common_file_path = Path('output/test_across_session_scatter_plot_new.h5')\n",
    "# print(f'common_file_path: {common_file_path}')\n",
    "# InstantaneousFiringRatesDataframeAccessor.add_results_to_inst_fr_results_table(curr_active_pipeline, common_file_path, file_mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d33a7c",
   "metadata": {
    "tags": [
     "NOW",
     "load",
     "plot"
    ]
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from pyphocorehelpers.indexing_helpers import partition, safe_pandas_get_group\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import InstantaneousFiringRatesDataframeAccessor, AcrossSessionsVisualizations\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import SingleBarResult\n",
    "\n",
    "common_file_path = Path('output/active_across_session_scatter_plot_results.h5')\n",
    "print(f'common_file_path: {common_file_path}')\n",
    "\n",
    "# InstantaneousSpikeRateGroupsComputation, : pd.DataFrame\n",
    "_shell_obj, loaded_result_df = InstantaneousFiringRatesDataframeAccessor.load_and_prepare_for_plot(common_file_path)\n",
    "# Perform the actual plotting:\n",
    "AcrossSessionsVisualizations.across_sessions_bar_graphs(_shell_obj, num_sessions=13, save_figure=False, enable_tiny_point_labels=False, enable_hover_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb580a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "maximum_timedelta: timedelta = timedelta(1, 0, 0) # 1 Day maximum time\n",
    "delta_since_last_compute: timedelta = curr_active_pipeline.get_time_since_last_computation()\n",
    "print(f'delta_since_last_compute: {delta_since_last_compute}')\n",
    "needs_recompute: bool = delta_since_last_compute > maximum_timedelta\n",
    "print(f'\\tneeds_recompute: {needs_recompute}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624326b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Serialization of preprocessing parameters test\n",
    "file_path = 'output/preprocessing_parameters.h5'\n",
    "\n",
    "with h5py.File(file_path, \"w\") as f:\n",
    "\tpreprocessing_group = f.create_group(\"preprocessing_parameters\")\n",
    "\n",
    "\t# Serialize epoch_estimation_parameters\n",
    "\tepoch_estimation_group = preprocessing_group.create_group(\"epoch_estimation_parameters\")\n",
    "\n",
    "\tlaps_group = epoch_estimation_group.create_group(\"laps\")\n",
    "\tlaps_group.attrs[\"N\"] = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"laps\"][\"N\"]\n",
    "\tlaps_group.attrs[\"should_backup_extant_laps_obj\"] = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"laps\"][\"should_backup_extant_laps_obj\"]\n",
    "\n",
    "\tPBEs_group = epoch_estimation_group.create_group(\"PBEs\")\n",
    "\tPBEs_group.attrs[\"thresh\"] = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"PBEs\"][\"thresh\"]\n",
    "\tPBEs_group.attrs[\"min_dur\"] = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"PBEs\"][\"min_dur\"]\n",
    "\tPBEs_group.attrs[\"merge_dur\"] = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"PBEs\"][\"merge_dur\"]\n",
    "\tPBEs_group.attrs[\"max_dur\"] = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"PBEs\"][\"max_dur\"]\n",
    "\n",
    "\treplays_group = epoch_estimation_group.create_group(\"replays\")\n",
    "\treplay_data = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"replays\"]\n",
    "\t# replay_dataframe = pd.DataFrame(replay_data)\n",
    "\t# replay_data.to_hdf(f, \"/preprocessing_parameters/epoch_estimation_parameters/replays\")\n",
    "\t## TODO: add the data here using Epoch's .to_hdf\n",
    "\t\n",
    "\t# Check for \"None\" values before setting attributes\n",
    "\tdef check_and_set(key, value):\n",
    "\t\tif value is not None:\n",
    "\t\t\treplays_group.attrs[key] = value\n",
    "\n",
    "\t# Set attributes if not \"None\", otherwise skip writing\n",
    "\tcheck_and_set(\"min_epoch_included_duration\", preprocessing_parameters_dict[\"epoch_estimation_parameters\"].get('replays', {}).get(\"min_epoch_included_duration\"))\n",
    "\tcheck_and_set(\"max_epoch_included_duration\", preprocessing_parameters_dict[\"epoch_estimation_parameters\"].get('replays', {}).get(\"max_epoch_included_duration\"))\n",
    "\tcheck_and_set(\"maximum_speed_thresh\", preprocessing_parameters_dict[\"epoch_estimation_parameters\"].get('replays', {}).get(\"maximum_speed_thresh\"))\n",
    "\tcheck_and_set(\"min_inclusion_fr_active_thresh\", preprocessing_parameters_dict[\"epoch_estimation_parameters\"].get('replays', {}).get(\"min_inclusion_fr_active_thresh\"))\n",
    "\tcheck_and_set(\"min_num_unique_aclu_inclusions\", preprocessing_parameters_dict[\"epoch_estimation_parameters\"].get('replays', {}).get(\"min_num_unique_aclu_inclusions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc30a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_default_neptune_plots = False\n",
    "# enable_default_neptune_plots = True\n",
    "\n",
    "## To file only:\n",
    "with matplotlib_file_only():\n",
    "\t# Perform non-interactive Matplotlib operations with 'AGG' backend\n",
    "\tmain_complete_figure_generations(curr_active_pipeline, enable_default_neptune_plots=enable_default_neptune_plots, save_figures_only=True, save_figure=True)\n",
    "\n",
    "## Clear the Programmatically open figures:\n",
    "plt.close('all') # this takes care of the matplotlib-backed figures.\n",
    "curr_active_pipeline.clear_display_outputs()\n",
    "curr_active_pipeline.clear_registered_output_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44783dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "# Perform interactive Matplotlib operations with 'Qt5Agg' backend\n",
    "_out_figures = main_complete_figure_generations(curr_active_pipeline, enable_default_neptune_plots=False, save_figures_only=False, save_figure=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943b8f18",
   "metadata": {},
   "source": [
    "# Common Display Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef70fb2",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": [
     "plot_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# configure backend here\n",
    "matplotlib.use('Qt5Agg')\n",
    "# backend_qt5agg\n",
    "# %matplotlib qt5\n",
    "# %matplotlib qt\n",
    "# matplotlib.use('AGG') # non-interactive backend ## 2022-08-16 - Surprisingly this works to make the matplotlib figures render only to .png file, not appear on the screen!\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "# mpl.rcParams['toolbar'] = 'None' # disable toolbars\n",
    "\n",
    "# Showing\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fbf214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pylustrator # customization of figures\n",
    "import matplotlib\n",
    "# configure backend here\n",
    "matplotlib.use('Qt5Agg')\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "import pylustrator # call `pylustrator.start()` before creating your first figure in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530208a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pylustrator.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8eddbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b490781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot The laps:\n",
    "from neuropy.utils.matplotlib_helpers import plot_position_curves_figure\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.laps import plot_laps_2d\n",
    "pylustrator.start()\n",
    "fig, out_axes_list = plot_laps_2d(global_session, legacy_plotting_mode=False, include_velocity=False, include_accel=False, figsize=(24, 10))\n",
    "out_axes_list[0].set_title('Estimated Laps')\n",
    "fig.canvas.manager.set_window_title('Estimated Laps')\n",
    "ax = out_axes_list[0]\n",
    "ax.set_xlim((1036.242685185441, 1441.769668184419))\n",
    "\n",
    "# Hide y-axis ticklabels\n",
    "plt.tick_params(axis='y', which='both', labelleft=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb32cee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "ax = fig.axes[0]\n",
    "ax\n",
    "ax.get_xlim()\n",
    "\n",
    "\n",
    "laps_example_region_xlims = (1036.242685185441, 1441.769668184419)\n",
    "\n",
    "fig, out_axes_list = plot_position_curves_figure(global_session.position, include_velocity=False, include_accel=False, figsize=(24, 10))\n",
    "\n",
    "_out1 = curr_active_pipeline.display('_display_long_short_laps', include_velocity=False, include_accel=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475b2e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c59882",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.plot._display_decoder_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9737539d",
   "metadata": {},
   "source": [
    "# 2023-09-07 - Track Graphics Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a866b1b",
   "metadata": {
    "tags": [
     "ACTIVE",
     "track_graphics"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphocorehelpers.geometry_helpers import BoundsRect, point_tuple_mid_point, map_value\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import LinearTrackDimensions\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import add_vertical_track_bounds_lines, add_track_shapes, test_LinearTrackDimensions_2D_pyqtgraph\n",
    "from neuropy.utils.mathutil import contiguous_regions, threshPeriods, compute_grid_bin_bounds, map_value\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import test_LinearTrackDimensions_2D_Matplotlib\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import LinearTrackInstance\n",
    "\n",
    "grid_bin_bounds = BoundsRect.init_from_grid_bin_bounds(global_pf2D.config.grid_bin_bounds)\n",
    "display(grid_bin_bounds)\n",
    "\n",
    "# long_track_dims = LinearTrackDimensions.init_from_grid_bin_bounds(grid_bin_bounds)\n",
    "# short_track_dims = LinearTrackDimensions.init_from_grid_bin_bounds(grid_bin_bounds)\n",
    "\n",
    "long_track_dims = LinearTrackDimensions(track_length=170.0)\n",
    "short_track_dims = LinearTrackDimensions(track_length=100.0)\n",
    "\n",
    "common_1D_platform_height = 0.25\n",
    "common_1D_track_height = 0.1\n",
    "long_track_dims.minor_axis_platform_side_width = common_1D_platform_height\n",
    "long_track_dims.track_width = common_1D_track_height # (short_track_dims.minor_axis_platform_side_width\n",
    "\n",
    "short_track_dims.minor_axis_platform_side_width = common_1D_platform_height\n",
    "short_track_dims.track_width = common_1D_track_height # (short_track_dims.minor_axis_platform_side_width\n",
    "\n",
    "# instances:\n",
    "long_track = LinearTrackInstance(long_track_dims, grid_bin_bounds=grid_bin_bounds)\n",
    "short_track = LinearTrackInstance(short_track_dims, grid_bin_bounds=grid_bin_bounds)\n",
    "\n",
    "print(long_track_dims)\n",
    "print(short_track_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c12b684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "\n",
    "# global_pf1D_dt.config.grid_bin_bounds\n",
    "\n",
    "\n",
    "def napari_add_grid_bin_bounds_rect(viewer: napari.viewer.Viewer, grid_bin_bounds):\n",
    "\t\"\"\" adds the animal's position as a track and a point layer to the napari viewer.\n",
    "\n",
    "\n",
    "\tUsage:\n",
    "\n",
    "\tfrom pyphoplacecellanalysis.GUI.Napari.napari_helpers import napari_add_animal_position\n",
    "\tnapari_add_animal_position(viewer=viewer, position_df=global_pf1D_dt.all_time_filtered_pos_df[['t','x','binned_x']], time_intervals)\n",
    "\n",
    "\n",
    "\t\"\"\"\n",
    "\t# rect = np.array([[0, 0], [3, 1]])\n",
    "\tgrid_bin_bounds_rect = grid_bin_bounds\n",
    "\tviewer.add_shapes(grid_bin_bounds_rect, shape_type='grid_bin_bounds_rect', edge_width=0.1)\n",
    "    \n",
    "napari_add_grid_bin_bounds_rect(viewer, grid_bin_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b29b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For napari need to map onto xbins axis:\n",
    "#TODO: Not working, did manual rect drawing below instead.\n",
    "\n",
    "assert len(viewer.dims.range) == 3\n",
    "t_range_tuple, neuron_id_range_tuple, xbin_range_tuple = viewer.dims.range\n",
    "# ((0.0, 3309.0, 1.0),\n",
    "#  (-0.2906298631133275, 85.0, 1.0),\n",
    "#  (-0.24635407377607876, 108.0, 1.0))\n",
    "xbin_min, xbin_max = (xbin_range_tuple[0], (xbin_range_tuple[1]-xbin_range_tuple[2])) # the max range isn't included, so we need to subtract off the step to get the real max\n",
    "xbin_width = (xbin_max - xbin_min) # total width in number of xbins\n",
    "x_to_xbins_multiplier: float = xbin_width/grid_bin_bounds.size[0] # multiply a number in normal coordinates to get the equivalent number of xbins\n",
    "x_to_xbins_multiplier\n",
    "\n",
    "map_track_coords_to_xbins_space = lambda v: map_value(v, (grid_bin_bounds.xmin, grid_bin_bounds.xmax), (xbin_min, xbin_max)) # same map\n",
    "# map_track_coords_to_ybins_space = lambda v: map_value(v, (grid_bin_bounds.ymin, grid_bin_bounds.ymax), (ybin_min, ybin_max)) # same map\n",
    "\n",
    "bin_space_grid_bin_bounds = deepcopy(grid_bin_bounds)\n",
    "bin_space_grid_bin_bounds.xmin = map_track_coords_to_xbins_space(grid_bin_bounds.xmin)\n",
    "bin_space_grid_bin_bounds.xmax = map_track_coords_to_xbins_space(grid_bin_bounds.xmax)\n",
    "\n",
    "bin_space_grid_bin_bounds.ymin = 0.0\n",
    "bin_space_grid_bin_bounds.ymax = 5.0\n",
    "\n",
    "bin_space_grid_bin_bounds\n",
    "\n",
    "# map_track_coords_to_xbins_space(grid_bin_bounds.xmin), map_track_coords_to_xbins_space(grid_bin_bounds.xmax)\n",
    "# bin_space_long_track_dims = LinearTrackDimensions.init_from_grid_bin_bounds(bin_space_grid_bin_bounds)\n",
    "# bin_space_short_track_dims = LinearTrackDimensions.init_from_grid_bin_bounds(bin_space_grid_bin_bounds)\n",
    "\n",
    "# common_1D_platform_height = 0.25\n",
    "# common_1D_track_height = 0.1\n",
    "# bin_space_long_track_dims.minor_axis_platform_side_width = common_1D_platform_height\n",
    "# bin_space_long_track_dims.track_width = common_1D_track_height # (short_track_dims.minor_axis_platform_side_width\n",
    "\n",
    "# bin_space_short_track_dims.minor_axis_platform_side_width = common_1D_platform_height\n",
    "# bin_space_short_track_dims.track_width = common_1D_track_height # (short_track_dims.minor_axis_platform_side_width\n",
    "\n",
    "bin_space_long_track_dims = deepcopy(long_track_dims)\n",
    "bin_space_short_track_dims = deepcopy(short_track_dims)\n",
    "\n",
    "bin_space_long_track_dims.axis_scale_factors = (x_to_xbins_multiplier, 1.0)\n",
    "bin_space_short_track_dims.axis_scale_factors = (x_to_xbins_multiplier, 1.0)\n",
    "\n",
    "bin_space_long_track = LinearTrackInstance(bin_space_long_track_dims, grid_bin_bounds=bin_space_grid_bin_bounds)\n",
    "bin_space_short_track = LinearTrackInstance(bin_space_short_track_dims, grid_bin_bounds=bin_space_grid_bin_bounds)\n",
    "\n",
    "bin_space_short_track\n",
    "\n",
    "t_range_tuple, neuron_id_range_tuple, xbin_range_tuple = viewer.dims.range\n",
    "t_range_tuple\n",
    "\n",
    "\n",
    "bin_space_grid_bin_bounds\n",
    "half_xbin_width = float(xbin_width)/2.0\n",
    "half_xbin_width\n",
    "bin_space_short_track.track_dimensions.scaled_total_length\n",
    "# vertices are top-left and bottom-right corners\n",
    "# [(x, 0.0, w, h) for x, y, w, h, *_unused in bin_space_short_track.rects]\n",
    "# short_track_rectangle_data = [BoundsRect.init_from_x_y_w_h_tuple((x+np.abs(x), y, w, h)).corner_points for x, y, w, h, *_unused in bin_space_short_track.rects]\n",
    "short_track_rectangle_data = [np.hstack((np.zeros((4,1)), BoundsRect.init_from_x_y_w_h_tuple((x+half_xbin_width, y, w, h)).corner_points))[:, :][:, [0, 2, 1]] for x, y, w, h, *_unused in bin_space_short_track.rects]\n",
    "long_track_rectangle_data = np.vstack([np.hstack((np.zeros((4,1)), BoundsRect.init_from_x_y_w_h_tuple((x+half_xbin_width, y, w, h)).corner_points))[:, [0, 2, 1]] for x, y, w, h, *_unused in bin_space_long_track.rects])\n",
    "\n",
    "# short_track_rectangle_data = np.vstack(short_track_rectangle_data)\n",
    "short_track_rectangle_data\n",
    "\n",
    "# array([[0, 2.375, 35], # bottom-left\n",
    "    #    [0, 2.625, 35], # bottom-right\n",
    "    #    [0, 2.375, 46.112], # top-left\n",
    "    #    [0, 2.625, 46.112], # top-right\n",
    "\n",
    "# [0,2,3,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb201f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# sync_point_y = -0.750314\n",
    "sync_point_y = 0.0 # the bottom (y-axis) value of the track\n",
    "track_platform_height_y = -5.19389 # the top coordinate (y-axis) value of the platforms\n",
    "\n",
    "## Time indicies for tracks:\n",
    "time_index = 0\n",
    "long_short_change_time_index = 2097 # APPROXIMATE\n",
    "t_range_tuple, neuron_id_range_tuple, xbin_range_tuple = viewer.dims.range\n",
    "long_time_indicies = np.arange(t_range_tuple[0], long_short_change_time_index)\n",
    "short_time_indicies = np.arange(long_short_change_time_index, (t_range_tuple[1]-t_range_tuple[2]))\n",
    "\n",
    "### Long Track Shape Layer:\n",
    "# Where the platform and the track connect:\n",
    "track_platform_connect_x_min = 14.157\n",
    "track_platform_connect_x_max = 91.6898\n",
    "long_track_shapes_data = list(itertools.chain.from_iterable([\n",
    "[\n",
    "np.array([[time_index, track_platform_height_y, track_platform_connect_x_max],\n",
    "        [time_index, track_platform_height_y, 106.093],\n",
    "        [time_index, sync_point_y, 106.093],\n",
    "        [time_index, sync_point_y, track_platform_connect_x_max]]),\n",
    " np.array([[time_index, -3.66162, 14.0037],\n",
    "        [time_index, -3.66162, track_platform_connect_x_max],\n",
    "        [time_index, sync_point_y, track_platform_connect_x_max],\n",
    "        [time_index, sync_point_y, 14.0037]]),\n",
    " np.array([[time_index, track_platform_height_y, -0.246354],\n",
    "        [time_index, track_platform_height_y, track_platform_connect_x_min],\n",
    "        [time_index, sync_point_y, track_platform_connect_x_min],\n",
    "        [time_index, sync_point_y, -0.246354]])\n",
    "]\n",
    "for time_index in long_time_indicies]))\n",
    "long_track_shapes_layer = viewer.add_shapes(long_track_shapes_data, shape_type='rectangle', name='long_track', edge_width=0, face_color='#aa0000ff')\n",
    "long_track_shapes_layer.editable = False\n",
    "\n",
    "\n",
    "### Short Track Shape Layer:\n",
    "# Where the platform and the track connect:\n",
    "track_platform_connect_x_min = 28.2539\n",
    "track_platform_connect_x_max = 73.7623\n",
    "\n",
    "short_track_shapes_data =  list(itertools.chain.from_iterable([\n",
    "[\n",
    "np.array([[time_index, track_platform_height_y, track_platform_connect_x_max],\n",
    "        [time_index, track_platform_height_y, 88.1655],\n",
    "        [time_index, sync_point_y, 88.1655],\n",
    "        [time_index, sync_point_y, track_platform_connect_x_max]]),\n",
    "np.array([[time_index, -3.66162, 28.1006],\n",
    "        [time_index, -3.66162, track_platform_connect_x_max],\n",
    "        [time_index, sync_point_y, track_platform_connect_x_max],\n",
    "        [time_index, sync_point_y, 28.1006]]),\n",
    "np.array([[time_index, track_platform_height_y, 13.8505],\n",
    "        [time_index, track_platform_height_y, track_platform_connect_x_min],\n",
    "        [time_index, sync_point_y, track_platform_connect_x_min],\n",
    "        [time_index, sync_point_y, 13.8505]])\n",
    "]\n",
    "for time_index in short_time_indicies]))\n",
    "\n",
    "short_track_shapes_layer = viewer.add_shapes(short_track_shapes_data, shape_type='rectangle', name='short_track', edge_width=0, face_color='royalblue')\n",
    "short_track_shapes_layer.editable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7499fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b12bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_track_shapes_layer.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc1240f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes_layer = viewer.layers['short_track_rectangle_data']\n",
    "shapes_layer.data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb9ebf9",
   "metadata": {},
   "source": [
    "# Test classifying various x-positions as belonging to outside the outside_maze, the track_endcaps, or the track_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce4a39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_rects_outputs, short_rects_outputs = add_track_shapes(grid_bin_bounds, ax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7494b78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long_offset=(150.0, 0.5)\n",
    "# short_offset=(150.0, -0.5)\n",
    "\n",
    "long_offset=(grid_bin_bounds.center_point[0], 0.5)\n",
    "short_offset=(grid_bin_bounds.center_point[0], -0.5)\n",
    "\n",
    "# # Create a second y-axis sharing the same x-axis as ax\n",
    "# ax2 = ax.twinx()\n",
    "# # ax2.plot(x, y2, 'b-')\n",
    "# ax2.set_ylabel('Track data', color='b')\n",
    "# # Set the adjustable attribute to 'datalim'\n",
    "# ax.set_adjustable('datalim')\n",
    "# ax2.set_adjustable('datalim')\n",
    "# long_track_dims.plot_rects(ax2, offset=long_offset)\n",
    "# short_track_dims.plot_rects(ax2, offset=short_offset)\n",
    "\n",
    "combined_item, rect_items, rects = long_track_dims.plot_rects(ax, offset=long_offset)\n",
    "short_track_dims.plot_rects(ax, offset=short_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36198209",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1, ax2 = test_LinearTrackDimensions_2D_Matplotlib(long_track_dims, short_track_dims, long_offset=(150.0, 0.5), short_offset=(150.0, -0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5840c779",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Find center from `grid_bin_bounds`\n",
    "# long_pf2D.bin_info\n",
    "grid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\n",
    "\n",
    "x_diff = (grid_bin_bounds[0][1] - grid_bin_bounds[0][0])\n",
    "y_diff = (grid_bin_bounds[1][1] - grid_bin_bounds[1][0])\n",
    "print(f'x_diff: {x_diff}, y_diff: {y_diff}')\n",
    "\n",
    "# Find the x, y midpoints:\n",
    "x_midpoint = grid_bin_bounds[0][0] + (x_diff/2.0)\n",
    "y_midpoint = grid_bin_bounds[1][0] + (y_diff/2.0)\n",
    "print(f'x_midpoint: {x_midpoint}, y_midpoint: {y_midpoint}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5185f516",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_bin_bounds_center_point = (point_tuple_mid_point(grid_bin_bounds[0]), point_tuple_mid_point(grid_bin_bounds[1])) # (145.43, 140.61)\n",
    "x_midpoint, y_midpoint = grid_bin_bounds_center_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5163e5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# long_track_dims.total_length # 214.0\n",
    "# short_track_dims.total_length # 144.0\n",
    "# zero_alignment_point = self.total_length/2.0\n",
    "long_notable_x_positions, _long_notable_y_positions = long_track_dims._build_component_notable_positions(offset_point=(x_midpoint, y_midpoint))\n",
    "short_notable_x_positions, _short_notable_y_positions = short_track_dims._build_component_notable_positions(offset_point=(x_midpoint, y_midpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc254a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _add_vertical_track_bounds_lines(grid_bin_bounds, ax=None):\n",
    "# \t\"\"\" \n",
    "# \tCaptures: long_notable_x_positions, short_notable_x_positions\n",
    "\t\n",
    "# \tUsage:\n",
    "# \t\tgrid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\n",
    "# \t\tlong_track_line_collection, short_track_line_collection = _add_vertical_track_bounds_lines(grid_bin_bounds=grid_bin_bounds, ax=ax)\n",
    "\n",
    "# \t\"\"\"\n",
    "# \tlong_track_dims = LinearTrackDimensions(track_length=170.0)\n",
    "# \tshort_track_dims = LinearTrackDimensions(track_length=100.0)\n",
    "\n",
    "# \t# Find center from `grid_bin_bounds` using `point_tuple_mid_point`\n",
    "# \tx_midpoint, y_midpoint = (point_tuple_mid_point(grid_bin_bounds[0]), point_tuple_mid_point(grid_bin_bounds[1])) # grid_bin_bounds_center_point: (145.43, 140.61)\n",
    "\n",
    "# \tlong_notable_x_positions, _long_notable_y_positions = long_track_dims._build_component_notable_positions(offset_point=(x_midpoint, y_midpoint))\n",
    "# \tshort_notable_x_positions, _short_notable_y_positions = short_track_dims._build_component_notable_positions(offset_point=(x_midpoint, y_midpoint))\n",
    "\n",
    "# \t# Omit the midpoint\n",
    "# \tlong_notable_x_platform_positions = long_notable_x_positions[[0,1,3,4]]\n",
    "# \tshort_notable_x_platform_positions = short_notable_x_positions[[0,1,3,4]]\n",
    "\n",
    "# \t## Adds to current axes:\n",
    "# \tif ax is None:\n",
    "# \t\tfig = plt.gcf()\n",
    "# \t\taxs = fig.get_axes()\n",
    "# \t\tax = axs[0]\n",
    "# \tlong_track_line_collection: matplotlib.collections.LineCollection = plt.vlines(long_notable_x_platform_positions, label='long_track_x_pos_lines', ymin=ax.get_ybound()[0], ymax=ax.get_ybound()[1], colors='#0000FFAA', linestyles='dashed') # matplotlib.collections.LineCollection\n",
    "# \tshort_track_line_collection: matplotlib.collections.LineCollection = plt.vlines(short_notable_x_platform_positions, label='short_track_x_pos_lines', ymin=ax.get_ybound()[0], ymax=ax.get_ybound()[1], colors='#FF0000AA', linestyles='dashed') # matplotlib.collections.LineCollection\n",
    "# \treturn long_track_line_collection, short_track_line_collection\n",
    "\n",
    "grid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\n",
    "long_track_line_collection, short_track_line_collection = add_vertical_track_bounds_lines(grid_bin_bounds=grid_bin_bounds, ax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2650ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect_items, rects = long_track_dims.plot_rects(axs[0]) # , offset=(x, y) # , offset=(0.1, 100.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20cfaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_track_line_collection.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7b24ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_track_line_collection.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdae8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_track_dims.plot_rects(ax, offset=)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8a25f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "axs = fig.get_axes()\n",
    "ax = axs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a48933",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_track_line_collection.remove()\n",
    "short_track_line_collection.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a142c83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.placefield import plot_1D_placecell_validation\n",
    "\n",
    "_out = plot_1D_placecell_validation(long_pf1D, 0)\n",
    "\n",
    "axes = _out[1]\n",
    "ax = axes[0]\n",
    "# ax = axes[1]\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff10cf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_track_dims = LinearTrackDimensions.init_from_grid_bin_bounds(grid_bin_bounds=grid_bin_bounds, debug_print=True)\n",
    "\n",
    "fig, axs = plt.subplots(2, 1)\n",
    "\n",
    "rect_items, rects = long_track_dims.plot_rects(axs[0]) # , offset=(x, y) # , offset=(0.1, 100.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5cf4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# long_track_dims.plot_rects(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4064c13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_grid_bin_bounds_validation', curr_active_pipeline.get_session_context(), defer_render=False, save_figure=True)\n",
    "fig = _out.figures[0]\n",
    "ax = _out.axes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1d9c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the bounding box coordinates and dimensions\n",
    "bbox = ax.bbox\n",
    "x, y, width, height = bbox.x0, bbox.y0, bbox.width, bbox.height\n",
    "x, y, width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b78ccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_empty = ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e6b7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect_items, rects = long_track_dims.plot_rects(ax_empty) # , offset=(x, y) # , offset=(0.1, 100.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1305f288",
   "metadata": {},
   "outputs": [],
   "source": [
    "(320.0, 983.7668560462606, 901.8181818181818, 91.99628790747863)\n",
    "active_track_dims = LinearTrackDimensions(width=901.8181818181818)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6645194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.transforms import Bbox\n",
    "\n",
    "# Step 2: Define a simple vector graphic (an arrow in this case)\n",
    "def draw_arrow(ax, x, y, width, height):\n",
    "    arrow = patches.FancyArrow(x, y, width, height, width=0.2*height, color=\"red\")\n",
    "    ax.add_patch(arrow)\n",
    "\n",
    "# Step 3: Scale and draw the arrow within a bounding box\n",
    "def draw_scaled_arrow_in_bbox(ax, bbox):\n",
    "    # Extract the bounding box coordinates and dimensions\n",
    "    x, y, width, height = bbox.x0, bbox.y0, bbox.width, bbox.height\n",
    "\n",
    "    # Draw the bounding box (for visualization)\n",
    "    rect = patches.Rectangle((x, y), width, height, linewidth=1, edgecolor='black', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "    # Draw the scaled arrow within the bounding box\n",
    "    draw_arrow(ax, x, y, width, height)\n",
    "\n",
    "# Main code\n",
    "fig, ax = plt.subplots()\n",
    "bbox = Bbox.from_bounds(0.2, 0.2, 0.6, 0.6)  # Define bounding box with [x, y, width, height]\n",
    "\n",
    "draw_scaled_arrow_in_bbox(ax, bbox)\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_aspect('equal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76364ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b365b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect_items[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea4f99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c8f5ab",
   "metadata": {},
   "source": [
    "# 2023-09-21 - Continuous Surprise Figure - How do I display it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dbe065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_perform_time_dependent_pf_sequential_surprise_computation'\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import plot_long_short_surprise_difference_plot, plot_long_short, plot_long_short_any_values\n",
    "from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import fig_surprise_results\n",
    "\n",
    "from neuropy.utils.matplotlib_helpers import draw_epoch_regions\n",
    "from pyphocorehelpers.DataStructure.RenderPlots.MatplotLibRenderPlots import MatplotlibRenderPlots\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import LongShortDisplayConfigManager\n",
    "long_short_display_config_manager = LongShortDisplayConfigManager()\n",
    "long_epoch_config = long_short_display_config_manager.long_epoch_config.as_matplotlib_kwargs()\n",
    "short_epoch_config = long_short_display_config_manager.short_epoch_config.as_matplotlib_kwargs()\n",
    "\n",
    "graphics_outputs_list = fig_surprise_results(curr_active_pipeline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d58220",
   "metadata": {},
   "source": [
    "### FOUND! 2023-09-21 - Found code that generated surprise plots, strangely not stored anywhere!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe7b982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: nSnapshots == n_post_update_times\n",
    "active_relative_entropy_results = active_extended_stats['pf_dt_sequential_surprise']\n",
    "post_update_times = active_relative_entropy_results['post_update_times'] # (4123,) = (nSnapshots,)\n",
    "snapshot_differences_result_dict = active_relative_entropy_results['snapshot_differences_result_dict']\n",
    "time_intervals = active_relative_entropy_results['time_intervals']\n",
    "long_short_rel_entr_curves_frames = active_relative_entropy_results['long_short_rel_entr_curves_frames'] # (4123, 108, 63) = (nSnapshots, n_neurons, n_xbins)\n",
    "short_long_rel_entr_curves_frames = active_relative_entropy_results['short_long_rel_entr_curves_frames'] # (4123, 108, 63) = (nSnapshots, n_neurons, n_xbins)\n",
    "flat_relative_entropy_results = active_relative_entropy_results['flat_relative_entropy_results'] # (4123, 63) - (nSnapshots, nXbins)\n",
    "flat_jensen_shannon_distance_results = active_relative_entropy_results['flat_jensen_shannon_distance_results'] # (4123, 63) - (nSnapshots, nXbins)\n",
    "flat_jensen_shannon_distance_across_all_positions = np.sum(np.abs(flat_jensen_shannon_distance_results), axis=1) # sum across all position bins # (4123,) - (nSnapshots)\n",
    "flat_surprise_across_all_positions = np.sum(np.abs(flat_relative_entropy_results), axis=1) # sum across all position bins # (4123,) - (nSnapshots)\n",
    "nSnapshots, n_neurons, n_xbins = np.shape(long_short_rel_entr_curves_frames)\n",
    "print(f'nSnapshots: {nSnapshots}, n_neurons: {n_neurons}, n_xbins: {n_xbins}') # nSnapshots: 3308, n_neurons: 85, n_xbins: 107"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1200faa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# post_update_times.shape\n",
    "# np.shape(post_update_times)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61282cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(flat_jensen_shannon_distance_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2d8d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(flat_relative_entropy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922a7718",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(flat_jensen_shannon_distance_across_all_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1194c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(long_short_rel_entr_curves_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a303ca32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7205c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTE: these results are NOT the same as the ones calculated in compute_snapshot_relative_entropy_surprise_differences.compute_surprise_relative_entropy_divergence, and I'm not quite sure why:\n",
    "# Jensen-Shannon distance is an average of KL divergence:\n",
    "from scipy.special import rel_entr\n",
    "mixture_distribution = 0.5 * (long_short_rel_entr_curves_frames + short_long_rel_entr_curves_frames)\n",
    "print(f'mixture_distribution.shape: {np.shape(mixture_distribution)}') # (nSnapshots, n_neurons, n_xbins)\n",
    "# jensen_shannon_distance = 0.5 * (sum(rel_entr(mixture_distribution, long_short_rel_entr_curves_frames)) + sum(rel_entr(mixture_distribution, short_long_rel_entr_curves_frames))) # is this right? I'm confused by sum(...) # (n_neurons, n_xbins)\n",
    "jensen_shannon_distance = 0.5 * (np.sum(rel_entr(mixture_distribution, long_short_rel_entr_curves_frames), axis=1) + np.sum(rel_entr(mixture_distribution, short_long_rel_entr_curves_frames), axis=1)) # alt version: (nSnapshots, n_xbins)\n",
    "print(f'jensen_shannon_distance.shape: {np.shape(jensen_shannon_distance)}') # (n_neurons, n_xbins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46af026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isclose(flat_jensen_shannon_distance_results, jensen_shannon_distance).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1fd095",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_image(flat_jensen_shannon_distance_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb518301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from silx.gui.plot import Plot2D\n",
    "\n",
    "plot = Plot2D()  # Create the plot widget\n",
    "plot.addImage(flat_jensen_shannon_distance_results, legend='flat_jensen_shannon_distance_results')  # Plot the 2D data set with default colormap\n",
    "plot.setGraphTitle('flat_jensen_shannon_distance_results')\n",
    "plot.getXAxis().setLabel('Position Bin')\n",
    "plot.getYAxis().setLabel('Snapshot Timebin')\n",
    "plot.show()  # Make the plot widget visible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9eca25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = Plot2D()  # Create the plot widget\n",
    "plot.addImage(jensen_shannon_distance, legend='jensen_shannon_distance')  # Plot the 2D data set with default colormap\n",
    "plot.setGraphTitle('jensen_shannon_distance')\n",
    "plot.getXAxis().setLabel('Position Bin')\n",
    "plot.getYAxis().setLabel('Snapshot Timebin')\n",
    "plot.show()  # Make the plot widget visible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589c3d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot = Plot2D()  # Create the plot widget\n",
    "plot.addImage(long_short_rel_entr_curves_frames, legend='image')  # Plot the 2D data set with default colormap\n",
    "plot.setGraphTitle('long_short_rel_entr_curves_frames')\n",
    "# plot.getXAxis().setLabel('Position Bin')\n",
    "# plot.getYAxis().setLabel('Snapshot Timebin')\n",
    "plot.show()  # Make the plot widget visible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f8f97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from silx.gui.plot.StackView import StackViewMainWindow\n",
    "\n",
    "# synthetic data, stack of 100 images of size 200x300\n",
    "# mystack = np.fromfunction(\n",
    "#     lambda i, j, k: np.sin(i/15.) + np.cos(j/4.) + 2 * np.sin(k/6.),\n",
    "#     (100, 200, 300)\n",
    "# )\n",
    "\n",
    "sv = StackViewMainWindow()\n",
    "sv.setColormap(\"jet\", autoscale=True)\n",
    "sv.setStack(long_short_rel_entr_curves_frames)\n",
    "# (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "sv.setLabels([\"post_update_time\", \"aclu\", \"Position (xbin)\"])\n",
    "sv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa37de28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "heatmap_pf1D_win, heatmap_pf1D_img = visualize_heatmap_pyqtgraph(flat_jensen_shannon_distance_results, show_yticks=False, title=f\"flat_jensen_shannon_distance_results\", defer_show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa164de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_pf1D_win, heatmap_pf1D_img = visualize_heatmap_pyqtgraph(flat_jensen_shannon_distance_across_all_positions, show_yticks=False, title=f\"flat_jensen_shannon_distance_across_all_positions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2295dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.matplotlib_helpers import draw_epoch_regions\n",
    "from neuropy.core.epoch import Epoch\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(post_update_times, flat_surprise_across_all_positions)\n",
    "ax.set_ylabel('Relative Entropy across all positions')\n",
    "ax.set_xlabel('t (seconds)')\n",
    "epochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, facecolor=('r','cyan'), alpha=0.1, edgecolors=None, labels_kwargs={'y_offset': -0.05, 'size': 14}, defer_render=True, debug_print=False)\n",
    "laps_epochs_collection, laps_epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.laps.as_epoch_obj(), ax, facecolor='r', edgecolors='black', labels_kwargs={'y_offset': -16.0, 'size':8}, defer_render=True, debug_print=False)\n",
    "# replays_epochs_collection, replays_epoch_labels = draw_epoch_regions(active_filter_epoch_obj, ax, facecolor='orange', edgecolors=None, labels_kwargs=None, defer_render=False, debug_print=False)\n",
    "fig.suptitle('flat_surprise_across_all_positions')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f00561d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(post_update_times, flat_jensen_shannon_distance_across_all_positions, label='JS_Distance')\n",
    "ax.set_ylabel('J-S Distance across all positions')\n",
    "ax.set_xlabel('t (seconds)')\n",
    "epochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, facecolor=('red','cyan'), alpha=0.1, edgecolors=None, labels_kwargs={'y_offset': -0.05, 'size': 14}, defer_render=True, debug_print=False)\n",
    "laps_epochs_collection, laps_epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.laps.as_epoch_obj(), ax, facecolor='red', edgecolors='black', labels_kwargs={'y_offset': -16.0, 'size':8}, defer_render=True, debug_print=False)\n",
    "# replays_epochs_collection, replays_epoch_labels = draw_epoch_regions(active_filter_epoch_obj, ax, facecolor='orange', edgecolors=None, labels_kwargs=None, defer_render=False, debug_print=False)\n",
    "fig.suptitle('flat_jensen_shannon_distance_across_all_positions')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df587d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show basic relative entropy vs. time plot:\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(post_update_times, flat_relative_entropy_results)\n",
    "ax.set_ylabel('Relative Entropy')\n",
    "ax.set_xlabel('t (seconds)')\n",
    "epochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, facecolor=('red','cyan'), alpha=0.1, edgecolors=None, labels_kwargs={'y_offset': -0.05, 'size': 14}, defer_render=False, debug_print=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316ffda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "win, plots = plot_long_short_surprise_difference_plot(curr_active_pipeline, long_results_obj, short_results_obj, long_epoch_name, short_epoch_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dc968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "win, (ax_long, ax_short), legend = plot_long_short(long_results_obj, short_results_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6066cafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fn = lambda a_results_obj: a_results_obj.all_epochs_decoded_epoch_time_bins_mean[:,0]\n",
    "# y_fn = lambda a_results_obj: a_results_obj.all_epochs_all_cells_one_left_out_posterior_to_scrambled_pf_surprises_mean\n",
    "# y_fn = lambda a_results_obj: a_results_obj.all_epochs_all_cells_one_left_out_posterior_to_pf_surprises_mean\n",
    "y_fn = lambda a_results_obj: a_results_obj.all_epochs_computed_one_left_out_posterior_to_pf_surprises\n",
    "\n",
    "# (time_bins, neurons), (epochs, neurons), (epochs)\n",
    "# all_epochs_computed_one_left_out_posterior_to_pf_surprises, all_epochs_computed_cell_one_left_out_posterior_to_pf_surprises_mean, all_epochs_all_cells_one_left_out_posterior_to_pf_surprises_mean\n",
    "win, plots_tuple, legend = plot_long_short_any_values(long_results_obj, short_results_obj, x=x_fn, y=y_fn) #  limit_aclus=[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5d42b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO 2023-09-21 16:19: - [ ] Does not work due to QCode issue\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.MultiContextComparingDisplayFunctions import _context_nested_docks\n",
    "\n",
    "\n",
    "# active_display_output = {}\n",
    "# active_identifying_filtered_session_ctx = global_epoch_context\n",
    "# display_output = active_display_output | curr_active_pipeline.display('_display_context_nested_docks', active_identifying_filtered_session_ctx, enable_gui=False, debug_print=False) # returns {'master_dock_win': master_dock_win, 'app': app, 'out_items': out_items}\n",
    "# master_dock_win = display_output['master_dock_win']\n",
    "# app = display_output['app']\n",
    "# out_items = display_output['out_items']\n",
    "\n",
    "include_includelist = curr_active_pipeline.active_completed_computation_result_names # ['maze', 'sprinkle']\n",
    "\n",
    "out_items = {}\n",
    "master_dock_win, app, out_items = _context_nested_docks(curr_active_pipeline, active_config_names=include_includelist, **{'enable_gui': True, 'debug_print': False})\n",
    "master_dock_win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7326d309",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_replay_stats_df: pd.DataFrame = jonathan_firing_rate_analysis_result.neuron_replay_stats_df\n",
    "short_pf_peak_x = neuron_replay_stats_df.short_pf_peak_x.values\n",
    "long_pf_peak_x = neuron_replay_stats_df.long_pf_peak_x.values\n",
    "\n",
    "# long_pf_peak_x_maze_classification = [classify_x_position(test_x, long_rects) for test_x in long_pf_peak_x.values]\n",
    "# short_pf_peak_x_maze_classification = [classify_x_position(test_x, short_rects) for test_x in short_pf_peak_x.values]\n",
    "# [classify_x_position(test_x, short_rects) for test_x in long_pf_peak_x.values]\n",
    "\n",
    "long_track.is_on_maze(long_pf_peak_x)\n",
    "# long_track.is_on_endcap(long_pf_peak_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4bc1b6",
   "metadata": {},
   "source": [
    "## NOW TODO 2023-09-20 22:33: - [ ] Need to fix tests and determing why some peaks are falling outside the bounds (as assessed by the is_on_maze function to see if implementation is valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e13f006",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# assert short_track.is_on_maze(short_pf_peak_x)[np.logical_not(np.isnan(short_pf_peak_x))].all(), f\"all valid short peaks should be located on the short track\" # should all be true yeah?\n",
    "assert long_track.is_on_maze(short_pf_peak_x)[np.logical_not(np.isnan(short_pf_peak_x))].all(), f\"all valid short peaks should be located on the long track\"\n",
    "assert long_track.is_on_maze(long_pf_peak_x)[np.logical_not(np.isnan(long_pf_peak_x))].all(), f\"all valid long peaks should be located on the long track. {long_track.is_on_maze(long_pf_peak_x)[np.logical_not(np.isnan(long_pf_peak_x))]}\" # not working\n",
    "assert short_track.is_on_maze(short_pf_peak_x)[np.logical_not(np.isnan(short_pf_peak_x))].all(), f\"all valid short peaks should be located on the short track. {short_track.is_on_maze(short_pf_peak_x)[np.logical_not(np.isnan(short_pf_peak_x))]}\" # not working\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ec27b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_track.is_on_endcap(long_pf_peak_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1bc2ae",
   "metadata": {},
   "source": [
    "## Debug Plots for `LinearTrackDimensions` and `LinearTrackInstance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0ece7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "app, w, cw, (long_track_dims, long_rect_items, long_rects), (short_track_dims, short_rect_items, short_rects) = test_LinearTrackDimensions_2D_pyqtgraph(long_track_dims, short_track_dims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cdcb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "axs = fig.get_axes()\n",
    "ax = axs[0]\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d49be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "## Adds a new subplot to an existing (fig, ax) without requiring modifications in the original code!\n",
    "\n",
    "# Get the current gridspec from ax\n",
    "gs = ax.get_subplotspec().get_gridspec()\n",
    "\n",
    "# Create a new gridspec with an additional column\n",
    "gs_new = gridspec.GridSpec(1, 2, width_ratios=[1, 0.5]) # new column is half the width of the current one\n",
    "\n",
    "# Reposition the existing ax using the new gridspec\n",
    "ax.set_position(gs_new[0, 0].get_position(fig))\n",
    "\n",
    "# Add a new subplot in the new column\n",
    "ax2 = fig.add_subplot(gs_new[0, 1])\n",
    "\n",
    "\n",
    "ax2.plot(np.cos(np.linspace(0, 10, 100)))\n",
    "# ax2.cla()\n",
    "# long_track_dims.plot_rects(ax2)\n",
    "\n",
    "# long_track_dims.plot_rects(ax2, offset=(0.1, 0.0))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffd94f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out2 = curr_active_pipeline.display('_display_batch_pho_jonathan_replay_firing_rate_comparison', included_unit_neuron_IDs=[2], n_max_plot_rows=2, save_figure=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a1d5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import fig_example_handpicked_pho_jonathan_active_set_cells\n",
    "\n",
    "_LxC_out, _SxC_out = fig_example_handpicked_pho_jonathan_active_set_cells(curr_active_pipeline, save_figure=True, included_LxC_example_neuron_IDs=[4, 58], included_SxC_example_neuron_IDs=[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6907963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neuropy.analyses.placefields import PfnDMixin, plotRaw_v_time\n",
    "from neuropy.analyses.placefields import PfnDMixin\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "_out3 = long_pf1D.plotRaw_v_time(0, should_include_trajectory=True, should_include_spikes=False, should_include_labels=True, use_filtered_positions=True, use_pandas_plotting=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a88a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out4 = long_pf1D.plotRaw_v_time(0, should_include_trajectory=True, should_include_spikes=False, should_include_labels=True, use_filtered_positions=False, use_pandas_plotting=False)\n",
    "# _out4 = long_pf1D.plotRaw_v_time(0, should_include_trajectory=True, should_include_spikes=False, should_include_labels=True, use_filtered_positions=False, use_pandas_plotting=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ff3397",
   "metadata": {},
   "source": [
    "#  PhoKamran2023Paper Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e59bdb",
   "metadata": {},
   "source": [
    "## Figure 1) pf1D Ratemaps, Active set, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77377ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot, plot_raster_plot\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap_pyqtgraph # used in `plot_kourosh_activity_style_figure`\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_1_add_replay_epoch_rasters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5035f2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "pf1d_compare_graphics, (example_epoch_rasters_L, example_epoch_rasters_S), example_stacked_epoch_graphics, fig_1c_figures_out_dict = PAPER_FIGURE_figure_1_full(curr_active_pipeline) # did not display the pf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05664e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = jonathan_firing_rate_analysis_result.rdf.rdf\n",
    "rdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267b2335",
   "metadata": {},
   "source": [
    "## Figure 2) `PaperFigureTwo`: LxC/SxC Analyses\n",
    "Note: this fails when SxC or LxC are empty for this session (as it's not meaningful to produce a comparison bar plot). In this case, aggregate across multiple sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63d9b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PaperFigureTwo\n",
    "\n",
    "_out_fig_2 = PaperFigureTwo(instantaneous_time_bin_size_seconds=0.01) # 10ms\n",
    "_out_fig_2.compute(curr_active_pipeline=curr_active_pipeline)\n",
    "_out_fig_2.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403e5c60",
   "metadata": {},
   "source": [
    "## Figure 3) `PAPER_FIGURE_figure_3`: Firing Rate Index and Long/Short Firing Rate Replays v. Laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6932845c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.matplotlib_helpers import FormattedFigureText\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import _plot_long_short_firing_rate_indicies\n",
    "# curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "_out, _out2 = PAPER_FIGURE_figure_3(curr_active_pipeline, defer_render=False, save_figure=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9796ffb1",
   "metadata": {},
   "source": [
    "## Other Paper-related explorations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90dda8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out2.figures\n",
    "_out.axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a2984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "['start']\n",
    "\n",
    "\n",
    "# Any change in duration over the recording session duration?\n",
    "rdf['duration']\n",
    "\n",
    "# rdf.plot.scatter('start', 'duration')\n",
    "\n",
    "# rdf.plot.scatter('duration', 'num_neuron_participating') # strong positive trend\n",
    "\n",
    "# rdf.plot.scatter('start', 'num_neuron_participating') # num neurons participating seems to increase over time, especially after the short track is introduced. Contrary to my hypothesis.\n",
    "\n",
    "rdf.plot.scatter('start', 'num_short_only_neuron_participating')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ['num_neuron_participating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dc28f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "a_plot_obj = curr_active_pipeline.plot\n",
    "a_plot_obj._display_spike_rasters_pyqtplot_2D()\n",
    "# '_display_spike_rasters_pyqtplot_2D': ' Plots a standalone 2D raster plot\\n        ',\n",
    "# '_display_spike_rasters_pyqtplot_3D': ' Plots a standalone 3D raster plot with independent/standalone controls built-in\\n        ',\n",
    "# '_display_spike_rasters_pyqtplot_3D_with_2D_controls': ' Plots a standalone 3D raster plot (via pyqtgraph) with a separate 2D raster plot as the window with which you can adjust the viewed window. \\n        ',\n",
    "# '_display_spike_rasters_vedo_3D': ' Plots a standalone 3D raster plot with independent/standalone controls built-in\\n        ',\n",
    "# '_display_spike_rasters_vedo_3D_with_2D_controls': ' Plots a standalone 3D raster plot (via Vedo) with a separate 2D raster plot as the window with which you can adjust the viewed window. \\n        ',\n",
    "# '_display_spike_rasters_window': ' Displays a Spike3DRasterWindowWidget with a configurable set of raster widgets and controls in it.\\n        ',type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0c9b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_display_function_docs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3877d9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf1d_compare_fig_L, pf1d_compare_fig_S = pf1d_compare_graphics.figures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44ffa57",
   "metadata": {
    "tags": [
     "active"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import build_shared_sorted_neuronIDs\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap_pyqtgraph\n",
    "\n",
    "ratemap = long_pf1D.ratemap\n",
    "included_unit_neuron_IDs = EITHER_subset.track_exclusive_aclus\n",
    "rediculous_final_sorted_all_included_neuron_ID, rediculous_final_sorted_all_included_pfmap = build_shared_sorted_neuronIDs(ratemap, included_unit_neuron_IDs, sort_ind=new_all_aclus_sort_indicies.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c7755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_pf1D_win, heatmap_pf1D_img = visualize_heatmap_pyqtgraph(rediculous_final_sorted_all_included_pfmap, show_yticks=False, title=f\"pf1D Sorted Visualization\", defer_show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66369f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_curves_sorted = long_pf1D.ratemap.normalized_tuning_curves[is_included][included_new_all_aclus_sort_indicies]\n",
    "heatmap_pf1D_win, heatmap_pf1D_img = visualize_heatmap_pyqtgraph(active_curves_sorted, show_yticks=False, title=f\"pf1D Sorted Visualization\", defer_show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5f0066",
   "metadata": {
    "tags": [
     "unwrap_figure_output",
     "interactive"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import DecodedEpochSlicesPaginatedFigureController\n",
    "\n",
    "## Stacked Epoch Plot\n",
    "example_stacked_epoch_graphics = curr_active_pipeline.display('_display_long_and_short_stacked_epoch_slices', defer_render=False, save_figure=True)\n",
    "pagination_controller_L, pagination_controller_S = example_stacked_epoch_graphics.plot_data['controllers']\n",
    "ax_L, ax_S = example_stacked_epoch_graphics.axes\n",
    "final_figure_context_L, final_context_S = example_stacked_epoch_graphics.context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cbb0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## After launching the interactive Stacked Epoch Plots for user epoch selection, try to update the selection with previously added annotations:\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from pyphoplacecellanalysis.GUI.Qt.Mixins.PaginationMixins import SelectionsObject\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import DecodedEpochSlicesPaginatedFigureController\n",
    "\n",
    "user_annotation_man = UserAnnotationsManager()\n",
    "user_annotations = user_annotation_man.get_user_annotations()\n",
    "\n",
    "final_context_L = curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='replays', decoder='long_results_obj')\n",
    "final_context_S = curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='replays', decoder='short_results_obj')\n",
    "# _out_pagination_controller.params.active_identifying_figure_ctx.adding_context(None,  user_annotation=\"selections\")\n",
    "selections_context_L = final_context_L.adding_context(None,  user_annotation=\"selections\")\n",
    "selections_context_S = final_context_S.adding_context(None,  user_annotation=\"selections\")\n",
    "\n",
    "saved_selection_L: SelectionsObject = pagination_controller_L.save_selection()\n",
    "saved_selection_S: SelectionsObject = pagination_controller_S.save_selection()\n",
    "# saved_selection_L = user_annotation_man.update_selections_from_annotations(saved_selection_L, user_annotations)\n",
    "# saved_selection_S = user_annotation_man.update_selections_from_annotations(saved_selection_S, user_annotations)\n",
    "\n",
    "saved_selection_L = saved_selection_L.update_selections_from_annotations(user_annotations, debug_print=False)\n",
    "saved_selection_S = saved_selection_S.update_selections_from_annotations(user_annotations, debug_print=False)\n",
    "\n",
    "## re-apply the selections:\n",
    "pagination_controller_L.restore_selections(saved_selection_L, defer_render=True)\n",
    "pagination_controller_S.restore_selections(saved_selection_S, defer_render=True)\n",
    "\n",
    "ax_L[0].figure.canvas.draw()  # .figures.canvas.draw()\n",
    "ax_S[0].figure.canvas.draw()  # .figures.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b2f39d",
   "metadata": {
    "tags": [
     "TODO"
    ]
   },
   "source": [
    "# 2023-09-06 - Plot the decoded positions for each replay on the track:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a592c55f",
   "metadata": {
    "tags": [
     "TODO"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import LinearTrackDimensions\n",
    "\n",
    "\n",
    "long_track_dims = LinearTrackDimensions(track_length=100.0)\n",
    "short_track_dims = LinearTrackDimensions(track_length=70.0)\n",
    "\n",
    "\n",
    "# long_track_dims.plot_rects(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fe2d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import _test_LinearTrackDimensions_2D\n",
    "\n",
    "app, w, cw, (long_track_dims, long_rect_items, long_rects), (short_track_dims, short_rect_items, short_rects) = _test_LinearTrackDimensions_2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48faca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_fig_3_a, _out_fig_3_b = PAPER_FIGURE_figure_3(curr_active_pipeline, defer_render=False, save_figure=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d481370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = _out_fig_3_a.axes[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c872e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_track_dims.plot_rects(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ff0f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "pagination_controller_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26f364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the symbol properties\n",
    "# symbol = pg.mkPen('w', width=1)  # Pen for the lines\n",
    "size = 1.0  # Fixed x-width\n",
    "symbol_brush = None  # No brush for the symbol (transparent fill)\n",
    "\n",
    "# override_scatter_plot_kwargs = dict(pxMode=False, symbol='|', size=size, pen={'color': 'w', 'width': 1.0}) # , brush=symbol_brush\n",
    "\n",
    "override_scatter_plot_kwargs = dict(pxMode=False, symbol='arrow_up', size=1.0, pen={'color': 'w', 'width': 1.0}, hoverable=True) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226bb530",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_epoch_spikes_df_L.spikes.rebuild_fragile_linear_neuron_IDXs();\n",
    "filter_epoch_spikes_df_S.spikes.rebuild_fragile_linear_neuron_IDXs();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b889b886",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_L, win_L, plots_L, plots_data_L = plot_multiple_raster_plot(epochs_df_L, filter_epoch_spikes_df_L, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs,\n",
    "\t\t\t\t\t\t\t\t\t\tepoch_id_key_name='replay_epoch_id', scatter_app_name=\"Long Decoded Example Replays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee132b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_S, win_S, plots_S, plots_data_S = plot_multiple_raster_plot(epochs_df_S, filter_epoch_spikes_df_S, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs,\n",
    "                                                                 epoch_id_key_name='replay_epoch_id', scatter_app_name=\"Short Decoded Example Replays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26dd0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test single `plot_raster_plot` calls\n",
    "an_epoch = list(epochs_df_L.itertuples())[0]\n",
    "an_epoch_spikes_df = filter_epoch_spikes_df_L[filter_epoch_spikes_df_L['replay_epoch_id'] == an_epoch.Index]\n",
    "\n",
    "_out_single_raster_plot = plot_raster_plot(an_epoch_spikes_df, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=None, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs, scatter_app_name=\"test1\")\n",
    "_out_single_raster_plot2 = plot_raster_plot(an_epoch_spikes_df, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs, scatter_app_name=\"test2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6071c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_alt, win_alt, plots_alt, plots_data_alt = plot_multiple_raster_plot(epochs_df_L, filter_epoch_spikes_df_L, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=None, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs,\n",
    "                                                                         epoch_id_key_name='replay_epoch_id', scatter_app_name=\"ALT Long Decoded Example Replays\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d20407c",
   "metadata": {},
   "source": [
    "### Testing `plot_kourosh_activity_style_figure` for debugging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69512447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import plot_kourosh_activity_style_figure\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.helpers import _helper_make_scatterplot_clickable\n",
    "\n",
    "plot_aclus = EITHER_subset.track_exclusive_aclus.copy()\n",
    "# plot_aclus = EITHER_subset.track_exclusive_aclus[new_all_aclus_sort_indicies].copy()\n",
    "_out_A = plot_kourosh_activity_style_figure(long_results_obj, long_session, plot_aclus, unit_sort_order=new_all_aclus_sort_indicies, epoch_idx=13, callout_epoch_IDXs=None, skip_rendering_callouts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326f29f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "app, win, plots, plots_data = _out_A\n",
    "# plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338d4092",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO 2023-06-27 10:42: - [ ] Desperitely need a class that \"explodes\" the important variables and their types out of a DynamicParameters (dict-like) or other object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517cdee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_n = plot_kourosh_activity_style_figure(long_results_obj, long_session, EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, epoch_idx=49, callout_epoch_IDXs=np.arange(6), skip_rendering_callouts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af748f5c",
   "metadata": {},
   "source": [
    "# 2023-07-14 - LxC and SxC PhoJonathanSession plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9415e3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import BatchPhoJonathanFiguresHelper\n",
    "\n",
    "## Get global 'jonathan_firing_rate_analysis' results:\n",
    "curr_jonathan_firing_rate_analysis = curr_active_pipeline.global_computation_results.computed_data['jonathan_firing_rate_analysis']\n",
    "neuron_replay_stats_df, rdf, aclu_to_idx, irdf = curr_jonathan_firing_rate_analysis.neuron_replay_stats_df, curr_jonathan_firing_rate_analysis.rdf.rdf, curr_jonathan_firing_rate_analysis.rdf.aclu_to_idx, curr_jonathan_firing_rate_analysis.irdf.irdf\n",
    "\n",
    "# with VizTracer(output_file=f\"viztracer_display_BatchPhoJonathanFiguresHelper_PlusPDF_20.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "# active_out_figures_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, included_unit_neuron_IDs=XOR_subset.track_exclusive_aclus, n_max_page_rows=20, write_vector_format=False, write_png=True) # active_out_figures_dict: {IdentifyingContext<('kdiba', 'gor01', 'two', '2006-6-07_16-40-19', 'BatchPhoJonathanReplayFRC', 'long_only', '(12,21,48)')>: <Figure size 1920x660 with 12 Axes>, IdentifyingContext<('kdiba', 'gor01', 'two', '2006-6-07_16-40-19', 'BatchPhoJonathanReplayFRC', 'short_only', '(18,19,65)')>: <Figure size 1920x660 with 12 Axes>}\n",
    "# print(f'active_out_figures_dict: {active_out_figures_dict}')\n",
    "\n",
    "# BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset\n",
    "active_out_figures_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, included_unit_neuron_IDs=EITHER_subset.track_exclusive_aclus, n_max_page_rows=20, write_vector_format=False, write_png=True) # active_out_figures_dict: {IdentifyingContext<('kdiba', 'gor01', 'two', '2006-6-07_16-40-19', 'BatchPhoJonathanReplayFRC', 'long_only', '(12,21,48)')>: <Figure size 1920x660 with 12 Axes>, IdentifyingContext<('kdiba', 'gor01', 'two', '2006-6-07_16-40-19', 'BatchPhoJonathanReplayFRC', 'short_only', '(18,19,65)')>: <Figure size 1920x660 with 12 Axes>}\n",
    "print(f'active_out_figures_dict: {active_out_figures_dict}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec1c4bb",
   "metadata": {
    "tags": [
     "ACTIVE_2023-09-07"
    ]
   },
   "outputs": [],
   "source": [
    "# 2023-09-07 - Build Example LxC/SxC cells from handpicked examples: aclus = [4, 58]\n",
    "# from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import build_extra_cell_info_label_string\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out2 = curr_active_pipeline.display('_display_batch_pho_jonathan_replay_firing_rate_comparison', n_max_plot_rows=2, save_figure=False, included_unit_neuron_IDs=[4, 58]) # , included_unit_neuron_IDs=[4, 58]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052f7ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.display(display_function='_display_2d_placefield_result_plot_ratemaps_2D', active_session_configuration_context=long_epoch_context)\n",
    "\n",
    "\n",
    "# curr_active_pipeline.display(display_function='_display_placemaps_pyqtplot_2D', active_session_configuration_context=long_epoch_context)\n",
    "curr_active_pipeline.display(display_function='_display_1d_placefields', active_session_configuration_context=long_epoch_context)\n",
    "# curr_active_pipeline.display(display_function='_display_2d_placefield_occupancy', active_session_configuration_context=long_epoch_context)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae8158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display(display_function='_display_2d_placefield_occupancy', active_session_configuration_context=long_epoch_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be309d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display(display_function='_display_2d_placefield_occupancy', active_session_configuration_context=short_epoch_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bb48de",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display(display_function='_display_2d_placefield_result_plot_ratemaps_2D', active_session_configuration_context=short_epoch_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5115fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display(display_function='_display_2d_placefield_result_plot_ratemaps_2D', active_session_configuration_context=long_epoch_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d12ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure() # new figure to hold the result\n",
    "# can show the figures by looping through and calling\n",
    "for a_ctxt, a_fig in active_out_figures_dict.items():\n",
    "    print(f'showing: {a_ctxt}')\n",
    "    a_fig.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edea79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]] # only uses global_session\n",
    "(epochs_df_L, epochs_df_S), (filter_epoch_spikes_df_L, filter_epoch_spikes_df_S), (good_example_epoch_indicies_L, good_example_epoch_indicies_S), (short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset), new_all_aclus_sort_indicies, assigning_epochs_obj = PAPER_FIGURE_figure_1_add_replay_epoch_rasters(curr_active_pipeline)\n",
    "\n",
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "long_laps, long_replays, short_laps, short_replays, global_laps, global_replays = [long_short_fr_indicies_analysis_results[k] for k in ['long_laps', 'long_replays', 'short_laps', 'short_replays', 'global_laps', 'global_replays']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d085cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813ab296",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_exclusive.track_exclusive_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05be832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_exclusive.track_exclusive_df['lap_delta_minus_inst_fr'] = LxC_ThetaDeltaMinus.cell_agg_inst_fr_list # (n_cells, )\n",
    "long_exclusive.track_exclusive_df['lap_delta_plus_inst_fr'] = LxC_ThetaDeltaPlus.cell_agg_inst_fr_list # (n_cells, )\n",
    "long_exclusive.track_exclusive_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3077438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = LxC_ThetaDeltaMinus.epoch_agg_inst_fr_list # (n_epochs, n_cells)\n",
    "# d = d[:,1]\n",
    "d = LxC_ThetaDeltaMinus.cell_agg_inst_fr_list # (n_cells, )\n",
    "d\n",
    "long_exclusive.track_exclusive_df['lap_delta_minus_inst_fr'] = LxC_ThetaDeltaMinus.cell_agg_inst_fr_list # (n_cells, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6984de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop out the very low (inactive) Epochs... I guess? But we want it to be influenced by the inactive epochs.\n",
    "curr_active_pipeline.\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d3f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(LxC_ThetaDeltaMinus.inst_fr_signals_list) # n_epochs\n",
    "d = LxC_ThetaDeltaMinus.inst_fr_df_list\n",
    "d[0]\n",
    "# (n_epochs, n_cells)\n",
    "# print(f'{d.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2b2901",
   "metadata": {},
   "source": [
    "## NOW: 2023-07-11 - Testing Batch-computed inst_firing_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c034766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchSessionCompletionHandler\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PaperFigureTwo, InstantaneousSpikeRateGroupsComputation\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsResults, AcrossSessionsVisualizations\n",
    "\n",
    "\n",
    "## Load the saved across-session results:\n",
    "inst_fr_output_filename = 'long_short_inst_firing_rate_result_handlers_2023-07-12.pkl'\n",
    "across_session_inst_fr_computation, across_sessions_instantaneous_fr_dict, across_sessions_instantaneous_frs_list = AcrossSessionsResults.load_across_sessions_data(global_data_root_parent_path=global_data_root_parent_path, inst_fr_output_filename=inst_fr_output_filename)\n",
    "# across_sessions_instantaneous_fr_dict = loadData(global_batch_result_inst_fr_file_path)\n",
    "num_sessions = len(across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2549c92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregate across all of the sessions to build a new combined `InstantaneousSpikeRateGroupsComputation`, which can be used to plot the \"PaperFigureTwo\", bar plots for many sessions.\n",
    "global_multi_session_context = IdentifyingContext(format_name='kdiba', num_sessions=0) # some global context across all of the sessions, not sure what to put here.\n",
    "\n",
    "# To correctly aggregate results across sessions, it only makes sense to combine entries at the `.cell_agg_inst_fr_list` variable and lower (as the number of cells can be added across sessions, treated as unique for each session).\n",
    "\n",
    "## Display the aggregate across sessions:\n",
    "_out_fig_2 = PaperFigureTwo(instantaneous_time_bin_size_seconds=0.01) # WARNING: we didn't save this info\n",
    "_out_fig_2.computation_result = across_session_inst_fr_computation\n",
    "_out_fig_2.active_identifying_session_ctx = across_session_inst_fr_computation.active_identifying_session_ctx\n",
    "# Set callback, the only self-specific property\n",
    "_out_fig_2._pipeline_file_callback_fn = curr_active_pipeline.output_figure # lambda args, kwargs: self.write_to_file(args, kwargs, curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f71cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "# Perform interactive Matplotlib operations with 'Qt5Agg' backend\n",
    "_fig_2_theta_out, _fig_2_replay_out = _out_fig_2.display(active_context=global_multi_session_context, title_modifier_fn=lambda original_title: f\"{original_title} ({num_sessions} sessions)\", save_figure=True)\n",
    "\t\n",
    "_out_fig_2.perform_save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed322ee",
   "metadata": {},
   "source": [
    "# `active_pf_nD`, `active_pf_nD_dt` visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8606b372",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.TimeSynchronizedOccupancyPlotter import TimeSynchronizedOccupancyPlotter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d478ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "curr_sync_occupancy_plotter = TimeSynchronizedOccupancyPlotter(global_pf2D_dt)\n",
    "curr_sync_occupancy_plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14388eec",
   "metadata": {},
   "source": [
    "# 2023-07-07 - `batch_extended_programmatic_figures` Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e3c3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "neptuner = batch_perform_all_plots(curr_active_pipeline, enable_neptune=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126028b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb off\n",
    "%load_ext viztracer\n",
    "from viztracer import VizTracer\n",
    "from pyphocorehelpers.print_helpers import get_now_day_str, get_now_time_str, get_now_time_precise_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a065e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-batch_extended_programmatic_figures.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "    batch_extended_programmatic_figures(curr_active_pipeline, write_vector_format=False, write_png=False, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef9f9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_extended_programmatic_figures(curr_active_pipeline, write_vector_format=False, write_png=False, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb9a021",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.logical_or(neuron_replay_stats_df['is_refined_LxC'], neuron_replay_stats_df['is_refined_SxC']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a49741",
   "metadata": {},
   "outputs": [],
   "source": [
    "JonathanFiringRateAnalysisResult = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc366f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "\n",
    "jonathan_firing_rate_analysis_result.refine_exclusivity_by_inst_frs_index(long_short_fr_indicies_df, frs_index_inclusion_magnitude=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0710f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea8d0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative Entropy/Surprise Results:\n",
    "active_extended_stats = global_results['extended_stats']\n",
    "active_relative_entropy_results = active_extended_stats['pf_dt_sequential_surprise'] # DynamicParameters\n",
    "historical_snapshots = active_relative_entropy_results['historical_snapshots']\n",
    "post_update_times: np.ndarray = active_relative_entropy_results['post_update_times'] # (4152,) = (n_post_update_times,)\n",
    "snapshot_differences_result_dict = active_relative_entropy_results['snapshot_differences_result_dict']\n",
    "time_intervals: np.ndarray = active_relative_entropy_results['time_intervals']\n",
    "surprise_time_bin_duration = (post_update_times[2]-post_update_times[1])\n",
    "long_short_rel_entr_curves_frames: np.ndarray = active_relative_entropy_results['long_short_rel_entr_curves_frames'] # (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "short_long_rel_entr_curves_frames: np.ndarray = active_relative_entropy_results['short_long_rel_entr_curves_frames'] # (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "flat_relative_entropy_results: np.ndarray = active_relative_entropy_results['flat_relative_entropy_results'] # (149, 63) - (nSnapshots, nXbins)\n",
    "flat_jensen_shannon_distance_results: np.ndarray = active_relative_entropy_results['flat_jensen_shannon_distance_results'] # (149, 63) - (nSnapshots, nXbins)\n",
    "flat_jensen_shannon_distance_across_all_positions: np.ndarray = np.sum(np.abs(flat_jensen_shannon_distance_results), axis=1) # sum across all position bins # (4152,) - (nSnapshots)\n",
    "flat_surprise_across_all_positions: np.ndarray = np.sum(np.abs(flat_relative_entropy_results), axis=1) # sum across all position bins # (4152,) - (nSnapshots)\n",
    "\n",
    "## Get the placefield dt matrix:\n",
    "if 'snapshot_occupancy_weighted_tuning_maps' not in active_relative_entropy_results:\n",
    "\t## Compute it if missing:\n",
    "\toccupancy_weighted_tuning_maps_over_time = np.stack([placefield_snapshot.occupancy_weighted_tuning_maps_matrix for placefield_snapshot in historical_snapshots.values()])\n",
    "\tactive_relative_entropy_results['snapshot_occupancy_weighted_tuning_maps'] = occupancy_weighted_tuning_maps_over_time\n",
    "else:\n",
    "\toccupancy_weighted_tuning_maps_over_time = active_relative_entropy_results['snapshot_occupancy_weighted_tuning_maps'] # (n_post_update_times, n_neurons, n_xbins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fae698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-dependent\n",
    "long_pf1D_dt, short_pf1D_dt, global_pf1D_dt = long_results.pf1D_dt, short_results.pf1D_dt, global_results.pf1D_dt\n",
    "long_pf2D_dt, short_pf2D_dt, global_pf2D_dt = long_results.pf2D_dt, short_results.pf2D_dt, global_results.pf2D_dt\n",
    "global_pf1D_dt: PfND_TimeDependent = global_results.pf1D_dt\n",
    "global_pf2D_dt: PfND_TimeDependent = global_results.pf2D_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5950b2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## long_short_endcap_analysis: checks for cells localized to the endcaps that have their placefields truncated after shortening the track\n",
    "truncation_checking_result: TruncationCheckingResults = curr_active_pipeline.global_computation_results.computed_data.long_short_endcap\n",
    "disappearing_endcap_aclus = truncation_checking_result.disappearing_endcap_aclus\n",
    "# disappearing_endcap_aclus\n",
    "trivially_remapping_endcap_aclus = truncation_checking_result.minor_remapping_endcap_aclus\n",
    "# trivially_remapping_endcap_aclus\n",
    "significant_distant_remapping_endcap_aclus = truncation_checking_result.significant_distant_remapping_endcap_aclus\n",
    "# significant_distant_remapping_endcap_aclus\n",
    "appearing_aclus = jonathan_firing_rate_analysis_result.neuron_replay_stats_df[jonathan_firing_rate_analysis_result.neuron_replay_stats_df['track_membership'] == SplitPartitionMembership.RIGHT_ONLY].index\n",
    "# appearing_aclus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720dda5d",
   "metadata": {},
   "source": [
    "# 2023-09-26 - Interactive `napari` testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4c18cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "from pyphoplacecellanalysis.GUI.Napari.napari_helpers import napari_add_surprise_data_layers, napari_add_animal_position, napari_set_time_windw_index\n",
    "\n",
    "# create the viewer and window\n",
    "viewer = napari.Viewer()\n",
    "napari_add_surprise_data_layers(viewer, active_relative_entropy_results)\n",
    "napari_add_animal_position(viewer=viewer, position_df=global_pf1D_dt.all_time_filtered_pos_df[['t','x','binned_x']], time_intervals=time_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0815fee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_below_threshold:float=0.0000001\n",
    "active_time_dependent_placefields = deepcopy(global_pf1D_dt)\n",
    "curr_ratemap = active_time_dependent_placefields.ratemap\n",
    "images = curr_ratemap.tuning_curves.copy() # 1D: (82, 112), 2D:(43, 63, 63)\n",
    "print(f'images.shape: {np.shape(images)}')\n",
    "occupancy = curr_ratemap.occupancy\n",
    "print(f'occupancy: {occupancy.shape}')\n",
    "# Compute Images:\n",
    "included_unit_indicies = np.arange(np.shape(images)[0]) # include all unless otherwise specified\n",
    "nMapsToShow = len(included_unit_indicies)\n",
    "print(f'nMapsToShow: {nMapsToShow}')\n",
    "# Get single cell info:\n",
    "# neuron_IDX = curr_included_unit_index\n",
    "# cell_ID = active_time_dependent_placefields.ratemap.neuron_ids[neuron_IDX]\n",
    "# curr_cell_identifier_string = f'Cell[{cell_ID}]'\n",
    "# curr_plot_identifier_string = f'TimeSynchronizedPlacefieldsPlotter.{curr_cell_identifier_string}'\n",
    "\n",
    "# Build the image item:\n",
    "# Update the image:\n",
    "# image = np.squeeze(images[a_linear_index,:,:])\n",
    "image = np.squeeze(images)\n",
    "# Pre-filter the data:\n",
    "with np.errstate(divide='ignore', invalid='ignore'):\n",
    "\timage = np.array(image) / np.nanmax(image) # note scaling by maximum here!\n",
    "\tif drop_below_threshold is not None:\n",
    "\t\timage[:, np.where(occupancy < drop_below_threshold)] = np.nan # null out the occupancy\n",
    "\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075d0e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Napari.napari_helpers import napari_export_video_frames\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd056119",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(screenshot)\n",
    "screenshot.shape # (1165, 1488, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaa129b",
   "metadata": {},
   "source": [
    "# 2023-09-27 - Exporting surprise ndarray to a video file for visualization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2ebd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add the animal's closest current position (binned) as a single colored pixel along the top of the array:\n",
    "len(global_pf1D_dt.historical_snapshots)\n",
    "\n",
    "global_pf1D_dt.historical_snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463a38ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from pyphocorehelpers.plotting.video_output_helpers import save_array_as_video\n",
    "\n",
    "colormap = cv2.COLORMAP_JET\n",
    "array = active_relative_entropy_results['snapshot_occupancy_weighted_tuning_maps'].copy()\n",
    "color_array = cv2.applyColorMap(array, colormap)\n",
    "video_out_path = save_array_as_video(array=color_array, video_filename='output/videos/snapshot_occupancy_weighted_tuning_maps.avi', isColor=True)\n",
    "print(f'video_out_path: {video_out_path}')\n",
    "reveal_in_system_file_manager(video_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c1a66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import export_active_relative_entropy_results_videos\n",
    "\n",
    "video_output_parent_path = export_active_relative_entropy_results_videos(active_relative_entropy_results, active_context=curr_active_pipeline.get_session_context())\n",
    "reveal_in_system_file_manager(video_output_parent_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba227418",
   "metadata": {},
   "source": [
    "# 2023-09-26 - Interactive `Spike3DRasterWindowWidget` exploration`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1ca4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Gets the existing SpikeRasterWindow or creates a new one if one doesn't already exist:\n",
    "from pyphocorehelpers.gui.Qt.TopLevelWindowHelper import TopLevelWindowHelper\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg # Used to get the app for TopLevelWindowHelper.top_level_windows\n",
    "## For searching with `TopLevelWindowHelper.all_widgets(...)`:\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import Spike2DRaster\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike3DRaster import Spike3DRaster\n",
    "from pyphoplacecellanalysis.GUI.Qt.SpikeRasterWindows.Spike3DRasterWindowWidget import Spike3DRasterWindowWidget\n",
    "\n",
    "found_spike_raster_windows = TopLevelWindowHelper.all_widgets(pg.mkQApp(), searchType=Spike3DRasterWindowWidget)\n",
    "\n",
    "if len(found_spike_raster_windows) < 1:\n",
    "\t# no existing spike_raster_windows. Make a new one\n",
    "\tprint(f'no existing SpikeRasterWindow. Creating a new one.')\n",
    "\t# Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\n",
    "\tactive_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.plot._display_spike_rasters_pyqtplot_2D().values()\n",
    "\n",
    "else:\n",
    "\tprint(f'found {len(found_spike_raster_windows)} existing Spike3DRasterWindowWidget windows using TopLevelWindowHelper.all_widgets(...). Will use the most recent.')\n",
    "\t# assert len(found_spike_raster_windows) == 1, f\"found {len(found_spike_raster_windows)} Spike3DRasterWindowWidget windows using TopLevelWindowHelper.all_widgets(...) but require exactly one.\"\n",
    "\t# Get the most recent existing one and reuse that:\n",
    "\tspike_raster_window = found_spike_raster_windows[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ddd088",
   "metadata": {},
   "outputs": [],
   "source": [
    "Spike3DRasterWindowWidget."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971ce291",
   "metadata": {},
   "source": [
    "# Interactive SpikeRasterWindow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dbe020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent, PlacefieldSnapshot\n",
    "\n",
    "global_pf1D_dt: PfND_TimeDependent = global_results.pf1D_dt\n",
    "global_pf2D_dt: PfND_TimeDependent = global_results.pf2D_dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307d5dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.TimeSynchronizedOccupancyPlotter import TimeSynchronizedOccupancyPlotter\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.TimeSynchronizedPlacefieldsPlotter import TimeSynchronizedPlacefieldsPlotter\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.Mixins.helpers import build_combined_time_synchronized_plotters_window\n",
    "\n",
    "active_pf_2D_dt = global_pf2D_dt\n",
    "active_pf_2D_dt.reset()\n",
    "active_pf_2D_dt.update(t=500.0, start_relative_t=True)\n",
    "all_plotters, root_dockAreaWindow, app = build_combined_time_synchronized_plotters_window(active_pf_2D_dt, fixed_window_duration = 15.0)\n",
    "controlling_widget, curr_sync_occupancy_plotter, curr_placefields_plotter = all_plotters # end up in some sort of `linkedViewChanged` loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8b7e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a VERY simple and efficient 1D plot of the animal on the track.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72cc6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "controlling_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306542c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\n",
    "_out = curr_active_pipeline.plot._display_spike_rasters_pyqtplot_2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2878ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.gui.Qt.TopLevelWindowHelper import TopLevelWindowHelper\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg # Used to get the app for TopLevelWindowHelper.top_level_windows\n",
    "## For searching with `TopLevelWindowHelper.all_widgets(...)`:\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import Spike2DRaster\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike3DRaster import Spike3DRaster\n",
    "from pyphoplacecellanalysis.GUI.Qt.SpikeRasterWindows.Spike3DRasterWindowWidget import Spike3DRasterWindowWidget\n",
    "\n",
    "found_spike_raster_windows = TopLevelWindowHelper.all_widgets(pg.mkQApp(), searchType=Spike3DRasterWindowWidget)\n",
    "# assert len(found_spike_raster_windows) == 1, f\"found {len(found_spike_raster_windows)} Spike3DRasterWindowWidget windows using TopLevelWindowHelper.all_widgets(...) but require exactly one.\"\n",
    "if len(found_spike_raster_windows) > 1:\n",
    "\tprint(f'found {len(found_spike_raster_windows)} widgets with the searchType provided:')\n",
    "\tprint(f'{found_spike_raster_windows}')\n",
    "\tprint(f'defaulting to using the most recent [-1]...')\n",
    "spike_raster_window = found_spike_raster_windows[-1]\n",
    "\n",
    "# Extras:\n",
    "active_2d_plot = spike_raster_window.spike_raster_plt_2d # <pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster.Spike2DRaster at 0x196c7244280>\n",
    "active_3d_plot = spike_raster_window.spike_raster_plt_3d # <pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster.Spike2DRaster at 0x196c7244280>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c2011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.SpikesRenderingBaseMixin import SpikeEmphasisState\n",
    "\n",
    "active_pf_2D = global_pf2D\n",
    "## Example 1: De-emphasize spikes excluded from the placefield calculations:\n",
    "is_spike_included_in_pf = np.isin(spike_raster_window.spike_raster_plt_2d.spikes_df.index, active_pf_2D.filtered_spikes_df.index)\n",
    "spike_raster_window.spike_raster_plt_2d.update_spike_emphasis(np.logical_not(is_spike_included_in_pf), SpikeEmphasisState.Deemphasized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ee44b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_spike_included_in_pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb21806",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_pf_2D_dt.update(t=1000.0, start_relative_t=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc70ee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.TimeSynchronizedPlacefieldsPlotter import TimeSynchronizedPlacefieldsPlotter\n",
    "\n",
    "curr_sync_occupancy_plotter = TimeSynchronizedOccupancyPlotter(global_pf2D_dt)\n",
    "curr_sync_occupancy_plotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67793210",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_pf2D_dt.historical_snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5a3382",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.TimeSynchronizedPlacefieldsPlotter import TimeSynchronizedPlacefieldsPlotter\n",
    "\n",
    "curr_sync_placefield_plotter = TimeSynchronizedPlacefieldsPlotter(global_pf2D_dt)\n",
    "curr_sync_placefield_plotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c722971",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.TimeSynchronizedPlacefieldsPlotter import TimeSynchronizedPlacefieldsPlotter\n",
    "\n",
    "curr_sync_placefield_plotter1D = TimeSynchronizedPlacefieldsPlotter(global_pf1D_dt)\n",
    "curr_sync_placefield_plotter1D.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7a0f86",
   "metadata": {},
   "source": [
    "# 2023-07-19 - Validation with 3D tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecde32c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "\n",
    "display_output = {}\n",
    "# active_config_name = long_epoch_name\n",
    "active_config_name = global_epoch_name\n",
    "active_config = curr_active_pipeline.active_configs[active_config_name]\n",
    "active_config.plotting_config.should_use_linear_track_geometry = True # indicate that it's a linear track so the better geometry can be used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80672dec",
   "metadata": {},
   "source": [
    "# 3D Plotters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0f0e7a",
   "metadata": {},
   "source": [
    "##  Programmatically adding several epoch rectangles by calling the addRenderable context menu functions all at once for SpikeRaster2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb05977",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_renderables_menu = active_2d_plot.ui.menus.custom_context_menus.add_renderables[0].programmatic_actions_dict\n",
    "menu_commands = ['AddTimeIntervals.PBEs', 'AddTimeIntervals.Ripples', 'AddTimeIntervals.Replays', 'AddTimeIntervals.Laps', 'AddTimeIntervals.Session.Epochs']\n",
    "for a_command in menu_commands:\n",
    "    add_renderables_menu[a_command].trigger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb2d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.Specific2DRenderTimeEpochs import General2DRenderTimeEpochs, Ripples_2DRenderTimeEpochs, inline_mkColor\n",
    "## Inline Concise: Position Replays, PBEs, and Ripples all below the scatter:\n",
    "# active_2d_plot.interval_datasources.Replays.update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, y_location=-10.0, height=7.5, pen_color=inline_mkColor('orange', 0.8), brush_color=inline_mkColor('orange', 0.5), **kwargs)) ## Fully inline\n",
    "# active_2d_plot.interval_datasources.PBEs.update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, y_location=-2.0, height=1.5, pen_color=inline_mkColor('pink', 0.8), brush_color=inline_mkColor('pink', 0.5), **kwargs)) ## Fully inline\n",
    "# active_2d_plot.interval_datasources.Ripples.update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, y_location=-12.0, height=1.5, pen_color=inline_mkColor('cyan', 0.8), brush_color=inline_mkColor('cyan', 0.5), **kwargs)) ## Fully inline\n",
    "# active_2d_plot.interval_datasources.SessionEpochs .update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, y_location=-12.0, height=1.5, pen_color=inline_mkColor('cyan', 0.8), brush_color=inline_mkColor('cyan', 0.5), **kwargs)) ## Fully inline\n",
    "epochs_update_dict = {\n",
    "    'Replays':dict(y_location=-10.0, height=7.5, pen_color=inline_mkColor('orange', 0.8), brush_color=inline_mkColor('orange', 0.5)),\n",
    "    'PBEs':dict(y_location=-2.0, height=1.5, pen_color=inline_mkColor('pink', 0.8), brush_color=inline_mkColor('pink', 0.5)),\n",
    "    'Ripples':dict(y_location=-12.0, height=1.5, pen_color=inline_mkColor('cyan', 0.8), brush_color=inline_mkColor('cyan', 0.5)),\n",
    "    'SessionEpochs ':dict(y_location=-12.0, height=1.5, pen_color=inline_mkColor('cyan', 0.8), brush_color=inline_mkColor('cyan', 0.5)),\n",
    "}\n",
    "active_2d_plot.update_rendered_intervals_visualization_properties(epochs_update_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8e16b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rendered_interval_keys = list(interval_info.keys())\n",
    "desired_interval_height_ratios = [2.0, 2.0, 1.0, 0.1, 1.0, 1.0, 1.0] # ratio of heights to each interval\n",
    "required_vertical_offsets, required_interval_heights = EpochRenderingMixin.build_stacked_epoch_layout(desired_interval_height_ratios, epoch_render_stack_height=20.0, interval_stack_location='below')\n",
    "stacked_epoch_layout_dict = {interval_key:dict(y_location=y_location, height=height) for interval_key, y_location, height in zip(rendered_interval_keys, required_vertical_offsets, required_interval_heights)} # Build a stacked_epoch_layout_dict to update the display\n",
    "active_2d_plot.update_rendered_intervals_visualization_properties(stacked_epoch_layout_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd240080",
   "metadata": {},
   "source": [
    "##  ipcDataExplorer - 3D Interactive Tuning Curves Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5568d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_display_function_docs_dict\n",
    "\n",
    "'_display_3d_image_plotter'\n",
    "'_display_long_short_laps'\n",
    "'_display_3d_interactive_custom_data_explorer'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c55128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.InteractiveDataExplorerBase import InteractiveDataExplorerBase\n",
    "# from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.InteractiveCustomDataExplorer import InteractiveCustomDataExplorer # TypeError: super(type, obj): obj must be an instance or subtype of type\n",
    "\n",
    "active_config_name = global_epoch_context\n",
    "# curr_active_pipeline.reload_default_display_functions()\n",
    "# _out = curr_active_pipeline.display('_display_3d_interactive_custom_data_explorer', long_epoch_name) # long_epoch_context\n",
    "display_dict = curr_active_pipeline.display('_display_3d_interactive_custom_data_explorer', active_config_name) # does not work, missing color info?\n",
    "iplapsDataExplorer = display_dict['iplapsDataExplorer']\n",
    "# plotter is available at\n",
    "p = display_dict['plotter']\n",
    "iplapsDataExplorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5ac39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "# df = pd.DataFrame([curr_active_pipeline.registered_display_function_docs_dict])\n",
    "# df = curr_active_pipeline.registered_display_function_docs_dict\n",
    "df = pd.DataFrame.from_dict(curr_active_pipeline.registered_display_function_docs_dict, orient='index', columns=['Value'])\n",
    "display_widget = widgets.Output()\n",
    "with display_widget:\n",
    "\tdisplay(df)\n",
    "display_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8949a4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.matplotlib_helpers import plot_position_curves_figure\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1df3828",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "graphics_output_dict = curr_active_pipeline.display('_display_long_short_laps', active_identifying_session_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5c4871",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out3 = curr_active_pipeline.display('_display_long_and_short_stacked_epoch_slices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c64ae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.laps import plot_lap_trajectories_3d\n",
    "# ## single_combined_plot == True mode (mode 1.):\n",
    "# p, laps_pages = plot_lap_trajectories_3d(curr_active_pipeline.sess, single_combined_plot=True)\n",
    "# p.show()\n",
    "\n",
    "## single_combined_plot == False mode (mode 2.):        \n",
    "p, laps_pages = plot_lap_trajectories_3d(curr_active_pipeline.sess, single_combined_plot=False, curr_num_subplots=len(curr_active_pipeline.sess.laps.lap_id), active_page_index=0)\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5ec90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.laps import plot_lap_trajectories_2d\n",
    "\n",
    "p_laps_2D, axs_laps_2D, laps_2D_pages = plot_lap_trajectories_2d(curr_active_pipeline.sess, curr_num_subplots=5, active_page_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428ddaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_laps_2D.suptitle('plot_lap_trajectories_2d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21c4da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = axs_laps_2D[0,0]\n",
    "ax_empty = axs_laps_2D[-1,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8b777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_track_position_offset = 1.0 * long_track_dims.compute_position_offset(grid_bin_bounds=grid_bin_bounds) # array([49.43, 140.61])\n",
    "long_track_position_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651f665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_bin_bounds_center_point = (point_tuple_mid_point(grid_bin_bounds[0]), point_tuple_mid_point(grid_bin_bounds[1])) # (145.43, 140.61)\n",
    "print(f'grid_bin_bounds_center_point: {grid_bin_bounds_center_point}')\n",
    "x_midpoint, y_midpoint = grid_bin_bounds_center_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77188bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_annotation_man = UserAnnotationsManager()\n",
    "user_annotations = user_annotation_man.get_user_annotations()\n",
    "\n",
    "final_context_L = curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='replays', decoder='long_results_obj')\n",
    "final_context_S = curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='replays', decoder='short_results_obj')\n",
    "# _out_pagination_controller.params.active_identifying_figure_ctx.adding_context(None,  user_annotation=\"selections\")\n",
    "selections_context_L = final_context_L.adding_context(None,  user_annotation=\"selections\")\n",
    "selections_context_S = final_context_S.adding_context(None,  user_annotation=\"selections\")\n",
    "\n",
    "## try to get the user annotations for this session:\n",
    "try:\n",
    "\tselection_idxs_L = user_annotations[selections_context_L]\n",
    "\tselection_idxs_S = user_annotations[selections_context_S]\n",
    "except KeyError as e:\n",
    "\tif allow_interactive_selection:\n",
    "\t\tprint(f'user annotations <good replay selections> are not found. Creating them interactively...')\n",
    "\t\tuser_annotations = interactive_good_epoch_selections(annotations_man=user_annotation_man, curr_active_pipeline=curr_active_pipeline)  # perform interactive selection. Should block here.\n",
    "\t\tselection_idxs_L = user_annotations[selections_context_L]\n",
    "\t\tselection_idxs_S = user_annotations[selections_context_S]\n",
    "\telse:\n",
    "\t\tprint(f'interactive annotation is not permitted. Failing.')\n",
    "\t\traise e\n",
    "except Exception as e:\n",
    "\tprint('Unhandled exception: {e}')\n",
    "\traise\n",
    "\n",
    "# for updating the filter_epochs_df (`filter_epochs_df`) from the selections:\n",
    "self.filter_epochs_df['long_is_user_included'] = np.isin(self.filter_epochs_df.index, selection_idxs_L)\n",
    "self.filter_epochs_df['short_is_user_included'] = np.isin(self.filter_epochs_df.index, selection_idxs_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bcd4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdf off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5ffd7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a222ab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from neuropy.utils.mixins.binning_helpers import transition_matrix\n",
    "\n",
    "### 1D Transition Matrix:\n",
    "\n",
    "def _compute_position_transition_matrix(xbin_labels, binned_x: np.ndarray, n_powers:int=3):\n",
    "\t\"\"\"  1D Transition Matrix from binned positions (e.g. 'binned_x')\n",
    "\n",
    "\t\tpf1D.xbin_labels # array([  1,   2,   3,   4,  ...)\n",
    "\t\tpf1D.filtered_pos_df['binned_x'].to_numpy() # array([116, 115, 115, ...,  93,  93,  93], dtype=int64)\n",
    "\t\"\"\"\n",
    "\tnum_position_states = len(xbin_labels)\n",
    "\t# binned_x = pos_1D.to_numpy()\n",
    "\tbinned_x_indicies = binned_x - 1\n",
    "\tbinned_x_transition_matrix = transition_matrix(deepcopy(binned_x_indicies), markov_order=1, max_state_index=num_position_states)\n",
    "\t# binned_x_transition_matrix_higher_order_list = [binned_x_transition_matrix, transition_matrix(deepcopy(binned_x_indicies), markov_order=2, max_state_index=num_position_states), transition_matrix(deepcopy(binned_x_indicies), markov_order=3, max_state_index=num_position_states)]\n",
    "\n",
    "\tbinned_x_transition_matrix[np.isnan(binned_x_transition_matrix)] = 0.0\n",
    "\tbinned_x_transition_matrix_higher_order_list = [binned_x_transition_matrix] + [np.linalg.matrix_power(binned_x_transition_matrix, n) for n in np.arange(2, n_powers+1)]\n",
    "\t# , np.linalg.matrix_power(binned_x_transition_matrix, 2), np.linalg.matrix_power(binned_x_transition_matrix, 3)\n",
    "\t# binned_x_transition_matrix.shape # (64, 64)\n",
    "\treturn binned_x_transition_matrix_higher_order_list\n",
    "\n",
    "def _build_decoded_positions_transition_matrix(active_one_step_decoder):\n",
    "\t\"\"\" Compute the transition_matrix from the decoded positions \n",
    "\n",
    "\tTODO: make sure that separate events (e.g. separate replays) are not truncated creating erronious transitions\n",
    "\n",
    "\t\"\"\"\n",
    "\t# active_time_window_variable = active_one_step_decoder.time_window_centers # get time window centers (n_time_window_centers,) # (4060,)\n",
    "\t# active_most_likely_positions = active_one_step_decoder.most_likely_positions.T # (4060, 2) NOTE: the most_likely_positions for the active_one_step_decoder are tranposed compared to the active_two_step_decoder\n",
    "\t# active_most_likely_positions = active_two_step_decoder.most_likely_positions # (2, 4060)\n",
    "\tactive_one_step_decoder.most_likely_position_flat_indicies\n",
    "\t# active_most_likely_positions = active_one_step_decoder.revised_most_likely_positions.T\n",
    "\t# active_most_likely_positions #.shape # (36246,)\n",
    "\n",
    "\tmost_likely_position_indicies = np.squeeze(np.array(np.unravel_index(active_one_step_decoder.most_likely_position_flat_indicies, active_one_step_decoder.original_position_data_shape))) # convert back to an array\n",
    "\tmost_likely_position_xbins = most_likely_position_indicies + 1 # add 1 to convert back to a bin label from an index\n",
    "\t# most_likely_position_indicies # (1, 36246)\n",
    "\n",
    "\txbin_labels = np.arange(active_one_step_decoder.original_position_data_shape[0]) + 1\n",
    "\n",
    "\tdecoded_binned_x_transition_matrix_higher_order_list = _compute_position_transition_matrix(xbin_labels, most_likely_position_indicies)\n",
    "\treturn decoded_binned_x_transition_matrix_higher_order_list, xbin_labels\n",
    "\n",
    "\n",
    "# pf1D = deepcopy(curr_active_pipeline.computation_results['maze1'].computed_data['pf1D'])\n",
    "pf1D = deepcopy(global_pf1D)\n",
    "# pf1D = deepcopy(short_pf1D)\n",
    "# pf1D = deepcopy(long_pf1D)\n",
    "binned_x_transition_matrix_higher_order_list = _compute_position_transition_matrix(pf1D.xbin_labels, pf1D.filtered_pos_df['binned_x'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dec59e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf1D.filtered_pos_df.plot(x='t',y='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb355dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization ______________________________________________________________________________________________________ #\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow, LayoutScrollability\n",
    "out = BasicBinnedImageRenderingWindow(binned_x_transition_matrix_higher_order_list[0], pf1D.xbin_labels, pf1D.xbin_labels, name='binned_x_transition_matrix', title=\"Transition Matrix for binned x (from, to)\", variable_label='Transition Matrix', scrollability_mode=LayoutScrollability.NON_SCROLLABLE)\n",
    "# out.add_data(row=1, col=0, matrix=active_eloy_analysis.pf_overlapDensity_2D, xbins=active_pf_2D_dt.xbin_labels, ybins=active_pf_2D_dt.ybin_labels, name='pf_overlapDensity', title='pf overlapDensity metric', variable_label='pf overlapDensity')\n",
    "\n",
    "# out.add_data(row=1, col=0, matrix=binned_x_transition_matrix_higher_order_list[1], xbins=pf1D.xbin_labels, ybins=pf1D.ybin_labels, name='binned_x_transition_matrix^2', title='2nd Order Transition Matrix for binned x (from, to)', variable_label='2nd Order Transition Matrix') # , scrollability_mode=LayoutScrollability.NON_SCROLLABLE\n",
    "# out.add_data(row=2, col=0, matrix=binned_x_transition_matrix_higher_order_list[2], xbins=pf1D.xbin_labels, ybins=pf1D.ybin_labels, name='binned_x_transition_matrix^3', title='3rd Order Transition Matrix for binned x (from, to)', variable_label='3rd Order Transition Matrix') # , scrollability_mode=LayoutScrollability.NON_SCROLLABLE\n",
    "\n",
    "# Separate Windows for each:\n",
    "# out2 = BasicBinnedImageRenderingWindow(binned_x_transition_matrix_higher_order_list[1], pf1D.xbin_labels, pf1D.xbin_labels, name='binned_x_transition_matrix^2', title=\"2nd Order Transition Matrix for binned x (from, to)\", variable_label='2nd Order Transition Matrix', scrollability_mode=LayoutScrollability.NON_SCROLLABLE)\n",
    "# out3 = BasicBinnedImageRenderingWindow(binned_x_transition_matrix_higher_order_list[2], pf1D.xbin_labels, pf1D.xbin_labels, name='binned_x_transition_matrix^3', title=\"3rd Order Transition Matrix for binned x (from, to)\", variable_label='3rd Order Transition Matrix', scrollability_mode=LayoutScrollability.NON_SCROLLABLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990e5f54",
   "metadata": {},
   "source": [
    "## 1. Compute the transition_matrix from the decoded positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e5db7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BayesianPlacemapPositionDecoder\n",
    "# active_one_step_decoder = deepcopy(long_one_step_decoder_1D) # long_results_obj.original_1D_decoder\n",
    "long_decoded_binned_x_transition_matrix_higher_order_list, long_xbin_labels = _build_decoded_positions_transition_matrix(active_one_step_decoder=deepcopy(long_one_step_decoder_1D))\n",
    "short_decoded_binned_x_transition_matrix_higher_order_list, short_xbin_labels = _build_decoded_positions_transition_matrix(active_one_step_decoder=deepcopy(short_one_step_decoder_1D))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcddd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_decoded = BasicBinnedImageRenderingWindow(decoded_binned_x_transition_matrix_higher_order_list[0], active_one_step_decoder.xbin_centers, active_one_step_decoder.xbin_centers, name='decoded_binned_x_transition_matrix', title=\"DECODED Transition Matrix for binned x (from, to)\", variable_label='Transition Matrix', scrollability_mode=LayoutScrollability.NON_SCROLLABLE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea34522",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "out = BasicBinnedImageRenderingWindow(binned_x_transition_matrix_higher_order_list[i], pf1D.xbin_labels, pf1D.xbin_labels, name='binned_x_transition_matrix', title=\"Transition Matrix for binned x (from, to)\", variable_label='Transition Matrix', scrollability_mode=LayoutScrollability.NON_SCROLLABLE)\n",
    "out.add_data(row=1, col=0, matrix=long_decoded_binned_x_transition_matrix_higher_order_list[i], xbins=long_xbin_labels, ybins=long_xbin_labels, name='long_decoded_binned_x_transition_matrix', title='Long DECODED Transition Matrix', variable_label='long decoded')\n",
    "out.add_data(row=2, col=0, matrix=short_decoded_binned_x_transition_matrix_higher_order_list[i], xbins=short_xbin_labels, ybins=short_xbin_labels, name='short_decoded_binned_x_transition_matrix', title='Short DECODED Transition Matrix', variable_label='short decoded')\n",
    "# out.add_data(row=1, col=0, matrix=binned_x_transition_matrix_higher_order_list[1], xbins=pf1D.xbin_labels, ybins=pf1D.ybin_labels, name='binned_x_transition_matrix^2', title='2nd Order Transition Matrix for binned x (from, to)', variable_label='2nd Order Transition Matrix') # , scrollability_mode=LayoutScrollability.NON_SCROLLABLE\n",
    "# out.add_data(row=2, col=0, matrix=binned_x_transition_matrix_higher_order_list[2], xbins=pf1D.xbin_labels, ybins=pf1D.ybin_labels, name='binned_x_transition_matrix^3', title='3rd Order Transition Matrix for binned x (from, to)', variable_label='3rd Order Transition Matrix') # , scrollability_mode=LayoutScrollability.NON_SCROLLABLE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fb7eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_one_step_decoder.most_likely_position_indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a8f4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## 2. Use the position transition matrix to determine how likely each decoded position's transition is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87cd169",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_binned_instantaneous_unit_specific_spike_rate = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.time_binned_instantaneous_unit_specific_spike_rate\n",
    "timestamps = time_binned_instantaneous_unit_specific_spike_rate.time_bins\n",
    "\n",
    "value_df = time_binned_instantaneous_unit_specific_spike_rate.instantaneous_unit_specific_spike_rate_values\n",
    "value_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0807be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of spikes version:\n",
    "time_binned_unit_specific_spike_rate = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.time_binned_unit_specific_spike_rate\n",
    "timestamps = time_binned_unit_specific_spike_rate.time_bins\n",
    "value_df = time_binned_unit_specific_spike_rate.time_binned_unit_specific_binned_spike_rate\n",
    "value_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7d4397",
   "metadata": {},
   "source": [
    "# global_computations pickling experiment\n",
    "global_computation_result has some representation of the global functions? Noticed that changing one of the `validate_computation_test` for a function resulted in the resultant pipeline being unpicklable although the data I added wasn't an issue.\n",
    "\n",
    "```python\n",
    "@function_attributes(short_name='long_short_fr_indicies_analyses', tags=['short_long','firing_rate', 'computation'], input_requires=[], output_provides=['long_short_fr_indicies_analysis'], uses=['pipeline_complete_compute_long_short_fr_indicies'], used_by=[], creation_date='2023-04-11 00:00', \n",
    "                         validate_computation_test=lambda curr_active_pipeline, computation_filter_name='maze': (curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis'], curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']['long_short_fr_indicies_df']), is_global=True)\n",
    "```\n",
    "\n",
    "### //2023-9-29 2:48 AM: Confirmed pickling issue with global_computation_result due to storing functions implicitly in `.computation_times`\n",
    "Not sure whether to convert to just use `a_fn.__name__` or some other non-changing identifier. The function is never used from the keys, I basically just want it to be a dynamic reference to the current version of the function although it might be useful to be able to see if the function has been modified in any way since last compute.\n",
    "\n",
    "[/c:/Users/pho/repos/Spike3DWorkEnv/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Model/ComputationResults.py:124](vscode://file/c:/Users/pho/repos/Spike3DWorkEnv/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/General/Model/ComputationResults.py:124)\n",
    "```python\n",
    "computation_times = state.pop('computation_times', None)\n",
    "        if computation_times is not None:\n",
    "            ## Strip the parameter-ness of the items:\n",
    "            computation_times = {str(fn.__name__):a_time for fn, a_time in computation_times.items()} # extract just the name from the function.\n",
    "            state['computation_times'] = computation_times # add back in\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eb50ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "_test_obj = curr_active_pipeline.global_computation_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c52cdf4",
   "metadata": {},
   "source": [
    "computation_times=DynamicParameters({<function LongShortTrackComputations._perform_long_short_decoding_analyses at 0x000001C818E06AF0>: datetime.datetime(2023, 9, 11, 11, 19, 49, 530975), <function LongShortTrackComputations._perform_long_short_firing_rate_analyses at 0x000001C818E06DC0>: datetime.datetime(2023, 9, 11, 11, 20, 40, 45474), <function LongShortTrackComputations._perform_jonathan_replay_firing_rate_analyses at 0x000001C818E06F70>: datetime.datetime(2023, 9, 11, 11, 20, 41, 5600), <function LongShortTrackComputations._perform_long_short_post_decoding_analysis at 0x000001C8194DB310>: datetime.datetime(2023, 9, 11, 11, 20, 43, 767961), <function LongShortTrackComputations._perform_long_short_endcap_analysis at 0x000001C8194DB5E0>: datetime.datetime(2023, 9, 19, 8, 24, 52, 891582), <function LongShortTrackComputations._perform_long_short_pf_overlap_analyses at 0x000001C8194DB820>: datetime.datetime(2023, 9, 28, 20, 32, 8, 468427), <function LongShortTrackComputations._perform_long_short_firing_rate_analyses at 0x000001C8194DB9D0>: datetime.datetime(2023, 9, 28, 20, 33, 4, 411283), <function LongShortTrackComputations._perform_jonathan_replay_firing_rate_analyses at 0x000001C8194DBB80>: datetime.datetime(2023, 9, 28, 20, 33, 5, 809308)}))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18de5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "_test_obj.computation_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8948a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dill.detect.badtypes(_test_obj) # pyphoplacecellanalysis.General.Model.ComputationResults.ComputationResult\n",
    "dill.detect.baditems(_test_obj)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
