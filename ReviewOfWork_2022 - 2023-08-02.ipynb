{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0056bc66-7629-4ef7-8c87-f28f8fcd9dc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T16:05:33.406068Z",
     "start_time": "2023-07-29T16:05:29.356227600Z"
    },
    "autorun": true,
    "tags": [
     "imports",
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "build_module_logger(module_name=\"Spike3D.pipeline\"):\n",
      "\t Module logger com.PhoHale.Spike3D.pipeline has file logging enabled and will log to EXTERNAL\\TESTING\\Logging\\debug_com.PhoHale.Spike3D.pipeline.log\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "# %load_ext viztracer\n",
    "# from viztracer import VizTracer\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import neptune # for logging progress and results\n",
    "from pyphoplacecellanalysis.General.Batch.NeptuneAiHelpers import set_environment_variables, neptune_output_figures\n",
    "neptune_kwargs = {'project':\"commander.pho/PhoDibaLongShort2023\",\n",
    "'api_token':\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIxOGIxODU2My1lZTNhLTQ2ZWMtOTkzNS02ZTRmNzM5YmNjNjIifQ==\"}\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "from copy import deepcopy\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "from attrs import define, field, fields, Factory\n",
    "\n",
    "# Pho's Formatting Preferences\n",
    "# from pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\n",
    "# set_pho_preferences_concise()\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "# from neuropy import core\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.core.epoch import NamedTimerange, Epoch\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.utils.matplotlib_helpers import matplotlib_file_only, matplotlib_configuration, matplotlib_configuration_update\n",
    "from neuropy.core.neuron_identities import NeuronIdentityTable, neuronTypesList, neuronTypesEnum\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "from neuropy.core.neurons import NeuronType\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from neuropy.core.position import Position\n",
    "\n",
    "from pyphocorehelpers.print_helpers import print_object_memory_usage, print_dataframe_memory_usage, print_value_overview_only, DocumentationFilePrinter, print_keys_if_possible, generate_html_string\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_load_session, batch_extended_computations, batch_extended_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import _find_any_context_neurons\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchSessionCompletionHandler # for `post_compute_validate(...)`\n",
    "from neuropy.utils.mixins.AttrsClassHelpers import AttrsBasedClassHelperMixin, serialized_field, serialized_attribute_field, non_serialized_field\n",
    "from neuropy.utils.mixins.HDF5_representable import HDF_DeserializationMixin, post_deserialize, HDF_SerializationMixin, HDFMixin\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BasePositionDecoder\n",
    "\n",
    "# Plotting\n",
    "import pylustrator # customization of figures\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "# import pylustrator # call `pylustrator.start()` before creating your first figure in code.\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot, plot_raster_plot\n",
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import DataSeriesColorHelpers\n",
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import UnitColoringMode, DataSeriesColorHelpers\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import _build_default_tick, build_scatter_plot_kwargs\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.Render2DScrollWindowPlot import Render2DScrollWindowPlotMixin, ScatterItemData\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_extended_programmatic_figures, batch_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PAPER_FIGURE_figure_1_add_replay_epoch_rasters, PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_3, main_complete_figure_generations\n",
    "\n",
    "global_data_root_parent_path = find_first_extant_path([Path(r'W:\\Data'), Path(r'/media/MAX/Data'), Path(r'/Volumes/MoverNew/data'), Path(r'/home/halechr/turbo/Data')])\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1538e2a-4e39-4d11-90b5-a9fef9258058",
   "metadata": {
    "tags": [
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "source": [
    "# Load Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f917bad9-8fe7-4882-b83b-71cf878fffd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T16:05:43.785201Z",
     "start_time": "2023-07-29T16:05:34.880381100Z"
    },
    "tags": [
     "load",
     "REQUIRED"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "basedir: W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\n",
      "Loading loaded session pickle file results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\loadedSessPickle.pkl... done.\n",
      "Loading pickled pipeline success: W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\loadedSessPickle.pkl.\n",
      "property already present in pickled version. No need to save.\n",
      "using provided computation_functions_name_includelist: ['_perform_baseline_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_two_step_position_decoding_computation']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "Loading loaded session pickle file results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\output\\global_computation_results.pkl... done.\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "included includelist is specified: ['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis already computed.\n",
      "long_short_fr_indicies_analyses already computed.\n",
      "long_short_decoding_analyses already computed.\n",
      "long_short_post_decoding already computed.\n",
      "done with all batch_extended_computations(...).\n",
      "no changes in global results.\n"
     ]
    }
   ],
   "source": [
    "%pdb off\n",
    "# ==================================================================================================================== #\n",
    "# Load Data                                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "active_data_mode_name = 'kdiba'\n",
    "local_session_root_parent_context = IdentifyingContext(format_name=active_data_mode_name) # , animal_name='', configuration_name='one', session_name=self.session_name\n",
    "local_session_root_parent_path = global_data_root_parent_path.joinpath('KDIBA')\n",
    "\n",
    "# [*] - indicates bad or session with a problem\n",
    "# 0, 1, 2, 3, 4, 5, 6, 7, [8], [9], 10, 11, [12], 13, 14, [15], [16], 17, \n",
    "# curr_context: IdentifyingContext = good_contexts_list[1] # select the session from all of the good sessions here.\n",
    "curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15') # DONE. Very good. Many good Pfs, many good replays.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43') # DONE, might be the BEST SESSION, good example session with lots of place cells, clean replays, and clear bar graphs.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31') # DONE, Good Pfs but no good replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-13_14-42-6') # BAD, 2023-07-14, unsure why still.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19') # DONE, GREAT, both good Pfs and replays!\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25') # DONE, Added replay selections. Very \"jumpy\" between the starts and ends of the track.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40') # DONE, Added replay selections. A TON of putative replays in general, most bad, but some good.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46') # DONE, added replay selections. Very few (like 12) replays each.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-13_15-22-3') # DONE, Good Pfs, no good epochs.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30') # DONE, okay replays (selected)\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50') # DONE, very few replays (selected)\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-19_13-34-40') # BAD\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54') # DONE, one replay each (selected)\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3') # BAD, Good Pfs strangely despite horrible map, no good epochs\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-12_15-25-59') # BAD, No Epochs\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-16_18-47-52')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-17_12-52-15')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-25_13-20-55')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-28_12-38-13')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44') # DONE, good. Many good pfs, many good replays.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0') # DONE, good?, replays selected, few\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25') # DONE, very few replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_12-15-3')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_22-4-5')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54') # DONE, replays selected, quite a few replays but few are very good.\n",
    "\n",
    "local_session_parent_path: Path = local_session_root_parent_path.joinpath(curr_context.animal, curr_context.exper_name) # 'gor01', 'one' - probably not needed anymore\n",
    "basedir: Path = local_session_parent_path.joinpath(curr_context.session_name).resolve()\n",
    "print(f'basedir: {str(basedir)}')\n",
    "\n",
    "# Read if possible:\n",
    "saving_mode = PipelineSavingScheme.SKIP_SAVING\n",
    "force_reload = False\n",
    "\n",
    "# Force write:\n",
    "# saving_mode = PipelineSavingScheme.TEMP_THEN_OVERWRITE\n",
    "# saving_mode = PipelineSavingScheme.OVERWRITE_IN_PLACE\n",
    "# force_reload = True\n",
    "\n",
    "## TODO: if loading is not possible, we need to change the `saving_mode` so that the new results are properly saved.\n",
    "\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-full_session_LOO_decoding_analysis.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "# epoch_name_includelist = ['maze']\n",
    "epoch_name_includelist = None\n",
    "active_computation_functions_name_includelist=[#'_perform_estimated_epochs_computation',  # AL:WAYS OFF\n",
    "                                            '_perform_baseline_placefield_computation',\n",
    "                                        # '_perform_time_dependent_placefield_computation', # AL:WAYS OFF\n",
    "                                        '_perform_extended_statistics_computation',\n",
    "                                        '_perform_position_decoding_computation', \n",
    "                                        '_perform_firing_rate_trends_computation',\n",
    "                                        '_perform_pf_find_ratemap_peaks_computation',\n",
    "                                        # '_perform_time_dependent_pf_sequential_surprise_computation' # AL:WAYS OFF\n",
    "                                        '_perform_two_step_position_decoding_computation',\n",
    "                                        # '_perform_recursive_latent_placefield_decoding' # AL:WAYS OFF\n",
    "                                    ]\n",
    "# active_computation_functions_name_includelist=['_perform_baseline_placefield_computation']\n",
    "\n",
    "curr_active_pipeline: NeuropyPipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_includelist=epoch_name_includelist,\n",
    "                                        computation_functions_name_includelist=active_computation_functions_name_includelist,\n",
    "                                        saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                        skip_extended_batch_computations=True, debug_print=False, fail_on_exception=False) # , active_pickle_filename = 'loadedSessPickle_withParameters.pkl'\n",
    "\n",
    "\n",
    "if not force_reload: # not just force_reload, needs to recompute whenever the computation fails.\n",
    "    try:\n",
    "        curr_active_pipeline.load_pickled_global_computation_results()\n",
    "    except Exception as e:\n",
    "        print(f'cannot load global results: {e}')\n",
    "\n",
    "# 6m 1.1s\n",
    "# 12m 15.6s\n",
    "\n",
    "try:\n",
    "    ## Post Compute Validate 2023-05-16:\n",
    "    was_updated = BatchSessionCompletionHandler.post_compute_validate(curr_active_pipeline) ## TODO: need to potentially re-save if was_updated\n",
    "    if was_updated:\n",
    "        try:\n",
    "            curr_active_pipeline.save_pipeline(saving_mode=saving_mode)\n",
    "        except Exception as e:\n",
    "            ## TODO: catch/log saving error and indicate that it isn't saved.\n",
    "            print(f'ERROR RE-SAVING PIPELINE after update. error: {e}')\n",
    "\n",
    "    curr_active_pipeline.reload_default_computation_functions()\n",
    "    extended_computations_include_includelist=['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding'] # do only specifiedl , 'long_short_rate_remapping'\n",
    "    force_recompute_global = force_reload\n",
    "    newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True, force_recompute=force_recompute_global, debug_print=False)\n",
    "    if (len(newly_computed_values) > 0) and (saving_mode.value != 'skip_saving'):\n",
    "        print(f'newly_computed_values: {newly_computed_values}. Saving global results...')\n",
    "        try:\n",
    "            # curr_active_pipeline.global_computation_results.persist_time = datetime.now()\n",
    "            # Try to write out the global computation function results:\n",
    "            curr_active_pipeline.save_global_computation_results()\n",
    "        except Exception as e:\n",
    "            print(f'\\n\\n!!WARNING!!: saving the global results threw the exception: {e}')\n",
    "            print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "    else:\n",
    "        print(f'no changes in global results.')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'second half threw: {e}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c850782f",
   "metadata": {},
   "source": [
    "# End Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87dc7ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## long_short_decoding_analyses:\n",
    "curr_long_short_decoding_analyses = curr_active_pipeline.global_computation_results.computed_data['long_short_leave_one_out_decoding_analysis']\n",
    "## Extract variables from results object:\n",
    "long_one_step_decoder_1D, short_one_step_decoder_1D, long_replays, short_replays, global_replays, long_shared_aclus_only_decoder, short_shared_aclus_only_decoder, shared_aclus, long_short_pf_neurons_diff, n_neurons, long_results_obj, short_results_obj, is_global = curr_long_short_decoding_analyses.long_decoder, curr_long_short_decoding_analyses.short_decoder, curr_long_short_decoding_analyses.long_replays, curr_long_short_decoding_analyses.short_replays, curr_long_short_decoding_analyses.global_replays, curr_long_short_decoding_analyses.long_shared_aclus_only_decoder, curr_long_short_decoding_analyses.short_shared_aclus_only_decoder, curr_long_short_decoding_analyses.shared_aclus, curr_long_short_decoding_analyses.long_short_pf_neurons_diff, curr_long_short_decoding_analyses.n_neurons, curr_long_short_decoding_analyses.long_results_obj, curr_long_short_decoding_analyses.short_results_obj, curr_long_short_decoding_analyses.is_global\n",
    "\n",
    "# (long_one_step_decoder_1D, short_one_step_decoder_1D), (long_one_step_decoder_2D, short_one_step_decoder_2D) = compute_short_long_constrained_decoders(curr_active_pipeline, recalculate_anyway=True)\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_epoch_context, short_epoch_context, global_epoch_context = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_epoch_name, short_epoch_name, global_epoch_name)]\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_computation_config, short_computation_config, global_computation_config = [curr_active_pipeline.computation_results[an_epoch_name]['computation_config'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "long_pf2D, short_pf2D, global_pf2D = long_results.pf2D, short_results.pf2D, global_results.pf2D\n",
    "decoding_time_bin_size = long_one_step_decoder_1D.time_bin_size # 1.0/30.0 # 0.03333333333333333\n",
    "\n",
    "## Get global 'long_short_post_decoding' results:\n",
    "curr_long_short_post_decoding = curr_active_pipeline.global_computation_results.computed_data['long_short_post_decoding']\n",
    "expected_v_observed_result, curr_long_short_rr = curr_long_short_post_decoding.expected_v_observed_result, curr_long_short_post_decoding.rate_remapping\n",
    "rate_remapping_df, high_remapping_cells_only = curr_long_short_rr.rr_df, curr_long_short_rr.high_only_rr_df\n",
    "Flat_epoch_time_bins_mean, Flat_decoder_time_bin_centers, num_neurons, num_timebins_in_epoch, num_total_flat_timebins, is_short_track_epoch, is_long_track_epoch, short_short_diff, long_long_diff = expected_v_observed_result['Flat_epoch_time_bins_mean'], expected_v_observed_result['Flat_decoder_time_bin_centers'], expected_v_observed_result['num_neurons'], expected_v_observed_result['num_timebins_in_epoch'], expected_v_observed_result['num_total_flat_timebins'], expected_v_observed_result['is_short_track_epoch'], expected_v_observed_result['is_long_track_epoch'], expected_v_observed_result['short_short_diff'], expected_v_observed_result['long_long_diff']\n",
    "\n",
    "jonathan_firing_rate_analysis_result = JonathanFiringRateAnalysisResult(**curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.to_dict())\n",
    "(epochs_df_L, epochs_df_S), (filter_epoch_spikes_df_L, filter_epoch_spikes_df_S), (good_example_epoch_indicies_L, good_example_epoch_indicies_S), (short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset), new_all_aclus_sort_indicies, assigning_epochs_obj = PAPER_FIGURE_figure_1_add_replay_epoch_rasters(curr_active_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdfc81e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use the `long_short_decoding_analyses` global result to access `long_results_obj.active_filter_epochs`:\n",
    "curr_long_short_decoding_analyses = curr_active_pipeline.global_computation_results.computed_data['long_short_leave_one_out_decoding_analysis']\n",
    "long_one_step_decoder_1D, short_one_step_decoder_1D, long_replays, short_replays, global_replays, long_shared_aclus_only_decoder, short_shared_aclus_only_decoder, shared_aclus, long_short_pf_neurons_diff, n_neurons, long_results_obj, short_results_obj, is_global = curr_long_short_decoding_analyses.long_decoder, curr_long_short_decoding_analyses.short_decoder, curr_long_short_decoding_analyses.long_replays, curr_long_short_decoding_analyses.short_replays, curr_long_short_decoding_analyses.global_replays, curr_long_short_decoding_analyses.long_shared_aclus_only_decoder, curr_long_short_decoding_analyses.short_shared_aclus_only_decoder, curr_long_short_decoding_analyses.shared_aclus, curr_long_short_decoding_analyses.long_short_pf_neurons_diff, curr_long_short_decoding_analyses.n_neurons, curr_long_short_decoding_analyses.long_results_obj, curr_long_short_decoding_analyses.short_results_obj, curr_long_short_decoding_analyses.is_global\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb580a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.sess.neurons.t_stop\n",
    "print(list(curr_active_pipeline.sess.neurons.to_dict().keys()))\n",
    "\n",
    "# {'t_start': self.t_start, 't_stop': self.t_stop, 'n_neurons': self.n_neurons}\n",
    "\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9f06fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.neurons.to_hdf('output/test_neuron_out.h5', key='neurons', session_uid='session_uid')\t # AttributeError: 'Neurons' object has no attribute '_spikes_df'... WTF?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f8e2d5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchNodeError",
     "evalue": "group ``/neuron_identities/neuron_identities`` does not have a child named ``attrs``",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchNodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyphoplacecellanalysis\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mGeneral\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mBatch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mAcrossSessionResults\u001b[39;00m \u001b[39mimport\u001b[39;00m AcrossSessionsResults\n\u001b[1;32m----> 2\u001b[0m AcrossSessionsResults\u001b[39m.\u001b[39;49mbuild_neuron_identity_table_to_hdf(\u001b[39m'\u001b[39;49m\u001b[39moutput/test_neuron_identities_out.h5\u001b[39;49m\u001b[39m'\u001b[39;49m, key\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/neuron_identities\u001b[39;49m\u001b[39m'\u001b[39;49m, spikes_df\u001b[39m=\u001b[39;49mcurr_active_pipeline\u001b[39m.\u001b[39;49msess\u001b[39m.\u001b[39;49mspikes_df, session_uid\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msession_uid\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Batch\\AcrossSessionResults.py:110\u001b[0m, in \u001b[0;36mAcrossSessionsResults.build_neuron_identity_table_to_hdf\u001b[1;34m(cls, file_path, key, spikes_df, session_uid)\u001b[0m\n\u001b[0;32m    107\u001b[0m table\u001b[39m.\u001b[39mflush()\n\u001b[0;32m    109\u001b[0m \u001b[39m# Metadata:\u001b[39;00m\n\u001b[1;32m--> 110\u001b[0m group\u001b[39m.\u001b[39;49mattrs[\u001b[39m'\u001b[39m\u001b[39mn_neurons\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m n_neurons\n\u001b[0;32m    111\u001b[0m group\u001b[39m.\u001b[39mattrs[\u001b[39m'\u001b[39m\u001b[39msession_uid\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m session_uid\n",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\tables\\group.py:798\u001b[0m, in \u001b[0;36mGroup.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    796\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_g_add_children_names()\n\u001b[0;32m    797\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m[name]\n\u001b[1;32m--> 798\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_f_get_child(name)\n",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\tables\\group.py:682\u001b[0m, in \u001b[0;36mGroup._f_get_child\u001b[1;34m(self, childname)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Get the child called childname of this group.\u001b[39;00m\n\u001b[0;32m    670\u001b[0m \n\u001b[0;32m    671\u001b[0m \u001b[39mIf the child exists (be it visible or not), it is returned.  Else, a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    677\u001b[0m \n\u001b[0;32m    678\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    680\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_g_check_open()\n\u001b[1;32m--> 682\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_g_check_has_child(childname)\n\u001b[0;32m    684\u001b[0m childpath \u001b[39m=\u001b[39m join_path(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_v_pathname, childname)\n\u001b[0;32m    685\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_v_file\u001b[39m.\u001b[39m_get_node(childpath)\n",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv\\lib\\site-packages\\tables\\group.py:375\u001b[0m, in \u001b[0;36mGroup._g_check_has_child\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    373\u001b[0m node_type \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_g_get_objinfo(name)\n\u001b[0;32m    374\u001b[0m \u001b[39mif\u001b[39;00m node_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mNoSuchNode\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 375\u001b[0m     \u001b[39mraise\u001b[39;00m NoSuchNodeError(\n\u001b[0;32m    376\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mgroup ``\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m`` does not have a child named ``\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m``\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m         \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_v_pathname, name))\n\u001b[0;32m    378\u001b[0m \u001b[39mreturn\u001b[39;00m node_type\n",
      "\u001b[1;31mNoSuchNodeError\u001b[0m: group ``/neuron_identities/neuron_identities`` does not have a child named ``attrs``"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsResults\n",
    "AcrossSessionsResults.build_neuron_identity_table_to_hdf('output/test_neuron_identities_out.h5', key='/', spikes_df=curr_active_pipeline.sess.spikes_df, session_uid='session_uid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cca46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.sess.neurons.spiketrains.shape # (108,)\n",
    "curr_active_pipeline.sess.neurons.spiketrains[0].shape # (235,)\n",
    "curr_active_pipeline.sess.neurons.spiketrains[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a7d269",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.flattened_spiketrains._spikes_df = add_explicit_dataframe_columns_from_lookup_df(curr_active_pipeline.sess.spikes_df, curr_active_pipeline.sess.neurons._extended_neuron_properties_df)\n",
    "curr_active_pipeline.sess.spikes_df.sort_values(by=['t_seconds'], inplace=True) # Need to re-sort by timestamps once done\n",
    "curr_active_pipeline.sess.spikes_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d3d700",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.neurons._extended_neuron_properties_df = pd.DataFrame() # add `neurons._extended_neuron_properties_df`\n",
    "\n",
    "['aclu', 'qclu', 'cell_type', 'shank', 'cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9b44de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tables as tb\n",
    "\n",
    "np.array([neuronTypesEnum[a_type.hdfcodingClassName] for a_type in curr_active_pipeline.sess.neurons.neuron_type])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655cf2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuronTypesEnum['pyr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecb0e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.spikes_df.n_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d644ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_grouped_spikes_df = curr_active_pipeline.sess.spikes_df.groupby(['aclu'])\n",
    "cell_spikes_dfs = [cell_grouped_spikes_df.get_group(a_neuron_id) for a_neuron_id in curr_active_pipeline.sess.spikes_df.spikes.neuron_ids] # a list of dataframes for each neuron_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a806c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_spikes_dfs[0][['shank', 'cluster', 'qclu']]\n",
    "\n",
    "\n",
    "\n",
    "curr_active_pipeline.sess.spikes_df.spikes.extract_unique_neuron_identities()\n",
    "\n",
    "# cell_spikes_dfs.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3aa948",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad000cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "[cell_grouped_spikes_df.get_group(a_neuron_id)['qclu'] for a_neuron_id in curr_active_pipeline.sess.spikes_df.spikes.neuron_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35478735",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.spikes_df.spikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7760523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'qclu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e16eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.neuron_replay_stats_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05725d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build general extended neuron info starting from `computed_neuron_info`:\n",
    "computed_neuron_info_df = deepcopy(jonathan_firing_rate_analysis_result.neuron_replay_stats_df)\n",
    "\n",
    "\n",
    "# computed_neuron_info['neuron_type'].to_numpy()\n",
    "\n",
    "def get_numpy_object_array_object_type(array):\n",
    "    assert len(array) > 0, f\"array must have at least one element to infer its type!\"\n",
    "    # pd.api.types.is_array_like(array)\n",
    "    # pd.api.types.is_object_dtype\n",
    "    if isinstance(array, pd.Series):\n",
    "        return type(array.values[0])\n",
    "    elif pd.api.types.is_list_like(array):\n",
    "        return type(array[0])\n",
    "    else:\n",
    "        raise TypeError\n",
    "    \n",
    "object_columns = computed_neuron_info_df.select_dtypes(include=['object']).columns\n",
    "object_columns_types = [get_numpy_object_array_object_type(computed_neuron_info_df[col]) for col in object_columns] # [<enum 'SplitPartitionMembership'>, <enum 'NeuronType'>]\n",
    "object_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81c8b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_neuron_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28bdc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns_types = [get_numpy_object_array_object_type(computed_neuron_info_df[col]) for col in object_columns]\n",
    "object_columns_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40063801",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns_types = [get_numpy_object_array_object_type(computed_neuron_info_df[col]) for col in object_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeeba40",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(computed_neuron_info['neuron_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6c6a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(computed_neuron_info['neuron_type'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eca2d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test automatic .to_hdf for BasePositionDecoder\n",
    "type(long_shared_aclus_only_decoder)\n",
    "\n",
    "long_shared_aclus_only_decoder.to_hdf('output/automatic_test.h5', '/long_shared_aclus_only_decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ea46b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import main_complete_figure_generations, InstantaneousSpikeRateGroupsComputation, SingleBarResult # for `BatchSessionCompletionHandler`\n",
    "\n",
    "_out_inst_fr_comps = InstantaneousSpikeRateGroupsComputation(instantaneous_time_bin_size_seconds=0.01) # 10ms\n",
    "_out_inst_fr_comps.compute(curr_active_pipeline=curr_active_pipeline, active_context=curr_active_pipeline.sess.get_context())\n",
    "LxC_ReplayDeltaMinus, LxC_ReplayDeltaPlus, SxC_ReplayDeltaMinus, SxC_ReplayDeltaPlus = _out_inst_fr_comps.LxC_ReplayDeltaMinus, _out_inst_fr_comps.LxC_ReplayDeltaPlus, _out_inst_fr_comps.SxC_ReplayDeltaMinus, _out_inst_fr_comps.SxC_ReplayDeltaPlus\n",
    "LxC_ThetaDeltaMinus, LxC_ThetaDeltaPlus, SxC_ThetaDeltaMinus, SxC_ThetaDeltaPlus = _out_inst_fr_comps.LxC_ThetaDeltaMinus, _out_inst_fr_comps.LxC_ThetaDeltaPlus, _out_inst_fr_comps.SxC_ThetaDeltaMinus, _out_inst_fr_comps.SxC_ThetaDeltaPlus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1600e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing `SingleBarResult` serialization:`\n",
    "_test_Fig2_Replay_FR: SingleBarResult = _out_inst_fr_comps.Fig2_Replay_FR[0]\n",
    "_test_Fig2_Replay_FR.to_hdf('output/automatic_test.h5', '/Fig2_Replay_FR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd419c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing `SpikeRateTrends` serialization\n",
    "_test_LxC_ReplayDeltaMinus: SpikeRateTrends = _out_inst_fr_comps.LxC_ReplayDeltaMinus #\n",
    "\n",
    "# _test_inst_fr_df_list: list[pd.DataFrame] = _test_LxC_ReplayDeltaMinus.inst_fr_df_list\n",
    "# inst_fr_df_list: a list containing a inst_fr_df for each epoch.\n",
    "# a `inst_fr_df` is a df with time bins along the rows and aclu values along the columns in the style of `unit_specific_binned_spike_counts`\n",
    "\n",
    "# _test_inst_fr_df_list\n",
    "_test_LxC_ReplayDeltaMinus.to_hdf('output/automatic_test.h5', '/LxC_ReplayDeltaMinus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e44c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_inst_fr_comps.to_hdf('output/automatic_test.h5', '/inst_fr_comps') # held up by SpikeRateTrends.inst_fr_df_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09b44f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting IdentifyingContext as a dict of HDF5-attribute such that they could be added to a group\n",
    "long_epoch_context.to_dict()\n",
    "\n",
    "\n",
    "long_epoch_context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f72f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_context: IdentifyingContext = deepcopy(long_epoch_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5db3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_context._get_session_context_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dae2cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_context.keypaths()\n",
    "\n",
    "a_context.get_description(separator=\"/\", include_property_names=False) # 'kdiba/gor01/one/2006-6-08_14-26-15/maze1'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360f9b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "doc_printer = DocumentationFilePrinter(doc_output_parent_folder=Path(r'C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\EXTERNAL\\DEVELOPER_NOTES\\DataStructureDocumentation'), doc_name='NeuropyPipeline')\n",
    "doc_printer.save_documentation('NeuropyPipeline', curr_active_pipeline, non_expanded_item_keys=['stage','_reverse_cellID_index_map', 'pf_listed_colormap', 'computation_results', 'active_configs', 'logger', 'plot', '_plot_object'],\n",
    "                               additional_excluded_item_classes=[\"<class 'pyphoplacecellanalysis.General.Pipeline.Stages.Display.Plot'>\"], max_depth=16) # 'Logger'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9c3f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_printer = DocumentationFilePrinter(doc_output_parent_folder=Path(r'C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\EXTERNAL\\DEVELOPER_NOTES\\DataStructureDocumentation'), doc_name='global_computation_results')\n",
    "doc_printer.save_documentation('global_computation_results', curr_active_pipeline.global_computation_results, non_expanded_item_keys=['sess','_reverse_cellID_index_map', 'pf_listed_colormap', 'computation_results', 'active_configs', 'logger', 'plot', '_plot_object'],\n",
    "                               additional_excluded_item_classes=[\"<class 'pyphoplacecellanalysis.General.Pipeline.Stages.Display.Plot'>\"], max_depth=16) # 'Logger'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9da00dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_printer = DocumentationFilePrinter(doc_output_parent_folder=Path(r'C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\EXTERNAL\\DEVELOPER_NOTES\\DataStructureDocumentation'), doc_name='BasePositionDecoder')\n",
    "doc_printer.save_documentation('BasePositionDecoder', curr_active_pipeline.global_computation_results, non_expanded_item_keys=['sess','_reverse_cellID_index_map', 'pf_listed_colormap', 'computation_results', 'active_configs', 'logger', 'plot', '_plot_object'],\n",
    "                               additional_excluded_item_classes=[\"<class 'pyphoplacecellanalysis.General.Pipeline.Stages.Display.Plot'>\"], max_depth=16) # 'Logger'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd88b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long_one_step_decoder_1D\n",
    "# type(long_one_step_decoder_1D) # pyphoplacecellanalysis.Analysis.Decoder.reconstruction.BayesianPlacemapPositionDecoder\n",
    "type(long_one_step_decoder_1D.pf) # neuropy.analyses.placefields.PfND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a3e743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long_short_leave_one_out_decoding_analysis.long_decoder.pf\n",
    "doc_printer = DocumentationFilePrinter(doc_output_parent_folder=Path(r'C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\EXTERNAL\\DEVELOPER_NOTES\\DataStructureDocumentation'), doc_name='BayesianPlacemapPositionDecoder')\n",
    "doc_printer.save_documentation('BayesianPlacemapPositionDecoder', long_one_step_decoder_1D, non_expanded_item_keys=[], additional_excluded_item_classes=[], max_depth=16) # 'Logger'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210ab1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_printer = DocumentationFilePrinter(doc_output_parent_folder=Path(r'C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\EXTERNAL\\DEVELOPER_NOTES\\DataStructureDocumentation'), doc_name='PfND')\n",
    "doc_printer.save_documentation('PfND', long_one_step_decoder_1D.pf, non_expanded_item_keys=[], additional_excluded_item_classes=[], max_depth=16) # 'Logger'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31e4a53",
   "metadata": {},
   "source": [
    "# 2023-07-29 - *NOW* - Get the data output to `hdf5` file format for easy integration across sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352ab47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses.placefields import PfND\n",
    "from neuropy.core.epoch import Epoch\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from neuropy.core.position import Position\n",
    "from neuropy.core.flattened_spiketrains import SpikesAccessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5b8def",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfND: PfND = deepcopy(long_one_step_decoder_1D.pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718a8094",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfND.spikes_df.columns\n",
    "\n",
    "['shank', 'cluster', 'aclu', 'qclu', 'cell_type', 'fragile_linear_neuron_IDX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0b0243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090c8239",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hdf5_output_path: Path = curr_active_pipeline.get_output_path().joinpath('test_data_new.h5')\n",
    "hdf5_output_path\n",
    "print(f'hdf5_output_path: {hdf5_output_path}')\n",
    "_pfnd_obj: PfND = long_one_step_decoder_1D.pf # self.position, self.spikes_df, self.epochs\n",
    "_pfnd_obj.to_hdf(file_path=hdf5_output_path, key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64504aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print_object_memory_usage(jonathan_firing_rate_analysis_result) # 5.690895 MB\n",
    "print_object_memory_usage(curr_long_short_post_decoding) # 0.119761 MB\n",
    "print_object_memory_usage(curr_long_short_decoding_analyses) # 1383.435345 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f0dfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_value_overview_only(jonathan_firing_rate_analysis_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15626a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _across_session_result_output_builder():\n",
    "\t\"\"\" takes the curr_active_pipeleine's loaded global results and prepares the output for use in across session aggregates.\n",
    "\n",
    "\t\"\"\"\n",
    "\t## Use the `long_short_decoding_analyses` global result to access `long_results_obj.active_filter_epochs`:\n",
    "\tcurr_long_short_decoding_analyses = curr_active_pipeline.global_computation_results.computed_data['long_short_leave_one_out_decoding_analysis']\n",
    "\tlong_one_step_decoder_1D, short_one_step_decoder_1D, long_replays, short_replays, global_replays, long_shared_aclus_only_decoder, short_shared_aclus_only_decoder, shared_aclus, long_short_pf_neurons_diff, n_neurons, long_results_obj, short_results_obj, is_global = curr_long_short_decoding_analyses.long_decoder, curr_long_short_decoding_analyses.short_decoder, curr_long_short_decoding_analyses.long_replays, curr_long_short_decoding_analyses.short_replays, curr_long_short_decoding_analyses.global_replays, curr_long_short_decoding_analyses.long_shared_aclus_only_decoder, curr_long_short_decoding_analyses.short_shared_aclus_only_decoder, curr_long_short_decoding_analyses.shared_aclus, curr_long_short_decoding_analyses.long_short_pf_neurons_diff, curr_long_short_decoding_analyses.n_neurons, curr_long_short_decoding_analyses.long_results_obj, curr_long_short_decoding_analyses.short_results_obj, curr_long_short_decoding_analyses.is_global\n",
    "\n",
    "\t## Use the `JonathanFiringRateAnalysisResult` to get info about the long/short placefields:\n",
    "\tjonathan_firing_rate_analysis_result = JonathanFiringRateAnalysisResult(**curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.to_dict())\n",
    "\tneuron_replay_stats_df, short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset = jonathan_firing_rate_analysis_result.get_cell_track_partitions()\n",
    "\n",
    "\t# I know `neuron_replay_stats_df` is directly useful\n",
    "\t\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc30a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable_default_neptune_plots = False\n",
    "enable_default_neptune_plots = True\n",
    "\n",
    "## To file only:\n",
    "with matplotlib_file_only():\n",
    "\t# Perform non-interactive Matplotlib operations with 'AGG' backend\n",
    "\tmain_complete_figure_generations(curr_active_pipeline, enable_default_neptune_plots=enable_default_neptune_plots, save_figures_only=True, save_figure=True)\n",
    "\n",
    "## Clear the Programmatically open figures:\n",
    "plt.close('all') # this takes care of the matplotlib-backed figures.\n",
    "curr_active_pipeline.clear_display_outputs()\n",
    "curr_active_pipeline.clear_registered_output_files()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44783dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "# Perform interactive Matplotlib operations with 'Qt5Agg' backend\n",
    "_out_figures = main_complete_figure_generations(curr_active_pipeline, enable_default_neptune_plots=False, save_figures_only=False, save_figure=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1811c08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.External.pyqtgraph import QtWidgets, QtCore, QtGui\n",
    "from pyphoplacecellanalysis.GUI.Qt.MainApplicationWindows.LauncherWidget.LauncherWidget import LauncherWidget\n",
    "\n",
    "widget = LauncherWidget()\n",
    "treeWidget = widget.mainTreeWidget # QTreeWidget\n",
    "widget.build_for_pipeline(curr_active_pipeline=curr_active_pipeline)\n",
    "widget.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1047af9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display('_display_3d_interactive_spike_and_behavior_browser', 'maze') # this works now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e37ccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.laps import plot_lap_trajectories_3d\n",
    "## single_combined_plot == True mode (mode 1.):\n",
    "# p, laps_pages = plot_lap_trajectories_3d(curr_active_pipeline.sess, single_combined_plot=True)\n",
    "# p.show()\n",
    "\n",
    "## single_combined_plot == False mode (mode 2.):        \n",
    "# p, laps_pages = plot_lap_trajectories_3d(curr_active_pipeline.sess, single_combined_plot=False, curr_num_subplots=len(curr_active_pipeline.sess.laps.lap_id), active_page_index=1)\n",
    "# p.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2dc954",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Display import Plot\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "plot_obj: Plot = curr_active_pipeline.plot\n",
    "\n",
    "# plot_obj._display_2d_placefield_occupancy()\n",
    "plot_obj._display_1d_placefield_occupancy(active_context=global_epoch_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d7d172",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_display_function_docs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a26b9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_replay_stats_df = jonathan_firing_rate_analysis_result.neuron_replay_stats_df\n",
    "neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac84a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.neurons import NeuronType\n",
    "# Include only pyramidal aclus:\n",
    "print(f'all shared_aclus: {len(shared_aclus)}\\nshared_aclus: {shared_aclus}')\n",
    "# shared_aclu_neuron_type = long_session.neurons.neuron_type[np.isin(long_session.neurons.neuron_ids, shared_aclus)]\n",
    "shared_aclu_neuron_type = curr_active_pipeline.sess.neurons.neuron_type[np.isin(curr_active_pipeline.sess.neurons.neuron_ids, shared_aclus)]\n",
    "assert len(shared_aclu_neuron_type) == len(shared_aclus)\n",
    "# Find only the aclus that are pyramidal:\n",
    "is_shared_aclu_pyramidal = (shared_aclu_neuron_type == NeuronType.PYRAMIDAL)\n",
    "pyramidal_only_shared_aclus = shared_aclus[is_shared_aclu_pyramidal]\n",
    "print(f'num pyramidal_only_shared_aclus: {len(pyramidal_only_shared_aclus)}\\npyramidal_only_shared_aclus: {pyramidal_only_shared_aclus}')\n",
    "# Find the other aclus (that are not pyramidal):\n",
    "is_shared_aclu_NOT_pyramidal = (shared_aclu_neuron_type != NeuronType.PYRAMIDAL)\n",
    "non_pyramidal_only_shared_aclus = shared_aclus[is_shared_aclu_NOT_pyramidal]\n",
    "print(f'num non_pyramidal_only_shared_aclus: {len(non_pyramidal_only_shared_aclus)}\\nnon_pyramidal_only_shared_aclus: {non_pyramidal_only_shared_aclus}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad85977",
   "metadata": {},
   "source": [
    "# 2023-07-21 - Setup UserAnnotations class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa162f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "\n",
    "\n",
    "annotations_man = UserAnnotationsManager()\n",
    "identifying_context_dict = annotations_man.get_hardcoded_specific_session_override_dict()\n",
    "\n",
    "relevant_entries = IdentifyingContext.matching(identifying_context_dict, criteria={'animal': 'vvp01'})\n",
    "relevant_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a354fa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "(epochs_df_L, epochs_df_S), (filter_epoch_spikes_df_L, filter_epoch_spikes_df_S), (good_example_epoch_indicies_L, good_example_epoch_indicies_S), (short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset), new_all_aclus_sort_indicies, assigning_epochs_obj = PAPER_FIGURE_figure_1_add_replay_epoch_rasters(curr_active_pipeline, allow_interactive_good_epochs_selection=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7943c591",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "user_annotations[IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3',display_fn_name='DecodedEpochSlices',epochs='replays',decoder='long_results_obj',user_annotation='selections')] = np.array([3, 19])\n",
    "user_annotations[IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3',display_fn_name='DecodedEpochSlices',epochs='replays',decoder='short_results_obj',user_annotation='selections')] = np.array([ 5, 16, 17, 19, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0fccb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.misc import DateTimeFormat\n",
    "\n",
    "DateTimeFormat.WHOLE_SECONDS.now_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7f36f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'user annotations <good replay selections> are not found. Creating them interactively...')\n",
    "user_annotations = interactive_good_epoch_selections(annotations_man=user_annotation_man, curr_active_pipeline=curr_active_pipeline)  # perform interactive selection. Should block here.\n",
    "selection_idxs_L = user_annotations[selections_context_L]\n",
    "selection_idxs_S = user_annotations[selections_context_S]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "943b8f18",
   "metadata": {},
   "source": [
    "# Common Display Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef70fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# configure backend here\n",
    "matplotlib.use('Qt5Agg')\n",
    "# backend_qt5agg\n",
    "# %matplotlib qt5\n",
    "# %matplotlib qt\n",
    "# matplotlib.use('AGG') # non-interactive backend ## 2022-08-16 - Surprisingly this works to make the matplotlib figures render only to .png file, not appear on the screen!\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "# mpl.rcParams['toolbar'] = 'None' # disable toolbars"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9e59bdb",
   "metadata": {},
   "source": [
    "# Figure 1) pf1D Ratemaps, Active set, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77377ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot, plot_raster_plot\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap_pyqtgraph # used in `plot_kourosh_activity_style_figure`\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_1_add_replay_epoch_rasters\n",
    "\n",
    "pf1d_compare_graphics, (example_epoch_rasters_L, example_epoch_rasters_S), example_stacked_epoch_graphics = PAPER_FIGURE_figure_1_full(curr_active_pipeline) # did not display the pf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3877d9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf1d_compare_fig_L, pf1d_compare_fig_S = pf1d_compare_graphics.figures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46626313",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf1d_compare_fig_L.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999442a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44ffa57",
   "metadata": {
    "tags": [
     "active"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import build_shared_sorted_neuronIDs\n",
    "\n",
    "ratemap = long_pf1D.ratemap\n",
    "included_unit_neuron_IDs = EITHER_subset.track_exclusive_aclus\n",
    "rediculous_final_sorted_all_included_neuron_ID, rediculous_final_sorted_all_included_pfmap = build_shared_sorted_neuronIDs(ratemap, included_unit_neuron_IDs, sort_ind=new_all_aclus_sort_indicies.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c7755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_pf1D_win, heatmap_pf1D_img = visualize_heatmap_pyqtgraph(rediculous_final_sorted_all_included_pfmap, show_yticks=False, title=f\"pf1D Sorted Visualization\", defer_show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66369f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_curves_sorted = long_pf1D.ratemap.normalized_tuning_curves[is_included][included_new_all_aclus_sort_indicies]\n",
    "heatmap_pf1D_win, heatmap_pf1D_img = visualize_heatmap_pyqtgraph(active_curves_sorted, show_yticks=False, title=f\"pf1D Sorted Visualization\", defer_show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5f0066",
   "metadata": {
    "tags": [
     "unwrap_figure_output",
     "interactive"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import DecodedEpochSlicesPaginatedFigureController\n",
    "\n",
    "## Stacked Epoch Plot\n",
    "example_stacked_epoch_graphics = curr_active_pipeline.display('_display_long_and_short_stacked_epoch_slices', defer_render=False, save_figure=True)\n",
    "pagination_controller_L, pagination_controller_S = example_stacked_epoch_graphics.plot_data['controllers']\n",
    "ax_L, ax_S = example_stacked_epoch_graphics.axes\n",
    "final_figure_context_L, final_context_S = example_stacked_epoch_graphics.context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6b8b4b",
   "metadata": {
    "tags": [
     "selections",
     "user_annotations"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.Mixins.PaginationMixins import SelectionsObject\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "\n",
    "user_annotations = UserAnnotationsManager.get_user_annotations()\n",
    "user_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaf1f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Capture current user selection\n",
    "saved_selection_L: SelectionsObject = pagination_controller_L.save_selection()\n",
    "saved_selection_S: SelectionsObject = pagination_controller_S.save_selection()\n",
    "user_annotations_L_context = saved_selection_L.figure_ctx.adding_context_if_missing(user_annotation='selections')\n",
    "user_annotations_S_context = saved_selection_S.figure_ctx.adding_context_if_missing(user_annotation='selections')\n",
    "user_annotations[user_annotations_L_context] = saved_selection_L.flat_all_data_indicies[saved_selection_L.is_selected]\n",
    "user_annotations[user_annotations_S_context] = saved_selection_S.flat_all_data_indicies[saved_selection_S.is_selected]\n",
    "# Updates the context. Needs to generate the code.\n",
    "\n",
    "## Generate code to insert int user_annotations:\n",
    "print('Add the following code to UserAnnotationsManager.get_user_annotations() function body:')\n",
    "print(f\"\\t\\tuser_annotations[{user_annotations_L_context.get_initialization_code_string()}] = np.array({list(saved_selection_L.flat_all_data_indicies[saved_selection_L.is_selected])})\")\n",
    "print(f\"\\t\\tuser_annotations[{user_annotations_S_context.get_initialization_code_string()}] = np.array({list(saved_selection_S.flat_all_data_indicies[saved_selection_S.is_selected])})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38e130b",
   "metadata": {
    "tags": [
     "selections",
     "user_annotations"
    ]
   },
   "outputs": [],
   "source": [
    "## Update the currently displayed selections with the user annotations:\n",
    "\n",
    "\n",
    "## Capture current user selection\n",
    "saved_selection_L = pagination_controller_L.save_selection()\n",
    "saved_selection_S = pagination_controller_S.save_selection()\n",
    "\n",
    "saved_selection_L = saved_selection_L.update_selections_from_annotations(user_annotations_dict=user_annotations)\n",
    "saved_selection_S = saved_selection_S.update_selections_from_annotations(user_annotations_dict=user_annotations)\n",
    "## re-apply the selections:\n",
    "pagination_controller_L.restore_selections(saved_selection_L)\n",
    "pagination_controller_S.restore_selections(saved_selection_S)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8858abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit_colors_list = None # default rainbow of colors for the raster plots\n",
    "neuron_qcolors_list = [pg.mkColor('black') for aclu in EITHER_subset.track_exclusive_aclus] # solid green for all\n",
    "unit_colors_list = DataSeriesColorHelpers.qColorsList_to_NDarray(neuron_qcolors_list, is_255_array=True)\n",
    "\n",
    "# Copy and modify the colors for the cells that are long/short exclusive:\n",
    "unit_colors_list_L = deepcopy(unit_colors_list)\n",
    "is_L_exclusive = np.isin(EITHER_subset.track_exclusive_aclus, long_exclusive.track_exclusive_aclus) # get long exclusive\n",
    "unit_colors_list_L[0, is_L_exclusive] = 255 # [1.0, 0.0, 0.0, 1.0]\n",
    "unit_colors_list_L[1, is_L_exclusive] = 0.0\n",
    "unit_colors_list_L[2, is_L_exclusive] = 0.0\n",
    "\n",
    "unit_colors_list_S = deepcopy(unit_colors_list)\n",
    "is_S_exclusive = np.isin(EITHER_subset.track_exclusive_aclus, short_exclusive.track_exclusive_aclus) # get short exclusive\n",
    "unit_colors_list_S[0, is_S_exclusive] = 0.0 # [1.0, 0.0, 0.0, 1.0]\n",
    "unit_colors_list_S[1, is_S_exclusive] = 0.0\n",
    "unit_colors_list_S[2, is_S_exclusive] = 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88c7d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spikes_df = an_epoch_spikes_df.copy()\n",
    "scatterplot_tooltips_kwargs = Render2DScrollWindowPlotMixin._build_spike_data_tuples_from_spikes_df(spikes_df)\n",
    "override_scatter_plot_kwargs = {**scatterplot_tooltips_kwargs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e594d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "override_scatter_plot_kwargs = {} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d10d246",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vtick = _build_default_tick(tick_width=1.0)\n",
    "\n",
    "# pxMode: If True, spots are always the same size regardless of scaling, and size is given in px. Otherwise, size is in scene coordinates and the spots scale with the view. To ensure effective caching, QPen and QBrush objects should be reused as much as possible. Default is True\n",
    "\n",
    "# size: The size (or list of sizes) of spots. If pxMode is True, this value is in pixels. Otherwise, it is in the items local coordinate system.\n",
    "\n",
    "override_scatter_plot_kwargs = dict(pxMode=True, symbol=vtick, size=10, pen={'color': 'w', 'width': 1.0})\n",
    "\n",
    "# override_scatter_plot_kwargs = dict(pxMode=False, symbol=vtick, size=1, pen={'color': 'w', 'width': 1.0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26f364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the symbol properties\n",
    "# symbol = pg.mkPen('w', width=1)  # Pen for the lines\n",
    "size = 1.0  # Fixed x-width\n",
    "symbol_brush = None  # No brush for the symbol (transparent fill)\n",
    "\n",
    "# override_scatter_plot_kwargs = dict(pxMode=False, symbol='|', size=size, pen={'color': 'w', 'width': 1.0}) # , brush=symbol_brush\n",
    "\n",
    "override_scatter_plot_kwargs = dict(pxMode=False, symbol='arrow_up', size=1.0, pen={'color': 'w', 'width': 1.0}, hoverable=True) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226bb530",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_epoch_spikes_df_L.spikes.rebuild_fragile_linear_neuron_IDXs();\n",
    "filter_epoch_spikes_df_S.spikes.rebuild_fragile_linear_neuron_IDXs();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b889b886",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_L, win_L, plots_L, plots_data_L = plot_multiple_raster_plot(epochs_df_L, filter_epoch_spikes_df_L, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs,\n",
    "\t\t\t\t\t\t\t\t\t\tepoch_id_key_name='replay_epoch_id', scatter_app_name=\"Long Decoded Example Replays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee132b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_S, win_S, plots_S, plots_data_S = plot_multiple_raster_plot(epochs_df_S, filter_epoch_spikes_df_S, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs,\n",
    "                                                                 epoch_id_key_name='replay_epoch_id', scatter_app_name=\"Short Decoded Example Replays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26dd0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test single `plot_raster_plot` calls\n",
    "an_epoch = list(epochs_df_L.itertuples())[0]\n",
    "an_epoch_spikes_df = filter_epoch_spikes_df_L[filter_epoch_spikes_df_L['replay_epoch_id'] == an_epoch.Index]\n",
    "\n",
    "_out_single_raster_plot = plot_raster_plot(an_epoch_spikes_df, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=None, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs, scatter_app_name=\"test1\")\n",
    "_out_single_raster_plot2 = plot_raster_plot(an_epoch_spikes_df, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs, scatter_app_name=\"test2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6071c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_alt, win_alt, plots_alt, plots_data_alt = plot_multiple_raster_plot(epochs_df_L, filter_epoch_spikes_df_L, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=None, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs,\n",
    "                                                                         epoch_id_key_name='replay_epoch_id', scatter_app_name=\"ALT Long Decoded Example Replays\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d20407c",
   "metadata": {},
   "source": [
    "### Testing `plot_kourosh_activity_style_figure` for debugging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69512447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import plot_kourosh_activity_style_figure\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.helpers import _helper_make_scatterplot_clickable\n",
    "\n",
    "plot_aclus = EITHER_subset.track_exclusive_aclus.copy()\n",
    "# plot_aclus = EITHER_subset.track_exclusive_aclus[new_all_aclus_sort_indicies].copy()\n",
    "_out_A = plot_kourosh_activity_style_figure(long_results_obj, long_session, plot_aclus, unit_sort_order=new_all_aclus_sort_indicies, epoch_idx=13, callout_epoch_IDXs=None, skip_rendering_callouts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326f29f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "app, win, plots, plots_data = _out_A\n",
    "# plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338d4092",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO 2023-06-27 10:42: - [ ] Desperitely need a class that \"explodes\" the important variables and their types out of a DynamicParameters (dict-like) or other object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517cdee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_n = plot_kourosh_activity_style_figure(long_results_obj, long_session, EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, epoch_idx=49, callout_epoch_IDXs=np.arange(6), skip_rendering_callouts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af748f5c",
   "metadata": {},
   "source": [
    "# 2023-07-14 - LxC and SxC PhoJonathanSession plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9415e3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import BatchPhoJonathanFiguresHelper\n",
    "\n",
    "## Get global 'jonathan_firing_rate_analysis' results:\n",
    "curr_jonathan_firing_rate_analysis = curr_active_pipeline.global_computation_results.computed_data['jonathan_firing_rate_analysis']\n",
    "neuron_replay_stats_df, rdf, aclu_to_idx, irdf = curr_jonathan_firing_rate_analysis['neuron_replay_stats_df'], curr_jonathan_firing_rate_analysis['rdf']['rdf'], curr_jonathan_firing_rate_analysis['rdf']['aclu_to_idx'], curr_jonathan_firing_rate_analysis['irdf']['irdf']\n",
    "\n",
    "# with VizTracer(output_file=f\"viztracer_display_BatchPhoJonathanFiguresHelper_PlusPDF_20.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "active_out_figures_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, included_unit_neuron_IDs=XOR_subset.track_exclusive_aclus, n_max_page_rows=20, write_vector_format=False, write_png=True) # active_out_figures_dict: {IdentifyingContext<('kdiba', 'gor01', 'two', '2006-6-07_16-40-19', 'BatchPhoJonathanReplayFRC', 'long_only', '(12,21,48)')>: <Figure size 1920x660 with 12 Axes>, IdentifyingContext<('kdiba', 'gor01', 'two', '2006-6-07_16-40-19', 'BatchPhoJonathanReplayFRC', 'short_only', '(18,19,65)')>: <Figure size 1920x660 with 12 Axes>}\n",
    "print(f'active_out_figures_dict: {active_out_figures_dict}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052f7ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.display(display_function='_display_2d_placefield_result_plot_ratemaps_2D', active_session_configuration_context=long_epoch_context)\n",
    "\n",
    "\n",
    "# curr_active_pipeline.display(display_function='_display_placemaps_pyqtplot_2D', active_session_configuration_context=long_epoch_context)\n",
    "\n",
    "curr_active_pipeline.display(display_function='_display_2d_placefield_occupancy', active_session_configuration_context=long_epoch_context)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d12ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure() # new figure to hold the result\n",
    "# can show the figures by looping through and calling\n",
    "for a_ctxt, a_fig in active_out_figures_dict.items():\n",
    "    print(f'showing: {a_ctxt}')\n",
    "    a_fig.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea9f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "curr_active_pipeline.registered_output_files_list"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a7c05d1",
   "metadata": {},
   "source": [
    "# Figure 2) Firing Rate Bar Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cf1ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantaneous versions:\n",
    "from pyphocorehelpers.mixins.serialized import SerializedAttributesAllowBlockSpecifyingClass\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PaperFigureTwo, InstantaneousSpikeRateGroupsComputation\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "\n",
    "_out_fig_2 = PaperFigureTwo(instantaneous_time_bin_size_seconds=0.01) # 10ms\n",
    "_out_fig_2.compute(curr_active_pipeline=curr_active_pipeline, active_context=curr_active_pipeline.sess.get_context())\n",
    "\n",
    "_out_fig_2_figs = {}\n",
    "\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "# Perform interactive Matplotlib operations with 'Qt5Agg' backend\n",
    "_out_fig_2_figs = _out_fig_2.display(defer_show=True, save_figure=True, active_context=curr_active_pipeline.sess.get_context())\n",
    "\n",
    "## Extract for debugging/checking:\n",
    "_out_inst_fr_comps = _out_fig_2.computation_result\n",
    "LxC_ReplayDeltaMinus, LxC_ReplayDeltaPlus, SxC_ReplayDeltaMinus, SxC_ReplayDeltaPlus = _out_inst_fr_comps.LxC_ReplayDeltaMinus, _out_inst_fr_comps.LxC_ReplayDeltaPlus, _out_inst_fr_comps.SxC_ReplayDeltaMinus, _out_inst_fr_comps.SxC_ReplayDeltaPlus\n",
    "LxC_ThetaDeltaMinus, LxC_ThetaDeltaPlus, SxC_ThetaDeltaMinus, SxC_ThetaDeltaPlus = _out_inst_fr_comps.LxC_ThetaDeltaMinus, _out_inst_fr_comps.LxC_ThetaDeltaPlus, _out_inst_fr_comps.SxC_ThetaDeltaMinus, _out_inst_fr_comps.SxC_ThetaDeltaPlus\n",
    "# LxC_ThetaDeltaMinus # cell_agg_inst_fr_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beca328b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_inst_fr_comps = InstantaneousSpikeRateGroupsComputation(instantaneous_time_bin_size_seconds=0.01) # 10ms\n",
    "_out_inst_fr_comps.compute(curr_active_pipeline=curr_active_pipeline, active_context=curr_active_pipeline.sess.get_context())\n",
    "LxC_ReplayDeltaMinus, LxC_ReplayDeltaPlus, SxC_ReplayDeltaMinus, SxC_ReplayDeltaPlus = _out_inst_fr_comps.LxC_ReplayDeltaMinus, _out_inst_fr_comps.LxC_ReplayDeltaPlus, _out_inst_fr_comps.SxC_ReplayDeltaMinus, _out_inst_fr_comps.SxC_ReplayDeltaPlus\n",
    "LxC_ThetaDeltaMinus, LxC_ThetaDeltaPlus, SxC_ThetaDeltaMinus, SxC_ThetaDeltaPlus = _out_inst_fr_comps.LxC_ThetaDeltaMinus, _out_inst_fr_comps.LxC_ThetaDeltaPlus, _out_inst_fr_comps.SxC_ThetaDeltaMinus, _out_inst_fr_comps.SxC_ThetaDeltaPlus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f34b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_fr_output_filename = 'long_short_inst_firing_rates.pkl'\n",
    "inst_fr_output_path = curr_active_pipeline.get_output_path().joinpath(inst_fr_output_filename).resolve()\n",
    "inst_fr_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455ed1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData, loadData\n",
    "\n",
    "# saveData(inst_fr_output_path, _out_fig_2)\n",
    "saveData(inst_fr_output_path, _out_fig_2.to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e77486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.print_helpers import print_filesystem_file_size, print_object_memory_usage\n",
    "\n",
    "\n",
    "print_object_memory_usage(_out_fig_2) #  2743.397699 MB\n",
    "# print_object_memory_usage(_out_fig_2.to_dict()) #  2743.397699 MB\n",
    "# print_object_memory_usage(_out_fig_2._pipeline_file_callback_fn) #  2737.983306 MB\n",
    "print(print_object_memory_usage(_out_inst_fr_comps)) #  5.489502 MB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2adc047",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print_object_memory_usage((LxC_ReplayDeltaMinus, LxC_ReplayDeltaPlus, SxC_ReplayDeltaMinus, SxC_ReplayDeltaPlus, LxC_ThetaDeltaMinus, LxC_ThetaDeltaPlus, SxC_ThetaDeltaMinus, SxC_ThetaDeltaPlus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de48d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "\n",
    "\n",
    "srt1 = PaperFigureTwo(**loadData(inst_fr_output_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61bee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "srt2 = loadData(inst_fr_output_path)\n",
    "\n",
    "# When combining two `SpikeRateTrends` objects, they may differ in any/all (n_timebins, n_epochs, n_cells) making it difficult to safely concatenate them. \n",
    "# `LxC_ThetaDeltaMinus`\n",
    "# srt1: SpikeRateTrends = deepcopy(LxC_ThetaDeltaMinus) # SpikeRateTrends(...)\n",
    "# srt2: SpikeRateTrends = deepcopy(LxC_ThetaDeltaMinus) # SpikeRateTrends(...)\n",
    "# concatenated = srt1 + srt2\n",
    "# concatenated = srt1.concatenate(srt2)\n",
    "concatenated = SpikeRateTrends.concatenate(srt1, srt2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edea79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]] # only uses global_session\n",
    "(epochs_df_L, epochs_df_S), (filter_epoch_spikes_df_L, filter_epoch_spikes_df_S), (good_example_epoch_indicies_L, good_example_epoch_indicies_S), (short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset), new_all_aclus_sort_indicies, assigning_epochs_obj = PAPER_FIGURE_figure_1_add_replay_epoch_rasters(curr_active_pipeline)\n",
    "\n",
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "long_laps, long_replays, short_laps, short_replays, global_laps, global_replays = [long_short_fr_indicies_analysis_results[k] for k in ['long_laps', 'long_replays', 'short_laps', 'short_replays', 'global_laps', 'global_replays']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d085cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813ab296",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_exclusive.track_exclusive_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05be832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_exclusive.track_exclusive_df['lap_delta_minus_inst_fr'] = LxC_ThetaDeltaMinus.cell_agg_inst_fr_list # (n_cells, )\n",
    "long_exclusive.track_exclusive_df['lap_delta_plus_inst_fr'] = LxC_ThetaDeltaPlus.cell_agg_inst_fr_list # (n_cells, )\n",
    "long_exclusive.track_exclusive_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3077438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = LxC_ThetaDeltaMinus.epoch_agg_inst_fr_list # (n_epochs, n_cells)\n",
    "# d = d[:,1]\n",
    "d = LxC_ThetaDeltaMinus.cell_agg_inst_fr_list # (n_cells, )\n",
    "d\n",
    "long_exclusive.track_exclusive_df['lap_delta_minus_inst_fr'] = LxC_ThetaDeltaMinus.cell_agg_inst_fr_list # (n_cells, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6984de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop out the very low (inactive) Epochs... I guess? But we want it to be influenced by the inactive epochs.\n",
    "curr_active_pipeline.\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d3f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(LxC_ThetaDeltaMinus.inst_fr_signals_list) # n_epochs\n",
    "d = LxC_ThetaDeltaMinus.inst_fr_df_list\n",
    "d[0]\n",
    "# (n_epochs, n_cells)\n",
    "# print(f'{d.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfd716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LxC_ThetaDeltaPlus\n",
    "# Look at percent change\n",
    "(LxC_ThetaDeltaPlus.cell_agg_inst_fr_list - LxC_ThetaDeltaMinus.cell_agg_inst_fr_list) / LxC_ThetaDeltaMinus.cell_agg_inst_fr_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2b2901",
   "metadata": {},
   "source": [
    "## NOW: 2023-07-11 - Testing Batch-computed inst_firing_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c034766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchSessionCompletionHandler\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PaperFigureTwo, InstantaneousSpikeRateGroupsComputation\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsResults, AcrossSessionsVisualizations\n",
    "\n",
    "\n",
    "## Load the saved across-session results:\n",
    "inst_fr_output_filename = 'long_short_inst_firing_rate_result_handlers_2023-07-12.pkl'\n",
    "across_session_inst_fr_computation, across_sessions_instantaneous_fr_dict, across_sessions_instantaneous_frs_list = AcrossSessionsResults.load_across_sessions_data(global_data_root_parent_path=global_data_root_parent_path, inst_fr_output_filename=inst_fr_output_filename)\n",
    "# across_sessions_instantaneous_fr_dict = loadData(global_batch_result_inst_fr_file_path)\n",
    "num_sessions = len(across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2549c92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregate across all of the sessions to build a new combined `InstantaneousSpikeRateGroupsComputation`, which can be used to plot the \"PaperFigureTwo\", bar plots for many sessions.\n",
    "global_multi_session_context = IdentifyingContext(format_name='kdiba', num_sessions=num_sessions) # some global context across all of the sessions, not sure what to put here.\n",
    "\n",
    "# To correctly aggregate results across sessions, it only makes sense to combine entries at the `.cell_agg_inst_fr_list` variable and lower (as the number of cells can be added across sessions, treated as unique for each session).\n",
    "\n",
    "## Display the aggregate across sessions:\n",
    "_out_fig_2 = PaperFigureTwo(instantaneous_time_bin_size_seconds=0.01) # WARNING: we didn't save this info\n",
    "_out_fig_2.computation_result = across_session_inst_fr_computation\n",
    "_out_fig_2.active_identifying_session_ctx = across_session_inst_fr_computation.active_identifying_session_ctx\n",
    "# Set callback, the only self-specific property\n",
    "_out_fig_2._pipeline_file_callback_fn = curr_active_pipeline.output_figure # lambda args, kwargs: self.write_to_file(args, kwargs, curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f71cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "# Perform interactive Matplotlib operations with 'Qt5Agg' backend\n",
    "_fig_2_theta_out, _fig_2_replay_out = _out_fig_2.display(active_context=global_multi_session_context, title_modifier_fn=lambda original_title: f\"{original_title} ({num_sessions} sessions)\", save_figure=True)\n",
    "\t\n",
    "_out_fig_2.perform_save()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d7b230c",
   "metadata": {},
   "source": [
    "# Figure 3) `PAPER_FIGURE_figure_3`: Firing Rate Index and Long/Short Firing Rate Replays v. Laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6008da8",
   "metadata": {
    "tags": [
     "figure_3",
     "active"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.utils.matplotlib_helpers import FormattedFigureText\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import _plot_long_short_firing_rate_indicies\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "_out, _out2 = PAPER_FIGURE_figure_3(curr_active_pipeline, defer_render=False, save_figure=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd3546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out2.figures\n",
    "_out.axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c49f148",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.0-0.090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd17dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = _out.figures\n",
    "fig\n",
    "# Computed long ($L$)|short($S$) firing rate indicies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14388eec",
   "metadata": {},
   "source": [
    "# 2023-07-07 - `batch_extended_programmatic_figures` Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e3c3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "neptuner = batch_perform_all_plots(curr_active_pipeline, enable_neptune=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126028b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_extended_programmatic_figures(curr_active_pipeline, write_vector_format=False, write_png=False, debug_print=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb4dcda",
   "metadata": {},
   "source": [
    "# Interactive Selection of User Annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb9aa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from pyphoplacecellanalysis.GUI.Qt.Mixins.PaginationMixins import SelectionsObject\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import DecodedEpochSlicesPaginatedFigureController\n",
    "\n",
    "user_annotation_man = UserAnnotationsManager()\n",
    "user_annotations = user_annotation_man.get_user_annotations()\n",
    "\n",
    "final_context_L = curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='replays', decoder='long_results_obj')\n",
    "final_context_S = curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='replays', decoder='short_results_obj')\n",
    "# _out_pagination_controller.params.active_identifying_figure_ctx.adding_context(None,  user_annotation=\"selections\")\n",
    "selections_context_L = final_context_L.adding_context(None,  user_annotation=\"selections\")\n",
    "selections_context_S = final_context_S.adding_context(None,  user_annotation=\"selections\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb42a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recover it from the last_added_display_output\n",
    "example_stacked_epoch_graphics = curr_active_pipeline.last_added_display_output # recover it from the last_added_display_output\n",
    "pagination_controller_L, pagination_controller_S = example_stacked_epoch_graphics.plot_data['controllers']\n",
    "ax_L, ax_S = example_stacked_epoch_graphics.axes\n",
    "figure_context_L, figure_context_S = example_stacked_epoch_graphics.context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50e1a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_annotations = UserAnnotationsManager.get_user_annotations()\n",
    "# user_annotations = self.get_user_annotations()\n",
    "\n",
    "## Capture current user selection\n",
    "\n",
    "# def _update_user_annotations_from_selections():\n",
    "# \t\"\"\" captures:\n",
    "# \t\tuser_annotations\n",
    "# \t\tpagination_controller_L, pagination_controller_S\n",
    "# \t\"\"\"\n",
    "saved_selection_L: SelectionsObject = pagination_controller_L.save_selection()\n",
    "user_annotations_L_context: IdentifyingContext = saved_selection_L.figure_ctx.adding_context_if_missing(user_annotation='selections')\n",
    "print(f'{user_annotations_L_context}\\n\\t{saved_selection_L.flat_all_data_indicies[saved_selection_L.is_selected]}')\n",
    "user_annotations[user_annotations_L_context] = saved_selection_L.flat_all_data_indicies[saved_selection_L.is_selected]\n",
    "\n",
    "saved_selection_S: SelectionsObject = pagination_controller_S.save_selection()\n",
    "user_annotations_S_context: IdentifyingContext = saved_selection_S.figure_ctx.adding_context_if_missing(user_annotation='selections')\n",
    "print(f'{user_annotations_S_context}\\n\\t{saved_selection_S.flat_all_data_indicies[saved_selection_S.is_selected]}')\n",
    "user_annotations[user_annotations_S_context] = saved_selection_S.flat_all_data_indicies[saved_selection_S.is_selected]\n",
    "\n",
    "## Generate code to insert int user_annotations:\n",
    "print('Add the following code to `pyphoplacecellanalysis.General.Model.user_annotations.UserAnnotationsManager.get_user_annotations()` function body:')\n",
    "print(f\"user_annotations[{user_annotations_L_context.get_initialization_code_string()}] = np.array({list(saved_selection_L.flat_all_data_indicies[saved_selection_L.is_selected])})\")\n",
    "print(f\"user_annotations[{user_annotations_S_context.get_initialization_code_string()}] = np.array({list(saved_selection_S.flat_all_data_indicies[saved_selection_S.is_selected])})\")\n",
    "\n",
    "# Stopping at (128, 89)\n",
    "\n",
    "# Updates the context. Needs to generate the code.\n",
    "# _update_user_annotations_from_selections()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9176bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "\n",
    "## Stacked Epoch Plot\n",
    "example_stacked_epoch_graphics = curr_active_pipeline.display('_display_long_and_short_stacked_epoch_slices', defer_render=False, save_figure=False) # Build a new one\n",
    "# example_stacked_epoch_graphics = curr_active_pipeline.last_added_display_output # recover it from the last_added_display_output\n",
    "pagination_controller_L, pagination_controller_S = example_stacked_epoch_graphics.plot_data['controllers'] # DecodedEpochSlicesPaginatedFigureController, DecodedEpochSlicesPaginatedFigureController\n",
    "ax_L, ax_S = example_stacked_epoch_graphics.axes\n",
    "figure_context_L, figure_context_S = example_stacked_epoch_graphics.context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989a8fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## After launching the interactive Stacked Epoch Plots for user epoch selection, try to update the selection with previously added annotations:\n",
    "saved_selection_L: SelectionsObject = pagination_controller_L.save_selection()\n",
    "saved_selection_S: SelectionsObject = pagination_controller_S.save_selection()\n",
    "saved_selection_L = user_annotation_man.update_selections_from_annotations(saved_selection_L, user_annotations)\n",
    "saved_selection_S = user_annotation_man.update_selections_from_annotations(saved_selection_S, user_annotations)\n",
    "\n",
    "## re-apply the selections:\n",
    "pagination_controller_L.restore_selections(saved_selection_L, defer_render=True)\n",
    "pagination_controller_S.restore_selections(saved_selection_S, defer_render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97436317",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_L[0].figure.canvas.draw()  # .figures.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c6bb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_S[0].figure.canvas.draw()  # .figures.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0af3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Capture current user selection:\n",
    "## Capture current user selection\n",
    "\n",
    "# def _update_user_annotations_from_selections():\n",
    "# \t\"\"\" captures:\n",
    "# \t\tuser_annotations\n",
    "# \t\tpagination_controller_L, pagination_controller_S\n",
    "# \t\"\"\"\n",
    "saved_selection_L: SelectionsObject = pagination_controller_L.save_selection()\n",
    "user_annotations_L_context: IdentifyingContext = saved_selection_L.figure_ctx.adding_context_if_missing(user_annotation='selections')\n",
    "print(f'{user_annotations_L_context}\\n\\t{saved_selection_L.flat_all_data_indicies[saved_selection_L.is_selected]}')\n",
    "user_annotations[user_annotations_L_context] = saved_selection_L.flat_all_data_indicies[saved_selection_L.is_selected]\n",
    "\n",
    "saved_selection_S: SelectionsObject = pagination_controller_S.save_selection()\n",
    "user_annotations_S_context: IdentifyingContext = saved_selection_S.figure_ctx.adding_context_if_missing(user_annotation='selections')\n",
    "print(f'{user_annotations_S_context}\\n\\t{saved_selection_S.flat_all_data_indicies[saved_selection_S.is_selected]}')\n",
    "user_annotations[user_annotations_S_context] = saved_selection_S.flat_all_data_indicies[saved_selection_S.is_selected]\n",
    "\n",
    "## Generate code to insert int user_annotations:\n",
    "print('Add the following code to `pyphoplacecellanalysis.General.Model.user_annotations.UserAnnotationsManager.get_user_annotations()` function body:')\n",
    "print(f\"user_annotations[{user_annotations_L_context.get_initialization_code_string()}] = np.array({list(saved_selection_L.flat_all_data_indicies[saved_selection_L.is_selected])})\")\n",
    "print(f\"user_annotations[{user_annotations_S_context.get_initialization_code_string()}] = np.array({list(saved_selection_S.flat_all_data_indicies[saved_selection_S.is_selected])})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79065b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import interactive_good_epoch_selections\n",
    "\n",
    "## try to get the user annotations for this session:\n",
    "try:\n",
    "\tselection_idxs_L = user_annotations[selections_context_L]\n",
    "\tselection_idxs_S = user_annotations[selections_context_S]\n",
    "except KeyError as e:\n",
    "\tprint(f'user annotations <good replay selections> are not found. Creating them interactively...')\n",
    "\t# user_annotation_man.interactive_good_epoch_selections(curr_active_pipeline=curr_active_pipeline) # perform interactive selection. Should block here.\n",
    "\t# user_annotations = interactive_good_epoch_selections(annotations_man=user_annotation_man, curr_active_pipeline=curr_active_pipeline) # perform interactive selection. Should block here.\n",
    "\n",
    "\t# Showing\n",
    "\trestore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "\n",
    "\t## Stacked Epoch Plot\n",
    "\texample_stacked_epoch_graphics = curr_active_pipeline.display('_display_long_and_short_stacked_epoch_slices', defer_render=False, save_figure=False)\n",
    "\tpagination_controller_L, pagination_controller_S = example_stacked_epoch_graphics.plot_data['controllers']\n",
    "\tax_L, ax_S = example_stacked_epoch_graphics.axes\n",
    "\tfigure_context_L, figure_context_S = example_stacked_epoch_graphics.context\n",
    "\n",
    "except Exception as e:\n",
    "\tprint('Unhandled exception: {e}')\n",
    "\traise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbead587",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd045d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user_annotations_L_context.get_initialization_code_string(subset_includelist=['format_name','animal','exper_name', 'session_name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4aefa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "\n",
    "IdentifyingContext._get_session_context_keys()\n",
    "\n",
    "# user_annotations_L_context.get_subset(subset_includelist=[IdentifyingContext._get_session_context_keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d07238",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_idxs_L = user_annotations[selections_context_L]\n",
    "selection_idxs_S = user_annotations[selections_context_S]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7a0f86",
   "metadata": {},
   "source": [
    "# 2023-07-19 - Validation with 3D tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecde32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.plot.\n",
    "\n",
    "display_output = {}\n",
    "active_config_name = long_epoch_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80672dec",
   "metadata": {},
   "source": [
    "# 3D Plotters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd240080",
   "metadata": {},
   "source": [
    "##  ipcDataExplorer - 3D Interactive Tuning Curves Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013b0306",
   "metadata": {},
   "outputs": [],
   "source": [
    "pActiveTuningCurvesPlotter = None\n",
    "\n",
    "zScalingFactor = 2000.0 # worked well before with default params\n",
    "# zScalingFactor = 50.0 # worked well before with default params\n",
    "display_output = display_output | curr_active_pipeline.display('_display_3d_interactive_tuning_curves_plotter', active_config_name, extant_plotter=display_output.get('pActiveTuningCurvesPlotter', None), panel_controls_mode='Qt', should_nan_non_visited_elements=False, zScalingFactor=zScalingFactor, separate_window=False)\n",
    "ipcDataExplorer = display_output['ipcDataExplorer']\n",
    "display_output['pActiveTuningCurvesPlotter'] = display_output.pop('plotter') # rename the key from the generic \"plotter\" to \"pActiveSpikesBehaviorPlotter\" to avoid collisions with others\n",
    "pActiveTuningCurvesPlotter = display_output['pActiveTuningCurvesPlotter']\n",
    "root_dockAreaWindow, placefieldControlsContainerWidget, pf_widgets = display_output['pane'] # for Qt mode:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9bf7ee",
   "metadata": {},
   "source": [
    "##  ipspikesDataExplorer - 3D Interactive Spike and Behavior Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c48fd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "pActiveSpikesBehaviorPlotter = None\n",
    "display_output = display_output | curr_active_pipeline.display('_display_3d_interactive_spike_and_behavior_browser', active_config_name, extant_plotter=display_output.get('pActiveSpikesBehaviorPlotter', None)) # Works now!\n",
    "ipspikesDataExplorer = display_output['ipspikesDataExplorer']\n",
    "display_output['pActiveSpikesBehaviorPlotter'] = display_output.pop('plotter') # rename the key from the generic \"plotter\" to \"pActiveSpikesBehaviorPlotter\" to avoid collisions with others\n",
    "pActiveSpikesBehaviorPlotter = display_output['pActiveSpikesBehaviorPlotter']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b9f4bd",
   "metadata": {},
   "source": [
    "###  Test adding the nearest predicted/decoded position as a red point to the 3D plotter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41895eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "_debug_print = False\n",
    "\n",
    "def _update_nearest_decoded_most_likely_position_callback(start_t, end_t):\n",
    "    \"\"\" Only uses end_t\n",
    "    Implicitly captures: ipspikesDataExplorer, _get_nearest_decoded_most_likely_position_callback\n",
    "    \n",
    "    Usage:\n",
    "        _update_nearest_decoded_most_likely_position_callback(0.0, ipspikesDataExplorer.t[0])\n",
    "        _conn = ipspikesDataExplorer.sigOnUpdateMeshes.connect(_update_nearest_decoded_most_likely_position_callback)\n",
    "\n",
    "    \"\"\"\n",
    "    def _get_nearest_decoded_most_likely_position_callback(t):\n",
    "        \"\"\" A callback that when passed a visualization timestamp (the current time to render) returns the most likely predicted position provided by the active_two_step_decoder\n",
    "        Implicitly captures:\n",
    "            active_one_step_decoder, active_two_step_decoder\n",
    "        Usage:\n",
    "            _get_nearest_decoded_most_likely_position_callback(9000.1)\n",
    "        \"\"\"\n",
    "        active_time_window_variable = active_one_step_decoder.time_window_centers # get time window centers (n_time_window_centers,) # (4060,)\n",
    "        active_most_likely_positions = active_one_step_decoder.most_likely_positions.T # (4060, 2) NOTE: the most_likely_positions for the active_one_step_decoder are tranposed compared to the active_two_step_decoder\n",
    "        # active_most_likely_positions = active_two_step_decoder.most_likely_positions # (2, 4060)\n",
    "        assert np.shape(active_time_window_variable)[0] == np.shape(active_most_likely_positions)[1], f\"timestamps and num positions must be the same but np.shape(active_time_window_variable): {np.shape(active_time_window_variable)} and np.shape(active_most_likely_positions): {np.shape(active_most_likely_positions)}!\"\n",
    "        last_window_index = np.searchsorted(active_time_window_variable, t, side='left') # side='left' ensures that no future values (later than 't') are ever returned\n",
    "        # TODO: CORRECTNESS: why is it returning an index that corresponds to a time later than the current time?\n",
    "        # for current time t=9000.0\n",
    "        #     last_window_index: 1577\n",
    "        #     last_window_time: 9000.5023\n",
    "        # EH: close enough\n",
    "        last_window_time = active_time_window_variable[last_window_index] # If there is no suitable index, return either 0 or N (where N is the length of `a`).\n",
    "        displayed_time_offset = t - last_window_time # negative value if the window time being displayed is in the future\n",
    "        if _debug_print:\n",
    "            print(f'for current time t={t}\\n\\tlast_window_index: {last_window_index}\\n\\tlast_window_time: {last_window_time}\\n\\tdisplayed_time_offset: {displayed_time_offset}')\n",
    "        return (last_window_time, *list(np.squeeze(active_most_likely_positions[:, last_window_index]).copy()))\n",
    "\n",
    "    t = end_t # the t under consideration should always be the end_t. This is written this way just for compatibility with the ipspikesDataExplorer.sigOnUpdateMeshes (float, float) signature\n",
    "    curr_t, curr_x, curr_y = _get_nearest_decoded_most_likely_position_callback(t)\n",
    "    curr_debug_point = [curr_x, curr_y, ipspikesDataExplorer.z_fixed[-1]]\n",
    "    if _debug_print:\n",
    "        print(f'tcurr_debug_point: {curr_debug_point}') # \\n\\tlast_window_time: {last_window_time}\\n\\tdisplayed_time_offset: {displayed_time_offset}\n",
    "    ipspikesDataExplorer.perform_plot_location_point('debug_point_plot', curr_debug_point, color='r', render=True)\n",
    "    return curr_debug_point\n",
    "\n",
    "_update_nearest_decoded_most_likely_position_callback(0.0, ipspikesDataExplorer.t[0])\n",
    "# _conn = pg.SignalProxy(ipspikesDataExplorer.sigOnUpdateMeshes, rateLimit=14, slot=_update_nearest_decoded_most_likely_position_callback)\n",
    "_conn = ipspikesDataExplorer.sigOnUpdateMeshes.connect(_update_nearest_decoded_most_likely_position_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1996cf9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
