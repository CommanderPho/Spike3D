{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33f7f339",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[0️⃣ ReviewOfWork (Main Notebook) - Imports](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77d98a7b",
   "metadata": {
    "tags": [
     "run-group-0-interactive",
     "run-group-0",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "PyQt5 formatters registered successfully\n",
      "MAX_LINE_LENGTH: 240\n",
      "doc_output_parent_folder: C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\EXTERNAL\\DEVELOPER_NOTES\\DataStructureDocumentation\n",
      "field.name: \"merged_directional_placefields\", variable_name: \"merged_directional_placefields\"\n",
      "field.name: \"rank_order_shuffle_analysis\", variable_name: \"rank_order_shuffle_analysis\"\n",
      "field.name: \"directional_decoders_decode_continuous\", variable_name: \"directional_decoders_decode_continuous\"\n",
      "field.name: \"directional_decoders_evaluate_epochs\", variable_name: \"directional_decoders_evaluate_epochs\"\n",
      "field.name: \"directional_decoders_epoch_heuristic_scoring\", variable_name: \"directional_decoders_epoch_heuristic_scoring\"\n",
      "field.name: \"directional_train_test_split\", variable_name: \"directional_train_test_split\"\n",
      "field.name: \"long_short_decoding_analyses\", variable_name: \"long_short_decoding_analyses\"\n",
      "field.name: \"long_short_rate_remapping\", variable_name: \"long_short_rate_remapping\"\n",
      "field.name: \"long_short_inst_spike_rate_groups\", variable_name: \"long_short_inst_spike_rate_groups\"\n",
      "field.name: \"wcorr_shuffle_analysis\", variable_name: \"wcorr_shuffle_analysis\"\n",
      "field.name: \"non_pbe_epochs_results\", variable_name: \"non_pbe_epochs_results\"\n",
      "field.name: \"position_decoding\", variable_name: \"position_decoding\"\n",
      "field.name: \"perform_specific_epochs_decoding\", variable_name: \"perform_specific_epochs_decoding\"\n",
      "field.name: \"DEP_ratemap_peaks\", variable_name: \"DEP_ratemap_peaks\"\n",
      "field.name: \"ratemap_peaks_prominence2d\", variable_name: \"ratemap_peaks_prominence2d\"\n",
      "DAY_DATE_STR: 2025-07-17, DAY_DATE_TO_USE: 2025-07-17\n",
      "NOW_DATETIME: 2025-07-17_0725AM, NOW_DATETIME_TO_USE: 2025-07-17_0725AM\n",
      "global_data_root_parent_path changed to W:\\Data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbad0320fb2d4bb5a65188226a2a0391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='Data Root:', layout=Layout(width='auto'), options=(WindowsPath('W:/Data'),), style=ToggleButtonsStyle(button_width='max-content'), tooltip='global_data_root_parent_path', value=WindowsPath('W:/Data'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "# %xmode Verbose\n",
    "# %xmode context\n",
    "%pdb off\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "# # Add exclusions for metaclass-using modules\n",
    "# %aimport -neuropy.core.session.dataSession\n",
    "# %aimport -neuropy.core.session.Formats.BaseDataSessionFormats\n",
    "# %aimport -neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat\n",
    "# %aimport -neuropy.core.session.Formats.Specific.BapunDataSessionFormat \n",
    "# %aimport -neuropy.core.session.Formats.Specific.RachelDataSessionFormat\n",
    "# %aimport -neuropy.core.session.Formats.Specific.HiroDataSessionFormt\n",
    "\n",
    "# # !pip install viztracer\n",
    "# %load_ext viztracer\n",
    "# from viztracer import VizTracer\n",
    "\n",
    "# %load_ext memory_profiler\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "os.environ['QT_API'] = 'pyqt5'\n",
    "os.environ['PYQTGRAPH_QT_LIB'] = 'PyQt5'\n",
    "\n",
    "# from PyQt5.QtWebEngineWidgets import QWebEngineView ## this must come first, before any QtApplication is made: 'ImportError: QtWebEngineWidgets must be imported or Qt.AA_ShareOpenGLContexts must be set before a QCoreApplication instance is created'\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "import importlib\n",
    "from copy import deepcopy\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "# pd.options.mode.dtype_backend = 'pyarrow' # use new pyarrow backend instead of numpy\n",
    "\n",
    "from attrs import define, field, fields, Factory, make_class\n",
    "import tables as tb\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Pho's Formatting Preferences\n",
    "import builtins\n",
    "\n",
    "import IPython\n",
    "from IPython.core.formatters import PlainTextFormatter\n",
    "from IPython import get_ipython\n",
    "\n",
    "from pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\n",
    "set_pho_preferences_concise()\n",
    "# Jupyter-lab enable printing for any line on its own (instead of just the last one in the cell)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# BEGIN PPRINT CUSTOMIZATION ___________________________________________________________________________________________ #\n",
    "\n",
    "## IPython pprint\n",
    "from pyphocorehelpers.pprint import wide_pprint, wide_pprint_ipython, wide_pprint_jupyter, MAX_LINE_LENGTH\n",
    "# Override default pprint\n",
    "builtins.pprint = wide_pprint\n",
    "\n",
    "ip = get_ipython()\n",
    "\n",
    "from pyphocorehelpers.ipython_helpers import CustomFormatterMagics\n",
    "\n",
    "# Register the magic\n",
    "get_ipython().register_magics(CustomFormatterMagics)\n",
    "\n",
    "\n",
    "\n",
    "from pyphocorehelpers.pyqt_ipython_rendering_helpers import PyQtFormatters\n",
    "from pyphoplacecellanalysis.General.Mixins.DisplayHelpers import debug_widget_geometry\n",
    "\n",
    "# Register formatters for specific PyQt5 types\n",
    "# Create an instance and register formatters\n",
    "qt_formatters = PyQtFormatters()\n",
    "qt_formatters.register()\n",
    "\n",
    "\n",
    "from pyphocorehelpers.print_helpers import render_scrollable_colored_table_from_dataframe, render_scrollable_colored_table\n",
    "\n",
    "# # import pho_jupyter_preview_widget\n",
    "# from pyphocorehelpers.pho_jupyter_preview_widget.ipython_helpers import PreviewWidgetMagics\n",
    "# from pyphocorehelpers.pho_jupyter_preview_widget.display_helpers import array_repr_with_graphical_preview\n",
    "\n",
    "# # # # Register the magic\n",
    "# ip.register_magics(PreviewWidgetMagics)\n",
    "\n",
    "# %config_ndarray_preview width=500\n",
    "\n",
    "# Register the custom display function for NumPy arrays\n",
    "# ip.display_formatter.formatters['text/html'].for_type(np.ndarray, lambda arr: array_preview_with_graphical_shape_repr_html(arr))\n",
    "# ip = array_repr_with_graphical_shape(ip=ip)\n",
    "# ip = array_repr_with_graphical_preview(ip=ip)\n",
    "# ip = dataframe_show_more_button(ip=ip)\n",
    "\n",
    "print(f'MAX_LINE_LENGTH: {MAX_LINE_LENGTH}')\n",
    "text_formatter: PlainTextFormatter = ip.display_formatter.formatters['text/plain']\n",
    "text_formatter.max_width = MAX_LINE_LENGTH\n",
    "text_formatter.for_type(object, wide_pprint_jupyter)\n",
    "\n",
    "\n",
    "# END PPRINT CUSTOMIZATION ___________________________________________________________________________________________ #\n",
    "\n",
    "from pyphocorehelpers.print_helpers import get_now_time_str, get_now_day_str\n",
    "from pyphocorehelpers.indexing_helpers import get_dict_subset\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path, file_uri_from_path\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "import pyphocorehelpers.programming_helpers as programming_helpers\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "# from neuropy import core\n",
    "from typing import Dict, List, Tuple, Optional, Callable, Union, Any\n",
    "from typing_extensions import TypeAlias\n",
    "import nptyping as ND\n",
    "from nptyping import NDArray\n",
    "import neuropy.utils.type_aliases as types\n",
    "\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder, find_local_session_paths\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.core.epoch import NamedTimerange, Epoch\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.utils.matplotlib_helpers import matplotlib_file_only, matplotlib_configuration, matplotlib_configuration_update\n",
    "from neuropy.core.neuron_identities import NeuronIdentityTable, neuronTypesList, neuronTypesEnum\n",
    "from neuropy.utils.mixins.AttrsClassHelpers import AttrsBasedClassHelperMixin, serialized_field, serialized_attribute_field, non_serialized_field, custom_define\n",
    "from neuropy.utils.mixins.HDF5_representable import HDF_DeserializationMixin, post_deserialize, HDF_SerializationMixin, HDFMixin, HDF_Converter\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.neurons import NeuronType\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from neuropy.core.position import Position\n",
    "from neuropy.core.session.dataSession import DataSession\n",
    "from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent, PlacefieldSnapshot\n",
    "from neuropy.utils.debug_helpers import debug_print_placefield, debug_print_subsession_neuron_differences, debug_print_ratemap, debug_print_spike_counts, debug_plot_2d_binning, print_aligned_columns, parameter_sweeps, _plot_parameter_sweep, compare_placefields_info\n",
    "from neuropy.utils.indexing_helpers import NumpyHelpers, union_of_arrays, intersection_of_arrays, find_desired_sort_indicies, paired_incremental_sorting\n",
    "from pyphocorehelpers.print_helpers import print_object_memory_usage, print_dataframe_memory_usage, print_value_overview_only, DocumentationFilePrinter, print_keys_if_possible, generate_html_string, document_active_variables\n",
    "from pyphocorehelpers.programming_helpers import metadata_attributes\n",
    "from pyphocorehelpers.function_helpers import function_attributes\n",
    "## Pho Programming Helpers:\n",
    "import inspect\n",
    "from pyphocorehelpers.print_helpers import DocumentationFilePrinter, TypePrintMode, print_keys_if_possible, debug_dump_object_member_shapes, print_value_overview_only, document_active_variables\n",
    "from pyphocorehelpers.programming_helpers import IPythonHelpers, PythonDictionaryDefinitionFormat, MemoryManagement, inspect_callable_arguments, get_arguments_as_optional_dict, GeneratedClassDefinitionType, CodeConversion\n",
    "from pyphocorehelpers.notebook_helpers import NotebookCellExecutionLogger\n",
    "from pyphocorehelpers.gui.Qt.TopLevelWindowHelper import TopLevelWindowHelper, print_widget_hierarchy\n",
    "from pyphocorehelpers.indexing_helpers import reorder_columns, reorder_columns_relative, dict_to_full_array\n",
    "from pyphocorehelpers.DataStructure.RenderPlots.MatplotLibRenderPlots import MatplotlibRenderPlots\n",
    "\n",
    "doc_output_parent_folder: Path = Path('EXTERNAL/DEVELOPER_NOTES/DataStructureDocumentation').resolve() # ../.\n",
    "print(f\"doc_output_parent_folder: {doc_output_parent_folder}\")\n",
    "assert doc_output_parent_folder.exists()\n",
    "\n",
    "_notebook_path:Path = Path(IPythonHelpers.try_find_notebook_filepath(IPython.extract_module_locals())).resolve() # Finds the path of THIS notebook\n",
    "# _notebook_execution_logger: NotebookCellExecutionLogger = NotebookCellExecutionLogger(notebook_path=_notebook_path, enable_logging_to_file=False) # Builds a logger that records info about this notebook\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_load_session, batch_extended_computations, batch_evaluate_required_computations, BatchPlotting # BatchPlotting.batch_extended_programmatic_figures\n",
    "\n",
    "\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme # used in perform_pipeline_save\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import PipelineJupyterHelpers, CustomProcessingPhases\n",
    "\n",
    "\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "pg.setConfigOptions(useOpenGL=True)    # Use OpenGL for rendering which handles larger coordinates\n",
    "\n",
    "from pyphocorehelpers.exception_helpers import ExceptionPrintingContext, CapturedException\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import _find_any_context_neurons\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchSessionCompletionHandler # for `post_compute_validate(...)`\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BasePositionDecoder\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsResults\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends # for `_perform_long_short_instantaneous_spike_rate_groups_analysis`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import SingleBarResult, InstantaneousSpikeRateGroupsComputation, TruncationCheckingResults # for `BatchSessionCompletionHandler`, `AcrossSessionsAggregator`\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import SplitPartitionMembership\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalComputationFunctions, DirectionalLapsResult, TrackTemplates, DecoderDecodedEpochsResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderGlobalComputationFunctions,  RankOrderComputationsContainer, RankOrderResult, RankOrderAnalyses\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import EpochComputationFunctions, EpochComputationsComputationsContainer, DecodingResultND, Compute_NonPBE_Epochs, KnownFilterEpochs\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.SequenceBasedComputations import WCorrShuffle, SequenceBasedComputationsContainer\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.ComputationFunctionRegistryHolder import ComputationFunctionRegistryHolder, computation_precidence_specifying_function, global_function\n",
    "\n",
    "from neuropy.utils.mixins.binning_helpers import transition_matrix\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import TransitionMatrixComputations\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates, get_proper_global_spikes_df\n",
    "\n",
    "from pyphocorehelpers.Filesystem.path_helpers import set_posix_windows\n",
    "\n",
    "from pyphocorehelpers.assertion_helpers import Assert\n",
    "\n",
    "# Plotting\n",
    "# import pylustrator # customization of figures\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "\n",
    "matplotlib.use('Qt5Agg')\n",
    "# %matplotlib inline\n",
    "# %matplotlib auto\n",
    "\n",
    "# _restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# import pylustrator # call `pylustrator.start()` before creating your first figure in code.\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap, visualize_heatmap_pyqtgraph # used in `plot_kourosh_activity_style_figure`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot, plot_raster_plot\n",
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import UnitColoringMode, DataSeriesColorHelpers\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import _build_default_tick, build_scatter_plot_kwargs\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.Render2DScrollWindowPlot import Render2DScrollWindowPlotMixin, ScatterItemData\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import BatchPlotting # BatchPlotting.batch_extended_programmatic_figures, BatchPlotting.batch_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "from pyphoplacecellanalysis.General.Mixins.SpikesRenderingBaseMixin import SpikeEmphasisState\n",
    "from pyphoplacecellanalysis.General.Model.SpecificComputationParameterTypes import ComputationKWargParameters\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PAPER_FIGURE_figure_1_add_replay_epoch_rasters, PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_3, main_complete_figure_generations\n",
    "# from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import *\n",
    "\n",
    "# Jupyter Widget Interactive\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import interactive_pipeline_widget, interactive_pipeline_files\n",
    "from pyphocorehelpers.gui.Jupyter.simple_widgets import fullwidth_path_widget, render_colors\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import PipelineJupyterHelpers, CustomProcessingPhases, PipelinePickleFileSelectorWidget\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.PhoContainerTool import GenericMatplotlibContainer, GenericPyQtGraphContainer, PhoBaseContainerTool\n",
    "\n",
    "from datetime import datetime, date, timedelta\n",
    "from pyphocorehelpers.print_helpers import get_now_day_str, get_now_rounded_time_str\n",
    "\n",
    "DAY_DATE_STR: str = date.today().strftime(\"%Y-%m-%d\")\n",
    "DAY_DATE_TO_USE = f'{DAY_DATE_STR}' # used for filenames throught the notebook\n",
    "print(f'DAY_DATE_STR: {DAY_DATE_STR}, DAY_DATE_TO_USE: {DAY_DATE_TO_USE}')\n",
    "\n",
    "NOW_DATETIME: str = get_now_rounded_time_str()\n",
    "NOW_DATETIME_TO_USE = f'{NOW_DATETIME}' # used for filenames throught the notebook\n",
    "print(f'NOW_DATETIME: {NOW_DATETIME}, NOW_DATETIME_TO_USE: {NOW_DATETIME_TO_USE}')\n",
    "\n",
    "def get_global_variable(var_name):\n",
    "    \"\"\" used by `PipelineJupyterHelpers._build_pipeline_custom_processing_mode_selector_widget(...)` to update the notebook's variables \"\"\"\n",
    "    return globals()[var_name]\n",
    "    \n",
    "def update_global_variable(var_name, value):\n",
    "    \"\"\" used by `PipelineJupyterHelpers._build_pipeline_custom_processing_mode_selector_widget(...)` to update the notebook's variables \"\"\"\n",
    "    globals()[var_name] = value\n",
    "\n",
    "from pyphocorehelpers.gui.Jupyter.simple_widgets import build_global_data_root_parent_path_selection_widget\n",
    "all_paths = [Path(r'/home/halechr/FastData'), Path('/Volumes/SwapSSD/Data'), Path('/Users/pho/data'), Path(r'/media/halechr/MAX/Data'), Path(r'W:\\Data'), Path(r'/home/halechr/cloud/turbo/Data'), Path(r'/Volumes/MoverNew/data'), Path(r'/home/halechr/turbo/Data'), Path(r'/Users/pho/cloud/turbo/Data')] # Path('/Volumes/FedoraSSD/FastData'), \n",
    "global_data_root_parent_path = None\n",
    "def on_user_update_path_selection(new_path: Path):\n",
    "    global global_data_root_parent_path\n",
    "    new_global_data_root_parent_path = new_path.resolve()\n",
    "    global_data_root_parent_path = new_global_data_root_parent_path\n",
    "    print(f'global_data_root_parent_path changed to {global_data_root_parent_path}')\n",
    "    assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "            \n",
    "global_data_root_parent_path_widget = build_global_data_root_parent_path_selection_widget(all_paths, on_user_update_path_selection)\n",
    "global_data_root_parent_path_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e81646",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[0️⃣ Load Pipeline](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f07773d",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-0",
     "all",
     "run-group-0-interactive",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basedir: W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bab2928b7be74288b75e6e6c5cf2543c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(ToggleButtons(description='CustomProcessingPhases:', options=('clean_run', 'continued_run', 'final_run'), style=ToggleButtonsStyle(description_width='initial'), tooltips=('Select clean_run', 'Select continued_run', 'Select final_run'), value='clean_run'), Label(value='Empty')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving_mode: PipelineSavingScheme.SKIP_SAVING, force_reload: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['lap_direction_determination',\n",
       " 'pf_computation',\n",
       " 'pfdt_computation',\n",
       " 'position_decoding',\n",
       " 'position_decoding_two_step',\n",
       " 'firing_rate_trends',\n",
       " 'extended_stats',\n",
       " 'long_short_decoding_analyses',\n",
       " 'jonathan_firing_rate_analysis',\n",
       " 'long_short_fr_indicies_analyses',\n",
       " 'short_long_pf_overlap_analyses',\n",
       " 'long_short_post_decoding',\n",
       " 'long_short_inst_spike_rate_groups',\n",
       " 'long_short_endcap_analysis',\n",
       " 'split_to_directional_laps',\n",
       " 'merged_directional_placefields',\n",
       " 'rank_order_shuffle_analysis',\n",
       " 'directional_train_test_split',\n",
       " 'directional_decoders_decode_continuous',\n",
       " 'directional_decoders_evaluate_epochs',\n",
       " 'directional_decoders_epoch_heuristic_scoring',\n",
       " 'extended_pf_peak_information',\n",
       " 'perform_wcorr_shuffle_analysis',\n",
       " 'non_PBE_epochs_results',\n",
       " 'generalized_specific_epochs_decoding']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.2.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 9;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.2.2.min.js\", \"https://cdn.holoviz.org/panel/1.2.3/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      Bokeh = root.Bokeh;\n      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      if (!reloading && (!bokeh_loaded || is_dev)) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='fb08de7d-aa43-4526-a689-4e341dccc7fa'>\n",
       "  <div id=\"ffd24a1b-c534-48e6-9dac-c7811ea25279\" data-root-id=\"fb08de7d-aa43-4526-a689-4e341dccc7fa\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"dbd6f7b4-7edb-43c3-9563-897c65baa31e\":{\"version\":\"3.2.2\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"fb08de7d-aa43-4526-a689-4e341dccc7fa\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"7fe781d0-b967-4fd8-9705-f5bd83447c57\",\"attributes\":{\"plot_id\":\"fb08de7d-aa43-4526-a689-4e341dccc7fa\",\"comm_id\":\"fa992a4ddac34d1b99593f69f26c89d7\",\"client_comm_id\":\"e35d462242dd4701ad12863713f5152a\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"dbd6f7b4-7edb-43c3-9563-897c65baa31e\",\"roots\":{\"fb08de7d-aa43-4526-a689-4e341dccc7fa\":\"ffd24a1b-c534-48e6-9dac-c7811ea25279\"},\"root_ids\":[\"fb08de7d-aa43-4526-a689-4e341dccc7fa\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  const is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1\n",
       "  function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version && !is_dev) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "fb08de7d-aa43-4526-a689-4e341dccc7fa"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.2.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n  var reloading = true;\n  var Bokeh = root.Bokeh;\n  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'tabulator': 'https://cdn.jsdelivr.net/npm/tabulator-tables@5.5.0/dist/js/tabulator', 'moment': 'https://cdn.jsdelivr.net/npm/luxon/build/global/luxon.min', 'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"tabulator\"], function(Tabulator) {\n\twindow.Tabulator = Tabulator\n\ton_load()\n      })\n      require([\"moment\"], function(moment) {\n\twindow.moment = moment\n\ton_load()\n      })\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 11;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['Tabulator'] !== undefined) && (!(window['Tabulator'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/js/tabulator.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['moment'] !== undefined) && (!(window['moment'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/luxon/build/global/luxon.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/js/tabulator.js\", \"https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/luxon/build/global/luxon.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [\"https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/css/tabulator_simple.min.css\"];\n  var inline_js = [    function(Bokeh) {\n      inject_raw_css(\".tabulator{position:relative;border:1px solid #999;font-size:14px;text-align:left;overflow:hidden;-webkit-transform:translateZ(0);-moz-transform:translateZ(0);-ms-transform:translateZ(0);-o-transform:translateZ(0);transform:translateZ(0)}.tabulator[tabulator-layout=fitDataFill] .tabulator-tableholder .tabulator-table{min-width:100%}.tabulator[tabulator-layout=fitDataTable]{display:inline-block}.tabulator.tabulator-block-select{user-select:none}.tabulator .tabulator-header{position:relative;box-sizing:border-box;width:100%;border-bottom:1px solid #999;background-color:#fff;color:#555;font-weight:700;white-space:nowrap;overflow:hidden;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none}.tabulator .tabulator-header.tabulator-header-hidden{display:none}.tabulator .tabulator-header .tabulator-header-contents{position:relative;overflow:hidden}.tabulator .tabulator-header .tabulator-header-contents .tabulator-headers{display:inline-block}.tabulator .tabulator-header .tabulator-col{display:inline-flex;position:relative;box-sizing:border-box;flex-direction:column;justify-content:flex-start;border-right:1px solid #ddd;background:#fff;text-align:left;vertical-align:bottom;overflow:hidden}.tabulator .tabulator-header .tabulator-col.tabulator-moving{position:absolute;border:1px solid #999;background:#e6e6e6;pointer-events:none}.tabulator .tabulator-header .tabulator-col .tabulator-col-content{box-sizing:border-box;position:relative;padding:4px}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-header-popup-button{padding:0 8px}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-header-popup-button:hover{cursor:pointer;opacity:.6}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title-holder{position:relative}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title{box-sizing:border-box;width:100%;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;vertical-align:bottom}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title.tabulator-col-title-wrap{white-space:normal;text-overflow:clip}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title .tabulator-title-editor{box-sizing:border-box;width:100%;border:1px solid #999;padding:1px;background:#fff}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title .tabulator-header-popup-button+.tabulator-title-editor{width:calc(100% - 22px)}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-sorter{display:flex;align-items:center;position:absolute;top:0;bottom:0;right:4px}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{width:0;height:0;border-left:6px solid transparent;border-right:6px solid transparent;border-bottom:6px solid #bbb}.tabulator .tabulator-header .tabulator-col.tabulator-col-group .tabulator-col-group-cols{position:relative;display:flex;border-top:1px solid #ddd;overflow:hidden;margin-right:-1px}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter{position:relative;box-sizing:border-box;margin-top:2px;width:100%;text-align:center}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter textarea{height:auto!important}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter svg{margin-top:3px}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter input::-ms-clear{width:0;height:0}.tabulator .tabulator-header .tabulator-col.tabulator-sortable .tabulator-col-title{padding-right:25px}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable.tabulator-col-sorter-element:hover{cursor:pointer;background-color:#e6e6e6}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=none] .tabulator-col-content .tabulator-col-sorter{color:#bbb}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=none] .tabulator-col-content .tabulator-col-sorter.tabulator-col-sorter-element .tabulator-arrow:hover{cursor:pointer;border-bottom:6px solid #555}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=none] .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{border-top:none;border-bottom:6px solid #bbb}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=ascending] .tabulator-col-content .tabulator-col-sorter{color:#666}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=ascending] .tabulator-col-content .tabulator-col-sorter.tabulator-col-sorter-element .tabulator-arrow:hover{cursor:pointer;border-bottom:6px solid #555}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=ascending] .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{border-top:none;border-bottom:6px solid #666}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=descending] .tabulator-col-content .tabulator-col-sorter{color:#666}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=descending] .tabulator-col-content .tabulator-col-sorter.tabulator-col-sorter-element .tabulator-arrow:hover{cursor:pointer;border-top:6px solid #555}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=descending] .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{border-bottom:none;border-top:6px solid #666;color:#666}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical .tabulator-col-content .tabulator-col-title{writing-mode:vertical-rl;text-orientation:mixed;display:flex;align-items:center;justify-content:center}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-col-vertical-flip .tabulator-col-title{transform:rotate(180deg)}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-sortable .tabulator-col-title{padding-right:0;padding-top:20px}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-sortable.tabulator-col-vertical-flip .tabulator-col-title{padding-right:0;padding-bottom:20px}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-sortable .tabulator-col-sorter{justify-content:center;left:0;right:0;top:4px;bottom:auto}.tabulator .tabulator-header .tabulator-frozen{position:sticky;left:0;z-index:10}.tabulator .tabulator-header .tabulator-frozen.tabulator-frozen-left{border-right:2px solid #ddd}.tabulator .tabulator-header .tabulator-frozen.tabulator-frozen-right{border-left:2px solid #ddd}.tabulator .tabulator-header .tabulator-calcs-holder{box-sizing:border-box;background:#fff!important;border-top:1px solid #ddd;border-bottom:1px solid #ddd}.tabulator .tabulator-header .tabulator-calcs-holder .tabulator-row{background:#fff!important}.tabulator .tabulator-header .tabulator-calcs-holder .tabulator-row .tabulator-col-resize-handle,.tabulator .tabulator-header .tabulator-frozen-rows-holder:empty{display:none}.tabulator .tabulator-tableholder{position:relative;width:100%;white-space:nowrap;overflow:auto;-webkit-overflow-scrolling:touch}.tabulator .tabulator-tableholder:focus{outline:none}.tabulator .tabulator-tableholder .tabulator-placeholder{box-sizing:border-box;display:flex;align-items:center;justify-content:center;width:100%}.tabulator .tabulator-tableholder .tabulator-placeholder[tabulator-render-mode=virtual]{min-height:100%;min-width:100%}.tabulator .tabulator-tableholder .tabulator-placeholder .tabulator-placeholder-contents{display:inline-block;text-align:center;padding:10px;color:#ccc;font-weight:700;font-size:20px;white-space:normal}.tabulator .tabulator-tableholder .tabulator-table{position:relative;display:inline-block;background-color:#fff;white-space:nowrap;overflow:visible;color:#333}.tabulator .tabulator-tableholder .tabulator-table .tabulator-row.tabulator-calcs{font-weight:700;background:#f2f2f2!important}.tabulator .tabulator-tableholder .tabulator-table .tabulator-row.tabulator-calcs.tabulator-calcs-top{border-bottom:2px solid #ddd}.tabulator .tabulator-tableholder .tabulator-table .tabulator-row.tabulator-calcs.tabulator-calcs-bottom{border-top:2px solid #ddd}.tabulator .tabulator-footer{border-top:1px solid #999;background-color:#fff;color:#555;font-weight:700;white-space:nowrap;user-select:none;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none}.tabulator .tabulator-footer .tabulator-footer-contents{display:flex;flex-direction:row;align-items:center;justify-content:space-between;padding:5px 10px}.tabulator .tabulator-footer .tabulator-footer-contents:empty{display:none}.tabulator .tabulator-footer .tabulator-calcs-holder{box-sizing:border-box;width:100%;text-align:left;background:#fff!important;border-bottom:1px solid #ddd;border-top:1px solid #ddd;overflow:hidden}.tabulator .tabulator-footer .tabulator-calcs-holder .tabulator-row{display:inline-block;background:#fff!important}.tabulator .tabulator-footer .tabulator-calcs-holder .tabulator-row .tabulator-col-resize-handle{display:none}.tabulator .tabulator-footer .tabulator-calcs-holder:only-child{margin-bottom:-5px;border-bottom:none}.tabulator .tabulator-footer>*+.tabulator-page-counter{margin-left:10px}.tabulator .tabulator-footer .tabulator-page-counter{font-weight:400}.tabulator .tabulator-footer .tabulator-paginator{flex:1;text-align:right;color:#555;font-family:inherit;font-weight:inherit;font-size:inherit}.tabulator .tabulator-footer .tabulator-page-size{display:inline-block;margin:0 5px;padding:2px 5px;border:1px solid #aaa;border-radius:3px}.tabulator .tabulator-footer .tabulator-pages{margin:0 7px}.tabulator .tabulator-footer .tabulator-page{display:inline-block;margin:0 2px;padding:2px 5px;border:1px solid #aaa;border-radius:3px;background:hsla(0,0%,100%,.2)}.tabulator .tabulator-footer .tabulator-page.active{color:#d00}.tabulator .tabulator-footer .tabulator-page:disabled{opacity:.5}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-footer .tabulator-page:not(.disabled):hover{cursor:pointer;background:rgba(0,0,0,.2);color:#fff}}.tabulator .tabulator-col-resize-handle{position:relative;display:inline-block;width:6px;margin-left:-3px;margin-right:-3px;z-index:10;vertical-align:middle}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-col-resize-handle:hover{cursor:ew-resize}}.tabulator .tabulator-col-resize-handle:last-of-type{width:3px;margin-right:0}.tabulator .tabulator-alert{position:absolute;display:flex;align-items:center;top:0;left:0;z-index:100;height:100%;width:100%;background:rgba(0,0,0,.4);text-align:center}.tabulator .tabulator-alert .tabulator-alert-msg{display:inline-block;margin:0 auto;padding:10px 20px;border-radius:10px;background:#fff;font-weight:700;font-size:16px}.tabulator .tabulator-alert .tabulator-alert-msg.tabulator-alert-state-msg{border:4px solid #333;color:#000}.tabulator .tabulator-alert .tabulator-alert-msg.tabulator-alert-state-error{border:4px solid #d00;color:#590000}.tabulator-row{position:relative;box-sizing:border-box;min-height:22px}.tabulator-row,.tabulator-row.tabulator-row-even{background-color:#fff}@media (hover:hover) and (pointer:fine){.tabulator-row.tabulator-selectable:hover{background-color:#bbb;cursor:pointer}}.tabulator-row.tabulator-selected{background-color:#9abcea}@media (hover:hover) and (pointer:fine){.tabulator-row.tabulator-selected:hover{background-color:#769bcc;cursor:pointer}}.tabulator-row.tabulator-row-moving{border:1px solid #000;background:#fff}.tabulator-row.tabulator-moving{position:absolute;border-top:1px solid #ddd;border-bottom:1px solid #ddd;pointer-events:none;z-index:15}.tabulator-row .tabulator-row-resize-handle{position:absolute;right:0;bottom:0;left:0;height:5px}.tabulator-row .tabulator-row-resize-handle.prev{top:0;bottom:auto}@media (hover:hover) and (pointer:fine){.tabulator-row .tabulator-row-resize-handle:hover{cursor:ns-resize}}.tabulator-row .tabulator-responsive-collapse{box-sizing:border-box;padding:5px;border-top:1px solid #ddd;border-bottom:1px solid #ddd}.tabulator-row .tabulator-responsive-collapse:empty{display:none}.tabulator-row .tabulator-responsive-collapse table{font-size:14px}.tabulator-row .tabulator-responsive-collapse table tr td{position:relative}.tabulator-row .tabulator-responsive-collapse table tr td:first-of-type{padding-right:10px}.tabulator-row .tabulator-cell{display:inline-block;position:relative;box-sizing:border-box;padding:4px;border-right:1px solid #ddd;vertical-align:middle;white-space:nowrap;overflow:hidden;text-overflow:ellipsis}.tabulator-row .tabulator-cell.tabulator-frozen{display:inline-block;position:sticky;left:0;background-color:inherit;z-index:10}.tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-left{border-right:2px solid #ddd}.tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-right{border-left:2px solid #ddd}.tabulator-row .tabulator-cell.tabulator-editing{border:1px solid #1d68cd;outline:none;padding:0}.tabulator-row .tabulator-cell.tabulator-editing input,.tabulator-row .tabulator-cell.tabulator-editing select{border:1px;background:transparent;outline:none}.tabulator-row .tabulator-cell.tabulator-validation-fail{border:1px solid #d00}.tabulator-row .tabulator-cell.tabulator-validation-fail input,.tabulator-row .tabulator-cell.tabulator-validation-fail select{border:1px;background:transparent;color:#d00}.tabulator-row .tabulator-cell.tabulator-row-handle{display:inline-flex;align-items:center;justify-content:center;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none}.tabulator-row .tabulator-cell.tabulator-row-handle .tabulator-row-handle-box{width:80%}.tabulator-row .tabulator-cell.tabulator-row-handle .tabulator-row-handle-box .tabulator-row-handle-bar{width:100%;height:3px;margin-top:2px;background:#666}.tabulator-row .tabulator-cell .tabulator-data-tree-branch{display:inline-block;vertical-align:middle;height:9px;width:7px;margin-top:-9px;margin-right:5px;border-bottom-left-radius:1px;border-left:2px solid #ddd;border-bottom:2px solid #ddd}.tabulator-row .tabulator-cell .tabulator-data-tree-control{display:inline-flex;justify-content:center;align-items:center;vertical-align:middle;height:11px;width:11px;margin-right:5px;border:1px solid #333;border-radius:2px;background:rgba(0,0,0,.1);overflow:hidden}@media (hover:hover) and (pointer:fine){.tabulator-row .tabulator-cell .tabulator-data-tree-control:hover{cursor:pointer;background:rgba(0,0,0,.2)}}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-collapse{display:inline-block;position:relative;height:7px;width:1px;background:transparent}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-collapse:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-expand{display:inline-block;position:relative;height:7px;width:1px;background:#333}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-expand:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle{display:inline-flex;align-items:center;justify-content:center;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none;height:15px;width:15px;border-radius:20px;background:#666;color:#fff;font-weight:700;font-size:1.1em}@media (hover:hover) and (pointer:fine){.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle:hover{opacity:.7;cursor:pointer}}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle.open .tabulator-responsive-collapse-toggle-close{display:initial}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle.open .tabulator-responsive-collapse-toggle-open{display:none}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle svg{stroke:#fff}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle .tabulator-responsive-collapse-toggle-close{display:none}.tabulator-row .tabulator-cell .tabulator-traffic-light{display:inline-block;height:14px;width:14px;border-radius:14px}.tabulator-row.tabulator-group{box-sizing:border-box;border-bottom:1px solid #999;border-right:1px solid #ddd;border-top:1px solid #999;padding:5px 5px 5px 10px;background:#ccc;font-weight:700;min-width:100%}@media (hover:hover) and (pointer:fine){.tabulator-row.tabulator-group:hover{cursor:pointer;background-color:rgba(0,0,0,.1)}}.tabulator-row.tabulator-group.tabulator-group-visible .tabulator-arrow{margin-right:10px;border-left:6px solid transparent;border-right:6px solid transparent;border-top:6px solid #666;border-bottom:0}.tabulator-row.tabulator-group.tabulator-group-level-1{padding-left:30px}.tabulator-row.tabulator-group.tabulator-group-level-2{padding-left:50px}.tabulator-row.tabulator-group.tabulator-group-level-3{padding-left:70px}.tabulator-row.tabulator-group.tabulator-group-level-4{padding-left:90px}.tabulator-row.tabulator-group.tabulator-group-level-5{padding-left:110px}.tabulator-row.tabulator-group .tabulator-group-toggle{display:inline-block}.tabulator-row.tabulator-group .tabulator-arrow{display:inline-block;width:0;height:0;margin-right:16px;border-top:6px solid transparent;border-bottom:6px solid transparent;border-right:0;border-left:6px solid #666;vertical-align:middle}.tabulator-row.tabulator-group span{margin-left:10px;color:#d00}.tabulator-popup-container{position:absolute;display:inline-block;box-sizing:border-box;background:#fff;border:1px solid #ddd;box-shadow:0 0 5px 0 rgba(0,0,0,.2);font-size:14px;overflow-y:auto;-webkit-overflow-scrolling:touch;z-index:10000}.tabulator-popup{padding:5px;border-radius:3px}.tabulator-tooltip{max-width:Min(500px,100%);padding:3px 5px;border-radius:2px;box-shadow:none;font-size:12px;pointer-events:none}.tabulator-menu .tabulator-menu-item{position:relative;box-sizing:border-box;padding:5px 10px;user-select:none}.tabulator-menu .tabulator-menu-item.tabulator-menu-item-disabled{opacity:.5}@media (hover:hover) and (pointer:fine){.tabulator-menu .tabulator-menu-item:not(.tabulator-menu-item-disabled):hover{cursor:pointer;background:#fff}}.tabulator-menu .tabulator-menu-item.tabulator-menu-item-submenu{padding-right:25px}.tabulator-menu .tabulator-menu-item.tabulator-menu-item-submenu:after{display:inline-block;position:absolute;top:calc(5px + .4em);right:10px;height:7px;width:7px;content:\\\"\\\";border-color:#ddd;border-style:solid;border-width:1px 1px 0 0;vertical-align:top;transform:rotate(45deg)}.tabulator-menu .tabulator-menu-separator{border-top:1px solid #ddd}.tabulator-edit-list{max-height:200px;font-size:14px;overflow-y:auto;-webkit-overflow-scrolling:touch}.tabulator-edit-list .tabulator-edit-list-item{padding:4px;color:#333;outline:none}.tabulator-edit-list .tabulator-edit-list-item.active{color:#fff;background:#1d68cd}.tabulator-edit-list .tabulator-edit-list-item.active.focused{outline:1px solid hsla(0,0%,100%,.5)}.tabulator-edit-list .tabulator-edit-list-item.focused{outline:1px solid #1d68cd}@media (hover:hover) and (pointer:fine){.tabulator-edit-list .tabulator-edit-list-item:hover{cursor:pointer;color:#fff;background:#1d68cd}}.tabulator-edit-list .tabulator-edit-list-placeholder{padding:4px;color:#333;text-align:center}.tabulator-edit-list .tabulator-edit-list-group{border-bottom:1px solid #ddd;padding:6px 4px 4px;color:#333;font-weight:700}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-2,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-2{padding-left:12px}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-3,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-3{padding-left:20px}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-4,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-4{padding-left:28px}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-5,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-5{padding-left:36px}.tabulator.tabulator-ltr{direction:ltr}.tabulator.tabulator-rtl{text-align:initial;direction:rtl}.tabulator.tabulator-rtl .tabulator-header .tabulator-col{text-align:initial;border-left:1px solid #ddd;border-right:initial}.tabulator.tabulator-rtl .tabulator-header .tabulator-col.tabulator-col-group .tabulator-col-group-cols{margin-right:0;margin-left:-1px}.tabulator.tabulator-rtl .tabulator-header .tabulator-col.tabulator-sortable .tabulator-col-title{padding-right:0;padding-left:25px}.tabulator.tabulator-rtl .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-sorter{left:8px;right:auto}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell{border-right:initial;border-left:1px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell .tabulator-data-tree-branch{margin-right:0;margin-left:5px;border-bottom-left-radius:0;border-bottom-right-radius:1px;border-left:initial;border-right:2px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell .tabulator-data-tree-control{margin-right:0;margin-left:5px}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-left{border-left:2px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-right{border-right:2px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-col-resize-handle:last-of-type{width:3px;margin-left:0;margin-right:-3px}.tabulator.tabulator-rtl .tabulator-footer .tabulator-calcs-holder{text-align:initial}.tabulator-print-fullscreen{position:absolute;top:0;bottom:0;left:0;right:0;z-index:10000}body.tabulator-print-fullscreen-hide>:not(.tabulator-print-fullscreen){display:none!important}.tabulator-print-table{border-collapse:collapse}.tabulator-print-table .tabulator-data-tree-branch{display:inline-block;vertical-align:middle;height:9px;width:7px;margin-top:-9px;margin-right:5px;border-bottom-left-radius:1px;border-left:2px solid #ddd;border-bottom:2px solid #ddd}.tabulator-print-table .tabulator-print-table-group{box-sizing:border-box;border-bottom:1px solid #999;border-right:1px solid #ddd;border-top:1px solid #999;padding:5px 5px 5px 10px;background:#ccc;font-weight:700;min-width:100%}@media (hover:hover) and (pointer:fine){.tabulator-print-table .tabulator-print-table-group:hover{cursor:pointer;background-color:rgba(0,0,0,.1)}}.tabulator-print-table .tabulator-print-table-group.tabulator-group-visible .tabulator-arrow{margin-right:10px;border-left:6px solid transparent;border-right:6px solid transparent;border-top:6px solid #666;border-bottom:0}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-1 td{padding-left:30px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-2 td{padding-left:50px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-3 td{padding-left:70px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-4 td{padding-left:90px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-5 td{padding-left:110px!important}.tabulator-print-table .tabulator-print-table-group .tabulator-group-toggle{display:inline-block}.tabulator-print-table .tabulator-print-table-group .tabulator-arrow{display:inline-block;width:0;height:0;margin-right:16px;border-top:6px solid transparent;border-bottom:6px solid transparent;border-right:0;border-left:6px solid #666;vertical-align:middle}.tabulator-print-table .tabulator-print-table-group span{color:#d00}.tabulator-print-table .tabulator-data-tree-control{display:inline-flex;justify-content:center;align-items:center;vertical-align:middle;height:11px;width:11px;margin-right:5px;border:1px solid #333;border-radius:2px;background:rgba(0,0,0,.1);overflow:hidden}@media (hover:hover) and (pointer:fine){.tabulator-print-table .tabulator-data-tree-control:hover{cursor:pointer;background:rgba(0,0,0,.2)}}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-collapse{display:inline-block;position:relative;height:7px;width:1px;background:transparent}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-collapse:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-expand{display:inline-block;position:relative;height:7px;width:1px;background:#333}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-expand:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator{border:none;background-color:#fff}.tabulator .tabulator-header .tabulator-calcs-holder{background:#f2f2f2!important;border-bottom:1px solid #999}.tabulator .tabulator-header .tabulator-calcs-holder .tabulator-row{background:#f2f2f2!important}.tabulator .tabulator-tableholder .tabulator-placeholder span{color:#000}.tabulator .tabulator-footer .tabulator-calcs-holder{background:#f2f2f2!important;border-bottom:1px solid #fff}.tabulator .tabulator-footer .tabulator-calcs-holder .tabulator-row{background:#f2f2f2!important}.tabulator-row{border-bottom:1px solid #ddd}.tabulator-row .tabulator-cell:last-of-type{border-right:none}.tabulator-row.tabulator-group span{color:#666}.tabulator-print-table .tabulator-print-table-group span{margin-left:10px;color:#666}\\n/*# sourceMappingURL=tabulator_simple.min.css.map */\");\n    },    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      Bokeh = root.Bokeh;\n      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      if (!reloading && (!bokeh_loaded || is_dev)) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.2.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n  var reloading = true;\n  var Bokeh = root.Bokeh;\n  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'tabulator': 'https://cdn.jsdelivr.net/npm/tabulator-tables@5.5.0/dist/js/tabulator', 'moment': 'https://cdn.jsdelivr.net/npm/luxon/build/global/luxon.min', 'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"tabulator\"], function(Tabulator) {\n\twindow.Tabulator = Tabulator\n\ton_load()\n      })\n      require([\"moment\"], function(moment) {\n\twindow.moment = moment\n\ton_load()\n      })\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 11;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['Tabulator'] !== undefined) && (!(window['Tabulator'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/js/tabulator.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['moment'] !== undefined) && (!(window['moment'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/luxon/build/global/luxon.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/js/tabulator.js\", \"https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/luxon/build/global/luxon.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [\"https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/css/tabulator_simple.min.css\"];\n  var inline_js = [    function(Bokeh) {\n      inject_raw_css(\".tabulator{position:relative;border:1px solid #999;font-size:14px;text-align:left;overflow:hidden;-webkit-transform:translateZ(0);-moz-transform:translateZ(0);-ms-transform:translateZ(0);-o-transform:translateZ(0);transform:translateZ(0)}.tabulator[tabulator-layout=fitDataFill] .tabulator-tableholder .tabulator-table{min-width:100%}.tabulator[tabulator-layout=fitDataTable]{display:inline-block}.tabulator.tabulator-block-select{user-select:none}.tabulator .tabulator-header{position:relative;box-sizing:border-box;width:100%;border-bottom:1px solid #999;background-color:#fff;color:#555;font-weight:700;white-space:nowrap;overflow:hidden;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none}.tabulator .tabulator-header.tabulator-header-hidden{display:none}.tabulator .tabulator-header .tabulator-header-contents{position:relative;overflow:hidden}.tabulator .tabulator-header .tabulator-header-contents .tabulator-headers{display:inline-block}.tabulator .tabulator-header .tabulator-col{display:inline-flex;position:relative;box-sizing:border-box;flex-direction:column;justify-content:flex-start;border-right:1px solid #ddd;background:#fff;text-align:left;vertical-align:bottom;overflow:hidden}.tabulator .tabulator-header .tabulator-col.tabulator-moving{position:absolute;border:1px solid #999;background:#e6e6e6;pointer-events:none}.tabulator .tabulator-header .tabulator-col .tabulator-col-content{box-sizing:border-box;position:relative;padding:4px}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-header-popup-button{padding:0 8px}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-header-popup-button:hover{cursor:pointer;opacity:.6}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title-holder{position:relative}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title{box-sizing:border-box;width:100%;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;vertical-align:bottom}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title.tabulator-col-title-wrap{white-space:normal;text-overflow:clip}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title .tabulator-title-editor{box-sizing:border-box;width:100%;border:1px solid #999;padding:1px;background:#fff}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title .tabulator-header-popup-button+.tabulator-title-editor{width:calc(100% - 22px)}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-sorter{display:flex;align-items:center;position:absolute;top:0;bottom:0;right:4px}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{width:0;height:0;border-left:6px solid transparent;border-right:6px solid transparent;border-bottom:6px solid #bbb}.tabulator .tabulator-header .tabulator-col.tabulator-col-group .tabulator-col-group-cols{position:relative;display:flex;border-top:1px solid #ddd;overflow:hidden;margin-right:-1px}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter{position:relative;box-sizing:border-box;margin-top:2px;width:100%;text-align:center}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter textarea{height:auto!important}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter svg{margin-top:3px}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter input::-ms-clear{width:0;height:0}.tabulator .tabulator-header .tabulator-col.tabulator-sortable .tabulator-col-title{padding-right:25px}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable.tabulator-col-sorter-element:hover{cursor:pointer;background-color:#e6e6e6}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=none] .tabulator-col-content .tabulator-col-sorter{color:#bbb}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=none] .tabulator-col-content .tabulator-col-sorter.tabulator-col-sorter-element .tabulator-arrow:hover{cursor:pointer;border-bottom:6px solid #555}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=none] .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{border-top:none;border-bottom:6px solid #bbb}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=ascending] .tabulator-col-content .tabulator-col-sorter{color:#666}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=ascending] .tabulator-col-content .tabulator-col-sorter.tabulator-col-sorter-element .tabulator-arrow:hover{cursor:pointer;border-bottom:6px solid #555}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=ascending] .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{border-top:none;border-bottom:6px solid #666}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=descending] .tabulator-col-content .tabulator-col-sorter{color:#666}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=descending] .tabulator-col-content .tabulator-col-sorter.tabulator-col-sorter-element .tabulator-arrow:hover{cursor:pointer;border-top:6px solid #555}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=descending] .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{border-bottom:none;border-top:6px solid #666;color:#666}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical .tabulator-col-content .tabulator-col-title{writing-mode:vertical-rl;text-orientation:mixed;display:flex;align-items:center;justify-content:center}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-col-vertical-flip .tabulator-col-title{transform:rotate(180deg)}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-sortable .tabulator-col-title{padding-right:0;padding-top:20px}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-sortable.tabulator-col-vertical-flip .tabulator-col-title{padding-right:0;padding-bottom:20px}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-sortable .tabulator-col-sorter{justify-content:center;left:0;right:0;top:4px;bottom:auto}.tabulator .tabulator-header .tabulator-frozen{position:sticky;left:0;z-index:10}.tabulator .tabulator-header .tabulator-frozen.tabulator-frozen-left{border-right:2px solid #ddd}.tabulator .tabulator-header .tabulator-frozen.tabulator-frozen-right{border-left:2px solid #ddd}.tabulator .tabulator-header .tabulator-calcs-holder{box-sizing:border-box;background:#fff!important;border-top:1px solid #ddd;border-bottom:1px solid #ddd}.tabulator .tabulator-header .tabulator-calcs-holder .tabulator-row{background:#fff!important}.tabulator .tabulator-header .tabulator-calcs-holder .tabulator-row .tabulator-col-resize-handle,.tabulator .tabulator-header .tabulator-frozen-rows-holder:empty{display:none}.tabulator .tabulator-tableholder{position:relative;width:100%;white-space:nowrap;overflow:auto;-webkit-overflow-scrolling:touch}.tabulator .tabulator-tableholder:focus{outline:none}.tabulator .tabulator-tableholder .tabulator-placeholder{box-sizing:border-box;display:flex;align-items:center;justify-content:center;width:100%}.tabulator .tabulator-tableholder .tabulator-placeholder[tabulator-render-mode=virtual]{min-height:100%;min-width:100%}.tabulator .tabulator-tableholder .tabulator-placeholder .tabulator-placeholder-contents{display:inline-block;text-align:center;padding:10px;color:#ccc;font-weight:700;font-size:20px;white-space:normal}.tabulator .tabulator-tableholder .tabulator-table{position:relative;display:inline-block;background-color:#fff;white-space:nowrap;overflow:visible;color:#333}.tabulator .tabulator-tableholder .tabulator-table .tabulator-row.tabulator-calcs{font-weight:700;background:#f2f2f2!important}.tabulator .tabulator-tableholder .tabulator-table .tabulator-row.tabulator-calcs.tabulator-calcs-top{border-bottom:2px solid #ddd}.tabulator .tabulator-tableholder .tabulator-table .tabulator-row.tabulator-calcs.tabulator-calcs-bottom{border-top:2px solid #ddd}.tabulator .tabulator-footer{border-top:1px solid #999;background-color:#fff;color:#555;font-weight:700;white-space:nowrap;user-select:none;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none}.tabulator .tabulator-footer .tabulator-footer-contents{display:flex;flex-direction:row;align-items:center;justify-content:space-between;padding:5px 10px}.tabulator .tabulator-footer .tabulator-footer-contents:empty{display:none}.tabulator .tabulator-footer .tabulator-calcs-holder{box-sizing:border-box;width:100%;text-align:left;background:#fff!important;border-bottom:1px solid #ddd;border-top:1px solid #ddd;overflow:hidden}.tabulator .tabulator-footer .tabulator-calcs-holder .tabulator-row{display:inline-block;background:#fff!important}.tabulator .tabulator-footer .tabulator-calcs-holder .tabulator-row .tabulator-col-resize-handle{display:none}.tabulator .tabulator-footer .tabulator-calcs-holder:only-child{margin-bottom:-5px;border-bottom:none}.tabulator .tabulator-footer>*+.tabulator-page-counter{margin-left:10px}.tabulator .tabulator-footer .tabulator-page-counter{font-weight:400}.tabulator .tabulator-footer .tabulator-paginator{flex:1;text-align:right;color:#555;font-family:inherit;font-weight:inherit;font-size:inherit}.tabulator .tabulator-footer .tabulator-page-size{display:inline-block;margin:0 5px;padding:2px 5px;border:1px solid #aaa;border-radius:3px}.tabulator .tabulator-footer .tabulator-pages{margin:0 7px}.tabulator .tabulator-footer .tabulator-page{display:inline-block;margin:0 2px;padding:2px 5px;border:1px solid #aaa;border-radius:3px;background:hsla(0,0%,100%,.2)}.tabulator .tabulator-footer .tabulator-page.active{color:#d00}.tabulator .tabulator-footer .tabulator-page:disabled{opacity:.5}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-footer .tabulator-page:not(.disabled):hover{cursor:pointer;background:rgba(0,0,0,.2);color:#fff}}.tabulator .tabulator-col-resize-handle{position:relative;display:inline-block;width:6px;margin-left:-3px;margin-right:-3px;z-index:10;vertical-align:middle}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-col-resize-handle:hover{cursor:ew-resize}}.tabulator .tabulator-col-resize-handle:last-of-type{width:3px;margin-right:0}.tabulator .tabulator-alert{position:absolute;display:flex;align-items:center;top:0;left:0;z-index:100;height:100%;width:100%;background:rgba(0,0,0,.4);text-align:center}.tabulator .tabulator-alert .tabulator-alert-msg{display:inline-block;margin:0 auto;padding:10px 20px;border-radius:10px;background:#fff;font-weight:700;font-size:16px}.tabulator .tabulator-alert .tabulator-alert-msg.tabulator-alert-state-msg{border:4px solid #333;color:#000}.tabulator .tabulator-alert .tabulator-alert-msg.tabulator-alert-state-error{border:4px solid #d00;color:#590000}.tabulator-row{position:relative;box-sizing:border-box;min-height:22px}.tabulator-row,.tabulator-row.tabulator-row-even{background-color:#fff}@media (hover:hover) and (pointer:fine){.tabulator-row.tabulator-selectable:hover{background-color:#bbb;cursor:pointer}}.tabulator-row.tabulator-selected{background-color:#9abcea}@media (hover:hover) and (pointer:fine){.tabulator-row.tabulator-selected:hover{background-color:#769bcc;cursor:pointer}}.tabulator-row.tabulator-row-moving{border:1px solid #000;background:#fff}.tabulator-row.tabulator-moving{position:absolute;border-top:1px solid #ddd;border-bottom:1px solid #ddd;pointer-events:none;z-index:15}.tabulator-row .tabulator-row-resize-handle{position:absolute;right:0;bottom:0;left:0;height:5px}.tabulator-row .tabulator-row-resize-handle.prev{top:0;bottom:auto}@media (hover:hover) and (pointer:fine){.tabulator-row .tabulator-row-resize-handle:hover{cursor:ns-resize}}.tabulator-row .tabulator-responsive-collapse{box-sizing:border-box;padding:5px;border-top:1px solid #ddd;border-bottom:1px solid #ddd}.tabulator-row .tabulator-responsive-collapse:empty{display:none}.tabulator-row .tabulator-responsive-collapse table{font-size:14px}.tabulator-row .tabulator-responsive-collapse table tr td{position:relative}.tabulator-row .tabulator-responsive-collapse table tr td:first-of-type{padding-right:10px}.tabulator-row .tabulator-cell{display:inline-block;position:relative;box-sizing:border-box;padding:4px;border-right:1px solid #ddd;vertical-align:middle;white-space:nowrap;overflow:hidden;text-overflow:ellipsis}.tabulator-row .tabulator-cell.tabulator-frozen{display:inline-block;position:sticky;left:0;background-color:inherit;z-index:10}.tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-left{border-right:2px solid #ddd}.tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-right{border-left:2px solid #ddd}.tabulator-row .tabulator-cell.tabulator-editing{border:1px solid #1d68cd;outline:none;padding:0}.tabulator-row .tabulator-cell.tabulator-editing input,.tabulator-row .tabulator-cell.tabulator-editing select{border:1px;background:transparent;outline:none}.tabulator-row .tabulator-cell.tabulator-validation-fail{border:1px solid #d00}.tabulator-row .tabulator-cell.tabulator-validation-fail input,.tabulator-row .tabulator-cell.tabulator-validation-fail select{border:1px;background:transparent;color:#d00}.tabulator-row .tabulator-cell.tabulator-row-handle{display:inline-flex;align-items:center;justify-content:center;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none}.tabulator-row .tabulator-cell.tabulator-row-handle .tabulator-row-handle-box{width:80%}.tabulator-row .tabulator-cell.tabulator-row-handle .tabulator-row-handle-box .tabulator-row-handle-bar{width:100%;height:3px;margin-top:2px;background:#666}.tabulator-row .tabulator-cell .tabulator-data-tree-branch{display:inline-block;vertical-align:middle;height:9px;width:7px;margin-top:-9px;margin-right:5px;border-bottom-left-radius:1px;border-left:2px solid #ddd;border-bottom:2px solid #ddd}.tabulator-row .tabulator-cell .tabulator-data-tree-control{display:inline-flex;justify-content:center;align-items:center;vertical-align:middle;height:11px;width:11px;margin-right:5px;border:1px solid #333;border-radius:2px;background:rgba(0,0,0,.1);overflow:hidden}@media (hover:hover) and (pointer:fine){.tabulator-row .tabulator-cell .tabulator-data-tree-control:hover{cursor:pointer;background:rgba(0,0,0,.2)}}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-collapse{display:inline-block;position:relative;height:7px;width:1px;background:transparent}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-collapse:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-expand{display:inline-block;position:relative;height:7px;width:1px;background:#333}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-expand:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle{display:inline-flex;align-items:center;justify-content:center;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none;height:15px;width:15px;border-radius:20px;background:#666;color:#fff;font-weight:700;font-size:1.1em}@media (hover:hover) and (pointer:fine){.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle:hover{opacity:.7;cursor:pointer}}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle.open .tabulator-responsive-collapse-toggle-close{display:initial}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle.open .tabulator-responsive-collapse-toggle-open{display:none}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle svg{stroke:#fff}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle .tabulator-responsive-collapse-toggle-close{display:none}.tabulator-row .tabulator-cell .tabulator-traffic-light{display:inline-block;height:14px;width:14px;border-radius:14px}.tabulator-row.tabulator-group{box-sizing:border-box;border-bottom:1px solid #999;border-right:1px solid #ddd;border-top:1px solid #999;padding:5px 5px 5px 10px;background:#ccc;font-weight:700;min-width:100%}@media (hover:hover) and (pointer:fine){.tabulator-row.tabulator-group:hover{cursor:pointer;background-color:rgba(0,0,0,.1)}}.tabulator-row.tabulator-group.tabulator-group-visible .tabulator-arrow{margin-right:10px;border-left:6px solid transparent;border-right:6px solid transparent;border-top:6px solid #666;border-bottom:0}.tabulator-row.tabulator-group.tabulator-group-level-1{padding-left:30px}.tabulator-row.tabulator-group.tabulator-group-level-2{padding-left:50px}.tabulator-row.tabulator-group.tabulator-group-level-3{padding-left:70px}.tabulator-row.tabulator-group.tabulator-group-level-4{padding-left:90px}.tabulator-row.tabulator-group.tabulator-group-level-5{padding-left:110px}.tabulator-row.tabulator-group .tabulator-group-toggle{display:inline-block}.tabulator-row.tabulator-group .tabulator-arrow{display:inline-block;width:0;height:0;margin-right:16px;border-top:6px solid transparent;border-bottom:6px solid transparent;border-right:0;border-left:6px solid #666;vertical-align:middle}.tabulator-row.tabulator-group span{margin-left:10px;color:#d00}.tabulator-popup-container{position:absolute;display:inline-block;box-sizing:border-box;background:#fff;border:1px solid #ddd;box-shadow:0 0 5px 0 rgba(0,0,0,.2);font-size:14px;overflow-y:auto;-webkit-overflow-scrolling:touch;z-index:10000}.tabulator-popup{padding:5px;border-radius:3px}.tabulator-tooltip{max-width:Min(500px,100%);padding:3px 5px;border-radius:2px;box-shadow:none;font-size:12px;pointer-events:none}.tabulator-menu .tabulator-menu-item{position:relative;box-sizing:border-box;padding:5px 10px;user-select:none}.tabulator-menu .tabulator-menu-item.tabulator-menu-item-disabled{opacity:.5}@media (hover:hover) and (pointer:fine){.tabulator-menu .tabulator-menu-item:not(.tabulator-menu-item-disabled):hover{cursor:pointer;background:#fff}}.tabulator-menu .tabulator-menu-item.tabulator-menu-item-submenu{padding-right:25px}.tabulator-menu .tabulator-menu-item.tabulator-menu-item-submenu:after{display:inline-block;position:absolute;top:calc(5px + .4em);right:10px;height:7px;width:7px;content:\\\"\\\";border-color:#ddd;border-style:solid;border-width:1px 1px 0 0;vertical-align:top;transform:rotate(45deg)}.tabulator-menu .tabulator-menu-separator{border-top:1px solid #ddd}.tabulator-edit-list{max-height:200px;font-size:14px;overflow-y:auto;-webkit-overflow-scrolling:touch}.tabulator-edit-list .tabulator-edit-list-item{padding:4px;color:#333;outline:none}.tabulator-edit-list .tabulator-edit-list-item.active{color:#fff;background:#1d68cd}.tabulator-edit-list .tabulator-edit-list-item.active.focused{outline:1px solid hsla(0,0%,100%,.5)}.tabulator-edit-list .tabulator-edit-list-item.focused{outline:1px solid #1d68cd}@media (hover:hover) and (pointer:fine){.tabulator-edit-list .tabulator-edit-list-item:hover{cursor:pointer;color:#fff;background:#1d68cd}}.tabulator-edit-list .tabulator-edit-list-placeholder{padding:4px;color:#333;text-align:center}.tabulator-edit-list .tabulator-edit-list-group{border-bottom:1px solid #ddd;padding:6px 4px 4px;color:#333;font-weight:700}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-2,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-2{padding-left:12px}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-3,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-3{padding-left:20px}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-4,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-4{padding-left:28px}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-5,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-5{padding-left:36px}.tabulator.tabulator-ltr{direction:ltr}.tabulator.tabulator-rtl{text-align:initial;direction:rtl}.tabulator.tabulator-rtl .tabulator-header .tabulator-col{text-align:initial;border-left:1px solid #ddd;border-right:initial}.tabulator.tabulator-rtl .tabulator-header .tabulator-col.tabulator-col-group .tabulator-col-group-cols{margin-right:0;margin-left:-1px}.tabulator.tabulator-rtl .tabulator-header .tabulator-col.tabulator-sortable .tabulator-col-title{padding-right:0;padding-left:25px}.tabulator.tabulator-rtl .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-sorter{left:8px;right:auto}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell{border-right:initial;border-left:1px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell .tabulator-data-tree-branch{margin-right:0;margin-left:5px;border-bottom-left-radius:0;border-bottom-right-radius:1px;border-left:initial;border-right:2px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell .tabulator-data-tree-control{margin-right:0;margin-left:5px}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-left{border-left:2px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-right{border-right:2px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-col-resize-handle:last-of-type{width:3px;margin-left:0;margin-right:-3px}.tabulator.tabulator-rtl .tabulator-footer .tabulator-calcs-holder{text-align:initial}.tabulator-print-fullscreen{position:absolute;top:0;bottom:0;left:0;right:0;z-index:10000}body.tabulator-print-fullscreen-hide>:not(.tabulator-print-fullscreen){display:none!important}.tabulator-print-table{border-collapse:collapse}.tabulator-print-table .tabulator-data-tree-branch{display:inline-block;vertical-align:middle;height:9px;width:7px;margin-top:-9px;margin-right:5px;border-bottom-left-radius:1px;border-left:2px solid #ddd;border-bottom:2px solid #ddd}.tabulator-print-table .tabulator-print-table-group{box-sizing:border-box;border-bottom:1px solid #999;border-right:1px solid #ddd;border-top:1px solid #999;padding:5px 5px 5px 10px;background:#ccc;font-weight:700;min-width:100%}@media (hover:hover) and (pointer:fine){.tabulator-print-table .tabulator-print-table-group:hover{cursor:pointer;background-color:rgba(0,0,0,.1)}}.tabulator-print-table .tabulator-print-table-group.tabulator-group-visible .tabulator-arrow{margin-right:10px;border-left:6px solid transparent;border-right:6px solid transparent;border-top:6px solid #666;border-bottom:0}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-1 td{padding-left:30px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-2 td{padding-left:50px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-3 td{padding-left:70px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-4 td{padding-left:90px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-5 td{padding-left:110px!important}.tabulator-print-table .tabulator-print-table-group .tabulator-group-toggle{display:inline-block}.tabulator-print-table .tabulator-print-table-group .tabulator-arrow{display:inline-block;width:0;height:0;margin-right:16px;border-top:6px solid transparent;border-bottom:6px solid transparent;border-right:0;border-left:6px solid #666;vertical-align:middle}.tabulator-print-table .tabulator-print-table-group span{color:#d00}.tabulator-print-table .tabulator-data-tree-control{display:inline-flex;justify-content:center;align-items:center;vertical-align:middle;height:11px;width:11px;margin-right:5px;border:1px solid #333;border-radius:2px;background:rgba(0,0,0,.1);overflow:hidden}@media (hover:hover) and (pointer:fine){.tabulator-print-table .tabulator-data-tree-control:hover{cursor:pointer;background:rgba(0,0,0,.2)}}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-collapse{display:inline-block;position:relative;height:7px;width:1px;background:transparent}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-collapse:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-expand{display:inline-block;position:relative;height:7px;width:1px;background:#333}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-expand:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator{border:none;background-color:#fff}.tabulator .tabulator-header .tabulator-calcs-holder{background:#f2f2f2!important;border-bottom:1px solid #999}.tabulator .tabulator-header .tabulator-calcs-holder .tabulator-row{background:#f2f2f2!important}.tabulator .tabulator-tableholder .tabulator-placeholder span{color:#000}.tabulator .tabulator-footer .tabulator-calcs-holder{background:#f2f2f2!important;border-bottom:1px solid #fff}.tabulator .tabulator-footer .tabulator-calcs-holder .tabulator-row{background:#f2f2f2!important}.tabulator-row{border-bottom:1px solid #ddd}.tabulator-row .tabulator-cell:last-of-type{border-right:none}.tabulator-row.tabulator-group span{color:#666}.tabulator-print-table .tabulator-print-table-group span{margin-left:10px;color:#666}\\n/*# sourceMappingURL=tabulator_simple.min.css.map */\");\n    },    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      Bokeh = root.Bokeh;\n      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      if (!reloading && (!bokeh_loaded || is_dev)) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.2.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n  var reloading = true;\n  var Bokeh = root.Bokeh;\n  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'tabulator': 'https://cdn.jsdelivr.net/npm/tabulator-tables@5.5.0/dist/js/tabulator', 'moment': 'https://cdn.jsdelivr.net/npm/luxon/build/global/luxon.min', 'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"tabulator\"], function(Tabulator) {\n\twindow.Tabulator = Tabulator\n\ton_load()\n      })\n      require([\"moment\"], function(moment) {\n\twindow.moment = moment\n\ton_load()\n      })\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 11;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['Tabulator'] !== undefined) && (!(window['Tabulator'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/js/tabulator.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['moment'] !== undefined) && (!(window['moment'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/luxon/build/global/luxon.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/js/tabulator.js\", \"https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/luxon/build/global/luxon.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [\"https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/css/tabulator_simple.min.css\"];\n  var inline_js = [    function(Bokeh) {\n      inject_raw_css(\".tabulator{position:relative;border:1px solid #999;font-size:14px;text-align:left;overflow:hidden;-webkit-transform:translateZ(0);-moz-transform:translateZ(0);-ms-transform:translateZ(0);-o-transform:translateZ(0);transform:translateZ(0)}.tabulator[tabulator-layout=fitDataFill] .tabulator-tableholder .tabulator-table{min-width:100%}.tabulator[tabulator-layout=fitDataTable]{display:inline-block}.tabulator.tabulator-block-select{user-select:none}.tabulator .tabulator-header{position:relative;box-sizing:border-box;width:100%;border-bottom:1px solid #999;background-color:#fff;color:#555;font-weight:700;white-space:nowrap;overflow:hidden;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none}.tabulator .tabulator-header.tabulator-header-hidden{display:none}.tabulator .tabulator-header .tabulator-header-contents{position:relative;overflow:hidden}.tabulator .tabulator-header .tabulator-header-contents .tabulator-headers{display:inline-block}.tabulator .tabulator-header .tabulator-col{display:inline-flex;position:relative;box-sizing:border-box;flex-direction:column;justify-content:flex-start;border-right:1px solid #ddd;background:#fff;text-align:left;vertical-align:bottom;overflow:hidden}.tabulator .tabulator-header .tabulator-col.tabulator-moving{position:absolute;border:1px solid #999;background:#e6e6e6;pointer-events:none}.tabulator .tabulator-header .tabulator-col .tabulator-col-content{box-sizing:border-box;position:relative;padding:4px}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-header-popup-button{padding:0 8px}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-header-popup-button:hover{cursor:pointer;opacity:.6}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title-holder{position:relative}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title{box-sizing:border-box;width:100%;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;vertical-align:bottom}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title.tabulator-col-title-wrap{white-space:normal;text-overflow:clip}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title .tabulator-title-editor{box-sizing:border-box;width:100%;border:1px solid #999;padding:1px;background:#fff}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title .tabulator-header-popup-button+.tabulator-title-editor{width:calc(100% - 22px)}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-sorter{display:flex;align-items:center;position:absolute;top:0;bottom:0;right:4px}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{width:0;height:0;border-left:6px solid transparent;border-right:6px solid transparent;border-bottom:6px solid #bbb}.tabulator .tabulator-header .tabulator-col.tabulator-col-group .tabulator-col-group-cols{position:relative;display:flex;border-top:1px solid #ddd;overflow:hidden;margin-right:-1px}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter{position:relative;box-sizing:border-box;margin-top:2px;width:100%;text-align:center}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter textarea{height:auto!important}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter svg{margin-top:3px}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter input::-ms-clear{width:0;height:0}.tabulator .tabulator-header .tabulator-col.tabulator-sortable .tabulator-col-title{padding-right:25px}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable.tabulator-col-sorter-element:hover{cursor:pointer;background-color:#e6e6e6}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=none] .tabulator-col-content .tabulator-col-sorter{color:#bbb}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=none] .tabulator-col-content .tabulator-col-sorter.tabulator-col-sorter-element .tabulator-arrow:hover{cursor:pointer;border-bottom:6px solid #555}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=none] .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{border-top:none;border-bottom:6px solid #bbb}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=ascending] .tabulator-col-content .tabulator-col-sorter{color:#666}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=ascending] .tabulator-col-content .tabulator-col-sorter.tabulator-col-sorter-element .tabulator-arrow:hover{cursor:pointer;border-bottom:6px solid #555}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=ascending] .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{border-top:none;border-bottom:6px solid #666}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=descending] .tabulator-col-content .tabulator-col-sorter{color:#666}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=descending] .tabulator-col-content .tabulator-col-sorter.tabulator-col-sorter-element .tabulator-arrow:hover{cursor:pointer;border-top:6px solid #555}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=descending] .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{border-bottom:none;border-top:6px solid #666;color:#666}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical .tabulator-col-content .tabulator-col-title{writing-mode:vertical-rl;text-orientation:mixed;display:flex;align-items:center;justify-content:center}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-col-vertical-flip .tabulator-col-title{transform:rotate(180deg)}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-sortable .tabulator-col-title{padding-right:0;padding-top:20px}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-sortable.tabulator-col-vertical-flip .tabulator-col-title{padding-right:0;padding-bottom:20px}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-sortable .tabulator-col-sorter{justify-content:center;left:0;right:0;top:4px;bottom:auto}.tabulator .tabulator-header .tabulator-frozen{position:sticky;left:0;z-index:10}.tabulator .tabulator-header .tabulator-frozen.tabulator-frozen-left{border-right:2px solid #ddd}.tabulator .tabulator-header .tabulator-frozen.tabulator-frozen-right{border-left:2px solid #ddd}.tabulator .tabulator-header .tabulator-calcs-holder{box-sizing:border-box;background:#fff!important;border-top:1px solid #ddd;border-bottom:1px solid #ddd}.tabulator .tabulator-header .tabulator-calcs-holder .tabulator-row{background:#fff!important}.tabulator .tabulator-header .tabulator-calcs-holder .tabulator-row .tabulator-col-resize-handle,.tabulator .tabulator-header .tabulator-frozen-rows-holder:empty{display:none}.tabulator .tabulator-tableholder{position:relative;width:100%;white-space:nowrap;overflow:auto;-webkit-overflow-scrolling:touch}.tabulator .tabulator-tableholder:focus{outline:none}.tabulator .tabulator-tableholder .tabulator-placeholder{box-sizing:border-box;display:flex;align-items:center;justify-content:center;width:100%}.tabulator .tabulator-tableholder .tabulator-placeholder[tabulator-render-mode=virtual]{min-height:100%;min-width:100%}.tabulator .tabulator-tableholder .tabulator-placeholder .tabulator-placeholder-contents{display:inline-block;text-align:center;padding:10px;color:#ccc;font-weight:700;font-size:20px;white-space:normal}.tabulator .tabulator-tableholder .tabulator-table{position:relative;display:inline-block;background-color:#fff;white-space:nowrap;overflow:visible;color:#333}.tabulator .tabulator-tableholder .tabulator-table .tabulator-row.tabulator-calcs{font-weight:700;background:#f2f2f2!important}.tabulator .tabulator-tableholder .tabulator-table .tabulator-row.tabulator-calcs.tabulator-calcs-top{border-bottom:2px solid #ddd}.tabulator .tabulator-tableholder .tabulator-table .tabulator-row.tabulator-calcs.tabulator-calcs-bottom{border-top:2px solid #ddd}.tabulator .tabulator-footer{border-top:1px solid #999;background-color:#fff;color:#555;font-weight:700;white-space:nowrap;user-select:none;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none}.tabulator .tabulator-footer .tabulator-footer-contents{display:flex;flex-direction:row;align-items:center;justify-content:space-between;padding:5px 10px}.tabulator .tabulator-footer .tabulator-footer-contents:empty{display:none}.tabulator .tabulator-footer .tabulator-calcs-holder{box-sizing:border-box;width:100%;text-align:left;background:#fff!important;border-bottom:1px solid #ddd;border-top:1px solid #ddd;overflow:hidden}.tabulator .tabulator-footer .tabulator-calcs-holder .tabulator-row{display:inline-block;background:#fff!important}.tabulator .tabulator-footer .tabulator-calcs-holder .tabulator-row .tabulator-col-resize-handle{display:none}.tabulator .tabulator-footer .tabulator-calcs-holder:only-child{margin-bottom:-5px;border-bottom:none}.tabulator .tabulator-footer>*+.tabulator-page-counter{margin-left:10px}.tabulator .tabulator-footer .tabulator-page-counter{font-weight:400}.tabulator .tabulator-footer .tabulator-paginator{flex:1;text-align:right;color:#555;font-family:inherit;font-weight:inherit;font-size:inherit}.tabulator .tabulator-footer .tabulator-page-size{display:inline-block;margin:0 5px;padding:2px 5px;border:1px solid #aaa;border-radius:3px}.tabulator .tabulator-footer .tabulator-pages{margin:0 7px}.tabulator .tabulator-footer .tabulator-page{display:inline-block;margin:0 2px;padding:2px 5px;border:1px solid #aaa;border-radius:3px;background:hsla(0,0%,100%,.2)}.tabulator .tabulator-footer .tabulator-page.active{color:#d00}.tabulator .tabulator-footer .tabulator-page:disabled{opacity:.5}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-footer .tabulator-page:not(.disabled):hover{cursor:pointer;background:rgba(0,0,0,.2);color:#fff}}.tabulator .tabulator-col-resize-handle{position:relative;display:inline-block;width:6px;margin-left:-3px;margin-right:-3px;z-index:10;vertical-align:middle}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-col-resize-handle:hover{cursor:ew-resize}}.tabulator .tabulator-col-resize-handle:last-of-type{width:3px;margin-right:0}.tabulator .tabulator-alert{position:absolute;display:flex;align-items:center;top:0;left:0;z-index:100;height:100%;width:100%;background:rgba(0,0,0,.4);text-align:center}.tabulator .tabulator-alert .tabulator-alert-msg{display:inline-block;margin:0 auto;padding:10px 20px;border-radius:10px;background:#fff;font-weight:700;font-size:16px}.tabulator .tabulator-alert .tabulator-alert-msg.tabulator-alert-state-msg{border:4px solid #333;color:#000}.tabulator .tabulator-alert .tabulator-alert-msg.tabulator-alert-state-error{border:4px solid #d00;color:#590000}.tabulator-row{position:relative;box-sizing:border-box;min-height:22px}.tabulator-row,.tabulator-row.tabulator-row-even{background-color:#fff}@media (hover:hover) and (pointer:fine){.tabulator-row.tabulator-selectable:hover{background-color:#bbb;cursor:pointer}}.tabulator-row.tabulator-selected{background-color:#9abcea}@media (hover:hover) and (pointer:fine){.tabulator-row.tabulator-selected:hover{background-color:#769bcc;cursor:pointer}}.tabulator-row.tabulator-row-moving{border:1px solid #000;background:#fff}.tabulator-row.tabulator-moving{position:absolute;border-top:1px solid #ddd;border-bottom:1px solid #ddd;pointer-events:none;z-index:15}.tabulator-row .tabulator-row-resize-handle{position:absolute;right:0;bottom:0;left:0;height:5px}.tabulator-row .tabulator-row-resize-handle.prev{top:0;bottom:auto}@media (hover:hover) and (pointer:fine){.tabulator-row .tabulator-row-resize-handle:hover{cursor:ns-resize}}.tabulator-row .tabulator-responsive-collapse{box-sizing:border-box;padding:5px;border-top:1px solid #ddd;border-bottom:1px solid #ddd}.tabulator-row .tabulator-responsive-collapse:empty{display:none}.tabulator-row .tabulator-responsive-collapse table{font-size:14px}.tabulator-row .tabulator-responsive-collapse table tr td{position:relative}.tabulator-row .tabulator-responsive-collapse table tr td:first-of-type{padding-right:10px}.tabulator-row .tabulator-cell{display:inline-block;position:relative;box-sizing:border-box;padding:4px;border-right:1px solid #ddd;vertical-align:middle;white-space:nowrap;overflow:hidden;text-overflow:ellipsis}.tabulator-row .tabulator-cell.tabulator-frozen{display:inline-block;position:sticky;left:0;background-color:inherit;z-index:10}.tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-left{border-right:2px solid #ddd}.tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-right{border-left:2px solid #ddd}.tabulator-row .tabulator-cell.tabulator-editing{border:1px solid #1d68cd;outline:none;padding:0}.tabulator-row .tabulator-cell.tabulator-editing input,.tabulator-row .tabulator-cell.tabulator-editing select{border:1px;background:transparent;outline:none}.tabulator-row .tabulator-cell.tabulator-validation-fail{border:1px solid #d00}.tabulator-row .tabulator-cell.tabulator-validation-fail input,.tabulator-row .tabulator-cell.tabulator-validation-fail select{border:1px;background:transparent;color:#d00}.tabulator-row .tabulator-cell.tabulator-row-handle{display:inline-flex;align-items:center;justify-content:center;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none}.tabulator-row .tabulator-cell.tabulator-row-handle .tabulator-row-handle-box{width:80%}.tabulator-row .tabulator-cell.tabulator-row-handle .tabulator-row-handle-box .tabulator-row-handle-bar{width:100%;height:3px;margin-top:2px;background:#666}.tabulator-row .tabulator-cell .tabulator-data-tree-branch{display:inline-block;vertical-align:middle;height:9px;width:7px;margin-top:-9px;margin-right:5px;border-bottom-left-radius:1px;border-left:2px solid #ddd;border-bottom:2px solid #ddd}.tabulator-row .tabulator-cell .tabulator-data-tree-control{display:inline-flex;justify-content:center;align-items:center;vertical-align:middle;height:11px;width:11px;margin-right:5px;border:1px solid #333;border-radius:2px;background:rgba(0,0,0,.1);overflow:hidden}@media (hover:hover) and (pointer:fine){.tabulator-row .tabulator-cell .tabulator-data-tree-control:hover{cursor:pointer;background:rgba(0,0,0,.2)}}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-collapse{display:inline-block;position:relative;height:7px;width:1px;background:transparent}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-collapse:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-expand{display:inline-block;position:relative;height:7px;width:1px;background:#333}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-expand:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle{display:inline-flex;align-items:center;justify-content:center;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none;height:15px;width:15px;border-radius:20px;background:#666;color:#fff;font-weight:700;font-size:1.1em}@media (hover:hover) and (pointer:fine){.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle:hover{opacity:.7;cursor:pointer}}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle.open .tabulator-responsive-collapse-toggle-close{display:initial}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle.open .tabulator-responsive-collapse-toggle-open{display:none}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle svg{stroke:#fff}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle .tabulator-responsive-collapse-toggle-close{display:none}.tabulator-row .tabulator-cell .tabulator-traffic-light{display:inline-block;height:14px;width:14px;border-radius:14px}.tabulator-row.tabulator-group{box-sizing:border-box;border-bottom:1px solid #999;border-right:1px solid #ddd;border-top:1px solid #999;padding:5px 5px 5px 10px;background:#ccc;font-weight:700;min-width:100%}@media (hover:hover) and (pointer:fine){.tabulator-row.tabulator-group:hover{cursor:pointer;background-color:rgba(0,0,0,.1)}}.tabulator-row.tabulator-group.tabulator-group-visible .tabulator-arrow{margin-right:10px;border-left:6px solid transparent;border-right:6px solid transparent;border-top:6px solid #666;border-bottom:0}.tabulator-row.tabulator-group.tabulator-group-level-1{padding-left:30px}.tabulator-row.tabulator-group.tabulator-group-level-2{padding-left:50px}.tabulator-row.tabulator-group.tabulator-group-level-3{padding-left:70px}.tabulator-row.tabulator-group.tabulator-group-level-4{padding-left:90px}.tabulator-row.tabulator-group.tabulator-group-level-5{padding-left:110px}.tabulator-row.tabulator-group .tabulator-group-toggle{display:inline-block}.tabulator-row.tabulator-group .tabulator-arrow{display:inline-block;width:0;height:0;margin-right:16px;border-top:6px solid transparent;border-bottom:6px solid transparent;border-right:0;border-left:6px solid #666;vertical-align:middle}.tabulator-row.tabulator-group span{margin-left:10px;color:#d00}.tabulator-popup-container{position:absolute;display:inline-block;box-sizing:border-box;background:#fff;border:1px solid #ddd;box-shadow:0 0 5px 0 rgba(0,0,0,.2);font-size:14px;overflow-y:auto;-webkit-overflow-scrolling:touch;z-index:10000}.tabulator-popup{padding:5px;border-radius:3px}.tabulator-tooltip{max-width:Min(500px,100%);padding:3px 5px;border-radius:2px;box-shadow:none;font-size:12px;pointer-events:none}.tabulator-menu .tabulator-menu-item{position:relative;box-sizing:border-box;padding:5px 10px;user-select:none}.tabulator-menu .tabulator-menu-item.tabulator-menu-item-disabled{opacity:.5}@media (hover:hover) and (pointer:fine){.tabulator-menu .tabulator-menu-item:not(.tabulator-menu-item-disabled):hover{cursor:pointer;background:#fff}}.tabulator-menu .tabulator-menu-item.tabulator-menu-item-submenu{padding-right:25px}.tabulator-menu .tabulator-menu-item.tabulator-menu-item-submenu:after{display:inline-block;position:absolute;top:calc(5px + .4em);right:10px;height:7px;width:7px;content:\\\"\\\";border-color:#ddd;border-style:solid;border-width:1px 1px 0 0;vertical-align:top;transform:rotate(45deg)}.tabulator-menu .tabulator-menu-separator{border-top:1px solid #ddd}.tabulator-edit-list{max-height:200px;font-size:14px;overflow-y:auto;-webkit-overflow-scrolling:touch}.tabulator-edit-list .tabulator-edit-list-item{padding:4px;color:#333;outline:none}.tabulator-edit-list .tabulator-edit-list-item.active{color:#fff;background:#1d68cd}.tabulator-edit-list .tabulator-edit-list-item.active.focused{outline:1px solid hsla(0,0%,100%,.5)}.tabulator-edit-list .tabulator-edit-list-item.focused{outline:1px solid #1d68cd}@media (hover:hover) and (pointer:fine){.tabulator-edit-list .tabulator-edit-list-item:hover{cursor:pointer;color:#fff;background:#1d68cd}}.tabulator-edit-list .tabulator-edit-list-placeholder{padding:4px;color:#333;text-align:center}.tabulator-edit-list .tabulator-edit-list-group{border-bottom:1px solid #ddd;padding:6px 4px 4px;color:#333;font-weight:700}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-2,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-2{padding-left:12px}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-3,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-3{padding-left:20px}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-4,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-4{padding-left:28px}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-5,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-5{padding-left:36px}.tabulator.tabulator-ltr{direction:ltr}.tabulator.tabulator-rtl{text-align:initial;direction:rtl}.tabulator.tabulator-rtl .tabulator-header .tabulator-col{text-align:initial;border-left:1px solid #ddd;border-right:initial}.tabulator.tabulator-rtl .tabulator-header .tabulator-col.tabulator-col-group .tabulator-col-group-cols{margin-right:0;margin-left:-1px}.tabulator.tabulator-rtl .tabulator-header .tabulator-col.tabulator-sortable .tabulator-col-title{padding-right:0;padding-left:25px}.tabulator.tabulator-rtl .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-sorter{left:8px;right:auto}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell{border-right:initial;border-left:1px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell .tabulator-data-tree-branch{margin-right:0;margin-left:5px;border-bottom-left-radius:0;border-bottom-right-radius:1px;border-left:initial;border-right:2px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell .tabulator-data-tree-control{margin-right:0;margin-left:5px}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-left{border-left:2px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-right{border-right:2px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-col-resize-handle:last-of-type{width:3px;margin-left:0;margin-right:-3px}.tabulator.tabulator-rtl .tabulator-footer .tabulator-calcs-holder{text-align:initial}.tabulator-print-fullscreen{position:absolute;top:0;bottom:0;left:0;right:0;z-index:10000}body.tabulator-print-fullscreen-hide>:not(.tabulator-print-fullscreen){display:none!important}.tabulator-print-table{border-collapse:collapse}.tabulator-print-table .tabulator-data-tree-branch{display:inline-block;vertical-align:middle;height:9px;width:7px;margin-top:-9px;margin-right:5px;border-bottom-left-radius:1px;border-left:2px solid #ddd;border-bottom:2px solid #ddd}.tabulator-print-table .tabulator-print-table-group{box-sizing:border-box;border-bottom:1px solid #999;border-right:1px solid #ddd;border-top:1px solid #999;padding:5px 5px 5px 10px;background:#ccc;font-weight:700;min-width:100%}@media (hover:hover) and (pointer:fine){.tabulator-print-table .tabulator-print-table-group:hover{cursor:pointer;background-color:rgba(0,0,0,.1)}}.tabulator-print-table .tabulator-print-table-group.tabulator-group-visible .tabulator-arrow{margin-right:10px;border-left:6px solid transparent;border-right:6px solid transparent;border-top:6px solid #666;border-bottom:0}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-1 td{padding-left:30px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-2 td{padding-left:50px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-3 td{padding-left:70px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-4 td{padding-left:90px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-5 td{padding-left:110px!important}.tabulator-print-table .tabulator-print-table-group .tabulator-group-toggle{display:inline-block}.tabulator-print-table .tabulator-print-table-group .tabulator-arrow{display:inline-block;width:0;height:0;margin-right:16px;border-top:6px solid transparent;border-bottom:6px solid transparent;border-right:0;border-left:6px solid #666;vertical-align:middle}.tabulator-print-table .tabulator-print-table-group span{color:#d00}.tabulator-print-table .tabulator-data-tree-control{display:inline-flex;justify-content:center;align-items:center;vertical-align:middle;height:11px;width:11px;margin-right:5px;border:1px solid #333;border-radius:2px;background:rgba(0,0,0,.1);overflow:hidden}@media (hover:hover) and (pointer:fine){.tabulator-print-table .tabulator-data-tree-control:hover{cursor:pointer;background:rgba(0,0,0,.2)}}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-collapse{display:inline-block;position:relative;height:7px;width:1px;background:transparent}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-collapse:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-expand{display:inline-block;position:relative;height:7px;width:1px;background:#333}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-expand:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator{border:none;background-color:#fff}.tabulator .tabulator-header .tabulator-calcs-holder{background:#f2f2f2!important;border-bottom:1px solid #999}.tabulator .tabulator-header .tabulator-calcs-holder .tabulator-row{background:#f2f2f2!important}.tabulator .tabulator-tableholder .tabulator-placeholder span{color:#000}.tabulator .tabulator-footer .tabulator-calcs-holder{background:#f2f2f2!important;border-bottom:1px solid #fff}.tabulator .tabulator-footer .tabulator-calcs-holder .tabulator-row{background:#f2f2f2!important}.tabulator-row{border-bottom:1px solid #ddd}.tabulator-row .tabulator-cell:last-of-type{border-right:none}.tabulator-row.tabulator-group span{color:#666}.tabulator-print-table .tabulator-print-table-group span{margin-left:10px;color:#666}\\n/*# sourceMappingURL=tabulator_simple.min.css.map */\");\n    },    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      Bokeh = root.Bokeh;\n      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      if (!reloading && (!bokeh_loaded || is_dev)) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba3489aec9224970895eca5b0d7b5d08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Column\n",
       "    [0] Tabulator(disabled=True, height=400, page_size=10, pagination='local', selection=[0], show_index=False, sorters=[{'field': 'Modification D...], value=              ...)\n",
       "    [1] Tabulator(disabled=True, height=400, page_size=10, pagination='local', selection=[0], show_index=False, sorters=[{'field': 'Modification D...], value=              ...)\n",
       "    [2] Column(margin=(10, 0))\n",
       "        [0] HTML(str)\n",
       "        [1] Row\n",
       "            [0] IntInput(end=100, name='Min FR (Hz)', start=0, value=2, width=150)\n",
       "            [1] TextInput(name='QClu Values', placeholder='Enter as list: [1, ..., value='[1, 2, 4, 6, 7, 8, 9]')\n",
       "    [3] Row\n",
       "        [0] Button(button_type='success', name='Save')\n",
       "        [1] Button(button_type='primary', name='Load')\n",
       "        [2] Button(button_type='warning', name='Compute')\n",
       "        [3] Button(button_type='primary', name='Compute New')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Load Data                                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "active_data_mode_name = 'kdiba'\n",
    "local_session_root_parent_context = IdentifyingContext(format_name=active_data_mode_name) # , animal_name='', configuration_name='one', session_name=a_sess.session_name\n",
    "local_session_root_parent_path = global_data_root_parent_path.joinpath('KDIBA')\n",
    "\n",
    "# [*] - indicates bad or session with a problem\n",
    "# 0, 1, 2, 3, 4, 5, 6, 7, [8], [9], 10, 11, [12], 13, 14, [15], [16], 17, \n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-07_11-26-53')\n",
    "curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15') # Recomputed 2025-06-10 00:56\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43') # Recomputed for 2.0Hz, allACLUS 2025-07-17 07:25\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31') # Recomputed 2025-06-10 01:16 \n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19') # Recomputed 2025-06-10 01:56  -- notedy ylims shifted up by about half the track width\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46') # Recomputed 2025-06-10 02:27 \n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30') ## BLOCKING ERROR with pf2D computation (empty) for 5Hz 2024-12-02 15:24 \n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50') # Recomputed 2025-06-10 02:40 \n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54') # 2025-06-10 02:52 -- about 3 good replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3') # Recomputed 2025-06-10 03:23\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25') # Recomputed 2024-12-16 19:33 -- about 5 good replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54') # Recomputed 2024-12-16 19:36 -- TONS of good replays, 10+ pages of them \n",
    "\n",
    "local_session_parent_path: Path = local_session_root_parent_path.joinpath(curr_context.animal, curr_context.exper_name) # 'gor01', 'one' - probably not needed anymore\n",
    "basedir: Path = local_session_parent_path.joinpath(curr_context.session_name).resolve()\n",
    "print(f'basedir: {str(basedir)}')\n",
    "\n",
    "epoch_name_includelist = None\n",
    "active_computation_functions_name_includelist=['lap_direction_determination',\n",
    "                                                'pf_computation',\n",
    "                                                'pfdt_computation',\n",
    "                                                # 'firing_rate_trends',\n",
    "                                                # 'pf_dt_sequential_surprise', \n",
    "                                            #    'ratemap_peaks_prominence2d',\n",
    "                                                'position_decoding', \n",
    "                                                # 'position_decoding_two_step', #'directional_decoders_epoch_heuristic_scoring',\n",
    "                                            #    'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping',\n",
    "                                            #     'long_short_inst_spike_rate_groups',\n",
    "                                            #     'long_short_endcap_analysis',\n",
    "                                            \n",
    "]\n",
    "\n",
    "## 'split_to_directional_laps' -- is global\n",
    "\n",
    "\n",
    "\n",
    "# Read if possible:\n",
    "saving_mode = PipelineSavingScheme.SKIP_SAVING\n",
    "force_reload = False\n",
    "\n",
    "# # Force write:\n",
    "# saving_mode = PipelineSavingScheme.TEMP_THEN_OVERWRITE\n",
    "# # saving_mode = PipelineSavingScheme.OVERWRITE_IN_PLACE\n",
    "# force_reload = True\n",
    "\n",
    "selector, on_value_change = PipelineJupyterHelpers._build_pipeline_custom_processing_mode_selector_widget(update_global_variable_fn=update_global_variable, debug_print=False, enable_full_view=True)\n",
    "# selector.value = 'clean_run'\n",
    "# selector.value = 'continued_run'\n",
    "selector.value = 'final_run'\n",
    "on_value_change(dict(new=selector.value)) ## do update manually so the workspace variables reflect the set values\n",
    "## TODO: if loading is not possible, we need to change the `saving_mode` so that the new results are properly saved.\n",
    "print(f\"saving_mode: {saving_mode}, force_reload: {force_reload}\")\n",
    "\n",
    "extended_computations_include_includelist_phase_dict: Dict[str, CustomProcessingPhases] = CustomProcessingPhases.get_extended_computations_include_includelist_phase_dict()\n",
    "\n",
    "current_phase: CustomProcessingPhases = CustomProcessingPhases[selector.value]  # Assuming selector.value is an instance of CustomProcessingPhases\n",
    "extended_computations_include_includelist: List[str] = [key for key, value in extended_computations_include_includelist_phase_dict.items() if value <= current_phase]\n",
    "display(extended_computations_include_includelist)\n",
    "force_recompute_override_computations_includelist = None\n",
    "# force_recompute_override_computations_includelist = ['split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous'] # \n",
    "\n",
    "# ## INPUTS: basedir\n",
    "active_session_pickle_file_widget = PipelinePickleFileSelectorWidget(directory=basedir, on_update_global_variable_callback=update_global_variable, on_get_global_variable_callback=get_global_variable)\n",
    "\n",
    "_subfn_load, _subfn_save, _subfn_compute, _subfn_compute_new = active_session_pickle_file_widget._build_load_save_callbacks(global_data_root_parent_path=global_data_root_parent_path, active_data_mode_name=active_data_mode_name, basedir=basedir, saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                                             extended_computations_include_includelist=extended_computations_include_includelist, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist)\n",
    "\n",
    "## try selecting the first\n",
    "did_find_valid_selection: bool = active_session_pickle_file_widget.try_select_first_valid_files()\n",
    "\n",
    "# Display the widget\n",
    "active_session_pickle_file_widget.servable()\n",
    "# active_session_pickle_file_widget.try_select_first_valid_files()\n",
    "\n",
    "# OUTPUTS: active_session_pickle_file_widget, widget.active_local_pkl, widget.active_global_pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6e0657",
   "metadata": {
    "tags": [
     "run-group-0-interactive",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_suffix: \"_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 8, 9]-frateThresh_2.0\"\n",
      "Computing loaded session pickle file results : \"W:/Data/KDIBA/gor01/one/2006-6-08_14-26-15/loadedSessPickle_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 8, 9]-frateThresh_2.0.pkl\"... \tdone.\n",
      "\tdone.\n",
      "\tdone.\n",
      "\tdone.\n",
      "\tdone.\n",
      "\tdone.\n",
      "\tdone.\n",
      "\tdone.\n",
      "\tdone.\n",
      "\tdone.\n",
      "\tdone.\n",
      "\tdone.\n",
      "\tdone.\n",
      "\tdone.\n",
      "\tdone.\n",
      "\tdone.\n",
      "build_logger(full_logger_string=\"2025-07-17_07-07-07.Apogee.kdiba.gor01.one.2006-6-08_14-26-15\", file_logging_dir: None):\n",
      "done.\n",
      "Loading pickled pipeline success: W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\loadedSessPickle_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 8, 9]-frateThresh_2.0.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['lap_direction_determination', 'pf_computation', 'firing_rate_trends', 'position_decoding']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_odd]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_even]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze1_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze2_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and `active_computation_results[maze_any]` already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "\t !!!||||||||||||||||||> RUNNING `PostHocPipelineFixup.FINAL_UPDATE_ALL(...)`:\n",
      "starting `PostHocPipelineFixup.FINAL_UPDATE_ALL(...)`...\n",
      "\t =================> RUNNING `PostHocPipelineFixup.FINAL_UPDATE_FILEPATHS(...)`:\n",
      "\t =================> RUNNING `PostHocPipelineFixup.FINAL_UPDATE_NON_PBE_EPOCHS(...)`:\n",
      "computing non_PBE epochs for session...\n",
      "\n",
      "Saving non_pbe results results : \"W:/Data/KDIBA/gor01/one/2006-6-08_14-26-15/2006-6-08_14-26-15.non_pbe.npy\"... 2006-6-08_14-26-15.non_pbe.npy saved\n",
      "done.\n",
      "computing non_PBE_EndcapsOnly epochs for session...\n",
      "\n",
      "Saving non_pbe_endcaps results results : \"W:/Data/KDIBA/gor01/one/2006-6-08_14-26-15/2006-6-08_14-26-15.non_pbe_endcaps.npy\"... 2006-6-08_14-26-15.non_pbe_endcaps.npy saved\n",
      "done.\n",
      "\t !!!||||||||||||||||||> RUNNING `PostHocPipelineFixup.FINAL_FIX_LAPS_FROM_OVERRIDES(...)`:\n",
      "\t !!!||||||||||||||||||> RUNNING `PostHocPipelineFixup.FINAL_FIX_GRID_BIN_BOUNDS(...)`:\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-08_14-26-15/2006-6-08_14-26-15.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-08_14-26-15/2006-6-08_14-26-15.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-08_14-26-15/2006-6-08_14-26-15.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-08_14-26-15/2006-6-08_14-26-15.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-08_14-26-15/2006-6-08_14-26-15.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-08_14-26-15/2006-6-08_14-26-15.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-08_14-26-15/2006-6-08_14-26-15.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-08_14-26-15/2006-6-08_14-26-15.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-08_14-26-15/2006-6-08_14-26-15.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-08_14-26-15/2006-6-08_14-26-15.position_info.mat\"... done.\n",
      "No grid bin bounds were changed. Everything should be up-to-date!\n",
      "No grid bin bounds were changed. Everything should be up-to-date!\n",
      "\tDirectionalLapsResult.init_from_pipeline_natural_epochs(...): was_modified: False\n",
      "\tPostHocPipelineFixup.FINAL_UPDATE_ALL(...): did_any_change: False\n",
      "Pipeline loaded from custom pickle!!\n",
      "# ==================================================================================================================== #\n",
      "        # on_load_local -- COMPLETE -- \n",
      "        # ==================================================================================================================== #\n",
      "override_global_computation_results_pickle_path: \"W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\output\\global_computation_results_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 8, 9]-frateThresh_2.0.pkl\"\n",
      "included includelist is specified: ['lap_direction_determination', 'pf_computation', 'pfdt_computation', 'position_decoding', 'position_decoding_two_step', 'firing_rate_trends', 'extended_stats', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis', 'split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_train_test_split', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring', 'extended_pf_peak_information', 'perform_wcorr_shuffle_analysis', 'non_PBE_epochs_results', 'generalized_specific_epochs_decoding'], so only performing these extended computations.\n",
      "Running batch_evaluate_required_computations(...) with global_epoch_name: \"maze_any\"\n",
      "done with all batch_evaluate_required_computations(...).\n",
      "Pre-load global computations: needs_computation_output_dict: ['split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring', 'directional_train_test_split', 'long_short_decoding_analyses', 'short_long_pf_overlap_analyses', 'long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis', 'wcorr_shuffle_analysis', 'extended_pf_peak_information', 'non_PBE_epochs_results', 'generalized_specific_epochs_decoding', 'position_decoding_two_step']\n",
      "Computing loaded session pickle file results : \"W:/Data/KDIBA/gor01/one/2006-6-08_14-26-15/output/global_computation_results_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 8, 9]-frateThresh_2.0.pkl\"... done.\n",
      "sucessfully_updated_keys: ['DirectionalLaps', 'DirectionalMergedDecoders', 'RankOrder', 'DirectionalDecodersDecoded', 'DirectionalDecodersEpochsEvaluations', 'Heuristics', 'long_short_leave_one_out_decoding_analysis', 'short_long_pf_overlap_analyses', 'long_short_fr_indicies_analysis', 'jonathan_firing_rate_analysis', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups', 'long_short_endcap', 'EpochComputations']\n",
      "successfully_loaded_keys: ['DirectionalLaps', 'DirectionalMergedDecoders', 'RankOrder', 'DirectionalDecodersDecoded', 'DirectionalDecodersEpochsEvaluations', 'Heuristics', 'long_short_leave_one_out_decoding_analysis', 'short_long_pf_overlap_analyses', 'long_short_fr_indicies_analysis', 'jonathan_firing_rate_analysis', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups', 'long_short_endcap', 'EpochComputations']\n",
      "included includelist is specified: ['lap_direction_determination', 'pf_computation', 'pfdt_computation', 'position_decoding', 'position_decoding_two_step', 'firing_rate_trends', 'extended_stats', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis', 'split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_train_test_split', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring', 'extended_pf_peak_information', 'perform_wcorr_shuffle_analysis', 'non_PBE_epochs_results', 'generalized_specific_epochs_decoding'], so only performing these extended computations.\n",
      "Running batch_evaluate_required_computations(...) with global_epoch_name: \"maze_any\"\n",
      "WARNING: FIXME TODO 2024-05-08 08:20: - [ ] Disabled checking for 'combined_best_direction_indicies', which is missing from both the laps and ripple dataframes after fresh computation for some reason.\n",
      "heuristic_score_col_names: ['avg_jump_cm', 'travel', 'coverage', 'total_distance_traveled', 'track_coverage_score', 'mseq_len', 'mseq_len_ignoring_intrusions', 'mseq_len_ignoring_intrusions_and_repeats', 'mseq_len_ratio_ignoring_intrusions_and_repeats', 'mseq_tcov', 'mseq_dtrav']\n",
      "done with all batch_evaluate_required_computations(...).\n",
      "Post-load global computations: needs_computation_output_dict: ['directional_train_test_split', 'wcorr_shuffle_analysis', 'extended_pf_peak_information', 'position_decoding_two_step']\n",
      "included includelist is specified: ['lap_direction_determination', 'pf_computation', 'pfdt_computation', 'position_decoding', 'position_decoding_two_step', 'firing_rate_trends', 'extended_stats', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_inst_spike_rate_groups', 'long_short_endcap_analysis', 'split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_train_test_split', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring', 'extended_pf_peak_information', 'perform_wcorr_shuffle_analysis', 'non_PBE_epochs_results', 'generalized_specific_epochs_decoding'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze_any\"\n",
      "`position_decoding_two_step` missing.\n",
      "\t Recomputing `position_decoding_two_step`...\n",
      "===>|> for filtered_session with filter named \"maze1_odd\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_two_step_position_decoding_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function DefaultComputationFunctions._perform_two_step_position_decoding_computation at 0x000001D0C8FB7700>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function DefaultComputationFunctions._perform_two_step_position_decoding_computation at 0x000001D0C8FB7700>\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (35451,)\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze2_odd\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_two_step_position_decoding_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function DefaultComputationFunctions._perform_two_step_position_decoding_computation at 0x000001D0C8FB7700>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function DefaultComputationFunctions._perform_two_step_position_decoding_computation at 0x000001D0C8FB7700>\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (24136,)\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze_odd\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_two_step_position_decoding_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function DefaultComputationFunctions._perform_two_step_position_decoding_computation at 0x000001D0C8FB7700>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function DefaultComputationFunctions._perform_two_step_position_decoding_computation at 0x000001D0C8FB7700>\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (61102,)\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze1_even\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_two_step_position_decoding_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function DefaultComputationFunctions._perform_two_step_position_decoding_computation at 0x000001D0C8FB7700>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function DefaultComputationFunctions._perform_two_step_position_decoding_computation at 0x000001D0C8FB7700>\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (35157,)\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze2_even\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_two_step_position_decoding_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function DefaultComputationFunctions._perform_two_step_position_decoding_computation at 0x000001D0C8FB7700>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function DefaultComputationFunctions._perform_two_step_position_decoding_computation at 0x000001D0C8FB7700>\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (24317,)\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze_even\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_two_step_position_decoding_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function DefaultComputationFunctions._perform_two_step_position_decoding_computation at 0x000001D0C8FB7700>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function DefaultComputationFunctions._perform_two_step_position_decoding_computation at 0x000001D0C8FB7700>\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (61116,)\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze1_any\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_two_step_position_decoding_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function DefaultComputationFunctions._perform_two_step_position_decoding_computation at 0x000001D0C8FB7700>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function DefaultComputationFunctions._perform_two_step_position_decoding_computation at 0x000001D0C8FB7700>\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (35943,)\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze2_any\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_two_step_position_decoding_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function DefaultComputationFunctions._perform_two_step_position_decoding_computation at 0x000001D0C8FB7700>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function DefaultComputationFunctions._perform_two_step_position_decoding_computation at 0x000001D0C8FB7700>\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (24936,)\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "===>|> for filtered_session with filter named \"maze_any\": Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_perform_two_step_position_decoding_computation'])...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function DefaultComputationFunctions._perform_two_step_position_decoding_computation at 0x000001D0C8FB7700>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function DefaultComputationFunctions._perform_two_step_position_decoding_computation at 0x000001D0C8FB7700>\n",
      "two_step_decoder_result['most_likely_position_flat_max_likelihood_values'].shape = (61902,)\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "\t done.\n",
      "Exception occured while validating (`validate_computation_test(...)`) after recomputation:\n",
      " Validation exception: 'pf1D_TwoStepDecoder'\n",
      "WARNING: FIXME TODO 2024-05-08 08:20: - [ ] Disabled checking for 'combined_best_direction_indicies', which is missing from both the laps and ripple dataframes after fresh computation for some reason.\n",
      "heuristic_score_col_names: ['avg_jump_cm', 'travel', 'coverage', 'total_distance_traveled', 'track_coverage_score', 'mseq_len', 'mseq_len_ignoring_intrusions', 'mseq_len_ignoring_intrusions_and_repeats', 'mseq_len_ratio_ignoring_intrusions_and_repeats', 'mseq_tcov', 'mseq_dtrav']\n",
      "`directional_train_test_split` missing.\n",
      "\t Recomputing `directional_train_test_split`...\n",
      "for global computations: Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_split_train_test_laps_data'], ...)...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function DirectionalPlacefieldGlobalComputationFunctions._split_train_test_laps_data at 0x000001D0CA614790>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function DirectionalPlacefieldGlobalComputationFunctions._split_train_test_laps_data at 0x000001D0D39C1940>\n",
      "training_data_portion: 0.8333333333333334, test_data_portion: 0.16666666666666663\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "\t done.\n",
      "`wcorr_shuffle_analysis` missing.\n",
      "\t Recomputing `wcorr_shuffle_analysis`...\n",
      "for global computations: Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['perform_wcorr_shuffle_analysis'], ...)...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function SequenceBasedComputationsGlobalComputationFunctions.perform_wcorr_shuffle_analysis at 0x000001D0CA804820>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function SequenceBasedComputationsGlobalComputationFunctions.perform_wcorr_shuffle_analysis at 0x000001D2D726F9D0>\n",
      "WARN: perform_wcorr_shuffle_analysis(...): include_includelist: ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any'] is specified but include_includelist is currently ignored! Continuing with defaults.\n",
      "perform_wcorr_shuffle_analysis(..., num_shuffles=1024)\n",
      "len(active_epochs_df): 611\n",
      "min_num_unique_aclu_inclusions: 16\n",
      "len(active_epochs_df): 611\n",
      "min_num_unique_aclu_inclusions: 16\n",
      "heuristic_score_col_names: ['avg_jump_cm', 'travel', 'coverage', 'total_distance_traveled', 'track_coverage_score', 'mseq_len', 'mseq_len_ignoring_intrusions', 'mseq_len_ignoring_intrusions_and_repeats', 'mseq_len_ratio_ignoring_intrusions_and_repeats', 'mseq_tcov', 'mseq_dtrav']\n",
      "\tbuild_complete_all_scores_merged_df(...): Encountered ERROR: 'score_long_LR' while trying to add \"a_score_col\": score, but trying to continue, so close!\n",
      "real_decoder_ripple_weighted_corr_arr: (317, 4)\n",
      "n_prev_completed_shuffles: 0.\n",
      "needed num_shuffles: 1024.\n",
      "need desired_new_num_shuffles: 1024 more shuffles.\n",
      "a_shuffle_IDXs: [45 10 67 39 76 66 42 59 13 47 36 29 52 71 57  1  2  4 32 70 54 62 49 22 26  3  5 17  6 73 69 74 14 51 20 15 63 34 61 27  0  8 50 38 25 53 46 77 65 40 23 33 12 68 19 75 64 37 11 41 72 58 21 28 60 55  9 48 30 44 31  7 35 18 43 16 56 24], a_shuffle_aclus: [ 62  14  90  56 108  89  59  81  17  64  53  41  70  97  76   3   4   7  49  96  73  84  67  31  35   5   8  24   9 100  93 102  19  69  27  21  85  51  83  36   2  11  68  55  34  71  63 109  88  57  32  50  16  92  26 107  86  54  15  58  98  78  28  37  82  74  13  66  45  61  48  10  52  25  60  23  75  33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [32 41 18 56 21  6 61 74 69 27 50 36 57  3 67 23 13 15  0 65 76 37 43 46 63 47 25 35 71 40 24 59 11 10  7 55 68 45 58 54 12 44 26 60 48 66 28 42 75 62  5 29 17 19 22 34 33 30  4 31 53  9  1 20 73 16 64  8 77 51 14  2 72 49 39 52 70 38], a_shuffle_aclus: [ 49  58  25  75  28   9  83 102  93  36  68  53  76   5  90  32  17  21   2  88 108  54  60  63  85  64  34  52  97  57  33  81  15  14  10  74  92  62  78  73  16  61  35  82  66  89  37  59 107  84   8  41  24  26  31  51  50  45   7  48  71  13   3  27 100  23  86  11 109  69  19   4  98  67  56  70  96  55]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [68 33 36 15  6  5 61 59 53 67  2 46 12  9 19 10 25 11 26 27 55 23  8  0 74 31 65 62 17 49 77 30 28  3 39  4 75 32 38 20 43 64 18 40 34 35 54 57 41 66 72 16 37 21 48 13 51 58 45 24 76 60 47 71 52 22 50  7  1 29 14 70 42 73 69 63 44 56], a_shuffle_aclus: [ 92  50  53  21   9   8  83  81  71  90   4  63  16  13  26  14  34  15  35  36  74  32  11   2 102  48  88  84  24  67 109  45  37   5  56   7 107  49  55  27  60  86  25  57  51  52  73  76  58  89  98  23  54  28  66  17  69  78  62  33 108  82  64  97  70  31  68  10   3  41  19  96  59 100  93  85  61  75]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [23 59 19 34 16 26  2 46 40  6 56 39 76 28 30  0 12 54 53 48 68 31 47  4 51 73 70 17 60 63 11 61 55 66 13  9 50 77 27 25 29 71 37  8 38 32 15 41 67 62  3 74 42 65 49 18 57 43 24  5 35 58 10  1 64 20 52 33 36 44 75  7 72 69 21 45 22 14], a_shuffle_aclus: [ 32  81  26  51  23  35   4  63  57   9  75  56 108  37  45   2  16  73  71  66  92  48  64   7  69 100  96  24  82  85  15  83  74  89  17  13  68 109  36  34  41  97  54  11  55  49  21  58  90  84   5 102  59  88  67  25  76  60  33   8  52  78  14   3  86  27  70  50  53  61 107  10  98  93  28  62  31  19]\n",
      "a_shuffle_IDXs: [48 73 11 70 30 17 14 47 77 56 41 24 63 32 55 19  4 54 62  2 12 69 64 20 65  9 18 21 68  8 60 31 40 13 33 52 27 61  5 59 37 22 49 46  3 44 72 16 38 58  0 26 53  6 43 75 50 76 74 28 57 71 35 45 66 23 34 25 15 51 36 29 39  1  7 10 42 67], a_shuffle_aclus: [ 66 100  15  96  45  24  19  64 109  75  58  33  85  49  74  26   7  73  84   4  16  93  86  27  88  13  25  28  92  11  82  48  57  17  50  70  36  83   8  81  54  31  67  63   5  61  98  23  55  78   2  35  71   9  60 107  68 108 102  37  76  97  52  62  89  32  51  34  21  69  53  41  56   3  10  14  59  90]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [23 19 22 37 62 50 61 42 69 60  5 77  0 70 71 63 47 59 28  4 66 12 27 11 48  9 54  3 26 16 72 25  6 76 33 21 29 34  1 68 43 49 38 65 15 32 30  8 14 67 58 75 31 73 41 18 55 44 17 20 39 51 56 52 24 36 45 57  2 64 13 46 53  7 10 74 35 40], a_shuffle_aclus: [ 32  26  31  54  84  68  83  59  93  82   8 109   2  96  97  85  64  81  37   7  89  16  36  15  66  13  73   5  35  23  98  34   9 108  50  28  41  51   3  92  60  67  55  88  21  49  45  11  19  90  78 107  48 100  58  25  74  61  24  27  56  69  75  70  33  53  62  76   4  86  17  63  71  10  14 102  52  57]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 2 70 51 43 73 30 25 39 27 22 56 18 40 60 31 52 46  4 72 23  8 13 63 59 37  1 33 16 47 11 19 55 64 71 49 65 76 12 14 42 74 38  5 10  7 54 20 29 15 48 69 45 62 66 21 68 58 67 24 34 53  3 26 57  9  6 41 32 75 35 61 77 50  0 28 17 36 44], a_shuffle_aclus: [  4  96  69  60 100  45  34  56  36  31  75  25  57  82  48  70  63   7  98  32  11  17  85  81  54   3  50  23  64  15  26  74  86  97  67  88 108  16  19  59 102  55   8  14  10  73  27  41  21  66  93  62  84  89  28  92  78  90  33  51  71   5  35  76  13   9  58  49 107  52  83 109  68   2  37  24  53  61]\n",
      "a_shuffle_IDXs: [39 76 38 72 25 66 53 10 52 62 50 22 63 49 31 48  4 58 51 11 13 45 27  2 30 43 54 40 65  6 35 24 29 19 37 21 55 56 75 36 33 71 64 12 28 41 67 17 46 68 69 23 74 16 70 57  8 44 73 14 32 20 42 34 61 47  5  0 15  9 77  3 59 26 60  7  1 18], a_shuffle_aclus: [ 56 108  55  98  34  89  71  14  70  84  68  31  85  67  48  66   7  78  69  15  17  62  36   4  45  60  73  57  88   9  52  33  41  26  54  28  74  75 107  53  50  97  86  16  37  58  90  24  63  92  93  32 102  23  96  76  11  61 100  19  49  27  59  51  83  64   8   2  21  13 109   5  81  35  82  10   3  25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [32 23  7 36 28 48 16 34 46  0 65 58 40  9 22 21 49 41 54 68 18 56 60 20 15 19 35 50 27 74 25 45 31 10 57 33 62 61 51  8 69  5 11 42 29 64  6 55 30 77 76  3 14 75 12 72 13 63 73 24 26 38 66 43 67 17 37 39 70 47 44  4 59  2  1 52 53 71], a_shuffle_aclus: [ 49  32  10  53  37  66  23  51  63   2  88  78  57  13  31  28  67  58  73  92  25  75  82  27  21  26  52  68  36 102  34  62  48  14  76  50  84  83  69  11  93   8  15  59  41  86   9  74  45 109 108   5  19 107  16  98  17  85 100  33  35  55  89  60  90  24  54  56  96  64  61   7  81   4   3  70  71  97]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [34 70 37 51  4 73 57  5 62 67 41 18 56 38 63 17 31 25 21 45 16 33 43  3  9 48 54 12 10 65 27 58 69 13 26 44 28 53 76 77 49 61 72 19 50 52 42 22 36 32  6 60 74 66 68  2 39 30 64 40 24  8 71 47  0 20 15 29 75  7 46  1 55 11 14 23 35 59], a_shuffle_aclus: [ 51  96  54  69   7 100  76   8  84  90  58  25  75  55  85  24  48  34  28  62  23  50  60   5  13  66  73  16  14  88  36  78  93  17  35  61  37  71 108 109  67  83  98  26  68  70  59  31  53  49   9  82 102  89  92   4  56  45  86  57  33  11  97  64   2  27  21  41 107  10  63   3  74  15  19  32  52  81]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [66 38 22 34 65 53 73 75 19 62 15 61 28 24 72  9 37  7 43 55  0  5 74  4 11 20 48 47 52 67 54 31 27 45 21  1  8 57 16 63 64 70 30 59 23  6 56 29 32 76 13 46 10 49 18 51 60 69 44 50 77 35 14 39 40 25  3 41 26 36 58 71 68 17  2 12 33 42], a_shuffle_aclus: [ 89  55  31  51  88  71 100 107  26  84  21  83  37  33  98  13  54  10  60  74   2   8 102   7  15  27  66  64  70  90  73  48  36  62  28   3  11  76  23  85  86  96  45  81  32   9  75  41  49 108  17  63  14  67  25  69  82  93  61  68 109  52  19  56  57  34   5  58  35  53  78  97  92  24   4  16  50  59]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [13 40  2 38  6 62 33 15 36 65 74 43 26 64 34 61 10 52 56  3 48 68 39 69 77 27 70 35 44 19 53 57  0 49 75 22 20 14 31  4 30 46  1 25  7 18 41 58  5 47 67 28 54 76 37 60  8 50 63 59 71  9 11 55 42 72 17 29 32 66 16 21 51 45 23 12 73 24], a_shuffle_aclus: [ 17  57   4  55   9  84  50  21  53  88 102  60  35  86  51  83  14  70  75   5  66  92  56  93 109  36  96  52  61  26  71  76   2  67 107  31  27  19  48   7  45  63   3  34  10  25  58  78   8  64  90  37  73 108  54  82  11  68  85  81  97  13  15  74  59  98  24  41  49  89  23  28  69  62  32  16 100  33]\n",
      "a_shuffle_IDXs: [27 40 32  5  7 75 48 26 59 65 17 28 25 76 29 13 41 71 68 74 47  9 51 14 67 72 36 34 11 77 23 60 37 66 24 18 49 56  1 55 54 62 33  4 31 20  2 63 22 52 64 12 30 39 38 61 70 57 73 43 50 35 42 21 15  0  6  3 69 46 10 16  8 45 58 53 19 44], a_shuffle_aclus: [ 36  57  49   8  10 107  66  35  81  88  24  37  34 108  41  17  58  97  92 102  64  13  69  19  90  98  53  51  15 109  32  82  54  89  33  25  67  75   3  74  73  84  50   7  48  27   4  85  31  70  86  16  45  56  55  83  96  76 100  60  68  52  59  28  21   2   9   5  93  63  14  23  11  62  78  71  26  61]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [36 73  8  7 62 49 46 47 30 57 66 77 29 61 18 45 38 10 11  9 48  3 58 15  1 41 21 28 34  2 67 20  5 43 19 24 32 37 42 63 23 25 60 39 54 56 26 12  4 52 72 40 75 27 35 65 71 50  0 31 64 17 22 76 51 14 59 33 69 16 55 13  6 74 68 70 53 44], a_shuffle_aclus: [ 53 100  11  10  84  67  63  64  45  76  89 109  41  83  25  62  55  14  15  13  66   5  78  21   3  58  28  37  51   4  90  27   8  60  26  33  49  54  59  85  32  34  82  56  73  75  35  16   7  70  98  57 107  36  52  88  97  68   2  48  86  24  31 108  69  19  81  50  93  23  74  17   9 102  92  96  71  61]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [32 31  4 37 33 16 11 58 59 24 10 36 43 26 65 12 56 34 14 19 53  6 30 42 52  0 48 45 35 25 62 60  1 40 17 68  7 18 74 71 61  8 72 77 50 69 23 67 49 57 15 75 20 51 54 39 63  3  5 47 27 21 13 22  9 66 70 29 44 76 73 46  2 55 28 38 64 41], a_shuffle_aclus: [ 49  48   7  54  50  23  15  78  81  33  14  53  60  35  88  16  75  51  19  26  71   9  45  59  70   2  66  62  52  34  84  82   3  57  24  92  10  25 102  97  83  11  98 109  68  93  32  90  67  76  21 107  27  69  73  56  85   5   8  64  36  28  17  31  13  89  96  41  61 108 100  63   4  74  37  55  86  58]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [65  4 33 53 24 67  6 21 18  5 58 66 73 76 57 38 12 19  3 69 74  7 11 16 50 42 34 56 63 47 72 54 46 13 28 15 61 14 64 37  2 17  9 39  0  1 45 71 25 55 59 27 23 41 22 49 36 60 32 26 31 10 44  8 35 51 29 43 68 77 70 30 52 48 75 62 20 40], a_shuffle_aclus: [ 88   7  50  71  33  90   9  28  25   8  78  89 100 108  76  55  16  26   5  93 102  10  15  23  68  59  51  75  85  64  98  73  63  17  37  21  83  19  86  54   4  24  13  56   2   3  62  97  34  74  81  36  32  58  31  67  53  82  49  35  48  14  61  11  52  69  41  60  92 109  96  45  70  66 107  84  27  57]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [33 69 19 42 17 11 49  3 38 62 65 57 36 14  9 31 50 32 23 10 51 15 18 41 48 64 66 27 29 12 52 39 53  1 47 13 70 25 21 34 16 73 76 24 59 74  2 72 43 61  0 20 77 26 58 35 45 30 22 56 55  8 75 40 28  4 68 46  5 37  7 67 44 60 71  6 54 63], a_shuffle_aclus: [ 50  93  26  59  24  15  67   5  55  84  88  76  53  19  13  48  68  49  32  14  69  21  25  58  66  86  89  36  41  16  70  56  71   3  64  17  96  34  28  51  23 100 108  33  81 102   4  98  60  83   2  27 109  35  78  52  62  45  31  75  74  11 107  57  37   7  92  63   8  54  10  90  61  82  97   9  73  85]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [75 68 65 45 53 14 49 59 29 37 16 52 73 66  9 54 69 36 76 74 24 31 21  0 12 50 38  2  8 64 42  1 51 22 43 26 17  5 47 61 62  3  7 18 48  4 70 60 41 33 40 19 39 28 77 34 23 13 63 25 56 55 72 27 57 35 44 46 20 32 11 71 67 58  6 30 10 15], a_shuffle_aclus: [107  92  88  62  71  19  67  81  41  54  23  70 100  89  13  73  93  53 108 102  33  48  28   2  16  68  55   4  11  86  59   3  69  31  60  35  24   8  64  83  84   5  10  25  66   7  96  82  58  50  57  26  56  37 109  51  32  17  85  34  75  74  98  36  76  52  61  63  27  49  15  97  90  78   9  45  14  21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [20  4 17 71 19  0 66 55 77 49 73 74 69 72 36 13 70 21 16 28 26 47 57 31 42 51 56 76 41 59  7 24  3 14 18  1 29 32 53 22 63 33 64 39 62 75  9 34  5 52 65 68 58 10 27 37  8 60 25 12  6 40 45 11 67 44 46 50 43 15 30 54  2 38 23 48 35 61], a_shuffle_aclus: [ 27   7  24  97  26   2  89  74 109  67 100 102  93  98  53  17  96  28  23  37  35  64  76  48  59  69  75 108  58  81  10  33   5  19  25   3  41  49  71  31  85  50  86  56  84 107  13  51   8  70  88  92  78  14  36  54  11  82  34  16   9  57  62  15  90  61  63  68  60  21  45  73   4  55  32  66  52  83]\n",
      "a_shuffle_IDXs: [46 64  1 31 48 65 67 66 21 75 32 26 44 38 39 22 27 29 50 68 42 41 35 54 45 62 52 57  3  2 11  6 69 12 43 13 10 77 76 18 59 72 58 16 60 63 33 71 25  9 17  0  8 14 51 53 70 23 36 30 49 24 37 56 74 20 73 55 34 19 15  7 61 28  4 40  5 47], a_shuffle_aclus: [ 63  86   3  48  66  88  90  89  28 107  49  35  61  55  56  31  36  41  68  92  59  58  52  73  62  84  70  76   5   4  15   9  93  16  60  17  14 109 108  25  81  98  78  23  82  85  50  97  34  13  24   2  11  19  69  71  96  32  53  45  67  33  54  75 102  27 100  74  51  26  21  10  83  37   7  57   8  64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [69 35 70 61 20 45 74 65 25 11 67  4 71 23 13 60 66 56 40 55 52 73 77 42 10 18 44 29 14 37 28 17 41 64 58 76 30 16 43 51 57 33  7 38 72  2 54 49 68 53 34  9 59 39 24 32 50 46 63  6 48  8 75  5 36 21  1 22 62  3 15 26 12 47 19 31  0 27], a_shuffle_aclus: [ 93  52  96  83  27  62 102  88  34  15  90   7  97  32  17  82  89  75  57  74  70 100 109  59  14  25  61  41  19  54  37  24  58  86  78 108  45  23  60  69  76  50  10  55  98   4  73  67  92  71  51  13  81  56  33  49  68  63  85   9  66  11 107   8  53  28   3  31  84   5  21  35  16  64  26  48   2  36]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [73 31 12 77 17  7 27 52 68 61 59 26 11 18 42 43 32  6 10 30  2 20 23 39  1 70 44 25  0 65 53 54 75 56 55 41 40 46  3 66 24 33 72 48 36 16 69 49  4  8 58 34 74 67 63  9 57  5 51 45 19 28 60 14 64 71 76 47 50 62 21 15 35 13 29 38 22 37], a_shuffle_aclus: [100  48  16 109  24  10  36  70  92  83  81  35  15  25  59  60  49   9  14  45   4  27  32  56   3  96  61  34   2  88  71  73 107  75  74  58  57  63   5  89  33  50  98  66  53  23  93  67   7  11  78  51 102  90  85  13  76   8  69  62  26  37  82  19  86  97 108  64  68  84  28  21  52  17  41  55  31  54]\n",
      "a_shuffle_IDXs: [39 70 56 67 75 10 32 34 33 60 22 46 26 29 31 40 48 77 37 25 71 20  1 61  3 64 55 73 16 58  6  5 62 12 17 18 15 35 76 51 13 19 63  2 68 23 49 41 74 24 30  8 52 72 69 42 14 36 59 45  0 43 11 28 53 54  7 47 66 38 27  9 57 44  4 65 50 21], a_shuffle_aclus: [ 56  96  75  90 107  14  49  51  50  82  31  63  35  41  48  57  66 109  54  34  97  27   3  83   5  86  74 100  23  78   9   8  84  16  24  25  21  52 108  69  17  26  85   4  92  32  67  58 102  33  45  11  70  98  93  59  19  53  81  62   2  60  15  37  71  73  10  64  89  55  36  13  76  61   7  88  68  28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [68 32 63 49 11  9  6 44 52 28 54 73 47 40 20 16 25 41 51 42 64 67  7 23 22 75 53 62 14 26 71 29 48 59 74 65 39 17  1 61 38  2 43 57 15  0 60 10 27 50  5 56 46 19 13 70 35 21 12 77 69 37 45 66 58 18 55  3  4 72 34  8 33 36 24 31 76 30], a_shuffle_aclus: [ 92  49  85  67  15  13   9  61  70  37  73 100  64  57  27  23  34  58  69  59  86  90  10  32  31 107  71  84  19  35  97  41  66  81 102  88  56  24   3  83  55   4  60  76  21   2  82  14  36  68   8  75  63  26  17  96  52  28  16 109  93  54  62  89  78  25  74   5   7  98  51  11  50  53  33  48 108  45]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [53 33 55 15 52 20 19 75 46 62 16 13 47  0 36 73 58 14  5  4 63 66 59 21 71 54 28 67 72  3 11 29 44 68 22 50  1  7 26 17 77 35 45 64  6 61 18 51  9 27 42 31 37 39 12 69 70 76 23 74 48 49 10 43 32 25  8 40 38 56 30 24 65  2 60 57 41 34], a_shuffle_aclus: [ 71  50  74  21  70  27  26 107  63  84  23  17  64   2  53 100  78  19   8   7  85  89  81  28  97  73  37  90  98   5  15  41  61  92  31  68   3  10  35  24 109  52  62  86   9  83  25  69  13  36  59  48  54  56  16  93  96 108  32 102  66  67  14  60  49  34  11  57  55  75  45  33  88   4  82  76  58  51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [42 31 50 16 53 29 45 37 59 70 64  1 27 33 73 20 49 22 40 19 54 75 13  0 58 24 10 47 77  4 26 65 62 18 60 69 61 12 34 21 56 28 30 14  7 51 41  2 23 63  8 38 55 17 71 57 46  6 76 67 43 72  5 48 11 39 66 32 52 44 15 68 74  3 36 35 25  9], a_shuffle_aclus: [ 59  48  68  23  71  41  62  54  81  96  86   3  36  50 100  27  67  31  57  26  73 107  17   2  78  33  14  64 109   7  35  88  84  25  82  93  83  16  51  28  75  37  45  19  10  69  58   4  32  85  11  55  74  24  97  76  63   9 108  90  60  98   8  66  15  56  89  49  70  61  21  92 102   5  53  52  34  13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [46  5 26 65 35 74 49 42 71 51 18 10 67 61  2 39 56  0 38 45 37 43  1 50 48 23  3 59 24 70 16 32 11  7 53 62 77 57 13 68  4  8 36 22 58 12 30 73 25 72 76 28 55 44 41  9 31  6 29 14 40 33 54 21 15 20 63 34 69 75 17 66 19 52 64 60 27 47], a_shuffle_aclus: [ 63   8  35  88  52 102  67  59  97  69  25  14  90  83   4  56  75   2  55  62  54  60   3  68  66  32   5  81  33  96  23  49  15  10  71  84 109  76  17  92   7  11  53  31  78  16  45 100  34  98 108  37  74  61  58  13  48   9  41  19  57  50  73  28  21  27  85  51  93 107  24  89  26  70  86  82  36  64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [10 53  8 33 49  1 59 24 58 66 75 19 69  0 21 37 34 22 52 30 25 11 71 48 18 44 35 46 43 61 29 70 12 57 23 55 47 16 17 63 72  4 77  3 60 56  9 27 67 15 76 13 36 14  7 50 68 39 32 73  2 31 45 74 26 51 41 64 28 42 65 38 40 54 20  5 62  6], a_shuffle_aclus: [ 14  71  11  50  67   3  81  33  78  89 107  26  93   2  28  54  51  31  70  45  34  15  97  66  25  61  52  63  60  83  41  96  16  76  32  74  64  23  24  85  98   7 109   5  82  75  13  36  90  21 108  17  53  19  10  68  92  56  49 100   4  48  62 102  35  69  58  86  37  59  88  55  57  73  27   8  84   9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [50  4 40 48 65 43 72  8 29 10  9 46 22 62 11 25 67 27 61 60 23  6 12 39 36 30 75 53 58 31 14 76 44 56 34  7 21 20 47 69 52 16 55  2 38 19 45 54 32 35  5 59 51 63 77 66 17 24 49 70 42 57  3 37 73  1 13 74 33 71 15 28 26 68 41 18  0 64], a_shuffle_aclus: [ 68   7  57  66  88  60  98  11  41  14  13  63  31  84  15  34  90  36  83  82  32   9  16  56  53  45 107  71  78  48  19 108  61  75  51  10  28  27  64  93  70  23  74   4  55  26  62  73  49  52   8  81  69  85 109  89  24  33  67  96  59  76   5  54 100   3  17 102  50  97  21  37  35  92  58  25   2  86]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [45 52 38  4 21 49 19 48 54  5 55 69  9  8 60  2 56 25 63 68 50 39 13 77 64 74 66 12 47 24 10 15 72  7 58 62 27 41 11 61 76 31 29 71 75 70 30 26 22 14 34  3  0 44 28 67 16 32 42 20 35  6 43 17 53 23 18 73 65 57 37 40 46 59 36  1 51 33], a_shuffle_aclus: [ 62  70  55   7  28  67  26  66  73   8  74  93  13  11  82   4  75  34  85  92  68  56  17 109  86 102  89  16  64  33  14  21  98  10  78  84  36  58  15  83 108  48  41  97 107  96  45  35  31  19  51   5   2  61  37  90  23  49  59  27  52   9  60  24  71  32  25 100  88  76  54  57  63  81  53   3  69  50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [75 62 39 70 48  3 53  2 18 57 41  0 76 28 23 29 27 10 61 12 35 47 45 40 44 25 32 38 56 66 21 15 68  8 46 26 36 24 16  5 67 69 20 52 65 34 19 63 74 64 11 77 49 33 30 72 42  6 13 37 58  7 43 54 73 55  9 59 31  4 17 14 51 60 71  1 50 22], a_shuffle_aclus: [107  84  56  96  66   5  71   4  25  76  58   2 108  37  32  41  36  14  83  16  52  64  62  57  61  34  49  55  75  89  28  21  92  11  63  35  53  33  23   8  90  93  27  70  88  51  26  85 102  86  15 109  67  50  45  98  59   9  17  54  78  10  60  73 100  74  13  81  48   7  24  19  69  82  97   3  68  31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [36 55  3 35 58 54 68 42 56 62 12 49 33 71 10 14  9 50 23  1 39 18 38 63 77 60 67 16 47 74 52 45 17 28 27 48 30  0 21 25  4 13 24 34 44 11 43 61 46  7 19 65 53 51 15 57 73 41 59 32 64 76 75 20 70 66  8  2 22 40  5  6 37 29 69 31 72 26], a_shuffle_aclus: [ 53  74   5  52  78  73  92  59  75  84  16  67  50  97  14  19  13  68  32   3  56  25  55  85 109  82  90  23  64 102  70  62  24  37  36  66  45   2  28  34   7  17  33  51  61  15  60  83  63  10  26  88  71  69  21  76 100  58  81  49  86 108 107  27  96  89  11   4  31  57   8   9  54  41  93  48  98  35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [42 30 36 62 40 45 75 19 20  5 73 10  1 35  3 66 44 32 27 25 41 37 51 15 29 59 33 67 49 13 14 23 43 70 47 28 39 18 72 16 24 31 26 71 60 68 55  4 46 48 56  0 50 12  9 76 54  8 52 77  7 11 57 53 21 22 34  2 63 61  6 69 64 74 38 65 17 58], a_shuffle_aclus: [ 59  45  53  84  57  62 107  26  27   8 100  14   3  52   5  89  61  49  36  34  58  54  69  21  41  81  50  90  67  17  19  32  60  96  64  37  56  25  98  23  33  48  35  97  82  92  74   7  63  66  75   2  68  16  13 108  73  11  70 109  10  15  76  71  28  31  51   4  85  83   9  93  86 102  55  88  24  78]\n",
      "a_shuffle_IDXs: [71 57 64 29 16 40  6  5 18 73 66 13  9 53 31 12 34 47 11 60 67 27 33 36 39 48 72 56 69 19 22 15 25  1 75 37 76  8 17  4 23 70 49 65  2 32 43 20 21 55 54 63 44 45 26  0  3 51 58 10 38 28 14  7 41 50 46 42 30 35 77 62 61 24 74 59 68 52], a_shuffle_aclus: [ 97  76  86  41  23  57   9   8  25 100  89  17  13  71  48  16  51  64  15  82  90  36  50  53  56  66  98  75  93  26  31  21  34   3 107  54 108  11  24   7  32  96  67  88   4  49  60  27  28  74  73  85  61  62  35   2   5  69  78  14  55  37  19  10  58  68  63  59  45  52 109  84  83  33 102  81  92  70]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [18 39 34 24 43 77 25 11 72 17 36 41 32 20 47 38 46  7  1 12 51  3 66 23 30 10 70 49 61 65 69 76 56  9 16  8 74 60 68 63  5 54 28 44 27 57 13 31  0 19 67 45 64 73  2 15 55 21 50 42 75 62 37 33 58 52 53 48  6 59 71 35 26  4 40 29 14 22], a_shuffle_aclus: [ 25  56  51  33  60 109  34  15  98  24  53  58  49  27  64  55  63  10   3  16  69   5  89  32  45  14  96  67  83  88  93 108  75  13  23  11 102  82  92  85   8  73  37  61  36  76  17  48   2  26  90  62  86 100   4  21  74  28  68  59 107  84  54  50  78  70  71  66   9  81  97  52  35   7  57  41  19  31]\n",
      "a_shuffle_IDXs: [57 39 35 13 24 77 17 69 14 44 58 37 32 16 23 66 42  9 11 56 26 74 67 70 52 76 75 22  8 51 49 18 53  6 45 61 48 29 31 10 15 55 20 62 65 21 72 46 33 34 73 64 60 40 47 30 43  1 28  2  4 68 27 50 54 36 63  5 19 59 38 71  7  0 25 12  3 41], a_shuffle_aclus: [ 76  56  52  17  33 109  24  93  19  61  78  54  49  23  32  89  59  13  15  75  35 102  90  96  70 108 107  31  11  69  67  25  71   9  62  83  66  41  48  14  21  74  27  84  88  28  98  63  50  51 100  86  82  57  64  45  60   3  37   4   7  92  36  68  73  53  85   8  26  81  55  97  10   2  34  16   5  58]\n",
      "a_shuffle_IDXs: [55 45 54  2 62 48 28 26 13 60 65  6 21 58 52 71 18 30 14 46 70 56 69 41 49 47 42 44 51 76 77 25 39 22 74 43 27 17 32 11 33 73 61 19 64  0 63  5 24 35 40 29 37 16 57 10  1 68 20 15 38 12 53  3 50 31 34 67  7  4 75 66 36 72  8 59 23  9], a_shuffle_aclus: [ 74  62  73   4  84  66  37  35  17  82  88   9  28  78  70  97  25  45  19  63  96  75  93  58  67  64  59  61  69 108 109  34  56  31 102  60  36  24  49  15  50 100  83  26  86   2  85   8  33  52  57  41  54  23  76  14   3  92  27  21  55  16  71   5  68  48  51  90  10   7 107  89  53  98  11  81  32  13]\n",
      "a_shuffle_IDXs: [ 4 21 72 54 51 43 58  5 37 70 41 66 18  8  2 57 30 74 20 27 71 19 31 10 12 24 75  9 50 47 61 44  1  6 39 65 60 68 33 53 13 16 32 48 69 38  0 49 17 76 67 29 73 15 77 55 64 23 25 52 62 46  3 22 28 34 35  7 45 56 42 63 59 26 14 36 40 11], a_shuffle_aclus: [  7  28  98  73  69  60  78   8  54  96  58  89  25  11   4  76  45 102  27  36  97  26  48  14  16  33 107  13  68  64  83  61   3   9  56  88  82  92  50  71  17  23  49  66  93  55   2  67  24 108  90  41 100  21 109  74  86  32  34  70  84  63   5  31  37  51  52  10  62  75  59  85  81  35  19  53  57  15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 3 33 72 63 28 61 74 41 16 60 62 38 64 25 76 40  7 34 11 20 15 48 12 24 44 46  6 37 73  4 77 68 55 45 54 70 35 29 36 21 71 53 30 57  2 22  5 51 52  0 10 23 69 13 56  8 75 39 19 67  1 47 42 49 26 17 59 14  9 31 58 18 66 27 32 43 50 65], a_shuffle_aclus: [  5  50  98  85  37  83 102  58  23  82  84  55  86  34 108  57  10  51  15  27  21  66  16  33  61  63   9  54 100   7 109  92  74  62  73  96  52  41  53  28  97  71  45  76   4  31   8  69  70   2  14  32  93  17  75  11 107  56  26  90   3  64  59  67  35  24  81  19  13  48  78  25  89  36  49  60  68  88]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [32 69 72 36 71 68  6 70 30 53 54 45 57  9 15 47 59 73 10 13 27 67 29  1 11 35 74  2  0 39 20 19 63 61 65 42 55 12 17 24  7 62 44 25 77 75 58 64 43 46 14 26 76 38 52 28 50 16 21 33 37 60 48 23  5 41 18 22  4 66 49 56 40  8  3 51 34 31], a_shuffle_aclus: [ 49  93  98  53  97  92   9  96  45  71  73  62  76  13  21  64  81 100  14  17  36  90  41   3  15  52 102   4   2  56  27  26  85  83  88  59  74  16  24  33  10  84  61  34 109 107  78  86  60  63  19  35 108  55  70  37  68  23  28  50  54  82  66  32   8  58  25  31   7  89  67  75  57  11   5  69  51  48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [20 15 47 64 50  0 52 18 54  8  2 66 70 40 17 44 69 36 14 60 32 37 41  4 77 34 55 45 21 28 31 27 58  7 71 42 59 49 30 23  9 67 10 68  6 29 13 19 76 33 35 48 53 63 11 24 61 72 74  5 73 39 57 43 26 46  3  1 75 56 62 25 22 12 65 16 38 51], a_shuffle_aclus: [ 27  21  64  86  68   2  70  25  73  11   4  89  96  57  24  61  93  53  19  82  49  54  58   7 109  51  74  62  28  37  48  36  78  10  97  59  81  67  45  32  13  90  14  92   9  41  17  26 108  50  52  66  71  85  15  33  83  98 102   8 100  56  76  60  35  63   5   3 107  75  84  34  31  16  88  23  55  69]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [66 26 53 10 15 63 55 54 73 12  9 17 62  7 23 30 19 47 60 11 74 14 21 75 39 13 28 22 70  8 24 43 48 44 68 56 33 40 61 45 72 36 77 38 49 27 20 29 18  0 34 35 37 51 52  4 50 76 41 25 31 58 69  2 71 32 65 42 64 57  3 46 59  6  1  5 67 16], a_shuffle_aclus: [ 89  35  71  14  21  85  74  73 100  16  13  24  84  10  32  45  26  64  82  15 102  19  28 107  56  17  37  31  96  11  33  60  66  61  92  75  50  57  83  62  98  53 109  55  67  36  27  41  25   2  51  52  54  69  70   7  68 108  58  34  48  78  93   4  97  49  88  59  86  76   5  63  81   9   3   8  90  23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [72 21 29 43 46  1 62  0 36  8 55 77 65 26  9 67 44  7 74 40 22 11 20 48  4 69 38 58 68 25 64 28 19 61 23 33  5 73 34 17 16 50 66 70  3 52 35 42 14  6 47 41 15 76  2 31 54 59 13 10 32 30 60 63 56 39 27 45 75 57 12 24 49 53 18 37 51 71], a_shuffle_aclus: [ 98  28  41  60  63   3  84   2  53  11  74 109  88  35  13  90  61  10 102  57  31  15  27  66   7  93  55  78  92  34  86  37  26  83  32  50   8 100  51  24  23  68  89  96   5  70  52  59  19   9  64  58  21 108   4  48  73  81  17  14  49  45  82  85  75  56  36  62 107  76  16  33  67  71  25  54  69  97]\n",
      "a_shuffle_IDXs: [68 76 54 49 16 14  3 23 64 55 52 17 69 30  9 39 74 63 46 77 42 29 11 72 62 50  8  1  6 70 43 56 32 28 61 18 60 25 65 20 10 40 15 53 67  2 26 58 22 47 35 24 34 75  4 45 66 44  7 36  5 41 48 21  0 12 57 38 73 31 71 19 59 33 51 37 13 27], a_shuffle_aclus: [ 92 108  73  67  23  19   5  32  86  74  70  24  93  45  13  56 102  85  63 109  59  41  15  98  84  68  11   3   9  96  60  75  49  37  83  25  82  34  88  27  14  57  21  71  90   4  35  78  31  64  52  33  51 107   7  62  89  61  10  53   8  58  66  28   2  16  76  55 100  48  97  26  81  50  69  54  17  36]\n",
      "a_shuffle_IDXs: [37 48 14 40 53  7 70 57 18 13 27  4  8 12 56 75 24 16 35  3 32 20 66 71 50  5  0 55 10 21 42 76 59 54 38 58 45 46 69 39 19 30  9 29  6 67 62 73 49 26 47  2 52 72 33  1 22 28 60 51 17 43 36 44 61 11 77 34 64 68 25 41 63 74 23 31 15 65], a_shuffle_aclus: [ 54  66  19  57  71  10  96  76  25  17  36   7  11  16  75 107  33  23  52   5  49  27  89  97  68   8   2  74  14  28  59 108  81  73  55  78  62  63  93  56  26  45  13  41   9  90  84 100  67  35  64   4  70  98  50   3  31  37  82  69  24  60  53  61  83  15 109  51  86  92  34  58  85 102  32  48  21  88]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [23 19 11 73 51  2 14 70 60 32 10 43  4 65 46 69 77  8 54 67  9 76 31 39 41 75  6  5 38 59 37 58  0 35 42 45 34  7 13 57 22 17 74 52 30 25 40 27 24 20 61 36 66 26  1 16 53 50 18 71  3 62 33 21 12 47 64 55 72 29 28 63 48 68 49 44 15 56], a_shuffle_aclus: [ 32  26  15 100  69   4  19  96  82  49  14  60   7  88  63  93 109  11  73  90  13 108  48  56  58 107   9   8  55  81  54  78   2  52  59  62  51  10  17  76  31  24 102  70  45  34  57  36  33  27  83  53  89  35   3  23  71  68  25  97   5  84  50  28  16  64  86  74  98  41  37  85  66  92  67  61  21  75]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [52 12 41 14 51 71 75 29 72 58 69 76 59  8 25 34 37  6  0 50 36  1  4 42 57 18 45 73 77  7 64  3 47 61 38 23 32 43 13 74 19 68 63 35 44 67 54 53  2 10 62  5 65 49 15 33 39 20 17 21 24 48 40 30 27 60 31 11 26  9 66 22 56 28 55 70 16 46], a_shuffle_aclus: [ 70  16  58  19  69  97 107  41  98  78  93 108  81  11  34  51  54   9   2  68  53   3   7  59  76  25  62 100 109  10  86   5  64  83  55  32  49  60  17 102  26  92  85  52  61  90  73  71   4  14  84   8  88  67  21  50  56  27  24  28  33  66  57  45  36  82  48  15  35  13  89  31  75  37  74  96  23  63]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [62 40 36 67 13 22 53 37 63 75 20 70 19 57 32  5 51 29  2 47 73 50 23 44 33 46 55 43 48 18 27 59 31  8 61 12 30 52 34 17 56 28 14 45  3 74  9 24 16  0 71 49 58 26 21 35 65 54 11 68 10 66  7 72 15  6 41 39  4 60 38 76 42 77 25 64 69  1], a_shuffle_aclus: [ 84  57  53  90  17  31  71  54  85 107  27  96  26  76  49   8  69  41   4  64 100  68  32  61  50  63  74  60  66  25  36  81  48  11  83  16  45  70  51  24  75  37  19  62   5 102  13  33  23   2  97  67  78  35  28  52  88  73  15  92  14  89  10  98  21   9  58  56   7  82  55 108  59 109  34  86  93   3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [50  6 43 57 67 15 53 61 55 70 21  9 34 49 54 69 27 17 75 25 39  2 36 71 38 32 10 26 60  4 28 37 52 30 68 66 44 63 51  3 23 24 76  8 18 46 29 35 22 56 77 13  5 64 20 45 19 14  1 58 31 41 12 62 59 48 16  0 47 72 65  7 73 33 40 11 74 42], a_shuffle_aclus: [ 68   9  60  76  90  21  71  83  74  96  28  13  51  67  73  93  36  24 107  34  56   4  53  97  55  49  14  35  82   7  37  54  70  45  92  89  61  85  69   5  32  33 108  11  25  63  41  52  31  75 109  17   8  86  27  62  26  19   3  78  48  58  16  84  81  66  23   2  64  98  88  10 100  50  57  15 102  59]\n",
      "a_shuffle_IDXs: [18  5 16 75 56 73 65 42 54 52 43 48 64 49 55 38 50 39 62 61 26  1 13 53 10 47 12 51 30  0 41 35 57  4 40 72 14 24  6 37 29 11 22 67 28 19 63  8 27 66 69 68 17 58 60 32 21  3 44 34 59 76  9  7 23 70 77 33 15  2 36 46 20 25 74 71 31 45], a_shuffle_aclus: [ 25   8  23 107  75 100  88  59  73  70  60  66  86  67  74  55  68  56  84  83  35   3  17  71  14  64  16  69  45   2  58  52  76   7  57  98  19  33   9  54  41  15  31  90  37  26  85  11  36  89  93  92  24  78  82  49  28   5  61  51  81 108  13  10  32  96 109  50  21   4  53  63  27  34 102  97  48  62]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [30 41 29 35 15 22 28 14 58 37 47 18 44 26 16 76  2 59 42 67 32  8 33 19  5 39 65 21  9 38  1 24 25 70 68 40 13 73 53 17  4  7  0 12 51 64 66 50 62 63 56 55 74 77 11 60 46 71 43 10 57 61 69 36 52  3 23 45  6 48 49 31 27 75 34 72 54 20], a_shuffle_aclus: [ 45  58  41  52  21  31  37  19  78  54  64  25  61  35  23 108   4  81  59  90  49  11  50  26   8  56  88  28  13  55   3  33  34  96  92  57  17 100  71  24   7  10   2  16  69  86  89  68  84  85  75  74 102 109  15  82  63  97  60  14  76  83  93  53  70   5  32  62   9  66  67  48  36 107  51  98  73  27]\n",
      "a_shuffle_IDXs: [51 14 63  5 57 45  2 36 21  1 52 56 16 32 39 47 25 76 49 68 27 22 61  4  9 54 35 65  0 55 48  7 62 73 72 42 28 53 71 24 44 41 58 67 11 37 60 66 19 13 46 18 29 38 70 12 31 17 43 64 20 15 34 26  6 74 23 69  8 30 33 40  3 10 75 59 77 50], a_shuffle_aclus: [ 69  19  85   8  76  62   4  53  28   3  70  75  23  49  56  64  34 108  67  92  36  31  83   7  13  73  52  88   2  74  66  10  84 100  98  59  37  71  97  33  61  58  78  90  15  54  82  89  26  17  63  25  41  55  96  16  48  24  60  86  27  21  51  35   9 102  32  93  11  45  50  57   5  14 107  81 109  68]\n",
      "a_shuffle_IDXs: [25 42 76 63 66 72 18 14 43 60 41 29 15 50  9 64 58 11 31 38 62 46 34 77 35 71  7  4 56 44 69 67 21 23 55 49  0 24 48  3 37 74 30 68  1 19 17 27 22 53 36 70 47  6  8 39 73 65 33 57 45 59 26 32 28 52 61 10  5 13 51 75 16 12 40  2 20 54], a_shuffle_aclus: [ 34  59 108  85  89  98  25  19  60  82  58  41  21  68  13  86  78  15  48  55  84  63  51 109  52  97  10   7  75  61  93  90  28  32  74  67   2  33  66   5  54 102  45  92   3  26  24  36  31  71  53  96  64   9  11  56 100  88  50  76  62  81  35  49  37  70  83  14   8  17  69 107  23  16  57   4  27  73]\n",
      "a_shuffle_IDXs: [54 43 58 57 45  5 31 44 51 64 68 21 26 27 32 61 77 70 36  8 55 66 16 28 53 12 63 60 23 49 20 62 47 10  1 14 46 11  9 72 13 69 29 75 76 74 42  2 35 40 19  7 67 17 52 65  0 38 25 30 15 48 73  6 37 22 56 39 24 18 59  4 33 41 71 50 34  3], a_shuffle_aclus: [ 73  60  78  76  62   8  48  61  69  86  92  28  35  36  49  83 109  96  53  11  74  89  23  37  71  16  85  82  32  67  27  84  64  14   3  19  63  15  13  98  17  93  41 107 108 102  59   4  52  57  26  10  90  24  70  88   2  55  34  45  21  66 100   9  54  31  75  56  33  25  81   7  50  58  97  68  51   5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [23 22 46  9 61 19 10 69 57 21 37 73 50 59 18  3 77 51 56  5 54 63  4 49 66 17 36 48 55  1 16 33 29  2  8 70 43 13 38 44 20 60 24 15 12 65 27 71 34 72 32 31 52 42 58 62 74 11 64  6 14 67 26 28 39 76  7 47 41 68 35 40 45 75 53 25  0 30], a_shuffle_aclus: [ 32  31  63  13  83  26  14  93  76  28  54 100  68  81  25   5 109  69  75   8  73  85   7  67  89  24  53  66  74   3  23  50  41   4  11  96  60  17  55  61  27  82  33  21  16  88  36  97  51  98  49  48  70  59  78  84 102  15  86   9  19  90  35  37  56 108  10  64  58  92  52  57  62 107  71  34   2  45]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [56 16 71 23 63  8 57 50 66 25 14 53 31 29  4 65 47 35 11 41 17 34 70 12 42 55 30 54 13 68 19 24 20 39 74 48  1 21  0 43  5 37 75 76 73 45 18 49 62 60 28 33 58 64 72 52  7 36 69 44  6 46 38 61 40 32 77 59 51  3  9  2 26 10 15 27 22 67], a_shuffle_aclus: [ 75  23  97  32  85  11  76  68  89  34  19  71  48  41   7  88  64  52  15  58  24  51  96  16  59  74  45  73  17  92  26  33  27  56 102  66   3  28   2  60   8  54 107 108 100  62  25  67  84  82  37  50  78  86  98  70  10  53  93  61   9  63  55  83  57  49 109  81  69   5  13   4  35  14  21  36  31  90]\n",
      "a_shuffle_IDXs: [73  8  1 23 28 15 69 54  7 47 58 35 57 62 43 29 32 70 76 67 24  0 68 39 55 56 77 16  5 44 31 74 41 75 71 10 21 46 66 49 38 51 61 59 48 65 13 25  4 72 19 52 45 37 27 14  2 36 40 22  6 64 33 17 26 60 53 12 30  3  9 34 42 18 50 20 63 11], a_shuffle_aclus: [100  11   3  32  37  21  93  73  10  64  78  52  76  84  60  41  49  96 108  90  33   2  92  56  74  75 109  23   8  61  48 102  58 107  97  14  28  63  89  67  55  69  83  81  66  88  17  34   7  98  26  70  62  54  36  19   4  53  57  31   9  86  50  24  35  82  71  16  45   5  13  51  59  25  68  27  85  15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 1 56  4 60 24 74 55 34 62 59 58 53 48 49 30 35  6 27 54 21 33 11 51 69 38  0 39 63 77 36 70 20 68 22 31 23 13 29 71 40 66 15  8 46  3 72 67 47  9 75 16 43 28 37 19  7 41  5 61 65 14 57 26 52 25 64 10 32 50 42 17 44 76 18 73 12  2 45], a_shuffle_aclus: [  3  75   7  82  33 102  74  51  84  81  78  71  66  67  45  52   9  36  73  28  50  15  69  93  55   2  56  85 109  53  96  27  92  31  48  32  17  41  97  57  89  21  11  63   5  98  90  64  13 107  23  60  37  54  26  10  58   8  83  88  19  76  35  70  34  86  14  49  68  59  24  61 108  25 100  16   4  62]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [49 28 48 42 40 70 37 30 57  2 21 71  3 20 34 25 12 63 27  9 68 51 33 56 77 14 32 44 66 58 29 39  8 45 50  6 11 65 76 64 43 15  5 35 55 38 67  4 23 24 46 31 17 13 36 62 60 22 74 54  7 52 26 47 18 10 41  0 75 19 73  1 59 72 53 69 16 61], a_shuffle_aclus: [ 67  37  66  59  57  96  54  45  76   4  28  97   5  27  51  34  16  85  36  13  92  69  50  75 109  19  49  61  89  78  41  56  11  62  68   9  15  88 108  86  60  21   8  52  74  55  90   7  32  33  63  48  24  17  53  84  82  31 102  73  10  70  35  64  25  14  58   2 107  26 100   3  81  98  71  93  23  83]\n",
      "a_shuffle_IDXs: [42  9 17 33 19 29 56  8 12 40 11 62 38  3 45 44 60 61 57 13 16 51 69 59 15 25 32 26 34 52  1 75 50 48 28 36 22  7 46 77 68 72 41 35 66 30 67  6  0 10 53 58 24 64 76 27 55 39 18 73 31 74 21 37  5  4 49 70 71 65 47 63 54  2 23 20 14 43], a_shuffle_aclus: [ 59  13  24  50  26  41  75  11  16  57  15  84  55   5  62  61  82  83  76  17  23  69  93  81  21  34  49  35  51  70   3 107  68  66  37  53  31  10  63 109  92  98  58  52  89  45  90   9   2  14  71  78  33  86 108  36  74  56  25 100  48 102  28  54   8   7  67  96  97  88  64  85  73   4  32  27  19  60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [76 52 26 45 31 44 54 46 40 36 14 75 10 68 34 55 29 50 41  8  5 51 59  3 62  9 65 24 48 43 19 13 58 64 63 21 12  1 20  4 73 61 42  7 35 30 11 49  0 23  2 69 71 32 77 70  6 15 18 74 47 27 72 33 37 38 16 66 53 39 67 22 17 56 57 28 60 25], a_shuffle_aclus: [108  70  35  62  48  61  73  63  57  53  19 107  14  92  51  74  41  68  58  11   8  69  81   5  84  13  88  33  66  60  26  17  78  86  85  28  16   3  27   7 100  83  59  10  52  45  15  67   2  32   4  93  97  49 109  96   9  21  25 102  64  36  98  50  54  55  23  89  71  56  90  31  24  75  76  37  82  34]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [14 18  4 39 47 66 31 37  8 63 13 36  9 59 55 76 64 19 28 26 16 35 62 69  0 45 54 61  1 72 27 46  2 15 43 73 12 32 65 44 38 29 20 30 68 60 58 71 53 67 25 70 33  5 41 57 22  3 56 51 11 42 77 17 74 21 34  7  6 52 50 24 49 48 40 10 23 75], a_shuffle_aclus: [ 19  25   7  56  64  89  48  54  11  85  17  53  13  81  74 108  86  26  37  35  23  52  84  93   2  62  73  83   3  98  36  63   4  21  60 100  16  49  88  61  55  41  27  45  92  82  78  97  71  90  34  96  50   8  58  76  31   5  75  69  15  59 109  24 102  28  51  10   9  70  68  33  67  66  57  14  32 107]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [73 32 65 28 43 38 50  7 39 18  5 23 49 55 71 52 45  0 41 59 31 54 10 19 66 16 48 62 58 61 77 14 57  9  3 29 60 35 56 42 25  6 17 69 51 26 21 76 64 44 24  4 67 75 70 47 68 22 46  8 40 13 63 36 72 74 30  2  1 11 15 27 53 12 37 33 20 34], a_shuffle_aclus: [100  49  88  37  60  55  68  10  56  25   8  32  67  74  97  70  62   2  58  81  48  73  14  26  89  23  66  84  78  83 109  19  76  13   5  41  82  52  75  59  34   9  24  93  69  35  28 108  86  61  33   7  90 107  96  64  92  31  63  11  57  17  85  53  98 102  45   4   3  15  21  36  71  16  54  50  27  51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [26 60  7 52 28 71 17 75 12 76 74 69  6  2 56 65 58 54 51 55 18  9 53 29 43 20 32 63 50 68 22 30 40 41 38 14 36 48 49 33 37 62 59 67 77 19 47 23  3 61 45  8 34 44 27  0 35  4 66 15 21 11 70  1 42 46 39 31 64  5 57 25 13 10 73 24 72 16], a_shuffle_aclus: [ 35  82  10  70  37  97  24 107  16 108 102  93   9   4  75  88  78  73  69  74  25  13  71  41  60  27  49  85  68  92  31  45  57  58  55  19  53  66  67  50  54  84  81  90 109  26  64  32   5  83  62  11  51  61  36   2  52   7  89  21  28  15  96   3  59  63  56  48  86   8  76  34  17  14 100  33  98  23]\n",
      "a_shuffle_IDXs: [49  1 22 65  0 13 28 56  5 42 37  6  7 57 64 14 73 10 74 62 43 29 33 53 72 47 55 41 36 34 15 75 69 32 19 67 61 17 71 20 68  3 52 12 51 25 11 18 26 70 50 35 16 38 63 44 40 30 24 76  8 45 48 31 27 23  9  4 21 60 59 54 39 77 66 58  2 46], a_shuffle_aclus: [ 67   3  31  88   2  17  37  75   8  59  54   9  10  76  86  19 100  14 102  84  60  41  50  71  98  64  74  58  53  51  21 107  93  49  26  90  83  24  97  27  92   5  70  16  69  34  15  25  35  96  68  52  23  55  85  61  57  45  33 108  11  62  66  48  36  32  13   7  28  82  81  73  56 109  89  78   4  63]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [74 42 60 49 41  0 69 40 70 26  6 12 53 23 77 66 24 44 31 54 58 34 35 22 76 56 67 50 39  3 17 59 46 43 73  8 45 20 61 15 64 21 32 47 11 52 62 48 63 19 27 57 25 10 37  1 38 29  2 16 13 33 68 14 18 71 55 36 75 72  9 65  7 28  4 51  5 30], a_shuffle_aclus: [102  59  82  67  58   2  93  57  96  35   9  16  71  32 109  89  33  61  48  73  78  51  52  31 108  75  90  68  56   5  24  81  63  60 100  11  62  27  83  21  86  28  49  64  15  70  84  66  85  26  36  76  34  14  54   3  55  41   4  23  17  50  92  19  25  97  74  53 107  98  13  88  10  37   7  69   8  45]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [45 77 69 64 11 43 23 20 17  5 36 71 12 63 61 67 62 31 24 59 35 57 21 30  7 41 72 40  1 37 74 46 28 32 70 50 38 51 68 13 52 39 44 18 56 27 26  8 58 22 49  6 15  9 34 29 48  4 54 10 75 16  2 33  0 47 73 65 25 42 53 55 66 60 19 14 76  3], a_shuffle_aclus: [ 62 109  93  86  15  60  32  27  24   8  53  97  16  85  83  90  84  48  33  81  52  76  28  45  10  58  98  57   3  54 102  63  37  49  96  68  55  69  92  17  70  56  61  25  75  36  35  11  78  31  67   9  21  13  51  41  66   7  73  14 107  23   4  50   2  64 100  88  34  59  71  74  89  82  26  19 108   5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [19  4 45 17  3 58 55 11 43 62 23 64 30 68 63 38  5 48 27 20 18 10 75 59  2 35 70 34 47 14  0 50 46 74 21 77 76 41 36 22 28 72 54 40 15 52 33 66 16 60 44 49 57  7 29 39 67  8 25 12 42 53 61 71 56 51 69 32  6 37 24  9 65 31 73  1 13 26], a_shuffle_aclus: [ 26   7  62  24   5  78  74  15  60  84  32  86  45  92  85  55   8  66  36  27  25  14 107  81   4  52  96  51  64  19   2  68  63 102  28 109 108  58  53  31  37  98  73  57  21  70  50  89  23  82  61  67  76  10  41  56  90  11  34  16  59  71  83  97  75  69  93  49   9  54  33  13  88  48 100   3  17  35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [49 12  3 26 64 72 27 18 13 76 75 37 23 54 32 42  9 73 51 17 71 69 29 16 61 28 20 66 47 52 59 35 63 40  8 24  1 65 39  0 46 43 57  6 67 25 19 10 38 77 31 22  2 34 50  4 33 41 30 11 58  5 56 15 68 48 74 36 62 44 53  7 45 60 14 55 70 21], a_shuffle_aclus: [ 67  16   5  35  86  98  36  25  17 108 107  54  32  73  49  59  13 100  69  24  97  93  41  23  83  37  27  89  64  70  81  52  85  57  11  33   3  88  56   2  63  60  76   9  90  34  26  14  55 109  48  31   4  51  68   7  50  58  45  15  78   8  75  21  92  66 102  53  84  61  71  10  62  82  19  74  96  28]\n",
      "a_shuffle_IDXs: [ 6 73 14 17  1 53 42 35 57  9 28 29 41 30 69 21 15  4 39 48 34 44 18 27 71 49 43 52 62 67 47 33 10 12 45  5 74 37 58 66 77 51 50  2 56 60 75  3 65 70 11  8 19 23 26 72 32 55 63 38  0 40 68 22 61 31 46  7 36 54 25 64 59 13 20 24 76 16], a_shuffle_aclus: [  9 100  19  24   3  71  59  52  76  13  37  41  58  45  93  28  21   7  56  66  51  61  25  36  97  67  60  70  84  90  64  50  14  16  62   8 102  54  78  89 109  69  68   4  75  82 107   5  88  96  15  11  26  32  35  98  49  74  85  55   2  57  92  31  83  48  63  10  53  73  34  86  81  17  27  33 108  23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [21 66 41 23 40 32 35 37  9 74 72 10  7 11  4  2 12 22 45  5 13 65 43 15 36 16 34 52 67 50 60 57 29 19 14  8 46 68 70 44 59 77 53 63 61 62 49 31 17 76 28 24 73 18 47 75 42 39 48  0 58 56 51 55 71 25  1 33 38 64  3 54  6 20 27 69 30 26], a_shuffle_aclus: [ 28  89  58  32  57  49  52  54  13 102  98  14  10  15   7   4  16  31  62   8  17  88  60  21  53  23  51  70  90  68  82  76  41  26  19  11  63  92  96  61  81 109  71  85  83  84  67  48  24 108  37  33 100  25  64 107  59  56  66   2  78  75  69  74  97  34   3  50  55  86   5  73   9  27  36  93  45  35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [19 57 75 58 73 36 12 45 28 40 52 76 33 63  3  8 65 59 37 64 71 22 51 42 27  0 46 30 39  4 69 61 29 21  2 49 41 70 18 47 25  6 10 20 13 44 54 14 56 15 23 72 67 11  9 26 60 17 24 35 55 66 32 68  5 74 50 77 48 31 62  1 43 38 34 53  7 16], a_shuffle_aclus: [ 26  76 107  78 100  53  16  62  37  57  70 108  50  85   5  11  88  81  54  86  97  31  69  59  36   2  63  45  56   7  93  83  41  28   4  67  58  96  25  64  34   9  14  27  17  61  73  19  75  21  32  98  90  15  13  35  82  24  33  52  74  89  49  92   8 102  68 109  66  48  84   3  60  55  51  71  10  23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [26 31 19 52 58  3 45 75 27 41 59  4 25 21 39 15 68 43 46 64 38 32 10  1 30 54 57 29  6 13 69 40 35 55 44 49 74  9 22 28 66  5 63 51 67 62  8 17 65 18 11 77 12 20 71 42 76 50 37  7 73 60 48 34 72 53 56 61 70 47  0 24 23 33  2 14 36 16], a_shuffle_aclus: [ 35  48  26  70  78   5  62 107  36  58  81   7  34  28  56  21  92  60  63  86  55  49  14   3  45  73  76  41   9  17  93  57  52  74  61  67 102  13  31  37  89   8  85  69  90  84  11  24  88  25  15 109  16  27  97  59 108  68  54  10 100  82  66  51  98  71  75  83  96  64   2  33  32  50   4  19  53  23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [47 46 25 74 61 17 71 30 15 38 51 39  1 36 41 13 26  7 35 69 64 18 14 33 56  4 72 48  3 77 22 58 60 49 27 68 40 65  5 52 50  0 70 31  2 57  8  9 59 23 12  6 28 75 11 66 16 29 20 63 43 54 32 21 45 53 19 10 73 24 44 42 76 37 55 34 67 62], a_shuffle_aclus: [ 64  63  34 102  83  24  97  45  21  55  69  56   3  53  58  17  35  10  52  93  86  25  19  50  75   7  98  66   5 109  31  78  82  67  36  92  57  88   8  70  68   2  96  48   4  76  11  13  81  32  16   9  37 107  15  89  23  41  27  85  60  73  49  28  62  71  26  14 100  33  61  59 108  54  74  51  90  84]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [56 65 42 26  3 73 35 45 76 53 20 59 46 23 48  9 21 32 58 62 24 43 74  6 17 52 30 40  7 11  4  5 36 49  2 10 22 39 77 72  8 13 34 75 28  1 15 63 64 57 12 31 60 38 33 25 50 47 66 71 41 68 69 61 18 37 44  0 67 70 55 51 14 54 27 19 29 16], a_shuffle_aclus: [ 75  88  59  35   5 100  52  62 108  71  27  81  63  32  66  13  28  49  78  84  33  60 102   9  24  70  45  57  10  15   7   8  53  67   4  14  31  56 109  98  11  17  51 107  37   3  21  85  86  76  16  48  82  55  50  34  68  64  89  97  58  92  93  83  25  54  61   2  90  96  74  69  19  73  36  26  41  23]\n",
      "a_shuffle_IDXs: [ 8 51 18 26 32  4 40 72 48 22 70 61 42 20 59 53 30  3 71 19  2 33 27 10 23 39  1 11 73 57 46 74 76 63  6 58  0 67 29 25 52 41 54 35 38  9 34 66 12 69 65 24  5 37 75 28 64 50 49 16 15 55 13 44  7 56 68 36 21 45 60 77 14 17 43 31 62 47], a_shuffle_aclus: [ 11  69  25  35  49   7  57  98  66  31  96  83  59  27  81  71  45   5  97  26   4  50  36  14  32  56   3  15 100  76  63 102 108  85   9  78   2  90  41  34  70  58  73  52  55  13  51  89  16  93  88  33   8  54 107  37  86  68  67  23  21  74  17  61  10  75  92  53  28  62  82 109  19  24  60  48  84  64]\n",
      "a_shuffle_IDXs: [44 33 12 13 43 38 24 48 70 77  2 10 19  0 72 50 17 71 27 55 74 73 15  7 56 68 47  1 54 29 60 62 76 34 32 52 63 36  5 39 31 66 26 25 37 59 64 75 16  9 69 65  6 30 61 20  3 51 22 14 45 53 18 41 42  4  8 46 11 28 67 40 23 49 57 21 58 35], a_shuffle_aclus: [ 61  50  16  17  60  55  33  66  96 109   4  14  26   2  98  68  24  97  36  74 102 100  21  10  75  92  64   3  73  41  82  84 108  51  49  70  85  53   8  56  48  89  35  34  54  81  86 107  23  13  93  88   9  45  83  27   5  69  31  19  62  71  25  58  59   7  11  63  15  37  90  57  32  67  76  28  78  52]\n",
      "a_shuffle_IDXs: [70 31 66  6 51 64 17 44 14 21 49 61 45 62  2 52 15 36 54  9 63 69  5 59 26 19  1  7 57 16 27 33 39 47 72 12 53 75 20 60 43 76 56 22 68 30 42  3 10 55 71 41  0 24 48 34 73 35 58 37 74 38  4 67 46 50 23 29 11 77 13 32 40 25  8 28 18 65], a_shuffle_aclus: [ 96  48  89   9  69  86  24  61  19  28  67  83  62  84   4  70  21  53  73  13  85  93   8  81  35  26   3  10  76  23  36  50  56  64  98  16  71 107  27  82  60 108  75  31  92  45  59   5  14  74  97  58   2  33  66  51 100  52  78  54 102  55   7  90  63  68  32  41  15 109  17  49  57  34  11  37  25  88]\n",
      "a_shuffle_IDXs: [19 76 32 75 22 10 56 34 11 12  7 49 52 51 33 68 18 57 63 67 29 69 40 35 43 17  5 55 24 41 42 62 72 39 54 44 70 48  9 25 66  1  3 15  8 14 58 28 47 45 38 21 73 71 16 59 53 36  6 60 27 30  0 50 13 37 65 20  4 74 46 64 26 31 23 77  2 61], a_shuffle_aclus: [ 26 108  49 107  31  14  75  51  15  16  10  67  70  69  50  92  25  76  85  90  41  93  57  52  60  24   8  74  33  58  59  84  98  56  73  61  96  66  13  34  89   3   5  21  11  19  78  37  64  62  55  28 100  97  23  81  71  53   9  82  36  45   2  68  17  54  88  27   7 102  63  86  35  48  32 109   4  83]\n",
      "a_shuffle_IDXs: [ 4 17 30 73 31 22 56 50 53 59 65 34 69  7 40  5 46 72 71 55 68 33 58 19  1  6 36  9 20 57 64 25 62 60  2 23 39 13 21 61 11 66 10 15 51 42 45 35  0 49 24 54 77  8 70 76 12 26 75 37 41 14 43 18 38 63 27 67  3 44 28 29 52 74 48 47 16 32], a_shuffle_aclus: [  7  24  45 100  48  31  75  68  71  81  88  51  93  10  57   8  63  98  97  74  92  50  78  26   3   9  53  13  27  76  86  34  84  82   4  32  56  17  28  83  15  89  14  21  69  59  62  52   2  67  33  73 109  11  96 108  16  35 107  54  58  19  60  25  55  85  36  90   5  61  37  41  70 102  66  64  23  49]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 3 69 15 71  9 45 29 24 66 26 61 74 60 53 41 59 32 47 70 18 63  1 75 21 52 55 23  4 44 16 48  2  7 30 49 58 22 19 13 39 12 72 35 31 11  5 67 46 40 50  6  0 14 68 20 62 57 38 54 64 73  8 28 37 25 10 42 65 33 36 76 51 56 27 77 43 34 17], a_shuffle_aclus: [  5  93  21  97  13  62  41  33  89  35  83 102  82  71  58  81  49  64  96  25  85   3 107  28  70  74  32   7  61  23  66   4  10  45  67  78  31  26  17  56  16  98  52  48  15   8  90  63  57  68   9   2  19  92  27  84  76  55  73  86 100  11  37  54  34  14  59  88  50  53 108  69  75  36 109  60  51  24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [39 46  7 76 58 59 32 64 28 22  8  2 73 27  5 72 15 13 57 18 24 42 12 34 16  3 66 26 45 38 74 35  4 30 20 10 71  0 41 75  9 29 44 67 33 77 47 19 68  1 60 55 14 37 51 43 11 52 65 61 54 23 40 21 53 70 50 63 17 49 36 62  6 56 69 31 48 25], a_shuffle_aclus: [ 56  63  10 108  78  81  49  86  37  31  11   4 100  36   8  98  21  17  76  25  33  59  16  51  23   5  89  35  62  55 102  52   7  45  27  14  97   2  58 107  13  41  61  90  50 109  64  26  92   3  82  74  19  54  69  60  15  70  88  83  73  32  57  28  71  96  68  85  24  67  53  84   9  75  93  48  66  34]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [33 73 23  8 28 44 30 34 46 75 38 40 60 74 69 17 77  9 29  5 21 61 31 32 64 36 35 12 48  4 49 10 52 39 55 20 76 42 66 63 54 18 16 14 72  7 65  3 50 58 70 45 24 67 53 51 25 37 15 71 57 59  6  1 13 62 27 41  0 47 11 22  2 26 56 68 19 43], a_shuffle_aclus: [ 50 100  32  11  37  61  45  51  63 107  55  57  82 102  93  24 109  13  41   8  28  83  48  49  86  53  52  16  66   7  67  14  70  56  74  27 108  59  89  85  73  25  23  19  98  10  88   5  68  78  96  62  33  90  71  69  34  54  21  97  76  81   9   3  17  84  36  58   2  64  15  31   4  35  75  92  26  60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [55 18 14 25  2 63 42 53 62 29 65 17 44 75 27 68 33 43 69 36 35  0 39  1 48 61  5 57  7  4 76  9 74 58 11 15 24 23 21 47 40 54  8 64 45 37 41 46 51 28 77 60 70 49 20 32 16 13 26 19 34 12  3 52 22 59 72 71 50 31 10 73 30 66  6 67 56 38], a_shuffle_aclus: [ 74  25  19  34   4  85  59  71  84  41  88  24  61 107  36  92  50  60  93  53  52   2  56   3  66  83   8  76  10   7 108  13 102  78  15  21  33  32  28  64  57  73  11  86  62  54  58  63  69  37 109  82  96  67  27  49  23  17  35  26  51  16   5  70  31  81  98  97  68  48  14 100  45  89   9  90  75  55]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [45 49 67 13 22 32 12 73 15 11 59  7 33 70 55 77 16 72 36 19 68 37 44 29 25 26 31  4 40 34 58 71  9 20  5 76 60 74 54  6 14 56 48 41 24  8  0 21 39 43 35 27 51  1 57  2 30 53 42  3 18 65 63 28 50 75 46 23 17 47 69 62 64 61 66 52 38 10], a_shuffle_aclus: [ 62  67  90  17  31  49  16 100  21  15  81  10  50  96  74 109  23  98  53  26  92  54  61  41  34  35  48   7  57  51  78  97  13  27   8 108  82 102  73   9  19  75  66  58  33  11   2  28  56  60  52  36  69   3  76   4  45  71  59   5  25  88  85  37  68 107  63  32  24  64  93  84  86  83  89  70  55  14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [55 49 10 45 14 76  0 51 56  1 52 12 32 77 20 13 21 54 57  7 15 68 66 28 46 26 70 39 30 40  6 60 73 74 65 18 35 47 63 31 17 71 24 37 69 41 59 27  4 42 16 48 11 58 64  8 38 19 44 72 23 34 33 75 43 50 25 62  5 29 22 36 53  3  9 61 67  2], a_shuffle_aclus: [ 74  67  14  62  19 108   2  69  75   3  70  16  49 109  27  17  28  73  76  10  21  92  89  37  63  35  96  56  45  57   9  82 100 102  88  25  52  64  85  48  24  97  33  54  93  58  81  36   7  59  23  66  15  78  86  11  55  26  61  98  32  51  50 107  60  68  34  84   8  41  31  53  71   5  13  83  90   4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [53 34 12 23 36 64 44 58 57 38 42 62 15  4 49 61 21 27  8  5 33 77 67 63 60 66 71 43  9  0 19 26 75 28 32 45 47 46 13 76 74 14 16 39 51 72 55 73 65 56 50 59 10 54 35 41 29 52  7  6 22  3 30 18 48 68 37 11 25 24  2 31 17  1 40 20 70 69], a_shuffle_aclus: [ 71  51  16  32  53  86  61  78  76  55  59  84  21   7  67  83  28  36  11   8  50 109  90  85  82  89  97  60  13   2  26  35 107  37  49  62  64  63  17 108 102  19  23  56  69  98  74 100  88  75  68  81  14  73  52  58  41  70  10   9  31   5  45  25  66  92  54  15  34  33   4  48  24   3  57  27  96  93]\n",
      "a_shuffle_IDXs: [ 3  7 27 45 47  0 39 37 20 22 19 17 35  5 13 53 75 34 31  2 15 70 54 72 59 68 48 76 10 77 51 66 52 62  6 55 38 44 26 25 21 65 30 43  8 50 46 40 24 12 73 67 61 28 63 33 57  4  1 71 69 74 16 11 29 32 58 56 14 49  9 41 64 36 23 60 18 42], a_shuffle_aclus: [  5  10  36  62  64   2  56  54  27  31  26  24  52   8  17  71 107  51  48   4  21  96  73  98  81  92  66 108  14 109  69  89  70  84   9  74  55  61  35  34  28  88  45  60  11  68  63  57  33  16 100  90  83  37  85  50  76   7   3  97  93 102  23  15  41  49  78  75  19  67  13  58  86  53  32  82  25  59]\n",
      "a_shuffle_IDXs: [ 2 28 39 44 66 47 41 60 74 11 43 54 67  6 65 52 58 38 68 32  4 45  1 26 77  0  8  9 27 16  5 49  7 10 20 59 46 75 48 37 31  3 70 57 14 19 21 69 25 18 23 61 42 35 51 64 12 53 34 50 15 63 73 56 62 40 29 36 71 30 55 24 13 17 76 72 33 22], a_shuffle_aclus: [  4  37  56  61  89  64  58  82 102  15  60  73  90   9  88  70  78  55  92  49   7  62   3  35 109   2  11  13  36  23   8  67  10  14  27  81  63 107  66  54  48   5  96  76  19  26  28  93  34  25  32  83  59  52  69  86  16  71  51  68  21  85 100  75  84  57  41  53  97  45  74  33  17  24 108  98  50  31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 2  1 56 65  0 59 40  5 47 23 48 14 67 24 39 75 43 20 45 63 29 41 42 31 26  8 15 73  4 71 44 64 25 33 52 46 58 54 76 16 62 37 68 66 57 69 17 77 13 19 18 10 55 74 27 53 35 32 11 72 49 30 51 12 21 60  3 61  6  7 28 38 22 50 70 34  9 36], a_shuffle_aclus: [  4   3  75  88   2  81  57   8  64  32  66  19  90  33  56 107  60  27  62  85  41  58  59  48  35  11  21 100   7  97  61  86  34  50  70  63  78  73 108  23  84  54  92  89  76  93  24 109  17  26  25  14  74 102  36  71  52  49  15  98  67  45  69  16  28  82   5  83   9  10  37  55  31  68  96  51  13  53]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [32 31 68 17 56 26  2  0 10 54 35  1 66 67 77 64 44  5 63 21 69 74 27 34 39 30  6 11  4 51 61 53 13 45 48 25 38 72 14 62 29 58 73 71 37 18 55 47 60  9 22  3 24 33 42 59 36 50 65 75  7 43 20  8 46 76 15 40 16 19 57 49 41 28 23 12 70 52], a_shuffle_aclus: [ 49  48  92  24  75  35   4   2  14  73  52   3  89  90 109  86  61   8  85  28  93 102  36  51  56  45   9  15   7  69  83  71  17  62  66  34  55  98  19  84  41  78 100  97  54  25  74  64  82  13  31   5  33  50  59  81  53  68  88 107  10  60  27  11  63 108  21  57  23  26  76  67  58  37  32  16  96  70]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [35 27 51 75 67 50 23 30  7 43 11 62 41 76 55 47 77 42  1 39 15 68 52 46 24 16 73 72 20  6  8 49 61 26 70 34 12 40 14 57 65 21 29 18 33 37 44 64 48 32 17 10 36 56  2 38 54  0 13  4 31 59 19 28 60  9 22 69  3 53 45 63 25 74  5 58 66 71], a_shuffle_aclus: [ 52  36  69 107  90  68  32  45  10  60  15  84  58 108  74  64 109  59   3  56  21  92  70  63  33  23 100  98  27   9  11  67  83  35  96  51  16  57  19  76  88  28  41  25  50  54  61  86  66  49  24  14  53  75   4  55  73   2  17   7  48  81  26  37  82  13  31  93   5  71  62  85  34 102   8  78  89  97]\n",
      "a_shuffle_IDXs: [46 36 12 48 15  7  8 52 55 64 33 77 14 42 21 13 23 76 50 67 24 38  5 66 41 19 17 53 49 62 58 65 35 68 43 30 45 31 74 18 69 22 27 16 51 32 57  4 73 47 20 29  3 26 61 60 63 59  0  6 75 28 70 54 39 34 72  9 40 25 11 10 56  1 37  2 71 44], a_shuffle_aclus: [ 63  53  16  66  21  10  11  70  74  86  50 109  19  59  28  17  32 108  68  90  33  55   8  89  58  26  24  71  67  84  78  88  52  92  60  45  62  48 102  25  93  31  36  23  69  49  76   7 100  64  27  41   5  35  83  82  85  81   2   9 107  37  96  73  56  51  98  13  57  34  15  14  75   3  54   4  97  61]\n",
      "a_shuffle_IDXs: [39 11  9 31  2  0 71 28 10 59 18 23 37 19  8 17 13 61 26 48 62  7 66 16 64 41 24 36 51 35 33 34  5  4 77  3 74 68 57 52 38 72 75 47 60 44 20 76 56 42 65 43 30 73  6 29  1 58 49 55 22 25 63 32 12 45 50 14 67 27 15 53 46 40 69 54 21 70], a_shuffle_aclus: [ 56  15  13  48   4   2  97  37  14  81  25  32  54  26  11  24  17  83  35  66  84  10  89  23  86  58  33  53  69  52  50  51   8   7 109   5 102  92  76  70  55  98 107  64  82  61  27 108  75  59  88  60  45 100   9  41   3  78  67  74  31  34  85  49  16  62  68  19  90  36  21  71  63  57  93  73  28  96]\n",
      "a_shuffle_IDXs: [11 44 32 60 19 77 33  6 31 58  2 55 57  4 76 64 18 48  9 38 17 70 71 46 73 25 36 35 68 62  1 20 39  0 28 66 24  8 23 30  5 26 63 74 52 12 29 43 34 47 45 51 72 27  7 10 41 40 16 37 21 69 50 22 14 49  3 54 15 61 56 75 13 53 59 42 67 65], a_shuffle_aclus: [ 15  61  49  82  26 109  50   9  48  78   4  74  76   7 108  86  25  66  13  55  24  96  97  63 100  34  53  52  92  84   3  27  56   2  37  89  33  11  32  45   8  35  85 102  70  16  41  60  51  64  62  69  98  36  10  14  58  57  23  54  28  93  68  31  19  67   5  73  21  83  75 107  17  71  81  59  90  88]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [60 62 32 36 39 76 72 40 20 34 16 63 15  1 27 49 73 22 75 58 19 24  7 11 68 70 71 13 12 52  2 38 46 65 53 43 21  8 30 59 42  0 55 25 44 66 61 67 47 26 28 33 17 48 35 69  6 10  4  5 77 23  9 45 50 41 56 54 14 51 74 37 31  3 64 29 18 57], a_shuffle_aclus: [ 82  84  49  53  56 108  98  57  27  51  23  85  21   3  36  67 100  31 107  78  26  33  10  15  92  96  97  17  16  70   4  55  63  88  71  60  28  11  45  81  59   2  74  34  61  89  83  90  64  35  37  50  24  66  52  93   9  14   7   8 109  32  13  62  68  58  75  73  19  69 102  54  48   5  86  41  25  76]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 2 27 70 66 47  0  1 61 25 59 44 42 22 48 14 63  4 17 37 16 13 41 54 65 15 74 72 12 57  7 45 32 35 51 64 75 43 26 50 71 31 56 24 30 55 77 60 69 46  5  8 33 21 76 36 49 67 10  9 34 39 52 29 40 11 20  3 38 62 53 19  6 23 68 58 73 18 28], a_shuffle_aclus: [  4  36  96  89  64   2   3  83  34  81  61  59  31  66  19  85   7  24  54  23  17  58  73  88  21 102  98  16  76  10  62  49  52  69  86 107  60  35  68  97  48  75  33  45  74 109  82  93  63   8  11  50  28 108  53  67  90  14  13  51  56  70  41  57  15  27   5  55  84  71  26   9  32  92  78 100  25  37]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [63 68 69 49 52  2 27 57 47 25 16 36 48 46  1 23 58 74 71 76 61  8 75 11 60 64 29 43 33 22 20 73 44  0 12 14 37 13 53 77 62 55  7 31 19 28 41 35 67 30 59 66 24 40 32 38  6 10  5 34 54 17 72  3 21 42 18 39 15 45 51 50 26  9 65  4 70 56], a_shuffle_aclus: [ 85  92  93  67  70   4  36  76  64  34  23  53  66  63   3  32  78 102  97 108  83  11 107  15  82  86  41  60  50  31  27 100  61   2  16  19  54  17  71 109  84  74  10  48  26  37  58  52  90  45  81  89  33  57  49  55   9  14   8  51  73  24  98   5  28  59  25  56  21  62  69  68  35  13  88   7  96  75]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [13 49 53 39 52 46 77 32  2 69 11 18 23 16 26 55 54  8 58 71 74 31 67 35 44  0 33 41 75 70  5 66 42  6 50 63 38 57 15 48 65 30 10 22 25 73 59 64 76 34 62 61  1 24 14 60 47 28 37 51 36 17  9  4 29 45 43 20 56 40 12 68 19  7 21 27 72  3], a_shuffle_aclus: [ 17  67  71  56  70  63 109  49   4  93  15  25  32  23  35  74  73  11  78  97 102  48  90  52  61   2  50  58 107  96   8  89  59   9  68  85  55  76  21  66  88  45  14  31  34 100  81  86 108  51  84  83   3  33  19  82  64  37  54  69  53  24  13   7  41  62  60  27  75  57  16  92  26  10  28  36  98   5]\n",
      "a_shuffle_IDXs: [57 38 20 37 64 10 21 67  2 70 49 16 43  9 73 53 34 22 50 40  0 18 62 51 25 42  4 32 45 52 61 74 60 33 29  1 54 56 15 31 69 23 76 65 24 17 36 30 72 68 59 27 41  7 11 12 14 39 26 47 55 28 75 44 48 13 66 71  8 63  5 19  3 46 77 35  6 58], a_shuffle_aclus: [ 76  55  27  54  86  14  28  90   4  96  67  23  60  13 100  71  51  31  68  57   2  25  84  69  34  59   7  49  62  70  83 102  82  50  41   3  73  75  21  48  93  32 108  88  33  24  53  45  98  92  81  36  58  10  15  16  19  56  35  64  74  37 107  61  66  17  89  97  11  85   8  26   5  63 109  52   9  78]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [25 30 49 41 64 47 54 12 52  8 34 56  5 66 20 38 31 22 72 17 51 43 75 74 13 70 62 24 28 35  0 58 26 50 11  7  4  1  9 16 33 55 29 14  6 69 39 37 42 71 61 65 48 19 46 76 59 18 67 36 40 53 77 32 60  2 68 57 27 21 73  3 44 63 10 15 45 23], a_shuffle_aclus: [ 34  45  67  58  86  64  73  16  70  11  51  75   8  89  27  55  48  31  98  24  69  60 107 102  17  96  84  33  37  52   2  78  35  68  15  10   7   3  13  23  50  74  41  19   9  93  56  54  59  97  83  88  66  26  63 108  81  25  90  53  57  71 109  49  82   4  92  76  36  28 100   5  61  85  14  21  62  32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [70 25 77 76 59 43 16 32 17 66 72 28 57 48 21  2 18 29 20 38 49 60 11  0 35  7 26 67 65 33 41  6 73 34  1 19  3 53  8 22 24 50 68 71 64 75 62 56 10 63 47 61 39 37  5 14 12 46 23 69 45  4 74 13 42 54 58 44 55 27 36 31 40 15 51  9 30 52], a_shuffle_aclus: [ 96  34 109 108  81  60  23  49  24  89  98  37  76  66  28   4  25  41  27  55  67  82  15   2  52  10  35  90  88  50  58   9 100  51   3  26   5  71  11  31  33  68  92  97  86 107  84  75  14  85  64  83  56  54   8  19  16  63  32  93  62   7 102  17  59  73  78  61  74  36  53  48  57  21  69  13  45  70]\n",
      "a_shuffle_IDXs: [36 20 46  3 25 10  2 74 30 22 72  8 17 31 47 24  4 32 23 52 14 49 18 50  5 15 13 59 57 70 61 35 33 53 55 45 28 60 73 76 75 51 39 16 34 63 65 26 48 77 71 42  1 43 62 64 41 29 27 56 54 67  7 66  0 12 44 68  9 37 11 38 58 69 21  6 19 40], a_shuffle_aclus: [ 53  27  63   5  34  14   4 102  45  31  98  11  24  48  64  33   7  49  32  70  19  67  25  68   8  21  17  81  76  96  83  52  50  71  74  62  37  82 100 108 107  69  56  23  51  85  88  35  66 109  97  59   3  60  84  86  58  41  36  75  73  90  10  89   2  16  61  92  13  54  15  55  78  93  28   9  26  57]\n",
      "a_shuffle_IDXs: [48  6 32 23 29 47 38  8 33 74 39 34 51 76  2 75 35 63 37 61 21 58  9 49 20 44 45 46 70 60 10 54 31 50 68 53 11 64 72 66 18  1 22 62 55 12 56  3 71 41 69 13 15  5 65 73  0 19 36  7 26 14 59  4 40 67 25 16 43 42 28 17 77 24 52 30 57 27], a_shuffle_aclus: [ 66   9  49  32  41  64  55  11  50 102  56  51  69 108   4 107  52  85  54  83  28  78  13  67  27  61  62  63  96  82  14  73  48  68  92  71  15  86  98  89  25   3  31  84  74  16  75   5  97  58  93  17  21   8  88 100   2  26  53  10  35  19  81   7  57  90  34  23  60  59  37  24 109  33  70  45  76  36]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [52  0 63  1 72 67 62 48 53 60 42 21 74 38 30  4 43  9 73 57 49 13 17  5 37 26 24  7 25 55 19 70 12 32 51 58 40 34 44 35 71  3 64  8 46 65 66 68 16 29 14 10 23 28 31 39 33 75 20 36 77 27 18 76 22 61 47 45 11 54 50 15 56 59 41  6 69  2], a_shuffle_aclus: [ 70   2  85   3  98  90  84  66  71  82  59  28 102  55  45   7  60  13 100  76  67  17  24   8  54  35  33  10  34  74  26  96  16  49  69  78  57  51  61  52  97   5  86  11  63  88  89  92  23  41  19  14  32  37  48  56  50 107  27  53 109  36  25 108  31  83  64  62  15  73  68  21  75  81  58   9  93   4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [23 74 66  1 10 58 56 63 20 48 51 25 43 33 28 77 14 72 11 30 67 69 53  9 54 42 35 18 15 46 45 44 61 70  3 36  4 17 60 34 37 52 22 50  6 62 68 19  8  2 49 73 41 38 39 24  7 29 76 75 13 64 16 31 47 26 59 12 27 55 57 40 21 71  5  0 32 65], a_shuffle_aclus: [ 32 102  89   3  14  78  75  85  27  66  69  34  60  50  37 109  19  98  15  45  90  93  71  13  73  59  52  25  21  63  62  61  83  96   5  53   7  24  82  51  54  70  31  68   9  84  92  26  11   4  67 100  58  55  56  33  10  41 108 107  17  86  23  48  64  35  81  16  36  74  76  57  28  97   8   2  49  88]\n",
      "a_shuffle_IDXs: [ 1 19 35 13 11 24  2 23 28 15  9 25 48 37 33  3 59 10 53  7 20 66 21 39 16 73 40 52 60 42 77 51 29 63 43 26  4 58 64 72 55 56 76 18 46 38 44 62 67 14 61 75 32 74 69 71 31 12 47 45  0 22 70 57  8 65  6 27 68 30 36 17 50 54  5 34 41 49], a_shuffle_aclus: [  3  26  52  17  15  33   4  32  37  21  13  34  66  54  50   5  81  14  71  10  27  89  28  56  23 100  57  70  82  59 109  69  41  85  60  35   7  78  86  98  74  75 108  25  63  55  61  84  90  19  83 107  49 102  93  97  48  16  64  62   2  31  96  76  11  88   9  36  92  45  53  24  68  73   8  51  58  67]\n",
      "a_shuffle_IDXs: [14 37 13 24 58 57 16 73 69 18 71 33  4 10 31 66 36  6 12 68 75 30  3 20 19 62 25  7 50 65 32 70 56 63  1 60 46  8 15 55 42 77 23  2 59 38 39  9 43 21  0 48 61 26 41  5 74 45 76 40 34 72 11 29 27 22 17 54 35 44 53 64 67 52 47 51 28 49], a_shuffle_aclus: [ 19  54  17  33  78  76  23 100  93  25  97  50   7  14  48  89  53   9  16  92 107  45   5  27  26  84  34  10  68  88  49  96  75  85   3  82  63  11  21  74  59 109  32   4  81  55  56  13  60  28   2  66  83  35  58   8 102  62 108  57  51  98  15  41  36  31  24  73  52  61  71  86  90  70  64  69  37  67]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [52  5 21 55 62 15 14 10 11 24 64 57 68 69 31 56  7 29 45 25 39 61 59 65 74 42 22 38 48 73 53 27  1  9 40 51 32 41 33 13 75 54 17 37 36  0 58  6 72 30 63 12  3 35 60 67 20 44 66 50  4 28 26 47 19 34 16  8 23 77 43 76 49 46  2 70 71 18], a_shuffle_aclus: [ 70   8  28  74  84  21  19  14  15  33  86  76  92  93  48  75  10  41  62  34  56  83  81  88 102  59  31  55  66 100  71  36   3  13  57  69  49  58  50  17 107  73  24  54  53   2  78   9  98  45  85  16   5  52  82  90  27  61  89  68   7  37  35  64  26  51  23  11  32 109  60 108  67  63   4  96  97  25]\n",
      "a_shuffle_IDXs: [13 66 57 48 46 55 77 70 47 35 71 59 76 42 26 16 19 23 67  7 21 50  9 30 51 17 28 34  3  0 27 22 44 43 29 45  5 39 75 73 40  8  4 20 32 38 54 53 63  2 58 74 14 25 33 68 69 49 72 65 12 11 64 37 24 10 60 41 31 18 52 61 36 56  1  6 62 15], a_shuffle_aclus: [ 17  89  76  66  63  74 109  96  64  52  97  81 108  59  35  23  26  32  90  10  28  68  13  45  69  24  37  51   5   2  36  31  61  60  41  62   8  56 107 100  57  11   7  27  49  55  73  71  85   4  78 102  19  34  50  92  93  67  98  88  16  15  86  54  33  14  82  58  48  25  70  83  53  75   3   9  84  21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [40 47 58  4 46 49 36  2 56 15  3 44 55 38 26  0 54 71  1 41 60 59 16 70 37 34 64 75 76 27 18 25 51 17 61 67 23  9 57  7 50 14 45 66 63  6 39 21 13 12 29 74 11 10 72 43 30 73 48 52 69 22 53 68 35  5 28 32 19 20 33 77 42 62 24 31  8 65], a_shuffle_aclus: [ 57  64  78   7  63  67  53   4  75  21   5  61  74  55  35   2  73  97   3  58  82  81  23  96  54  51  86 107 108  36  25  34  69  24  83  90  32  13  76  10  68  19  62  89  85   9  56  28  17  16  41 102  15  14  98  60  45 100  66  70  93  31  71  92  52   8  37  49  26  27  50 109  59  84  33  48  11  88]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [23  1  6 16 53 77 21 37 19 33 40 62 56 26 51 42 49 11 25 41 28 35 13 17 61 45 75 14 15 48  9 20 38 72 36 27 30 34 31 66 43 58 29 10  5 63  2 24 70 76 47 52 67 54 18 57 73  0 74 55 46  4  7 12  3 32 69 71 39 68 65 44 59  8 64 22 50 60], a_shuffle_aclus: [ 32   3   9  23  71 109  28  54  26  50  57  84  75  35  69  59  67  15  34  58  37  52  17  24  83  62 107  19  21  66  13  27  55  98  53  36  45  51  48  89  60  78  41  14   8  85   4  33  96 108  64  70  90  73  25  76 100   2 102  74  63   7  10  16   5  49  93  97  56  92  88  61  81  11  86  31  68  82]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [45  2 71  4 70 66 29 76 39 23 48 24 19 10 67 38  7 53 47 52 14 59  6 58 60 68 74 22 61 18 31 27  8  5 55 46 42 11 63 35 65 30 17 36 13 12 15 28 62 37 72 64 51 20 75 34  1 77 21 73 16 54 57 25  9 56 50 40 41 26 32 49 43  0  3 69 44 33], a_shuffle_aclus: [ 62   4  97   7  96  89  41 108  56  32  66  33  26  14  90  55  10  71  64  70  19  81   9  78  82  92 102  31  83  25  48  36  11   8  74  63  59  15  85  52  88  45  24  53  17  16  21  37  84  54  98  86  69  27 107  51   3 109  28 100  23  73  76  34  13  75  68  57  58  35  49  67  60   2   5  93  61  50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [40 35 10 12 17 32 26 53 69 27 23  4  1 16 46 55 59 70 71 11 58 61 54 56 31 67 49 37 76  5 20 42 33 47 41  0 74 29 39 14 65  3 24 75 15 21  7 19 22 28  9 36 60 34  6 63 25 73 77  8 48 44 18 64 50 68 45 66 30 57 72 38 62 52 43  2 51 13], a_shuffle_aclus: [ 57  52  14  16  24  49  35  71  93  36  32   7   3  23  63  74  81  96  97  15  78  83  73  75  48  90  67  54 108   8  27  59  50  64  58   2 102  41  56  19  88   5  33 107  21  28  10  26  31  37  13  53  82  51   9  85  34 100 109  11  66  61  25  86  68  92  62  89  45  76  98  55  84  70  60   4  69  17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [63 36 51 46 40 37 61 34 31  2 58 38 72 15 70  6 22  5 55  9 74 28 23 52 60 13 67 24 19 48 45 68 73 26 56 49 59 25 12 39 69 75 41 57 65 18  1  0 64 42 30  4 10 27 47 21 54 20 17 33  8 43  7 14 29 50 76 35 32 66 77 16 71 11  3 53 44 62], a_shuffle_aclus: [ 85  53  69  63  57  54  83  51  48   4  78  55  98  21  96   9  31   8  74  13 102  37  32  70  82  17  90  33  26  66  62  92 100  35  75  67  81  34  16  56  93 107  58  76  88  25   3   2  86  59  45   7  14  36  64  28  73  27  24  50  11  60  10  19  41  68 108  52  49  89 109  23  97  15   5  71  61  84]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [22 15 28 77 51 24 60 21  3  2 11 42 61  6 16 57 25 74  1 36 37 32 66 34 13 47 41  7 39 48 62 46 52 43 40 50  0 44 75 63 35 20 65 64 67 70 73 26  5 14 19 23 72 12 10 69 49 38 30 71 45 54 29 59  8 27 53 18 58  4 56 68 17  9 55 76 31 33], a_shuffle_aclus: [ 31  21  37 109  69  33  82  28   5   4  15  59  83   9  23  76  34 102   3  53  54  49  89  51  17  64  58  10  56  66  84  63  70  60  57  68   2  61 107  85  52  27  88  86  90  96 100  35   8  19  26  32  98  16  14  93  67  55  45  97  62  73  41  81  11  36  71  25  78   7  75  92  24  13  74 108  48  50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [62 68 22 11  0 21  9 75 43  3 27 51 18 17 42  7 56 70 47 53 66 40 41 54 37  2 24 57 46 16 55 61 26 19 60 69  8 15 63 32 38 30 35 31 50 39 52 76 48 74  4 14 67 36 73 58 44 65 72 13 71 25 45 20 77 49  6 23 59 64 28 12 10 29  5 33  1 34], a_shuffle_aclus: [ 84  92  31  15   2  28  13 107  60   5  36  69  25  24  59  10  75  96  64  71  89  57  58  73  54   4  33  76  63  23  74  83  35  26  82  93  11  21  85  49  55  45  52  48  68  56  70 108  66 102   7  19  90  53 100  78  61  88  98  17  97  34  62  27 109  67   9  32  81  86  37  16  14  41   8  50   3  51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [55 19 44 17 49  9 77 28 10 60 22  4 29 75 69 50 25 34 47 48 35 57 15 36 18 64 33 13 37 11 45 68 73  1 65 24 27 42  0 14 51  7 70 39 58 32  6 12 21 43 71 16 76 63 54 23 38 30 56 52  8 74 31  5 40  2 61 46 41 72 26 59 62  3 53 66 67 20], a_shuffle_aclus: [ 74  26  61  24  67  13 109  37  14  82  31   7  41 107  93  68  34  51  64  66  52  76  21  53  25  86  50  17  54  15  62  92 100   3  88  33  36  59   2  19  69  10  96  56  78  49   9  16  28  60  97  23 108  85  73  32  55  45  75  70  11 102  48   8  57   4  83  63  58  98  35  81  84   5  71  89  90  27]\n",
      "a_shuffle_IDXs: [56  2  8  3 54  4 68 27 26 77 32 25 76 75 63 69 16 33 15 59 13 30 53 21 34 66 49 10  6 22 52 71 24 20 28 38 40 48 23 29 58 67 47  5 61 57 35 36 45 46 44 18 50 14 11 70 12 43 72  1  0 17 19  9 62 65 51 42 37  7 73 41 64 39 60 55 74 31], a_shuffle_aclus: [ 75   4  11   5  73   7  92  36  35 109  49  34 108 107  85  93  23  50  21  81  17  45  71  28  51  89  67  14   9  31  70  97  33  27  37  55  57  66  32  41  78  90  64   8  83  76  52  53  62  63  61  25  68  19  15  96  16  60  98   3   2  24  26  13  84  88  69  59  54  10 100  58  86  56  82  74 102  48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [51 34  2 22 33 69 62 74 70 52 19 60 20 29 68 37 58 57 16  1 47 27 54 18 61 64 55 48 13 24 43 30 75 50 73  0 10 36 17 72 40 71 45 56 65  3  7 66 63 46 21  8  5 15 12 35 23 31  4 32 11 53 42 44 14 41 39 76 25  9 67 28 26 49 38  6 59 77], a_shuffle_aclus: [ 69  51   4  31  50  93  84 102  96  70  26  82  27  41  92  54  78  76  23   3  64  36  73  25  83  86  74  66  17  33  60  45 107  68 100   2  14  53  24  98  57  97  62  75  88   5  10  89  85  63  28  11   8  21  16  52  32  48   7  49  15  71  59  61  19  58  56 108  34  13  90  37  35  67  55   9  81 109]\n",
      "a_shuffle_IDXs: [25 70 41 20 77  8 55 24 12 26 38 58 61 19 28 50 15 31 57  2 16 21 37 30 22 11 53  9 44 27 69 14 34 75 67 59 56 73 72 48 23 45 32 43  5 10 74 65 60 17 39  0  7 35 71  6 52  3 46 68 47 62 33 42 63 13  4 64 29 49 36 51 76  1 54 40 66 18], a_shuffle_aclus: [ 34  96  58  27 109  11  74  33  16  35  55  78  83  26  37  68  21  48  76   4  23  28  54  45  31  15  71  13  61  36  93  19  51 107  90  81  75 100  98  66  32  62  49  60   8  14 102  88  82  24  56   2  10  52  97   9  70   5  63  92  64  84  50  59  85  17   7  86  41  67  53  69 108   3  73  57  89  25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [27 20  9  6 32 59 53 67 41  2 52 68 69 58 35 10 23 65 16 57 43 49 37 19 45 70 12  8 14  4 11 40 62 61 48 36 47 28 42  7 22 25 74 26  3 44 73 75 31 13 54 30  1 29 72 51 60 77 17 33 64 34 66 15 63 39 55 50 71 38  5 24  0 18 76 56 21 46], a_shuffle_aclus: [ 36  27  13   9  49  81  71  90  58   4  70  92  93  78  52  14  32  88  23  76  60  67  54  26  62  96  16  11  19   7  15  57  84  83  66  53  64  37  59  10  31  34 102  35   5  61 100 107  48  17  73  45   3  41  98  69  82 109  24  50  86  51  89  21  85  56  74  68  97  55   8  33   2  25 108  75  28  63]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [43 48 62 63 67 47 72 32 66 15 53 69 71 64 77  8  1 25 56 57 20 27 26 18 28 30  4 17 75 11 73 49  9  2 22  7 74 44 42 40 50 61 76 65 51  5 19 38 36 13 33 24 23 58 54 29  3 35 45  6 41 39 55 10 70 14 59 21 60 52 16 68 37 12 46 31 34  0], a_shuffle_aclus: [ 60  66  84  85  90  64  98  49  89  21  71  93  97  86 109  11   3  34  75  76  27  36  35  25  37  45   7  24 107  15 100  67  13   4  31  10 102  61  59  57  68  83 108  88  69   8  26  55  53  17  50  33  32  78  73  41   5  52  62   9  58  56  74  14  96  19  81  28  82  70  23  92  54  16  63  48  51   2]\n",
      "a_shuffle_IDXs: [11 71 69 24 74 70 58 49 12 16 50 13 32 72 62 23 46 43  7 21 25 26 68  1 65 67 15  3 52 47  9 45 30 38 39  2 60  0 56 61 42 77 75 35 20 29 57  5 73 10 55  4 19 33  8 37 66 40 63 22 31  6 64 53 17 18 44 41 36 76 54 48 34 59 27 51 14 28], a_shuffle_aclus: [ 15  97  93  33 102  96  78  67  16  23  68  17  49  98  84  32  63  60  10  28  34  35  92   3  88  90  21   5  70  64  13  62  45  55  56   4  82   2  75  83  59 109 107  52  27  41  76   8 100  14  74   7  26  50  11  54  89  57  85  31  48   9  86  71  24  25  61  58  53 108  73  66  51  81  36  69  19  37]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [32 29 31 76 71 42 67  9 62 70 44 74 17  1 40 75 50 27 58 69 30  4 68 77 59 72 15 33 41 12 23 53 38 28 35  5 18 49 54 25 56 57 24 48 20 21 73 11 37  0 16 34 43 55 14  7 61 39  8 63 46 26 22 10  6 36 51 66  3 64 47 60 65 52 19  2 45 13], a_shuffle_aclus: [ 49  41  48 108  97  59  90  13  84  96  61 102  24   3  57 107  68  36  78  93  45   7  92 109  81  98  21  50  58  16  32  71  55  37  52   8  25  67  73  34  75  76  33  66  27  28 100  15  54   2  23  51  60  74  19  10  83  56  11  85  63  35  31  14   9  53  69  89   5  86  64  82  88  70  26   4  62  17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [75 12 61 41 43 44 68  3 58 31 65 56 42 16 70  1 39 23 25 52 60 21 26 69 36  2 32 49 72 76 55 20 74 10 64 11 22 46 38 37 18 57  0 19 27 48 66 30 63 53  6 71 54 73 50 77 28 15 33 59 17 13 34 14  5 40 29 47 35 67 62 24  8 51  4  9  7 45], a_shuffle_aclus: [107  16  83  58  60  61  92   5  78  48  88  75  59  23  96   3  56  32  34  70  82  28  35  93  53   4  49  67  98 108  74  27 102  14  86  15  31  63  55  54  25  76   2  26  36  66  89  45  85  71   9  97  73 100  68 109  37  21  50  81  24  17  51  19   8  57  41  64  52  90  84  33  11  69   7  13  10  62]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [27 48 31 58 15 67 28 36 22 41  9 68 60  2 56 70  0 57 11 52 61 62 77 14  5 16 29 35 55 54 66 34 65 23  7 30  3 76 74  1 40 10 32 24 72 12 19  6 73 38 71 43 37 17 25 18 59 33  8 64 49 20 69 26 42 53 50 39 45 47 21 75 44 63 13  4 51 46], a_shuffle_aclus: [ 36  66  48  78  21  90  37  53  31  58  13  92  82   4  75  96   2  76  15  70  83  84 109  19   8  23  41  52  74  73  89  51  88  32  10  45   5 108 102   3  57  14  49  33  98  16  26   9 100  55  97  60  54  24  34  25  81  50  11  86  67  27  93  35  59  71  68  56  62  64  28 107  61  85  17   7  69  63]\n",
      "a_shuffle_IDXs: [54  6 37 32 70 71 61 18 76 19 63 20 75  9 73 39  1 30 16 47 12 74  7 17 60 21 45 64  0  5 28  3 44 58 48  8 22 65 10 49 11 41 43 66 26 13  4 35 23 72 15 24 42 68 62 25 46 69 59 50 34 77 38 36 29 40 52 33 27 14 55 51 57  2 31 67 56 53], a_shuffle_aclus: [ 73   9  54  49  96  97  83  25 108  26  85  27 107  13 100  56   3  45  23  64  16 102  10  24  82  28  62  86   2   8  37   5  61  78  66  11  31  88  14  67  15  58  60  89  35  17   7  52  32  98  21  33  59  92  84  34  63  93  81  68  51 109  55  53  41  57  70  50  36  19  74  69  76   4  48  90  75  71]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [45 38  2 63 29 12  4  7 18 28 68 39 47 41 25 72 62 58 42 22 32 13 40 64 17 59 67 15 71 16 65 14 75 34 70 66 27 37 77 36 21 69 60  0 55 54 50 53 74 24 49  5  1  8 10 33  6 44 30 23  9 52  3 31 57 73 56 26 46 51 19 48 20 61 43 35 11 76], a_shuffle_aclus: [ 62  55   4  85  41  16   7  10  25  37  92  56  64  58  34  98  84  78  59  31  49  17  57  86  24  81  90  21  97  23  88  19 107  51  96  89  36  54 109  53  28  93  82   2  74  73  68  71 102  33  67   8   3  11  14  50   9  61  45  32  13  70   5  48  76 100  75  35  63  69  26  66  27  83  60  52  15 108]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [10 49 76 74 75 51 23 60 50 43 52 29 32 68 61 36 13 46 28 70 73 33 38 63 35 25 20 41 27 37 69 40 26 53  6  4 55 65 77 21 42  1 59 44 17 45 34 71 72 11  5 39 66 22 15  7 57 58  2 47 12 62 19  0 31 30  3  8 64 48 14 67 18 16 24  9 54 56], a_shuffle_aclus: [ 14  67 108 102 107  69  32  82  68  60  70  41  49  92  83  53  17  63  37  96 100  50  55  85  52  34  27  58  36  54  93  57  35  71   9   7  74  88 109  28  59   3  81  61  24  62  51  97  98  15   8  56  89  31  21  10  76  78   4  64  16  84  26   2  48  45   5  11  86  66  19  90  25  23  33  13  73  75]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [58 75 25 74 64 46  2  3 38 26 20 69 37  6 17 39 49 41 77 32 10 22 33 15 59 35 23  4 60 11 56 43 65  0 73 47 76 42 29 16 27 36 61 12 24 54  7 31 51 48 71 28 40 62 53 13 68  1 44 45 52 57 19  5 67 18 34 72 50 63 55 14 66 21 30  9 70  8], a_shuffle_aclus: [ 78 107  34 102  86  63   4   5  55  35  27  93  54   9  24  56  67  58 109  49  14  31  50  21  81  52  32   7  82  15  75  60  88   2 100  64 108  59  41  23  36  53  83  16  33  73  10  48  69  66  97  37  57  84  71  17  92   3  61  62  70  76  26   8  90  25  51  98  68  85  74  19  89  28  45  13  96  11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [61 36 47 67 38 63 27  0 59 62 35 56 15 20 51 48 69 28 64 43  9 57 74 16 39 49 13 70 55 72 30 60 14 40  8 17 66 18 50 53 41 33 76 71 42 77 75 19 23 24 45 12 68 34 31  7  1 32 25  2  6  3 21 29 58 73 11 46 37 52 65 54 22 10  4 44  5 26], a_shuffle_aclus: [ 83  53  64  90  55  85  36   2  81  84  52  75  21  27  69  66  93  37  86  60  13  76 102  23  56  67  17  96  74  98  45  82  19  57  11  24  89  25  68  71  58  50 108  97  59 109 107  26  32  33  62  16  92  51  48  10   3  49  34   4   9   5  28  41  78 100  15  63  54  70  88  73  31  14   7  61   8  35]\n",
      "a_shuffle_IDXs: [51 35 16 27 29 75 23 12 64 72 42 33 54 73 25 59 58 13 40 74 32 69 19 57  2 48 55 68 14 18 17 46 53 39 49 31 24  3 21  5 61 71  4 56 52 15 70 20 43 37 28  6 38 26 66 45 77  0 10 63 22 34  9 67 62  7 65 11 47 41 30 50 76 44 60 36  8  1], a_shuffle_aclus: [ 69  52  23  36  41 107  32  16  86  98  59  50  73 100  34  81  78  17  57 102  49  93  26  76   4  66  74  92  19  25  24  63  71  56  67  48  33   5  28   8  83  97   7  75  70  21  96  27  60  54  37   9  55  35  89  62 109   2  14  85  31  51  13  90  84  10  88  15  64  58  45  68 108  61  82  53  11   3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [40  9  0 28 60 59 25 75 26 20 44 43 21 62  7 17 69 49 73 16 27 71  5 31 12 56 54 41 39 15  4 37 72 76 51 24 52 64 14 74 55 22 50  8 42 48 29 30 57 32  2 35  1 70 46 47 23 65 19 61 33 45 68 58 18  6 13 36 63 66 53 77 34  3 11 38 67 10], a_shuffle_aclus: [ 57  13   2  37  82  81  34 107  35  27  61  60  28  84  10  24  93  67 100  23  36  97   8  48  16  75  73  58  56  21   7  54  98 108  69  33  70  86  19 102  74  31  68  11  59  66  41  45  76  49   4  52   3  96  63  64  32  88  26  83  50  62  92  78  25   9  17  53  85  89  71 109  51   5  15  55  90  14]\n",
      "a_shuffle_IDXs: [62 17 43  0 14 77 65 28 24 34 68 31  7  3  8 74 73 13 12 44 57 15 47 40 58 26 49 72 19 35 25 60 27 32 48 51 53 54 67 50  6 10 37 52 56 30 71  2 69 39 66 38 33 22 61 75 16 55 59 76 46  4 42  1 23 36 64 11  9 20 70 63 45 21 18 29 41  5], a_shuffle_aclus: [ 84  24  60   2  19 109  88  37  33  51  92  48  10   5  11 102 100  17  16  61  76  21  64  57  78  35  67  98  26  52  34  82  36  49  66  69  71  73  90  68   9  14  54  70  75  45  97   4  93  56  89  55  50  31  83 107  23  74  81 108  63   7  59   3  32  53  86  15  13  27  96  85  62  28  25  41  58   8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [23 53 70  9 14  6 59 40 73 62 26 28 21  7 64 38 44 35  8 27 20 75 29  5 33 25 13 55 19 30 31 76 41 48 15 24 36 68 39 18  1 54 69 52 67 11  2 42 50  0 57 32 74 63 34 43 71  4 12 60 65  3 22 47 37 61 72 58 56 45 10 51 77 49 66 46 17 16], a_shuffle_aclus: [ 32  71  96  13  19   9  81  57 100  84  35  37  28  10  86  55  61  52  11  36  27 107  41   8  50  34  17  74  26  45  48 108  58  66  21  33  53  92  56  25   3  73  93  70  90  15   4  59  68   2  76  49 102  85  51  60  97   7  16  82  88   5  31  64  54  83  98  78  75  62  14  69 109  67  89  63  24  23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [22 64 49 16 54 63 15 10 44 52 77 39  8 17 34 46 12  2  3  1 36 74 71 35 40 51 53 69 48 65 33 61 55 21 41 19 13 42 14 58  7 24  5 50 30 47 11  4 56 67 32 26 20 66 31 28 38 27 73 29  6  0 45 62  9 72 70 43 37 60 25 76 18 23 59 75 68 57], a_shuffle_aclus: [ 31  86  67  23  73  85  21  14  61  70 109  56  11  24  51  63  16   4   5   3  53 102  97  52  57  69  71  93  66  88  50  83  74  28  58  26  17  59  19  78  10  33   8  68  45  64  15   7  75  90  49  35  27  89  48  37  55  36 100  41   9   2  62  84  13  98  96  60  54  82  34 108  25  32  81 107  92  76]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [52 18 74 16  2 47 44 30 33 22 23 72 59 66 43 21 77 63 49 56  9  0 15 73 39  4 58 76  3 51 67 48 46 75 35  6 28  5  1 53 57 34 61 25 68 42 60 65 62 40 64 45 31 12 38 36 10 14 71 70 32 13 27 55 69 11 20 41 24 17 37  8 50  7 54 19 26 29], a_shuffle_aclus: [ 70  25 102  23   4  64  61  45  50  31  32  98  81  89  60  28 109  85  67  75  13   2  21 100  56   7  78 108   5  69  90  66  63 107  52   9  37   8   3  71  76  51  83  34  92  59  82  88  84  57  86  62  48  16  55  53  14  19  97  96  49  17  36  74  93  15  27  58  33  24  54  11  68  10  73  26  35  41]\n",
      "a_shuffle_IDXs: [ 3 62 21 75 16 48 38 52 27 60 77 70 46 73 59  5  7 37  2 22 42 12 36 26 39 76 54 49 13  8 28 71 55 51 56 63 11 18 50 67 24 64 23 66 30  0 57 45 32 17  1 20 14 53 47 25 72 40 61 58  9 44 35  4 41  6 10 15 43 68 29 69 74 65 33 31 19 34], a_shuffle_aclus: [  5  84  28 107  23  66  55  70  36  82 109  96  63 100  81   8  10  54   4  31  59  16  53  35  56 108  73  67  17  11  37  97  74  69  75  85  15  25  68  90  33  86  32  89  45   2  76  62  49  24   3  27  19  71  64  34  98  57  83  78  13  61  52   7  58   9  14  21  60  92  41  93 102  88  50  48  26  51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [20 77 34 63 35 54 23 13 15  5 37 14 17 58 62 43 30 64 72  7 46 60 21 56 24 10 11 48 51 52 68 26 55 22 53 39 16 12 50 33 49 67 31 47 69 59 32 40 76 45 18 19  1  2 25 44 66  0  4  6 75 61 57 70  3 42 28 36 73 38 71 74 27 41  9 65 29  8], a_shuffle_aclus: [ 27 109  51  85  52  73  32  17  21   8  54  19  24  78  84  60  45  86  98  10  63  82  28  75  33  14  15  66  69  70  92  35  74  31  71  56  23  16  68  50  67  90  48  64  93  81  49  57 108  62  25  26   3   4  34  61  89   2   7   9 107  83  76  96   5  59  37  53 100  55  97 102  36  58  13  88  41  11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [16 46 73 29 13 39 25 74  1 30 26 76 24 47 64 43 61 62 50 36  3 58  4 60 11 14 53 48 35 65 33  0 40 59  9 27 45 57 44 72 10  5 49 77 71 66 75 19 68 34 22 37  8 70 52 15 56 17  7 20 21 41 31 63 28 42 38 69  2 51 32 67 12  6 55 23 18 54], a_shuffle_aclus: [ 23  63 100  41  17  56  34 102   3  45  35 108  33  64  86  60  83  84  68  53   5  78   7  82  15  19  71  66  52  88  50   2  57  81  13  36  62  76  61  98  14   8  67 109  97  89 107  26  92  51  31  54  11  96  70  21  75  24  10  27  28  58  48  85  37  59  55  93   4  69  49  90  16   9  74  32  25  73]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [14 27 50 13 41  2 22 40 75 30 70 52 36 66 71 72 74 38 53 60 16  8 58 69 49 57 48 35 21 25  3 29 65 56 46 73 39 44  9 24 42 23 45 55 43 20 11 68 18 15 47 76  0  1 37 31 12 77 32 64  7 17  6 19 59 26 61  4 67 63 28 62 33 10 51 54 34  5], a_shuffle_aclus: [ 19  36  68  17  58   4  31  57 107  45  96  70  53  89  97  98 102  55  71  82  23  11  78  93  67  76  66  52  28  34   5  41  88  75  63 100  56  61  13  33  59  32  62  74  60  27  15  92  25  21  64 108   2   3  54  48  16 109  49  86  10  24   9  26  81  35  83   7  90  85  37  84  50  14  69  73  51   8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 0  1 18 53 30 64 37  2 60 43 58 67 11 62 15 26 49 48 23 34 63  7 36 25 75 70 17 52  5 32 24 56 59 39 29 55 14  4 46  6 57 10 20 71  9 54 73 22 76 13 50  3 33 19 21 74 12 31 51 61  8 28 38 42 35 47 27 68 77 66 41 44 45 72 69 65 16 40], a_shuffle_aclus: [  2   3  25  71  45  86  54   4  82  60  78  90  15  84  21  35  67  66  32  51  85  10  53  34 107  96  24  70   8  49  33  75  81  56  41  74  19   7  63   9  76  14  27  97  13  73 100  31 108  17  68   5  50  26  28 102  16  48  69  83  11  37  55  59  52  64  36  92 109  89  58  61  62  98  93  88  23  57]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [32 23 40 59 38 69  3 39 52 20 50 75 58 56 72 49 53  2 73 43 57 11 45  5 26  7 62  6 12 64 42 15 10 16 68 44  4 41 31 71 67 60 28 55  1  0 74 24 25 70 65 76 54 33  8 34 19 61 14 77 13  9 63 47 48 29 36 17 51 35 22 30 37 21 46 66 27 18], a_shuffle_aclus: [ 49  32  57  81  55  93   5  56  70  27  68 107  78  75  98  67  71   4 100  60  76  15  62   8  35  10  84   9  16  86  59  21  14  23  92  61   7  58  48  97  90  82  37  74   3   2 102  33  34  96  88 108  73  50  11  51  26  83  19 109  17  13  85  64  66  41  53  24  69  52  31  45  54  28  63  89  36  25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [66 31 29 24  5 65 54 28  1  2 77 63 68 20 69 17 53 33 60 76 26 13 15 70 62 22  3 45 40 56 61 50 48  6 23 52 11 67 14 71 35 47  7 39 44 38 19  8 55 74 36 58 10  9 27 64 49 21 34 57 30 59 12 42 73 72  0 16 43 32 46 25 41 75 51 37  4 18], a_shuffle_aclus: [ 89  48  41  33   8  88  73  37   3   4 109  85  92  27  93  24  71  50  82 108  35  17  21  96  84  31   5  62  57  75  83  68  66   9  32  70  15  90  19  97  52  64  10  56  61  55  26  11  74 102  53  78  14  13  36  86  67  28  51  76  45  81  16  59 100  98   2  23  60  49  63  34  58 107  69  54   7  25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [48 39 52 28 60 29 30 17 41 47 77 38 57 22 18 69 20 44 45 34 56 70 76 37  6 23 54  2 73 62 12 10 19 65 40 25 43 51 16  3 50 59 26 36 72  1 42 53 71 68 13  7 46 11 64 67 58  9  0 55 74 15 66 35 33 14 21  5  4 24 49 32 75 63 31  8 61 27], a_shuffle_aclus: [ 66  56  70  37  82  41  45  24  58  64 109  55  76  31  25  93  27  61  62  51  75  96 108  54   9  32  73   4 100  84  16  14  26  88  57  34  60  69  23   5  68  81  35  53  98   3  59  71  97  92  17  10  63  15  86  90  78  13   2  74 102  21  89  52  50  19  28   8   7  33  67  49 107  85  48  11  83  36]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 1 17 18 53 63  9 14 77 74 16 38 46 39  4 42  7 26 62  6 15 50 28 22 64 45 33 58 34 66  5 13 48 47 54 69 75 65  3  8 60 11  0 19 76 43 36 29 70 41 27 67 52 24 59 49 31 56  2 44 35 12 25 30 61 10 32 55 21 68 73 71 23 57 40 37 20 51 72], a_shuffle_aclus: [  3  24  25  71  85  13  19 109 102  23  55  63  56   7  59  10  35  84   9  21  68  37  31  86  62  50  78  51  89   8  17  66  64  73  93 107  88   5  11  82  15   2  26 108  60  53  41  96  58  36  90  70  33  81  67  48  75   4  61  52  16  34  45  83  14  49  74  28  92 100  97  32  76  57  54  27  69  98]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [35 53 56 60  9 15  5 20 18  3 61 75 58 47 29 40 63 27 76 55 49 74 59 71 31  1 32 37 57 16 72 17 43  0 42 51 45 52 64 68 38 33 19 41 10 54 62 28 25 48 23  4 22 77 36  7 44 70 34  6 65 50 67 30 46  8 24 39 13 66 69 14 73 26 12 21 11  2], a_shuffle_aclus: [ 52  71  75  82  13  21   8  27  25   5  83 107  78  64  41  57  85  36 108  74  67 102  81  97  48   3  49  54  76  23  98  24  60   2  59  69  62  70  86  92  55  50  26  58  14  73  84  37  34  66  32   7  31 109  53  10  61  96  51   9  88  68  90  45  63  11  33  56  17  89  93  19 100  35  16  28  15   4]\n",
      "a_shuffle_IDXs: [42 23 74 35 14 43  3  8  6 26 21  9 25 17 47 12 68 34 60  1 38 11 49 63 24 13 19 22  4 36 39 66 57 32 54 67 62 75 45 31 40 71 59 72 51 61 48  5 37 53 58 29 27 28 30  0 33 77 65 46 10 70 69  2 73 56 64 16 20 41 50 55  7 18 52 44 15 76], a_shuffle_aclus: [ 59  32 102  52  19  60   5  11   9  35  28  13  34  24  64  16  92  51  82   3  55  15  67  85  33  17  26  31   7  53  56  89  76  49  73  90  84 107  62  48  57  97  81  98  69  83  66   8  54  71  78  41  36  37  45   2  50 109  88  63  14  96  93   4 100  75  86  23  27  58  68  74  10  25  70  61  21 108]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [43 21 41  4 54 76 77 15 71 17  7 26 33 30 32 13  0 31 75 57 42 63 62 35 14 12 65 46 55 18 50 23 38 10 51 68 16  8  3  5 20 37 27 61 40 45  2 24 73 52 49 60 67 69 66 11 47 39 64 48 56 44 58 36  1 28  9  6 72 19 29 53 70 59 25 22 74 34], a_shuffle_aclus: [ 60  28  58   7  73 108 109  21  97  24  10  35  50  45  49  17   2  48 107  76  59  85  84  52  19  16  88  63  74  25  68  32  55  14  69  92  23  11   5   8  27  54  36  83  57  62   4  33 100  70  67  82  90  93  89  15  64  56  86  66  75  61  78  53   3  37  13   9  98  26  41  71  96  81  34  31 102  51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [18  7 63 24 25 27  8 49 30 75 48 62  0 53 70 43 39 26  1 46 10 40 69 54 76 15  5  9 13 28  6 67 11 34 64 58 60 61 55 77 23 31 44 57 41 21 45 20 65 33 29 17 35 22 56 74 73 71 51 36 50 72 52 16  2 42 47 32 14 59 68 19 12 38  3 66 37  4], a_shuffle_aclus: [ 25  10  85  33  34  36  11  67  45 107  66  84   2  71  96  60  56  35   3  63  14  57  93  73 108  21   8  13  17  37   9  90  15  51  86  78  82  83  74 109  32  48  61  76  58  28  62  27  88  50  41  24  52  31  75 102 100  97  69  53  68  98  70  23   4  59  64  49  19  81  92  26  16  55   5  89  54   7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 0 68 56 69 43 12 77 26  6  1  7  2 70 32 51 41 55  4 33 21 36 28  9 22 14 53 25 40 57 37 61 48 54 65 35 66 45 13 24 20 59 29 19 30 15 62 60 75 74 39 34 18 16 17 73 10 42 23 58  5 50 63 31 27 46 11 71 72  3 44 76 52 67  8 49 47 64 38], a_shuffle_aclus: [  2  92  75  93  60  16 109  35   9   3  10   4  96  49  69  58  74   7  50  28  53  37  13  31  19  71  34  57  76  54  83  66  73  88  52  89  62  17  33  27  81  41  26  45  21  84  82 107 102  56  51  25  23  24 100  14  59  32  78   8  68  85  48  36  63  15  97  98   5  61 108  70  90  11  67  64  86  55]\n",
      "a_shuffle_IDXs: [31 60 64  5 72 45 57 71 51 61  9 53 23  2 67 15 52 22 38 20 48 62 14  6 50 12 41 77 46 44  4 42 43 65 34 58 55 36  3 28  0 13 33 47 35 54 75  7 30 63  8 10 68 70 56 11 17  1 25 40 39 76 26 24 21 16 69 37 49 18 27 32 73 74 29 66 59 19], a_shuffle_aclus: [ 48  82  86   8  98  62  76  97  69  83  13  71  32   4  90  21  70  31  55  27  66  84  19   9  68  16  58 109  63  61   7  59  60  88  51  78  74  53   5  37   2  17  50  64  52  73 107  10  45  85  11  14  92  96  75  15  24   3  34  57  56 108  35  33  28  23  93  54  67  25  36  49 100 102  41  89  81  26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [44 43  0 49 36 15 56 76 70 48 40  8 77 64 35 26 71 38 75 57 45  1 68 23 73  7 25 60 12 29 10  3 32 51  5 28 50 42 61  4 22 65 69 20 21 67 11 46  2 17 59 72 37 39 62 47 52  9  6 14 13 74 41 27 55 19 63 66 24 54 16 34 31 30 53 33 18 58], a_shuffle_aclus: [ 61  60   2  67  53  21  75 108  96  66  57  11 109  86  52  35  97  55 107  76  62   3  92  32 100  10  34  82  16  41  14   5  49  69   8  37  68  59  83   7  31  88  93  27  28  90  15  63   4  24  81  98  54  56  84  64  70  13   9  19  17 102  58  36  74  26  85  89  33  73  23  51  48  45  71  50  25  78]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 5 19 58 75 76 39 43 77 32 46 62  9  0 69 51  1 70 66 27 42 17 50 59  6 12 26 37 31 14 36 40 44 11 28 41 23 61 16 65 47 45 29 33 10 73 22  3 35  8 49 30 56 38 52 24 13  7 68 57 53 21  2 60 34 15 72 67 63 74 54 71 64 25 48 18 20 55  4], a_shuffle_aclus: [  8  26  78 107 108  56  60 109  49  63  84  13   2  93  69   3  96  89  36  59  24  68  81   9  16  35  54  48  19  53  57  61  15  37  58  32  83  23  88  64  62  41  50  14 100  31   5  52  11  67  45  75  55  70  33  17  10  92  76  71  28   4  82  51  21  98  90  85 102  73  97  86  34  66  25  27  74   7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 2 28 22 19 13 21 29 12 27 31 66 48 73 70  9  7 25 39 36 34 77 57 71 49 14 65 64 75 59  4 51 11  1  8 44 46 10 37 32 76 74 61  3 63 54 17 50 45 68 42 15 23 58 33 18 67 56 47  0 35 62 52  5 20 60 72 55 26 41 16 24 43 53 69 30 38 40  6], a_shuffle_aclus: [  4  37  31  26  17  28  41  16  36  48  89  66 100  96  13  10  34  56  53  51 109  76  97  67  19  88  86 107  81   7  69  15   3  11  61  63  14  54  49 108 102  83   5  85  73  24  68  62  92  59  21  32  78  50  25  90  75  64   2  52  84  70   8  27  82  98  74  35  58  23  33  60  71  93  45  55  57   9]\n",
      "a_shuffle_IDXs: [14 29 61 50  4 15  5 52 22 72 30 45 47 43 69  8 25 54 27 38 58 34 53 36 11 42 55 65  6 16  1 39 73 62 18  9 56 70 77 64 44 60 67 40 37  2 13 75 68 66 24 41 51 10 76 17 48 12  7 23 74 20  3 28 35 21 31 59 63 71 19 49 32 46 33 57  0 26], a_shuffle_aclus: [ 19  41  83  68   7  21   8  70  31  98  45  62  64  60  93  11  34  73  36  55  78  51  71  53  15  59  74  88   9  23   3  56 100  84  25  13  75  96 109  86  61  82  90  57  54   4  17 107  92  89  33  58  69  14 108  24  66  16  10  32 102  27   5  37  52  28  48  81  85  97  26  67  49  63  50  76   2  35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [58  4 70 45 47 26 44 20 68 18 61 32  5  0 69 31 51 57  9 43 71  8 56 21 41 46 17 66 54 13 53 16  2 14 40 60 27 15 35 10  3 64 48 11 65 22 37  6 74 33 30 77 23 63 49  7 55  1 36 19 12 29 67 25 59 28 73 76 50 42 24 62 72 52 75 34 38 39], a_shuffle_aclus: [ 78   7  96  62  64  35  61  27  92  25  83  49   8   2  93  48  69  76  13  60  97  11  75  28  58  63  24  89  73  17  71  23   4  19  57  82  36  21  52  14   5  86  66  15  88  31  54   9 102  50  45 109  32  85  67  10  74   3  53  26  16  41  90  34  81  37 100 108  68  59  33  84  98  70 107  51  55  56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [68 46  8 43 66 20 51 41 28 36 52 56 26 49 63 27 47 57 48 54 72 18 39 76  0 14 17 31 44 74 34 29 40 13 62 58 73  6 30 71 77 50  4 69 12 23 11 59 16 10  2 75 60  5 21 22 64 53 19 38 25 32 37 42 15 33  1 61  7 24 45  3 70  9 55 65 67 35], a_shuffle_aclus: [ 92  63  11  60  89  27  69  58  37  53  70  75  35  67  85  36  64  76  66  73  98  25  56 108   2  19  24  48  61 102  51  41  57  17  84  78 100   9  45  97 109  68   7  93  16  32  15  81  23  14   4 107  82   8  28  31  86  71  26  55  34  49  54  59  21  50   3  83  10  33  62   5  96  13  74  88  90  52]\n",
      "a_shuffle_IDXs: [26 15 53 42 70 49 33 75 54 37 39 14 35 77  5 61 67 16 64 10 29 34 11 57 55 20 40 36 51 66 19 59 32 24 25 38 63 43 41 68 65 46 31 27 71 74  6 12 76 30 69  8 52 22 48 18 50 21 58 56 47 73  3  7 45 28 23 62 72 44 13 17  2  4  1 60  9  0], a_shuffle_aclus: [ 35  21  71  59  96  67  50 107  73  54  56  19  52 109   8  83  90  23  86  14  41  51  15  76  74  27  57  53  69  89  26  81  49  33  34  55  85  60  58  92  88  63  48  36  97 102   9  16 108  45  93  11  70  31  66  25  68  28  78  75  64 100   5  10  62  37  32  84  98  61  17  24   4   7   3  82  13   2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [45 11  9 51 39  4 26 43 61 28 54 49 32  5 73 16 35 62 34 74 64 66 36 59  2 19 57  3 65  7 50 76 68 18 55  6  0 75 37 22 13  8 52 60 48 53 63 25 72 58 30 15 17 21  1 23 46 56 77 31 41 10 71 44 20 40 69 27 47 24 29 12 67 38 14 70 33 42], a_shuffle_aclus: [ 62  15  13  69  56   7  35  60  83  37  73  67  49   8 100  23  52  84  51 102  86  89  53  81   4  26  76   5  88  10  68 108  92  25  74   9   2 107  54  31  17  11  70  82  66  71  85  34  98  78  45  21  24  28   3  32  63  75 109  48  58  14  97  61  27  57  93  36  64  33  41  16  90  55  19  96  50  59]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [27 61 14 42  6 47 20 26  4 10 15 16 24 37 76 19 63 41 28  1  8 69 62 39  9 59 12 74 29 21 17 23 57 34  5 31 75 67  7 60 36 70 58 43 66 48 33  2 38 49 54 46 32 73  0 55 13 45 53 22 18 68 25 40 44 64 65 71 50 72 52 77  3 11 30 51 35 56], a_shuffle_aclus: [ 36  83  19  59   9  64  27  35   7  14  21  23  33  54 108  26  85  58  37   3  11  93  84  56  13  81  16 102  41  28  24  32  76  51   8  48 107  90  10  82  53  96  78  60  89  66  50   4  55  67  73  63  49 100   2  74  17  62  71  31  25  92  34  57  61  86  88  97  68  98  70 109   5  15  45  69  52  75]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [46 31 17 19 62 25  4  2 66 39 74 47 36 23 18 22 55 10 65 32  1 76  0 41 11 68 38 64 50 24 28 20  5 75  6 63 49 21 33  8 72 51 45 12 58 34 15 59  9 35 67 73  3 37  7 40 54 61 52 13 60 70 42 30 69 53 77 29 14 71 43 27 16 57 48 44 26 56], a_shuffle_aclus: [ 63  48  24  26  84  34   7   4  89  56 102  64  53  32  25  31  74  14  88  49   3 108   2  58  15  92  55  86  68  33  37  27   8 107   9  85  67  28  50  11  98  69  62  16  78  51  21  81  13  52  90 100   5  54  10  57  73  83  70  17  82  96  59  45  93  71 109  41  19  97  60  36  23  76  66  61  35  75]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [37  8  7 41 62 64 40 46 45 71 56 11 38 39 76 65 47 21 55 77 48  6 20  3 50 15  1 22 74 60 52 44 31 61 43 26 68 30 10 24 54 69 27 49 75 72 73  4  0 28  9 66 51 18 25  2 29 59 32 14 23 33 36 34 17 57 13 16 42  5 19 70 35 53 67 58 63 12], a_shuffle_aclus: [ 54  11  10  58  84  86  57  63  62  97  75  15  55  56 108  88  64  28  74 109  66   9  27   5  68  21   3  31 102  82  70  61  48  83  60  35  92  45  14  33  73  93  36  67 107  98 100   7   2  37  13  89  69  25  34   4  41  81  49  19  32  50  53  51  24  76  17  23  59   8  26  96  52  71  90  78  85  16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [13 67 53  5  7 21 69 36 50 72  8 62 22 35 17 11 25 63 19  0 26 14 59 23 31 58 74 10 48 34 56 52 57 75 27 18  4 44 20 51  3 77 45 76 71 38 42 37 39 46 32 64 28 30  1  6 70 65 43 29 68 60 24 15 16  9 73  2 12 54 49 66 33 55 41 40 47 61], a_shuffle_aclus: [ 17  90  71   8  10  28  93  53  68  98  11  84  31  52  24  15  34  85  26   2  35  19  81  32  48  78 102  14  66  51  75  70  76 107  36  25   7  61  27  69   5 109  62 108  97  55  59  54  56  63  49  86  37  45   3   9  96  88  60  41  92  82  33  21  23  13 100   4  16  73  67  89  50  74  58  57  64  83]\n",
      "a_shuffle_IDXs: [73 38  0  4 58 31 27 53 64 44 10 52  5 74 17  9 13 24 14 71 16 60 30 25 61 54 18 69  8 50 23 12 36 37 29 67 43 19 77 47 48 21  3 75 57 59 76 72 55 42 68 62 46 32 49 70 45 41 63 34 20 28 22 35 15 26  1 56 40  6 33  2 11 66  7 51 65 39], a_shuffle_aclus: [100  55   2   7  78  48  36  71  86  61  14  70   8 102  24  13  17  33  19  97  23  82  45  34  83  73  25  93  11  68  32  16  53  54  41  90  60  26 109  64  66  28   5 107  76  81 108  98  74  59  92  84  63  49  67  96  62  58  85  51  27  37  31  52  21  35   3  75  57   9  50   4  15  89  10  69  88  56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [64  4  6 30 25 72 31 52 56 58 35 33 50 13 41 17 34 62 47 76 45 27  7 43 39 55 67 51  0 38 59  9 26 69 73  5 70  8 32 57  3 48 53 49 65 24 66 74 75 37 14 61  1 29 77 19 20 10 68 54 16 63 46 42 18 21 15  2 11 12 22 23 44 60 36 40 28 71], a_shuffle_aclus: [ 86   7   9  45  34  98  48  70  75  78  52  50  68  17  58  24  51  84  64 108  62  36  10  60  56  74  90  69   2  55  81  13  35  93 100   8  96  11  49  76   5  66  71  67  88  33  89 102 107  54  19  83   3  41 109  26  27  14  92  73  23  85  63  59  25  28  21   4  15  16  31  32  61  82  53  57  37  97]\n",
      "a_shuffle_IDXs: [18 46 10 57  2 56 37 32  9 26 67  8 58 16 38 22 25 39 62 49 50 51 71 72 59 12 28 42 35 69 11 44 76  7 43 64 23 36 21 48 20 17  1 45 70 52 34 15 30  4 60 66 55 63 77  0 68 29 54  5 65 75 27 31 74  3 53 41 14 61 19 24 40 33  6 47 73 13], a_shuffle_aclus: [ 25  63  14  76   4  75  54  49  13  35  90  11  78  23  55  31  34  56  84  67  68  69  97  98  81  16  37  59  52  93  15  61 108  10  60  86  32  53  28  66  27  24   3  62  96  70  51  21  45   7  82  89  74  85 109   2  92  41  73   8  88 107  36  48 102   5  71  58  19  83  26  33  57  50   9  64 100  17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [59 66 71 37 32 53 30 36 33 25 38 65 48 10 21 39 56 24 76 77 35 11 74  9  1 14 49 26 58 51  6 61 44 57 72 42  8  3 12  0 41 34 62  2  4 54  5 46 43 20 70 47 50 68 40 17 18 19 60 29 13 15 75 73 64 55 27 23 45 67 69 63 31 28  7 16 22 52], a_shuffle_aclus: [ 81  89  97  54  49  71  45  53  50  34  55  88  66  14  28  56  75  33 108 109  52  15 102  13   3  19  67  35  78  69   9  83  61  76  98  59  11   5  16   2  58  51  84   4   7  73   8  63  60  27  96  64  68  92  57  24  25  26  82  41  17  21 107 100  86  74  36  32  62  90  93  85  48  37  10  23  31  70]\n",
      "a_shuffle_IDXs: [ 7 32 35 44 45 41 53 39 54  6 71 65  1 63 58 67 48  0 73 74  9 26 13 77 70 64 75 22 61 33 51 60 25 68 40 34  8 72 49 66 19 24 29 38 31 17 12 47 20 23 46 50  5 21 10  4 11 18 14 30 16 15 52 55 28 27 42 59 56 76 57 62  2 43  3 69 36 37], a_shuffle_aclus: [ 10  49  52  61  62  58  71  56  73   9  97  88   3  85  78  90  66   2 100 102  13  35  17 109  96  86 107  31  83  50  69  82  34  92  57  51  11  98  67  89  26  33  41  55  48  24  16  64  27  32  63  68   8  28  14   7  15  25  19  45  23  21  70  74  37  36  59  81  75 108  76  84   4  60   5  93  53  54]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [13 24 44  3 18 33 38 66 26 59 55 62 16 71 75 35 41 46 19 60 39 53 77 48 45  2 68 27 52 57 23 73 32  4 31  1 64 43  6 74 29  7  0 54 51 28 34 36 49  8 50 12 56  9 37 11 20 72 21 25 70 42 10  5 67 30 22 14 58 61 15 65 69 76 63 47 40 17], a_shuffle_aclus: [ 17  33  61   5  25  50  55  89  35  81  74  84  23  97 107  52  58  63  26  82  56  71 109  66  62   4  92  36  70  76  32 100  49   7  48   3  86  60   9 102  41  10   2  73  69  37  51  53  67  11  68  16  75  13  54  15  27  98  28  34  96  59  14   8  90  45  31  19  78  83  21  88  93 108  85  64  57  24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 8 12 76 36 31 23 43 25 17 38 32 37 52 41 16 71 49 46 44 61 11 29 35 74 15 34 21 27 39 19 24 73 48 65 10 42 57 75 40 30 13  9 53 54 26  2 66 33  5 77 68 63  0 55 22  6  3 58 28  4 59 70 14 47 18 62 56 64  7 72 60 69 51 50 45 20 67  1], a_shuffle_aclus: [ 11  16 108  53  48  32  60  34  24  55  49  54  70  58  23  97  67  63  61  83  15  41  52 102  21  51  28  36  56  26  33 100  66  88  14  59  76 107  57  45  17  13  71  73  35   4  89  50   8 109  92  85   2  74  31   9   5  78  37   7  81  96  19  64  25  84  75  86  10  98  82  93  69  68  62  27  90   3]\n",
      "a_shuffle_IDXs: [64 75 57  0 39 19 26 50 53 58 20  4  7 40 41 18 59  2 31 72 17 69 38 36  3 52 37 11 34  6 12 13 43 42 65  9 63 25 62 45 67 56 14 10 70 33 28 74  8 21 23 47 77 32 61 73 71 46 66 51 76  5 15 55 22 60 27 54 49 35 48 30 44 29 24 16  1 68], a_shuffle_aclus: [ 86 107  76   2  56  26  35  68  71  78  27   7  10  57  58  25  81   4  48  98  24  93  55  53   5  70  54  15  51   9  16  17  60  59  88  13  85  34  84  62  90  75  19  14  96  50  37 102  11  28  32  64 109  49  83 100  97  63  89  69 108   8  21  74  31  82  36  73  67  52  66  45  61  41  33  23   3  92]\n",
      "a_shuffle_IDXs: [43 67  8 16 24  6 20 26 18 72 56 48 42 25 52 69 74 13 58 41  9 64 33 35 49 54 38 21 22 55 70 31 27 17 65 23 75  7 63 32 47 28  3 39 45 37 61 40  1 62  2 34 68 11 10 76 30 51 12 57 77  5 53 44 71  4 19  0 60 59 46 73 66 15 36 14 29 50], a_shuffle_aclus: [ 60  90  11  23  33   9  27  35  25  98  75  66  59  34  70  93 102  17  78  58  13  86  50  52  67  73  55  28  31  74  96  48  36  24  88  32 107  10  85  49  64  37   5  56  62  54  83  57   3  84   4  51  92  15  14 108  45  69  16  76 109   8  71  61  97   7  26   2  82  81  63 100  89  21  53  19  41  68]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 8 27 46 53 20 72 55 62 75 67 61 73 54 31 13  5 45 74 43 49 17 38 47 69 37  7 34  3 70 42 36 44  9 77 35 60  1 10 64 24 40  0 14 65 15 71 48 41 30 63 51  4 68 25 23 57 28 58 50 76 26 16 12 19 59 21 56 22 39  6 11 52 18 33 66  2 32 29], a_shuffle_aclus: [ 11  36  63  71  27  98  74  84 107  90  83 100  73  48  17   8  62 102  60  67  24  55  64  93  54  10  51   5  96  59  53  61  13 109  52  82   3  14  86  33  57   2  19  88  21  97  66  58  45  85  69   7  92  34  32  76  37  78  68 108  35  23  16  26  81  28  75  31  56   9  15  70  25  50  89   4  49  41]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [28 29 45 42 70 50 20 66 36 24 15 39 44 61 12 53 37  2 22 55 41 49 76 62 10 21 56 31 43 59 67 72 18 11 26 35 71 68 65 13 32 77  6 73  4 40 19  8 60 30 25  5 75 52 58 16 74 51 27 63 47 17 38 23 34 69  3 14  1 57 48  0 46 54  7  9 64 33], a_shuffle_aclus: [ 37  41  62  59  96  68  27  89  53  33  21  56  61  83  16  71  54   4  31  74  58  67 108  84  14  28  75  48  60  81  90  98  25  15  35  52  97  92  88  17  49 109   9 100   7  57  26  11  82  45  34   8 107  70  78  23 102  69  36  85  64  24  55  32  51  93   5  19   3  76  66   2  63  73  10  13  86  50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [58  0 42 32 21 29 53 37 51 64 47 11 59 14 71 20  2 56 36 15 23 31 72  3 38 77 28 40 70 75 61 26 50 62 16 13 35 25 45 73  7 10  6  9 60 34 57  5 22 63 46 44 69 74 68 33 67 17 52 66 55 24 19  4 41 65 12 76 49 30 27 43  1 18 54 39  8 48], a_shuffle_aclus: [ 78   2  59  49  28  41  71  54  69  86  64  15  81  19  97  27   4  75  53  21  32  48  98   5  55 109  37  57  96 107  83  35  68  84  23  17  52  34  62 100  10  14   9  13  82  51  76   8  31  85  63  61  93 102  92  50  90  24  70  89  74  33  26   7  58  88  16 108  67  45  36  60   3  25  73  56  11  66]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [41 24 56 34 65 10 38 62 53 66 14 48 40 31 52  8 27 49  7 59 35 11 57 73 16 13 20 26 51 23 64 60 44 61 25 28  2 67 33 63 18 45 15 17 42 46 69 43 70  4 47 55  3  1 32  9 21 77  5 22 72 58 68 75  0 36 50 54 29 19 76 37 71 30 74  6 39 12], a_shuffle_aclus: [ 58  33  75  51  88  14  55  84  71  89  19  66  57  48  70  11  36  67  10  81  52  15  76 100  23  17  27  35  69  32  86  82  61  83  34  37   4  90  50  85  25  62  21  24  59  63  93  60  96   7  64  74   5   3  49  13  28 109   8  31  98  78  92 107   2  53  68  73  41  26 108  54  97  45 102   9  56  16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [50  5 53 48 23 67 61 30 41 44 46 51 21 57 56 20 73 49 59  8  2 70 32 39 25 55 17 29 14 52 16 34 38 72 42 74  7 65 76 28 11 45  1 31 64 37 19  3 12 33 43 18  0 77  4 60 63 27 47 15  9 54 58 40 36 35 13 62 10 22  6 68 71 26 75 24 69 66], a_shuffle_aclus: [ 68   8  71  66  32  90  83  45  58  61  63  69  28  76  75  27 100  67  81  11   4  96  49  56  34  74  24  41  19  70  23  51  55  98  59 102  10  88 108  37  15  62   3  48  86  54  26   5  16  50  60  25   2 109   7  82  85  36  64  21  13  73  78  57  53  52  17  84  14  31   9  92  97  35 107  33  93  89]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [12 27  1 48 28 13 21 43 40  5 75 60 17 14  4 77  0 24 68 58 42  2  9 55 64 53 54 69 19 50 52 59 66 71 31 30 44 25 23 29 70 37 32 22 56 36 61 26 74 57 49 10 35 67 47 76  3 72 38 20 18 73 16 41 15 63 51 39 34  7 65 33  6 62 11 46 45  8], a_shuffle_aclus: [ 16  36   3  66  37  17  28  60  57   8 107  82  24  19   7 109   2  33  92  78  59   4  13  74  86  71  73  93  26  68  70  81  89  97  48  45  61  34  32  41  96  54  49  31  75  53  83  35 102  76  67  14  52  90  64 108   5  98  55  27  25 100  23  58  21  85  69  56  51  10  88  50   9  84  15  63  62  11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [24 40  8 71 46 10  0 77 13 22 68 38 57 31 32 34 49  5  2 66 37 60  1 65 62 26 42 56 33 23 47 17 51 12 18 73 21 55 53 27 59  9 15 76 19  4 44  3 29 75 70 14 48 41 36 69 50 72 45  7 20 25 61 64 11 52 39 28 67 54  6 16 74 43 30 63 35 58], a_shuffle_aclus: [ 33  57  11  97  63  14   2 109  17  31  92  55  76  48  49  51  67   8   4  89  54  82   3  88  84  35  59  75  50  32  64  24  69  16  25 100  28  74  71  36  81  13  21 108  26   7  61   5  41 107  96  19  66  58  53  93  68  98  62  10  27  34  83  86  15  70  56  37  90  73   9  23 102  60  45  85  52  78]\n",
      "a_shuffle_IDXs: [46 76 70 57 56 20 67 47 73 28 26 11 13 60  5 41 31 77 66 29 63 49 45 53 74  2 52 58 25 44  3 69 43 33  0 12 54 37 51 34 15 42 40 10 65 14 22 17 21 24 71 62 32 55 75 18 19 72  8 50  4 64 68 27 48  9  6 35  1 36 23  7 61 16 59 39 38 30], a_shuffle_aclus: [ 63 108  96  76  75  27  90  64 100  37  35  15  17  82   8  58  48 109  89  41  85  67  62  71 102   4  70  78  34  61   5  93  60  50   2  16  73  54  69  51  21  59  57  14  88  19  31  24  28  33  97  84  49  74 107  25  26  98  11  68   7  86  92  36  66  13   9  52   3  53  32  10  83  23  81  56  55  45]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [14 39 68 23 29 53 38  6 32 18 10  5  1 28 15  2 51 63 45 71 34 62  8 56 12 70 59 40 67 47 17  9 64 57 58 42 73 65 49 50 27 16 41 30 60  4 72 21 35 11 75 77 13 54 19 74 25 76  0 44 55 33 37  3 52 69 43 48 66 46 26  7 22 61 24 36 31 20], a_shuffle_aclus: [ 19  56  92  32  41  71  55   9  49  25  14   8   3  37  21   4  69  85  62  97  51  84  11  75  16  96  81  57  90  64  24  13  86  76  78  59 100  88  67  68  36  23  58  45  82   7  98  28  52  15 107 109  17  73  26 102  34 108   2  61  74  50  54   5  70  93  60  66  89  63  35  10  31  83  33  53  48  27]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [67 17 30 59 73 63 23 62 33 70 10 72 35 18 45  4 31 38 37 43 75 12 58  9  5 50 53 21 14 47 32 77 20  2  7 66 25 74 54 52 46 26 27 39  6  3 48  1 40 24 49 22  8 36 15 60 61 68 65 56 28 13 51 57 69  0 16 64 41 76 42 29 11 44 71 19 55 34], a_shuffle_aclus: [ 90  24  45  81 100  85  32  84  50  96  14  98  52  25  62   7  48  55  54  60 107  16  78  13   8  68  71  28  19  64  49 109  27   4  10  89  34 102  73  70  63  35  36  56   9   5  66   3  57  33  67  31  11  53  21  82  83  92  88  75  37  17  69  76  93   2  23  86  58 108  59  41  15  61  97  26  74  51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [59 32 65 45 39 48 70  3 15 31 38 47 35 36 67 34 28 62 66  6 10 42 73 69 75 63 12 11 77 76 58 21 46  5 26 24 52 17 40 14 18 23  1  7 13 56  0 22 55 16 64 41  8 53 60 54 51 37  4 74 57 72 68  9 50 27 20 33 29 30 71 43  2 25 19 49 44 61], a_shuffle_aclus: [ 81  49  88  62  56  66  96   5  21  48  55  64  52  53  90  51  37  84  89   9  14  59 100  93 107  85  16  15 109 108  78  28  63   8  35  33  70  24  57  19  25  32   3  10  17  75   2  31  74  23  86  58  11  71  82  73  69  54   7 102  76  98  92  13  68  36  27  50  41  45  97  60   4  34  26  67  61  83]\n",
      "a_shuffle_IDXs: [76  4 36 28 63 41 19 75  0 34 20  1 24 71 47 66 23 26 15 22 37 64 16 12 44  8 29 40 13 25 55  6 14 65 45  5  3 70 61 35 51 10 57 60 39 53  9 50 17 74 49 42 62 58 56 30 48 69 73 43 68 52 59 54 31 33  7 18 21 38 77 72 67  2 27 32 46 11], a_shuffle_aclus: [108   7  53  37  85  58  26 107   2  51  27   3  33  97  64  89  32  35  21  31  54  86  23  16  61  11  41  57  17  34  74   9  19  88  62   8   5  96  83  52  69  14  76  82  56  71  13  68  24 102  67  59  84  78  75  45  66  93 100  60  92  70  81  73  48  50  10  25  28  55 109  98  90   4  36  49  63  15]\n",
      "a_shuffle_IDXs: [22  2 21 58 32 59 42 14 39 45 63  6 72 46 65 64  1  8 38 30 43  7 76 48 57 54 67 28 26 73 10 71 12 55 19 11 20 27  5 24 69 44 13 47 74 62  4 49  9 60 36 52 35 50 75 77 31 23 40 18 34 53 68 41  3 56 66 25 15 51 37  0 70 33 17 29 16 61], a_shuffle_aclus: [ 31   4  28  78  49  81  59  19  56  62  85   9  98  63  88  86   3  11  55  45  60  10 108  66  76  73  90  37  35 100  14  97  16  74  26  15  27  36   8  33  93  61  17  64 102  84   7  67  13  82  53  70  52  68 107 109  48  32  57  25  51  71  92  58   5  75  89  34  21  69  54   2  96  50  24  41  23  83]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [64 40  8 21 33 76 53  6 42 25  3 37 44 51  4 32 77 47 57 59 48 28 68 19 41 17 38 13 58 66 27 36 22 24 29 71 75  9 30 34 67 45 31 15 26 55 61 73 56 60  0 20 11 72 52 49 74  5 14 43 62 10 54 70  7 16  2 35 23 18  1 65 46 69 63 12 50 39], a_shuffle_aclus: [ 86  57  11  28  50 108  71   9  59  34   5  54  61  69   7  49 109  64  76  81  66  37  92  26  58  24  55  17  78  89  36  53  31  33  41  97 107  13  45  51  90  62  48  21  35  74  83 100  75  82   2  27  15  98  70  67 102   8  19  60  84  14  73  96  10  23   4  52  32  25   3  88  63  93  85  16  68  56]\n",
      "a_shuffle_IDXs: [42 66 64 63 38 76 27 74 57 41 31 40 54 39 29 61 20 73 58 75  8 24 67 17 46 19 62 10 36  3 34 28  9  7 44 32 37 11 35  6 53 43 30 47  1 25 22 70 26 15  2 68 21  5 60 23 14 16 55 12 51 71 69 65  4 59 48 45 72  0 49 56 18 33 13 50 52 77], a_shuffle_aclus: [ 59  89  86  85  55 108  36 102  76  58  48  57  73  56  41  83  27 100  78 107  11  33  90  24  63  26  84  14  53   5  51  37  13  10  61  49  54  15  52   9  71  60  45  64   3  34  31  96  35  21   4  92  28   8  82  32  19  23  74  16  69  97  93  88   7  81  66  62  98   2  67  75  25  50  17  68  70 109]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 8 27 43 41 23 54 63 30  9 61 28  3 77  2 73 42 50 74 38 37 51 72 71 44 26 64 36 17 18  7 46 34 19 68  0 11 60 12  5 21 56  4 48 53 49 47 62 57 65 31 29 69 76 33 22 25 32 59 13 16 52 45 75 14  1 20 39 67 15 58 35 55  6 24 10 70 66 40], a_shuffle_aclus: [ 11  36  60  58  32  73  85  45  13  83  37   5 109   4 100  59  68 102  55  54  69  98  97  61  35  86  53  24  25  10  63  51  26  92   2  15  82  16   8  28  75   7  66  71  67  64  84  76  88  48  41  93 108  50  31  34  49  81  17  23  70  62 107  19   3  27  56  90  21  78  52  74   9  33  14  96  89  57]\n",
      "a_shuffle_IDXs: [50 10 69  3 22 68 29 44 59 34  9 54 65 31 51 66 55 75 57 27 42 11 56 40 43 63 21 47 38  0  5 49 48 45 25 17 71 77 36 13 30  7 41 73 26 52 46 20 62 35  6  8 15  1 18 14 33 16 39  4 23  2 76 37 32 74 72 67 24 58 19 64 70 53 12 28 60 61], a_shuffle_aclus: [ 68  14  93   5  31  92  41  61  81  51  13  73  88  48  69  89  74 107  76  36  59  15  75  57  60  85  28  64  55   2   8  67  66  62  34  24  97 109  53  17  45  10  58 100  35  70  63  27  84  52   9  11  21   3  25  19  50  23  56   7  32   4 108  54  49 102  98  90  33  78  26  86  96  71  16  37  82  83]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [48 62 37 16  7 61 77 69 45 38 71 49 59  4 22 60 56 50 23  6 70 12  1  2  8 17 54 20 25 42 63 53 46 36 66 21 43  0 58 26 57  5 28 33 67 31 10 41 14  9 65 30 44 74 72 68 27 13 47 34 35 29 11 64 32 55  3 76 73 24 18 15 39 40 19 51 52 75], a_shuffle_aclus: [ 66  84  54  23  10  83 109  93  62  55  97  67  81   7  31  82  75  68  32   9  96  16   3   4  11  24  73  27  34  59  85  71  63  53  89  28  60   2  78  35  76   8  37  50  90  48  14  58  19  13  88  45  61 102  98  92  36  17  64  51  52  41  15  86  49  74   5 108 100  33  25  21  56  57  26  69  70 107]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [24 70 10 31 69  0 77 15 73 62 26 34 43 68  9 39 65 22 76 20 75  7 35 49 12 57 53 25 21 36 50 32 52 61 46 44 74 13 71 67 51  8 37 17 60 16 72  2 30 45 58 28 38 41 33 29 47  3 54 63 19 66 64 42 56 48  5 59 11  6 40 14  1  4 55 23 27 18], a_shuffle_aclus: [ 33  96  14  48  93   2 109  21 100  84  35  51  60  92  13  56  88  31 108  27 107  10  52  67  16  76  71  34  28  53  68  49  70  83  63  61 102  17  97  90  69  11  54  24  82  23  98   4  45  62  78  37  55  58  50  41  64   5  73  85  26  89  86  59  75  66   8  81  15   9  57  19   3   7  74  32  36  25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [21 65 60 59 22 10 40 44 11 13 54 67 31  4 36 35 76 34 48 47 62 32 39  8 33 50 73 23  9 55  5 24 53 18 17 63 45 57 64 75 12 26 49  2 70 68 58 41  7  1 74 19 16 28 42 71  3 30 69 37 77 25  6 14 46 52 29 51 38 43 27 15 72 66 20 61 56  0], a_shuffle_aclus: [ 28  88  82  81  31  14  57  61  15  17  73  90  48   7  53  52 108  51  66  64  84  49  56  11  50  68 100  32  13  74   8  33  71  25  24  85  62  76  86 107  16  35  67   4  96  92  78  58  10   3 102  26  23  37  59  97   5  45  93  54 109  34   9  19  63  70  41  69  55  60  36  21  98  89  27  83  75   2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [64 17  9 10 46  1 26 42 70  8 41 74 27  4 40 31 60 75 11 45 12  5 51 34 73 52 22 65 49 63 57 39 33 48 47  2 43 38 18 77 66 55 37 20 25 14  6 68 23 58 53 13 24  0 15 54 59 44 71 16 21 69 19 28 72  3 76 36 62 56 61 32 30 50 67  7 29 35], a_shuffle_aclus: [ 86  24  13  14  63   3  35  59  96  11  58 102  36   7  57  48  82 107  15  62  16   8  69  51 100  70  31  88  67  85  76  56  50  66  64   4  60  55  25 109  89  74  54  27  34  19   9  92  32  78  71  17  33   2  21  73  81  61  97  23  28  93  26  37  98   5 108  53  84  75  83  49  45  68  90  10  41  52]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 7  4 28 55 13 64 10 21 29 43 65 56  1 52 11 14  9 63 51 24 22 68 26 23 41 61 39 38 32 74 34 19  2 48 58 45 72  5 53 33 59 62 18 69 57 40 31 49 50  3  6 17 42 46 73 30 16 20 67  8 60 66 12 25 37  0 15 54 70 75 27 71 77 36 44 47 35 76], a_shuffle_aclus: [ 10   7  37  74  17  86  14  28  41  60  88  75   3  70  15  19  13  85  69  33  31  92  35  32  58  83  56  55  49 102  51  26   4  66  78  62  98   8  71  50  81  84  25  93  76  57  48  67  68   5   9  24  59  63 100  45  23  27  90  11  82  89  16  34  54   2  21  73  96 107  36  97 109  53  61  64  52 108]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 1 60 58 44 27 38 51 63 70  5  4  8 59 22 49 76 50 73 61 62  2 12  6 45 54 18 39 23 69 42  0 33 41 57 37 13 65 47 25 20 67 28 15 66 16 26 52 14 75 36 43  7 19 56 30 64 35 68 77 31 72 11 10 29 21 40 53 48 34 17 46  3 24 55 74 32  9 71], a_shuffle_aclus: [  3  82  78  61  36  55  69  85  96   8   7  11  81  31  67 108  68 100  83  84   4  16   9  62  73  25  56  32  93  59   2  50  58  76  54  17  88  64  34  27  90  37  21  89  23  35  70  19 107  53  60  10  26  75  45  86  52  92 109  48  98  15  14  41  28  57  71  66  51  24  63   5  33  74 102  49  13  97]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 3 75  2 64 25 10 46 56 18 50 16 42 37 36 38 62  6 66 49 28 14 19 22 13 26  1 58 41 52 71 44 72 48 20 17 76 57 27 40 32 23 33 59 70 65 67  4  7 61  8 15 51  9 53 54  0 45 43 21 35 73 63 47  5 30 68 24 55 29 12 77 34 39 69 31 11 74 60], a_shuffle_aclus: [  5 107   4  86  34  14  63  75  25  68  23  59  54  53  55  84   9  89  67  37  19  26  31  17  35   3  78  58  70  97  61  98  66  27  24 108  76  36  57  49  32  50  81  96  88  90   7  10  83  11  21  69  13  71  73   2  62  60  28  52 100  85  64   8  45  92  33  74  41  16 109  51  56  93  48  15 102  82]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [71 44 69 32 15 23 46  7 61 49 51 41 16 11 76 58 25 17 62  2 77 10 12 67  3  5 56 55  9 31 70 14  4 27 64 20 24 29  8 34 19 35  0 26 36 47 73 43 18 68 65 13 37 39 28 75 52 66 60  6 33 48 72 63 21 53  1 38 40 30 42 45 57 50 22 74 59 54], a_shuffle_aclus: [ 97  61  93  49  21  32  63  10  83  67  69  58  23  15 108  78  34  24  84   4 109  14  16  90   5   8  75  74  13  48  96  19   7  36  86  27  33  41  11  51  26  52   2  35  53  64 100  60  25  92  88  17  54  56  37 107  70  89  82   9  50  66  98  85  28  71   3  55  57  45  59  62  76  68  31 102  81  73]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [42 46 74 57 22 12 71 18 54 63  3 52  1 19 72 17 60 66 49  8 21 73 23 70 69 20 61 62 10  0 64 24 34  5 59 30 26 11  2 75 35  9 38 44 43 45 76 33 16  7 32 65 48 37 13 36 40 53 28 25 67 14 29 58 51 39 41 31 68  4 15 77  6 47 27 50 56 55], a_shuffle_aclus: [ 59  63 102  76  31  16  97  25  73  85   5  70   3  26  98  24  82  89  67  11  28 100  32  96  93  27  83  84  14   2  86  33  51   8  81  45  35  15   4 107  52  13  55  61  60  62 108  50  23  10  49  88  66  54  17  53  57  71  37  34  90  19  41  78  69  56  58  48  92   7  21 109   9  64  36  68  75  74]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [64 39 74 24 67 51 71 65 14 42 45 44 66 29  2 17  9  5 28 23 38 75 70 76 13 41  8  1 50 54  7 68 31 47 20 43 26  0 59 15 62 61 77 56  3 35 52 53 73 72 22 48 60 40 58 10 32 21 46 37 16 57 11 25 12  6 30 69 63 18 34 19  4 36 27 33 55 49], a_shuffle_aclus: [ 86  56 102  33  90  69  97  88  19  59  62  61  89  41   4  24  13   8  37  32  55 107  96 108  17  58  11   3  68  73  10  92  48  64  27  60  35   2  81  21  84  83 109  75   5  52  70  71 100  98  31  66  82  57  78  14  49  28  63  54  23  76  15  34  16   9  45  93  85  25  51  26   7  53  36  50  74  67]\n",
      "a_shuffle_IDXs: [58 22 73 31 26 15 32 69  8 55 38 21 53 75 61  7  9 43 18 70 56 45 46 17 71 76 14 67 64 74 49 65 10 60  6 16 24  1 52 51 34 19 48 13 23 11 33  2 41 30 59 12 50 25 44 66 77 63 36  3 35  4 28 47 27 62 39 40 29 20  5 37 54  0 68 57 42 72], a_shuffle_aclus: [ 78  31 100  48  35  21  49  93  11  74  55  28  71 107  83  10  13  60  25  96  75  62  63  24  97 108  19  90  86 102  67  88  14  82   9  23  33   3  70  69  51  26  66  17  32  15  50   4  58  45  81  16  68  34  61  89 109  85  53   5  52   7  37  64  36  84  56  57  41  27   8  54  73   2  92  76  59  98]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [46 42 54 26 76 58 31  9  2 52 23 50 22  6 17 44 30 18  7 37 77 21 14 43  5 51 28 67 68 60 38 32 36 55 66 47 12 70  0 72 65 45 20 71 63 33 74 73  3 11 75 19 64 69 53 16 62 57  1 56  8 13 10 34 15 41 35 25 39 59 49 29 27 24 48 61  4 40], a_shuffle_aclus: [ 63  59  73  35 108  78  48  13   4  70  32  68  31   9  24  61  45  25  10  54 109  28  19  60   8  69  37  90  92  82  55  49  53  74  89  64  16  96   2  98  88  62  27  97  85  50 102 100   5  15 107  26  86  93  71  23  84  76   3  75  11  17  14  51  21  58  52  34  56  81  67  41  36  33  66  83   7  57]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [55 24 65 13 53 26 68 29 73 35 56 60 57 77 12 47 67 45 30  3 28  2 18 76 48 36 44 46 74 51 38 42  4  0 69  1 34 20 64 27 37 43 40 21 23 66  8 72 49  9  6 41 11 61 52 70 17 71 32 25 10 31 39 14 58  5 33 15 50  7 19 63 22 54 16 62 75 59], a_shuffle_aclus: [ 74  33  88  17  71  35  92  41 100  52  75  82  76 109  16  64  90  62  45   5  37   4  25 108  66  53  61  63 102  69  55  59   7   2  93   3  51  27  86  36  54  60  57  28  32  89  11  98  67  13   9  58  15  83  70  96  24  97  49  34  14  48  56  19  78   8  50  21  68  10  26  85  31  73  23  84 107  81]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 4 68 71 38  7 43 25 12 10 63 59 11 53 70 42 55 24 34 45 14 26 33 46 36 73 41 21 69 58 48 35 76 52 29  3  6 49 61 47  9 39 13 22 18 65 44 15 28 64 75 19 32 50 72 31 74 57 66 51 16  8 20  5 40 27 60 77  0 62 67 56 30 17 54 37 23  2  1], a_shuffle_aclus: [  7  92  97  55  10  60  34  16  14  85  81  15  71  96  59  74  33  51  62  19  35  50  63  53 100  58  28  93  78  66  52 108  70  41   5   9  67  83  64  13  56  17  31  25  88  61  21  37  86 107  26  49  68  98  48 102  76  89  69  23  11  27   8  57  36  82 109   2  84  90  75  45  24  73  54  32   4   3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [52 36 72 54 65 25  2 23 71 22 32 57 19 27 53  9 31 75 43 44 67 11 42  3 41 66  0 18 35 46 68  4 49 47 69 39 56 34 73 30 28 50  5 21  6 48 17 45 20 15 38 76 16 60 59 14 74 77 58 70  1 10 55  8 13 37 63 24 64 62 40  7 51 33 29 12 61 26], a_shuffle_aclus: [ 70  53  98  73  88  34   4  32  97  31  49  76  26  36  71  13  48 107  60  61  90  15  59   5  58  89   2  25  52  63  92   7  67  64  93  56  75  51 100  45  37  68   8  28   9  66  24  62  27  21  55 108  23  82  81  19 102 109  78  96   3  14  74  11  17  54  85  33  86  84  57  10  69  50  41  16  83  35]\n",
      "a_shuffle_IDXs: [ 7 75 15 28 19  3 36 44  6 56 12 69 14 60 34 43 77 27 71 29 23 70 31 57 54 49 18 66 41 64 67  8 51 11 52 26 33 32 59 25 39 30  4 65 42 61 48 72 21 47 55 22 38 37 13  0 68  1  2 50 45 24 17 16 62 73 40 53  5 58 74 35 20 10 76 46  9 63], a_shuffle_aclus: [ 10 107  21  37  26   5  53  61   9  75  16  93  19  82  51  60 109  36  97  41  32  96  48  76  73  67  25  89  58  86  90  11  69  15  70  35  50  49  81  34  56  45   7  88  59  83  66  98  28  64  74  31  55  54  17   2  92   3   4  68  62  33  24  23  84 100  57  71   8  78 102  52  27  14 108  63  13  85]\n",
      "a_shuffle_IDXs: [ 6 71 76 36 65 50 26 45  9 73 37 29 74 56 51 27 18 16 31 43 42 28 60 30 44 70 14 55 53 34 46 23  8  3 20  1 35 59 64 13 21 11 77 40 61  2 33 10 58 49 24 48 72 17 69 32  5 15 57  0 54 47 68  7 39 75 52 62 66 67 12 38 19  4 25 63 22 41], a_shuffle_aclus: [  9  97 108  53  88  68  35  62  13 100  54  41 102  75  69  36  25  23  48  60  59  37  82  45  61  96  19  74  71  51  63  32  11   5  27   3  52  81  86  17  28  15 109  57  83   4  50  14  78  67  33  66  98  24  93  49   8  21  76   2  73  64  92  10  56 107  70  84  89  90  16  55  26   7  34  85  31  58]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [44 57  1 34 27 37 77 17 36 38 59 26 65 55 28 25 64 11 29 72 43 63 56 42 18 41 39 75 23 69 74  7 52 47 62 48  6 68 49 12 20 70 30  3 22 40 15 53 46  9 51 32 67 71  5 45 54  4 50 60 73 66 76 61 14 19 33  2 35 10 31 21  8  0 16 58 13 24], a_shuffle_aclus: [ 61  76   3  51  36  54 109  24  53  55  81  35  88  74  37  34  86  15  41  98  60  85  75  59  25  58  56 107  32  93 102  10  70  64  84  66   9  92  67  16  27  96  45   5  31  57  21  71  63  13  69  49  90  97   8  62  73   7  68  82 100  89 108  83  19  26  50   4  52  14  48  28  11   2  23  78  17  33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [18 51 70 22 54 30 55  5 14 73 21 60  0 69 26 16 61 43  7 72 32 24 27 34 75  9 41 28 17  8 39 20  2 63  4 67 77 42 50 31 47 15 19 56 25 58 35 76 36  6 13 10 71  3 40 45 65 37 66 29 64 11 33 68 46 23 62 59 38 53 44 12 48 57 52 49  1 74], a_shuffle_aclus: [ 25  69  96  31  73  45  74   8  19 100  28  82   2  93  35  23  83  60  10  98  49  33  36  51 107  13  58  37  24  11  56  27   4  85   7  90 109  59  68  48  64  21  26  75  34  78  52 108  53   9  17  14  97   5  57  62  88  54  89  41  86  15  50  92  63  32  84  81  55  71  61  16  66  76  70  67   3 102]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [47 24 14  0 40 73  7 31 46  1 76 33  5 30 77 43 64 23 63 37 36 74 44 32 18 53 66 52 48 20 11 61 19 12 13 10 69 49 55 71 27  4 51 70  2 39 21 58  6 25 41 50 57 15 62 38 72 34 26 68 16 29 59 17 35 56 65 22 60  3 42 54  9 67  8 75 28 45], a_shuffle_aclus: [ 64  33  19   2  57 100  10  48  63   3 108  50   8  45 109  60  86  32  85  54  53 102  61  49  25  71  89  70  66  27  15  83  26  16  17  14  93  67  74  97  36   7  69  96   4  56  28  78   9  34  58  68  76  21  84  55  98  51  35  92  23  41  81  24  52  75  88  31  82   5  59  73  13  90  11 107  37  62]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 0 55 46 21 32 70 54 31  1 24 69 41 62 18 47 38 44 56 75 74 57 36 58 59 19 25 60 68 77 40 67 10 61  9 35 43  8  3  6 11 64 51 14 73 66 39 23 63 26 13 53 34 30 15  7  5 37 22 16 76 72 42 50 27 17 20  4 12 71 49 48 29 45 28  2 52 65 33], a_shuffle_aclus: [  2  74  63  28  49  96  73  48   3  33  93  58  84  25  64  55  61  75 107 102  76  53  78  81  26  34  82  92 109  57  90  14  83  13  52  60  11   5   9  15  86  69  19 100  89  56  32  85  35  17  71  51  45  21  10   8  54  31  23 108  98  59  68  36  24  27   7  16  97  67  66  41  62  37   4  70  88  50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [31 46  3 72 23 20 25  2 52 29 40 77 61 21 73 42 54 28 76 30 47 57 38 75 24 53 48 67 17 18  4 14 65 68 62 13 63 74 15 10 33  6 41 11 39 49 16 19 12  0 55 51 27 71  1 37 44 22  5 32  7 60 59 64 66 43 50 26 58 36 70 69 35 34  8  9 56 45], a_shuffle_aclus: [ 48  63   5  98  32  27  34   4  70  41  57 109  83  28 100  59  73  37 108  45  64  76  55 107  33  71  66  90  24  25   7  19  88  92  84  17  85 102  21  14  50   9  58  15  56  67  23  26  16   2  74  69  36  97   3  54  61  31   8  49  10  82  81  86  89  60  68  35  78  53  96  93  52  51  11  13  75  62]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [35 12 21 27 67  8 19 73 71 64 65 39  5 41 55 47 22 38 61 34 69 24 77 74 42 48 20 56 72 18 14 63 16 30 36 33 11 68 25 43 51 28 37 50 49 29  2  0 10 44 62 23 57  6 54 58 45 60 46  4 70 26 17 13 32 40 66 75 31  7  1 59 52  9 53 76  3 15], a_shuffle_aclus: [ 52  16  28  36  90  11  26 100  97  86  88  56   8  58  74  64  31  55  83  51  93  33 109 102  59  66  27  75  98  25  19  85  23  45  53  50  15  92  34  60  69  37  54  68  67  41   4   2  14  61  84  32  76   9  73  78  62  82  63   7  96  35  24  17  49  57  89 107  48  10   3  81  70  13  71 108   5  21]\n",
      "a_shuffle_IDXs: [66 52 53 57 31 40 28  3  4 16 61 25  7 45 21 42 39  6 19 38 12 77 30 48 63 10 11 65 73 33  0 43 36 54 15 49  9 41 13 22 47 76 64 58 26 27  8 18 14 56 60 46 74 67 44 70 72 20 50  1 75 34  5 17 37 23 69 71 59 32 51 24 68 62 55 35  2 29], a_shuffle_aclus: [ 89  70  71  76  48  57  37   5   7  23  83  34  10  62  28  59  56   9  26  55  16 109  45  66  85  14  15  88 100  50   2  60  53  73  21  67  13  58  17  31  64 108  86  78  35  36  11  25  19  75  82  63 102  90  61  96  98  27  68   3 107  51   8  24  54  32  93  97  81  49  69  33  92  84  74  52   4  41]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [59 61 32 53 27 13 29 75 77 36  7 37 28 20 49 31 58 64 52 72 10 57  6 16 38 21 30 11 48 71 34 25 47 60 19 23  1 62 43  2 44 50 22 74 76 73  3  9 12 51  5 42 55 54 45 14 67 26  8 41 46 70 66 39  4 40 15 69 68 33 24 35 63 17 65  0 18 56], a_shuffle_aclus: [ 81  83  49  71  36  17  41 107 109  53  10  54  37  27  67  48  78  86  70  98  14  76   9  23  55  28  45  15  66  97  51  34  64  82  26  32   3  84  60   4  61  68  31 102 108 100   5  13  16  69   8  59  74  73  62  19  90  35  11  58  63  96  89  56   7  57  21  93  92  50  33  52  85  24  88   2  25  75]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [18 76 77 72 46 70 42 66 35 55 11 74 12 52 40 15 17 10  7 25 71 39 30 13 37 27 31 58 63 38  8 48  6 33 29 26 21 19 67 57  5 50 28 20  2 49  1 59 75  3 44 62 53 34  4 41 45 51 22 32 23 43 60 68  9 14 36 64 65  0 56 73 47 61 16 69 54 24], a_shuffle_aclus: [ 25 108 109  98  63  96  59  89  52  74  15 102  16  70  57  21  24  14  10  34  97  56  45  17  54  36  48  78  85  55  11  66   9  50  41  35  28  26  90  76   8  68  37  27   4  67   3  81 107   5  61  84  71  51   7  58  62  69  31  49  32  60  82  92  13  19  53  86  88   2  75 100  64  83  23  93  73  33]\n",
      "a_shuffle_IDXs: [56 59 35  8 40 65 18 50 74 52 39 67 77  1 64 55 68 61 76 25  2 66  3 42 28  0 62 49 27 38  9 20 48 51 17 10 21 44 73 29 15  7 12 43 63 37 30 32 46 72 54 31 58 71 13 47 19 23 57 69 36  5 14 33  6 24  4 26 60 45 70 22 53 16 75 34 11 41], a_shuffle_aclus: [ 75  81  52  11  57  88  25  68 102  70  56  90 109   3  86  74  92  83 108  34   4  89   5  59  37   2  84  67  36  55  13  27  66  69  24  14  28  61 100  41  21  10  16  60  85  54  45  49  63  98  73  48  78  97  17  64  26  32  76  93  53   8  19  50   9  33   7  35  82  62  96  31  71  23 107  51  15  58]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [11 64 75 21  6  5 12 10 55 50 65  1 45 27 41 25 29 63 23 34 76 37 16 71 77 35  7 52 28 40 47 62  2 32 53 68 24 44 66 58 20 31 57 15  0 73 67 43 17 39 36 54 69 74 61  8 38 59  9 33 14 13 60  4 46 48 18 72  3 70 22 26 56 30 51 19 42 49], a_shuffle_aclus: [ 15  86 107  28   9   8  16  14  74  68  88   3  62  36  58  34  41  85  32  51 108  54  23  97 109  52  10  70  37  57  64  84   4  49  71  92  33  61  89  78  27  48  76  21   2 100  90  60  24  56  53  73  93 102  83  11  55  81  13  50  19  17  82   7  63  66  25  98   5  96  31  35  75  45  69  26  59  67]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [27 28  5 35  2 36 24  8 47 64 15 69 71 11 75 55 29 43 53 31 17 49 41 20 22 40 72 25 74 62  1 76 63 44 65  9 46 52 70 30 66 45 32 34  0 39 12 77 51 58 73 54 61  7 38 26 37  4 13 68 21 67 19 42 33 59 50  3 14 60 10 48  6 56 18 16 57 23], a_shuffle_aclus: [ 36  37   8  52   4  53  33  11  64  86  21  93  97  15 107  74  41  60  71  48  24  67  58  27  31  57  98  34 102  84   3 108  85  61  88  13  63  70  96  45  89  62  49  51   2  56  16 109  69  78 100  73  83  10  55  35  54   7  17  92  28  90  26  59  50  81  68   5  19  82  14  66   9  75  25  23  76  32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [47  7 28 63 72 37  6 49  5 25 70 40 44  9 48 74 50 29 61 34  2 21 11  4 57 46 54 10 22 38  3 14 19 23 35 69 65 42 41 56 15 16 64 39 45 18 51 31 60 27 58 12 71 33  8 32 77 67 53 30  0 76 66  1 68 13 59 17 26 52 55 62 43 36 20 75 73 24], a_shuffle_aclus: [ 64  10  37  85  98  54   9  67   8  34  96  57  61  13  66 102  68  41  83  51   4  28  15   7  76  63  73  14  31  55   5  19  26  32  52  93  88  59  58  75  21  23  86  56  62  25  69  48  82  36  78  16  97  50  11  49 109  90  71  45   2 108  89   3  92  17  81  24  35  70  74  84  60  53  27 107 100  33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 3 27 54 65 31  2 22 64 62 53 10 36 17 32 44  6 50  1  9 25 41 59 40 43 30 24 28 75 45 39 73 77 49 42 72 19  8 61 57 29 34 26 23 38 71 18 58 21 56 66 70 37 76 13 33 69 16 60  0 55 48 11 46  5 68 12 35 47 15 20 51 74 63 52 14  7 67  4], a_shuffle_aclus: [  5  36  73  88  48   4  31  86  84  71  14  53  24  49  61   9  68   3  13  34  58  81  57  60  45  33  37 107  62  56 100 109  67  59  98  26  11  83  76  41  51  35  32  55  97  25  78  28  75  89  96  54 108  17  50  93  23  82   2  74  66  15  63   8  92  16  52  64  21  27  69 102  85  70  19  10  90   7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 4 37 70 76 63 48 56 69  3 65 20 71 13  1  0 29 17 53 73 59 32 49 21 74 58 47 57 68 18 77 54 31 25 51 45 10 12 42  7  9 24 26 62 60 33 27 66 39 50  6  5 23 44 22 52 64 19 28 40 38 16 41 15 36 14  2 35 75 55 72 61  8 11 46 34 30 43 67], a_shuffle_aclus: [  7  54  96 108  85  66  75  93   5  88  27  97  17   3   2  41  24  71 100  81  49  67  28 102  78  64  76  92  25 109  73  48  34  69  62  14  16  59  10  13  33  35  84  82  50  36  89  56  68   9   8  32  61  31  70  86  26  37  57  55  23  58  21  53  19   4  52 107  74  98  83  11  15  63  51  45  60  90]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [11 55 48  3 30 51 23 18 12 32 25 57 16  6 54 22 66  4  0  2 53 10  7 21 64 67 28 75 27  5 45 68 77 49 71 29 20  1 52 62 26 74 61 15 59 44 17 69 70 56 13 76  9 41 39 47 42 58 36 65 37 43 63 72 14 34 60  8 33 31 24 35 38 19 40 50 46 73], a_shuffle_aclus: [ 15  74  66   5  45  69  32  25  16  49  34  76  23   9  73  31  89   7   2   4  71  14  10  28  86  90  37 107  36   8  62  92 109  67  97  41  27   3  70  84  35 102  83  21  81  61  24  93  96  75  17 108  13  58  56  64  59  78  53  88  54  60  85  98  19  51  82  11  50  48  33  52  55  26  57  68  63 100]\n",
      "a_shuffle_IDXs: [75 15  3 16 59 55 68 45 11 27 20 53  8 70 76 12 35 48 44 43 32 60 66 37 38 69 34 24  9  7 28 25 29 61 23 36 67 19  0 39 58 17  1 18 56 71  5 63  4 31 21 72 40 73 26 14 10 54 46 41 33 42 51 47 64 22 52 62 49 74 13  6 77 57 30  2 50 65], a_shuffle_aclus: [107  21   5  23  81  74  92  62  15  36  27  71  11  96 108  16  52  66  61  60  49  82  89  54  55  93  51  33  13  10  37  34  41  83  32  53  90  26   2  56  78  24   3  25  75  97   8  85   7  48  28  98  57 100  35  19  14  73  63  58  50  59  69  64  86  31  70  84  67 102  17   9 109  76  45   4  68  88]\n",
      "a_shuffle_IDXs: [ 0 67 63 77 28 70 55 36 71 47  8 11 51 46 68 37 56 22 19 75 42 69 40 50  3 10 48 21 15 66  6 64 26 58 45 59 18 52 38  7 73 43 30 27 74 49  5 60 32  2 23 61 34 57 29 62  4 41 20 16 12  1 53 54 76 24  9 72 35 25 39 13 65 33 44 31 14 17], a_shuffle_aclus: [  2  90  85 109  37  96  74  53  97  64  11  15  69  63  92  54  75  31  26 107  59  93  57  68   5  14  66  28  21  89   9  86  35  78  62  81  25  70  55  10 100  60  45  36 102  67   8  82  49   4  32  83  51  76  41  84   7  58  27  23  16   3  71  73 108  33  13  98  52  34  56  17  88  50  61  48  19  24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [16 68 36 45 11  4 32 41 69 43 76 34 56 21 63  0 49 30 22  5 42 73 15 64 18 62 54  1  6 71  2 72 33 28 29 53 57 38 40 52 58 24 23 46 44 61 13 51 12 70  8 35 47 50 14 19  9 25 31 17 37 55 65 74 26  3 27 20 48 67 10 59 60 75 77 66  7 39], a_shuffle_aclus: [ 23  92  53  62  15   7  49  58  93  60 108  51  75  28  85   2  67  45  31   8  59 100  21  86  25  84  73   3   9  97   4  98  50  37  41  71  76  55  57  70  78  33  32  63  61  83  17  69  16  96  11  52  64  68  19  26  13  34  48  24  54  74  88 102  35   5  36  27  66  90  14  81  82 107 109  89  10  56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [52  7 28 20 48  6 53 26 61  4 29 43 68  8 11 37 56 74 72 33 70 27 24 49 16 76 40 67 17 44  3 75  9 60 14 15 39 63 65 51 73 55 38 47 41 45 19 12 54 64 35 22 30 66 57 42 21  2 46 69  5  1 59 71 50 23 77 25 13 36  0 32 58 10 34 31 62 18], a_shuffle_aclus: [ 70  10  37  27  66   9  71  35  83   7  41  60  92  11  15  54  75 102  98  50  96  36  33  67  23 108  57  90  24  61   5 107  13  82  19  21  56  85  88  69 100  74  55  64  58  62  26  16  73  86  52  31  45  89  76  59  28   4  63  93   8   3  81  97  68  32 109  34  17  53   2  49  78  14  51  48  84  25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [76 63 36  7 17 49 46 12  4 74 13 69 26 29 32 65 42 15 27 64 77 75 72 25 39 56 66 41  6 24 37 67 35 58 31  1 44 11  8 19 20 57 59 28 45 34 50 54 43  5 33 62 23 48 18 73 21 10 47 68 16 70 14 38 51 53 30 52 55 22 71  9 60 40  2  0  3 61], a_shuffle_aclus: [108  85  53  10  24  67  63  16   7 102  17  93  35  41  49  88  59  21  36  86 109 107  98  34  56  75  89  58   9  33  54  90  52  78  48   3  61  15  11  26  27  76  81  37  62  51  68  73  60   8  50  84  32  66  25 100  28  14  64  92  23  96  19  55  69  71  45  70  74  31  97  13  82  57   4   2   5  83]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [60 39 35 40 73 33 48 11 72 56 69 22 53 51 12 71 44 58 16  8 76 24 19 26  5 13 45 10 61 42 18 75 43 59 63 65 52 32  6  3 66 15  7 70  0  4 36 34 30 47 31 64 77 21 46 55 28  1 62 57 49 38 14 67 25 37  2 27 29 50 68 17 20 74 41 23 54  9], a_shuffle_aclus: [ 82  56  52  57 100  50  66  15  98  75  93  31  71  69  16  97  61  78  23  11 108  33  26  35   8  17  62  14  83  59  25 107  60  81  85  88  70  49   9   5  89  21  10  96   2   7  53  51  45  64  48  86 109  28  63  74  37   3  84  76  67  55  19  90  34  54   4  36  41  68  92  24  27 102  58  32  73  13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 2 25 26 21 20 48  0 61 28 70 27 34 66 24 75 16  7 44 38 31  9 54 60 71 39 69 35 15 73 18 37 32 57 53  8 17 65  4 59 76 41 77 45 46  1 22  3 52 40 50 12 36 33 14 30 63 55 13 74 10 43 11 56 47 49 29 58 42 67 64 51 23  5  6 72 19 62 68], a_shuffle_aclus: [  4  34  35  28  27  66   2  83  37  96  36  51  89  33 107  23  10  61  55  48  13  73  82  97  56  93  52  21 100  25  54  49  76  71  11  24  88   7  81 108  58 109  62  63   3  31   5  70  57  68  16  53  50  19  45  85  74  17 102  14  60  15  75  64  67  41  78  59  90  86  69  32   8   9  98  26  84  92]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [14 33 47  7 38 54 64 10 57 44 48 70 27 25 46 35 63 21 23 72 24 37  6 61 75 36 77 67 40 49  3  5 74 11 13 65 51 76 19 60 52 58  8 69 17 73 50 59 39 30  1 18 68 12 28 71 26 29 62 20 66  0 43  4 53 34  2 31 15 56 32 55  9 45 16 22 42 41], a_shuffle_aclus: [ 19  50  64  10  55  73  86  14  76  61  66  96  36  34  63  52  85  28  32  98  33  54   9  83 107  53 109  90  57  67   5   8 102  15  17  88  69 108  26  82  70  78  11  93  24 100  68  81  56  45   3  25  92  16  37  97  35  41  84  27  89   2  60   7  71  51   4  48  21  75  49  74  13  62  23  31  59  58]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [28 21 52 44 33 10 17 47 56 45 34 36 32 57 51  5 49 19 72 59 73 75 58 26 14 38 22 70  1 66 12 42 39 65 20 16 62 35 37  7 69 13 11  4  3 15 29 61 40 68 74 64 53 67  6 23 43  8  0 27 25 71  2 48 46 60  9 24 18 55 30 76 50 63 77 41 54 31], a_shuffle_aclus: [ 37  28  70  61  50  14  24  64  75  62  51  53  49  76  69   8  67  26  98  81 100 107  78  35  19  55  31  96   3  89  16  59  56  88  27  23  84  52  54  10  93  17  15   7   5  21  41  83  57  92 102  86  71  90   9  32  60  11   2  36  34  97   4  66  63  82  13  33  25  74  45 108  68  85 109  58  73  48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [74 56 35 16 57 70 29 69 41 18 19 33 51 63 64 22 62 15 26 27 36 47 58 61  6 54 75 72 55 59 43 24 60 42 67 13 30 48 76 44 38  4 10 20 52  3 14 37 21 65 17 50 77 34 45 23 66 73  1 11  7 32 49 25  0  8 68  9  5 71 12  2 40 46 31 39 28 53], a_shuffle_aclus: [102  75  52  23  76  96  41  93  58  25  26  50  69  85  86  31  84  21  35  36  53  64  78  83   9  73 107  98  74  81  60  33  82  59  90  17  45  66 108  61  55   7  14  27  70   5  19  54  28  88  24  68 109  51  62  32  89 100   3  15  10  49  67  34   2  11  92  13   8  97  16   4  57  63  48  56  37  71]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 8 51  5 38 30 70 42 76 16 65 68 45 67 61 47 41 72  3  7 62 32 55 56 60 19 26 35 39 63 25 69 17 49  6 46 15 59  1 14  9  4 21 33 54 53 31 13 18 58 20 27 66 10 74 22 29 11 40 23 28 48 37  0 64 12 52 77 57 44 24 75 50 71 43  2 34 36 73], a_shuffle_aclus: [ 11  69   8  55  45  96  59 108  23  88  92  62  90  83  64  58  98   5  10  84  49  74  75  82  26  35  52  56  85  34  93  24  67   9  63  21  81   3  19  13   7  28  50  73  71  48  17  25  78  27  36  89  14 102  31  41  15  57  32  37  66  54   2  86  16  70 109  76  61  33 107  68  97  60   4  51  53 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [42 35 15 71 38 67  6 75 23 13 72 28 11 34 64 59 55 24 66 50 45 22 18 73 36 47 61 43 62 70 53 25 30 74 65 54 14 68 31 29 20 69  2 12 51  9 40 63 48 33 19 76 39 27 10 41 52 21  3 60  0 57 77 32  5 37 17 44 56  4 26  1  8 16 46 58  7 49], a_shuffle_aclus: [ 59  52  21  97  55  90   9 107  32  17  98  37  15  51  86  81  74  33  89  68  62  31  25 100  53  64  83  60  84  96  71  34  45 102  88  73  19  92  48  41  27  93   4  16  69  13  57  85  66  50  26 108  56  36  14  58  70  28   5  82   2  76 109  49   8  54  24  61  75   7  35   3  11  23  63  78  10  67]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [12 59 35 58 17 45 28 75 61 23 20 70 57 53 67  5 51 39 56 34 74  6 60 63 76 40 65 26 11 64 24 46 54 68 73 43  0 30 38 29 48 62 49 13 15  8  4 41 36 69 19  1 18 37 55 47 66 71 72 16 32 42 10  3 25 21  7 77  2 22 14  9 31 44 27 33 50 52], a_shuffle_aclus: [ 16  81  52  78  24  62  37 107  83  32  27  96  76  71  90   8  69  56  75  51 102   9  82  85 108  57  88  35  15  86  33  63  73  92 100  60   2  45  55  41  66  84  67  17  21  11   7  58  53  93  26   3  25  54  74  64  89  97  98  23  49  59  14   5  34  28  10 109   4  31  19  13  48  61  36  50  68  70]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [70 17 41 76 73  2 19 55 53 15 14 75  1 39 13 30 48  8 64 72 40 37 26 36 77  9 10 22 50 31 69 46 21 34 56 43 54 67 33  0  4  7 11 60 57 23 16 25 45 35 32 24 68 59  3 71  6 42 62 28 20 65 61 18 44 29 49 51 12 27  5 63 52 58 66 74 38 47], a_shuffle_aclus: [ 96  24  58 108 100   4  26  74  71  21  19 107   3  56  17  45  66  11  86  98  57  54  35  53 109  13  14  31  68  48  93  63  28  51  75  60  73  90  50   2   7  10  15  82  76  32  23  34  62  52  49  33  92  81   5  97   9  59  84  37  27  88  83  25  61  41  67  69  16  36   8  85  70  78  89 102  55  64]\n",
      "a_shuffle_IDXs: [67 43 52 77 70 12  5 49 23 54  2 22 37 66  1 31  6 55  9 30 38 13 21 63 15 39 72 29 41 60 73  3 19  8 57 42 68 45 75 36 28  4 56 76 50 14  0 17 33 48 26 34 58 53 59  7 40 47 25 27 32 61 51 69 44 74 24 16 11 46 20 35 62 10 71 18 64 65], a_shuffle_aclus: [ 90  60  70 109  96  16   8  67  32  73   4  31  54  89   3  48   9  74  13  45  55  17  28  85  21  56  98  41  58  82 100   5  26  11  76  59  92  62 107  53  37   7  75 108  68  19   2  24  50  66  35  51  78  71  81  10  57  64  34  36  49  83  69  93  61 102  33  23  15  63  27  52  84  14  97  25  86  88]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [57 10 13 24 67 64 14 58 40 39 12 27  0  2 19 69 56  4 53 51 41 75 29 31 70  8 25 20 35 43 32 55 17 54 26 59 47  5 60 72 36 45  9 33  7  3 42 23 74 63 71 22 65 77 50  6 21 61 37 30 38 62 11  1 68 73 18 52 28 34 66 46 48 49 44 76 15 16], a_shuffle_aclus: [ 76  14  17  33  90  86  19  78  57  56  16  36   2   4  26  93  75   7  71  69  58 107  41  48  96  11  34  27  52  60  49  74  24  73  35  81  64   8  82  98  53  62  13  50  10   5  59  32 102  85  97  31  88 109  68   9  28  83  54  45  55  84  15   3  92 100  25  70  37  51  89  63  66  67  61 108  21  23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [51 77 67 27 24 12 10 65  6 56 59 41 29 42 45 70 43 54 17 11 75 57 35 19  2 40 33 68 49 69 38 61  1 64 58 16 21 48 30 36 23 44 72 39 32 26 34 52  3 62 20 55 63 53 47 31 15  9  5 76 14 37  7 46 18 73  0 22 28 50 13 25 74 60  8 71  4 66], a_shuffle_aclus: [ 69 109  90  36  33  16  14  88   9  75  81  58  41  59  62  96  60  73  24  15 107  76  52  26   4  57  50  92  67  93  55  83   3  86  78  23  28  66  45  53  32  61  98  56  49  35  51  70   5  84  27  74  85  71  64  48  21  13   8 108  19  54  10  63  25 100   2  31  37  68  17  34 102  82  11  97   7  89]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [48 17 58 43 12 44 49 31 74 10 20 15 22  0  6 75  1 62 70 56 23 71 69  5 59 41 24 14 36 27  4 57  7 55 42 68 60 76 61 77 64 40 37 46 54 34 11 26 66 30 63 18 13 53 29 52 65 72  9 38 21  3 32 28 50 45 51 33 47 16 35 39  2 25 19 73  8 67], a_shuffle_aclus: [ 66  24  78  60  16  61  67  48 102  14  27  21  31   2   9 107   3  84  96  75  32  97  93   8  81  58  33  19  53  36   7  76  10  74  59  92  82 108  83 109  86  57  54  63  73  51  15  35  89  45  85  25  17  71  41  70  88  98  13  55  28   5  49  37  68  62  69  50  64  23  52  56   4  34  26 100  11  90]\n",
      "a_shuffle_IDXs: [40 56 74 16 51 55 44 34 35 13  0 58 27 59 46 36 62 26 73 10 68 63 30  7  2  9 54 64 22 32 24 20 67  3 53 15 47 43 57 70 50 14 31 28 66  4 41 75 65 12 17 52  5 19 39 48  8 23 11  6 38 25 42 18 37 45 61 60 33  1 21 49 77 72 29 76 69 71], a_shuffle_aclus: [ 57  75 102  23  69  74  61  51  52  17   2  78  36  81  63  53  84  35 100  14  92  85  45  10   4  13  73  86  31  49  33  27  90   5  71  21  64  60  76  96  68  19  48  37  89   7  58 107  88  16  24  70   8  26  56  66  11  32  15   9  55  34  59  25  54  62  83  82  50   3  28  67 109  98  41 108  93  97]\n",
      "a_shuffle_IDXs: [73 76 55 56 17 37 22 10 27 35 63 77 60 74  2 30 26 50 43 16 18 38 39 19 62 59  6 28 13  8  4 29 40 23 42 58 36 69 67 57 54 66 34 14 25 46 48 53 41 31 52 61 65 71 32 11 12 64 75  0 45  1 20 68  9 44  5 72 33 24 21 70  3  7 15 49 47 51], a_shuffle_aclus: [100 108  74  75  24  54  31  14  36  52  85 109  82 102   4  45  35  68  60  23  25  55  56  26  84  81   9  37  17  11   7  41  57  32  59  78  53  93  90  76  73  89  51  19  34  63  66  71  58  48  70  83  88  97  49  15  16  86 107   2  62   3  27  92  13  61   8  98  50  33  28  96   5  10  21  67  64  69]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [31 68 38 42  6 17 19 69 41 24 55 77 51 50 62 44 47 74 22 36 33 60 25 76 29 70 59 46 58 66 48 67  7 49 71 23 53 15 16 28  0 43 61  3 14 20 52  2 35 72  1  8 11 18  5 10 39 12 54 57 21 56 63 40 27 26 73 30 34 65 45 13  4 32 64 37 75  9], a_shuffle_aclus: [ 48  92  55  59   9  24  26  93  58  33  74 109  69  68  84  61  64 102  31  53  50  82  34 108  41  96  81  63  78  89  66  90  10  67  97  32  71  21  23  37   2  60  83   5  19  27  70   4  52  98   3  11  15  25   8  14  56  16  73  76  28  75  85  57  36  35 100  45  51  88  62  17   7  49  86  54 107  13]\n",
      "a_shuffle_IDXs: [21 51 55 72  4 15 35 22 37 59 17 23 14  3 10 20 46 58 11 76 49 52 69  7 53 19 56 38 45 34  2 44 33 50 27 41  9 70 63 26  6 65 62 18 36  0 25 75 40 12 16 31 77 29 13 74 43 60 39 42  8 47 71 67  1 64 30 48  5 24 54 66 28 32 73 61 57 68], a_shuffle_aclus: [ 28  69  74  98   7  21  52  31  54  81  24  32  19   5  14  27  63  78  15 108  67  70  93  10  71  26  75  55  62  51   4  61  50  68  36  58  13  96  85  35   9  88  84  25  53   2  34 107  57  16  23  48 109  41  17 102  60  82  56  59  11  64  97  90   3  86  45  66   8  33  73  89  37  49 100  83  76  92]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [51  2 43 25 45 57 75 21 24 69 38 77  7  9 67 76 61 33 14 60 71 15 16 53 41 22 34 18  5 48 58 31 72 73 36 23 37 17 10 11 68 19 55  3 20 28 13 26 12 49 29 40 50 54 74 70 62  6 52 46 65 59 47 44 39 42 63 56  1 30  0 35 27 64 32 66  8  4], a_shuffle_aclus: [ 69   4  60  34  62  76 107  28  33  93  55 109  10  13  90 108  83  50  19  82  97  21  23  71  58  31  51  25   8  66  78  48  98 100  53  32  54  24  14  15  92  26  74   5  27  37  17  35  16  67  41  57  68  73 102  96  84   9  70  63  88  81  64  61  56  59  85  75   3  45   2  52  36  86  49  89  11   7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [50 57  0 53 24 19 31  4  8 20  7 36 33 58 23 10 43 74 40 17 37 46 42 32 30 18  5 68 12  1 66 56 75 69 26  3 55 27 13 49 41  2 76 51 65 22 28 45 72 25 70 61 77 11 34 21 64 47 38 59 52 48 54 60 39 15  9 71 62 63 16 29  6 67 14 44 73 35], a_shuffle_aclus: [ 68  76   2  71  33  26  48   7  11  27  10  53  50  78  32  14  60 102  57  24  54  63  59  49  45  25   8  92  16   3  89  75 107  93  35   5  74  36  17  67  58   4 108  69  88  31  37  62  98  34  96  83 109  15  51  28  86  64  55  81  70  66  73  82  56  21  13  97  84  85  23  41   9  90  19  61 100  52]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [30 69 46 39 74 64 21  3 47 65 52 51  8 28 36 55 63 73 50 72 45 34 20 49 24 13 32 33  7 22 26 23 41 57 54 29 44 68  4 31 60  5 27 14  0 59 38 43 70 75 42 48 37 10 71 35 58 76 11 77  1 18 17 67 25 19 16 15  6 53 66 62 12  9 61 40 56  2], a_shuffle_aclus: [ 45  93  63  56 102  86  28   5  64  88  70  69  11  37  53  74  85 100  68  98  62  51  27  67  33  17  49  50  10  31  35  32  58  76  73  41  61  92   7  48  82   8  36  19   2  81  55  60  96 107  59  66  54  14  97  52  78 108  15 109   3  25  24  90  34  26  23  21   9  71  89  84  16  13  83  57  75   4]\n",
      "a_shuffle_IDXs: [34  9  0 61 10 18 35 29 65 73 77 24 16 17  1 43 30 36 45 56 23 68 46 22 58 48 25 74 67  2 33 64 51 55 62 15 53 71  7 40 54 44 47 76 19  3 63 12 20 31 21 60 66 13  4 50 14  8  5 49 38 57 72  6 28 32 70 69 75 52 39 42 59 41 27 11 37 26], a_shuffle_aclus: [ 51  13   2  83  14  25  52  41  88 100 109  33  23  24   3  60  45  53  62  75  32  92  63  31  78  66  34 102  90   4  50  86  69  74  84  21  71  97  10  57  73  61  64 108  26   5  85  16  27  48  28  82  89  17   7  68  19  11   8  67  55  76  98   9  37  49  96  93 107  70  56  59  81  58  36  15  54  35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [57 33 66 77 40 36 17 18 59 54 65  3 76 51 41 56 27 19 26 52 47 12  0 39 44 63 50 30 62 24 68 38 25 64 28 42 20 75 58 37 32 43 48 23  5 70 60  2 16  8 45 74 73  9 29  7 71 49 55 46 10 61  1 11 34 72 14 22 31  4 69  6 35 13 15 53 21 67], a_shuffle_aclus: [ 76  50  89 109  57  53  24  25  81  73  88   5 108  69  58  75  36  26  35  70  64  16   2  56  61  85  68  45  84  33  92  55  34  86  37  59  27 107  78  54  49  60  66  32   8  96  82   4  23  11  62 102 100  13  41  10  97  67  74  63  14  83   3  15  51  98  19  31  48   7  93   9  52  17  21  71  28  90]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [17 20 76 14 11 35  2 59 29 68 37  0 15 75 25 57 49 43 12 24 74 71 73 31 19 23 30 58 32 55 70  8 45  9 22  3 64 63 65 46 34  6 61 51 28 44 10 27 33 52 62  7  1 66 38  4  5 40 50 41 39 56 69 48 72 53 60 36 18 47 16 54 42 67 77 26 21 13], a_shuffle_aclus: [ 24  27 108  19  15  52   4  81  41  92  54   2  21 107  34  76  67  60  16  33 102  97 100  48  26  32  45  78  49  74  96  11  62  13  31   5  86  85  88  63  51   9  83  69  37  61  14  36  50  70  84  10   3  89  55   7   8  57  68  58  56  75  93  66  98  71  82  53  25  64  23  73  59  90 109  35  28  17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [63 51 71 64 24 23 12 16 27 47 20 14  9 31 43  8 69 36 35  3 58 41 60 61  7 11 32 18 54  1 40 46 66 57 17 29 21 76 72 62 68 34 28 49 10 30 56 38 77 59  4 45  6 75  2  0 44 50 22  5 25 15 55 52 67 73 53 74 39 65 26 33 13 42 48 70 37 19], a_shuffle_aclus: [ 85  69  97  86  33  32  16  23  36  64  27  19  13  48  60  11  93  53  52   5  78  58  82  83  10  15  49  25  73   3  57  63  89  76  24  41  28 108  98  84  92  51  37  67  14  45  75  55 109  81   7  62   9 107   4   2  61  68  31   8  34  21  74  70  90 100  71 102  56  88  35  50  17  59  66  96  54  26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [42 47 73 63 44 32 46 27 59  2 61 56 76  7 14 37 52 72 60 66 25 22 31 41 11 40 38 20 15 13 49 62 43 33 53 75 10 48 28 54 12 71 68 39 70 30  0 64  5 19 57 35 21 50  8  4  9 67 29 24 26 45 16 65  1 55  6 17 34 51 18 23 74 69 36 58 77  3], a_shuffle_aclus: [ 59  64 100  85  61  49  63  36  81   4  83  75 108  10  19  54  70  98  82  89  34  31  48  58  15  57  55  27  21  17  67  84  60  50  71 107  14  66  37  73  16  97  92  56  96  45   2  86   8  26  76  52  28  68  11   7  13  90  41  33  35  62  23  88   3  74   9  24  51  69  25  32 102  93  53  78 109   5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [65  1 17 75 58 69 12  2  0 31 44 60 47 41 71 54 56 22 74 21 26 64 27 40 32 16 28 61 51 43 34 30 76 53 67 24  3 62 77  8 13 73 38 49 42 68  5 25 36 52 18  7 33 55  9 10 23 46 20 19 72 45 39 57 50 59 66 14 48 15 63  4 70 29 35 11 37  6], a_shuffle_aclus: [ 88   3  24 107  78  93  16   4   2  48  61  82  64  58  97  73  75  31 102  28  35  86  36  57  49  23  37  83  69  60  51  45 108  71  90  33   5  84 109  11  17 100  55  67  59  92   8  34  53  70  25  10  50  74  13  14  32  63  27  26  98  62  56  76  68  81  89  19  66  21  85   7  96  41  52  15  54   9]\n",
      "a_shuffle_IDXs: [62  6 42 54  1 46 21 12 77 14 57 19 61 35 30 13 75  8 25 32 15 60 33 55 10 66 50 16 17 76 37 43 67 22 31 27 23 48 11  9  3  7 36 70 40 56 34 47 44 53 65 64 51 73 24 45 58 52 18  4 28  2 20 26 38 39 72  5 49 74 59 63 71 69 41 29 68  0], a_shuffle_aclus: [ 84   9  59  73   3  63  28  16 109  19  76  26  83  52  45  17 107  11  34  49  21  82  50  74  14  89  68  23  24 108  54  60  90  31  48  36  32  66  15  13   5  10  53  96  57  75  51  64  61  71  88  86  69 100  33  62  78  70  25   7  37   4  27  35  55  56  98   8  67 102  81  85  97  93  58  41  92   2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [70 23 54 73 44  7 16 55 18 75 69 67 60 45 53 68  9 61 76 30  8 21 37 28 19 20  3 58 31 26 13 17  2 43 52 42 36 51 34 62 11 57  0 33 49 46 66 15 38 24 12 14 29 41 63 35 59 10 72  4  1 47 48 56  6 40 25 77 64 22 71  5 32 39 74 27 65 50], a_shuffle_aclus: [ 96  32  73 100  61  10  23  74  25 107  93  90  82  62  71  92  13  83 108  45  11  28  54  37  26  27   5  78  48  35  17  24   4  60  70  59  53  69  51  84  15  76   2  50  67  63  89  21  55  33  16  19  41  58  85  52  81  14  98   7   3  64  66  75   9  57  34 109  86  31  97   8  49  56 102  36  88  68]\n",
      "a_shuffle_IDXs: [34 32 29 31 37 56 45  4 73 41 11 74 10 19 65 54 59  6 64 18 38 22 50 13 75 23 67 21 12  0 43 25 62 76 51  3  5 66  7 53 49 44 33 16 20 71 60 35 14 57 63 15 39 46  8 52 70 72  9 30 55 36 61 28 40 68 69 27 58 24  2 17 47 48 42  1 77 26], a_shuffle_aclus: [ 51  49  41  48  54  75  62   7 100  58  15 102  14  26  88  73  81   9  86  25  55  31  68  17 107  32  90  28  16   2  60  34  84 108  69   5   8  89  10  71  67  61  50  23  27  97  82  52  19  76  85  21  56  63  11  70  96  98  13  45  74  53  83  37  57  92  93  36  78  33   4  24  64  66  59   3 109  35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 1 18 48 27 55 38 43 60 49 63  0 30 47 23 37 53 68 46 57 72 75 28  5 50 70 77 73  7  3 16 71 12 52 56 61 33 13 34 22 67 36 58 31 39 74 41 44 69 64 32  9 25 65 45 21 59 40  2 14 66 35 24 62  6  8 10 17 26 54 15 51 11 20  4 19 42 29 76], a_shuffle_aclus: [  3  25  66  36  74  55  60  82  67  85   2  45  64  32  54  71  92  63  76  98 107  37   8  68  96 109 100  10   5  23  97  16  70  75  83  50  17  51  31  90  53  78  48  56 102  58  61  93  86  49  13  34  88  62  28  81  57   4  19  89  52  33  84   9  11  14  24  35  73  21  69  15  27   7  26  59  41 108]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [24 18 22 63 51 72 67 71 20  2 42 11 49 77  6 29 65 44 58 39 43 61  9 19  3 16 45 53 37 26 10 46 69 64  5 32 76 56 60  8  1 66 25 54 14 75 21 13 33 62 68 12 59 38 73 47 35 17 23 27 40 30 74 15 57 48  4 52  0 36 31  7 34 28 70 55 41 50], a_shuffle_aclus: [ 33  25  31  85  69  98  90  97  27   4  59  15  67 109   9  41  88  61  78  56  60  83  13  26   5  23  62  71  54  35  14  63  93  86   8  49 108  75  82  11   3  89  34  73  19 107  28  17  50  84  92  16  81  55 100  64  52  24  32  36  57  45 102  21  76  66   7  70   2  53  48  10  51  37  96  74  58  68]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [58  1  2 66 25 56 40 64 12  8 23 16 71 10  5 61 13  7 33 36  6 69 22 41 17 73 52 19 55 72 76 53  4 43 11 67 31 62  9 37 50 21 42 54 70 51 39 44 65 29 60 38 35 45 68  0 18 28 34 47 15  3 32 59 46 26 24 27 20 14 74 77 75 48 30 49 63 57], a_shuffle_aclus: [ 78   3   4  89  34  75  57  86  16  11  32  23  97  14   8  83  17  10  50  53   9  93  31  58  24 100  70  26  74  98 108  71   7  60  15  90  48  84  13  54  68  28  59  73  96  69  56  61  88  41  82  55  52  62  92   2  25  37  51  64  21   5  49  81  63  35  33  36  27  19 102 109 107  66  45  67  85  76]\n",
      "a_shuffle_IDXs: [56 44 14 45 49 53 39 10 69 64 13 71 77  1 47 40 46 75 38 54  8 51 62 73  2 59 18 33 43  7 17 52  0 65 31 34  3 12 22 50 19 76 23  4  6 27  9 41 37 74 48 32 57 70 11 36 26 58 72 24 66 61 29 68 67 16 35 20 63 55  5 30 15 60 25 28 21 42], a_shuffle_aclus: [ 75  61  19  62  67  71  56  14  93  86  17  97 109   3  64  57  63 107  55  73  11  69  84 100   4  81  25  50  60  10  24  70   2  88  48  51   5  16  31  68  26 108  32   7   9  36  13  58  54 102  66  49  76  96  15  53  35  78  98  33  89  83  41  92  90  23  52  27  85  74   8  45  21  82  34  37  28  59]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 8 14  2 10 15  3 64 73 55 36 31  1  7 29 40 13  9 32 50 19 41 43 49 21 42 65 52 39 57 74 75 34 76 37 18 27 46 59  0 25 16 67 69  5 44 45 51 77 35 26  6 22 60 33 58 48  4 11 23 54 38 28 20 56 70 62 24 30 66 61 53 72 63 12 47 71 68 17], a_shuffle_aclus: [ 11  19   4  14  21   5  86 100  74  53  48   3  10  41  57  17  13  49  68  26  58  60  67  28  59  88  70  56  76 102 107  51 108  54  25  36  63  81   2  34  23  90  93   8  61  62  69 109  52  35   9  31  82  50  78  66   7  15  32  73  55  37  27  75  96  84  33  45  89  83  71  98  85  16  64  97  92  24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 4 57 54 58  1  9 31 34 45 67 36 14 13 73 75 10 52 38 22 33 65 40 44 61 39 60 28 63 15 21 49 32  3 18  2 68 20 35 76 41 23 27 26 74 77 16 25 71 51 42 19 11 29 12 53 62 47 17 59 69  0 56 72 48 70 37  7 24 64 46  8 30 43  6 66 55 50  5], a_shuffle_aclus: [  7  76  73  78   3  13  48  51  62  90  53  19  17 100 107  14  70  55  31  50  88  57  61  83  56  82  37  85  21  28  67  49   5  25   4  92  27  52 108  58  32  36  35 102 109  23  34  97  69  59  26  15  41  16  71  84  64  24  81  93   2  75  98  66  96  54  10  33  86  63  11  45  60   9  89  74  68   8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [12 65  4 52 55 31 56 34 60 72 53 59 54 70 33  8 14 25  6 62 50 71 76 63 39 57 18 69 58 38 67 19 77 64 74 41  0 28 73 21 26 29 17  9 35 40 24 16  3 43 48 32 68 22 30 46 27 66  2 49 15 44 23 37  5 45  7 61 11 51 10  1 47 13 20 75 42 36], a_shuffle_aclus: [ 16  88   7  70  74  48  75  51  82  98  71  81  73  96  50  11  19  34   9  84  68  97 108  85  56  76  25  93  78  55  90  26 109  86 102  58   2  37 100  28  35  41  24  13  52  57  33  23   5  60  66  49  92  31  45  63  36  89   4  67  21  61  32  54   8  62  10  83  15  69  14   3  64  17  27 107  59  53]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [20 77 72 14 12 10 18 46  6 75 53 22 38 39 25 65 35  9 62 23  5 33 42 27 48 26  1 16 61 59  3 44 74 58 17 52 66  8 40 30 63 32  4  2 43 60 41 24 56 13 15 34 70 37 51 11  0 45 55 76 19 49 71 67 68 50  7 64 29 54 57 31 69 21 47 73 28 36], a_shuffle_aclus: [ 27 109  98  19  16  14  25  63   9 107  71  31  55  56  34  88  52  13  84  32   8  50  59  36  66  35   3  23  83  81   5  61 102  78  24  70  89  11  57  45  85  49   7   4  60  82  58  33  75  17  21  51  96  54  69  15   2  62  74 108  26  67  97  90  92  68  10  86  41  73  76  48  93  28  64 100  37  53]\n",
      "a_shuffle_IDXs: [13 27 47 19 76 26 42 33 45  1 46 72 63 68 34 24 36 77 61 50  6 60 21 66 44 73 35 31  7 64 18 28 62 43 12 58  4 14 23  3 69 38 10 57 48 32 75 25 55  0 49 53 54 59 41 16 29  9 39 71 65  5  2 15 56 51  8 67 52 40 22 70 20 17 11 30 37 74], a_shuffle_aclus: [ 17  36  64  26 108  35  59  50  62   3  63  98  85  92  51  33  53 109  83  68   9  82  28  89  61 100  52  48  10  86  25  37  84  60  16  78   7  19  32   5  93  55  14  76  66  49 107  34  74   2  67  71  73  81  58  23  41  13  56  97  88   8   4  21  75  69  11  90  70  57  31  96  27  24  15  45  54 102]\n",
      "a_shuffle_IDXs: [17 30 13 43 54 38 67 52  9 51 65 66 21 37 11 77 62 60 55 76 46  6 20 63 59 28 32 61 56 34 58 53 19 71 75 44 27 16 22 45 12 72 41 47 15 35 42 26 14 36 48  8 74 73  4  5 24  2  0 69 39 23 68 57  1  3 18 33 70 29 25 50  7 10 64 40 49 31], a_shuffle_aclus: [ 24  45  17  60  73  55  90  70  13  69  88  89  28  54  15 109  84  82  74 108  63   9  27  85  81  37  49  83  75  51  78  71  26  97 107  61  36  23  31  62  16  98  58  64  21  52  59  35  19  53  66  11 102 100   7   8  33   4   2  93  56  32  92  76   3   5  25  50  96  41  34  68  10  14  86  57  67  48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [47  2 75 50  8 20  5 63 57 67 40  3 23 68 44 42 25 49 11 59 41 72 13 48  4 14 73 52 36  6 53 37 62 64 32 56  1 34 16 39 27 71 69 17 10 15 54 55 65 43  9 28 31  0 22 35 51 18  7 26 66 38 77 70 33 12 30 60 24 61 19 21 76 29 74 58 45 46], a_shuffle_aclus: [ 64   4 107  68  11  27   8  85  76  90  57   5  32  92  61  59  34  67  15  81  58  98  17  66   7  19 100  70  53   9  71  54  84  86  49  75   3  51  23  56  36  97  93  24  14  21  73  74  88  60  13  37  48   2  31  52  69  25  10  35  89  55 109  96  50  16  45  82  33  83  26  28 108  41 102  78  62  63]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [74 15 36 62  6 60 58 14 39 64  1 48 68 24 54  9 69 27 10  2 34 17 65 77 20 12  8 66 47 59 50 56 67 45 33 40 38 11 44 63 32 26 49  0 21 57  5 73 43 29  4 18 71 72 53  3 51 37 70 16 46 41 13 30 25 42 52 35 22 31 61 75  7 28 23 55 19 76], a_shuffle_aclus: [102  21  53  84   9  82  78  19  56  86   3  66  92  33  73  13  93  36  14   4  51  24  88 109  27  16  11  89  64  81  68  75  90  62  50  57  55  15  61  85  49  35  67   2  28  76   8 100  60  41   7  25  97  98  71   5  69  54  96  23  63  58  17  45  34  59  70  52  31  48  83 107  10  37  32  74  26 108]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [37  9 38  7 57 55  8 67 31 62 17  3 50 68 26 25 77 70 52 53 27  0 66 16 73  6 32 28 10 15 12 30 44 20  5 60 69 34 51 72 64 58 63 41 59 54 75 39 48 40 11 76 21 24 65 22 45 42 47 74 36 23 61  2 13  4 49 29 35 19 33 56 46 18 71 43 14  1], a_shuffle_aclus: [ 54  13  55  10  76  74  11  90  48  84  24   5  68  92  35  34 109  96  70  71  36   2  89  23 100   9  49  37  14  21  16  45  61  27   8  82  93  51  69  98  86  78  85  58  81  73 107  56  66  57  15 108  28  33  88  31  62  59  64 102  53  32  83   4  17   7  67  41  52  26  50  75  63  25  97  60  19   3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [35 55 40 57 65  4 33 70 62 25 41 39 77 61 27 11 66 45 18  9 60 31 47 71 46 10  5  6 59 73 30 21 50 37 51 32  0 13 48  8 36 28 63  2 19 68 75 16 58 56 67 12 74 76 23 53 54 34 49 14 22 43  7 15  3 38 44 17 24 72 52 64  1 26 29 42 69 20], a_shuffle_aclus: [ 52  74  57  76  88   7  50  96  84  34  58  56 109  83  36  15  89  62  25  13  82  48  64  97  63  14   8   9  81 100  45  28  68  54  69  49   2  17  66  11  53  37  85   4  26  92 107  23  78  75  90  16 102 108  32  71  73  51  67  19  31  60  10  21   5  55  61  24  33  98  70  86   3  35  41  59  93  27]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [25 27 53 77 13  5 12 32 11 46  2 38 64 61  9 18 48 19 55 68 51 67 41 20 56 33 59 16  6 36 37 40 75 54 35 49 66 14 73 34 58 47 62 15 42 57 39  4 45 76 50 63 31 69 70 72 24 17 30 43 65  1 29 10 26  3  7 23 74 71 52  8 22 28  0 21 44 60], a_shuffle_aclus: [ 34  36  71 109  17   8  16  49  15  63   4  55  86  83  13  25  66  26  74  92  69  90  58  27  75  50  81  23   9  53  54  57 107  73  52  67  89  19 100  51  78  64  84  21  59  76  56   7  62 108  68  85  48  93  96  98  33  24  45  60  88   3  41  14  35   5  10  32 102  97  70  11  31  37   2  28  61  82]\n",
      "a_shuffle_IDXs: [34  1 72 21 69 65 77 53  2 71 68 11 31  4 59 17 51 62 20 56 76 19 29 33 67 24 43 46 26 41 27 70 49 63 12 44 35 30 25 37 75 36 61 18 10 40 14 16 64 47 45 57  9 52 66 50  3 48  8  5 54  0 13 39 38 15 32  7 55 73 22 28 42 74 23  6 58 60], a_shuffle_aclus: [ 51   3  98  28  93  88 109  71   4  97  92  15  48   7  81  24  69  84  27  75 108  26  41  50  90  33  60  63  35  58  36  96  67  85  16  61  52  45  34  54 107  53  83  25  14  57  19  23  86  64  62  76  13  70  89  68   5  66  11   8  73   2  17  56  55  21  49  10  74 100  31  37  59 102  32   9  78  82]\n",
      "a_shuffle_IDXs: [24 17 47 38 40 19 48 31 55 41 34 71 61 22 16 39 70 49 72 64 62 20 35 69 63  3 50  9  2 11 14 58 27  7 73 13 29 59  4 57 23 76  1 60 43  5 25 46 65 56 44 10 37 26 52 36 28 21 77 18 67  6 54 75 33 53 66 45 30  0 15 51  8 12 32 74 42 68], a_shuffle_aclus: [ 33  24  64  55  57  26  66  48  74  58  51  97  83  31  23  56  96  67  98  86  84  27  52  93  85   5  68  13   4  15  19  78  36  10 100  17  41  81   7  76  32 108   3  82  60   8  34  63  88  75  61  14  54  35  70  53  37  28 109  25  90   9  73 107  50  71  89  62  45   2  21  69  11  16  49 102  59  92]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [24 50 35 77  1 42 73 27 67 62 16 40 63 31 10 47 28  3 41 17 21 46  5 15 64 26 74  9 59 36 37 75 39 71  8 30 60 53 51 11 29 72 32 61 49 19 48 70 45 25 76 20 33 54 69 68  6 56  2 13  0 55  7 52 57 58 65 34 14 43 18 38  4 23 12 66 44 22], a_shuffle_aclus: [ 33  68  52 109   3  59 100  36  90  84  23  57  85  48  14  64  37   5  58  24  28  63   8  21  86  35 102  13  81  53  54 107  56  97  11  45  82  71  69  15  41  98  49  83  67  26  66  96  62  34 108  27  50  73  93  92   9  75   4  17   2  74  10  70  76  78  88  51  19  60  25  55   7  32  16  89  61  31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [57 44 46 60 64 74 33 11 31 34 14 58 42 70  2  7 39 27 47 29  8 12 71 45 22 49 51 43 54 76 25 32 65 66 21 36  9 28  3 53  1 75 63  6 55 68 62 19 13 67 35 77 17 38 37 23 59 69 30 73 16 15 52 56 18 61 24 72 10  0 20 26 40 50 48  4  5 41], a_shuffle_aclus: [ 76  61  63  82  86 102  50  15  48  51  19  78  59  96   4  10  56  36  64  41  11  16  97  62  31  67  69  60  73 108  34  49  88  89  28  53  13  37   5  71   3 107  85   9  74  92  84  26  17  90  52 109  24  55  54  32  81  93  45 100  23  21  70  75  25  83  33  98  14   2  27  35  57  68  66   7   8  58]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [47 38  9 62  6 12 30 73  8  3 15 24 37 75 68 64 53 77 56 72  2 13 42 60 31 74 27 57  5 48 18 49  4 51 46 35 50 70 39 41 40 71 61 34 25 11 21 45 28 69  1 20 33 76 58 36 19  7 43 26  0 44 10 67 23 29 66 32 14 17 63 65 52 55 22 59 16 54], a_shuffle_aclus: [ 64  55  13  84   9  16  45 100  11   5  21  33  54 107  92  86  71 109  75  98   4  17  59  82  48 102  36  76   8  66  25  67   7  69  63  52  68  96  56  58  57  97  83  51  34  15  28  62  37  93   3  27  50 108  78  53  26  10  60  35   2  61  14  90  32  41  89  49  19  24  85  88  70  74  31  81  23  73]\n",
      "a_shuffle_IDXs: [ 2 25 54 45 71 37 43 23 59 50 58 56 76  5 12 41 61  3 65 16 42 74 10 48 40 46 11 30 15 49 21 35 14 24 70  7 13 31 69 32 33 17 47  6 77 68 67 19 75 55 60 18  1 52 72 57 29 26  0 38 53 63 44 20 73 64 39 28 66 51 62 34  8 36  4 22  9 27], a_shuffle_aclus: [  4  34  73  62  97  54  60  32  81  68  78  75 108   8  16  58  83   5  88  23  59 102  14  66  57  63  15  45  21  67  28  52  19  33  96  10  17  48  93  49  50  24  64   9 109  92  90  26 107  74  82  25   3  70  98  76  41  35   2  55  71  85  61  27 100  86  56  37  89  69  84  51  11  53   7  31  13  36]\n",
      "a_shuffle_IDXs: [73 33 57 22 20 13 11 72  3 77 66 55 62 43 42 38 59  9 12 24 70 10 58 75  6 27 40 49 34 36  8 56 64 74 39 63 45 61 46 53 51 60 41 48  4 47 17 25 18 50 65 71 29  2 28 30 16 35 44 54 26 15 32  5 67 19  0 21 23  7 31 14 69 37 68  1 76 52], a_shuffle_aclus: [100  50  76  31  27  17  15  98   5 109  89  74  84  60  59  55  81  13  16  33  96  14  78 107   9  36  57  67  51  53  11  75  86 102  56  85  62  83  63  71  69  82  58  66   7  64  24  34  25  68  88  97  41   4  37  45  23  52  61  73  35  21  49   8  90  26   2  28  32  10  48  19  93  54  92   3 108  70]\n",
      "a_shuffle_IDXs: [19 77  0 39 60 67 73  7 25 51  8 45 14 64 38 24 56 10 48 37 53  3 62 27 22 26 55 57 47 59 15 50 40 52 30 21 54 23  9 72 76 33 42 46 71 35 68 28 18 12  6 61 36 66 49 69 34 13 43 75  4 70 63  5 44 58 11  2 20 41  1 31 32 74 65 29 16 17], a_shuffle_aclus: [ 26 109   2  56  82  90 100  10  34  69  11  62  19  86  55  33  75  14  66  54  71   5  84  36  31  35  74  76  64  81  21  68  57  70  45  28  73  32  13  98 108  50  59  63  97  52  92  37  25  16   9  83  53  89  67  93  51  17  60 107   7  96  85   8  61  78  15   4  27  58   3  48  49 102  88  41  23  24]\n",
      "a_shuffle_IDXs: [11 54 47 51 60 16 76 12 32  4 63 33 61 39 26 19 64  9 28 46 59 38 15 43 10 55 52  7 68 31 37 65 35 29  3  2 20  0 17 53 45 13 72 74 48 23 66 42 21 67 50 49 24 71 44  8 56 69 14  1 41 25 27 58 40 62  6 75 77  5 22 57 70 36 34 18 30 73], a_shuffle_aclus: [ 15  73  64  69  82  23 108  16  49   7  85  50  83  56  35  26  86  13  37  63  81  55  21  60  14  74  70  10  92  48  54  88  52  41   5   4  27   2  24  71  62  17  98 102  66  32  89  59  28  90  68  67  33  97  61  11  75  93  19   3  58  34  36  78  57  84   9 107 109   8  31  76  96  53  51  25  45 100]\n",
      "a_shuffle_IDXs: [56  1 20 41 52 57 53 23 40 11 70 17 22 58 25 64 43 54 48 62 30 31  2 39 60 65 21 51  9 55  3 50 12 63 15 74 76 45 10 42 35 68 47 33 36  5 49 67 29 37 69 34 32 26 71 73  7 24 66  0 18 77 75 14 72 61  6  8 13 46 59 19 44 16 38 27  4 28], a_shuffle_aclus: [ 75   3  27  58  70  76  71  32  57  15  96  24  31  78  34  86  60  73  66  84  45  48   4  56  82  88  28  69  13  74   5  68  16  85  21 102 108  62  14  59  52  92  64  50  53   8  67  90  41  54  93  51  49  35  97 100  10  33  89   2  25 109 107  19  98  83   9  11  17  63  81  26  61  23  55  36   7  37]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [72 19  6 54 64 62 11 12 49 71 44 16 35 76 21 43  7 52 45 20 32  2 25 37 42 18 56 48 36 60 40 57 65 41 68 23 59 73 50  9 70 39 28 75  1 63 77 15 30 38 69 61  0 33 27 47  4 58 10 13 24 26 29 66  8 51 53 17 22 14  5 31 74 46 67 34  3 55], a_shuffle_aclus: [ 98  26   9  73  86  84  15  16  67  97  61  23  52 108  28  60  10  70  62  27  49   4  34  54  59  25  75  66  53  82  57  76  88  58  92  32  81 100  68  13  96  56  37 107   3  85 109  21  45  55  93  83   2  50  36  64   7  78  14  17  33  35  41  89  11  69  71  24  31  19   8  48 102  63  90  51   5  74]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [26 59 14 65 75 60 19 24 31 42 51 58 53 22 71 76 44 66 67 25 43 63 16 73  6 41 70 48 40 30 72 12 69 74 46 29 62 64 49  7 23 21 36 33 27 45 37  2 17 13 11 28  3 38 10 20 32 61 54 34 77  0  8 50  1 56  5 57  9 18 15 47 39 68 55 35 52  4], a_shuffle_aclus: [ 35  81  19  88 107  82  26  33  48  59  69  78  71  31  97 108  61  89  90  34  60  85  23 100   9  58  96  66  57  45  98  16  93 102  63  41  84  86  67  10  32  28  53  50  36  62  54   4  24  17  15  37   5  55  14  27  49  83  73  51 109   2  11  68   3  75   8  76  13  25  21  64  56  92  74  52  70   7]\n",
      "a_shuffle_IDXs: [35 20 77 73  9 36  4  3 55 61 14 71 47 54 59 28 46 76 75 60 72 21 37  6 27 16 52 11 40 56 24 17  0 29 51 64 65 34 57  7 41 53 32 39 44  1 33 18 23 12 10 22 31 26 48 19 58 42 68 25  8 69 49 66 63 38 50 13 67 30 15  5 43 74  2 45 62 70], a_shuffle_aclus: [ 52  27 109 100  13  53   7   5  74  83  19  97  64  73  81  37  63 108 107  82  98  28  54   9  36  23  70  15  57  75  33  24   2  41  69  86  88  51  76  10  58  71  49  56  61   3  50  25  32  16  14  31  48  35  66  26  78  59  92  34  11  93  67  89  85  55  68  17  90  45  21   8  60 102   4  62  84  96]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [52 51  2 46 72 32 68 37 64 76 14 41  1 58 45 25 21 17 23 10 65 39 19 63  5 38 75 24 16 28 22  9 29 13 30 42 35 77 62 12 48 36 26 31 20 27 60 11 57 70 54 59 40 43  8 18 56 50 73 66 15 74 33 61 34  4  7 71 49 53 69  6 47 55  3  0 67 44], a_shuffle_aclus: [ 70  69   4  63  98  49  92  54  86 108  19  58   3  78  62  34  28  24  32  14  88  56  26  85   8  55 107  33  23  37  31  13  41  17  45  59  52 109  84  16  66  53  35  48  27  36  82  15  76  96  73  81  57  60  11  25  75  68 100  89  21 102  50  83  51   7  10  97  67  71  93   9  64  74   5   2  90  61]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [37 56 27 43 64  5 42 62 75 49  4 14  2 17 18 76 71 15 33 40 54 68 11  1 52 77 73 20 53 66 32 58 22  3 29 50 34 48 57 55 51 74 23 35  9 72 44 47 60 38 70 16 41 28 13 10 67 24 30 39 19 63 26 69 21  6 65 45  0 59  7 61 25 36  8 31 46 12], a_shuffle_aclus: [ 54  75  36  60  86   8  59  84 107  67   7  19   4  24  25 108  97  21  50  57  73  92  15   3  70 109 100  27  71  89  49  78  31   5  41  68  51  66  76  74  69 102  32  52  13  98  61  64  82  55  96  23  58  37  17  14  90  33  45  56  26  85  35  93  28   9  88  62   2  81  10  83  34  53  11  48  63  16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [62 72 61 20 73 60 69  3 74  2 77 14 15 25 53 48 66 27 22  8 42 17  7 29 36 24 33 58  0 51 31 67 50 12 39 45 18 65 63 13 34 64 47 19 44 55 40  6 56 21 70 54  1 68 49 23 41  9 30 28 71 32 75  5 59 43 76 46 52 57 10 16  4 35 26 38 37 11], a_shuffle_aclus: [ 84  98  83  27 100  82  93   5 102   4 109  19  21  34  71  66  89  36  31  11  59  24  10  41  53  33  50  78   2  69  48  90  68  16  56  62  25  88  85  17  51  86  64  26  61  74  57   9  75  28  96  73   3  92  67  32  58  13  45  37  97  49 107   8  81  60 108  63  70  76  14  23   7  52  35  55  54  15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [52 54 14 41 50 73 69 27  1 46 20 59 77 19 33 16 40 43  2 57 39 45  7 31 22 42 38 47 12 17 51 28 56 32 75 66 21 25 10 44 48 64 60 30 26  6  0 35 15 71  4 62 24 70 34  3 76 65 29 23 67 18 11 53  8 36 13  9  5 49 74 58 55 68 37 72 63 61], a_shuffle_aclus: [ 70  73  19  58  68 100  93  36   3  63  27  81 109  26  50  23  57  60   4  76  56  62  10  48  31  59  55  64  16  24  69  37  75  49 107  89  28  34  14  61  66  86  82  45  35   9   2  52  21  97   7  84  33  96  51   5 108  88  41  32  90  25  15  71  11  53  17  13   8  67 102  78  74  92  54  98  85  83]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [71 77 22 50 63 39 40 59  7  9 55 74  0 43 23 66 69 51  4 64 41 28 10 38 57 31 21 60 20  5 53 76 19 62 29 14  8 72 68 35 24 67 12 36 56 48 25 54 70  3 49 65 11 30  2 44 46 45 47 75  6 18 61 27 33 26 73 13 34  1 58 15 52 37 16 32 42 17], a_shuffle_aclus: [ 97 109  31  68  85  56  57  81  10  13  74 102   2  60  32  89  93  69   7  86  58  37  14  55  76  48  28  82  27   8  71 108  26  84  41  19  11  98  92  52  33  90  16  53  75  66  34  73  96   5  67  88  15  45   4  61  63  62  64 107   9  25  83  36  50  35 100  17  51   3  78  21  70  54  23  49  59  24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [58 15 19 17 49 55 14 38 71 77 18 43 76 67 59 69 44 42 74 54 63 68 66 24 52 23 21 60  6  0 13 36 46 61 10 35  2 16  9 41 50 32 39  8 37 12  1 26 64  3  7 75 51 33 72 34 31 70 29 40 62 22 27 20 47 11 45 30 57 53 65 28 25  5 56 48 73  4], a_shuffle_aclus: [ 78  21  26  24  67  74  19  55  97 109  25  60 108  90  81  93  61  59 102  73  85  92  89  33  70  32  28  82   9   2  17  53  63  83  14  52   4  23  13  58  68  49  56  11  54  16   3  35  86   5  10 107  69  50  98  51  48  96  41  57  84  31  36  27  64  15  62  45  76  71  88  37  34   8  75  66 100   7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [57 52  9 66 21 25 61 14  1 19 23 64 37  7 38 18 44 26 39 75  6 43 35 34 69 60 54 40 30 47 67 24 58 63 71 27 22 70  8 36 31 15 45 46 50 42  0 77 62 33 11  3 20 55  2 51 76 41 65 53  5 16 72 74  4 28 68 32 73 13 10 29 56 48 49 17 59 12], a_shuffle_aclus: [ 76  70  13  89  28  34  83  19   3  26  32  86  54  10  55  25  61  35  56 107   9  60  52  51  93  82  73  57  45  64  90  33  78  85  97  36  31  96  11  53  48  21  62  63  68  59   2 109  84  50  15   5  27  74   4  69 108  58  88  71   8  23  98 102   7  37  92  49 100  17  14  41  75  66  67  24  81  16]\n",
      "a_shuffle_IDXs: [32 47 17 40  4 35 69  2 41 12  3 39 51 44  5 67 31 54 55 53 56 62 66 11 20 33  0 23 30 26 70 34 48  6 24 21 29 63 38 46 57 16  9 45 52 50 60 27 37 58  8 73 10 43 36 22  1 19 42 49  7 28 59 65 68 64 76 72 75 71 77 15 61 25 14 74 13 18], a_shuffle_aclus: [ 49  64  24  57   7  52  93   4  58  16   5  56  69  61   8  90  48  73  74  71  75  84  89  15  27  50   2  32  45  35  96  51  66   9  33  28  41  85  55  63  76  23  13  62  70  68  82  36  54  78  11 100  14  60  53  31   3  26  59  67  10  37  81  88  92  86 108  98 107  97 109  21  83  34  19 102  17  25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [26  0  6 53 69 38 32 42 39 35 51 22 13 19 25 10 62 76  2 67  1 37 49  4 30 41 34 54 20 27 24 65 14 75 11 18  7 40  9 73 46 52 58 15 29 71 48 70 60 63 64 57  3 23 59 77 50 44  5 17 33  8 74 28 16 45 61 12 55 21 43 36 31 68 47 72 56 66], a_shuffle_aclus: [ 35   2   9  71  93  55  49  59  56  52  69  31  17  26  34  14  84 108   4  90   3  54  67   7  45  58  51  73  27  36  33  88  19 107  15  25  10  57  13 100  63  70  78  21  41  97  66  96  82  85  86  76   5  32  81 109  68  61   8  24  50  11 102  37  23  62  83  16  74  28  60  53  48  92  64  98  75  89]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [60 38 26 13  3 16 77 58  0 65 72 73 75 22 37 42 59 18 34 12 29 49 39 57 67 36 69 74 48  7 10 51 54 62 55 15 66  6 52  8 44 17  4 33 43 53  2 46 68 27  9 14 11 24 56 41  1 63 45 31 28 61 47 25 20 30 40 21 50 76 71 70 23  5 19 32 64 35], a_shuffle_aclus: [ 82  55  35  17   5  23 109  78   2  88  98 100 107  31  54  59  81  25  51  16  41  67  56  76  90  53  93 102  66  10  14  69  73  84  74  21  89   9  70  11  61  24   7  50  60  71   4  63  92  36  13  19  15  33  75  58   3  85  62  48  37  83  64  34  27  45  57  28  68 108  97  96  32   8  26  49  86  52]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [47 16 11  3 31 26 23 14 77 43 70 58 15 71 44 37 65 49 60  9 35 38 69 68 27 34 76 62 66  4  8 63 30  5 45 18 12 28 72 42 64 51 33 40 55 46 54 41  2 57 13 56 29 67 25  1 75 52 10 59 22 61 50 48  6  0 73 36 74 53 32 21 17  7 24 39 19 20], a_shuffle_aclus: [ 64  23  15   5  48  35  32  19 109  60  96  78  21  97  61  54  88  67  82  13  52  55  93  92  36  51 108  84  89   7  11  85  45   8  62  25  16  37  98  59  86  69  50  57  74  63  73  58   4  76  17  75  41  90  34   3 107  70  14  81  31  83  68  66   9   2 100  53 102  71  49  28  24  10  33  56  26  27]\n",
      "a_shuffle_IDXs: [40  7 20 71 41 35  9  2 55 26 23 30 57  3  1 12 32  6 38 19 75 49  5 43 44 48 70 56 45 27 67 74 60 69 64 28 63  4 24 10 61 16 13 52 17 29 50 58 31 33 25 37 59 14 53 72 36 51 22 39 11 15 34 54 66 68 62 46 18  8 77  0 73 42 65 47 76 21], a_shuffle_aclus: [ 57  10  27  97  58  52  13   4  74  35  32  45  76   5   3  16  49   9  55  26 107  67   8  60  61  66  96  75  62  36  90 102  82  93  86  37  85   7  33  14  83  23  17  70  24  41  68  78  48  50  34  54  81  19  71  98  53  69  31  56  15  21  51  73  89  92  84  63  25  11 109   2 100  59  88  64 108  28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 9 22 61 39 50 67 40  4 10 57  1 46 17 12 36 16 53  7 66 23  3 20 44 68 37 51 72 52  2 71  0 70 11 29 32 45 14 42 74  5  6 30 21 41 75 24 62 55 35 64 60 56 54 69 19 25 33 27 38 49 76 28 18 47 48 77 73 31 43 58 15 63 13 59 34  8 26 65], a_shuffle_aclus: [ 13  31  83  56  68  90  57   7  14  76   3  63  24  16  53  23  71  10  89  32   5  27  61  92  54  69  98  70   4  97   2  96  15  41  49  62  19  59 102   8   9  45  28  58 107  33  84  74  52  86  82  75  73  93  26  34  50  36  55  67 108  37  25  64  66 109 100  48  60  78  21  85  17  81  51  11  35  88]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [52 71 42 14 76  8 72  2 68 51 46 21 35 27 53 24 16 36 50  4  6 62 69  5 63 48 23 40 30 55 44 11  9 26 73 64 65 47 32 45 74 56 39 37 34 54 20  0 59 70 43 67 28  7 61 10 22 33  1 41 19  3 25 12 57 49 31 17 18 66 75 77 15 29 60 58 13 38], a_shuffle_aclus: [ 70  97  59  19 108  11  98   4  92  69  63  28  52  36  71  33  23  53  68   7   9  84  93   8  85  66  32  57  45  74  61  15  13  35 100  86  88  64  49  62 102  75  56  54  51  73  27   2  81  96  60  90  37  10  83  14  31  50   3  58  26   5  34  16  76  67  48  24  25  89 107 109  21  41  82  78  17  55]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [11 14 38 36 71 42 48 53 30 72 26 49 23 75 21 13  1 39 35 46  6 32  0 47 60 57 69 20 50 73 41 24 25 28 77 43 34 22 19 51 76 61  5 16 40 37 56 67 64 55  8 65 15 31 33 62 17 29 52 18 10 70 59  4 12  9 63 74 27  7 54 68 45  3 58  2 44 66], a_shuffle_aclus: [ 15  19  55  53  97  59  66  71  45  98  35  67  32 107  28  17   3  56  52  63   9  49   2  64  82  76  93  27  68 100  58  33  34  37 109  60  51  31  26  69 108  83   8  23  57  54  75  90  86  74  11  88  21  48  50  84  24  41  70  25  14  96  81   7  16  13  85 102  36  10  73  92  62   5  78   4  61  89]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [28 48 37  5  2 77 64 20 35  8 12 47 36  4 19 25 68 70 42 15 67 11 30 56 55 16 66  1 17 34 13 71 74 27 76 21 50 63 32 59 53 26 22 62 41  7 49 51  9 45 72 73 75  6 33  3 31 52 69 29  0 10 60 24 58 57 18 43 44 61 23 40 54 65 38 14 39 46], a_shuffle_aclus: [ 37  66  54   8   4 109  86  27  52  11  16  64  53   7  26  34  92  96  59  21  90  15  45  75  74  23  89   3  24  51  17  97 102  36 108  28  68  85  49  81  71  35  31  84  58  10  67  69  13  62  98 100 107   9  50   5  48  70  93  41   2  14  82  33  78  76  25  60  61  83  32  57  73  88  55  19  56  63]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [52 18 51 40 55 70 76 59 53 12 66 10 65 43 49 56 21 46 23 75  7  8  1 41 29 39 35 44 71 47 30 20 68  0 61  9 26 64 13 77  6 28 62 24 54 33 50 73 27 16 32  4 14 67 69 37 17 22 19 38 58 74 11 42 63 36 60  5 25 72  3  2 57 45 48 15 34 31], a_shuffle_aclus: [ 70  25  69  57  74  96 108  81  71  16  89  14  88  60  67  75  28  63  32 107  10  11   3  58  41  56  52  61  97  64  45  27  92   2  83  13  35  86  17 109   9  37  84  33  73  50  68 100  36  23  49   7  19  90  93  54  24  31  26  55  78 102  15  59  85  53  82   8  34  98   5   4  76  62  66  21  51  48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [22 29  3 33 38 40  4  8 65 41 15 62 45 21 67 66  9 68 50 18 63 52 44 35 70 47  6  2 26 48 19 11 30 54 16 71 31 46 55  7 27 37 51  1 24 20 59  0 53 72 75 42 49 13 17 57 36 60 58 12 76 73 74 77 28 23 10 34 56 39 69 14 32 43 25  5 61 64], a_shuffle_aclus: [ 31  41   5  50  55  57   7  11  88  58  21  84  62  28  90  89  13  92  68  25  85  70  61  52  96  64   9   4  35  66  26  15  45  73  23  97  48  63  74  10  36  54  69   3  33  27  81   2  71  98 107  59  67  17  24  76  53  82  78  16 108 100 102 109  37  32  14  51  75  56  93  19  49  60  34   8  83  86]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [48 63  6 40 57  1 47  3 24 53 21 72 54 73 17 51 49 44 61 25 27 20 76 18  9 69 70 33 60 31 42 56 11 34 75 30 36  8 71 77 41 74  0 16 14 45 35  2 13 59 52 62 29 23 65 37  5 26 39 58 43 64 28  7 55 12 66 32 46 19 67 38 50 15 10  4 22 68], a_shuffle_aclus: [ 66  85   9  57  76   3  64   5  33  71  28  98  73 100  24  69  67  61  83  34  36  27 108  25  13  93  96  50  82  48  59  75  15  51 107  45  53  11  97 109  58 102   2  23  19  62  52   4  17  81  70  84  41  32  88  54   8  35  56  78  60  86  37  10  74  16  89  49  63  26  90  55  68  21  14   7  31  92]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 0 62 51 61 11  8 28 56  9 29 26 52 54 17 72 48 22 19 60 31  5 36 16 30 39 32 49 43 21 68 13 24 34 50 57 27 67  4 20 76 35 47  1 42 69 66 55 12 45 71 58 41 77  3 70 75 33  6 10 59 74 23 25 15 64 40 44 65 73 18 38  2 53 63 46 37  7 14], a_shuffle_aclus: [  2  84  69  83  15  11  37  75  13  41  35  70  73  24  98  66  31  26  82  48   8  53  23  45  56  49  67  60  28  92  17  33  51  68  76  36  90   7  27 108  52  64   3  59  93  89  74  16  62  97  78  58 109   5  96 107  50   9  14  81 102  32  34  21  86  57  61  88 100  25  55   4  71  85  63  54  10  19]\n",
      "a_shuffle_IDXs: [34  2 60 24 31  8  3 35 30 58 65 14 27  5  4 32 10 55 68 37 70 36 52 47 57 18 13 66 51  9 22 49 61 53 46 69 15 67 25 63 71 12 43 39 72 20 64  1 26 11 23 76 44 40 17 50 33  0 54 73 74 29 48 38 62 28 42  7 59 75 19 56 45  6 21 41 77 16], a_shuffle_aclus: [ 51   4  82  33  48  11   5  52  45  78  88  19  36   8   7  49  14  74  92  54  96  53  70  64  76  25  17  89  69  13  31  67  83  71  63  93  21  90  34  85  97  16  60  56  98  27  86   3  35  15  32 108  61  57  24  68  50   2  73 100 102  41  66  55  84  37  59  10  81 107  26  75  62   9  28  58 109  23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [53 44 11 67  3 35 74 43 20 16 48 70 63 17 36 13 32 19 14 21 42 33 71  6 76 60 62 15 10  0 39 18 57 12 65 38 24 58 59  7 46  1 54 61 41 22 26 25 77 40 75 47 66 69 51 37 45 49 23  9 55 27 50  5  8 68 28 34  4 52 56 29 64 31  2 73 30 72], a_shuffle_aclus: [ 71  61  15  90   5  52 102  60  27  23  66  96  85  24  53  17  49  26  19  28  59  50  97   9 108  82  84  21  14   2  56  25  76  16  88  55  33  78  81  10  63   3  73  83  58  31  35  34 109  57 107  64  89  93  69  54  62  67  32  13  74  36  68   8  11  92  37  51   7  70  75  41  86  48   4 100  45  98]\n",
      "a_shuffle_IDXs: [29 65 76 40 41 26 25 49 59 38 61 21 14 15 70 34 72  7 32 46 23 75 68  5 28 56 12 71  3 37 55  4 11 67  9 36  0 50 39 53 74 48 10 69 35  2 45 44 54 27 24 62 19 52 22 51 57 20 73 58 16 77 63  6 43  1 18 17  8 31 33 30 60 64 66 13 47 42], a_shuffle_aclus: [ 41  88 108  57  58  35  34  67  81  55  83  28  19  21  96  51  98  10  49  63  32 107  92   8  37  75  16  97   5  54  74   7  15  90  13  53   2  68  56  71 102  66  14  93  52   4  62  61  73  36  33  84  26  70  31  69  76  27 100  78  23 109  85   9  60   3  25  24  11  48  50  45  82  86  89  17  64  59]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 9 41 37 36 21 31 20 40 56 33 75 18  4 72 11 15 10 27 73  8 54 29 67 77 76 25 12 69 42 30 66 63 13 70  2 55 34 39 74  0 62 52 47 46 26  3 48 44 17  6  7 49 28 32 16 43 51 50 58 59 23 14  1 24 64 60 57 45 61 65  5 53 38 68 35 22 19 71], a_shuffle_aclus: [ 13  58  54  53  28  48  27  57  75  50 107  25   7  98  15  21  14  36 100  11  73  41  90 109 108  34  16  93  59  45  89  85  17  96   4  74  51  56 102   2  84  70  64  63  35   5  66  61  24   9  10  67  37  49  23  60  69  68  78  81  32  19   3  33  86  82  76  62  83  88   8  71  55  92  52  31  26  97]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [76 18 26 55 49  7  8  9 35  3 59 37  6 34 48 33 41 12 39 58 44 21  4 67 47 56 60 28 16 11 74 50 54 13 10 65 20 15 46 63 53 77 40 69 62 73 70 68 51 24 61 30  0 66 19  1 31 22 64 32 27 25 75  2 57 71 29 52 23  5 17 38 45 42 43 36 14 72], a_shuffle_aclus: [108  25  35  74  67  10  11  13  52   5  81  54   9  51  66  50  58  16  56  78  61  28   7  90  64  75  82  37  23  15 102  68  73  17  14  88  27  21  63  85  71 109  57  93  84 100  96  92  69  33  83  45   2  89  26   3  48  31  86  49  36  34 107   4  76  97  41  70  32   8  24  55  62  59  60  53  19  98]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [16 57 34  9 37 36 67 75  6 60 63 25 19 74 18 50 69 49 30 61 15 38 39 35  5 70 46 28 41 59 10 54  8 14 45 44 47 13 27 62 26 68 24 56 40 43 64 29 12 58 23 72 33 76 52  1 42 53 31 77  0 55  2 17  7  4 71 65 51 73 66 32  3 21 20 11 48 22], a_shuffle_aclus: [ 23  76  51  13  54  53  90 107   9  82  85  34  26 102  25  68  93  67  45  83  21  55  56  52   8  96  63  37  58  81  14  73  11  19  62  61  64  17  36  84  35  92  33  75  57  60  86  41  16  78  32  98  50 108  70   3  59  71  48 109   2  74   4  24  10   7  97  88  69 100  89  49   5  28  27  15  66  31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [43  8 68 21 26 65 30 18 22 16  7 75  4 66 36 74 76 42 61 53 32 57 11 63 15 40 46 49 70 77 60 39 69 27 51 47  5 52 14 67 59  1  9  2 20 73 28 50 19 33 29  6 64  0  3 71 10 23 24 34 31 13 54 45 56 25 37 38 41 62 17 12 55 72 44 58 35 48], a_shuffle_aclus: [ 60  11  92  28  35  88  45  25  31  23  10 107   7  89  53 102 108  59  83  71  49  76  15  85  21  57  63  67  96 109  82  56  93  36  69  64   8  70  19  90  81   3  13   4  27 100  37  68  26  50  41   9  86   2   5  97  14  32  33  51  48  17  73  62  75  34  54  55  58  84  24  16  74  98  61  78  52  66]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [57 42 17 36 56 38 32 55 33 27 46 21 50 30 72  2 16  1  0 18 23 44 29 28 52 66 70 37 47 43 71 77  6 20 64 31 76 14 34 48 12 67 24 73 58 53 10  7 25  9 61 40 65 54 68 69 13  5 39 74 45 15 11 41  4 63 62 22  8 75 19 26 59 49 51 35 60  3], a_shuffle_aclus: [ 76  59  24  53  75  55  49  74  50  36  63  28  68  45  98   4  23   3   2  25  32  61  41  37  70  89  96  54  64  60  97 109   9  27  86  48 108  19  51  66  16  90  33 100  78  71  14  10  34  13  83  57  88  73  92  93  17   8  56 102  62  21  15  58   7  85  84  31  11 107  26  35  81  67  69  52  82   5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [73 29 60  0 59 18  7 22 17 50 48 42  8 56 43 13 71 44 74 70 72  6 32 55 20  1 28 15 64 12 77  2 23 21 51 38 33 66 36  5 40 45 62 35 53  4 39 16 57 67 52 31 37 47 63  3 10 30 68 58 25 11 61 65 19 69 54 49  9 75 27 24 76 14 34 41 46 26], a_shuffle_aclus: [100  41  82   2  81  25  10  31  24  68  66  59  11  75  60  17  97  61 102  96  98   9  49  74  27   3  37  21  86  16 109   4  32  28  69  55  50  89  53   8  57  62  84  52  71   7  56  23  76  90  70  48  54  64  85   5  14  45  92  78  34  15  83  88  26  93  73  67  13 107  36  33 108  19  51  58  63  35]\n",
      "a_shuffle_IDXs: [60 43  2 18 56 58 14 70 45 69 46 31 55 74 59 66 47 15 13 19 24 67  9 52  6 50 33  4 72 22 57 68  8 62 29 61 21 27 54 23  5 76 65 64 32 26 20 71 63 75  3 12 73  1 11 53 25 28 40 49 77 37 42 44 16 51 10  7 17  0 36 35 38 39 41 48 34 30], a_shuffle_aclus: [ 82  60   4  25  75  78  19  96  62  93  63  48  74 102  81  89  64  21  17  26  33  90  13  70   9  68  50   7  98  31  76  92  11  84  41  83  28  36  73  32   8 108  88  86  49  35  27  97  85 107   5  16 100   3  15  71  34  37  57  67 109  54  59  61  23  69  14  10  24   2  53  52  55  56  58  66  51  45]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [73 25 38 46 67 39 49  0 29 16 35 50 62 10 14 60 54 12 42 21 75 70 59 51 34 57 55 76 40  4 77  1 61 45  8 18 44 15  9 37 36 47 32 30 56  5 19 72  7 13 22 63  6 27 53 66 65 31 17 33 26 74 48 23 28 43 24 11  2 64  3 52 41 20 69 68 71 58], a_shuffle_aclus: [100  34  55  63  90  56  67   2  41  23  52  68  84  14  19  82  73  16  59  28 107  96  81  69  51  76  74 108  57   7 109   3  83  62  11  25  61  21  13  54  53  64  49  45  75   8  26  98  10  17  31  85   9  36  71  89  88  48  24  50  35 102  66  32  37  60  33  15   4  86   5  70  58  27  93  92  97  78]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [77 17 32 35 24 74 10 54  7  4  3 22 61 25 66 19 56 34 45  5 69 48 37  1 58 47 28 16 26 43 40 55 27 18 39 70  9 33 62 31  2 12 38 14 23  8 44 73 42 51 11 46 76 67 72 50 57 53 60 64 13 29 75 41 49 21 59 20 65  0 52 15 30 36 63  6 71 68], a_shuffle_aclus: [109  24  49  52  33 102  14  73  10   7   5  31  83  34  89  26  75  51  62   8  93  66  54   3  78  64  37  23  35  60  57  74  36  25  56  96  13  50  84  48   4  16  55  19  32  11  61 100  59  69  15  63 108  90  98  68  76  71  82  86  17  41 107  58  67  28  81  27  88   2  70  21  45  53  85   9  97  92]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [77  5 51 72 49 67 75 21 23 27 39 32 42 64 38 40 35 44 52 28 12 10 60 74  9 29 63 16  3 66 65 18 13 30 43 50 34 57 36 56 31 48 55 71 47  4  7 17 15  1 20 59 53 19 26 54 68 33  2 24 11  8 73 58 61 69 14  0 41  6 46 37 62 22 45 25 70 76], a_shuffle_aclus: [109   8  69  98  67  90 107  28  32  36  56  49  59  86  55  57  52  61  70  37  16  14  82 102  13  41  85  23   5  89  88  25  17  45  60  68  51  76  53  75  48  66  74  97  64   7  10  24  21   3  27  81  71  26  35  73  92  50   4  33  15  11 100  78  83  93  19   2  58   9  63  54  84  31  62  34  96 108]\n",
      "a_shuffle_IDXs: [ 7 59 45 28 19 70 68 75 31 64 25 65 48 72 37 17 58  2 71 61  3 38 11 55 51 52 41 40 44 43 57 23 12 42 15 24  8 74 29 36 13 34  5 21 60 50 73 47 54 56  0 22  4 53  6 67 32 18 69 10  1 66 35 49 39 30 27  9 63 62 26 16 77 33 46 76 20 14], a_shuffle_aclus: [ 10  81  62  37  26  96  92 107  48  86  34  88  66  98  54  24  78   4  97  83   5  55  15  74  69  70  58  57  61  60  76  32  16  59  21  33  11 102  41  53  17  51   8  28  82  68 100  64  73  75   2  31   7  71   9  90  49  25  93  14   3  89  52  67  56  45  36  13  85  84  35  23 109  50  63 108  27  19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [62 68 69 13 48 22 67 76 59 28 17  3 18 34 29 73 53 50 58 74 12 40 46 75 33 27 56 26 71 45 14 10  2 55 32 15 41  7 49 43  0 38 60 51 42 65  1 39 20 47 30 19 70 66 36 52 54 16 44 31 21  6 25 72  5 37 57  8 63 24 77 23 35 11  9 64 61  4], a_shuffle_aclus: [ 84  92  93  17  66  31  90 108  81  37  24   5  25  51  41 100  71  68  78 102  16  57  63 107  50  36  75  35  97  62  19  14   4  74  49  21  58  10  67  60   2  55  82  69  59  88   3  56  27  64  45  26  96  89  53  70  73  23  61  48  28   9  34  98   8  54  76  11  85  33 109  32  52  15  13  86  83   7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [54  4 30 64 36 14 56 63 44 37 74 12 72 62 66  0 51 60 18 53  1 55 42 11 34 35 58 15 43 50 13 17 41 67 65 31 29 57  8 39 22  6  2  7 21 16 10 71 38 45 76 28 61 20 46 47 75 52 68 69 73 48 33 32 77 25 40 70 59 27 23  3 49  9  5 19 24 26], a_shuffle_aclus: [ 73   7  45  86  53  19  75  85  61  54 102  16  98  84  89   2  69  82  25  71   3  74  59  15  51  52  78  21  60  68  17  24  58  90  88  48  41  76  11  56  31   9   4  10  28  23  14  97  55  62 108  37  83  27  63  64 107  70  92  93 100  66  50  49 109  34  57  96  81  36  32   5  67  13   8  26  33  35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [33  5 53  3 58 77 11 74 67 36 49 46 25  9 73 19 42 13 41 14 35 55  0 65  7 48 45 76  6 26 69 52  4 34 12  1  8 56 66 44 27 71 63 18 10 47 64 54 62 40 43 28 51 38 22 23 24 75 29 50 31 61 57 20 59 17 15 39 70  2 37 30 60 72 32 21 16 68], a_shuffle_aclus: [ 50   8  71   5  78 109  15 102  90  53  67  63  34  13 100  26  59  17  58  19  52  74   2  88  10  66  62 108   9  35  93  70   7  51  16   3  11  75  89  61  36  97  85  25  14  64  86  73  84  57  60  37  69  55  31  32  33 107  41  68  48  83  76  27  81  24  21  56  96   4  54  45  82  98  49  28  23  92]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [18 47 15 36 34 65 73 27  2 25 56 13 45 64 66 41 61 11 43 37 74 68 32 54  0  1 50 57 17 24 10 60 16  8 72 69 58 76 71  5 22 63 77  4 26 28 19 62 51 38 42 67 23 46  9 39 29 49 52  7 14 48 70  3 35  6 30 12 55 21 44 59 33 75 40 31 20 53], a_shuffle_aclus: [ 25  64  21  53  51  88 100  36   4  34  75  17  62  86  89  58  83  15  60  54 102  92  49  73   2   3  68  76  24  33  14  82  23  11  98  93  78 108  97   8  31  85 109   7  35  37  26  84  69  55  59  90  32  63  13  56  41  67  70  10  19  66  96   5  52   9  45  16  74  28  61  81  50 107  57  48  27  71]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [73  2 69 54 55 52 65 61 49 72 59 16 42 10 41 53 20  0 40 50 77  1 46 33 32 39 66 27 75 24 64 67 22  9 15 36 23 35 14 37 29 30 18 34 48 26  4 63 68  8  5 21 57 38 17 44 13 56 51 31 28 11 25 45 12 43  6 71 74 62  3 76 47 19 58  7 60 70], a_shuffle_aclus: [100   4  93  73  74  70  88  83  67  98  81  23  59  14  58  71  27   2  57  68 109   3  63  50  49  56  89  36 107  33  86  90  31  13  21  53  32  52  19  54  41  45  25  51  66  35   7  85  92  11   8  28  76  55  24  61  17  75  69  48  37  15  34  62  16  60   9  97 102  84   5 108  64  26  78  10  82  96]\n",
      "a_shuffle_IDXs: [ 2 19 13 22 11 14  1 58 53 67 17 70  3 71 15  9 54 48 34 45 16  5 60 39 61 51 43 20  0 36 37 66 72 62 42 68  6 77 64 38  7 59 74 50 27 76 44 33 29 47 10 41 35 55  8 18 32 57 12 69 25 75 63 31 26 65 23 40 52  4 56 46 49 30 28 73 24 21], a_shuffle_aclus: [  4  26  17  31  15  19   3  78  71  90  24  96   5  97  21  13  73  66  51  62  23   8  82  56  83  69  60  27   2  53  54  89  98  84  59  92   9 109  86  55  10  81 102  68  36 108  61  50  41  64  14  58  52  74  11  25  49  76  16  93  34 107  85  48  35  88  32  57  70   7  75  63  67  45  37 100  33  28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [65 29 40 68  9 18 31  1 17 23 56 28 26 71 10 11 63 77 15 55 41 72 22 30 37 34 35 19 62 45 44 74 64 61 54 43 14  8 57  5 49 20 50 36 27  4 73 48 59 38 39  7 47 67 60 33 52 51 42 16 24 70 53 32 76 66  2 69  0 13 12 21 25  6 75 58 46  3], a_shuffle_aclus: [ 88  41  57  92  13  25  48   3  24  32  75  37  35  97  14  15  85 109  21  74  58  98  31  45  54  51  52  26  84  62  61 102  86  83  73  60  19  11  76   8  67  27  68  53  36   7 100  66  81  55  56  10  64  90  82  50  70  69  59  23  33  96  71  49 108  89   4  93   2  17  16  28  34   9 107  78  63   5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [72 31 48 76 63 70 27 20 41 66 14 34  3 42 62 30 64 75 68 50 67 74 15  6 58 73 18 65 49 23  8  7 33  1  2 52 26 71 61 29 36  5 54 44 56 39 24 45  9 19 53 13 77 17 21 35  4 25 46 16 28 40 38 37 32 43 59 55 12  0 11 51 69 47 22 60 10 57], a_shuffle_aclus: [ 98  48  66 108  85  96  36  27  58  89  19  51   5  59  84  45  86 107  92  68  90 102  21   9  78 100  25  88  67  32  11  10  50   3   4  70  35  97  83  41  53   8  73  61  75  56  33  62  13  26  71  17 109  24  28  52   7  34  63  23  37  57  55  54  49  60  81  74  16   2  15  69  93  64  31  82  14  76]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [77 51 37  4 26 41 67 38 42 73 36  1 25  9 10 18 49 64 33 34  2  8 40 24 16 27  6 63  3 71 53 50 74 69 35 72 70 58 54 59 47 62 12 31 52 30 43 66  7 19  0 39 48 55 46 32 75 15 60 17 14 28 21 61 65 20 11 45 22 44 13 23  5 29 76 56 57 68], a_shuffle_aclus: [109  69  54   7  35  58  90  55  59 100  53   3  34  13  14  25  67  86  50  51   4  11  57  33  23  36   9  85   5  97  71  68 102  93  52  98  96  78  73  81  64  84  16  48  70  45  60  89  10  26   2  56  66  74  63  49 107  21  82  24  19  37  28  83  88  27  15  62  31  61  17  32   8  41 108  75  76  92]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [43 12 23 73  3 62 49 39 26 15 29 22 14 45  7 19 55 34 63 10 44 74  5 18 37 28 25 11 46 69  4 57  9 64 36 35  8 13 24 33 72 53 17 20 38 65 61  1 32 16 77 75 47 51 66 40 27 54 52 50 76 71 21 42 41  6 67  0 56 68  2 58 59 60 48 70 30 31], a_shuffle_aclus: [ 60  16  32 100   5  84  67  56  35  21  41  31  19  62  10  26  74  51  85  14  61 102   8  25  54  37  34  15  63  93   7  76  13  86  53  52  11  17  33  50  98  71  24  27  55  88  83   3  49  23 109 107  64  69  89  57  36  73  70  68 108  97  28  59  58   9  90   2  75  92   4  78  81  82  66  96  45  48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [66 39 44  9 55 32 13 59 68 23 26 60 17  6 75 48 24 33 46 50 74 57  5  7  8 65 28 11 21 16  4 61 43 45 29 72 34 36 56 77 12 63 67  0 22  3 10 20 49 47 51 25 70 38 52 18 40 31 37 35 19 14 15 30 69 53 58  1 42 76 64 27  2 62 71 73 41 54], a_shuffle_aclus: [ 89  56  61  13  74  49  17  81  92  32  35  82  24   9 107  66  33  50  63  68 102  76   8  10  11  88  37  15  28  23   7  83  60  62  41  98  51  53  75 109  16  85  90   2  31   5  14  27  67  64  69  34  96  55  70  25  57  48  54  52  26  19  21  45  93  71  78   3  59 108  86  36   4  84  97 100  58  73]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [18  5 20 21 46 45 36 10 16  4 65 42 64  7 71 73 62 41 17 39 25 44 74 75 56 37 30  3  9 55 48 49 50  0 60 15 33 72 54 59 11 53 63 70 31 13 32 22  6 14 12 40 61 66 26 52 69 38  2 58 77 76  8 68 24 29 19 43 51 35 57 23 67 34 27 28 47  1], a_shuffle_aclus: [ 25   8  27  28  63  62  53  14  23   7  88  59  86  10  97 100  84  58  24  56  34  61 102 107  75  54  45   5  13  74  66  67  68   2  82  21  50  98  73  81  15  71  85  96  48  17  49  31   9  19  16  57  83  89  35  70  93  55   4  78 109 108  11  92  33  41  26  60  69  52  76  32  90  51  36  37  64   3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [63 25 51 62 34 40 27 58 21 45 74 13 55 42  8 71 49 14  5 36 28 52 69 31 44  0 64 37 30  3 22 59 39 38  1 20 54 15 29 47  7 77 53 56 70 26 17  4 66 61  6 76 19 10 75 50 68  9 46 41 67 33 18 35 48 16 72 11  2 32 57 73 24 43 65 12 60 23], a_shuffle_aclus: [ 85  34  69  84  51  57  36  78  28  62 102  17  74  59  11  97  67  19   8  53  37  70  93  48  61   2  86  54  45   5  31  81  56  55   3  27  73  21  41  64  10 109  71  75  96  35  24   7  89  83   9 108  26  14 107  68  92  13  63  58  90  50  25  52  66  23  98  15   4  49  76 100  33  60  88  16  82  32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [63 36 39 16 64 10 75 50 53 54 13 21 71 14 23 73 29 44 41 33  8 77 49 15 47 17  4 60 57 56 18 40 59 68 12  5 30 25 58 11 43  3 66  0 67 70 62  9 52  6 27 74 37 31 45 46 22 24 32 26 19  7  2 48 72 34 55 28 38 65 69 42  1 61 20 35 51 76], a_shuffle_aclus: [ 85  53  56  23  86  14 107  68  71  73  17  28  97  19  32 100  41  61  58  50  11 109  67  21  64  24   7  82  76  75  25  57  81  92  16   8  45  34  78  15  60   5  89   2  90  96  84  13  70   9  36 102  54  48  62  63  31  33  49  35  26  10   4  66  98  51  74  37  55  88  93  59   3  83  27  52  69 108]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [31  9  8 46  1 35 51 61 76 15 53 14 42 23 77 59 39 62  7  6 21 49 68 30 65  0 20 69 10 58 48 34 47 50 27 44 75 74  4 12 60 28 57 32 73 24 16 38 25 71 63 70 64 55 41 13 40 67 72 56 18 19 33 22  2  5 45 26 11 43 29  3 66 36 54 52 17 37], a_shuffle_aclus: [ 48  13  11  63   3  52  69  83 108  21  71  19  59  32 109  81  56  84  10   9  28  67  92  45  88   2  27  93  14  78  66  51  64  68  36  61 107 102   7  16  82  37  76  49 100  33  23  55  34  97  85  96  86  74  58  17  57  90  98  75  25  26  50  31   4   8  62  35  15  60  41   5  89  53  73  70  24  54]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [22 25 62 37 71 19 13 23 69  0 42 70 53 28 44 61 11 67  6  4 68 10 57 74 31 14 56 27 32  9 16 50 64 48 15 77 26 52 20 76 12 18 38 41 45 55 40  1 43 59 51 35  3 73 33  5 66 54 46 29 34 60 47 65  7 17 63 72 39 58 21  8 24 30 75 36  2 49], a_shuffle_aclus: [ 31  34  84  54  97  26  17  32  93   2  59  96  71  37  61  83  15  90   9   7  92  14  76 102  48  19  75  36  49  13  23  68  86  66  21 109  35  70  27 108  16  25  55  58  62  74  57   3  60  81  69  52   5 100  50   8  89  73  63  41  51  82  64  88  10  24  85  98  56  78  28  11  33  45 107  53   4  67]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [64  8 27 24 47 22 74 62 45 76 36 29 70  4 30 50 54 41 55 63 14 26 52  5 25 61 19 38 33 77 53  3 57 15 10  0 66 68 20 75 18 73 49 37  9 34 65 32  6 51 69 40 17 11 44 71  1 58 60 72 59 31 42 67 12 43 28 56  7 13 35 23 46 21 39 16 48  2], a_shuffle_aclus: [ 86  11  36  33  64  31 102  84  62 108  53  41  96   7  45  68  73  58  74  85  19  35  70   8  34  83  26  55  50 109  71   5  76  21  14   2  89  92  27 107  25 100  67  54  13  51  88  49   9  69  93  57  24  15  61  97   3  78  82  98  81  48  59  90  16  60  37  75  10  17  52  32  63  28  56  23  66   4]\n",
      "a_shuffle_IDXs: [77 60 64 40 76 68  5 47 21 45  0  3 48 57 63 10 16 22 11  9 55 25 33 42 75 36 59  7 46 73 54  6 66 56 19 41 69 67 20 62 71 65 38 26 31 32 58 50  4 29 28 12 15 27 72 30 24  1 43  8 23 18 51 39 14 49 37 35  2 17 13 74 52 34 61 70 44 53], a_shuffle_aclus: [109  82  86  57 108  92   8  64  28  62   2   5  66  76  85  14  23  31  15  13  74  34  50  59 107  53  81  10  63 100  73   9  89  75  26  58  93  90  27  84  97  88  55  35  48  49  78  68   7  41  37  16  21  36  98  45  33   3  60  11  32  25  69  56  19  67  54  52   4  24  17 102  70  51  83  96  61  71]\n",
      "a_shuffle_IDXs: [44 11 76 21 46 50 28 57 23 16 15 59 36 20 13 33 47 74  7 53 10 40  3 56 55 58 72 14  2 52 29 12  0 45 30 48 27 49 17 73 25 34  9 70  1 71 19  4  5  6 37 38 68 26 75 18 39 64 63 60 62 43 65 51 42 66 32  8 61 69 41 54 77 24 31 22 67 35], a_shuffle_aclus: [ 61  15 108  28  63  68  37  76  32  23  21  81  53  27  17  50  64 102  10  71  14  57   5  75  74  78  98  19   4  70  41  16   2  62  45  66  36  67  24 100  34  51  13  96   3  97  26   7   8   9  54  55  92  35 107  25  56  86  85  82  84  60  88  69  59  89  49  11  83  93  58  73 109  33  48  31  90  52]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [10 47 22 27  4 41 23 67 48 19 56 50 29 49  1 34 33 46 14  2 28 61 77 59 25 40 20  9 65  6 74  8  3 75 62 16 72 18 68 32 12 24  5 52 30 73 60 31 53 71 36 45 70 69 58 43 57 63 21 51 35 11 37 42 17 64 38 66 39 76 15 26 44  7 13  0 55 54], a_shuffle_aclus: [ 14  64  31  36   7  58  32  90  66  26  75  68  41  67   3  51  50  63  19   4  37  83 109  81  34  57  27  13  88   9 102  11   5 107  84  23  98  25  92  49  16  33   8  70  45 100  82  48  71  97  53  62  96  93  78  60  76  85  28  69  52  15  54  59  24  86  55  89  56 108  21  35  61  10  17   2  74  73]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [55 60 66 61 77 11 20 17 21  6 10  7 72 23 27 43 71  0 57 25 31 18 19 24  3 65 39 35 44  1 53 58 48 70 75 49 64 38 47 68 46  9 40 36 15  5 22 16 34 51 37 45 33 54 73 29 30 41 63  2 76 50 67  8 62 28 52 12 56 42 74 69 59 14 26 13  4 32], a_shuffle_aclus: [ 74  82  89  83 109  15  27  24  28   9  14  10  98  32  36  60  97   2  76  34  48  25  26  33   5  88  56  52  61   3  71  78  66  96 107  67  86  55  64  92  63  13  57  53  21   8  31  23  51  69  54  62  50  73 100  41  45  58  85   4 108  68  90  11  84  37  70  16  75  59 102  93  81  19  35  17   7  49]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 9  1 62 43 49 25 12 24 72 28 54 16 76 14  6  7 70 17 40 20  8  5 74 34 23 15 26 36 19 66 47 64 57 46  4 18 30 45 75 68 73 33 11 41 65 37 50 59 69 77 71  3 67 53 55 56 58 27 52 31 42  2  0 48 63 35 60 38 13 32 61 51 29 44 21 22 39 10], a_shuffle_aclus: [ 13   3  84  60  67  34  16  33  98  37  73  23 108  19   9  10  96  24  57  27  11   8 102  51  32  21  35  53  26  89  64  86  76  63   7  25  45  62 107  92 100  50  15  58  88  54  68  81  93 109  97   5  90  71  74  75  78  36  70  48  59   4   2  66  85  52  82  55  17  49  83  69  41  61  28  31  56  14]\n",
      "a_shuffle_IDXs: [72 75 23 54 74 64 12 13 52 41 14 36 61  0 47 26 68  7 45 18 35 43 31 27 15 33 29 24 62 55  1 73 58 63 32 40  5 53 20 19 16 11 21 51 25 65 57 10 56 48  6 69 70 22 46 38  8 66  4 37 50  9 17 42 28 71 76 30 60 34  3 44 39 59  2 67 49 77], a_shuffle_aclus: [ 98 107  32  73 102  86  16  17  70  58  19  53  83   2  64  35  92  10  62  25  52  60  48  36  21  50  41  33  84  74   3 100  78  85  49  57   8  71  27  26  23  15  28  69  34  88  76  14  75  66   9  93  96  31  63  55  11  89   7  54  68  13  24  59  37  97 108  45  82  51   5  61  56  81   4  90  67 109]\n",
      "a_shuffle_IDXs: [62 41 26 72 54 68 12 60 61 29 10 37  6 31 42 40 43 11 64 30 70 16  2 75 39 36 67 21 23  8 63  5 33 27 22 17 71  4 32 34 66 44 38 49  7 28 46 45  3 56 53 55 35 48 14 73  1 50  0 18 24 25 69 20 15 51 74 13 76 19 65 47 58 59 77 57 52  9], a_shuffle_aclus: [ 84  58  35  98  73  92  16  82  83  41  14  54   9  48  59  57  60  15  86  45  96  23   4 107  56  53  90  28  32  11  85   8  50  36  31  24  97   7  49  51  89  61  55  67  10  37  63  62   5  75  71  74  52  66  19 100   3  68   2  25  33  34  93  27  21  69 102  17 108  26  88  64  78  81 109  76  70  13]\n",
      "a_shuffle_IDXs: [62 37 75 22  6 59 64 48 70 41  8 10  9 12 46 34 56 54 50 45 36 11 69 32 57 68 15 18 77 33 66 39 55 42  3 60 21 76  1  7 13 16 44 14 29 38 74 20 73 51 27 28  2 43 47 53  0 67 26  5 61 19 72 31 52 24 17 25 63  4 58 30 35 40 23 71 49 65], a_shuffle_aclus: [ 84  54 107  31   9  81  86  66  96  58  11  14  13  16  63  51  75  73  68  62  53  15  93  49  76  92  21  25 109  50  89  56  74  59   5  82  28 108   3  10  17  23  61  19  41  55 102  27 100  69  36  37   4  60  64  71   2  90  35   8  83  26  98  48  70  33  24  34  85   7  78  45  52  57  32  97  67  88]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 7 25 76 20 15 48 41 68 18 10 13 14 34 44  8  6  9 43 40 12 57 30 35 19 33 36 56 29 60 74 50 62 73 55 69 27 17 45 37  2 58 47 46 23  5 32 52 53 38 11 42  0  1  4 77 22 70 49 26 75 65 71 67 63 21 61 64 66 72 39  3 54 28 24 59 16 31 51], a_shuffle_aclus: [ 10  34 108  27  21  66  58  92  25  14  17  19  51  61  11   9  13  60  57  16  76  45  52  26  50  53  75  41  82 102  68  84 100  74  93  36  24  62  54   4  78  64  63  32   8  49  70  71  55  15  59   2   3   7 109  31  96  67  35 107  88  97  90  85  28  83  86  89  98  56   5  73  37  33  81  23  48  69]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [58 40 57 70 34 35 55 48 74 62 69 76  1  0 27 53 36 11 26 61 67  4 73 10 63 18  9 65 43  5 13 42 66 31 64 30 28 49  3 46 45 71 38 44 47 15 77 68  6 52 59 12 19  7 60 21 29 51 75 37 41  2 56 72 33 16 24 32 25 39 50 14 17 20 23  8 22 54], a_shuffle_aclus: [ 78  57  76  96  51  52  74  66 102  84  93 108   3   2  36  71  53  15  35  83  90   7 100  14  85  25  13  88  60   8  17  59  89  48  86  45  37  67   5  63  62  97  55  61  64  21 109  92   9  70  81  16  26  10  82  28  41  69 107  54  58   4  75  98  50  23  33  49  34  56  68  19  24  27  32  11  31  73]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [51  4 27 67 40 58 76 24 21 32 73 39  7  0 57 12  8 52 11 65 66  6 55 20  1 29 46 60 41 15 30 14 44 77 50 61 54 64 28 43 56 74 26 25 68 69 45 18 48 37 42  5 59 23 49 22 33 35 63 53 36 19 16 17  2 75 13 72 38 10 71  3 47  9 70 31 62 34], a_shuffle_aclus: [ 69   7  36  90  57  78 108  33  28  49 100  56  10   2  76  16  11  70  15  88  89   9  74  27   3  41  63  82  58  21  45  19  61 109  68  83  73  86  37  60  75 102  35  34  92  93  62  25  66  54  59   8  81  32  67  31  50  52  85  71  53  26  23  24   4 107  17  98  55  14  97   5  64  13  96  48  84  51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [31 76 51 69 10 29 58 68 61 71 48  1 15 32 47 77 62 24 26 73 44 50 45  5 60 72 37 20 52 35 41 21 19 13 30 38 17 14 11 42 53 27  4  0 70 49 36 33  3 25 16 22 56 74 64  7 59  9 67 40 12 18 65 54  6 28 43 66  2 23 34 75  8 63 39 46 55 57], a_shuffle_aclus: [ 48 108  69  93  14  41  78  92  83  97  66   3  21  49  64 109  84  33  35 100  61  68  62   8  82  98  54  27  70  52  58  28  26  17  45  55  24  19  15  59  71  36   7   2  96  67  53  50   5  34  23  31  75 102  86  10  81  13  90  57  16  25  88  73   9  37  60  89   4  32  51 107  11  85  56  63  74  76]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [35 43 46  5  8 41  1 67 51 19 26 39 69 15 75 44  0 12 76 37 74 48 63 33  2 13 21  9  4 70 66 68 25 59 56 60 38 77 16 20  6 50 30 14 28 55 24 32 11 10 17 61 52 49 72 42 34 23 31 29 27 40 47 54 53  7 73 45 18 71 65 22 64  3 57 58 62 36], a_shuffle_aclus: [ 52  60  63   8  11  58   3  90  69  26  35  56  93  21 107  61   2  16 108  54 102  66  85  50   4  17  28  13   7  96  89  92  34  81  75  82  55 109  23  27   9  68  45  19  37  74  33  49  15  14  24  83  70  67  98  59  51  32  48  41  36  57  64  73  71  10 100  62  25  97  88  31  86   5  76  78  84  53]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [50  4  9 27 72 19 10 43 22 71 65 13 32 52 76 55 11  1 30 44 59 54 31 12 63 38 48 66  0 42 14 46 77 37  7 28 45 64 73 58 29 75 60  6 57 23 33 51 39 18  5 20 53 61 15 40 69 74 16  8 35 25  2 62 26 70 68 49 17 21 24 41  3 67 47 36 34 56], a_shuffle_aclus: [ 68   7  13  36  98  26  14  60  31  97  88  17  49  70 108  74  15   3  45  61  81  73  48  16  85  55  66  89   2  59  19  63 109  54  10  37  62  86 100  78  41 107  82   9  76  32  50  69  56  25   8  27  71  83  21  57  93 102  23  11  52  34   4  84  35  96  92  67  24  28  33  58   5  90  64  53  51  75]\n",
      "a_shuffle_IDXs: [ 2 12 35  8  4  5 34 59 15 63 77  3 36  1 39 27 22 49 28  9 71 21 41 76 33 18 11 54 30 10 37 31 51 24 32 17 55 69 14 40 52 58 67 57 44 66 73 46 64 53 68 23 16 60 13 19 20 61 48 56 26 62 75 65 29 74 38  7 42  0 50 45 72  6 70 43 47 25], a_shuffle_aclus: [  4  16  52  11   7   8  51  81  21  85 109   5  53   3  56  36  31  67  37  13  97  28  58 108  50  25  15  73  45  14  54  48  69  33  49  24  74  93  19  57  70  78  90  76  61  89 100  63  86  71  92  32  23  82  17  26  27  83  66  75  35  84 107  88  41 102  55  10  59   2  68  62  98   9  96  60  64  34]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [56 47 44 55 33 60 39 17 62 43 76 35 11 53  3 31 58 42 50 34 18 69 29 22 40 36 28 32 37 20 68 10 16 75  1  2 66 25 57  0 15 74 63 45 54 65 52 21 77  5 61 30 14 19  4 13 48 67 59  7 23 70 46 24 72  9 49 64 73 12 41 38 51 71  8 26  6 27], a_shuffle_aclus: [ 75  64  61  74  50  82  56  24  84  60 108  52  15  71   5  48  78  59  68  51  25  93  41  31  57  53  37  49  54  27  92  14  23 107   3   4  89  34  76   2  21 102  85  62  73  88  70  28 109   8  83  45  19  26   7  17  66  90  81  10  32  96  63  33  98  13  67  86 100  16  58  55  69  97  11  35   9  36]\n",
      "a_shuffle_IDXs: [ 4 48  6 22 52 71 16 43 29 70 57 17 36 15 18  2 11  7 54 51 63 14 21 47 55 56 35 20 67 42 77 75 66 24 69 65 26 23 74 32  0 68 34 33 28 49  1 53 39 62 31  3 58 45 12 46 60 50 76 41 25 27 73 61 37 72 38 13 10 59 64 30 19  9 44  5 40  8], a_shuffle_aclus: [  7  66   9  31  70  97  23  60  41  96  76  24  53  21  25   4  15  10  73  69  85  19  28  64  74  75  52  27  90  59 109 107  89  33  93  88  35  32 102  49   2  92  51  50  37  67   3  71  56  84  48   5  78  62  16  63  82  68 108  58  34  36 100  83  54  98  55  17  14  81  86  45  26  13  61   8  57  11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 0 29 11 27 45 41  1 26 30 54 15 25 22 39 56 61 33 16 35 44 49 75 31 59  9 64 19 28 17  6 14 63 67  2 77 53 40 66 37 58 13 43 48 18 51 52 10 65  3 73 34 24 46  7 70  5 21 42 68 69 60 20  8  4 38 57 71 74 12 47 72 55 76 23 32 50 62 36], a_shuffle_aclus: [  2  41  15  36  62  58   3  35  45  73  21  34  31  56  75  83  50  23  52  61  67 107  48  81  13  86  26  37  24   9  19  85  90   4 109  71  57  89  54  78  17  60  66  25  69  70  14  88   5 100  51  33  63  10  96   8  28  59  92  93  82  27  11   7  55  76  97 102  16  64  98  74 108  32  49  68  84  53]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [15 43 47 10 34 41 28  8 14 76 40 52 72 54  7 50 27 11 71 67 24 46  6 21 74  2 61 22  5 60 16 63 12 70 58 64 30 36  4 33 18 19 53 68 31 73 66 77 44 55  9 75  0 62 49  1 59 25 32 20 57 45 29 51 38 69 35 23 17 26 65 42 48 56 37 13 39  3], a_shuffle_aclus: [ 21  60  64  14  51  58  37  11  19 108  57  70  98  73  10  68  36  15  97  90  33  63   9  28 102   4  83  31   8  82  23  85  16  96  78  86  45  53   7  50  25  26  71  92  48 100  89 109  61  74  13 107   2  84  67   3  81  34  49  27  76  62  41  69  55  93  52  32  24  35  88  59  66  75  54  17  56   5]\n",
      "a_shuffle_IDXs: [77 27 63 45 61  9 76 62 22 67  7 40 60 75 29 58 43 65 35 42 10 55 39 73 37 15 23 19 38 48  3  8  1 51 32 47 53 57 70 24 28  4  6  2 69 20 25 18 41 14  5 33 46 16 74 66 59 44 13 64 31 34 12 21 49 72 54 30 56 26 50 68  0 71 11 17 52 36], a_shuffle_aclus: [109  36  85  62  83  13 108  84  31  90  10  57  82 107  41  78  60  88  52  59  14  74  56 100  54  21  32  26  55  66   5  11   3  69  49  64  71  76  96  33  37   7   9   4  93  27  34  25  58  19   8  50  63  23 102  89  81  61  17  86  48  51  16  28  67  98  73  45  75  35  68  92   2  97  15  24  70  53]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [36 71 15 30 13 76  6 75 33 49 56 43 26  8 28 20 52 29 74 37 18 51  9 69 32 34 53 24 14 64 42 44 22 55 62 45 57 54 39 10 11  3 66 38  7 50 68  2 23 72 19 31 59 73 47 27  5 65 70 35 46 48 25 12 60 77 16 58 40 67 41 63  0 21 17  4 61  1], a_shuffle_aclus: [ 53  97  21  45  17 108   9 107  50  67  75  60  35  11  37  27  70  41 102  54  25  69  13  93  49  51  71  33  19  86  59  61  31  74  84  62  76  73  56  14  15   5  89  55  10  68  92   4  32  98  26  48  81 100  64  36   8  88  96  52  63  66  34  16  82 109  23  78  57  90  58  85   2  28  24   7  83   3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [51 10 12 14 38 44 28  7 42 67 29 53 25 76 64 18  0 71  4  5 39 41 11  9  3 31 20 33 46 62 35 65 16  2 43 60 30 55 54  6 17 52 56 50 47 57 24 66 77 48 40 74 26 36 34 32 68  8 21 37 73 49  1 72 15 22 58 59 70 27 63 69 45 13 75 23 19 61], a_shuffle_aclus: [ 69  14  16  19  55  61  37  10  59  90  41  71  34 108  86  25   2  97   7   8  56  58  15  13   5  48  27  50  63  84  52  88  23   4  60  82  45  74  73   9  24  70  75  68  64  76  33  89 109  66  57 102  35  53  51  49  92  11  28  54 100  67   3  98  21  31  78  81  96  36  85  93  62  17 107  32  26  83]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [50  5 24 46 14 41 18 70 68  9 67 31 35 61  6 38 76  0 10 75 77 27 28 72 42 19 22 57 36 66 69 73  8 23 34 47 39 25 26 59 54 60 65 63 49  1 53 52 40 37  2 64 56 29 16 30 71 17 13  7 58 45 32 20 51  4 33 43  3 15 21 74 55 12 48 11 44 62], a_shuffle_aclus: [ 68   8  33  63  19  58  25  96  92  13  90  48  52  83   9  55 108   2  14 107 109  36  37  98  59  26  31  76  53  89  93 100  11  32  51  64  56  34  35  81  73  82  88  85  67   3  71  70  57  54   4  86  75  41  23  45  97  24  17  10  78  62  49  27  69   7  50  60   5  21  28 102  74  16  66  15  61  84]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 2 41 71 43 72 76 27 69 54 53  0 39 57 74 52 50 63 37 17 19 29 12 24 56 30 45 66 42 49 44 62 14 77 55 11 32 60 51  1 48  9 59  8 35 21 26 36 61 25  4  7 10 15 23 65 22 40 68  3 28 75 47 16 31 34 70 46  6 13 58 64 38 67 73 33 18 20  5], a_shuffle_aclus: [  4  58  97  60  98 108  36  93  73  71   2  56  76 102  70  68  85  54  24  26  41  16  33  75  45  62  89  59  67  61  84  19 109  74  15  49  82  69   3  66  13  81  11  52  28  35  53  83  34   7  10  14  21  32  88  31  57  92   5  37 107  64  23  48  51  96  63   9  17  78  86  55  90 100  50  25  27   8]\n",
      "a_shuffle_IDXs: [20 73 36 49 18 48 76 66 47 70 75 12 42 16 31 68 41 40 57 64 30 58  5 56 51 34 14 77 29 21 32 71 72 17 11 50 35 26 38 67 65 63  0 10 69 24 61 15 13 23 27 54 45  7  2 62 52  8  3 53 28 74 60 46  4 37 43  6 59  9 25 19 33 39 22 44 55  1], a_shuffle_aclus: [ 27 100  53  67  25  66 108  89  64  96 107  16  59  23  48  92  58  57  76  86  45  78   8  75  69  51  19 109  41  28  49  97  98  24  15  68  52  35  55  90  88  85   2  14  93  33  83  21  17  32  36  73  62  10   4  84  70  11   5  71  37 102  82  63   7  54  60   9  81  13  34  26  50  56  31  61  74   3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 0 65  8  7 17 23 22 32 50 58 38 49  9 13 71 14 19 59  3 16 66 54 55 12  4 56 74 10  2 30 51 76  6 64 36 68 61 48 28 11 72 75 24 73 26 21 33 77 57 62 39 52 15 31  5 29 53 45 46 37 60 42 40 41 27 69 35  1 70 44 34 67 18 25 47 20 43 63], a_shuffle_aclus: [  2  88  11  10  24  32  31  49  68  78  55  67  13  17  97  19  26  81   5  23  89  73  74  16   7  75 102  14   4  45  69 108   9  86  53  92  83  66  37  15  98 107  33 100  35  28  50 109  76  84  56  70  21  48   8  41  71  62  63  54  82  59  57  58  36  93  52   3  96  61  51  90  25  34  64  27  60  85]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [18 23 68 26 47 28 11 25 38  7  4 60 37 17 13 27 29 22 44 30 34 71 21 16 54 57 48  2 66  3 35 24 42 63 15 20 39 74  9 31 33 19  0  5 64 70 45 75 56 43 59 55 49 69 53 61 76 52  1 46 51 72 10 77 12 50 67 32 62 40 58 41  8 65 36 73 14  6], a_shuffle_aclus: [ 25  32  92  35  64  37  15  34  55  10   7  82  54  24  17  36  41  31  61  45  51  97  28  23  73  76  66   4  89   5  52  33  59  85  21  27  56 102  13  48  50  26   2   8  86  96  62 107  75  60  81  74  67  93  71  83 108  70   3  63  69  98  14 109  16  68  90  49  84  57  78  58  11  88  53 100  19   9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [68 34 52 10 73 25 38 64  7 70 76 29 20 36 61  6 33 53 69 56 15 14 39 57 71 32 24 37 60 40 72 21 66 74 19 23 12 31 49 22  5  4 43 55 59 54 46 63 47 65  1 17 62 58  0 18 11 13 45 48 44  2 67 50 75  8 42 51 28 77 26  9 35 30 27 41 16  3], a_shuffle_aclus: [ 92  51  70  14 100  34  55  86  10  96 108  41  27  53  83   9  50  71  93  75  21  19  56  76  97  49  33  54  82  57  98  28  89 102  26  32  16  48  67  31   8   7  60  74  81  73  63  85  64  88   3  24  84  78   2  25  15  17  62  66  61   4  90  68 107  11  59  69  37 109  35  13  52  45  36  58  23   5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [17 56 12 32 16 60 38 11 20 40 53 13 27 50  7  8 62 34 66 51 42 69 37 25 64 23  9 70 57 43 33  5  4 77 35 75 65  2 44 55 31 24 26 28  0 58 19 30 63 15 49 71  6 59 68 45 52 39 74 41 22 48 14  1 61 47 29 10 76 18 46 21 36  3 72 67 54 73], a_shuffle_aclus: [ 24  75  16  49  23  82  55  15  27  57  71  17  36  68  10  11  84  51  89  69  59  93  54  34  86  32  13  96  76  60  50   8   7 109  52 107  88   4  61  74  48  33  35  37   2  78  26  45  85  21  67  97   9  81  92  62  70  56 102  58  31  66  19   3  83  64  41  14 108  25  63  28  53   5  98  90  73 100]\n",
      "a_shuffle_IDXs: [48 23 67 53 15 56  0 38 35 54  2 13 14 17  9 74 76 69 57 75 60 41 72 28 49 46 10  7 29 37 36 51 19 59 31  4 77  3 68 16 22 44 52 33 71 63 45 25 12 20 70 26  8 58 18 43  5 24 40 65 64 30 47 27 21 32 66 39  6 73 42 50 34 55 62 11 61  1], a_shuffle_aclus: [ 66  32  90  71  21  75   2  55  52  73   4  17  19  24  13 102 108  93  76 107  82  58  98  37  67  63  14  10  41  54  53  69  26  81  48   7 109   5  92  23  31  61  70  50  97  85  62  34  16  27  96  35  11  78  25  60   8  33  57  88  86  45  64  36  28  49  89  56   9 100  59  68  51  74  84  15  83   3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [12 54 38 68 63  2 48 14 35 66 77 47 23 28  9 76 73 61  3 42  8 21 44 31 75 39 71 22 10 43  1 60 50 15 19  6 26 58 46 72 74  4 49  7 36 25 51 57 41 30 37 29 65 20  5 24 16 52 53 32 67 18 55 33 27 64 62  0 34 59 70 45 56 13 40 69 17 11], a_shuffle_aclus: [ 16  73  55  92  85   4  66  19  52  89 109  64  32  37  13 108 100  83   5  59  11  28  61  48 107  56  97  31  14  60   3  82  68  21  26   9  35  78  63  98 102   7  67  10  53  34  69  76  58  45  54  41  88  27   8  33  23  70  71  49  90  25  74  50  36  86  84   2  51  81  96  62  75  17  57  93  24  15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [10 32 56 54 58 68 61 45 51 71 35 18 30 38 24 42 67  5 25 13 55 28 26 46 52  1 40 69  3 65 63 11 70 41 72 77 39 12  2 74  9 31 33  8 53  0 20 66 21 17 29 14 47 50 36 76 62 16 37 60 19 27 57 48 75 23  6 43 34 15 44 59 64  4  7 49 73 22], a_shuffle_aclus: [ 14  49  75  73  78  92  83  62  69  97  52  25  45  55  33  59  90   8  34  17  74  37  35  63  70   3  57  93   5  88  85  15  96  58  98 109  56  16   4 102  13  48  50  11  71   2  27  89  28  24  41  19  64  68  53 108  84  23  54  82  26  36  76  66 107  32   9  60  51  21  61  81  86   7  10  67 100  31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 1 57 42 54 38 68  3 45  4 29 50  7 63 12 21  0 49  8  9 18 70  2 56 22 64 44 10 36  6 14 73 28 32 30 52 75 46 15 39 31 20 37 59  5 61 62 33 69 25 48 53 67 26 65 11 40 72 66 58 41 27 51 60 19 76 55 43 71 24 74 23 47 35 77 34 16 13 17], a_shuffle_aclus: [  3  76  59  73  55  92   5  62   7  41  68  10  85  16  28   2  67  11  13  25  96   4  75  31  86  61  14  53   9  19 100  37  49  45  70 107  63  21  56  48  27  54  81   8  83  84  50  93  34  66  71  90  35  88  15  57  98  89  78  58  36  69  82  26 108  74  60  97  33 102  32  64  52 109  51  23  17  24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 7 22 27  5 57 47 14 40 75 23 41  2  3 25 15 32 20 26 18 61 71 31 39 36 30  9 70 48 42 60 63 65 51 73  6 13 35  1 69 28 33  4 12 19 52  0 11 45 43 64 44 76 34 74 10 66  8 68 56 54 53 58 46 77 16 59 29 38 67 72 49 37 55 21 50 24 17 62], a_shuffle_aclus: [ 10  31  36   8  76  64  19  57 107  32  58   4   5  34  21  49  27  35  25  83  97  48  56  53  45  13  96  66  59  82  85  88  69 100   9  17  52   3  93  37  50   7  16  26  70   2  15  62  60  86  61 108  51 102  14  89  11  92  75  73  71  78  63 109  23  81  41  55  90  98  67  54  74  28  68  33  24  84]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 5 40 22 32 60  9 71 28 54 19 58 26 69 73 63 21 29 53 12 38 75  7 55 62 30 27 39 23 57 44 70  8 24 47 14  4 16 25 45 72 17 50 43 20 42 77 67 34 11 65  2 33  3 10 49 52 36 18 31 59 35  6 41  1 48 37 76 15 74 51 46 56 64 68  0 61 66 13], a_shuffle_aclus: [  8  57  31  49  82  13  97  37  73  26  78  35  93 100  85  28  41  71  16  55 107  10  74  84  45  36  56  32  76  61  96  11  33  64  19   7  23  34  62  98  24  68  60  27  59 109  90  51  15  88   4  50   5  14  67  70  53  25  48  81  52   9  58   3  66  54 108  21 102  69  63  75  86  92   2  83  89  17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [26 42 58  0 61 25 56 45  8 44 41 52 75 65 23 46 64 63 47 35 77 16 22 27 62  3 28 40 66 33 38 13 31 76 59 21  9 17 43  2 70 51 74 60 19 71 49 11 12  7 32  4 18 34 67 36 14 72 37 30 10 48  5 73 24 55 29 68 54  1 57  6 53 20 50 39 69 15], a_shuffle_aclus: [ 35  59  78   2  83  34  75  62  11  61  58  70 107  88  32  63  86  85  64  52 109  23  31  36  84   5  37  57  89  50  55  17  48 108  81  28  13  24  60   4  96  69 102  82  26  97  67  15  16  10  49   7  25  51  90  53  19  98  54  45  14  66   8 100  33  74  41  92  73   3  76   9  71  27  68  56  93  21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [77 55 32 53 36 44 72 10  3  2 47 68 25  8 40 42 31 48 43 73 46 14 12 64 50 24  5 38 75 56 34  1  9 74 29 49 26 28 57 60 23 13 22 41 45 58 66 21  6 20 16 19 54  7 63 69 18 52 37 51 27  0 65 70 62 30 33 35 39 17 15 67 11 71 59  4 61 76], a_shuffle_aclus: [109  74  49  71  53  61  98  14   5   4  64  92  34  11  57  59  48  66  60 100  63  19  16  86  68  33   8  55 107  75  51   3  13 102  41  67  35  37  76  82  32  17  31  58  62  78  89  28   9  27  23  26  73  10  85  93  25  70  54  69  36   2  88  96  84  45  50  52  56  24  21  90  15  97  81   7  83 108]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 9 45 25 10 33 12 44 13 54 75 60 22  8 73 32 24 56  4 76 48 69  1 65 20 21  5 38 37 26 71  3 47 49 36 66 55 46 28 61 23 70 11 34  7 19 51  6 41 72  2 35 52 63 39 74 14 58 42 77 30 62 43 40 53 67 59 50 16 31 57 15 29 18 64 27 17 68  0], a_shuffle_aclus: [ 13  62  34  14  50  16  61  17  73 107  82  31  11 100  49  33  75   7 108  66  93   3  88  27  28   8  55  54  35  97   5  64  67  53  89  74  63  37  83  32  96  15  51  10  26  69   9  58  98   4  52  70  85  56 102  19  78  59 109  45  84  60  57  71  90  81  68  23  48  76  21  41  25  86  36  24  92   2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [58  6 22 54 70 71 39 34 75 56 61 55 59 65 25 33 49 21 42 15 73  1  5 43 74  3 69 57 12 38 29 62 52 48 20 31 13 14 66 27 47 68 41 36 19  2 23 76  0 72 63 51  8 10 53  9 26 30 37 16 64 50 46 17 28  7 67 18 44 40 35 24 60 32 77 45 11  4], a_shuffle_aclus: [ 78   9  31  73  96  97  56  51 107  75  83  74  81  88  34  50  67  28  59  21 100   3   8  60 102   5  93  76  16  55  41  84  70  66  27  48  17  19  89  36  64  92  58  53  26   4  32 108   2  98  85  69  11  14  71  13  35  45  54  23  86  68  63  24  37  10  90  25  61  57  52  33  82  49 109  62  15   7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [37  7 24 43 12 47 34 62 52 15 67  8 23 76 10 59 70 72 73 63 75 22 58 57  2 69 14  1 28 71 64 17 31  6 54 46  3 33 66 32  9 11 49 60 18  0 13 19 61 48  4 45 27 25 35 68  5 50 55 40 74 44 38 77 29 41 30 36 20 53 42 65 51 39 16 26 56 21], a_shuffle_aclus: [ 54  10  33  60  16  64  51  84  70  21  90  11  32 108  14  81  96  98 100  85 107  31  78  76   4  93  19   3  37  97  86  24  48   9  73  63   5  50  89  49  13  15  67  82  25   2  17  26  83  66   7  62  36  34  52  92   8  68  74  57 102  61  55 109  41  58  45  53  27  71  59  88  69  56  23  35  75  28]\n",
      "a_shuffle_IDXs: [34 51 46 19 20 70 10 72 36 74 64 52 59 47  5  7 12 30  2  0 14 32 58 53 38 41 37 42 77 54 49 65  8 15 56 40 25 71 21 50 22 39 13 60  9 57 62  1  4 29 63  3 45 31 33 11 76 44 66 69 24 18  6 67 16 73 17 55 28 23 61 48 27 43 68 35 26 75], a_shuffle_aclus: [ 51  69  63  26  27  96  14  98  53 102  86  70  81  64   8  10  16  45   4   2  19  49  78  71  55  58  54  59 109  73  67  88  11  21  75  57  34  97  28  68  31  56  17  82  13  76  84   3   7  41  85   5  62  48  50  15 108  61  89  93  33  25   9  90  23 100  24  74  37  32  83  66  36  60  92  52  35 107]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [75 64  6 46 40 23 58 67 74 16 13 37 15 56  5 73 21 29  8 12 43 61 69 49 33 47  7  0 41 48 57 27 63 11 34 76 10 62 42 31 77  3 18 45 71 17 65 50 24 30 38 39 60 20 70 44 32 26 28 14 55 53  9 36  2 72 54  1 52 59 68 35 66 19  4 22 25 51], a_shuffle_aclus: [107  86   9  63  57  32  78  90 102  23  17  54  21  75   8 100  28  41  11  16  60  83  93  67  50  64  10   2  58  66  76  36  85  15  51 108  14  84  59  48 109   5  25  62  97  24  88  68  33  45  55  56  82  27  96  61  49  35  37  19  74  71  13  53   4  98  73   3  70  81  92  52  89  26   7  31  34  69]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [51 26 70 54 53 77 35 15 19 11 67 24  1 40  4 33 38  7 20 66 47 57 25 44 50 41 16 73 60 18 39 37 12 64 49 28 48 59 55 69  8 68 71 31 13  5 62 74 29 56 21 65 46 36  0 76  2 52 10 34 63  9 75 32 72 30 17  3 58 45 43 61 42 27  6 14 23 22], a_shuffle_aclus: [ 69  35  96  73  71 109  52  21  26  15  90  33   3  57   7  50  55  10  27  89  64  76  34  61  68  58  23 100  82  25  56  54  16  86  67  37  66  81  74  93  11  92  97  48  17   8  84 102  41  75  28  88  63  53   2 108   4  70  14  51  85  13 107  49  98  45  24   5  78  62  60  83  59  36   9  19  32  31]\n",
      "a_shuffle_IDXs: [13 50 31 61 32 29 24 37 65 46 59  4 47 55 63 23 58  6 51 12 15 68 75 28 49 22 72 36 30  8 27 73  2 56 53 21 67  1 60 34 71 54 66 38 14 77 11 70 74  3 69 44  5  9 76  0 10 57 17 18 41 35 16 39 40 26 19 33 20 52 45 42 62 64 43  7 25 48], a_shuffle_aclus: [ 17  68  48  83  49  41  33  54  88  63  81   7  64  74  85  32  78   9  69  16  21  92 107  37  67  31  98  53  45  11  36 100   4  75  71  28  90   3  82  51  97  73  89  55  19 109  15  96 102   5  93  61   8  13 108   2  14  76  24  25  58  52  23  56  57  35  26  50  27  70  62  59  84  86  60  10  34  66]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [26 68 22 52 50 25 19 13 20 24 57 44 35 51 31 36  2 73 60 37 33 46 64 28  7 40  0  3 32 72 17 67 10 47 53 34 74 45 49 18 77  6 16 70  8 14 62 58 11 15 48 43 71 66 42  1  5 54 63 41 21 76 27 75 38 59 65 61  4 30 12 55 56 29 39  9 23 69], a_shuffle_aclus: [ 35  92  31  70  68  34  26  17  27  33  76  61  52  69  48  53   4 100  82  54  50  63  86  37  10  57   2   5  49  98  24  90  14  64  71  51 102  62  67  25 109   9  23  96  11  19  84  78  15  21  66  60  97  89  59   3   8  73  85  58  28 108  36 107  55  81  88  83   7  45  16  74  75  41  56  13  32  93]\n",
      "a_shuffle_IDXs: [22 31 17 25  9 47 49 73 57 11 70 30 69 38 36 76 65 32 68 16 51 45 67  3 19  1 54 33 35 23 61 13 24 52 14 56  4 29 43 62 34 20 26 44 55 46 75 21 63  8 28 15 37  2 66 74 48 53  7 77 59 42 39  5 58 72 41 27 50 18 64 10 71 40 12  6  0 60], a_shuffle_aclus: [ 31  48  24  34  13  64  67 100  76  15  96  45  93  55  53 108  88  49  92  23  69  62  90   5  26   3  73  50  52  32  83  17  33  70  19  75   7  41  60  84  51  27  35  61  74  63 107  28  85  11  37  21  54   4  89 102  66  71  10 109  81  59  56   8  78  98  58  36  68  25  86  14  97  57  16   9   2  82]\n",
      "a_shuffle_IDXs: [51 24 52  4 66  9 48 16 17 61 75 39 19 44  7 13 38 18 21 28 10 33 42 34 20 11 62  8 59 60 15 56 49 40 45 37 55 64 68 71 25 54 30 72  6  2 77 58 35 27 73 63 46 12 67 22 29 31 14 76 41 43 47 74 23 57 36 70 32 53  5  1  3 50  0 26 69 65], a_shuffle_aclus: [ 69  33  70   7  89  13  66  23  24  83 107  56  26  61  10  17  55  25  28  37  14  50  59  51  27  15  84  11  81  82  21  75  67  57  62  54  74  86  92  97  34  73  45  98   9   4 109  78  52  36 100  85  63  16  90  31  41  48  19 108  58  60  64 102  32  76  53  96  49  71   8   3   5  68   2  35  93  88]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [45 53 71 36 30 49 48  5 63 13 12 62 69  3 18 50 17 77 67 44 35 56 16 15 39 73 42 20 61 38 33 72  9  2  7 27  8 34 31 57 58 68 54 32 11 22 26 60  1 65 21 74 70 52 25 47 43 37 40 23 41  6 19 59 75  4 10 46 66 76 29  0 55 64 24 51 28 14], a_shuffle_aclus: [ 62  71  97  53  45  67  66   8  85  17  16  84  93   5  25  68  24 109  90  61  52  75  23  21  56 100  59  27  83  55  50  98  13   4  10  36  11  51  48  76  78  92  73  49  15  31  35  82   3  88  28 102  96  70  34  64  60  54  57  32  58   9  26  81 107   7  14  63  89 108  41   2  74  86  33  69  37  19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [47 35 70 15 14 67 62  0 68 64 73  7 60 77 40 32  9 28 61 16 39  4 48 17 38 55 22 72 76 27 30 42 12 45 69 19 31 49 37 26 57 21 56 44 24 34 20 43 52  5 66 51 54 18 41 23 46 13 10 25 65 74 58  1  2 11  6 36  3 59 71 33 53 29 50 75  8 63], a_shuffle_aclus: [ 64  52  96  21  19  90  84   2  92  86 100  10  82 109  57  49  13  37  83  23  56   7  66  24  55  74  31  98 108  36  45  59  16  62  93  26  48  67  54  35  76  28  75  61  33  51  27  60  70   8  89  69  73  25  58  32  63  17  14  34  88 102  78   3   4  15   9  53   5  81  97  50  71  41  68 107  11  85]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [42 40  6 69 30 17 31 33 25 43 16 59 37 64 52  4 14 46 66 10 34 72 61 62 56 32  0 47 71 36 41 70 50 22  1 75 28 45 63 44 49 77 55 48 51 39 27 12 60 29 68 57 21 23  2 67  3  5 18  7  9 54 19 76 13 74 26 38 15 65 24 58 53 73 35 11  8 20], a_shuffle_aclus: [ 59  57   9  93  45  24  48  50  34  60  23  81  54  86  70   7  19  63  89  14  51  98  83  84  75  49   2  64  97  53  58  96  68  31   3 107  37  62  85  61  67 109  74  66  69  56  36  16  82  41  92  76  28  32   4  90   5   8  25  10  13  73  26 108  17 102  35  55  21  88  33  78  71 100  52  15  11  27]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [51 75 44 32 39 25 34  8 71 22 29 24 18 63 58 76 69  0 33 55  5 62 72 35 54 45 74 14 66 11  4 57 41 77 15 23 37 19 60 36 17  9 10 53 48 47  7 70 68  6 12 64 26 50  3 21 56  2 46 59 28 67 61 16 42 40 27 30 20  1 49 65 52 38 13 73 43 31], a_shuffle_aclus: [ 69 107  61  49  56  34  51  11  97  31  41  33  25  85  78 108  93   2  50  74   8  84  98  52  73  62 102  19  89  15   7  76  58 109  21  32  54  26  82  53  24  13  14  71  66  64  10  96  92   9  16  86  35  68   5  28  75   4  63  81  37  90  83  23  59  57  36  45  27   3  67  88  70  55  17 100  60  48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [76 16 50  4 68  6 47 19 45  3 31 24 14 39 36 35 69 71 29 17 27 20  8 48 46 41 26 10 72  1 63  5 77 23 60  7 74 21  0 18 25 66 62 42 55 38  9 30 12 75 51 52 57 40 13 44 33 22 43 67 53 37 65  2 15 59 32 49 11 54 58 73 56 70 61 34 64 28], a_shuffle_aclus: [108  23  68   7  92   9  64  26  62   5  48  33  19  56  53  52  93  97  41  24  36  27  11  66  63  58  35  14  98   3  85   8 109  32  82  10 102  28   2  25  34  89  84  59  74  55  13  45  16 107  69  70  76  57  17  61  50  31  60  90  71  54  88   4  21  81  49  67  15  73  78 100  75  96  83  51  86  37]\n",
      "a_shuffle_IDXs: [54 34 36 27 43 18 48 73 71 29 24 22  7 47 68 63 55 19  2 42 62 45 57 39 66 17 40 70 58 33 56 10 14 41  0  1 51 46  6 75 64 53 44 20 59 52 77 49 12 35 11 13 61 25 21 76 69 74  9  4  5 28 32 65 67 30 23 60 26 37 31 38 15  3 50 72  8 16], a_shuffle_aclus: [ 73  51  53  36  60  25  66 100  97  41  33  31  10  64  92  85  74  26   4  59  84  62  76  56  89  24  57  96  78  50  75  14  19  58   2   3  69  63   9 107  86  71  61  27  81  70 109  67  16  52  15  17  83  34  28 108  93 102  13   7   8  37  49  88  90  45  32  82  35  54  48  55  21   5  68  98  11  23]\n",
      "a_shuffle_IDXs: [ 1 44 71 26  8 55 41  3 48 12 29  4 35 21 38 57 24 74 37 68 50 30 45 16 14 43 73 72 20 13 54 39 64 36 77 53 19 52 67 46 17 15 65 62 75 11 18 32 59 22 49  0  2 31 76 40  5 69 27 61 23 60 56 58 25 70 42 63  7  9 28 34 33  6 10 66 47 51], a_shuffle_aclus: [  3  61  97  35  11  74  58   5  66  16  41   7  52  28  55  76  33 102  54  92  68  45  62  23  19  60 100  98  27  17  73  56  86  53 109  71  26  70  90  63  24  21  88  84 107  15  25  49  81  31  67   2   4  48 108  57   8  93  36  83  32  82  75  78  34  96  59  85  10  13  37  51  50   9  14  89  64  69]\n",
      "a_shuffle_IDXs: [48 18 75 72 28 33 71 67 76 62  5 43  2  8 31 38 77 60 50 54 32 12 59 19 36  6 69 17 40 51 14 56 11 70 22 46 74 65  4 30 10 42 27 49 55 64 26  7 68 66 63 45 47  1  0 57 41 29 15 58 16 13 25 61 44  9 21 23 73 35 37 53 39 52 20  3 34 24], a_shuffle_aclus: [ 66  25 107  98  37  50  97  90 108  84   8  60   4  11  48  55 109  82  68  73  49  16  81  26  53   9  93  24  57  69  19  75  15  96  31  63 102  88   7  45  14  59  36  67  74  86  35  10  92  89  85  62  64   3   2  76  58  41  21  78  23  17  34  83  61  13  28  32 100  52  54  71  56  70  27   5  51  33]\n",
      "a_shuffle_IDXs: [30 75  7 69 66 14 64  5 15 42 22 65 28 19 58 27 49 12 71  4 18 32 21 13 44 62 11  3 16 50 31  1 24 73  0 26 52 60 72 41 48 29 67 53  8 63 20 38 37  9 39 10 36 17 43 35 25 34 56 51 23 70 40  6 45 77 33 68 61  2 54 55 57 76 74 59 47 46], a_shuffle_aclus: [ 45 107  10  93  89  19  86   8  21  59  31  88  37  26  78  36  67  16  97   7  25  49  28  17  61  84  15   5  23  68  48   3  33 100   2  35  70  82  98  58  66  41  90  71  11  85  27  55  54  13  56  14  53  24  60  52  34  51  75  69  32  96  57   9  62 109  50  92  83   4  73  74  76 108 102  81  64  63]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [11 47 68 27 32 45 67 57 36 44  2 31 10 51 16 56 74  7 58 65 52 61 37  0 63 73 48 49 33 26 62 41 53 38  9 70 69 60 21  1 40 13 34 76 14 23 17 30  3 42 22 19 24  5  4 54 18 43 75 59 28 77 46 72 64 35 39  6 71 20 55 15 66 12 50 25  8 29], a_shuffle_aclus: [ 15  64  92  36  49  62  90  76  53  61   4  48  14  69  23  75 102  10  78  88  70  83  54   2  85 100  66  67  50  35  84  58  71  55  13  96  93  82  28   3  57  17  51 108  19  32  24  45   5  59  31  26  33   8   7  73  25  60 107  81  37 109  63  98  86  52  56   9  97  27  74  21  89  16  68  34  11  41]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [54 20 35 60  7  8 44 38  3 65 39 19 46 34 72 12 59 45 24 33 36 22 13 51 26 17 31 64 73 55 56 41 52  2 71 75 29  5 27 23 50 49 74  9 11 25 63 14 32 48 30 18 67 66 47 77 15 43  6 16 68 69 58 40  1 70 76 57 21  4 28 61 37 62 53 42 10  0], a_shuffle_aclus: [ 73  27  52  82  10  11  61  55   5  88  56  26  63  51  98  16  81  62  33  50  53  31  17  69  35  24  48  86 100  74  75  58  70   4  97 107  41   8  36  32  68  67 102  13  15  34  85  19  49  66  45  25  90  89  64 109  21  60   9  23  92  93  78  57   3  96 108  76  28   7  37  83  54  84  71  59  14   2]\n",
      "a_shuffle_IDXs: [65 11 24 48 25 35 58 17 29 47 70 74 61 16 18  0 19 55 75 21 20 73 42 22 10 45 66 69 41 13 51  1 30 34 27 77  6  3 28 15  5 49 14 72 12 44 60 67  2 36 40 32 46 76 68 62  7 57  8 31 54 39 38 26 53 23 33 50 52  4 37 43 63 59  9 64 71 56], a_shuffle_aclus: [ 88  15  33  66  34  52  78  24  41  64  96 102  83  23  25   2  26  74 107  28  27 100  59  31  14  62  89  93  58  17  69   3  45  51  36 109   9   5  37  21   8  67  19  98  16  61  82  90   4  53  57  49  63 108  92  84  10  76  11  48  73  56  55  35  71  32  50  68  70   7  54  60  85  81  13  86  97  75]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [43 55  6 72 36  3 49 56 26 42  5 62 24 35 61 12 37 63 13 71 44 15 45 66 16 40 20 48 59 74  8 11 73 60  9 67 50 28 14  4  7 34 76 22 69 58 70 68 77 31 38 25 75 41 18 29 46 17 23  1 19 27 51  0 32 30 64 54 52 65 39 53 57 10 21 47 33  2], a_shuffle_aclus: [ 60  74   9  98  53   5  67  75  35  59   8  84  33  52  83  16  54  85  17  97  61  21  62  89  23  57  27  66  81 102  11  15 100  82  13  90  68  37  19   7  10  51 108  31  93  78  96  92 109  48  55  34 107  58  25  41  63  24  32   3  26  36  69   2  49  45  86  73  70  88  56  71  76  14  28  64  50   4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 4 77 76 22 54 25 69 66 36 26 60 42 37 20 43 56 70 16 40 62 28 48 47 30 18 63 13 49 10 15 46  2  6 14 38  1 55 58 41 17 29 68 21 23 45 71 34 67 75  3 44 53  0 50 65 73 51  5 19 61 33 32 72 57 64 27 35 52 31 39 12  7 74 11 24  8  9 59], a_shuffle_aclus: [  7 109 108  31  73  34  93  89  53  35  82  59  54  27  60  75  96  23  57  84  37  66  64  45  25  85  17  67  14  21  63   4   9  19  55   3  74  78  58  24  41  92  28  32  62  97  51  90 107   5  61  71   2  68  88 100  69   8  26  83  50  49  98  76  86  36  52  70  48  56  16  10 102  15  33  11  13  81]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [58 49 10 15 47 38 72 40 30 20 64  5 34 17 31 60 50 39 70 66 68 14 48 36 67 23 54 61 76 46  3  1 57  7 53 63 28 24  0 74 35 71 41 25  2 13 32 12 33 62  8 52 45 16 56  9 51 18 22 29 77 44 11 69 21 59 73 42 37  6 75  4 65 43 19 55 27 26], a_shuffle_aclus: [ 78  67  14  21  64  55  98  57  45  27  86   8  51  24  48  82  68  56  96  89  92  19  66  53  90  32  73  83 108  63   5   3  76  10  71  85  37  33   2 102  52  97  58  34   4  17  49  16  50  84  11  70  62  23  75  13  69  25  31  41 109  61  15  93  28  81 100  59  54   9 107   7  88  60  26  74  36  35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [56 57 18 36 58 59 66 22 55 49 76 43 35 75 19 48 72 32 40 62  7 71 73 24 64 30 47 12 65 33 70 67 45  9 23 29 44 60 61 69  8 31  3 39  1 25 68 52 53 42 10 46 21  2 11 16 13 77  4 54 26 15  6 50  0 38 17 74 27 34  5 51 14 63 20 28 37 41], a_shuffle_aclus: [ 75  76  25  53  78  81  89  31  74  67 108  60  52 107  26  66  98  49  57  84  10  97 100  33  86  45  64  16  88  50  96  90  62  13  32  41  61  82  83  93  11  48   5  56   3  34  92  70  71  59  14  63  28   4  15  23  17 109   7  73  35  21   9  68   2  55  24 102  36  51   8  69  19  85  27  37  54  58]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [30 54 68 31 13 25 35 63 32 41 61  3 15 20 46 67 18 29 55 27 58 36 14  8 28 17 73 69 74 39 64 12 22 19 23 50 53 24 59 40 76 62 49 52 75 57 71  1 33 51 34  9 44 48 77 26 16 37 60  7 56 10 11 43 47  4 21 42 70 66  2 38  5 65 72  6  0 45], a_shuffle_aclus: [ 45  73  92  48  17  34  52  85  49  58  83   5  21  27  63  90  25  41  74  36  78  53  19  11  37  24 100  93 102  56  86  16  31  26  32  68  71  33  81  57 108  84  67  70 107  76  97   3  50  69  51  13  61  66 109  35  23  54  82  10  75  14  15  60  64   7  28  59  96  89   4  55   8  88  98   9   2  62]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [25 29 42 17 55 33 28 47 61 68 24 56 14 72 23 73 26 51 40 31 52  6 77 70 65  4 48 43 46 22 75 71 10 60 38  8 15 21 16  3 18 69 62 36 67 30  5 41 35 27  1 63 11 19 66  0 20 39 76 45 64 44 50 74 57 54 32 34  2  9 13 37  7 59 53 49 58 12], a_shuffle_aclus: [ 34  41  59  24  74  50  37  64  83  92  33  75  19  98  32 100  35  69  57  48  70   9 109  96  88   7  66  60  63  31 107  97  14  82  55  11  21  28  23   5  25  93  84  53  90  45   8  58  52  36   3  85  15  26  89   2  27  56 108  62  86  61  68 102  76  73  49  51   4  13  17  54  10  81  71  67  78  16]\n",
      "a_shuffle_IDXs: [65 28 46  5  0 32 48 67  3 54 31 58 64 73 19 71 26 57 24 38 43 61 69 16 36 77 17 55 25  1 14 12 29 21 11 37 33  4 53 76 63 74  9 22 66 40 52 59 42 51  7 72 62 20 34 60 27 13 15 39 10 44 18 45 30 68 56 47 41 70  8 50 23  2 35  6 49 75], a_shuffle_aclus: [ 88  37  63   8   2  49  66  90   5  73  48  78  86 100  26  97  35  76  33  55  60  83  93  23  53 109  24  74  34   3  19  16  41  28  15  54  50   7  71 108  85 102  13  31  89  57  70  81  59  69  10  98  84  27  51  82  36  17  21  56  14  61  25  62  45  92  75  64  58  96  11  68  32   4  52   9  67 107]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [31 24 73  8  6 53  7 50 45 55 40 71 34 14 32 47 67  3  1 29 19 42 22 16 70 10 13 66 56 33 44 48 23 25  5 20  0 54 43 46 61 49  2 51 60 30 52 27  9 38 64 35 21 59 58 62 68 39 65 74 41 77 11 76 75 28 69 26 18 17 36 12 37 72  4 15 63 57], a_shuffle_aclus: [ 48  33 100  11   9  71  10  68  62  74  57  97  51  19  49  64  90   5   3  41  26  59  31  23  96  14  17  89  75  50  61  66  32  34   8  27   2  73  60  63  83  67   4  69  82  45  70  36  13  55  86  52  28  81  78  84  92  56  88 102  58 109  15 108 107  37  93  35  25  24  53  16  54  98   7  21  85  76]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [29  5 48 12 60 76 66 63 59 69 23 20 26 51 15 62 70 24 52 47 10 41 54 32 19 14 74  3 50 46 58  1 39 64  6 16  9 36 21 40 55 56 22 72 42 37  4 61 65 31 49 44 75 11 17 28 68 13 77 35 71  0  7 57  2 53 43 33 34 30 67 73 25 18 38 45  8 27], a_shuffle_aclus: [ 41   8  66  16  82 108  89  85  81  93  32  27  35  69  21  84  96  33  70  64  14  58  73  49  26  19 102   5  68  63  78   3  56  86   9  23  13  53  28  57  74  75  31  98  59  54   7  83  88  48  67  61 107  15  24  37  92  17 109  52  97   2  10  76   4  71  60  50  51  45  90 100  34  25  55  62  11  36]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [46 13 14 11 25 65 51 23  7 54 59 20 52 45 27 49 19 32 77 44 48 73 53 70 75 30 61 34 56  5 57 60 62 67 41 58 68  9 76  8 39 35 69 26 66  4 10  0 55 33  1 37 28 12 17 43  2 21 64  3 63 47 29 74 36 31 24  6 16 42 71 50 18 15 72 22 38 40], a_shuffle_aclus: [ 63  17  19  15  34  88  69  32  10  73  81  27  70  62  36  67  26  49 109  61  66 100  71  96 107  45  83  51  75   8  76  82  84  90  58  78  92  13 108  11  56  52  93  35  89   7  14   2  74  50   3  54  37  16  24  60   4  28  86   5  85  64  41 102  53  48  33   9  23  59  97  68  25  21  98  31  55  57]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [37  2 29 68 42 55 19 27 31 15 76 33 10 61 20 77 30 45  1  4 67 73 12 53 57 13  9 64 56 59 48  7 11 58 71 65 49 41 75 63 24 72 51  8  3 25  5 60  6 44 36 34 22 66 69 50 47 35 39 52 74 16 62  0 54 18 26 43 28 17 14 32 38 40 21 46 70 23], a_shuffle_aclus: [ 54   4  41  92  59  74  26  36  48  21 108  50  14  83  27 109  45  62   3   7  90 100  16  71  76  17  13  86  75  81  66  10  15  78  97  88  67  58 107  85  33  98  69  11   5  34   8  82   9  61  53  51  31  89  93  68  64  52  56  70 102  23  84   2  73  25  35  60  37  24  19  49  55  57  28  63  96  32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [67 21 25 24  3 61 19 55 14 29 37 64  9 22 12 38 75 59 33 56  8 50  7 77  5 18 47 76 53 70 10 23 41 11  0 43 42  1 26 62 57 20 15 13 52 63 69 68 40 48 65 58 46  2 16 27 17 49 39  6  4 74 66 73 44 35 32 31 36 30 54 60 34 28 51 71 72 45], a_shuffle_aclus: [ 90  28  34  33   5  83  26  74  19  41  54  86  13  31  16  55 107  81  50  75  11  68  10 109   8  25  64 108  71  96  14  32  58  15   2  60  59   3  35  84  76  27  21  17  70  85  93  92  57  66  88  78  63   4  23  36  24  67  56   9   7 102  89 100  61  52  49  48  53  45  73  82  51  37  69  97  98  62]\n",
      "a_shuffle_IDXs: [75 28 52 18 71 63 25 70 14 43 20 56 60 55 39 37 62 47 30 13 42 40 73 27 77 72  6 29  8 34 68 50 10  1 24  0 66 59 49 44 17  9 32 67 64 61  3  7 45 16 53 38 21 36 35 51 19 26 54  2 74 22  4 76 69 31 58 48 41 23 15 11 65  5 57 33 46 12], a_shuffle_aclus: [107  37  70  25  97  85  34  96  19  60  27  75  82  74  56  54  84  64  45  17  59  57 100  36 109  98   9  41  11  51  92  68  14   3  33   2  89  81  67  61  24  13  49  90  86  83   5  10  62  23  71  55  28  53  52  69  26  35  73   4 102  31   7 108  93  48  78  66  58  32  21  15  88   8  76  50  63  16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [44 49  8 41 66 63 17 30 36  3 65 54 57 10  5 47  6 68 40  2 37 71 32 15 59 77 39 58 26 61 67 64 51 45 73 75  9 11  0 74 43 42 27 70 13 29 28 76 19 12 52  7 18 46 38 24 50 16 35  4 33 21 53 56 25 72 20 23 14  1 55 48 69 34 31 22 60 62], a_shuffle_aclus: [ 61  67  11  58  89  85  24  45  53   5  88  73  76  14   8  64   9  92  57   4  54  97  49  21  81 109  56  78  35  83  90  86  69  62 100 107  13  15   2 102  60  59  36  96  17  41  37 108  26  16  70  10  25  63  55  33  68  23  52   7  50  28  71  75  34  98  27  32  19   3  74  66  93  51  48  31  82  84]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [33 29 11 76 52 54 41  9 70 53 30 18  4  8 68 25 31 60 73 15 58 13 35 45 59 66 19  2 37 24 69 71 26 44 23  1 38 57 50 62  0 22 55 72 67 74 14 40 39  7 43 34  3 27 75 49 16 21 12 32 28 46 64 51 17 47 10  6 42 61 36 56 20  5 63 77 65 48], a_shuffle_aclus: [ 50  41  15 108  70  73  58  13  96  71  45  25   7  11  92  34  48  82 100  21  78  17  52  62  81  89  26   4  54  33  93  97  35  61  32   3  55  76  68  84   2  31  74  98  90 102  19  57  56  10  60  51   5  36 107  67  23  28  16  49  37  63  86  69  24  64  14   9  59  83  53  75  27   8  85 109  88  66]\n",
      "a_shuffle_IDXs: [21 77 22 68 52  0 23 56 35 46 24 36 75 47 34 45 55 69 25 11 40 53 19 15  4 66 31 51  9  1 59 12 27 76 20  7 16 38 71 32 28 10  5 42 73 54 58 74 72 64 17 43 62 39 33 29 70 30 14 18  2 44  6 61 26 65 48 67  3 41 60  8 50 13 49 57 63 37], a_shuffle_aclus: [ 28 109  31  92  70   2  32  75  52  63  33  53 107  64  51  62  74  93  34  15  57  71  26  21   7  89  48  69  13   3  81  16  36 108  27  10  23  55  97  49  37  14   8  59 100  73  78 102  98  86  24  60  84  56  50  41  96  45  19  25   4  61   9  83  35  88  66  90   5  58  82  11  68  17  67  76  85  54]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [17 40  7 63 64 30 56 34  6 48 39 32 41 69 16 29  4 21 12 15 55 71 74 14 57 49 31 47 43 67  5 51 42 54 45 59 53 52 36 37 70  9 25 20 50 26 75 46 13  2 66  8 22 73 23 76 19 62  0 24 28 33 38 61 27 77  3 58 44 68 10 18 11 65 60 35 72  1], a_shuffle_aclus: [ 24  57  10  85  86  45  75  51   9  66  56  49  58  93  23  41   7  28  16  21  74  97 102  19  76  67  48  64  60  90   8  69  59  73  62  81  71  70  53  54  96  13  34  27  68  35 107  63  17   4  89  11  31 100  32 108  26  84   2  33  37  50  55  83  36 109   5  78  61  92  14  25  15  88  82  52  98   3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [43 71 53  5 21 26 75 77 12 31 40 16 60 51 13 66  0 54 11 39 72  2 20 17 70 23 55 46 24 19 33  7 65 25 42 57 61 62  9  1 67  6 73 27 64 44 69 59 41  4 50 74 15 68 36 52 76 56 14 48 22 63 28 45 38 32 29 58 37 18 47 35 49  3  8 30 10 34], a_shuffle_aclus: [ 60  97  71   8  28  35 107 109  16  48  57  23  82  69  17  89   2  73  15  56  98   4  27  24  96  32  74  63  33  26  50  10  88  34  59  76  83  84  13   3  90   9 100  36  86  61  93  81  58   7  68 102  21  92  53  70 108  75  19  66  31  85  37  62  55  49  41  78  54  25  64  52  67   5  11  45  14  51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [45 12 34 27 26 32 57  7 75 21 41 55 38 17 68 33 37 46 18 50 48  3 22 66 29 30 20  2 51 63 52 58  4 71 16 43 15 23 11 44 39 69 28 65 56 53 24 36 64 54 72 67 14 61  1 35  5 70 59 73  9  0  8 25  6 47 49 13 74 42 60 77 40 62 19 31 10 76], a_shuffle_aclus: [ 62  16  51  36  35  49  76  10 107  28  58  74  55  24  92  50  54  63  25  68  66   5  31  89  41  45  27   4  69  85  70  78   7  97  23  60  21  32  15  61  56  93  37  88  75  71  33  53  86  73  98  90  19  83   3  52   8  96  81 100  13   2  11  34   9  64  67  17 102  59  82 109  57  84  26  48  14 108]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [46 68 25 14  3 53 57 66  0 48 12 44 73 75 24 11  8 36 74 47 39 29 55 65 69 50 71 54 31 61 23 27 63 40 22 10 20 43 62 28  4  1 19 45 18 51 59 67 37  2  7 32 60 52 13 34 76 49 42 77  6 38 26 35 70 58 33 30 56 15 17  9 64 16 41 21  5 72], a_shuffle_aclus: [ 63  92  34  19   5  71  76  89   2  66  16  61 100 107  33  15  11  53 102  64  56  41  74  88  93  68  97  73  48  83  32  36  85  57  31  14  27  60  84  37   7   3  26  62  25  69  81  90  54   4  10  49  82  70  17  51 108  67  59 109   9  55  35  52  96  78  50  45  75  21  24  13  86  23  58  28   8  98]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [70 39 51  9 66 36 28 52 69 41 53  0 58 25 67  8 46 10 37 48 22 35 56  3 55 43 20 61 23 74 76 54 40 72 57 26 60  6 45 62 38 12 21 42 14 68 11 29 59  2 49 27  1 19  7 31 47 75 44 17 16 30 24 33 34 77 50 32 18 63 13 71  4 15 73 64 65  5], a_shuffle_aclus: [ 96  56  69  13  89  53  37  70  93  58  71   2  78  34  90  11  63  14  54  66  31  52  75   5  74  60  27  83  32 102 108  73  57  98  76  35  82   9  62  84  55  16  28  59  19  92  15  41  81   4  67  36   3  26  10  48  64 107  61  24  23  45  33  50  51 109  68  49  25  85  17  97   7  21 100  86  88   8]\n",
      "a_shuffle_IDXs: [12 35 21  8 32 58 13 49 40 77 37  0 15 63  6 26 71 57 75 46 74 68 55 22 62 45 24 76 33 20 31 17  5 30  9 25 60 48 34 27 28 69 39 11 72 61  1 14 19 73 67  4 66 41 44 47 29 23  7 50 10 53 54  2 52 18 64 59  3 16 42 51 36 56 65 70 38 43], a_shuffle_aclus: [ 16  52  28  11  49  78  17  67  57 109  54   2  21  85   9  35  97  76 107  63 102  92  74  31  84  62  33 108  50  27  48  24   8  45  13  34  82  66  51  36  37  93  56  15  98  83   3  19  26 100  90   7  89  58  61  64  41  32  10  68  14  71  73   4  70  25  86  81   5  23  59  69  53  75  88  96  55  60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [18 54 62 32 15 12 33 72 29  8 23 11 39 67 51 34  0 50 48 65 45 25 16 66  6 17 61 44  4 55 56 41 73 35 70  1 64 77 10 68 27 30 21 75 52  3 24 49 36 22 42 63 31 58 69 13 57 37 53 19 38 20  2 71 47 26  9 46 59 76 14 28 43  7 40  5 60 74], a_shuffle_aclus: [ 25  73  84  49  21  16  50  98  41  11  32  15  56  90  69  51   2  68  66  88  62  34  23  89   9  24  83  61   7  74  75  58 100  52  96   3  86 109  14  92  36  45  28 107  70   5  33  67  53  31  59  85  48  78  93  17  76  54  71  26  55  27   4  97  64  35  13  63  81 108  19  37  60  10  57   8  82 102]\n",
      "a_shuffle_IDXs: [71 30  1 32 44 41 58 66 16 34 55 56 72 47  3 33 10 52 14 75  9 49 35 59 45 12 48 22 64 39 18 46 27  7  8 25 15 54 21 67 53 19  4  2 65 69 57 60 13 62 17  5 63 24 61 37 31  0 23 68  6 40 28 51 29 77 20 42 11 43 70 73 26 50 36 74 38 76], a_shuffle_aclus: [ 97  45   3  49  61  58  78  89  23  51  74  75  98  64   5  50  14  70  19 107  13  67  52  81  62  16  66  31  86  56  25  63  36  10  11  34  21  73  28  90  71  26   7   4  88  93  76  82  17  84  24   8  85  33  83  54  48   2  32  92   9  57  37  69  41 109  27  59  15  60  96 100  35  68  53 102  55 108]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [75  8  5 28 17 65 42 27 70 77 53 38 48 71  1 51 67 61 46 58 47 76 30 35 60 44 54 12 21 32 73 55  4 13 62 25 29 43 19 41 64 34 14 45 18 69 11  7 37 63  2  6 16 10 50 26 39 33 24 20 23  3 72 59  9 66 15  0 36 22 52 56 49 40 57 68 74 31], a_shuffle_aclus: [107  11   8  37  24  88  59  36  96 109  71  55  66  97   3  69  90  83  63  78  64 108  45  52  82  61  73  16  28  49 100  74   7  17  84  34  41  60  26  58  86  51  19  62  25  93  15  10  54  85   4   9  23  14  68  35  56  50  33  27  32   5  98  81  13  89  21   2  53  31  70  75  67  57  76  92 102  48]\n",
      "a_shuffle_IDXs: [35 55 69 54 23 64 37 49 76 77 46 39 75 66 65 16 22 57 60 27 28 10 19  5 40 21 18 30 45 11  1 13 43  4 71 51 44 56 34 38 36 32  8 73 74  0 62 41 29 42  6 70 67 15 59  2 61 33 58 72 68 31  3 20 24 17  9 14  7 12 63 50 25 53 52 47 26 48], a_shuffle_aclus: [ 52  74  93  73  32  86  54  67 108 109  63  56 107  89  88  23  31  76  82  36  37  14  26   8  57  28  25  45  62  15   3  17  60   7  97  69  61  75  51  55  53  49  11 100 102   2  84  58  41  59   9  96  90  21  81   4  83  50  78  98  92  48   5  27  33  24  13  19  10  16  85  68  34  71  70  64  35  66]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [77 68 20 10 48 27  0 56 53  8 52 31  7 40 13 70 61 25  9 14 69 15 76 19 18 37  6 47 32 72 64 26 50 33 41 54  1 59  5 58 23  4 12 73 67  2 45 71 38 75 74 66 22 43 39 16 36 17 49 51 34 46 11 42 60 55 62 35 28 29 44  3 21 57 30 63 65 24], a_shuffle_aclus: [109  92  27  14  66  36   2  75  71  11  70  48  10  57  17  96  83  34  13  19  93  21 108  26  25  54   9  64  49  98  86  35  68  50  58  73   3  81   8  78  32   7  16 100  90   4  62  97  55 107 102  89  31  60  56  23  53  24  67  69  51  63  15  59  82  74  84  52  37  41  61   5  28  76  45  85  88  33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [24 64 42 21 38 32 40 74 68 18 70 67 25  5 61  0 17 49 69  1 51 41  7 52 66 20 44  6 60 75 58 56 57 28 36 11 71  8 55 43 19 48 37 77 45 39 73 30 29 46 33 12 14 54 22 31 76  9  4 53 47 35 15 16 72 10 27  3 63  2 50 62 13 34 23 26 59 65], a_shuffle_aclus: [ 33  86  59  28  55  49  57 102  92  25  96  90  34   8  83   2  24  67  93   3  69  58  10  70  89  27  61   9  82 107  78  75  76  37  53  15  97  11  74  60  26  66  54 109  62  56 100  45  41  63  50  16  19  73  31  48 108  13   7  71  64  52  21  23  98  14  36   5  85   4  68  84  17  51  32  35  81  88]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 7 69 70  5 41 23 63 46 72  3 28 36 52 64 37 38 15  8 51 40 18  4 56 45 58 30 34 29 62  9 42 32  1 16 55 39 76 54 65 74 77 48 12 57 24 47  6 59 11 66 31 44 49  2  0 43 33 60 26 21 13 53 19 68 25 27 50 61 71 35 73 14 22 10 75 67 17 20], a_shuffle_aclus: [ 10  93  96   8  58  32  85  63  98   5  37  53  70  86  54  55  21  11  69  57  25   7  75  62  78  45  51  41  84  13  59  49   3  23  74  56 108  73  88 102 109  66  16  76  33  64   9  81  15  89  48  61  67   4   2  60  50  82  35  28  17  71  26  92  34  36  68  83  97  52 100  19  31  14 107  90  24  27]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [68  2 25 76 62  5 59 45 55 43 41 17  9 52 69 47 63 20 13 31 54 21 44 19 14 22 51 49 29 42 64 48 67 24  4  3 60 10 75 18 28  7 57 61 11 53 33 74 77 35 58 65 15 32 16  1  6 56 38 34 23 50 71 39  8 36 27 73 12 66  0 30 37 26 46 70 40 72], a_shuffle_aclus: [ 92   4  34 108  84   8  81  62  74  60  58  24  13  70  93  64  85  27  17  48  73  28  61  26  19  31  69  67  41  59  86  66  90  33   7   5  82  14 107  25  37  10  76  83  15  71  50 102 109  52  78  88  21  49  23   3   9  75  55  51  32  68  97  56  11  53  36 100  16  89   2  45  54  35  63  96  57  98]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [74 69  1  4 70 11 29 41 64 12 57 21 60  2 46 48 38 33 51 54 18 67 61 55 66  7 62  0  8 68 36 17 63 20  3 76 28 75  6 50 45 40 31 65 30 13 44 35  9 22 24 56 72 42 37 71 16 47 14 59 10 32 39 49 77 23 52 15 27 19 26 25 53  5 58 73 34 43], a_shuffle_aclus: [102  93   3   7  96  15  41  58  86  16  76  28  82   4  63  66  55  50  69  73  25  90  83  74  89  10  84   2  11  92  53  24  85  27   5 108  37 107   9  68  62  57  48  88  45  17  61  52  13  31  33  75  98  59  54  97  23  64  19  81  14  49  56  67 109  32  70  21  36  26  35  34  71   8  78 100  51  60]\n",
      "a_shuffle_IDXs: [52 11 69  9  5 22 65 56 41 34 70 75 28 23 43 19 58 13  0 44 42 30  8 51 45 10 33 54 76 25  4  1 39 21 73 57 64 31 77 15 29 12 49 16  2  6 36 72 71 18 24 38  3 62 40  7 47 46 37 74 20 53 14 27 17 59 48 67 63 32 61 26 35 66 68 50 60 55], a_shuffle_aclus: [ 70  15  93  13   8  31  88  75  58  51  96 107  37  32  60  26  78  17   2  61  59  45  11  69  62  14  50  73 108  34   7   3  56  28 100  76  86  48 109  21  41  16  67  23   4   9  53  98  97  25  33  55   5  84  57  10  64  63  54 102  27  71  19  36  24  81  66  90  85  49  83  35  52  89  92  68  82  74]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [64 29 19 60 74 65  1 17 71 43 47  3 31 15 48 11 75 23 56 69 27 62 22 14  2 45 59 68 38 35 57 50 52 42 34  5  8 55 70 54 20 28 26 12 49 18 58 33 24 40 77 30 10 39 37  7 67  6 66 41 21 53 25 61  9 63 76 36 51 73 13 44 72 32  0 46 16  4], a_shuffle_aclus: [ 86  41  26  82 102  88   3  24  97  60  64   5  48  21  66  15 107  32  75  93  36  84  31  19   4  62  81  92  55  52  76  68  70  59  51   8  11  74  96  73  27  37  35  16  67  25  78  50  33  57 109  45  14  56  54  10  90   9  89  58  28  71  34  83  13  85 108  53  69 100  17  61  98  49   2  63  23   7]\n",
      "a_shuffle_IDXs: [14 25 51 18 53 35 42 60  1 16 61 11 64 77 22 66 29 65 41 13 76 59 32 50 54 74 40 70 48 49 24 46 21 37 27 75 52 31 10  3 23  0 72  6  4 28  2 57  9 33 71 19 62 45 12 55 36 67 43  8 47 69  5 30 34 20 38 63 39 15 68 56  7 73 26 17 44 58], a_shuffle_aclus: [ 19  34  69  25  71  52  59  82   3  23  83  15  86 109  31  89  41  88  58  17 108  81  49  68  73 102  57  96  66  67  33  63  28  54  36 107  70  48  14   5  32   2  98   9   7  37   4  76  13  50  97  26  84  62  16  74  53  90  60  11  64  93   8  45  51  27  55  85  56  21  92  75  10 100  35  24  61  78]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [75  8 20 58 22 50 68  0 11 39 47 61 15 44 72 16  9 17 53 24 23 28 45 73 10 52 14 66 69 37 29 35 19 26 33 27 71 55 76 31 36 46 30  4 18 77  6 57 34 63 67 51 43 64 59  5 25  1 48 54  2 21 74 42 38 70 62 41  3 13 40 12 32 49 60 65 56  7], a_shuffle_aclus: [107  11  27  78  31  68  92   2  15  56  64  83  21  61  98  23  13  24  71  33  32  37  62 100  14  70  19  89  93  54  41  52  26  35  50  36  97  74 108  48  53  63  45   7  25 109   9  76  51  85  90  69  60  86  81   8  34   3  66  73   4  28 102  59  55  96  84  58   5  17  57  16  49  67  82  88  75  10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [30 43 74 69 36 33 67 29 49  2  0 44 39 12 55 31  1 13 18 28 23  4 20 57 38 45  6 25 35  3 46 63 40 61  7 17 76 11 32 26 47 34 19 16 27 52 77 21 68 50 66 65 41 15 10 48 70  8 42 37  5 73 60 71 62 75 22 58 14 72  9 53 56 54 59 24 64 51], a_shuffle_aclus: [ 45  60 102  93  53  50  90  41  67   4   2  61  56  16  74  48   3  17  25  37  32   7  27  76  55  62   9  34  52   5  63  85  57  83  10  24 108  15  49  35  64  51  26  23  36  70 109  28  92  68  89  88  58  21  14  66  96  11  59  54   8 100  82  97  84 107  31  78  19  98  13  71  75  73  81  33  86  69]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [65 52 53 28 31 46 18 32  8 69 11  0  7 64 38 68 66 21 34 22 35 14 36  5 67 49 13 16 77  4 12 62 25 40 59 74 33 15 23 29  1 60 75 24 50 70 42 48 20 10 47 37  3 56 61 30 58 27 44 54 73 76 63  6 19 57 43 26 51 45 72 41 71 17 39 55  9  2], a_shuffle_aclus: [ 88  70  71  37  48  63  25  49  11  93  15   2  10  86  55  92  89  28  51  31  52  19  53   8  90  67  17  23 109   7  16  84  34  57  81 102  50  21  32  41   3  82 107  33  68  96  59  66  27  14  64  54   5  75  83  45  78  36  61  73 100 108  85   9  26  76  60  35  69  62  98  58  97  24  56  74  13   4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [23 34 66 60 29 72 12 73 53 31 15 39 59 55 16 20 50  9 71 19 37 47 75 68 67 52 45 30 11 41 33 57 44 61 22 10  3 69  7 40  6 18  0 65 42 51  4 35 28 25 21 74 58 46 13 70 14 56  8 26 32  2  5 43 48 77 62 54 63 76 36 38 17 27 64 49 24  1], a_shuffle_aclus: [ 32  51  89  82  41  98  16 100  71  48  21  56  81  74  23  27  68  13  97  26  54  64 107  92  90  70  62  45  15  58  50  76  61  83  31  14   5  93  10  57   9  25   2  88  59  69   7  52  37  34  28 102  78  63  17  96  19  75  11  35  49   4   8  60  66 109  84  73  85 108  53  55  24  36  86  67  33   3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [47  9  0 38 21 43 60 10 56 77 17 28 68 44 57 70 74 52 40 46 16 14 25 12 35 72 53 65  2 50 66 29  7 31 59  8  4 22 73 36 75 39 33 51 26 18 41 71 34 61 30 45 11  3 32 13 20 23 37 67  1 49 69  6 64 24 15 48 19 58 63 76 27 62 54 55  5 42], a_shuffle_aclus: [ 64  13   2  55  28  60  82  14  75 109  24  37  92  61  76  96 102  70  57  63  23  19  34  16  52  98  71  88   4  68  89  41  10  48  81  11   7  31 100  53 107  56  50  69  35  25  58  97  51  83  45  62  15   5  49  17  27  32  54  90   3  67  93   9  86  33  21  66  26  78  85 108  36  84  73  74   8  59]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [68 71 66 20  4 55  3 29 35  0 67 12  1  5 59 32 42  8 13 52 63 34 31 36 73 64 11 47 44 70 65 37 26  9 14 46 27 22 18 76 60 62 61  2 15 54 19 39 56 75 77 40  7 28 24 38 48 10 51  6 50 25 23 30 49 45 16 17 57 33 69 58 43 41 21 74 72 53], a_shuffle_aclus: [ 92  97  89  27   7  74   5  41  52   2  90  16   3   8  81  49  59  11  17  70  85  51  48  53 100  86  15  64  61  96  88  54  35  13  19  63  36  31  25 108  82  84  83   4  21  73  26  56  75 107 109  57  10  37  33  55  66  14  69   9  68  34  32  45  67  62  23  24  76  50  93  78  60  58  28 102  98  71]\n",
      "a_shuffle_IDXs: [21  5 28 29 38  3 73 69 62 32 53 12 67 49 13 33 61 27 18 14 54 70 57 66 24 17 50 75 60 43  7 39 63 64 45 16 76  6 58 47 41 10 25 52 77  8 59 56 26 37 51 36 74 22 34  4 65 48 44 55 35 19 68 31 40 23 72 30 11  0 46 71 42 20  2  1  9 15], a_shuffle_aclus: [ 28   8  37  41  55   5 100  93  84  49  71  16  90  67  17  50  83  36  25  19  73  96  76  89  33  24  68 107  82  60  10  56  85  86  62  23 108   9  78  64  58  14  34  70 109  11  81  75  35  54  69  53 102  31  51   7  88  66  61  74  52  26  92  48  57  32  98  45  15   2  63  97  59  27   4   3  13  21]\n",
      "a_shuffle_IDXs: [48 28  4 24 16 15 35 73 45 40 47 76 65 41 13 10 55 14 27 62 71 56 18 31 50 66  8 63 46 22 75  5 29 67 72  0 60  9 11 74 21 51 33 26 52 17 54 36 57 32 39  1 69 25 42 23 34 19 64 20  2 43 44 77 12 38  7 70 59 61 58  6 30  3 53 68 49 37], a_shuffle_aclus: [ 66  37   7  33  23  21  52 100  62  57  64 108  88  58  17  14  74  19  36  84  97  75  25  48  68  89  11  85  63  31 107   8  41  90  98   2  82  13  15 102  28  69  50  35  70  24  73  53  76  49  56   3  93  34  59  32  51  26  86  27   4  60  61 109  16  55  10  96  81  83  78   9  45   5  71  92  67  54]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [54 12 57 77  1 40  5 70 21 17 32 41 11 74 60 49 50 30 51 71 16 29 25  9 10 45 43 36 56  8 34 68 28 73  7 61 27 58 37 33 46 39 62  4 42 26 75 67  2 66 19 35 22 47 13 24 59 52 55 20 63 65 48 23 53 64 69  6 44  0  3 72 15 38 18 31 76 14], a_shuffle_aclus: [ 73  16  76 109   3  57   8  96  28  24  49  58  15 102  82  67  68  45  69  97  23  41  34  13  14  62  60  53  75  11  51  92  37 100  10  83  36  78  54  50  63  56  84   7  59  35 107  90   4  89  26  52  31  64  17  33  81  70  74  27  85  88  66  32  71  86  93   9  61   2   5  98  21  55  25  48 108  19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [34 53  8 27 36 47 51  7 46 64 58 65 49 43 42 70 57  2 62 74 52 33 23 66 30 37 41 72 31  0 54 60 32 26 25 28 73 50 76 38 67 21 55  1 10 59 29  4 35  9 39  5 68 11 69 63 44 22  6 12 45 14 61 75 17 71 16  3 13 19 20 48 15 18 40 56 77 24], a_shuffle_aclus: [ 51  71  11  36  53  64  69  10  63  86  78  88  67  60  59  96  76   4  84 102  70  50  32  89  45  54  58  98  48   2  73  82  49  35  34  37 100  68 108  55  90  28  74   3  14  81  41   7  52  13  56   8  92  15  93  85  61  31   9  16  62  19  83 107  24  97  23   5  17  26  27  66  21  25  57  75 109  33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [23 61 44 30 65 70 42 69 15 37 68 64 16 28 76  6 72 36 62 32 29 24 17  3 75 47 67 50 60 73 13 41 59 39 66 25  5 55 40 34 63 20 31  1 74  7 14 12 52 49 57 11 77 43 18  2 26  9 27 53  8 46 19 56 21 22 71 38 35 58  0 33  4 10 45 51 48 54], a_shuffle_aclus: [ 32  83  61  45  88  96  59  93  21  54  92  86  23  37 108   9  98  53  84  49  41  33  24   5 107  64  90  68  82 100  17  58  81  56  89  34   8  74  57  51  85  27  48   3 102  10  19  16  70  67  76  15 109  60  25   4  35  13  36  71  11  63  26  75  28  31  97  55  52  78   2  50   7  14  62  69  66  73]\n",
      "a_shuffle_IDXs: [74 10 37  6 46  7  9 11 35 58 29  0 18 13 55 28 68 41  4 60 34 30 72 50 43 42 49 38 32 31 33 71 48  2 75 69 39 40 66 56  3 21 53 67 25 65 73  8 14 45 27 23 17 62 36 70 61 76 12 44  1 15 51  5 22 19 26 16 54 57 77 52 20 63 64 47 59 24], a_shuffle_aclus: [102  14  54   9  63  10  13  15  52  78  41   2  25  17  74  37  92  58   7  82  51  45  98  68  60  59  67  55  49  48  50  97  66   4 107  93  56  57  89  75   5  28  71  90  34  88 100  11  19  62  36  32  24  84  53  96  83 108  16  61   3  21  69   8  31  26  35  23  73  76 109  70  27  85  86  64  81  33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [30 17 47 12 44 28 54 24 69 50 51 74 38 72 73 68 40 55 32 62 58  5 67 37 52 43 21 15  4 29 76 75  6  1 20 71 10  7 45 48 66 63 16  0 18 36 22 25 23  2 60 39  8 42 65 70 41  3 56 77 33  9 35 13 27 57 19 59 31 14 34 46 49 64 26 11 61 53], a_shuffle_aclus: [ 45  24  64  16  61  37  73  33  93  68  69 102  55  98 100  92  57  74  49  84  78   8  90  54  70  60  28  21   7  41 108 107   9   3  27  97  14  10  62  66  89  85  23   2  25  53  31  34  32   4  82  56  11  59  88  96  58   5  75 109  50  13  52  17  36  76  26  81  48  19  51  63  67  86  35  15  83  71]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 6 62 72  1 37 36 51 58 69 27 75 66 71 73 50 67 70 18  3 65 21 54 52 63 35  2 59 76 56 23 20 31 38 24  7 34 41 60  4 13 43 28 47 44 55 45 77  8 46 15 74 64 48 11 30 61 26 22 42 39  9 16 17 68 10 33 14 32 29 25 57  5 12 49 40 19 53  0], a_shuffle_aclus: [  9  84  98   3  54  53  69  78  93  36 107  89  97 100  68  90  96  25   5  88  28  73  70  85  52   4  81 108  75  32  27  48  55  33  10  51  58  82   7  17  60  37  64  61  74  62 109  11  63  21 102  86  66  15  45  83  35  31  59  56  13  23  24  92  14  50  19  49  41  34  76   8  16  67  57  26  71   2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [77 71 33 18 61 66 28 17 74 22 27 49 72  4 29  7 16 67  9 41 73 23 48 37 38 47 10  8 31 39  0 32  6 11 62 45 30 60 69  3  1 50  2 68 44 12 46 53 35 15 43 21 58 76 59 57 26 51 25 64  5 55 34 19 63 42 65 75 13 56 54 70 40 36 24 14 20 52], a_shuffle_aclus: [109  97  50  25  83  89  37  24 102  31  36  67  98   7  41  10  23  90  13  58 100  32  66  54  55  64  14  11  48  56   2  49   9  15  84  62  45  82  93   5   3  68   4  92  61  16  63  71  52  21  60  28  78 108  81  76  35  69  34  86   8  74  51  26  85  59  88 107  17  75  73  96  57  53  33  19  27  70]\n",
      "a_shuffle_IDXs: [32 76 58 69 48 17 62 13 49  4 19 28  1 26 77 53 39 41 43 21  7 22 29 42 70 67 33 61 10 59 50 74 47 54 71 23 37 24 11  8 35 68 27 20 40 12 44  9 25 73 64  2 30 36 57  3 63 38 51 34 18 46 72 16 66 45 52  0 75 15 31 65 14  6  5 55 56 60], a_shuffle_aclus: [ 49 108  78  93  66  24  84  17  67   7  26  37   3  35 109  71  56  58  60  28  10  31  41  59  96  90  50  83  14  81  68 102  64  73  97  32  54  33  15  11  52  92  36  27  57  16  61  13  34 100  86   4  45  53  76   5  85  55  69  51  25  63  98  23  89  62  70   2 107  21  48  88  19   9   8  74  75  82]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [21 35 64 22 71  0 63 77 46 31 56 40 76  3 54 67 36 32  4  6 12 68  9 10 18 73 45 47 38  1 23 66 50 30 15 62 55 14 42 25 13 61 39 37 72 48 29 74 11 65 27 24 16 57 41 52 33  8 19 26 28 59 69 20 43  2 75 60 58 17 51  7 49  5 44 53 34 70], a_shuffle_aclus: [ 28  52  86  31  97   2  85 109  63  48  75  57 108   5  73  90  53  49   7   9  16  92  13  14  25 100  62  64  55   3  32  89  68  45  21  84  74  19  59  34  17  83  56  54  98  66  41 102  15  88  36  33  23  76  58  70  50  11  26  35  37  81  93  27  60   4 107  82  78  24  69  10  67   8  61  71  51  96]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [63 65 28 76 27 22 43 60  9 41 34 25 75 33 44 38 53 73 40 50 39 52 66  8 64 58 47 16 59 10 24 30 15 48 19 20 56 17 55 54 68 42 51 77 62 21 26 12 35 71 70 37 69 11 74 45 14 13 67 29 23 72 46 32 18 36  3  6 49  5  0  7  2 57 61 31  1  4], a_shuffle_aclus: [ 85  88  37 108  36  31  60  82  13  58  51  34 107  50  61  55  71 100  57  68  56  70  89  11  86  78  64  23  81  14  33  45  21  66  26  27  75  24  74  73  92  59  69 109  84  28  35  16  52  97  96  54  93  15 102  62  19  17  90  41  32  98  63  49  25  53   5   9  67   8   2  10   4  76  83  48   3   7]\n",
      "a_shuffle_IDXs: [24 49 62 32 26 58 53 39 76 65 46 35 13 11  3 69 70  9 68 77  6 27 43  4 74 15 52 25 55 41 18 59  5 16 34 60  8 10 48  0 36 14 19 73 51 47 72 57  1 38 40 17 29 37 42 54 61 30 23 75 20 64  7 28 44 66 12 31 67 50 56 71 63 45 22 21 33  2], a_shuffle_aclus: [ 33  67  84  49  35  78  71  56 108  88  63  52  17  15   5  93  96  13  92 109   9  36  60   7 102  21  70  34  74  58  25  81   8  23  51  82  11  14  66   2  53  19  26 100  69  64  98  76   3  55  57  24  41  54  59  73  83  45  32 107  27  86  10  37  61  89  16  48  90  68  75  97  85  62  31  28  50   4]\n",
      "a_shuffle_IDXs: [74 42 37 45 31 77  1 61 34 35 27 66 59 75 33 46 69 76 47  7 10 49 25 38 50  0 63 70 71  6 64 57 24  8 40 26 12 68  5 51 16 15 39 48 21 67 65 20 19 58 56 23 11 32 22 18 14 41 60 73 55  9 17 30 36 53 52 44 72 13 29  2  3 54 28  4 62 43], a_shuffle_aclus: [102  59  54  62  48 109   3  83  51  52  36  89  81 107  50  63  93 108  64  10  14  67  34  55  68   2  85  96  97   9  86  76  33  11  57  35  16  92   8  69  23  21  56  66  28  90  88  27  26  78  75  32  15  49  31  25  19  58  82 100  74  13  24  45  53  71  70  61  98  17  41   4   5  73  37   7  84  60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [37 44 47 77  1 45 46 14 53  9 34 60  4 24  8 35  5 62 70 55 74 67 21 58 48 42 68 65 49 76 31 66 27 51 38  6 72 40 71 19 52 33 39 15 28 30 54 12 29 41 50 61 69 43 17 57  0 26 75 18 56 59 22 32 63 20 11  7  3 73 25  2 16 64 10 13 36 23], a_shuffle_aclus: [ 54  61  64 109   3  62  63  19  71  13  51  82   7  33  11  52   8  84  96  74 102  90  28  78  66  59  92  88  67 108  48  89  36  69  55   9  98  57  97  26  70  50  56  21  37  45  73  16  41  58  68  83  93  60  24  76   2  35 107  25  75  81  31  49  85  27  15  10   5 100  34   4  23  86  14  17  53  32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [11 64 17 55 30 46  4 27  7 51 40 73  8 68 54 47 13 59 49 12  2 37 72 16 34 58 62 39 20 50 25 21 63 44 45 18 75 26 31 36 57 60 74 41 66 71 23  0 52 15  6 70  9 48 76 32 43 61 65  5 42  3 24 28 53 22 67  1 38 35 10 33 56 69 77 14 19 29], a_shuffle_aclus: [ 15  86  24  74  45  63   7  36  10  69  57 100  11  92  73  64  17  81  67  16   4  54  98  23  51  78  84  56  27  68  34  28  85  61  62  25 107  35  48  53  76  82 102  58  89  97  32   2  70  21   9  96  13  66 108  49  60  83  88   8  59   5  33  37  71  31  90   3  55  52  14  50  75  93 109  19  26  41]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [56 32 12 33  9 70 48 24 76 13 52  1 61 14 72 28 69 53 65 44 29 77  4 41 66 58 47 68 34 18 42  2 73 35 21 59 37 25  0 39 19 38  8 51 64  7 50 57 23 20 43  5 63 26 10 46 67 16 74 75 54  3 49 11 31 71 62 55 60 17 15 45 36  6 30 22 27 40], a_shuffle_aclus: [ 75  49  16  50  13  96  66  33 108  17  70   3  83  19  98  37  93  71  88  61  41 109   7  58  89  78  64  92  51  25  59   4 100  52  28  81  54  34   2  56  26  55  11  69  86  10  68  76  32  27  60   8  85  35  14  63  90  23 102 107  73   5  67  15  48  97  84  74  82  24  21  62  53   9  45  31  36  57]\n",
      "a_shuffle_IDXs: [26 68 19 37 29  2 11 38 35 77 49 43  5 41 48 15 39 73 69 74 40 42 58 50 67  7 70  1 46 47 14 54 61 30 75 28 34  4 64 17 24 36 25 62 10 31 52 20 16 21  0 33 66 18 57 63 53 60 22 56  3 71 45 44  6 32 27 51  8 23  9 55 13 72 59 76 65 12], a_shuffle_aclus: [ 35  92  26  54  41   4  15  55  52 109  67  60   8  58  66  21  56 100  93 102  57  59  78  68  90  10  96   3  63  64  19  73  83  45 107  37  51   7  86  24  33  53  34  84  14  48  70  27  23  28   2  50  89  25  76  85  71  82  31  75   5  97  62  61   9  49  36  69  11  32  13  74  17  98  81 108  88  16]\n",
      "a_shuffle_IDXs: [57 17 73 20 64 60  7 45 53 38 51 42 77 52  1 29 19 75 12 30 23 43 59 21 56 54 33 46  6 39 47  2 35 70 67 26 34 15 28 55 18 63 62 71 48 24 65 10 14 44 69 66 49 58  8 36 61 31 22  9  3 32 41 76 11 27 68 37 25  0 50 74  4 13 16 40  5 72], a_shuffle_aclus: [ 76  24 100  27  86  82  10  62  71  55  69  59 109  70   3  41  26 107  16  45  32  60  81  28  75  73  50  63   9  56  64   4  52  96  90  35  51  21  37  74  25  85  84  97  66  33  88  14  19  61  93  89  67  78  11  53  83  48  31  13   5  49  58 108  15  36  92  54  34   2  68 102   7  17  23  57   8  98]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [65 66 60 59 38 53 11 46 72 33 76 51 37 34  4 12 67  9 75 35 10 20 47 56 44 62 58 68 49 25 41 45 15 16 22 29 13 14 54 70 24 31 28  7  6 52 19 48 64 26 23 30 50  5  1 43 39 57  0 17 61 55 18  8 40 77 21 63 36 32 69 27  2  3 73 74 42 71], a_shuffle_aclus: [ 88  89  82  81  55  71  15  63  98  50 108  69  54  51   7  16  90  13 107  52  14  27  64  75  61  84  78  92  67  34  58  62  21  23  31  41  17  19  73  96  33  48  37  10   9  70  26  66  86  35  32  45  68   8   3  60  56  76   2  24  83  74  25  11  57 109  28  85  53  49  93  36   4   5 100 102  59  97]\n",
      "a_shuffle_IDXs: [54 30 58 64 12 68  1 52  7 55 44 24 37 35 20 18 74 41 19 16 23 43 75 77  9 70 57 34 63 11  0 47 17 31 29 32 66 72 53 40 50  4 45  3 28 13 22 73 56 61 42 48 15 14 33 65  6  5 59 51 71 10 21  2 36 60 69 25 67 26 49 62 27  8 76 39 38 46], a_shuffle_aclus: [ 73  45  78  86  16  92   3  70  10  74  61  33  54  52  27  25 102  58  26  23  32  60 107 109  13  96  76  51  85  15   2  64  24  48  41  49  89  98  71  57  68   7  62   5  37  17  31 100  75  83  59  66  21  19  50  88   9   8  81  69  97  14  28   4  53  82  93  34  90  35  67  84  36  11 108  56  55  63]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [52  8 62 77 41 20 39 11  3 70 27 23 69 60 66 74 67  4 57 50 44 34 10 45 13 68  2 71 29  0 35 54 38 65 16 40 53 75 25 30 36 47 48 37  9 46 42 58 63 59 31 55  7 43 76 61 15 21 49 51 32 73 72 64 17 56  5 28 26 19 33 12 18  6 14  1 24 22], a_shuffle_aclus: [ 70  11  84 109  58  27  56  15   5  96  36  32  93  82  89 102  90   7  76  68  61  51  14  62  17  92   4  97  41   2  52  73  55  88  23  57  71 107  34  45  53  64  66  54  13  63  59  78  85  81  48  74  10  60 108  83  21  28  67  69  49 100  98  86  24  75   8  37  35  26  50  16  25   9  19   3  33  31]\n",
      "a_shuffle_IDXs: [12 14  4  8 46 15 17 29 60 32 23 77 64  6 47 45 24 48 74 34 52 38 75 49 20 16 10 27 39 71 36 59 68 43 53 58 42 40 28 19 57 37 30 69 50 18 21 26 56 70 76 35  5 54 25 41 11 67  1 31 61 66 51 65  2 33 55  9 63 44  0  7 62 73 22  3 72 13], a_shuffle_aclus: [ 16  19   7  11  63  21  24  41  82  49  32 109  86   9  64  62  33  66 102  51  70  55 107  67  27  23  14  36  56  97  53  81  92  60  71  78  59  57  37  26  76  54  45  93  68  25  28  35  75  96 108  52   8  73  34  58  15  90   3  48  83  89  69  88   4  50  74  13  85  61   2  10  84 100  31   5  98  17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 9 10 28 19 18 61 38 25 17 41 26 36  4 39 20  3 14 42 30 46 22 57 56 62 66  7 58 29 12 13 60 34 64  1 48  0 45 55 71 37 74 16 77 73 21  6 65 44 67 31 40 24 72 51 68 76 70  5 15  2 59 43 11 32 27 54 33 52 63 75 35 50 47 49 23 53 69  8], a_shuffle_aclus: [ 13  14  37  26  25  83  55  34  24  58  35  53   7  56  27   5  19  59  45  63  31  76  75  84  89  10  78  41  16  17  82  51  86   3  66   2  62  74  97  54 102  23 109 100  28   9  88  61  90  48  57  33  98  69  92 108  96   8  21   4  81  60  15  49  36  73  50  70  85 107  52  68  64  67  32  71  93  11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [65  8 44 53 43 14 54  7 29 20 42 22 45 76 70 26 39  5 40 56 34 27 38 16 46 35 48 69  1 13 15 30 49 64  0 67 31 11 51 61 55 57 18 32 36 41 23  9 28  4 74 12  2 62 25 66 71 75 77 47 10 33 58 50  6  3 72 63 17 60 37 73 21 59 19 24 68 52], a_shuffle_aclus: [ 88  11  61  71  60  19  73  10  41  27  59  31  62 108  96  35  56   8  57  75  51  36  55  23  63  52  66  93   3  17  21  45  67  86   2  90  48  15  69  83  74  76  25  49  53  58  32  13  37   7 102  16   4  84  34  89  97 107 109  64  14  50  78  68   9   5  98  85  24  82  54 100  28  81  26  33  92  70]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [27 51 47 32 46 11 14 29 73 40 69 15 71  4 22  1 65  6 34 76 41 38 33 54 28 25 57  7 12 18  9 60 35 48 61 19 68  8 43  2 74 30 20 17 67 55 49 59 72 77 62  3 63 36 70 24 42  5 21 44 10 39 13 75  0 52 16 50 64 23 31 37 66 58 45 53 26 56], a_shuffle_aclus: [ 36  69  64  49  63  15  19  41 100  57  93  21  97   7  31   3  88   9  51 108  58  55  50  73  37  34  76  10  16  25  13  82  52  66  83  26  92  11  60   4 102  45  27  24  90  74  67  81  98 109  84   5  85  53  96  33  59   8  28  61  14  56  17 107   2  70  23  68  86  32  48  54  89  78  62  71  35  75]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [20 67 12 49 32  2 24 61 60 63 68  6 66 16 62 29 47 21 57 42 34  3 54 11 45 50 22 13 38 40 48 52 77 70 43 71 72  5 39  9 44 15 23 19 31 36 10 18 51 74 58 65 75 76 55 37 30 69 46  8 27  7 25 64 33  0 26 59 53 28 35 17 56 73  4 41 14  1], a_shuffle_aclus: [ 27  90  16  67  49   4  33  83  82  85  92   9  89  23  84  41  64  28  76  59  51   5  73  15  62  68  31  17  55  57  66  70 109  96  60  97  98   8  56  13  61  21  32  26  48  53  14  25  69 102  78  88 107 108  74  54  45  93  63  11  36  10  34  86  50   2  35  81  71  37  52  24  75 100   7  58  19   3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [41 35 15 50 34 27 13 67  9 71 44 42 54  1 32 56 40  5 36 26 11 31 65 69 74 70 58 29  8 62  7 38  2 47 75 53 24 21 19 49 25  4  0 17 16 73 60 14 68 37 77 51 64 23 33 30 48 57 20 10 63 61 12 46 76 39 72 43 52 45 28 59 66 55 22 18  6  3], a_shuffle_aclus: [ 58  52  21  68  51  36  17  90  13  97  61  59  73   3  49  75  57   8  53  35  15  48  88  93 102  96  78  41  11  84  10  55   4  64 107  71  33  28  26  67  34   7   2  24  23 100  82  19  92  54 109  69  86  32  50  45  66  76  27  14  85  83  16  63 108  56  98  60  70  62  37  81  89  74  31  25   9   5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [51 24 14 30 50  2 40  6 59 41 66  1 76 55 21 62  7 56 35 26 31 39 52  4 23 29 47 36 73 61 64 67 70 71  9 63 19 17 57 32 33 72 13 10  0 28  8 75  5 18 11 49  3 37 38 27 68 34 60 42 20 22 77 48 45 58 12 44 74 46 54 65 43 16 69 53 25 15], a_shuffle_aclus: [ 69  33  19  45  68   4  57   9  81  58  89   3 108  74  28  84  10  75  52  35  48  56  70   7  32  41  64  53 100  83  86  90  96  97  13  85  26  24  76  49  50  98  17  14   2  37  11 107   8  25  15  67   5  54  55  36  92  51  82  59  27  31 109  66  62  78  16  61 102  63  73  88  60  23  93  71  34  21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [65 32 77 64 62 42 58 31 47 16 41 18 22 49  1 19 66 24 15  3 40 39 71 35  5 70 53 28 44 50 43 72 75 48 51 36 67 63 56 29 13  6 59 11 38 27 25 10 69 52 21 14 61 55 73  7 37 26 34 23  2 46 33 45 54  9 17  4 68 74 60  0  8 30 20 76 57 12], a_shuffle_aclus: [ 88  49 109  86  84  59  78  48  64  23  58  25  31  67   3  26  89  33  21   5  57  56  97  52   8  96  71  37  61  68  60  98 107  66  69  53  90  85  75  41  17   9  81  15  55  36  34  14  93  70  28  19  83  74 100  10  54  35  51  32   4  63  50  62  73  13  24   7  92 102  82   2  11  45  27 108  76  16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [13 74 60 18 34 43  8 72 33 51 23 68  9 37 65 21 48 11 16 38 58 45 67 41 20 77 10 35  1 63 30 26 75 31 19 28 69 61 27 55 29 71 52  5 49 44 24  4 57 70 12 54  7 47 64  3 17 14 39 46 40 59 76 32 50 15 62 53 25 42  6 36  2 56 66 22  0 73], a_shuffle_aclus: [ 17 102  82  25  51  60  11  98  50  69  32  92  13  54  88  28  66  15  23  55  78  62  90  58  27 109  14  52   3  85  45  35 107  48  26  37  93  83  36  74  41  97  70   8  67  61  33   7  76  96  16  73  10  64  86   5  24  19  56  63  57  81 108  49  68  21  84  71  34  59   9  53   4  75  89  31   2 100]\n",
      "a_shuffle_IDXs: [ 9 33  5 37 68 43 21 75 34 29 77 40 11 27 53 22 51 23  0 12 49 62 15 52 38  6 26 39 18 46 57 24 55 44 69 41 20 35  8  7 30 72 56 74 61 47 50 66  2  1 19 54 70  3 63 28 42 64 65 60 13 73 48 10 14  4 76 45 16 32 71 31 25 58 67 36 17 59], a_shuffle_aclus: [ 13  50   8  54  92  60  28 107  51  41 109  57  15  36  71  31  69  32   2  16  67  84  21  70  55   9  35  56  25  63  76  33  74  61  93  58  27  52  11  10  45  98  75 102  83  64  68  89   4   3  26  73  96   5  85  37  59  86  88  82  17 100  66  14  19   7 108  62  23  49  97  48  34  78  90  53  24  81]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [69 24 32 59 62 49 36 55 33 35 31 30 29 34 50 20 28 14  7 19 61 56 54 51 66 75  6 74 60  1 10 17 58 57 43 18  0 41 13 45 63 21 39 42 11 38 16 72 67 77 12 70 68 26 25 73 15 46 47 44 71 52  3 37  4 23 22 76 27 65 48  2 64  5 40  9 53  8], a_shuffle_aclus: [ 93  33  49  81  84  67  53  74  50  52  48  45  41  51  68  27  37  19  10  26  83  75  73  69  89 107   9 102  82   3  14  24  78  76  60  25   2  58  17  62  85  28  56  59  15  55  23  98  90 109  16  96  92  35  34 100  21  63  64  61  97  70   5  54   7  32  31 108  36  88  66   4  86   8  57  13  71  11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [51 58 10 64  5  7 37  6 60 11 17 63 16 46 72  8  2 24 61  9 44 77 69 13 41 54 31 29 39 45 49 62  3 36 22 38 75 52 18 14 65 43 19 56 35 74 50 66 27 55 15 76 34 59  1  0  4 40 21 33 47 42 26 57 25 23 71 20 67 48 68 70 30 73 32 12 28 53], a_shuffle_aclus: [ 69  78  14  86   8  10  54   9  82  15  24  85  23  63  98  11   4  33  83  13  61 109  93  17  58  73  48  41  56  62  67  84   5  53  31  55 107  70  25  19  88  60  26  75  52 102  68  89  36  74  21 108  51  81   3   2   7  57  28  50  64  59  35  76  34  32  97  27  90  66  92  96  45 100  49  16  37  71]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 1 74 15 60 66 77 40  3 21 27 58 76 62  5 12 50 64 65 71 47 19 39 51 67 31 34  4 72 55 73 38 52 70 35 37 29 41  6 24 53 10 28  0 36 56 59 61  7 18 48 49 20  9 23  2 13 54 14 68 43 42 25 75 17 16 63 57 69 11 45 33 22 32 44 30  8 46 26], a_shuffle_aclus: [  3 102  21  82  89 109  57   5  28  36  78 108  84   8  16  68  86  88  97  64  26  56  69  90  48  51   7  98  74 100  55  70  96  52  54  41  58   9  33  71  14  37   2  53  75  81  83  10  25  66  67  27  13  32   4  17  73  19  92  60  59  34 107  24  23  85  76  93  15  62  50  31  49  61  45  11  63  35]\n",
      "a_shuffle_IDXs: [47 59 39 54 52  5 15  0 43 76  8 31 33 41 62 48 26 57 77 56 36  9  7 40 35 53 65 23  4 17 50 11 67 46 66  3 20 55 63 24 73 72 61 64 51 16 10 13 27 70 28 58 49 60 38 25 19 14 32 29 42  2 30 37 12 69 74  1 18  6 44 71 45 34 68 21 75 22], a_shuffle_aclus: [ 64  81  56  73  70   8  21   2  60 108  11  48  50  58  84  66  35  76 109  75  53  13  10  57  52  71  88  32   7  24  68  15  90  63  89   5  27  74  85  33 100  98  83  86  69  23  14  17  36  96  37  78  67  82  55  34  26  19  49  41  59   4  45  54  16  93 102   3  25   9  61  97  62  51  92  28 107  31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [25 51 24 76  3 32 20 71 64 60 18 19 59 30 44 67  1 40 47  7 68 65 22 54  4 52 43 66 58  5 31 13 28 45 36 63 46 77 37 10 57  8 75 41 42 61 14 27 21 56 15 70 16 69  0 12 62 55 74 48 17 73 11  9 26 35 72  6  2 33 34 53 50 39 23 49 29 38], a_shuffle_aclus: [ 34  69  33 108   5  49  27  97  86  82  25  26  81  45  61  90   3  57  64  10  92  88  31  73   7  70  60  89  78   8  48  17  37  62  53  85  63 109  54  14  76  11 107  58  59  83  19  36  28  75  21  96  23  93   2  16  84  74 102  66  24 100  15  13  35  52  98   9   4  50  51  71  68  56  32  67  41  55]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [35 31 30 16 32 68 70 39 27 29 65 44 49 46  5  4 47  8 61 36 69 25 62 57  0 12 54 71 33 21 45 20 66 18 13 74 40 63 26 15 22 19  2 67 73  6 23 34  1 56 28 53 77 51 42 17 55 64 14 75 59  9 37 43 58 76 50 38 41 10 72 48  3 11 60 24 52  7], a_shuffle_aclus: [ 52  48  45  23  49  92  96  56  36  41  88  61  67  63   8   7  64  11  83  53  93  34  84  76   2  16  73  97  50  28  62  27  89  25  17 102  57  85  35  21  31  26   4  90 100   9  32  51   3  75  37  71 109  69  59  24  74  86  19 107  81  13  54  60  78 108  68  55  58  14  98  66   5  15  82  33  70  10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [20 49  0 73 54 74 29  1 19 16 39 68 36 48 56 11  3 65  6 61 18  8  2 35 67 22 43 10 64 51 31 34 52 15 60 53 40 17 27 14 62 76 63 23 21 45  9 44 70 26 38 47  7 66 59 25 46 50 41 69 55 75 32  5 71 72  4 12 57 30 77 42 28 58 13 37 33 24], a_shuffle_aclus: [ 27  67   2 100  73 102  41   3  26  23  56  92  53  66  75  15   5  88   9  83  25  11   4  52  90  31  60  14  86  69  48  51  70  21  82  71  57  24  36  19  84 108  85  32  28  62  13  61  96  35  55  64  10  89  81  34  63  68  58  93  74 107  49   8  97  98   7  16  76  45 109  59  37  78  17  54  50  33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [32 44 62 24 26 50 55 21 37 75 10  9  1 17 40 64  0 65 25 68  7 57 53 45 39  2 41 66 31 11  8 28 14 15 59 77 43 38 33  5 46 76 67 20 42 27 72 60 49 61 73 63 70  6 69  4  3 23 47 51 34 12 71 54 58 16 22 19 48 52 18 56 35 30 13 36 29 74], a_shuffle_aclus: [ 49  61  84  33  35  68  74  28  54 107  14  13   3  24  57  86   2  88  34  92  10  76  71  62  56   4  58  89  48  15  11  37  19  21  81 109  60  55  50   8  63 108  90  27  59  36  98  82  67  83 100  85  96   9  93   7   5  32  64  69  51  16  97  73  78  23  31  26  66  70  25  75  52  45  17  53  41 102]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 9 39 22 15 25 43 31 63 73 34 14 68 71 30 37 55 77 76  3 35  1 57  0 13 75 64 61 28 19  7 51  8 23 33 69 36 48 62 66 47 21 45 74 70 12 29 32 56 60 17 65 59 49 53 72 11 10  2 18 58  5  6 16  4 44 46 20 26 67 41 40 50 24 27 42 54 52 38], a_shuffle_aclus: [ 13  56  31  21  34  60  48  85 100  51  19  92  97  45  54  74 109 108   5  52   3  76   2  17 107  86  83  37  26  10  69  11  32  50  93  53  66  84  89  64  28  62 102  96  16  41  49  75  82  24  88  81  67  71  98  15  14   4  25  78   8   9  23   7  61  63  27  35  90  58  57  68  33  36  59  73  70  55]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [74 73 18 17 49 58  7  4 71 11 27 32 31  8 36 40 75 24 69 25 13 43 10 46  2 16 30 70 28 12 35 50 41 45 33 61 34  0 21 72 26 51 52 14 15 44 68 53 48 67 42 56 23 39 59 77 47  1 57 19  3 66 64 29 62  5 22 20 63 76 60 65 54 38  9 37 55  6], a_shuffle_aclus: [102 100  25  24  67  78  10   7  97  15  36  49  48  11  53  57 107  33  93  34  17  60  14  63   4  23  45  96  37  16  52  68  58  62  50  83  51   2  28  98  35  69  70  19  21  61  92  71  66  90  59  75  32  56  81 109  64   3  76  26   5  89  86  41  84   8  31  27  85 108  82  88  73  55  13  54  74   9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [58 23 16 30 11 47 61 50  4 38 13 32 53 15 65 59 49 48 28  7 55 73 27 36 42 39 45 21 60 12 69 31 26 68 67 41  1 52 18 77 20  8 76  2 57 54 51 43 37 33 25 24 71 63 72 34  3 46 10 56 70 19  5 40  6  9 66 14 35 74 44 29 62 75  0 64 22 17], a_shuffle_aclus: [ 78  32  23  45  15  64  83  68   7  55  17  49  71  21  88  81  67  66  37  10  74 100  36  53  59  56  62  28  82  16  93  48  35  92  90  58   3  70  25 109  27  11 108   4  76  73  69  60  54  50  34  33  97  85  98  51   5  63  14  75  96  26   8  57   9  13  89  19  52 102  61  41  84 107   2  86  31  24]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [25  2 19 47  0 40 21 14 70 71  8 38 31 32 65 17 10 12 22 68 35 69 59 43 11 20  6 56 54 73 62 24 76  3 16 57 34 18 61 33  4 55 44 36 15 63  5 75 29 64 28  7 37 49 74 41 27 58 46 67 77 53 26 60  1 45 30 50 52 51 42 48 66 13 39 23 72  9], a_shuffle_aclus: [ 34   4  26  64   2  57  28  19  96  97  11  55  48  49  88  24  14  16  31  92  52  93  81  60  15  27   9  75  73 100  84  33 108   5  23  76  51  25  83  50   7  74  61  53  21  85   8 107  41  86  37  10  54  67 102  58  36  78  63  90 109  71  35  82   3  62  45  68  70  69  59  66  89  17  56  32  98  13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [57 33 76 23 66 51 36 73 75 19 38 53  1 11 14  7 46 34  5 50 26 69 49 63 70 40 12 72 39  4 30 21 77 24  8  6 10 59 71 41 68 25 27  2 16 47 64 61 35 17 29 48 31 20 54 65 13 62 45 74 56  0 37 60  3 18 32 43 15 58  9 44 22 28 55 42 67 52], a_shuffle_aclus: [ 76  50 108  32  89  69  53 100 107  26  55  71   3  15  19  10  63  51   8  68  35  93  67  85  96  57  16  98  56   7  45  28 109  33  11   9  14  81  97  58  92  34  36   4  23  64  86  83  52  24  41  66  48  27  73  88  17  84  62 102  75   2  54  82   5  25  49  60  21  78  13  61  31  37  74  59  90  70]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 1 45 23 21 49 31 39  0 56  6 41 32 71 54 55  8 52 14 40  5 63 37 69  4 34 61 10 47 42 73 20 26 25  3 72 35 70 24 16 27 36 15 65 17 12  9 43 46 28 33 51 62 48 50 66 67 59 53 57 22 19 30 64 75 77 13 18 74 11 38  7  2 29 44 58 60 76 68], a_shuffle_aclus: [  3  62  32  28  67  48  56   2  75   9  58  49  97  73  74  11  70  19  57   8  85  54  93   7  51  83  14  64  59 100  27  35  34   5  98  52  96  33  23  36  53  21  88  24  16  13  60  63  37  50  69  84  66  68  89  90  81  71  76  31  26  45  86 107 109  17  25 102  15  55  10   4  41  61  78  82 108  92]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 9 49 28 51 77 46 35 55 41  4 42 58 21 13 37 59 36 24 71 31 23  8  5 69 18 60 74 62  3 10  0 56 43 33 34 70 76 32 54 72 14 27 63  1  6 65 66 12 75 20 47 29 67 38 19 45 53 30 40 52 61 64 68 22 25 17 50 11 57  2 44 26 15 39 16 48  7 73], a_shuffle_aclus: [ 13  67  37  69 109  63  52  74  58   7  59  78  28  17  54  81  53  33  97  48  32  11   8  93  25  82 102  84   5  14   2  75  60  50  51  96 108  49  73  98  19  36  85   3   9  88  89  16 107  27  64  41  90  55  26  62  71  45  57  70  83  86  92  31  34  24  68  15  76   4  61  35  21  56  23  66  10 100]\n",
      "a_shuffle_IDXs: [21 22 52 51  2 75 61 26 69 47  3 50 29 59  4 43 11 34 40 36  8 66 54 42 17 45 56 57 23 32 58 60  6 37 74 77 63  5 24 12 38 67 31 48 14 68 15 49 72 16  1 62 70 20 33 41 28 18 71 55 46 39 27 35 44 73 19  9 30 53 64 10 76 65 13  7 25  0], a_shuffle_aclus: [ 28  31  70  69   4 107  83  35  93  64   5  68  41  81   7  60  15  51  57  53  11  89  73  59  24  62  75  76  32  49  78  82   9  54 102 109  85   8  33  16  55  90  48  66  19  92  21  67  98  23   3  84  96  27  50  58  37  25  97  74  63  56  36  52  61 100  26  13  45  71  86  14 108  88  17  10  34   2]\n",
      "a_shuffle_IDXs: [35 40 75 52 49 32 26  9  5 73 42  1 12 76  7 19 64 77  0 34  4 37  6 46  3 68 43 58 57 67 17 61 27 38 20 71 53 45 56 66  2 33 25  8 47 23 22 11 44 28 74 30 18 31 13 72 69 14 10 39 36 55 48 29 21 59 50 16 65 54 60 24 41 51 15 70 62 63], a_shuffle_aclus: [ 52  57 107  70  67  49  35  13   8 100  59   3  16 108  10  26  86 109   2  51   7  54   9  63   5  92  60  78  76  90  24  83  36  55  27  97  71  62  75  89   4  50  34  11  64  32  31  15  61  37 102  45  25  48  17  98  93  19  14  56  53  74  66  41  28  81  68  23  88  73  82  33  58  69  21  96  84  85]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [60 38 54 23 36 15  3 50 46 56 43 75 45 16 24 25 51 18  1 14 27  5 70 42 26 34 35  2 30 58 71 63 55 76 59 28 73 52 11 39 67  6 47 37 22 33 57 32  9 62 17 48 21 29  7 77 31 19  0 69 66 12 49 40  8 10 20 41 74 53 65  4 72 61 68 64 44 13], a_shuffle_aclus: [ 82  55  73  32  53  21   5  68  63  75  60 107  62  23  33  34  69  25   3  19  36   8  96  59  35  51  52   4  45  78  97  85  74 108  81  37 100  70  15  56  90   9  64  54  31  50  76  49  13  84  24  66  28  41  10 109  48  26   2  93  89  16  67  57  11  14  27  58 102  71  88   7  98  83  92  86  61  17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 4 67 29 32 24 16 22 57 70 75 69  2 62 50 42 56 12 19 55 60 73  3 46 38 27 48  1 47 43 41 61 33 63 14 39  9 74 23 76 28 45 20  8 71 59 11 37 21 25 54 15 53 49 30  5 13 65 26 51  0 34 68 17 44 31 36 35 77 18  7 52 58 66  6 10 40 72 64], a_shuffle_aclus: [  7  90  41  49  33  23  31  76  96 107  93   4  84  68  59  75  16  26  74  82 100   5  63  55  36  66   3  64  60  58  83  50  85  19  56  13 102  32 108  37  62  27  11  97  81  15  54  28  34  73  21  71  67  45   8  17  88  35  69   2  51  92  24  61  48  53  52 109  25  10  70  78  89   9  14  57  98  86]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 6 61 33 39 15 14 25 66 52  1 38 49 46 17  5 41 50 12 26 45 19  9 11 29 37 34 24 57 44 70 77 62 72 51 54 58 32 73 74 69  2 67 42 40 48  0 43 27 21 30 31  8 71 60 35 65 28 59 13 23 18 55 16 63  4  7 75 36 64  3 20 68 10 53 47 22 76 56], a_shuffle_aclus: [  9  83  50  56  21  19  34  89  70   3  55  67  63  24   8  58  68  16  35  62  26  13  15  41  54  51  33  76  61  96 109  84  98  69  73  78  49 100 102  93   4  90  59  57  66   2  60  36  28  45  48  11  97  82  52  88  37  81  17  32  25  74  23  85   7  10 107  53  86   5  27  92  14  71  64  31 108  75]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [26 24 33 41 51 17 46 18  3 58  6 16 55 52 48 68  7 70  9 28 39 30  1 60 20 40 35 59 73 31 74 25 65  2 64 23 10  4 57 71 62 69 12 76 42 13 29 44 61 43 54 11 36 77 63 21 22  8 14 32 49 19 53 50 66 34 72  0 47 27 15 38 45 75  5 67 37 56], a_shuffle_aclus: [ 35  33  50  58  69  24  63  25   5  78   9  23  74  70  66  92  10  96  13  37  56  45   3  82  27  57  52  81 100  48 102  34  88   4  86  32  14   7  76  97  84  93  16 108  59  17  41  61  83  60  73  15  53 109  85  28  31  11  19  49  67  26  71  68  89  51  98   2  64  36  21  55  62 107   8  90  54  75]\n",
      "a_shuffle_IDXs: [69  4 15 63 45 22 70 16 19 52 54 12 20 47 55 71 42 28 73 10 65 27 29 46 24 62 56 40 26 66  2 39 57 25 37 72 58 21 60  8 23 77  7 64 59 11 48 33 41 67  3 53  6 36  5 30 34 35  1  0 17 75  9 38 31 14 74 49 68 43 51 76 13 32 44 61 50 18], a_shuffle_aclus: [ 93   7  21  85  62  31  96  23  26  70  73  16  27  64  74  97  59  37 100  14  88  36  41  63  33  84  75  57  35  89   4  56  76  34  54  98  78  28  82  11  32 109  10  86  81  15  66  50  58  90   5  71   9  53   8  45  51  52   3   2  24 107  13  55  48  19 102  67  92  60  69 108  17  49  61  83  68  25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [71 20 10 19 62 47 24  6  7 53 40 42 46 15  0 60 61 14 68 65 64 54  5 41 74 49 17 76 66  3 69 27 22 70  2 72 36 59 77 73 39 35 32 34 12 25 43 33 28 55 37 21 30  8 29 51 31 67  9 75 11 45 52 56 16 63 38 48 23 58 18  4 50 13 44 26 57  1], a_shuffle_aclus: [ 97  27  14  26  84  64  33   9  10  71  57  59  63  21   2  82  83  19  92  88  86  73   8  58 102  67  24 108  89   5  93  36  31  96   4  98  53  81 109 100  56  52  49  51  16  34  60  50  37  74  54  28  45  11  41  69  48  90  13 107  15  62  70  75  23  85  55  66  32  78  25   7  68  17  61  35  76   3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [36 20 37 55 65 22 24 59 10 35 61 29 14 26 56 25 57 19 73 41 33 17  0 40 64 38 48 75  4 53 54 71 15 60 44 67 45 16 76 72 34 58 47 66 69 13  2 30 42 39 49 46 77  8 70 63 51  6 21 23  5  3  1 74 28 12 68 52 11  7 50 31 62  9 27 18 43 32], a_shuffle_aclus: [ 53  27  54  74  88  31  33  81  14  52  83  41  19  35  75  34  76  26 100  58  50  24   2  57  86  55  66 107   7  71  73  97  21  82  61  90  62  23 108  98  51  78  64  89  93  17   4  45  59  56  67  63 109  11  96  85  69   9  28  32   8   5   3 102  37  16  92  70  15  10  68  48  84  13  36  25  60  49]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 5 44 13 27 76 50 35 67 37 33 49 51  0 61 22 32 65 40 25  7 62 36 59 41 56 57  4 46 18 39 64 66 42 29 71 16 14 68 55  2 21 11 69 19 24 45 20 53 60  9 17  3 34 54  8  1 48 74 26 43 38  6 28 12 75 52 31 77 70 23 72 73 10 63 30 47 58 15], a_shuffle_aclus: [  8  61  17  36 108  68  52  90  54  50  67  69   2  83  31  49  88  57  34  10  84  53  81  58  75  76   7  63  25  56  86  89  59  41  97  23  19  92  74   4  28  15  93  26  33  62  27  71  82  13  24   5  51  73  11   3  66 102  35  60  55   9  37  16 107  70  48 109  96  32  98 100  14  85  45  64  78  21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 7 74 71  8 48  4 35 54 36 64 23 52 15 72 14 11 58 17 61 70 30 68 21  6 45 77 41 40 34 47 10 19  3 32 28 46 63 16  2 44 38 51 13 53 66 42 31 26 12 69 65 27 50 60 25 75  1 55  0 43 59 62 22 33 67  9 24 73 29 20 37 49  5 76 56 39 57 18], a_shuffle_aclus: [ 10 102  97  11  66   7  52  73  53  86  32  70  21  98  19  15  78  24  83  96  45  92  28   9  62 109  58  57  51  64  14  26   5  49  37  63  85  23   4  61  55  69  17  71  89  59  48  35  16  93  88  36  68  82  34 107   3  74   2  60  81  84  31  50  90  13  33 100  41  27  54  67   8 108  75  56  76  25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [24 13 11 62 33 72 14 53  1 15 21 49 41 19 59 22 36 52 32 60  6 66 45 75 10 71  0 70 44 46 30 38 48 63 74 55 54 25 76 26  3 43 64 27 39 68 69 51  7 37  2  5 65 34  8 31 28 61 57 23 17 16 67 29 50  9 20 35 42 77 58 40 47 73 18 56 12  4], a_shuffle_aclus: [ 33  17  15  84  50  98  19  71   3  21  28  67  58  26  81  31  53  70  49  82   9  89  62 107  14  97   2  96  61  63  45  55  66  85 102  74  73  34 108  35   5  60  86  36  56  92  93  69  10  54   4   8  88  51  11  48  37  83  76  32  24  23  90  41  68  13  27  52  59 109  78  57  64 100  25  75  16   7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 3 39 50 34 69  0 75 54 49 11 71  1 23 12 59 46 77  7 27  5 64 55  6  9 14 63 31 60 37 52 17 22 67 65 44 48 62 13 38 74 40 76 53 15 72 25 58 10 61 51 33 73 70 35 41 32 29 21  8  2 26 24  4 16 18 20 56 68 66 36 47 19 42 30 28 45 43 57], a_shuffle_aclus: [  5  56  68  51  93   2 107  73  67  15  97   3  32  16  81  63 109  10  36   8  86  74   9  13  19  85  48  82  54  70  24  31  90  88  61  66  84  17  55 102  57 108  71  21  98  34  78  14  83  69  50 100  96  52  58  49  41  28  11   4  35  33   7  23  25  27  75  92  89  53  64  26  59  45  37  62  60  76]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [41 72 39  0 47 59 33 67 43 21 34 17 19 40 66 27 14 10 29 42 51 12  2 37 50 65 46 74 32  5 15  4 20 13 56 49 23 58 35 75  6 28 54 61 73 45 36  8 30 24 44 71 77 26 18 53  3  7 16 63 70 69 25  1 11 68 38 62  9 55 22 31 57 48 64 52 60 76], a_shuffle_aclus: [ 58  98  56   2  64  81  50  90  60  28  51  24  26  57  89  36  19  14  41  59  69  16   4  54  68  88  63 102  49   8  21   7  27  17  75  67  32  78  52 107   9  37  73  83 100  62  53  11  45  33  61  97 109  35  25  71   5  10  23  85  96  93  34   3  15  92  55  84  13  74  31  48  76  66  86  70  82 108]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [14 63  4 24 60 75 52 33 67  3 65 68 35 45 32  7 11 38 27 48 66  6 58 55 47 64 70 71 23 40 50 10 49 37 77 41 13 19  9 16  1 57 46 26 43 28  8 15 59  0 61 30 39 44 56 42 62 22 69  5 74 12 53 31 72 54  2 76 51 73 17 18 20 25 21 36 29 34], a_shuffle_aclus: [ 19  85   7  33  82 107  70  50  90   5  88  92  52  62  49  10  15  55  36  66  89   9  78  74  64  86  96  97  32  57  68  14  67  54 109  58  17  26  13  23   3  76  63  35  60  37  11  21  81   2  83  45  56  61  75  59  84  31  93   8 102  16  71  48  98  73   4 108  69 100  24  25  27  34  28  53  41  51]\n",
      "a_shuffle_IDXs: [33 52 71 56  2  4 28 76 70  6  7 62 57  9 12 29 42 45 37  0 39 40 14 53 27 32 21  1 59 31 54 58 16 15 61 17 66 26 49 20 72 51 36 60 55 47 48 77 67 34  8 44 73 46 35 65 50 68 74 10 43  5 63 69 18  3 30 38 75 64 22 11 24 19 13 25 23 41], a_shuffle_aclus: [ 50  70  97  75   4   7  37 108  96   9  10  84  76  13  16  41  59  62  54   2  56  57  19  71  36  49  28   3  81  48  73  78  23  21  83  24  89  35  67  27  98  69  53  82  74  64  66 109  90  51  11  61 100  63  52  88  68  92 102  14  60   8  85  93  25   5  45  55 107  86  31  15  33  26  17  34  32  58]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [23 69 48 25 61 74 40 77 50 66 67 34 12 24 14 60 43 75 36 26 31 35 65 32 13 28 56 47 10  3 73 18 20 49  6 29  5 71 46 44 70  9 22 45 59 30 57 39 63 51 72 15 37 54 33  4  8  1 62 17 41 21  0 68  2 58 53 42 19 76 64 11 38  7 55 16 52 27], a_shuffle_aclus: [ 32  93  66  34  83 102  57 109  68  89  90  51  16  33  19  82  60 107  53  35  48  52  88  49  17  37  75  64  14   5 100  25  27  67   9  41   8  97  63  61  96  13  31  62  81  45  76  56  85  69  98  21  54  73  50   7  11   3  84  24  58  28   2  92   4  78  71  59  26 108  86  15  55  10  74  23  70  36]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [65 75 21 56 18  1 67 29 54 11 37 70 69 51  7 49 44  4 36 41 77 61 12 31 62 32 38 10 43  8 71 27 45  5 24 57 72 46 47 40  3 17 26 22 60  0 15 55 35 19 33 20 64 58 13 25  6  2 50 63 48 73 23 52 68  9 53 66 39 30 14 76 74 59 42 28 34 16], a_shuffle_aclus: [ 88 107  28  75  25   3  90  41  73  15  54  96  93  69  10  67  61   7  53  58 109  83  16  48  84  49  55  14  60  11  97  36  62   8  33  76  98  63  64  57   5  24  35  31  82   2  21  74  52  26  50  27  86  78  17  34   9   4  68  85  66 100  32  70  92  13  71  89  56  45  19 108 102  81  59  37  51  23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [13 75 24 57 74 50 72 63 38 34 22 62 39 35 18  4 56 27  6 53  7 77 17 54 65 71 51  2  1 10 30 23 44 33  5 64 66 61 68 32 37 41 29 73 20 12 19  0 15 36  9 26 60 59 14  8 70 69 55 11  3 42 52 46 31 16 58 49 40 47 48 43 28 67 21 45 76 25], a_shuffle_aclus: [ 17 107  33  76 102  68  98  85  55  51  31  84  56  52  25   7  75  36   9  71  10 109  24  73  88  97  69   4   3  14  45  32  61  50   8  86  89  83  92  49  54  58  41 100  27  16  26   2  21  53  13  35  82  81  19  11  96  93  74  15   5  59  70  63  48  23  78  67  57  64  66  60  37  90  28  62 108  34]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [61 26 56 50 54 25 23 12 76 73 62 58 38 16 77 45 55 47  5 51  6 29 11 63 60  3 53 49 22  9  7  4 71 75 66 72 31 67 14 52 44 36  8 48 28 30 32 33 37  1  0 21 70 68 65 10 46 13  2 74 39 35 19 15 17 57 64 27 20 42 69 18 24 40 34 43 59 41], a_shuffle_aclus: [ 83  35  75  68  73  34  32  16 108 100  84  78  55  23 109  62  74  64   8  69   9  41  15  85  82   5  71  67  31  13  10   7  97 107  89  98  48  90  19  70  61  53  11  66  37  45  49  50  54   3   2  28  96  92  88  14  63  17   4 102  56  52  26  21  24  76  86  36  27  59  93  25  33  57  51  60  81  58]\n",
      "a_shuffle_IDXs: [51 14 24 42 39 34 36 53 75 27 35 47  0 74 69 58 12 41  3 66 60 50 59 68 57 13 67  7 10  4 49 38 54 71 46 22 65  2  9 17 55 77 20 32 44 37 70 45 73 15 28 19 21  1 33  5 18 16 26 43 31 30 72 11 63 40  6 76 25 61 62 48 64 29 52 56 23  8], a_shuffle_aclus: [ 69  19  33  59  56  51  53  71 107  36  52  64   2 102  93  78  16  58   5  89  82  68  81  92  76  17  90  10  14   7  67  55  73  97  63  31  88   4  13  24  74 109  27  49  61  54  96  62 100  21  37  26  28   3  50   8  25  23  35  60  48  45  98  15  85  57   9 108  34  83  84  66  86  41  70  75  32  11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [13  3 54 73  6 44 64  5 75 39  1 59 49 62 23 68 38 52 43 61 58 20 69 19 31 47 25 10 66 55  4 28 70 24 63 40 22 56  7 48  2 60 45 71  0 57 18 74 76 53 11 77 26 14  8 16 27 30 37 51 50 17 67 46 15 33 35 34 21 32 42  9 12 29 72 36 65 41], a_shuffle_aclus: [ 17   5  73 100   9  61  86   8 107  56   3  81  67  84  32  92  55  70  60  83  78  27  93  26  48  64  34  14  89  74   7  37  96  33  85  57  31  75  10  66   4  82  62  97   2  76  25 102 108  71  15 109  35  19  11  23  36  45  54  69  68  24  90  63  21  50  52  51  28  49  59  13  16  41  98  53  88  58]\n",
      "a_shuffle_IDXs: [22 21 50  0 53 41 19 12 75  9 57 47 38 31 45 71 46 27 23 62  3 66  6 11  5 51 32 61 54 73 55 20  2 63 29 18 35 30 13 33 58 24 76 67 72 59 56 14 25 37 64 42 43 15 39  8 40 16 17  4 65 10 34 74  1 26 60 49 69 48 52 36 44 28 77  7 68 70], a_shuffle_aclus: [ 31  28  68   2  71  58  26  16 107  13  76  64  55  48  62  97  63  36  32  84   5  89   9  15   8  69  49  83  73 100  74  27   4  85  41  25  52  45  17  50  78  33 108  90  98  81  75  19  34  54  86  59  60  21  56  11  57  23  24   7  88  14  51 102   3  35  82  67  93  66  70  53  61  37 109  10  92  96]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [22 71 15 25 16 65 76 40 62 66 35 48 58 54  8 20  7 17 10 64 55  9 72 46 56 27 52 70 13 45 14 44 53 50 21 30 60 47 59  3 73  5 69  1 57 34 23 38 39 43 37 26 24  6 36 18 77  0 51 31 32  2 29 67 61 42 11 28 63 49 74 75 12  4 33 19 68 41], a_shuffle_aclus: [ 31  97  21  34  23  88 108  57  84  89  52  66  78  73  11  27  10  24  14  86  74  13  98  63  75  36  70  96  17  62  19  61  71  68  28  45  82  64  81   5 100   8  93   3  76  51  32  55  56  60  54  35  33   9  53  25 109   2  69  48  49   4  41  90  83  59  15  37  85  67 102 107  16   7  50  26  92  58]\n",
      "a_shuffle_IDXs: [77 34  7 14 46 66  6 16 18 74 10 64 45 65 61 75 44 26  4  0 19 59  1 41 15 36 54 27  5 48 23 43 51 24 62 72 11 33 52 76 68 30 38 40 22 53 28 25 42 60 39 17  8 12 35 50 21 32 71  2 67 73  9 20 47 69 70 55 58 29 57 13 31 56 63 37 49  3], a_shuffle_aclus: [109  51  10  19  63  89   9  23  25 102  14  86  62  88  83 107  61  35   7   2  26  81   3  58  21  53  73  36   8  66  32  60  69  33  84  98  15  50  70 108  92  45  55  57  31  71  37  34  59  82  56  24  11  16  52  68  28  49  97   4  90 100  13  27  64  93  96  74  78  41  76  17  48  75  85  54  67   5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [45 14 29 19 46 27 41 49 76 62 20 36  3 16 75  4 60 17 56 30 23 50 52 72 44 11 67 22  9 35 69 12 66 40  2 15 42  0 51 37 68 55 47 74 48 70 57 63 25 77 33  6  1 26 64 61 13 59 39 53 24 43 58 18 38 10 73  5  8 28 21 54 34 32 65 31  7 71], a_shuffle_aclus: [ 62  19  41  26  63  36  58  67 108  84  27  53   5  23 107   7  82  24  75  45  32  68  70  98  61  15  90  31  13  52  93  16  89  57   4  21  59   2  69  54  92  74  64 102  66  96  76  85  34 109  50   9   3  35  86  83  17  81  56  71  33  60  78  25  55  14 100   8  11  37  28  73  51  49  88  48  10  97]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [59  4 63 11  1  2 39 64  6 42 57 32 14 31 20  8 16 26 27 46 72 49 35 70 60 51 50 52 21 37 36 44 77 28 69 55 34 18 41  0 58  7 65 45  5 54 17 48 66 38 29  3 40 13 30 67 12 71 33 23 56 15 62 22 19  9 25 68 47 76 10 75 61 53 43 24 74 73], a_shuffle_aclus: [ 81   7  85  15   3   4  56  86   9  59  76  49  19  48  27  11  23  35  36  63  98  67  52  96  82  69  68  70  28  54  53  61 109  37  93  74  51  25  58   2  78  10  88  62   8  73  24  66  89  55  41   5  57  17  45  90  16  97  50  32  75  21  84  31  26  13  34  92  64 108  14 107  83  71  60  33 102 100]\n",
      "a_shuffle_IDXs: [27 40 35 23 31 64 76 36 18 74 11 48 73 30 70 12 47 41 67  1 46  0 66 17 49  9 19 75 57 28 25 32 39  8 43 37 34 60 61  4 22 69  5 63 45 65 50 55 59 58 15  6 29 44 33 24 13 71 16 53 10  2 20 51  7 56 77 14 72 52 42  3 68 21 62 54 26 38], a_shuffle_aclus: [ 36  57  52  32  48  86 108  53  25 102  15  66 100  45  96  16  64  58  90   3  63   2  89  24  67  13  26 107  76  37  34  49  56  11  60  54  51  82  83   7  31  93   8  85  62  88  68  74  81  78  21   9  41  61  50  33  17  97  23  71  14   4  27  69  10  75 109  19  98  70  59   5  92  28  84  73  35  55]\n",
      "a_shuffle_IDXs: [21  8 41  3 67 38 42  6 64 43  1 66 52 71 44 65  0 45 58 61 70 14 53 57 51 46 39 16 62  4 73 19 29 11 50 77 18 15 74 69 48 33 28 54 32 59 13 24 26 34 40 23 12 20 55 47 75  2 10 56 37 35 27 30 25 36 17  5 60  7 22 63 72  9 31 76 68 49], a_shuffle_aclus: [ 28  11  58   5  90  55  59   9  86  60   3  89  70  97  61  88   2  62  78  83  96  19  71  76  69  63  56  23  84   7 100  26  41  15  68 109  25  21 102  93  66  50  37  73  49  81  17  33  35  51  57  32  16  27  74  64 107   4  14  75  54  52  36  45  34  53  24   8  82  10  31  85  98  13  48 108  92  67]\n",
      "a_shuffle_IDXs: [ 6 53 26 40 70 17 29  1 32 59 52 36 42 44 30 43  4 35 49 25 39 47 14 33 46 45 73 77 54 72 51 28 74 71 62 21  0 38 22 67 61 58  7 12 50 57 69 63 31 27 48 11  8 20 56 55 68 65 34 15  9 66  5 16  3 13 60  2 37 41 10 23 76 75 64 19 18 24], a_shuffle_aclus: [  9  71  35  57  96  24  41   3  49  81  70  53  59  61  45  60   7  52  67  34  56  64  19  50  63  62 100 109  73  98  69  37 102  97  84  28   2  55  31  90  83  78  10  16  68  76  93  85  48  36  66  15  11  27  75  74  92  88  51  21  13  89   8  23   5  17  82   4  54  58  14  32 108 107  86  26  25  33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [27 44 66 29 22  0 19 75  9  3 36 53 23 26 50 48 32 14 71 52 11 12 77 68 63 46 72 15 70 30  8 62 76 16  6 69 56  1 18 39 54  2 42 17 33 58 64 25 73 34 55 31 40 43 38 51 60 47 35 74  7 57 20 59  4 24 41 49 10 45 28 67 21 13  5 65 37 61], a_shuffle_aclus: [ 36  61  89  41  31   2  26 107  13   5  53  71  32  35  68  66  49  19  97  70  15  16 109  92  85  63  98  21  96  45  11  84 108  23   9  93  75   3  25  56  73   4  59  24  50  78  86  34 100  51  74  48  57  60  55  69  82  64  52 102  10  76  27  81   7  33  58  67  14  62  37  90  28  17   8  88  54  83]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [24 36  5 47 76 44 41 48 31 43 63 72 73 54  3 28 35 26  9 74 70 17 16 18 66 40 65 20 53 69  4 27 32 75 39 30 52 15 25 77 13 49 12 62 60 71  2 38 42 45 64  1  6 55 67 11 61 37 51 34 10 33 19 14 50 59 46 29 57  7 21 68  0  8 56 58 22 23], a_shuffle_aclus: [ 33  53   8  64 108  61  58  66  48  60  85  98 100  73   5  37  52  35  13 102  96  24  23  25  89  57  88  27  71  93   7  36  49 107  56  45  70  21  34 109  17  67  16  84  82  97   4  55  59  62  86   3   9  74  90  15  83  54  69  51  14  50  26  19  68  81  63  41  76  10  28  92   2  11  75  78  31  32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [56 17  4 20 54 18 43 10 39 70 61 47 37 26 29 71 64  8 21 59 57 38 68 76 14 31 25 11  2 23 55 50 22 65  7 12 52 73 36 34 13  3 24 35 40 19 45 44 53 66 62 46 69  9 27 32 58 42  6 51 74 48  5 15 60 72 33 49  1 30 28 67 63 16  0 41 77 75], a_shuffle_aclus: [ 75  24   7  27  73  25  60  14  56  96  83  64  54  35  41  97  86  11  28  81  76  55  92 108  19  48  34  15   4  32  74  68  31  88  10  16  70 100  53  51  17   5  33  52  57  26  62  61  71  89  84  63  93  13  36  49  78  59   9  69 102  66   8  21  82  98  50  67   3  45  37  90  85  23   2  58 109 107]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [52 54  0  1 27 21 75 36 61 55 77 22 37 12  4 76 58  3 71 43  9 67  5  8 39 13 40 74 34 59 41  2 45 31 51 44 26 15 29 49 60 48 47 66 20 70 16 25 65 56 24 11 10 62 68 30 73 53 18 23 46 42 69 72 14 33 35  7 50 17 57 32 64 63 38  6 28 19], a_shuffle_aclus: [ 70  73   2   3  36  28 107  53  83  74 109  31  54  16   7 108  78   5  97  60  13  90   8  11  56  17  57 102  51  81  58   4  62  48  69  61  35  21  41  67  82  66  64  89  27  96  23  34  88  75  33  15  14  84  92  45 100  71  25  32  63  59  93  98  19  50  52  10  68  24  76  49  86  85  55   9  37  26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [61 76 69  1 71 58 45 44 16 65 47 68 10 13 73 41 26 53 49  8 15 38 67 42 32 14  4 27 57 52 39 54 60 66 22 12  6 11 34  2 30 36 24  0  9 17 40 37 21 77 29 63 25 59 62  5  3 64 18 75 50 23 43 20 70 28 51 46 56 35 55 48 31 74 33 72  7 19], a_shuffle_aclus: [ 83 108  93   3  97  78  62  61  23  88  64  92  14  17 100  58  35  71  67  11  21  55  90  59  49  19   7  36  76  70  56  73  82  89  31  16   9  15  51   4  45  53  33   2  13  24  57  54  28 109  41  85  34  81  84   8   5  86  25 107  68  32  60  27  96  37  69  63  75  52  74  66  48 102  50  98  10  26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [73 20 55 71 64 17 51 31 69 70 18 13 53 60 10  8 42 61 35 11 21 26 75  7  3 24 19 57 34 48 76 38  2 68 36 74 63 14 33 49 47  4 12 56 58 28  9 16 27 29 45 32  1 41 37 39 77 52 72 66 15 62 59 65 40 67 46 50 43 25 30  5  0 44  6 54 22 23], a_shuffle_aclus: [100  27  74  97  86  24  69  48  93  96  25  17  71  82  14  11  59  83  52  15  28  35 107  10   5  33  26  76  51  66 108  55   4  92  53 102  85  19  50  67  64   7  16  75  78  37  13  23  36  41  62  49   3  58  54  56 109  70  98  89  21  84  81  88  57  90  63  68  60  34  45   8   2  61   9  73  31  32]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [77 20  8 15 66 34 38 63  4 36 64 69 39 74 10 50 21 67 56 48 17  9 12  0 54 22 55 25 73 27 76 19 30 68 43 28 52 45 23  7 33 60 26 49 13 35 72  1 29 62 32 18 16 40 65 71  2 44 59 75 42 58 11 61  5 46  3 37 31 53 57 47 14 41 70 51  6 24], a_shuffle_aclus: [109  27  11  21  89  51  55  85   7  53  86  93  56 102  14  68  28  90  75  66  24  13  16   2  73  31  74  34 100  36 108  26  45  92  60  37  70  62  32  10  50  82  35  67  17  52  98   3  41  84  49  25  23  57  88  97   4  61  81 107  59  78  15  83   8  63   5  54  48  71  76  64  19  58  96  69   9  33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [44 74 16 25 76 55  0  7 22 18 11 14 47 27 77 33 63 49 30 29 57  3 28  4 17 35 73 67 60 39 62 13 36 68 46 75 61 26 38 64 52  6  1 37 72 42 53 41 56 32 66 21 70 19 40 12 71 50 48  8 69 23 65  5 10 24 45 20 59 15 34 54  2 43 31 51 58  9], a_shuffle_aclus: [ 61 102  23  34 108  74   2  10  31  25  15  19  64  36 109  50  85  67  45  41  76   5  37   7  24  52 100  90  82  56  84  17  53  92  63 107  83  35  55  86  70   9   3  54  98  59  71  58  75  49  89  28  96  26  57  16  97  68  66  11  93  32  88   8  14  33  62  27  81  21  51  73   4  60  48  69  78  13]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [50 72 58 60 66 10  0 45 48  7 29 11 64 22 46 59 13  8 34 76 56 17 16 21  1 39 24 43 54 19 44 57  5 65 51 55 25 49 30  2 26 35 36 14  4 37 12 47  9 15 23 28 73 62 75 42 41 31  3 71 38 61 27 74 68  6 20 18 63 32 77 70 69 52 40 33 67 53], a_shuffle_aclus: [ 68  98  78  82  89  14   2  62  66  10  41  15  86  31  63  81  17  11  51 108  75  24  23  28   3  56  33  60  73  26  61  76   8  88  69  74  34  67  45   4  35  52  53  19   7  54  16  64  13  21  32  37 100  84 107  59  58  48   5  97  55  83  36 102  92   9  27  25  85  49 109  96  93  70  57  50  90  71]\n",
      "a_shuffle_IDXs: [76 35 13 52 22 47 57 74  2 59 75 39  6 56 46 31 17 40 12 58 38 48 73 72 66 25 28  7  1 30 19 24 16 50 20 45 29 11 68 27 42 18 77 33 63 55 15 65 21 37 26 14 71 53 49  3 69 23 41 43 67 70 10 62  9 34 32  5  4 54  0 61 60  8 44 36 51 64], a_shuffle_aclus: [108  52  17  70  31  64  76 102   4  81 107  56   9  75  63  48  24  57  16  78  55  66 100  98  89  34  37  10   3  45  26  33  23  68  27  62  41  15  92  36  59  25 109  50  85  74  21  88  28  54  35  19  97  71  67   5  93  32  58  60  90  96  14  84  13  51  49   8   7  73   2  83  82  11  61  53  69  86]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [20  6 21 51 61 66 56 35 57 27 44 38 48 52 68 55 72 39 75 10 69  5  4 53 46 77 22 47 16 65 14 28 42 31 63 70 76 59  8 37 74 11 25 49 64 24 17 34  2 67 40 62 15 33 23 71 19  7  1 18 43 50 58 60 29 73 13  0 45  3 32 30 12  9 36 41 26 54], a_shuffle_aclus: [ 27   9  28  69  83  89  75  52  76  36  61  55  66  70  92  74  98  56 107  14  93   8   7  71  63 109  31  64  23  88  19  37  59  48  85  96 108  81  11  54 102  15  34  67  86  33  24  51   4  90  57  84  21  50  32  97  26  10   3  25  60  68  78  82  41 100  17   2  62   5  49  45  16  13  53  58  35  73]\n",
      "a_shuffle_IDXs: [23 40 53 66 68  6 56 30  1 74  2 10 17 64 22 49 47 65 28 50  5 45 36 14 12 34 27 21 29 33 11 63  8 72 15 61 25 18 20 13 75 41 46 51 42 44  4 57 59 76 19 67 55 60 16 73 48 32 24  3 71 58 70 39 38 52 69 54  7 26 35  0  9 31 62 37 77 43], a_shuffle_aclus: [ 32  57  71  89  92   9  75  45   3 102   4  14  24  86  31  67  64  88  37  68   8  62  53  19  16  51  36  28  41  50  15  85  11  98  21  83  34  25  27  17 107  58  63  69  59  61   7  76  81 108  26  90  74  82  23 100  66  49  33   5  97  78  96  56  55  70  93  73  10  35  52   2  13  48  84  54 109  60]\n",
      "a_shuffle_IDXs: [27 24 10 71 31 63 16 55 25 36 56 39  3 76 22 21 67 28 43 12 30 29  5 44 49 40 75 18 17  9 69 58 45 47 15 57 66 60 38 32 35 50 59 34  2 20 46 41 52  6 65 62 70 64 72 33 37 73  0 61  8 26 74  7 13 19 51 54 53 23 77 48  1 68 14 42 11  4], a_shuffle_aclus: [ 36  33  14  97  48  85  23  74  34  53  75  56   5 108  31  28  90  37  60  16  45  41   8  61  67  57 107  25  24  13  93  78  62  64  21  76  89  82  55  49  52  68  81  51   4  27  63  58  70   9  88  84  96  86  98  50  54 100   2  83  11  35 102  10  17  26  69  73  71  32 109  66   3  92  19  59  15   7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 9 37 39 34 73 40 55 53  7 19 38 56 67 27 17 20 70 32 47 60 21 44 10 11 33 59 18 23 28 48 25 14 29  2 64  0 61 69  8  5 30  4 42 57 51 58 65 52 71 74 13 75 43 50 35 15 16 54 31 24 77 66 68 36  6 63 72 41 45 46  3 26 76 49 62  1 12 22], a_shuffle_aclus: [ 13  54  56  51 100  57  74  71  10  26  55  75  90  36  24  27  96  49  64  82  28  61  14  15  50  81  25  32  37  66  34  19  41   4  86   2  83  93  11   8  45   7  59  76  69  78  88  70  97 102  17 107  60  68  52  21  23  73  48  33 109  89  92  53   9  85  98  58  62  63   5  35 108  67  84   3  16  31]\n",
      "a_shuffle_IDXs: [34  3 14 54 59 19 69  6 57 11 45 74 61 36 62 31 25 72 43 50 66 41 75 39 22 48 33 70 21 65 27 32 35  0 44  2 26 15 58 40  4  8 77  5 30 17 18 56 55 53 63 52 71 47 76 42 20 73 24 10 28 38 68  9 12  1 64 29 49 46 13 16  7 60 67 23 37 51], a_shuffle_aclus: [ 51   5  19  73  81  26  93   9  76  15  62 102  83  53  84  48  34  98  60  68  89  58 107  56  31  66  50  96  28  88  36  49  52   2  61   4  35  21  78  57   7  11 109   8  45  24  25  75  74  71  85  70  97  64 108  59  27 100  33  14  37  55  92  13  16   3  86  41  67  63  17  23  10  82  90  32  54  69]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [75 77 41 55 74 61  8 45 24 11 20  3 44 40 18  4 76 43 49 36  2  6 29 52  5 25 16 19 50 73 51 65  1 56 60 21 27 70 17 33 28 39 13 59 71 15 38 14  9 35 58  0 53 23 34 37 48 67 47 72 57 62 32 10 31 22 68  7 66 26 54 46 69 42 64 30 12 63], a_shuffle_aclus: [107 109  58  74 102  83  11  62  33  15  27   5  61  57  25   7 108  60  67  53   4   9  41  70   8  34  23  26  68 100  69  88   3  75  82  28  36  96  24  50  37  56  17  81  97  21  55  19  13  52  78   2  71  32  51  54  66  90  64  98  76  84  49  14  48  31  92  10  89  35  73  63  93  59  86  45  16  85]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 8 42 32  5 28  0 25 61 76 18 23 16 41 58 17 13 43 10 49 62 50 26 34 40 24 47 68 21  2 77 45 73 51 59 36  7 75 64 67 14 20 46 56 11 19 72 69 54 29 44 15 70  6 35  4 57 38  9 22 74 48 63 66  1  3 52 30 60 33 55 39 71 37 12 65 31 27 53], a_shuffle_aclus: [ 11  59  49   8  37   2  34  83 108  25  32  23  58  78  24  17  60  14  67  84  68  35  51  57  33  64  92  28   4 109  62 100  69  81  53  10 107  86  90  19  27  63  75  15  26  98  93  73  41  61  21  96   9  52   7  76  55  13  31 102  66  85  89   3   5  70  45  82  50  74  56  97  54  16  88  48  36  71]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [16 54 24 38 25 32 57  7 68 50 34 26 41 11 64 55 67 75 65 49 35 13 40 56  6 43 17  2  5 59 30 48 53 61 63 36 44 47 37 77  3 28 21 69  9 46 14 23 39 29 31 71 62  8 12 51 22 60 27 19 33 73 10  4 74 58 76 66 52 18 70  0 15 45 42  1 72 20], a_shuffle_aclus: [ 23  73  33  55  34  49  76  10  92  68  51  35  58  15  86  74  90 107  88  67  52  17  57  75   9  60  24   4   8  81  45  66  71  83  85  53  61  64  54 109   5  37  28  93  13  63  19  32  56  41  48  97  84  11  16  69  31  82  36  26  50 100  14   7 102  78 108  89  70  25  96   2  21  62  59   3  98  27]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [34 13 74 49 15 30 59 42 23 40 19 71  3 36 20 68 50 56  7  4 24 66 33 65 41  8 64  0 76 62 58 17 44 45 37 38 16 69 63  5 10 61  6 31 55 26 72 77  9 73 12 53 46 29 60 22 28 70 57 43  1 11 52 14 47 27 75 48  2 54 25 32 67 18 51 21 39 35], a_shuffle_aclus: [ 51  17 102  67  21  45  81  59  32  57  26  97   5  53  27  92  68  75  10   7  33  89  50  88  58  11  86   2 108  84  78  24  61  62  54  55  23  93  85   8  14  83   9  48  74  35  98 109  13 100  16  71  63  41  82  31  37  96  76  60   3  15  70  19  64  36 107  66   4  73  34  49  90  25  69  28  56  52]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 4 35 30 60 39 50 55 14 49 69 40 34 66 44 72 46 18 74 13 12  9 51 70  3 32 73 52 41 45 10 75 59 76  2  7 43 42 33 47 77 27 31 37 56 22 38 54 67 28 71  0 58 24 15 21 68 16  1 23 26 64 65 29 62 25 61  6 36 48 63 53 20 57  5 11  8 17 19], a_shuffle_aclus: [  7  52  45  82  56  68  74  19  67  93  57  51  89  61  98  63  25 102  17  16  13  69  96   5  49 100  70  58  62  14 107  81 108   4  10  60  59  50  64 109  36  48  54  75  31  55  73  90  37  97   2  78  33  21  28  92  23   3  32  35  86  88  41  84  34  83   9  53  66  85  71  27  76   8  15  11  24  26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [62 48 19 40 15 53 49 45  9 68 14 16 25 70 20 39 66 50 28 29 11  6 17 33  2 64 52 61 27 59 35 51 76  8  5  7 42 10 21 44 38 75 56 72 71  1 41 55 26 22  0 24 77 36 31 65 63 69 34 57 73 23  4 60 13 46 30 47 58 54 37 32  3 12 43 67 74 18], a_shuffle_aclus: [ 84  66  26  57  21  71  67  62  13  92  19  23  34  96  27  56  89  68  37  41  15   9  24  50   4  86  70  83  36  81  52  69 108  11   8  10  59  14  28  61  55 107  75  98  97   3  58  74  35  31   2  33 109  53  48  88  85  93  51  76 100  32   7  82  17  63  45  64  78  73  54  49   5  16  60  90 102  25]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [35 13 23 69 17 64 60  7 70 31 52 43 58 11 12 72 45 20 50  0 21 73 67 49 22 37 14 48  5 51 77 42  1 56 46 62 19 59 15 38 32 10 30  8 71 26  3 75 44 74 24 65 57 53 47 76 61 29  2 40  9 55 28 63 66 39  4 36 33 54 25 41 27 16 18 68 34  6], a_shuffle_aclus: [ 52  17  32  93  24  86  82  10  96  48  70  60  78  15  16  98  62  27  68   2  28 100  90  67  31  54  19  66   8  69 109  59   3  75  63  84  26  81  21  55  49  14  45  11  97  35   5 107  61 102  33  88  76  71  64 108  83  41   4  57  13  74  37  85  89  56   7  53  50  73  34  58  36  23  25  92  51   9]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [41 58 47 32 66 44 62 22 75 42 27 55 49 24 40 11  6 52 51 17 64 18 54 68 74 70 10 61 67  0 21 29 45 14 60 50 77  9 39  4 38 12 37 36 69 20 25 76 31 19  5 56 71 46  8 57 59 15 28 13 30  2 53  3 33 48 65 63  1 43 72 73 26 34 35  7 23 16], a_shuffle_aclus: [ 58  78  64  49  89  61  84  31 107  59  36  74  67  33  57  15   9  70  69  24  86  25  73  92 102  96  14  83  90   2  28  41  62  19  82  68 109  13  56   7  55  16  54  53  93  27  34 108  48  26   8  75  97  63  11  76  81  21  37  17  45   4  71   5  50  66  88  85   3  60  98 100  35  51  52  10  32  23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [20 47 11 41 69 40  7 75 37 51 10 36 76 22  4 74 58 48  5 65 21 66  6 49 53 68 13 52 60 67 27 25  9 70 71 50  3 17 55 14 63 73 26 72 64 43 38 77 35 19  2 56 33 28 31  8 44 61 30 32 54 23 45 15 29 46 59  1  0 12 34 18 39 62 57 42 24 16], a_shuffle_aclus: [ 27  64  15  58  93  57  10 107  54  69  14  53 108  31   7 102  78  66   8  88  28  89   9  67  71  92  17  70  82  90  36  34  13  96  97  68   5  24  74  19  85 100  35  98  86  60  55 109  52  26   4  75  50  37  48  11  61  83  45  49  73  32  62  21  41  63  81   3   2  16  51  25  56  84  76  59  33  23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [67 13 36 34 56 70 33 75 68 40 30 10 52 54 19 69 65 74  5 47 73 63 43 46 23 51 15 38 41 17 11 50  8 37 77 42 71 66 27 48 21 45 20 29 16 14  4 22  0 59  3 28  2 49  9 72 35 58  1  7 18 62 44 60  6 25 55 53 39 26 12 76 24 57 32 64 61 31], a_shuffle_aclus: [ 90  17  53  51  75  96  50 107  92  57  45  14  70  73  26  93  88 102   8  64 100  85  60  63  32  69  21  55  58  24  15  68  11  54 109  59  97  89  36  66  28  62  27  41  23  19   7  31   2  81   5  37   4  67  13  98  52  78   3  10  25  84  61  82   9  34  74  71  56  35  16 108  33  76  49  86  83  48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [61 21 20  3 10 40 66 44  8 58 74 55 48 54  6 42 38 49 29 23 69 19 51 53 12 75  4 36 73 45 16 71 25 56 72 15 34 11 64 52 65 50 60 62 76 70 24  7 59 27 67 43 17 63 41  9 37 18 26 13 33 47 14 77  0  1 31 22 28 46 39 57  5  2 68 30 32 35], a_shuffle_aclus: [ 83  28  27   5  14  57  89  61  11  78 102  74  66  73   9  59  55  67  41  32  93  26  69  71  16 107   7  53 100  62  23  97  34  75  98  21  51  15  86  70  88  68  82  84 108  96  33  10  81  36  90  60  24  85  58  13  54  25  35  17  50  64  19 109   2   3  48  31  37  63  56  76   8   4  92  45  49  52]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [11 13 52 38 24 71  3 53 10  7 23  0 42 63 48 20 60 35 27 70 74 40 33 54  1 44 39 49 28 43 45 34 75 31 18 17  5 61 59 58 36  9 46 76  4 47 67 65 12 21 64 62 55 26 25 22 16 37 19 50 15 30 73 32 56  6  2 72 29 57  8 69 66 41 51 14 68 77], a_shuffle_aclus: [ 15  17  70  55  33  97   5  71  14  10  32   2  59  85  66  27  82  52  36  96 102  57  50  73   3  61  56  67  37  60  62  51 107  48  25  24   8  83  81  78  53  13  63 108   7  64  90  88  16  28  86  84  74  35  34  31  23  54  26  68  21  45 100  49  75   9   4  98  41  76  11  93  89  58  69  19  92 109]\n",
      "a_shuffle_IDXs: [26 22 58 37 76 11  5 18 66 10  1 65 72 73 24 63 64 38 74 77 71 49  0 56 17 52 32 29 23 42 47 67  9 53 21 69 55 30 75 25 48 31  6 15 54 19 27 60 33 40 20 41 59 50  4 70  3 61 57 62 36 34 45 44  8 14 68 51 43 13 35 39 28 12 46  2 16  7], a_shuffle_aclus: [ 35  31  78  54 108  15   8  25  89  14   3  88  98 100  33  85  86  55 102 109  97  67   2  75  24  70  49  41  32  59  64  90  13  71  28  93  74  45 107  34  66  48   9  21  73  26  36  82  50  57  27  58  81  68   7  96   5  83  76  84  53  51  62  61  11  19  92  69  60  17  52  56  37  16  63   4  23  10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [23 26 72 60  9 65  1 64 32  5 19 66  4 37 29  3 18 69 67 27 70 61 58 45 30 53 28 41 33 56 62 38 57 10 71 17 14 42 43 12 48 36 75 73 16 68 34 47 63 44 39  6 46  7 22 55  8 76 35 50 31 40 11 21 51 20 59 54 49 77 25  2 13 74 52  0 24 15], a_shuffle_aclus: [ 32  35  98  82  13  88   3  86  49   8  26  89   7  54  41   5  25  93  90  36  96  83  78  62  45  71  37  58  50  75  84  55  76  14  97  24  19  59  60  16  66  53 107 100  23  92  51  64  85  61  56   9  63  10  31  74  11 108  52  68  48  57  15  28  69  27  81  73  67 109  34   4  17 102  70   2  33  21]\n",
      "a_shuffle_IDXs: [29 55 48 54  0 18 10  1 66 32 71 31 49 77 22 33 72 14  5 12 23 64 26 43 67 27 39 37 58 74 34 19 44 28 50 76 13 70  2 15 60 68 24 53 38 41  4 11 62 25 73 51  9 59 57 21 52 30 36 16 35 46 17 63  6 40 45 20  3 56 65 47  7 69  8 75 61 42], a_shuffle_aclus: [ 41  74  66  73   2  25  14   3  89  49  97  48  67 109  31  50  98  19   8  16  32  86  35  60  90  36  56  54  78 102  51  26  61  37  68 108  17  96   4  21  82  92  33  71  55  58   7  15  84  34 100  69  13  81  76  28  70  45  53  23  52  63  24  85   9  57  62  27   5  75  88  64  10  93  11 107  83  59]\n",
      "a_shuffle_IDXs: [72 13 56  7 37 48 68  5 18 32 12 16 55 41 34 64 17 77 42  2 14 73 63 20 65 67 52 59 61  9 69 58 29 19 40 54 25 26 30 31 50 71 45 49 22 66 60  6 35 76 27 57 24 62  4 15 46 36 38 21 51  0  3 43 39 10 53  8 70  1 75 23 44 11 74 28 47 33], a_shuffle_aclus: [ 98  17  75  10  54  66  92   8  25  49  16  23  74  58  51  86  24 109  59   4  19 100  85  27  88  90  70  81  83  13  93  78  41  26  57  73  34  35  45  48  68  97  62  67  31  89  82   9  52 108  36  76  33  84   7  21  63  53  55  28  69   2   5  60  56  14  71  11  96   3 107  32  61  15 102  37  64  50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [28 17 33 31  3 15  0 69  6  2 56  1 11 22 16 75 50 35 70 52 37  7 42 47 39 60 53 27 26 64 21 25 13 58 49 46 54 34 67 63 76 71 55  4 48 38 68 19 61 77 45 30 32 41 65  8 20 73 24 57 12  5 59 51 66 18 43 62 40 44 29 36  9 74 23 10 72 14], a_shuffle_aclus: [ 37  24  50  48   5  21   2  93   9   4  75   3  15  31  23 107  68  52  96  70  54  10  59  64  56  82  71  36  35  86  28  34  17  78  67  63  73  51  90  85 108  97  74   7  66  55  92  26  83 109  62  45  49  58  88  11  27 100  33  76  16   8  81  69  89  25  60  84  57  61  41  53  13 102  32  14  98  19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [29  3 61 38 77 18 14 24 72 58 76 54 71 53 41 62  8 48 33 42  7 26 67 64 73 57  2  6 44 15 16 11 46 31 19 20 22 66 69  9 51 32  5  0 49 34 30 13  1 12 35 55 23 74  4 50 68 27 39 63 37 10 56 47 40 36 60 59 28 25 45 21 65 70 75 52 17 43], a_shuffle_aclus: [ 41   5  83  55 109  25  19  33  98  78 108  73  97  71  58  84  11  66  50  59  10  35  90  86 100  76   4   9  61  21  23  15  63  48  26  27  31  89  93  13  69  49   8   2  67  51  45  17   3  16  52  74  32 102   7  68  92  36  56  85  54  14  75  64  57  53  82  81  37  34  62  28  88  96 107  70  24  60]\n",
      "a_shuffle_IDXs: [33  2 34 37 15 72 30 38 62 77 31 32 10 18  1  6 75 27 54 61 22 11 65 16 21 68 28 13  5  8 14 41 73 24 53 71 25 43 29 48  0 52  7 39 70 45 64 26 74 12 66 69  4 42 19 23 56 47 44 20 49 60 46 57 63 51 67 35 55 50 40  3 17 58 76 36  9 59], a_shuffle_aclus: [ 50   4  51  54  21  98  45  55  84 109  48  49  14  25   3   9 107  36  73  83  31  15  88  23  28  92  37  17   8  11  19  58 100  33  71  97  34  60  41  66   2  70  10  56  96  62  86  35 102  16  89  93   7  59  26  32  75  64  61  27  67  82  63  76  85  69  90  52  74  68  57   5  24  78 108  53  13  81]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [61 38 21 30 20 70 45 35 18 51 36 27 23 50 39  0 31 19  9 74 52 14  5  8 59 67 47 53 56 37  6  4 25 16 65 60 41 15 73 76 69 44 10 28 68 40  3 29 66 77  1 33 63 58  2 13 34 26 46 54 32 17 42 24 49 55 75 11 48 22 57 72 62 12 43 64 71  7], a_shuffle_aclus: [ 83  55  28  45  27  96  62  52  25  69  53  36  32  68  56   2  48  26  13 102  70  19   8  11  81  90  64  71  75  54   9   7  34  23  88  82  58  21 100 108  93  61  14  37  92  57   5  41  89 109   3  50  85  78   4  17  51  35  63  73  49  24  59  33  67  74 107  15  66  31  76  98  84  16  60  86  97  10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [47 10 37 27 66 31 67 42 29 74 73 77 18 57 71 41  1 13 56 17 49 21 24 52 16  6 28 38 53 39 43  9 62 69 50 11 23 46 60 45 51 44 30  2 32 61 35  8 68 26  0  4 54 19 25 75 72 59 55 48 34  5 33 40 12 36  3 76 58 64 70 14  7 22 63 20 15 65], a_shuffle_aclus: [ 64  14  54  36  89  48  90  59  41 102 100 109  25  76  97  58   3  17  75  24  67  28  33  70  23   9  37  55  71  56  60  13  84  93  68  15  32  63  82  62  69  61  45   4  49  83  52  11  92  35   2   7  73  26  34 107  98  81  74  66  51   8  50  57  16  53   5 108  78  86  96  19  10  31  85  27  21  88]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [12 14 22 15 68 74  2  7 31  8 39 27 24 59 45 41 65 55 17 48 72 23 64 26  6 58  9 47 21  3 50 44 49 57 32 34 42  0 77 35 46 28 73 76 71 70  4 40  5 16 75 63 37 66 19 67 62 43 13 60 20 51 36 56 52 29 10 38 18 33 54 11 25 69 30 53 61  1], a_shuffle_aclus: [ 16  19  31  21  92 102   4  10  48  11  56  36  33  81  62  58  88  74  24  66  98  32  86  35   9  78  13  64  28   5  68  61  67  76  49  51  59   2 109  52  63  37 100 108  97  96   7  57   8  23 107  85  54  89  26  90  84  60  17  82  27  69  53  75  70  41  14  55  25  50  73  15  34  93  45  71  83   3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [18 48 14 75 67 19 62 13 58 20 63 41 39  2  8 24 50 74 25 11 72 29 36 43 73 17 44 55  5  7 21 28 40 66 15 68  3 70 42  6 71 69 77 49 76 37 54 26  9 51 59 57 27 12 23 32 45 10 33 46 31 56 61 53 30  1 34 52  0 64 60  4 38 65 16 22 35 47], a_shuffle_aclus: [ 25  66  19 107  90  26  84  17  78  27  85  58  56   4  11  33  68 102  34  15  98  41  53  60 100  24  61  74   8  10  28  37  57  89  21  92   5  96  59   9  97  93 109  67 108  54  73  35  13  69  81  76  36  16  32  49  62  14  50  63  48  75  83  71  45   3  51  70   2  86  82   7  55  88  23  31  52  64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [70 21 52 15 25 47 10 55 73 28 33 11 26 32 66 62 23  9  5 31 72 46 63 56 13 39  4 36 43 41 57 29 19 58  7  8 65 48 35 34 51 61 44 54 37  6 77  0 40 74 22 49  2 76 45  3 64 68 16 20 53 27 50 60 30 59 67 71 69 75 38 18 24  1 17 12 14 42], a_shuffle_aclus: [ 96  28  70  21  34  64  14  74 100  37  50  15  35  49  89  84  32  13   8  48  98  63  85  75  17  56   7  53  60  58  76  41  26  78  10  11  88  66  52  51  69  83  61  73  54   9 109   2  57 102  31  67   4 108  62   5  86  92  23  27  71  36  68  82  45  81  90  97  93 107  55  25  33   3  24  16  19  59]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [77 33 34 56 12 70 18 46 35 32  7 59 19  9 17 16 11 31  5 76 14 75 51 71 52 63 58 38 44 55 62 64 74 40  6 15  8 39 37 73 54 41 26 30 49 53  0  3  1 57 47 20 13 65 21 36  2 60 10 67  4 61 29 43 50 27 66 25 68 23 48 22 28 72 42 69 45 24], a_shuffle_aclus: [109  50  51  75  16  96  25  63  52  49  10  81  26  13  24  23  15  48   8 108  19 107  69  97  70  85  78  55  61  74  84  86 102  57   9  21  11  56  54 100  73  58  35  45  67  71   2   5   3  76  64  27  17  88  28  53   4  82  14  90   7  83  41  60  68  36  89  34  92  32  66  31  37  98  59  93  62  33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [60 48 31 77 35 19 44 42  3 59 47  2 45 67 72 74 76  9 71  7 21 58 14 15  6 73 55 43 50 75 16 30 20 39 17  0 41 40  8 64 22 33 23 12 56 28 26 36 66 24 51  5 25 27 70 29 18 57 65 61 52 13 49 46 32  1  4 54 11 38 10 68 63 37 69 53 62 34], a_shuffle_aclus: [ 82  66  48 109  52  26  61  59   5  81  64   4  62  90  98 102 108  13  97  10  28  78  19  21   9 100  74  60  68 107  23  45  27  56  24   2  58  57  11  86  31  50  32  16  75  37  35  53  89  33  69   8  34  36  96  41  25  76  88  83  70  17  67  63  49   3   7  73  15  55  14  92  85  54  93  71  84  51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [49 53 17 51 41  5 39 33 20 36 71  2 48 68 34 63 55 64  9 73 47  3  8 27 40 61 60  6 76 72 37 16 15 22 10 18 59 35 57 32 11 50 69 45 30 62 31 56 23 28 46 38 44 12 14  1  0 13 24 19 67 26 42 58 25 75 70 65 29 77 74  4 52  7 54 43 21 66], a_shuffle_aclus: [ 67  71  24  69  58   8  56  50  27  53  97   4  66  92  51  85  74  86  13 100  64   5  11  36  57  83  82   9 108  98  54  23  21  31  14  25  81  52  76  49  15  68  93  62  45  84  48  75  32  37  63  55  61  16  19   3   2  17  33  26  90  35  59  78  34 107  96  88  41 109 102   7  70  10  73  60  28  89]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [74 56 23  1 68 60  0 16 12  9 70 30  3  8 45 14 52 17 50 51 11 48 40 36  7 63 34 77  5 33 35 24 62  4 32 71 75 29 41 10 49 20 66 13 59 31 65 25 53 55 18 27 47 64 43  6 38 69 76 28 61 15 42 37 39  2 73 46 21 54 57 72 67 58 44 19 22 26], a_shuffle_aclus: [102  75  32   3  92  82   2  23  16  13  96  45   5  11  62  19  70  24  68  69  15  66  57  53  10  85  51 109   8  50  52  33  84   7  49  97 107  41  58  14  67  27  89  17  81  48  88  34  71  74  25  36  64  86  60   9  55  93 108  37  83  21  59  54  56   4 100  63  28  73  76  98  90  78  61  26  31  35]\n",
      "a_shuffle_IDXs: [47 67 46 26 31 49 54  3 53  6 64 77 37 20  7  2 29 14  9 10 66 55  8  4 68 69 25 58 21 18 36 16 11 61 76 43 28 57 45 56 17 22 48 27 30 13 62 33 12 59 38 40 74 44 32  0 23 34 19 35 63 70 65 60 42 24 75  1  5 73 72 50 71 52 39 41 15 51], a_shuffle_aclus: [ 64  90  63  35  48  67  73   5  71   9  86 109  54  27  10   4  41  19  13  14  89  74  11   7  92  93  34  78  28  25  53  23  15  83 108  60  37  76  62  75  24  31  66  36  45  17  84  50  16  81  55  57 102  61  49   2  32  51  26  52  85  96  88  82  59  33 107   3   8 100  98  68  97  70  56  58  21  69]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [75 40  4 76 64 28 39 55 57 34 65 19 13 72 20 50  3  2 12 23 41 10 67 60 45 33  9  5 74 59 16 66 38 73 43 42 61 29 26 46 25 77 27 63  0  6 56 71 35 22  8 31 36 52 14  1 68 21 62 48 54 17 49  7 11 69 18 24 32 30 51 53 58 15 44 37 70 47], a_shuffle_aclus: [107  57   7 108  86  37  56  74  76  51  88  26  17  98  27  68   5   4  16  32  58  14  90  82  62  50  13   8 102  81  23  89  55 100  60  59  83  41  35  63  34 109  36  85   2   9  75  97  52  31  11  48  53  70  19   3  92  28  84  66  73  24  67  10  15  93  25  33  49  45  69  71  78  21  61  54  96  64]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [40 75 33 42 77 13 58 73 70 29 53 71 20 35 47 26 36  6 60 68 49  5 37 69 61 11  9 30 18  7 25 59 15  1 55  0  3 65 14 17 38 67 46 45 51 48 21 57 63 72 39 54 24 76 66 27  8 56 19 32  4 64 31 12 50 23 74 22 41 10 44 28  2 62 34 52 16 43], a_shuffle_aclus: [ 57 107  50  59 109  17  78 100  96  41  71  97  27  52  64  35  53   9  82  92  67   8  54  93  83  15  13  45  25  10  34  81  21   3  74   2   5  88  19  24  55  90  63  62  69  66  28  76  85  98  56  73  33 108  89  36  11  75  26  49   7  86  48  16  68  32 102  31  58  14  61  37   4  84  51  70  23  60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [42  2 70 54 62  3 21 60 59 25 76 53 66 48  9 37  7 28 19 15 52 64 57 67 46 22  4 32 12 39 68  5 16 77 29 55 61 38 74 49 73 30 71 34 10 75 50 35 51 47 33  8  6 13 72 45 41 27 56 43 36 40 24 65  1 20  0 11 17 31 26 14 18 63 44 23 58 69], a_shuffle_aclus: [ 59   4  96  73  84   5  28  82  81  34 108  71  89  66  13  54  10  37  26  21  70  86  76  90  63  31   7  49  16  56  92   8  23 109  41  74  83  55 102  67 100  45  97  51  14 107  68  52  69  64  50  11   9  17  98  62  58  36  75  60  53  57  33  88   3  27   2  15  24  48  35  19  25  85  61  32  78  93]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [31 59 61 18 65 23 27  0 41 22 32 73 47 24  3 40 77 51 49 67 63 56 54 68  5 71 52 70 20 76 74  2 58 55  8 69 19 42 15 10 25 14 34 66  7  9 35 28 33  6 62 21 44 29 50 64 46 45 17 38 48 30 53 13 43 57 11 26 72 37 75 12 36  4 60  1 16 39], a_shuffle_aclus: [ 48  81  83  25  88  32  36   2  58  31  49 100  64  33   5  57 109  69  67  90  85  75  73  92   8  97  70  96  27 108 102   4  78  74  11  93  26  59  21  14  34  19  51  89  10  13  52  37  50   9  84  28  61  41  68  86  63  62  24  55  66  45  71  17  60  76  15  35  98  54 107  16  53   7  82   3  23  56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [76  1 70 65 13 31 12 51 41 23 68 55 40 35  7  5 37 42 29 67 18 14 50 69  8 34  4 58 33 47 38 62 22 64 73  3 24 57 27 61 15 72 11 71  2 25 19 48 53 28 32 16 46 44 17 75 26 39  0  9 10 20 21 77 59 36 45 30 60 66  6 49 74 63 52 54 43 56], a_shuffle_aclus: [108   3  96  88  17  48  16  69  58  32  92  74  57  52  10   8  54  59  41  90  25  19  68  93  11  51   7  78  50  64  55  84  31  86 100   5  33  76  36  83  21  98  15  97   4  34  26  66  71  37  49  23  63  61  24 107  35  56   2  13  14  27  28 109  81  53  62  45  82  89   9  67 102  85  70  73  60  75]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [44 13 10 56 28 52 24 75  4 43 58  5  8 38 27 74 54 25 31 34 36 40 61 57 51 26 67 15 39 42 46  2 70 32 33 63 50 73 18 68 14  9 72 12  6 29 16 45 55 60 41 53  1 69  3 37 48  0 65 64 30 23 22 17 20 76 21 77  7 35 47 71 66 11 49 62 19 59], a_shuffle_aclus: [ 61  17  14  75  37  70  33 107   7  60  78   8  11  55  36 102  73  34  48  51  53  57  83  76  69  35  90  21  56  59  63   4  96  49  50  85  68 100  25  92  19  13  98  16   9  41  23  62  74  82  58  71   3  93   5  54  66   2  88  86  45  32  31  24  27 108  28 109  10  52  64  97  89  15  67  84  26  81]\n",
      "a_shuffle_IDXs: [58 61  3 28 20  5 74  4 43 27 11 31 59 49 64 53 67 77 14 13 21 37 40 69 26  6 48 70 51 44 56 65 46 52 18 63 73 71 75  7  8 41 33 72 16 47 38 17 34 35 30 66 60  9 36 29 50 24 68  1 54 55 23 42 76 22 57 32 45 39 12  2  0 25 10 19 15 62], a_shuffle_aclus: [ 78  83   5  37  27   8 102   7  60  36  15  48  81  67  86  71  90 109  19  17  28  54  57  93  35   9  66  96  69  61  75  88  63  70  25  85 100  97 107  10  11  58  50  98  23  64  55  24  51  52  45  89  82  13  53  41  68  33  92   3  73  74  32  59 108  31  76  49  62  56  16   4   2  34  14  26  21  84]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [15 31 25 37 36 32  5 62 28 73 24 54  3 75 21 29 20 40 44 33 64 45 56 69  9  8 41 63 67 49 55 48 26 12 22 35 16 34 19  7 68 27 77 59 51  0 42 50 18 39 52  4 66 10  6 70 30 58 38 71  1 61 72  2 53 76 13 46 11 17 47 60 57 23 74 14 43 65], a_shuffle_aclus: [ 21  48  34  54  53  49   8  84  37 100  33  73   5 107  28  41  27  57  61  50  86  62  75  93  13  11  58  85  90  67  74  66  35  16  31  52  23  51  26  10  92  36 109  81  69   2  59  68  25  56  70   7  89  14   9  96  45  78  55  97   3  83  98   4  71 108  17  63  15  24  64  82  76  32 102  19  60  88]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 2 41  9 61 26 52 30 40 60 46 45 17 64 62 19 57 33 31 27  8 32 55 53 24 13 70  5 28 43 76 23 75 12 37 71 35 22 48  1 73 16 50 10  0 49 11 67 77  6 63 59 66 21 36 20 68 56 51 65  3 29  4 54 14 18  7 15 44 72 42 47 74 39 34 38 58 69 25], a_shuffle_aclus: [  4  58  13  83  35  70  45  57  82  63  62  24  86  84  26  76  50  48  36  11  49  74  71  33  17  96   8  37  60 108  32 107  16  54  97  52  31  66   3 100  23  68  14   2  67  15  90 109   9  85  81  89  28  53  27  92  75  69  88   5  41   7  73  19  25  10  21  61  98  59  64 102  56  51  55  78  93  34]\n",
      "a_shuffle_IDXs: [68 66 45 70 18 50 44 57 38 75 16 46 47 77 33 23 58 64 42 55 14 21  4 34 52 62  8 56 32 26 11 43 27 24  3 35 59 10 30  5  0 12  1 76 51 36  2  7 17 28  9 37 67 49 22 65 25 63  6 15 72 19 31 39 53 48 60 71 13 41 74 29 69 54 20 73 40 61], a_shuffle_aclus: [ 92  89  62  96  25  68  61  76  55 107  23  63  64 109  50  32  78  86  59  74  19  28   7  51  70  84  11  75  49  35  15  60  36  33   5  52  81  14  45   8   2  16   3 108  69  53   4  10  24  37  13  54  90  67  31  88  34  85   9  21  98  26  48  56  71  66  82  97  17  58 102  41  93  73  27 100  57  83]\n",
      "a_shuffle_IDXs: [41 16 28 61 52 47 20 57 48 27  3 55 23 43 32 70 40 24 72  5 34 66 14 42 75 68 31  4 22  2 19 69 10 62 77 15 35 60 54 25 39 21  8 33 46 64 18 59 53 76 49  1 11 51 67 74 38  6 73 45 63 71 13  9  0 56 26 58 30 44 29 36 17 50 37 65 12  7], a_shuffle_aclus: [ 58  23  37  83  70  64  27  76  66  36   5  74  32  60  49  96  57  33  98   8  51  89  19  59 107  92  48   7  31   4  26  93  14  84 109  21  52  82  73  34  56  28  11  50  63  86  25  81  71 108  67   3  15  69  90 102  55   9 100  62  85  97  17  13   2  75  35  78  45  61  41  53  24  68  54  88  16  10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [40  0 26 34  4 36 58 67 62 76  9  1 15 33 18 17 10 51 24 21 70 35 44 11 29  6 20 60 47 74 50 46  5 14 32 73 52 53 61 54 48 13 71 56 41 22 42  2 38 19 25 72 37 49 66 55 68  8 65 59 45 63 28 27 75 64  3  7 30 57 39 43 23 77 69 16 12 31], a_shuffle_aclus: [ 57   2  35  51   7  53  78  90  84 108  13   3  21  50  25  24  14  69  33  28  96  52  61  15  41   9  27  82  64 102  68  63   8  19  49 100  70  71  83  73  66  17  97  75  58  31  59   4  55  26  34  98  54  67  89  74  92  11  88  81  62  85  37  36 107  86   5  10  45  76  56  60  32 109  93  23  16  48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [25 33 74 43 71  4 60 67  1 61 18  5 23 75 44 40 55 45  6 57 69 30 76 39 54 70 49 46 13 36 16 12 24 26 42  7 64 66 50 59 53 68 37 58 38 41 32 65 48 14 51 10 19 73 27 11  0 62 77 29 35 15 17  8 31 34  9 20 47 63 72  3 22 21  2 28 56 52], a_shuffle_aclus: [ 34  50 102  60  97   7  82  90   3  83  25   8  32 107  61  57  74  62   9  76  93  45 108  56  73  96  67  63  17  53  23  16  33  35  59  10  86  89  68  81  71  92  54  78  55  58  49  88  66  19  69  14  26 100  36  15   2  84 109  41  52  21  24  11  48  51  13  27  64  85  98   5  31  28   4  37  75  70]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [55 71 33  6 47 60  3 59 36 15  5  9  8 54  0 68 52 31 34 16 48 57 75 41 25 19 21 10 64 29 51 44 35 26 58 20 65 73 30 50 18 46 67 24 69 39 76 27 13 56 62  1 17  7 37 77 38 32 53 42 70 72 61 45  2 74 66 43  4 14 40 63 12 22 49 28 23 11], a_shuffle_aclus: [ 74  97  50   9  64  82   5  81  53  21   8  13  11  73   2  92  70  48  51  23  66  76 107  58  34  26  28  14  86  41  69  61  52  35  78  27  88 100  45  68  25  63  90  33  93  56 108  36  17  75  84   3  24  10  54 109  55  49  71  59  96  98  83  62   4 102  89  60   7  19  57  85  16  31  67  37  32  15]\n",
      "a_shuffle_IDXs: [69 16 27 40 48 59 17 14 44 63  1 31 10 64  4 76 22 13 26 66 61 74 24 34 12 58 37 49 72 62 33 20 45 67 36  7 18 47 65 39 52 71 42  8  0 73 35 29 51  2 25 57 11 56 41 60 28 15  5 77 19  6 55 50 38 54 30  3 70 68  9 75 43 23 32 53 21 46], a_shuffle_aclus: [ 93  23  36  57  66  81  24  19  61  85   3  48  14  86   7 108  31  17  35  89  83 102  33  51  16  78  54  67  98  84  50  27  62  90  53  10  25  64  88  56  70  97  59  11   2 100  52  41  69   4  34  76  15  75  58  82  37  21   8 109  26   9  74  68  55  73  45   5  96  92  13 107  60  32  49  71  28  63]\n",
      "a_shuffle_IDXs: [21 51 14 20 76 75 49 46 56 22 10 25 34 64 18 16 48 47 42 33 53 39 31 69 30 62 28 66 15 58 24 65  2  9 23 35  8 11 60 36 61  1  6 17 68 41 26 19  5 54 38 72 27 55 71 43 32 52 37 29 73 59  3 13  0 70 74 45  7 44 77 12 67 40  4 50 57 63], a_shuffle_aclus: [ 28  69  19  27 108 107  67  63  75  31  14  34  51  86  25  23  66  64  59  50  71  56  48  93  45  84  37  89  21  78  33  88   4  13  32  52  11  15  82  53  83   3   9  24  92  58  35  26   8  73  55  98  36  74  97  60  49  70  54  41 100  81   5  17   2  96 102  62  10  61 109  16  90  57   7  68  76  85]\n",
      "a_shuffle_IDXs: [34 22 72 60 47 24 57 28 21 27 68 70 74 32  9 44 20 30 29 23 18  2 53 76 41 38 61 19 77  6 50 56 39 66 63 43 11 40  3  1 13 33 58 15 46 49 73 36 59 25  4 12  5 64 17 69 35 31 67 62 26 52 48 16  0 10 51 42  7 54 71 45 65 75 55 37  8 14], a_shuffle_aclus: [ 51  31  98  82  64  33  76  37  28  36  92  96 102  49  13  61  27  45  41  32  25   4  71 108  58  55  83  26 109   9  68  75  56  89  85  60  15  57   5   3  17  50  78  21  63  67 100  53  81  34   7  16   8  86  24  93  52  48  90  84  35  70  66  23   2  14  69  59  10  73  97  62  88 107  74  54  11  19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [25  0 45 13 64 23 76  5 51 77 58 41  6 11 26  8 69 53  1 54 14 28 31 65 39 20 35 52 75  3  7 32 66 40 48 12 57 74  4 49 59 61 71 44 22 38 63 56 42 46 24 43 36 27 15 21 47 50 37  9 62 73 67 29 34 18 30  2 70 17 72 16 55 10 19 68 33 60], a_shuffle_aclus: [ 34   2  62  17  86  32 108   8  69 109  78  58   9  15  35  11  93  71   3  73  19  37  48  88  56  27  52  70 107   5  10  49  89  57  66  16  76 102   7  67  81  83  97  61  31  55  85  75  59  63  33  60  53  36  21  28  64  68  54  13  84 100  90  41  51  25  45   4  96  24  98  23  74  14  26  92  50  82]\n",
      "a_shuffle_IDXs: [13 64 50 15 49 54 31 14 45 61 73 57 74 63 68 55 30 75 17 23 29  3 41 25 40 77 76 37 51 19 69 11  5 46 38  2 72 71 47 52  1 60 26 16  9 39 67 12 56 32 36  8 62 48  6 22 42 44 20 18 24  0 27 34 28  4 33 35  7 70 66 53 65 43 58 21 10 59], a_shuffle_aclus: [ 17  86  68  21  67  73  48  19  62  83 100  76 102  85  92  74  45 107  24  32  41   5  58  34  57 109 108  54  69  26  93  15   8  63  55   4  98  97  64  70   3  82  35  23  13  56  90  16  75  49  53  11  84  66   9  31  59  61  27  25  33   2  36  51  37   7  50  52  10  96  89  71  88  60  78  28  14  81]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [25  3 50  8 27 15 77 17 60 20 22  5 68 37 64 18 46  9 63 62 74 66 41 57 33 30 53 29 35  6 73 12 45 69 67 58 55 52 19 54  0 48 39 38 32 42 16 23 34 10 21 71 43 51 72 13 11 59  4 24 44 14 26 47 28 36  7 61  1 49 56 31  2 40 70 76 65 75], a_shuffle_aclus: [ 34   5  68  11  36  21 109  24  82  27  31   8  92  54  86  25  63  13  85  84 102  89  58  76  50  45  71  41  52   9 100  16  62  93  90  78  74  70  26  73   2  66  56  55  49  59  23  32  51  14  28  97  60  69  98  17  15  81   7  33  61  19  35  64  37  53  10  83   3  67  75  48   4  57  96 108  88 107]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [65 55 32 68 29 50  4 37 39 70 33 53 26  3 42 30 16 27 44 74 54 12 61 64 60 52  2 51 56 41 59 25 22 72 48  8 57 76 13 58 49 19 18 17 15 40  7  0 66 46 71 63 20 62 73 77  6 10 75 31 11 23 43 14 34  5 36 67  9 28  1 47 38 24 69 35 21 45], a_shuffle_aclus: [ 88  74  49  92  41  68   7  54  56  96  50  71  35   5  59  45  23  36  61 102  73  16  83  86  82  70   4  69  75  58  81  34  31  98  66  11  76 108  17  78  67  26  25  24  21  57  10   2  89  63  97  85  27  84 100 109   9  14 107  48  15  32  60  19  51   8  53  90  13  37   3  64  55  33  93  52  28  62]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [30 56 31 66 19 43 69 49 14 34  2 32  0 29 60 74  6 72 17 38 64 18 52 20 41  5 27 33 47 45 76 37 70 12 63 50 54 10 58  7 59 71 15  3 48 61 16 75 23 13 68  9 21 46 11 67 42 35 26 22  8  4 65 62 28 24 44 57  1 25 39 55 36 40 77 51 73 53], a_shuffle_aclus: [ 45  75  48  89  26  60  93  67  19  51   4  49   2  41  82 102   9  98  24  55  86  25  70  27  58   8  36  50  64  62 108  54  96  16  85  68  73  14  78  10  81  97  21   5  66  83  23 107  32  17  92  13  28  63  15  90  59  52  35  31  11   7  88  84  37  33  61  76   3  34  56  74  53  57 109  69 100  71]\n",
      "a_shuffle_IDXs: [45 23 29 67 39 26  5 60 40 24 77 68 30 13 11 25 22 57 72 27 48 31 33  6 65 58 54 55 14 20 69 74  9 62 53 10 17 75  2  8 73  7 34 63 59 16 47 51 49 38 35 71 76 43 64  0 36 66 46 18  3 21 37 44 61  1 15 50 52 19 12 70 56  4 42 32 28 41], a_shuffle_aclus: [ 62  32  41  90  56  35   8  82  57  33 109  92  45  17  15  34  31  76  98  36  66  48  50   9  88  78  73  74  19  27  93 102  13  84  71  14  24 107   4  11 100  10  51  85  81  23  64  69  67  55  52  97 108  60  86   2  53  89  63  25   5  28  54  61  83   3  21  68  70  26  16  96  75   7  59  49  37  58]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [57 20 75 72 59 21 49  7 44 74 24 71 26 51  3 38 66  9  6  1 29 27 56 69 32 19 17 43 55 16 54 60 15 64 41 11 65 67  8 63 30 70 42 13 36  5  0 22 31  4 25 62 28 77 53 61 68 46 47 52 33 12 18 40 23  2 45 48 73 58 10 35 34 37 76 39 50 14], a_shuffle_aclus: [ 76  27 107  98  81  28  67  10  61 102  33  97  35  69   5  55  89  13   9   3  41  36  75  93  49  26  24  60  74  23  73  82  21  86  58  15  88  90  11  85  45  96  59  17  53   8   2  31  48   7  34  84  37 109  71  83  92  63  64  70  50  16  25  57  32   4  62  66 100  78  14  52  51  54 108  56  68  19]\n",
      "a_shuffle_IDXs: [59 25 71 52 23  1 32 64  0 40 27 48 35 18 63 38 28 22 10 42 45  6 29 34 11  3 58 65 13 12 77 54 49 53 55 68 36 61 44 51 43 75 20  4 15 76 37 67  5 56 46 41 39 74  2 72 60 19 14 31 33 24  9 62  7 26 57 47 17 16 50 21 30 66 70 73  8 69], a_shuffle_aclus: [ 81  34  97  70  32   3  49  86   2  57  36  66  52  25  85  55  37  31  14  59  62   9  41  51  15   5  78  88  17  16 109  73  67  71  74  92  53  83  61  69  60 107  27   7  21 108  54  90   8  75  63  58  56 102   4  98  82  26  19  48  50  33  13  84  10  35  76  64  24  23  68  28  45  89  96 100  11  93]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [48 27 18 22 11 76 40 56  8 69 54 46  4 47  7 61  1 41 52 43 36 67 13 58 25 65 38 33 12 30 29 62 26 55 34  9 35 60 42 53 77 50 23 66 74 75 51  3 32 72 49 44 15 17 57 21  2 31 64 59 39  5  0 14 68 28 20 16  6 70 71 37 19 45 10 73 63 24], a_shuffle_aclus: [ 66  36  25  31  15 108  57  75  11  93  73  63   7  64  10  83   3  58  70  60  53  90  17  78  34  88  55  50  16  45  41  84  35  74  51  13  52  82  59  71 109  68  32  89 102 107  69   5  49  98  67  61  21  24  76  28   4  48  86  81  56   8   2  19  92  37  27  23   9  96  97  54  26  62  14 100  85  33]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [47 26  8 10 46 77 69 59 21 62 19 33 16 39 20 63 22 23 61 29 17 60 28 70  4 54 76  6 24 27  3  9 55 51 32 65 38 50 75 25 14 45 53 15 72 57 49 56 43 18  0  2 30  1 12 58 68  7 11 36 67 66 64 74 71 35 52 48 31 13 40 41 44  5 37 42 34 73], a_shuffle_aclus: [ 64  35  11  14  63 109  93  81  28  84  26  50  23  56  27  85  31  32  83  41  24  82  37  96   7  73 108   9  33  36   5  13  74  69  49  88  55  68 107  34  19  62  71  21  98  76  67  75  60  25   2   4  45   3  16  78  92  10  15  53  90  89  86 102  97  52  70  66  48  17  57  58  61   8  54  59  51 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [59 56 23 43 32 51 44 26 62 19 16  8 15 29 12 73 64 52  0 11 35  4 13 45 75 40  7 70  6 63 34 22 61  9 68 57 27 33 17  2 10 21 38 77 74 55 48 65 66 58 50 30 24  1 31 53 37 69 41 36 20 67 39 18 28 72 54 49 47  5 25 76 46  3 71 42 60 14], a_shuffle_aclus: [ 81  75  32  60  49  69  61  35  84  26  23  11  21  41  16 100  86  70   2  15  52   7  17  62 107  57  10  96   9  85  51  31  83  13  92  76  36  50  24   4  14  28  55 109 102  74  66  88  89  78  68  45  33   3  48  71  54  93  58  53  27  90  56  25  37  98  73  67  64   8  34 108  63   5  97  59  82  19]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [25  2 37 68 38 29 47 12 19  0 57 71 11 22 61 72 67 59 21 27 62 56 60 66 14 51 23 40 13 42 32 18 55 73 45 34 63 49 16 43 53  1 31 76 65 64 26 36 15 17  9 50 46 54 58 33  7 70 30 74 48 35 24 10 41 69 75 77  4 44  8  5 39 20 28  3  6 52], a_shuffle_aclus: [ 34   4  54  92  55  41  64  16  26   2  76  97  15  31  83  98  90  81  28  36  84  75  82  89  19  69  32  57  17  59  49  25  74 100  62  51  85  67  23  60  71   3  48 108  88  86  35  53  21  24  13  68  63  73  78  50  10  96  45 102  66  52  33  14  58  93 107 109   7  61  11   8  56  27  37   5   9  70]\n",
      "a_shuffle_IDXs: [61 57 12 11 25 52 27 65 56 18  9 42 62 58  6 75 63  4 68 20 43 77 41 76 40 36 53 28 15 73 44  5 49  2 35 21 29 19 50 22 60 45 67 23 74 59 70 13 64  7  8 72  1  0 46 17 33 37 32  3 31 10 71 38 51 24 30 26 54 16 66 14 48 47 34 69 55 39], a_shuffle_aclus: [ 83  76  16  15  34  70  36  88  75  25  13  59  84  78   9 107  85   7  92  27  60 109  58 108  57  53  71  37  21 100  61   8  67   4  52  28  41  26  68  31  82  62  90  32 102  81  96  17  86  10  11  98   3   2  63  24  50  54  49   5  48  14  97  55  69  33  45  35  73  23  89  19  66  64  51  93  74  56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [74 67 17 33 47 16 12 19 40 75 43 29 14 50 58 10  0 57 21 34 54 25 76 23 73 53  7 39 46 44 49 20 55 41 72 22 61 30  1 69 27 37  6 66 24 35 70 28  8 26 56 42 60 71 36 51 65 38 48 31 63 11  9 59 68 18  3 13 64  4  2 45 15 77 62  5 32 52], a_shuffle_aclus: [102  90  24  50  64  23  16  26  57 107  60  41  19  68  78  14   2  76  28  51  73  34 108  32 100  71  10  56  63  61  67  27  74  58  98  31  83  45   3  93  36  54   9  89  33  52  96  37  11  35  75  59  82  97  53  69  88  55  66  48  85  15  13  81  92  25   5  17  86   7   4  62  21 109  84   8  49  70]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [63 75 27 50 62 26  0 70 30 38  3 60 58  5 74 10 45 48 20 19 55 69 67  4 41 52 16 43 77 73  6 39 14 35 12 76 34 47 64 21 13 36 42 71  8 40 25 15 23 56 17 31 65 44 37 11 32 18 22 59  2 24 66 61 53  1 46  9 33 54 51 28 29  7 57 72 68 49], a_shuffle_aclus: [ 85 107  36  68  84  35   2  96  45  55   5  82  78   8 102  14  62  66  27  26  74  93  90   7  58  70  23  60 109 100   9  56  19  52  16 108  51  64  86  28  17  53  59  97  11  57  34  21  32  75  24  48  88  61  54  15  49  25  31  81   4  33  89  83  71   3  63  13  50  73  69  37  41  10  76  98  92  67]\n",
      "a_shuffle_IDXs: [73 15 58 57 14 67 51 12 72 65 48 40  0 74 66 52  1 25 18  2 55 23 62 35 36 38  5 69 33 68 46 10 49 44 28 26 60 39 76  8  6 43 75 61 59 34 42 11 70 41 56 71 22 77 53 13 24  9  4 54 47 32 45 29 64 63 21 27  3 37 20 50 19 30 17 16  7 31], a_shuffle_aclus: [100  21  78  76  19  90  69  16  98  88  66  57   2 102  89  70   3  34  25   4  74  32  84  52  53  55   8  93  50  92  63  14  67  61  37  35  82  56 108  11   9  60 107  83  81  51  59  15  96  58  75  97  31 109  71  17  33  13   7  73  64  49  62  41  86  85  28  36   5  54  27  68  26  45  24  23  10  48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 3 16 23  6 52 48 15 72 25 62 76 65 74 43 32 42 54 45 20 44 68 59 66 10 13 36 61 58 12 18 64 67 63 38  8 14 55  7 28 39 75 40 26  0 56  4 47  5 33 19  9 35 27 17 60 29 73 50 71 30  1 22 24 57 77 46 51 49 21 53  2 37 70 11 31 41 69 34], a_shuffle_aclus: [  5  23  32   9  70  66  21  98  34  84 108  88 102  60  49  59  73  62  27  61  92  81  89  14  17  53  83  78  16  25  86  90  85  55  11  19  74  10  37  56 107  57  35   2  75   7  64   8  50  26  13  52  36  24  82  41 100  68  97  45   3  31  33  76 109  63  69  67  28  71   4  54  96  15  48  58  93  51]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [67 69 66 28 13  4 18 70 26 63 17 60  5 52 75 45 30 10 57 31 42 21 14 11 27  0  7 20 37 77 51 71 58 72 36 49 53 61 46 47 34  9 39 29 76 38 24 74  2 22  8 56 50 59 64 23  6 33 15  3 68  1 65 48 43 40 44 19 35 16 73 41 25 62 32 55 54 12], a_shuffle_aclus: [ 90  93  89  37  17   7  25  96  35  85  24  82   8  70 107  62  45  14  76  48  59  28  19  15  36   2  10  27  54 109  69  97  78  98  53  67  71  83  63  64  51  13  56  41 108  55  33 102   4  31  11  75  68  81  86  32   9  50  21   5  92   3  88  66  60  57  61  26  52  23 100  58  34  84  49  74  73  16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [20 27  4 59 71 55 14 43  6 52 50 73  7  8 10 17 26 49 31 40 33 53 22 56 42 39 75 12 57 68 29 47 76  5 77 11 30 72 23 41 45 24 64 46 61 60  2 28 62 38 34 74 37 67 13 15 21 58  1 54 35  9 32  0 63 69 16 36 70 18 51 66 48 25  3 65 44 19], a_shuffle_aclus: [ 27  36   7  81  97  74  19  60   9  70  68 100  10  11  14  24  35  67  48  57  50  71  31  75  59  56 107  16  76  92  41  64 108   8 109  15  45  98  32  58  62  33  86  63  83  82   4  37  84  55  51 102  54  90  17  21  28  78   3  73  52  13  49   2  85  93  23  53  96  25  69  89  66  34   5  88  61  26]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [16 45 67 68 60 36 66 48 23 30 25 77 54  1  8 11 75 61 65 33 13 15 64 42 47 26  7 57 44 51  6 73 27 50 43 31 74 72 62 28  3 14 40 71 18 59 70 69 49  0 39 34 53 56 41 35 38 63  4 10  2 46 24 12 52 29 37 76 55 22 58 17 19 20 32 21  9  5], a_shuffle_aclus: [ 23  62  90  92  82  53  89  66  32  45  34 109  73   3  11  15 107  83  88  50  17  21  86  59  64  35  10  76  61  69   9 100  36  68  60  48 102  98  84  37   5  19  57  97  25  81  96  93  67   2  56  51  71  75  58  52  55  85   7  14   4  63  33  16  70  41  54 108  74  31  78  24  26  27  49  28  13   8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [53  7  8 45 18 65  6 44 62 16 71 68 41 33 12 66 75  1 64 10 19 72 60 35 31  2 69  0 49 39 50 14 11 37 25 13 54 56 30 26 59 46 48 61  4 23 73 28 38 24 29 20 34 42 76 77 40 17 70 51  9 32 52 58 15 74 63 55 67 36 57  5 47 21 22 27  3 43], a_shuffle_aclus: [ 71  10  11  62  25  88   9  61  84  23  97  92  58  50  16  89 107   3  86  14  26  98  82  52  48   4  93   2  67  56  68  19  15  54  34  17  73  75  45  35  81  63  66  83   7  32 100  37  55  33  41  27  51  59 108 109  57  24  96  69  13  49  70  78  21 102  85  74  90  53  76   8  64  28  31  36   5  60]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [38 60 27 26 50 45 55 65  9 47 11 14 19 52 56 58 48 15 36 32 49 73 72 71 20 42 74  6 21 13  5 30 40 39  0 57 51 41  4 54 31 76 59 61 33 68 62 44 63 66 25 23 17 29 10 64  8 53 22 70  2 16 34 12 67 35 75  3  1 69 24 28 18 37 77 43  7 46], a_shuffle_aclus: [ 55  82  36  35  68  62  74  88  13  64  15  19  26  70  75  78  66  21  53  49  67 100  98  97  27  59 102   9  28  17   8  45  57  56   2  76  69  58   7  73  48 108  81  83  50  92  84  61  85  89  34  32  24  41  14  86  11  71  31  96   4  23  51  16  90  52 107   5   3  93  33  37  25  54 109  60  10  63]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [57  9 69 30 43 24 53 73 13 42 72 61  2 19 12 29 58 63 25 47 54  1 64  7 49 45 52 65 22 75 51 14 37 62 74 23 21  4 77 15 44 16 34 55 50 38 66 70 56 40 18  5 46 36 10 17 71 32 39 60 35  8  0  6 59  3 68 26 11 48 41 76 28 67 27 20 31 33], a_shuffle_aclus: [ 76  13  93  45  60  33  71 100  17  59  98  83   4  26  16  41  78  85  34  64  73   3  86  10  67  62  70  88  31 107  69  19  54  84 102  32  28   7 109  21  61  23  51  74  68  55  89  96  75  57  25   8  63  53  14  24  97  49  56  82  52  11   2   9  81   5  92  35  15  66  58 108  37  90  36  27  48  50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [32 53 69 24 25 70 57 37  1 62  8  3 16 15 51 30  7 54 58 14 17 60 23 68 41 20 55 67 18 34 29 40 61 64 44  0 45 74 11 35 65  2  9  5 48 36 56 13 26 52 50 28 63 73 19 43 46 75 33 66 27  6 59 71 42 31 10 47 21 49 39  4 38 12 76 77 72 22], a_shuffle_aclus: [ 49  71  93  33  34  96  76  54   3  84  11   5  23  21  69  45  10  73  78  19  24  82  32  92  58  27  74  90  25  51  41  57  83  86  61   2  62 102  15  52  88   4  13   8  66  53  75  17  35  70  68  37  85 100  26  60  63 107  50  89  36   9  81  97  59  48  14  64  28  67  56   7  55  16 108 109  98  31]\n",
      "a_shuffle_IDXs: [70  1 26 49 67 43 75  3 41 14 21 33 50  5 28 19 25 18 13 62 30 71 74  0 73  9 64 34 10 22 66 47 40  8 17 68  2 57 48 31 54 63 27 77 36 44 38 23 32 58 52 53 61 45 51 12 24 59 16 72 20 76 56 55 65 35 15  6 39 42 46 11  7 29 69 60 37  4], a_shuffle_aclus: [ 96   3  35  67  90  60 107   5  58  19  28  50  68   8  37  26  34  25  17  84  45  97 102   2 100  13  86  51  14  31  89  64  57  11  24  92   4  76  66  48  73  85  36 109  53  61  55  32  49  78  70  71  83  62  69  16  33  81  23  98  27 108  75  74  88  52  21   9  56  59  63  15  10  41  93  82  54   7]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [69 46 48 71 18 42 70 66 63 14 62 77 22 74 59  5 75 27  9 72 32 10 52 45 35 39 43 50 56  0 55 57 17 20 24 65 31 30  7  1 21 64 73  6 29 36 68 53 23 67 15 40  8  3 25 13 58 28 76 19 60 33 34 49 61 26 44 47 37  2 51 12 11 16 54  4 41 38], a_shuffle_aclus: [ 93  63  66  97  25  59  96  89  85  19  84 109  31 102  81   8 107  36  13  98  49  14  70  62  52  56  60  68  75   2  74  76  24  27  33  88  48  45  10   3  28  86 100   9  41  53  92  71  32  90  21  57  11   5  34  17  78  37 108  26  82  50  51  67  83  35  61  64  54   4  69  16  15  23  73   7  58  55]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [ 6 28 60 27 55 63 76 21 59  7 52 66 41 26 17 61 62 13  3 48 42 12 44 16 34 57 53 75 67 30  4 65 24 70 14 64 10 58  5 37 71 45 15 19 74 35 51 31 54 36 18  1 33  9 32  8 38 77 20 47 11 25  0 43 39 69 22 29 23 73 40 56 46  2 68 49 50 72], a_shuffle_aclus: [  9  37  82  36  74  85 108  28  81  10  70  89  58  35  24  83  84  17   5  66  59  16  61  23  51  76  71 107  90  45   7  88  33  96  19  86  14  78   8  54  97  62  21  26 102  52  69  48  73  53  25   3  50  13  49  11  55 109  27  64  15  34   2  60  56  93  31  41  32 100  57  75  63   4  92  67  68  98]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [61 76 46 57 60 48 32 64  3 58 72  6 53 28 27 33  9  0 29 36 14  5 52 23 62 70 40 51 15 25 39 26 56 63 18 75 73 65  7 49  8 35 55 50 71  1 34 38 16 45  2 30 69 22 47 67 42 74 12 37 54 31 66 13 68 44 77 19 43 10 17 11 24 59 21 20  4 41], a_shuffle_aclus: [ 83 108  63  76  82  66  49  86   5  78  98   9  71  37  36  50  13   2  41  53  19   8  70  32  84  96  57  69  21  34  56  35  75  85  25 107 100  88  10  67  11  52  74  68  97   3  51  55  23  62   4  45  93  31  64  90  59 102  16  54  73  48  89  17  92  61 109  26  60  14  24  15  33  81  28  27   7  58]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [56 12 52  5 77 38 53 57 67 74 48 45 28 46 64 49 71 69 27 14 19 35 17 24  0  9 72 41 30 59 55 43 40 70 23  3  4 25 42 21 51 34  1 10 65 62 66 58  6  2 18 50  7 36 54 16  8 15 32 22 11 20 31 73 68 33 29 37 13 26 44 61 47 76 75 60 63 39], a_shuffle_aclus: [ 75  16  70   8 109  55  71  76  90 102  66  62  37  63  86  67  97  93  36  19  26  52  24  33   2  13  98  58  45  81  74  60  57  96  32   5   7  34  59  28  69  51   3  14  88  84  89  78   9   4  25  68  10  53  73  23  11  21  49  31  15  27  48 100  92  50  41  54  17  35  61  83  64 108 107  82  85  56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [64 15 21 71 53 32 31  0 12 13  7 75  6 40 73 66 62 30  8  5 58 70 47 25 45 63  3  1 27 68 49 56 29 20 22 10 44 65 35 24  4  9 61 16 69 77 26 33 60 14 18 42 41 36 39 59 51 46 57 50 37 43 19 11 38 76 55 52 23 72 34  2 17 48 74 67 54 28], a_shuffle_aclus: [ 86  21  28  97  71  49  48   2  16  17  10 107   9  57 100  89  84  45  11   8  78  96  64  34  62  85   5   3  36  92  67  75  41  27  31  14  61  88  52  33   7  13  83  23  93 109  35  50  82  19  25  59  58  53  56  81  69  63  76  68  54  60  26  15  55 108  74  70  32  98  51   4  24  66 102  90  73  37]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [41 32 77 64 71  3 48 53 50 59 43 22 55  0 63 24  5 19 46 68 26  7 20 27 15 18 16 72 31  1  6 58 40 25 57 49 33 21 30 52 28 13 61 34 75 67 54 45  4  9 73 56 10 65 62 47 29 60 11 12 76 36 51  8 35 39 70 66 14 74  2 23 44 37 38 69 17 42], a_shuffle_aclus: [ 58  49 109  86  97   5  66  71  68  81  60  31  74   2  85  33   8  26  63  92  35  10  27  36  21  25  23  98  48   3   9  78  57  34  76  67  50  28  45  70  37  17  83  51 107  90  73  62   7  13 100  75  14  88  84  64  41  82  15  16 108  53  69  11  52  56  96  89  19 102   4  32  61  54  55  93  24  59]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [59  5 66 13 73 23 51 17 22 61 70  4 46 41 56 58 44 37  8 31 19 36 34 10 26  6 42 53  2  1 24 12 32 15  7 45 50 74 65 71 30 27 77 38 25 57 64 14 55 62  3 72 67 52 75  0 40 28 18 11 43 35 33 21 76 69 47 60 68 49  9 48 20 29 63 16 54 39], a_shuffle_aclus: [ 81   8  89  17 100  32  69  24  31  83  96   7  63  58  75  78  61  54  11  48  26  53  51  14  35   9  59  71   4   3  33  16  49  21  10  62  68 102  88  97  45  36 109  55  34  76  86  19  74  84   5  98  90  70 107   2  57  37  25  15  60  52  50  28 108  93  64  82  92  67  13  66  27  41  85  23  73  56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [32 42 37 15 51 54 69 16 20 10 52  9 11 31 55 67 71 45 63 74 60 33 49 58 24 73  2 12  6 66  1 19 22 72  4 43 64 29 13 44 68 21 38 39 77 46  8 50 25 76 27 48 14 53 56 59 26 23 65 28 57 70 40  0 41 75  3 47 61 30 35 17 62 34  7 18 36  5], a_shuffle_aclus: [ 49  59  54  21  69  73  93  23  27  14  70  13  15  48  74  90  97  62  85 102  82  50  67  78  33 100   4  16   9  89   3  26  31  98   7  60  86  41  17  61  92  28  55  56 109  63  11  68  34 108  36  66  19  71  75  81  35  32  88  37  76  96  57   2  58 107   5  64  83  45  52  24  84  51  10  25  53   8]\n",
      "a_shuffle_IDXs: [20 40 30 13 58 54 41  4 72 60 19 48 63 57 46  9 32 66 70 22 26 33 42 21 27 44 51 65 73 45 56 15  5  8 12  2 67 24 14 38 28 10 29 76 49 74  3 47 75 77 61  6 55 23 34 43 50 11 64 68 59 39 69 36 35 37 18 16  7 62  0 53  1 71 17 25 52 31], a_shuffle_aclus: [ 27  57  45  17  78  73  58   7  98  82  26  66  85  76  63  13  49  89  96  31  35  50  59  28  36  61  69  88 100  62  75  21   8  11  16   4  90  33  19  55  37  14  41 108  67 102   5  64 107 109  83   9  74  32  51  60  68  15  86  92  81  56  93  53  52  54  25  23  10  84   2  71   3  97  24  34  70  48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [51 19 63 15 28 75 77 69 29 17 74 76 52 40 65  6 62 41  0 31 48 26 16  4 70  9 56 59  7 32 36 22  8 50 14 25 27 46 66  3 67 54 49 61 64  2 35 12 44 30 53 71 23 37 18 39 20 58 55 47 13 33 11 21 24 72 73  5 43 42 57 38 60 10 34 68  1 45], a_shuffle_aclus: [ 69  26  85  21  37 107 109  93  41  24 102 108  70  57  88   9  84  58   2  48  66  35  23   7  96  13  75  81  10  49  53  31  11  68  19  34  36  63  89   5  90  73  67  83  86   4  52  16  61  45  71  97  32  54  25  56  27  78  74  64  17  50  15  28  33  98 100   8  60  59  76  55  82  14  51  92   3  62]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [54 63 29 36 14 70 40  0 68 25 61 67 18 44 64 24 73 72  7 43 33 50 20 42 62  5 45 34 47 11 60 35  6 69 55  4 51 23 59 38 46 37 26 71 19 21 39 49 31 66 74  2  8 65 16 32 28 15 48 30  3 53 27 75 41 77 57 10 52 76 56 17  1 13 12  9 58 22], a_shuffle_aclus: [ 73  85  41  53  19  96  57   2  92  34  83  90  25  61  86  33 100  98  10  60  50  68  27  59  84   8  62  51  64  15  82  52   9  93  74   7  69  32  81  55  63  54  35  97  26  28  56  67  48  89 102   4  11  88  23  49  37  21  66  45   5  71  36 107  58 109  76  14  70 108  75  24   3  17  16  13  78  31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [36 35 71  5 46 64  6 56 62 22 32 69 60 13 12 75 49 21  7 65 28 31 41 53  2 77 34 11 66 14  9 23 63  0 24 47 55 45 38 18 40 16 29 57 19 76 52 72 26 48 59 54 20 70 17  1 68 27 42 33  4 15 58 30 50  3 44 67 25 37 10 74 51 73 43  8 61 39], a_shuffle_aclus: [ 53  52  97   8  63  86   9  75  84  31  49  93  82  17  16 107  67  28  10  88  37  48  58  71   4 109  51  15  89  19  13  32  85   2  33  64  74  62  55  25  57  23  41  76  26 108  70  98  35  66  81  73  27  96  24   3  92  36  59  50   7  21  78  45  68   5  61  90  34  54  14 102  69 100  60  11  83  56]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [33  9 40  2  4 32  1 64 18  6 45  5 71 23 73 62 66 29 43 59 25 52 46 21  0 12 39 63 34 20  3 44 17 10 28 70 68 50 26 75 74 47 38 54 72 37 35 60 31 27 76 13 67 53 58 30  7 36 55 48 56 49 65 11 15 24 14 16 42 19 57 77 41 69 22  8 51 61], a_shuffle_aclus: [ 50  13  57   4   7  49   3  86  25   9  62   8  97  32 100  84  89  41  60  81  34  70  63  28   2  16  56  85  51  27   5  61  24  14  37  96  92  68  35 107 102  64  55  73  98  54  52  82  48  36 108  17  90  71  78  45  10  53  74  66  75  67  88  15  21  33  19  23  59  26  76 109  58  93  31  11  69  83]\n",
      "a_shuffle_IDXs: [23 18 62  3 27 29 69 40 74 56 64 53 41 24  6  7 39 15 32  0 19 35 54  4 43  1 72 11 21 48 68 42  5 67 37 44 34 77 10 12  2 70 36 60 66 55 25 17 71 61 33 28 13 76 22 65 31  9 75 20 45 30 16 46 58 49  8 59 47 14 26 52 73 57 50 63 38 51], a_shuffle_aclus: [ 32  25  84   5  36  41  93  57 102  75  86  71  58  33   9  10  56  21  49   2  26  52  73   7  60   3  98  15  28  66  92  59   8  90  54  61  51 109  14  16   4  96  53  82  89  74  34  24  97  83  50  37  17 108  31  88  48  13 107  27  62  45  23  63  78  67  11  81  64  19  35  70 100  76  68  85  55  69]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_shuffle_IDXs: [46 18 58  3 41 34 35  9 24 26 38 43 49 16 19 50 37 47 74 15 56 64  0 52 51 22 71 23 75 42 33 40 14 54 57 69 70  6 30 29 63 48 68 77 10 17 61 12 65 28 27  2 55 36 72 39 67 73  1 53 20  7 25 31 11 60 21  8  4 59 13  5 45 62 32 44 76 66], a_shuffle_aclus: [ 63  25  78   5  58  51  52  13  33  35  55  60  67  23  26  68  54  64 102  21  75  86   2  70  69  31  97  32 107  59  50  57  19  73  76  93  96   9  45  41  85  66  92 109  14  24  83  16  88  37  36   4  74  53  98  56  90 100   3  71  27  10  34  48  15  82  28  11   7  81  17   8  62  84  49  61 108  89]\n",
      "a_shuffle_IDXs: [68 24 46 30 65 67 49 33 56 21 55 58 75 62  9 64 22 71 11 34 27 47 32 18 23 66 35 28 37 51 36 59 77 63 52 12 15 60 43 48 72  7  8 70 54  4 29 40 74 16 61 39 42 25 38 50 17  5 44  2  1  6 31 10  3 20 73 69 76  0 53 57 14 45 19 41 13 26], a_shuffle_aclus: [ 92  33  63  45  88  90  67  50  75  28  74  78 107  84  13  86  31  97  15  51  36  64  49  25  32  89  52  37  54  69  53  81 109  85  70  16  21  82  60  66  98  10  11  96  73   7  41  57 102  23  83  56  59  34  55  68  24   8  61   4   3   9  48  14   5  27 100  93 108   2  71  76  19  62  26  58  17  35]\n",
      "a_shuffle_IDXs: [39 54 20 75 56 17 49  9  3 42 63 15 29 13  1 48 19 37 51 52 58 30 41  8 23  0 47 43 36 26 70 46  5 25 45 71 40 35 61 66 77  2 76 28 73 44  7 18 59 74 38 60 57 65 12 72  4 22 16 69 11 32 53 68 27 21 67 34 31  6 10 33 24 64 14 62 55 50], a_shuffle_aclus: [ 56  73  27 107  75  24  67  13   5  59  85  21  41  17   3  66  26  54  69  70  78  45  58  11  32   2  64  60  53  35  96  63   8  34  62  97  57  52  83  89 109   4 108  37 100  61  10  25  81 102  55  82  76  88  16  98   7  31  23  93  15  49  71  92  36  28  90  51  48   9  14  50  33  86  19  84  74  68]\n"
     ]
    }
   ],
   "source": [
    "if did_find_valid_selection:\n",
    "\t_subfn_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c038f64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_subfn_compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3776d302",
   "metadata": {},
   "outputs": [],
   "source": [
    "_subfn_compute_new()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabb8569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom_suffix: str = '_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0'\n",
    "\n",
    "minimum_inclusion_fr_Hz = active_session_pickle_file_widget.current_parameter_values['minimum_inclusion_fr_Hz']\n",
    "included_qclu_values = active_session_pickle_file_widget.current_parameter_values['included_qclu_values']\n",
    "\n",
    "included_qclu_values\n",
    "\n",
    "custom_suffix: str = f'_withNewComputedReplays-qclu_{included_qclu_values}-frateThresh_{minimum_inclusion_fr_Hz:2f}'\n",
    "custom_suffix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac6b6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set default local comp pkl:\n",
    "default_selected_local_file_name: str = 'loadedSessPickle.pkl'\n",
    "default_local_section_indicies = [active_session_pickle_file_widget.local_file_browser_widget._data['File Name'].tolist().index(default_selected_local_file_name)]\n",
    "active_session_pickle_file_widget.local_file_browser_widget.selection = default_local_section_indicies\n",
    "\n",
    "## Set default global computation pkl:\n",
    "default_selected_global_file_name: str = 'global_computation_results.pkl'\n",
    "default_global_section_indicies = [active_session_pickle_file_widget.global_file_browser_widget._data['File Name'].tolist().index(default_selected_global_file_name)]\n",
    "active_session_pickle_file_widget.global_file_browser_widget.selection = default_global_section_indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaac9d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.pickle_path\n",
    "# curr_active_pipeline.has_associated_pickle\n",
    "curr_active_pipeline.save_pipeline("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c072a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.IPyWidgets.SaveAsWidget import PipelineBackupWidget\n",
    "\n",
    "backup_widget = PipelineBackupWidget(curr_active_pipeline)\n",
    "backup_widget.servable()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb1135e",
   "metadata": {},
   "source": [
    "## <a id='toc2_1_'></a>[2024-06-25 - Load from saved custom](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5515d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline, custom_suffix, proposed_load_pkl_path = active_session_pickle_file_widget.on_load_local(global_data_root_parent_path=global_data_root_parent_path, active_data_mode_name=active_data_mode_name, basedir=basedir, saving_mode=saving_mode, force_reload=force_reload)\n",
    "curr_active_pipeline = active_session_pickle_file_widget.on_load_global(curr_active_pipeline=curr_active_pipeline, basedir=basedir, extended_computations_include_includelist=extended_computations_include_includelist, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist,\n",
    "                                       skip_global_load=False, force_reload=False, override_global_computation_results_pickle_path=active_session_pickle_file_widget.active_global_pkl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9337ddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads custom pipeline pickles that were saved out via `custom_save_filepaths['pipeline_pkl'] = curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE, active_pickle_filename=custom_save_filenames['pipeline_pkl'])`\n",
    "\n",
    "## INPUTS: global_data_root_parent_path, active_data_mode_name, basedir, saving_mode, force_reload, custom_save_filenames\n",
    "# custom_suffix: str = '_withNewKamranExportedReplays'\n",
    "\n",
    "# custom_suffix: str = '_withNewComputedReplays'\n",
    "# custom_suffix: str = '_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0'\n",
    "\n",
    "# custom_save_filenames = {\n",
    "#     'pipeline_pkl':f'loadedSessPickle{custom_suffix}.pkl',\n",
    "#     'global_computation_pkl':f\"global_computation_results{custom_suffix}.pkl\",\n",
    "#     'pipeline_h5':f'pipeline{custom_suffix}.h5',\n",
    "# }\n",
    "# print(f'custom_save_filenames: {custom_save_filenames}')\n",
    "# custom_save_filepaths = {k:v for k, v in custom_save_filenames.items()}\n",
    "\n",
    "# # ==================================================================================================================== #\n",
    "# # PIPELINE LOADING                                                                                                     #\n",
    "# # ==================================================================================================================== #\n",
    "# # load the custom saved outputs\n",
    "# active_pickle_filename = custom_save_filenames['pipeline_pkl'] # 'loadedSessPickle_withParameters.pkl'\n",
    "# print(f'active_pickle_filename: \"{active_pickle_filename}\"')\n",
    "# # assert active_pickle_filename.exists()\n",
    "# active_session_h5_filename = custom_save_filenames['pipeline_h5'] # 'pipeline_withParameters.h5'\n",
    "# print(f'active_session_h5_filename: \"{active_session_h5_filename}\"')\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "## DO NOT allow recompute if the file doesn't exist!!\n",
    "# Computing loaded session pickle file results : \"W:/Data/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle_withNewComputedReplays.pkl\"... done.\n",
    "# Failure loading W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\loadedSessPickle_withNewComputedReplays.pkl.\n",
    "# proposed_load_pkl_path = basedir.joinpath(active_pickle_filename).resolve()\n",
    "\n",
    "## INPUTS: widget.active_global_pkl, widget.active_global_pkl\n",
    "\n",
    "if active_session_pickle_file_widget.active_global_pkl is None:\n",
    "    skip_global_load: bool = True\n",
    "    override_global_computation_results_pickle_path = None\n",
    "else:\n",
    "    skip_global_load: bool = False\n",
    "    override_global_computation_results_pickle_path = active_session_pickle_file_widget.active_global_pkl.resolve()\n",
    "    Assert.path_exists(override_global_computation_results_pickle_path)\n",
    "    override_global_computation_results_pickle_path\n",
    "\n",
    "\n",
    "proposed_load_pkl_path = active_session_pickle_file_widget.active_local_pkl.resolve()\n",
    "Assert.path_exists(proposed_load_pkl_path)\n",
    "proposed_load_pkl_path\n",
    "\n",
    "custom_suffix: str = active_session_pickle_file_widget.try_extract_custom_suffix()\n",
    "print(f'custom_suffix: \"{custom_suffix}\"')\n",
    "\n",
    "## OUTPUTS: custom_suffix, proposed_load_pkl_path, (override_global_computation_results_pickle_path, skip_global_load)\n",
    "from pyphocorehelpers.Filesystem.path_helpers import set_posix_windows\n",
    "## INPUTS: proposed_load_pkl_path\n",
    "assert proposed_load_pkl_path.exists(), f\"for a saved custom the file must exist!\"\n",
    "\n",
    "epoch_name_includelist=None\n",
    "active_computation_functions_name_includelist=['lap_direction_determination', 'pf_computation','firing_rate_trends', 'position_decoding']\n",
    "\n",
    "with set_posix_windows():\n",
    "    curr_active_pipeline: NeuropyPipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_includelist=epoch_name_includelist,\n",
    "                                            computation_functions_name_includelist=active_computation_functions_name_includelist,\n",
    "                                            saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                            skip_extended_batch_computations=True, debug_print=False, fail_on_exception=True, active_pickle_filename=proposed_load_pkl_path) # , active_pickle_filename = 'loadedSessPickle_withParameters.pkl'\n",
    "\n",
    "## Post Compute Validate 2023-05-16:\n",
    "was_updated = BatchSessionCompletionHandler.post_compute_validate(curr_active_pipeline) ## TODO: need to potentially re-save if was_updated. This will fail because constained versions not ran yet.\n",
    "if was_updated:\n",
    "    print(f'was_updated: {was_updated}')\n",
    "    try:\n",
    "        if saving_mode == PipelineSavingScheme.SKIP_SAVING:\n",
    "            print(f'WARNING: PipelineSavingScheme.SKIP_SAVING but need to save post_compute_validate changes!!')\n",
    "        else:\n",
    "            curr_active_pipeline.save_pipeline(saving_mode=saving_mode)\n",
    "    except Exception as e:\n",
    "        ## TODO: catch/log saving error and indicate that it isn't saved.\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'ERROR RE-SAVING PIPELINE after update. error: {e}')\n",
    "\n",
    "print(f'Pipeline loaded from custom pickle!!')\n",
    "## OUTPUT: curr_active_pipeline\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Global computations loading:                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "# Loads saved global computations that were saved out via: `custom_save_filepaths['global_computation_pkl'] = curr_active_pipeline.save_global_computation_results(override_global_pickle_filename=custom_save_filenames['global_computation_pkl'])`\n",
    "## INPUTS: custom_save_filenames\n",
    "## INPUTS: curr_active_pipeline, override_global_computation_results_pickle_path, extended_computations_include_includelist\n",
    "\n",
    "override_global_computation_results_pickle_path = None\n",
    "# override_global_computation_results_pickle_path = custom_save_filenames['global_computation_pkl']\n",
    "print(f'override_global_computation_results_pickle_path: \"{override_global_computation_results_pickle_path}\"')\n",
    "\n",
    "# Pre-load ___________________________________________________________________________________________________________ #\n",
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Pre-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "# valid_computed_results_output_list\n",
    "\n",
    "# Try Unpickling Global Computations to update pipeline ______________________________________________________________ #\n",
    "if (not force_reload) and (not skip_global_load): # not just force_reload, needs to recompute whenever the computation fails.\n",
    "    try:\n",
    "        # INPUTS: override_global_computation_results_pickle_path\n",
    "        with set_posix_windows():\n",
    "            sucessfully_updated_keys, successfully_loaded_keys = curr_active_pipeline.load_pickled_global_computation_results(override_global_computation_results_pickle_path=override_global_computation_results_pickle_path,\n",
    "                                                                                            allow_overwrite_existing=True, allow_overwrite_existing_allow_keys=extended_computations_include_includelist, ) # is new\n",
    "            print(f'sucessfully_updated_keys: {sucessfully_updated_keys}\\nsuccessfully_loaded_keys: {successfully_loaded_keys}')\n",
    "            did_any_paths_change: bool = curr_active_pipeline.post_load_fixup_sess_basedirs(updated_session_basepath=deepcopy(basedir)) ## use INPUT: basedir\n",
    "            \n",
    "    except FileNotFoundError as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'cannot load global results because pickle file does not exist! Maybe it has never been created? {e}')\n",
    "    except Exception as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'Unhandled exception: cannot load global results: {e}')\n",
    "        raise\n",
    "\n",
    "# Post-Load __________________________________________________________________________________________________________ #\n",
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "\n",
    "\n",
    "\n",
    "## fixup missing paths\n",
    "# self.basepath: WindowsPath('/nfs/turbo/umms-kdiba/KDIBA/gor01/one/2006-6-09_1-22-43')\n",
    "\n",
    "## INPUTS: basedir\n",
    "did_any_paths_change: bool = curr_active_pipeline.post_load_fixup_sess_basedirs(updated_session_basepath=deepcopy(basedir)) ## use INPUT: basedir\n",
    "\n",
    "# Compute ____________________________________________________________________________________________________________ #\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "force_recompute_global = force_reload\n",
    "# force_recompute_global = True\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "if (len(newly_computed_values) > 0):\n",
    "    print(f'newly_computed_values: {newly_computed_values}.')\n",
    "    if (saving_mode.value != 'skip_saving'):\n",
    "        print(f'Saving global results...')\n",
    "        try:\n",
    "            # curr_active_pipeline.global_computation_results.persist_time = datetime.now()\n",
    "            # Try to write out the global computation function results:\n",
    "            curr_active_pipeline.save_global_computation_results()\n",
    "        except Exception as e:\n",
    "            exception_info = sys.exc_info()\n",
    "            e = CapturedException(e, exception_info)\n",
    "            print(f'\\n\\n!!WARNING!!: saving the global results threw the exception: {e}')\n",
    "            print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "    else:\n",
    "        print(f'\\n\\n!!WARNING!!: changes to global results have been made but they will not be saved since saving_mode.value == \"skip_saving\"')\n",
    "        print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "else:\n",
    "    print(f'no changes in global results.')\n",
    "\n",
    "# Post-compute _______________________________________________________________________________________________________ #\n",
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=False, force_recompute_override_computations_includelist=[], debug_print=True)\n",
    "print(f'Post-compute validation: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "\n",
    "# Post-Load __________________________________________________________________________________________________________ #\n",
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "\n",
    "print(f'force_reload: {force_reload}, saving_mode: {saving_mode}')\n",
    "force_reload\n",
    "saving_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f813f01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## indicate that it was loaded with a custom suffix\n",
    "curr_active_pipeline.pickle_path ## correct\n",
    "curr_active_pipeline.global_computation_results_pickle_path ## correct\n",
    "\n",
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE, override_pickle_path=curr_active_pipeline.pickle_path, active_pickle_filename=curr_active_pipeline.pickle_path.name) #active_pickle_filename=\n",
    "curr_active_pipeline.save_global_computation_results(override_global_pickle_path=curr_active_pipeline.global_computation_results_pickle_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49de9fb9",
   "metadata": {},
   "source": [
    "## 0️⃣💾 Save Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba28da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_selected_local_file_name: str = 'loadedSessPickle.pkl'\n",
    "if curr_active_pipeline.pickle_path is None:\n",
    "    curr_active_pipeline.pickle_path = Path('W:/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/loadedSessPickle.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89fe1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## indicate that it was loaded with a custom suffix\n",
    "curr_active_pipeline.pickle_path ## correct\n",
    "curr_active_pipeline.global_computation_results_pickle_path ## correct\n",
    "\n",
    "if curr_active_pipeline.pickle_path is None:\n",
    "    active_pickle_filename = 'loadedSessPickle.pkl'\n",
    "else:\n",
    "    active_pickle_filename = curr_active_pipeline.pickle_path.name\n",
    "    \n",
    "print(f'active_pickle_filename: {active_pickle_filename}')\n",
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE, override_pickle_path=curr_active_pipeline.pickle_path, active_pickle_filename=active_pickle_filename) #active_pickle_filename=\n",
    "curr_active_pipeline.save_global_computation_results(override_global_pickle_path=curr_active_pipeline.global_computation_results_pickle_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9ba82e",
   "metadata": {},
   "source": [
    "## <a id='toc2_3_'></a>[0️⃣ Normal Pipeline Load](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8167df1c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-0",
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-full_session_LOO_decoding_analysis.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "# epoch_name_includelist = ['maze']\n",
    "\n",
    "curr_active_pipeline: NeuropyPipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_includelist=epoch_name_includelist,\n",
    "                                        computation_functions_name_includelist=active_computation_functions_name_includelist,\n",
    "                                        saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                        skip_extended_batch_computations=True, debug_print=True, fail_on_exception=False) #, time_bin_size = 0.025 time_bin_size = 0.058, override_parameters_flat_keypaths_dict = dict(), \n",
    "# , active_pickle_filename = 'loadedSessPickle_withParameters.pkl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b125667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.get_failed_computations()\n",
    "curr_active_pipeline.clear_all_failed_computations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76c7dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# {'maze1_odd': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze2_odd': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze_odd': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze1_even': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze2_even': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze_even': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze1_any': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze2_any': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze_any': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')}}\n",
    "\n",
    "_out = curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_split_to_directional_laps'], fail_on_exception=True, debug_print=True)\n",
    "\n",
    "\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_split_to_directional_laps'], computation_kwargs_list=[{}], \n",
    "#                                                   enabled_filter_names=None, fail_on_exception=True, debug_print=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8edcd94",
   "metadata": {
    "tags": [
     "run-group-0"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "## Post Compute Validate 2023-05-16:\n",
    "# was_updated = BatchSessionCompletionHandler.post_compute_validate(curr_active_pipeline) ## TODO: need to potentially re-save if was_updated. This will fail because constained versions not ran yet.\n",
    "was_updated = False\n",
    "if was_updated:\n",
    "    print(f'was_updated: {was_updated}')\n",
    "    try:\n",
    "        curr_active_pipeline.save_pipeline(saving_mode=saving_mode)\n",
    "    except Exception as e:\n",
    "        ## TODO: catch/log saving error and indicate that it isn't saved.\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'ERROR RE-SAVING PIPELINE after update. error: {e}')\n",
    "\n",
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Pre-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "# valid_computed_results_output_list\n",
    "if not force_reload: # not just force_reload, needs to recompute whenever the computation fails.\n",
    "    try:\n",
    "        # curr_active_pipeline.load_pickled_global_computation_results()\n",
    "        with set_posix_windows():\n",
    "            sucessfully_updated_keys, successfully_loaded_keys = curr_active_pipeline.load_pickled_global_computation_results(allow_overwrite_existing=True, allow_overwrite_existing_allow_keys=extended_computations_include_includelist) # is new\n",
    "            \n",
    "        print(f'sucessfully_updated_keys: {sucessfully_updated_keys}\\nsuccessfully_loaded_keys: {successfully_loaded_keys}')\n",
    "    except FileNotFoundError as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'cannot load global results because pickle file does not exist! Maybe it has never been created? {e}')\n",
    "    except Exception as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'Unhandled exception: cannot load global results: {e}')\n",
    "        raise\n",
    "\n",
    "# Recomputing active_epoch_placefields... \t done.\n",
    "# Recomputing active_epoch_placefields2D... \t done.\n",
    "# WARN: f\"len(self.is_non_firing_time_bin): 30459, self.num_time_windows: 30762\", trying to recompute them....\n",
    "# UNHANDLED EXCEPTION: Unable to allocate 3.46 GiB for an array with shape (15124, 30724) and data type float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9809aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.accumulated_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcac55a8",
   "metadata": {
    "tags": [
     "run-group-0",
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "force_recompute_global = force_reload # Post-load global computations: needs_computation_output_dict: ['rank_order_shuffle_analysis', 'directional_train_test_split', 'short_long_pf_overlap_analyses', 'wcorr_shuffle_analysis', 'extended_pf_peak_information', 'position_decoding_two_step']\n",
    "# force_recompute_global = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4321d2fc",
   "metadata": {
    "tags": [
     "run-group-0"
    ]
   },
   "outputs": [],
   "source": [
    "fail_on_exception = False\n",
    "\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=fail_on_exception, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "if (len(newly_computed_values) > 0):\n",
    "    print(f'newly_computed_values: {newly_computed_values}.')\n",
    "    if (saving_mode.value != 'skip_saving'):\n",
    "        print(f'Saving global results...')\n",
    "        try:\n",
    "            # curr_active_pipeline.global_computation_results.persist_time = datetime.now()\n",
    "            # Try to write out the global computation function results:\n",
    "            curr_active_pipeline.save_global_computation_results()\n",
    "        except Exception as e:\n",
    "            exception_info = sys.exc_info()\n",
    "            e = CapturedException(e, exception_info)\n",
    "            print(f'\\n\\n!!WARNING!!: saving the global results threw the exception: {e}')\n",
    "            print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "    else:\n",
    "        print(f'\\n\\n!!WARNING!!: changes to global results have been made but they will not be saved since saving_mode.value == \"skip_saving\"')\n",
    "        print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "else:\n",
    "    print(f'no changes in global results.')\n",
    "\n",
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=fail_on_exception, progress_print=True,\n",
    "                                                    force_recompute=False, force_recompute_override_computations_includelist=[], debug_print=True)\n",
    "print(f'Post-compute validation: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615018da",
   "metadata": {},
   "source": [
    "## <a id='toc2_4_'></a>[0️⃣ Shared Post-Pipeline load stuff](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c842f5e4",
   "metadata": {
    "tags": [
     "run-group-0-interactive",
     "run-2025-04-11_full-session_marginals",
     "run-group-0"
    ]
   },
   "outputs": [],
   "source": [
    "# BATCH_DATE_TO_USE: str = f'{DAY_DATE_TO_USE}_GL'\n",
    "# BATCH_DATE_TO_USE: str = f'{DAY_DATE_TO_USE}_rMBP' # TODO: Change this as needed, templating isn't actually doing anything rn.\n",
    "BATCH_DATE_TO_USE: str = f'{DAY_DATE_TO_USE}_Apogee'\n",
    "# BATCH_DATE_TO_USE: str = f'{DAY_DATE_TO_USE}_Lab'\n",
    " \n",
    "try:\n",
    "    if custom_suffix is not None:\n",
    "        BATCH_DATE_TO_USE = f'{BATCH_DATE_TO_USE}{custom_suffix}'\n",
    "        print(f'Adding custom suffix: \"{custom_suffix}\" - BATCH_DATE_TO_USE: \"{BATCH_DATE_TO_USE}\"')\n",
    "except NameError as err:\n",
    "    custom_suffix = None\n",
    "    print(f'NO CUSTOM SUFFIX.')\n",
    "\n",
    "known_collected_output_paths = [Path(v).resolve() for v in ['/nfs/turbo/umms-kdiba/Data/Output/collected_outputs', '/home/halechr/FastData/collected_outputs/',\n",
    "                                                           '/home/halechr/cloud/turbo/Data/Output/collected_outputs',\n",
    "                                                           r'C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\output\\collected_outputs',\n",
    "                                                           r\"K:\\scratch\\collected_outputs\",\n",
    "                                                           '/Users/pho/data/collected_outputs',\n",
    "                                                          'output/gen_scripts/']]\n",
    "collected_outputs_path = find_first_extant_path(known_collected_output_paths)\n",
    "assert collected_outputs_path.exists(), f\"collected_outputs_path: {collected_outputs_path} does not exist! Is the right computer's config commented out above?\"\n",
    "# fullwidth_path_widget(scripts_output_path, file_name_label='Scripts Output Path:')\n",
    "print(f'collected_outputs_path: {collected_outputs_path}')\n",
    "# collected_outputs_path.mkdir(exist_ok=True)\n",
    "# assert collected_outputs_path.exists()\n",
    "\n",
    "## Build the output prefix from the session context:\n",
    "active_context = curr_active_pipeline.get_session_context()\n",
    "curr_session_name: str = curr_active_pipeline.session_name # '2006-6-08_14-26-15'\n",
    "CURR_BATCH_OUTPUT_PREFIX: str = f\"{BATCH_DATE_TO_USE}-{curr_session_name}\"\n",
    "print(f'CURR_BATCH_OUTPUT_PREFIX: \"{CURR_BATCH_OUTPUT_PREFIX}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606e8116",
   "metadata": {},
   "source": [
    "## <a id='toc2_5_'></a>[Specific Recomputations](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f010d1a9",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "any_most_recent_computation_time, each_epoch_latest_computation_time, each_epoch_each_result_computation_completion_times, (global_computations_latest_computation_time, global_computation_completion_times) = curr_active_pipeline.get_computation_times(debug_print=False)\n",
    "# each_epoch_latest_computation_time\n",
    "each_epoch_each_result_computation_completion_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3d4f61",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd11d0f",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.clear_all_failed_computations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ff30b7",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computation_config.instantaneous_time_bin_size_seconds = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58db94e",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "force_recompute_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f285cd23",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "force_recompute_global = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47820977",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "extended_computations_include_includelist=['lap_direction_determination', 'pf_computation', 'firing_rate_trends', 'pfdt_computation',\n",
    "    # 'pf_dt_sequential_surprise',\n",
    "    #  'ratemap_peaks_prominence2d',\n",
    "    'extended_stats',\n",
    "    'long_short_decoding_analyses',\n",
    "    'jonathan_firing_rate_analysis',\n",
    "    'long_short_fr_indicies_analyses',\n",
    "    'short_long_pf_overlap_analyses',\n",
    "    'long_short_post_decoding',\n",
    "    # 'long_short_rate_remapping',\n",
    "    'long_short_inst_spike_rate_groups',\n",
    "    'long_short_endcap_analysis',\n",
    "    # 'spike_burst_detection',\n",
    "    'split_to_directional_laps',\n",
    "    'merged_directional_placefields',\n",
    "    'rank_order_shuffle_analysis',\n",
    "    'directional_decoders_decode_continuous',\n",
    "    'directional_decoders_evaluate_epochs',\n",
    "    'directional_decoders_epoch_heuristic_scoring',\n",
    "] # do only specified\n",
    "\n",
    "# ['split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous']\n",
    "\n",
    "# force_recompute_override_computations_includelist = [\n",
    "#     'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring',\n",
    "#     'split_to_directional_laps', 'lap_direction_determination', 'DirectionalLaps',\n",
    "#     'merged_directional_placefields',\n",
    "#     'directional_decoders_decode_continuous',\n",
    "# ]\n",
    "force_recompute_override_computations_includelist = None\n",
    "\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "newly_computed_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc0a702",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# extended_computations_include_includelist=['ratemap_peaks_prominence2d', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring',] # do only specified\n",
    "extended_computations_include_includelist=['rank_order_shuffle_analysis', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs' ] # do only specified\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db62d145",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "newly_computed_values = curr_active_pipeline.batch_extended_computations(include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = curr_active_pipeline.batch_evaluate_required_computations(include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02779f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27120a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "newly_computed_values = curr_active_pipeline.batch_extended_computations(include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3927a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = curr_active_pipeline.batch_evaluate_required_computations(include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8b307a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d357f9",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# mmm ## lots of m's to break computations\n",
    "\n",
    "## Next wave of computations\n",
    "extended_computations_include_includelist=['directional_decoders_epoch_heuristic_scoring',] # do only specified\n",
    "force_recompute_override_computations_includelist = deepcopy(extended_computations_include_includelist)\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617dbaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mmm ## lots of m's to break computations\n",
    "\n",
    "## Next wave of computations\n",
    "extended_computations_include_includelist=['rank_order_shuffle_analysis',] # do only specified\n",
    "force_recompute_override_computations_includelist = deepcopy(extended_computations_include_includelist)\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3efc4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'lap_direction_determination'\n",
    "extended_computations_include_includelist=['_split_to_directional_laps'] # do only specified\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=True)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_split_to_directional_laps'], computation_kwargs_list=None, enabled_filter_names=None, fail_on_exception=True, debug_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d834f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "curr_active_pipeline.get_failed_computations() # 'maze1_odd': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:973<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')}\n",
    "\n",
    "# curr_active_pipeline.rerun_failed_computations()\n",
    "# curr_active_pipeline.stage.rerun_failed_computations()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e982eb",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[0️⃣ Pho Interactive Pipeline Jupyter Widget](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce08192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import interactive_pipeline_widget, interactive_pipeline_files\n",
    "\n",
    "_pipeline_jupyter_widget = interactive_pipeline_widget(curr_active_pipeline=curr_active_pipeline)\n",
    "# display(_pipeline_jupyter_widget)\n",
    "_pipeline_jupyter_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474f4c95",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[1️⃣ End Run](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a533ba8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T23:21:40.700275900Z",
     "start_time": "2023-11-16T23:21:40.584273Z"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "# (long_one_step_decoder_1D, short_one_step_decoder_1D), (long_one_step_decoder_2D, short_one_step_decoder_2D) = compute_short_long_constrained_decoders(curr_active_pipeline, recalculate_anyway=True)\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_epoch_context, short_epoch_context, global_epoch_context = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_epoch_name, short_epoch_name, global_epoch_name)]\n",
    "long_epoch_obj, short_epoch_obj = [Epoch(curr_active_pipeline.sess.epochs.to_dataframe().epochs.label_slice(an_epoch_name.removesuffix('_any'))) for an_epoch_name in [long_epoch_name, short_epoch_name]] #TODO 2023-11-10 20:41: - [ ] Issue with getting actual Epochs from sess.epochs for directional laps: emerges because long_epoch_name: 'maze1_any' and the actual epoch label in curr_active_pipeline.sess.epochs is 'maze1' without the '_any' part.\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_computation_config, short_computation_config, global_computation_config = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "long_pf2D, short_pf2D, global_pf2D = long_results.pf2D, short_results.pf2D, global_results.pf2D\n",
    "\n",
    "assert short_epoch_obj.n_epochs > 0, f'long_epoch_obj: {long_epoch_obj}, short_epoch_obj: {short_epoch_obj}'\n",
    "assert long_epoch_obj.n_epochs > 0, f'long_epoch_obj: {long_epoch_obj}, short_epoch_obj: {short_epoch_obj}'\n",
    "\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "t_start, t_delta, t_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b841b01c",
   "metadata": {
    "tags": [
     "created-2025-07-07"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e348e0c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "# directional_merged_decoders_result = deepcopy(directional_decoders_epochs_decode_result)\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "\n",
    "spikes_df = deepcopy(curr_active_pipeline.sess.spikes_df)\n",
    "spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528460fb",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "global_computation_results = curr_active_pipeline.global_computation_results\n",
    "\n",
    "rank_order_results = curr_active_pipeline.global_computation_results.computed_data.get('RankOrder', None) # : \"RankOrderComputationsContainer\"\n",
    "if rank_order_results is not None:\n",
    "    minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "else:        \n",
    "    ## get from parameters:\n",
    "    minimum_inclusion_fr_Hz: float = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.included_qclu_values\n",
    "\n",
    "\n",
    "directional_laps_results: DirectionalLapsResult = global_computation_results.computed_data['DirectionalLaps']\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\n",
    "# print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "# print(f'included_qclu_values: {included_qclu_values}')\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "ripple_decoding_time_bin_size: float = directional_merged_decoders_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_merged_decoders_result.laps_decoding_time_bin_size\n",
    "# pos_bin_size = _recover_position_bin_size(track_templates.get_decoders()[0]) # 3.793023081021702\n",
    "# print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}, ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}, pos_bin_size: {pos_bin_size}')\n",
    "# pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "\n",
    "## Simple Pearson Correlation\n",
    "assert spikes_df is not None\n",
    "(laps_simple_pf_pearson_merged_df, ripple_simple_pf_pearson_merged_df), corr_column_names = directional_merged_decoders_result.compute_simple_spike_time_v_pf_peak_x_by_epoch(track_templates=track_templates, spikes_df=deepcopy(spikes_df))\n",
    "## OUTPUTS: (laps_simple_pf_pearson_merged_df, ripple_simple_pf_pearson_merged_df), corr_column_names\n",
    "## Computes the highest-valued decoder for this score:\n",
    "try:\n",
    "    best_decoder_index_col_name: str = 'best_decoder_index'\n",
    "    laps_simple_pf_pearson_merged_df[best_decoder_index_col_name] = laps_simple_pf_pearson_merged_df[corr_column_names].abs().apply(lambda row: np.argmax(row.values), axis=1)\n",
    "    ripple_simple_pf_pearson_merged_df[best_decoder_index_col_name] = ripple_simple_pf_pearson_merged_df[corr_column_names].abs().apply(lambda row: np.argmax(row.values), axis=1)\n",
    "except KeyError as e:\n",
    "    pass # KeyError: \"None of [Index(['long_LR_pf_peak_x_pearsonr', 'long_RL_pf_peak_x_pearsonr', 'short_LR_pf_peak_x_pearsonr', 'short_RL_pf_peak_x_pearsonr'], dtype='object')] are in the [columns]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed4d1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_directional_pf1D_Decoder = directional_merged_decoders_result.all_directional_pf1D_Decoder\n",
    "pf1D = all_directional_pf1D_Decoder.pf\n",
    "# all_directional_pf1D_Decoder\n",
    "pf1D\n",
    "# all_directional_pf1D_Decoder.pf.plot_occupancy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1dc2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sort from left to right by peak location, and bottom-to-top by context\n",
    "# pf1D.peak_indicies\n",
    "# pf1D.peak_tuning_curve_center_of_mass_bin_coordinates\n",
    "\n",
    "# pf1D.get_tuning_curve_peak_df\n",
    "# pf1D.tuning_curves_dict\n",
    "# pf1D.tuning_curves\n",
    "\n",
    "# pf1D\n",
    "directional_laps_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eed3e0c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult, SingleEpochDecodedResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)\n",
    "\n",
    "pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict\n",
    "decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict\n",
    "\n",
    "print(f'pos_bin_size: {pos_bin_size}')\n",
    "print(f'ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}')\n",
    "print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}')\n",
    "\n",
    "# Radon Transforms:\n",
    "decoder_laps_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_df_dict\n",
    "decoder_ripple_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_df_dict\n",
    "decoder_laps_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_extras_dict\n",
    "decoder_ripple_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_extras_dict\n",
    "\n",
    "# Weighted correlations:\n",
    "laps_weighted_corr_merged_df: pd.DataFrame = directional_decoders_epochs_decode_result.laps_weighted_corr_merged_df\n",
    "ripple_weighted_corr_merged_df: pd.DataFrame = directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "decoder_laps_weighted_corr_df_dict: Dict[str, pd.DataFrame] = directional_decoders_epochs_decode_result.decoder_laps_weighted_corr_df_dict\n",
    "decoder_ripple_weighted_corr_df_dict: Dict[str, pd.DataFrame] = directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict\n",
    "\n",
    "# Pearson's correlations:\n",
    "laps_simple_pf_pearson_merged_df: pd.DataFrame = directional_decoders_epochs_decode_result.laps_simple_pf_pearson_merged_df\n",
    "ripple_simple_pf_pearson_merged_df: pd.DataFrame = directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df\n",
    "\n",
    "# laps_simple_pf_pearson_merged_df\n",
    "# ripple_simple_pf_pearson_merged_df\n",
    "\n",
    "# ## Drop rows where all are missing\n",
    "# corr_column_names = ['long_LR_pf_peak_x_pearsonr', 'long_RL_pf_peak_x_pearsonr', 'short_LR_pf_peak_x_pearsonr', 'short_RL_pf_peak_x_pearsonr']\n",
    "# # ripple_simple_pf_pearson_merged_df.dropna(subset=corr_column_names, axis='index', how='all') # 350/412 rows\n",
    "# filtered_laps_simple_pf_pearson_merged_df: pd.DataFrame = laps_simple_pf_pearson_merged_df.dropna(subset=corr_column_names, axis='index', how='any') # 320/412 rows\n",
    "# filtered_ripple_simple_pf_pearson_merged_df: pd.DataFrame = ripple_simple_pf_pearson_merged_df.dropna(subset=corr_column_names, axis='index', how='any') # 320/412 rows\n",
    "\n",
    "## Update the `decoder_ripple_filter_epochs_decoder_result_dict` with the included epochs:\n",
    "# decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_ripple_filter_epochs_decoder_result_dict[a_name].filtered_by_epochs(filtered_ripple_simple_pf_pearson_merged_df.index) for a_name, a_df in decoder_ripple_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_laps_filter_epochs_decoder_result_dict[a_name].filtered_by_epochs(filtered_laps_simple_pf_pearson_merged_df.index) for a_name, a_df in decoder_laps_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_ripple_filter_epochs_decoder_result_dict[a_name].filtered_by_epoch_times(filtered_ripple_simple_pf_pearson_merged_df[['start', 'stop']].to_numpy()) for a_name, a_df in decoder_ripple_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_laps_filter_epochs_decoder_result_dict[a_name].filtered_by_epoch_times(filtered_laps_simple_pf_pearson_merged_df[['start', 'stop']].to_numpy()) for a_name, a_df in decoder_laps_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_ripple_filter_epochs_decoder_result_dict[a_name].filtered_by_epoch_times(filtered_ripple_simple_pf_pearson_merged_df['start'].to_numpy()) for a_name, a_df in decoder_ripple_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_laps_filter_epochs_decoder_result_dict[a_name].filtered_by_epoch_times(filtered_laps_simple_pf_pearson_merged_df['start'].to_numpy()) for a_name, a_df in decoder_laps_filter_epochs_decoder_result_dict.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987755c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b35196",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "# I have several python variables I want to print: t_start, t_delta, t_end\n",
    "# I want to generate a print statement that explicitly lists the variable name prior to its value like `print(f't_start: {t_start}, t_delta: {t_delta}, t_end: {t_end}')`\n",
    "# Currently I have to t_start, t_delta, t_end\n",
    "curr_active_pipeline.get_session_context()\n",
    "\n",
    "print(f'{curr_active_pipeline.session_name}:\\tt_start: {t_start}, t_delta: {t_delta}, t_end: {t_end}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49f5d4f",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "# Unpack all directional variables:\n",
    "## {\"even\": \"RL\", \"odd\": \"LR\"}\n",
    "long_LR_name, short_LR_name, global_LR_name, long_RL_name, short_RL_name, global_RL_name, long_any_name, short_any_name, global_any_name = ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "\n",
    "# Most popular\n",
    "# long_LR_name, short_LR_name, long_RL_name, short_RL_name, global_any_name\n",
    "\n",
    "# Unpacking for `(long_LR_name, long_RL_name, short_LR_name, short_RL_name)`\n",
    "(long_LR_context, long_RL_context, short_LR_context, short_RL_context) = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj, global_any_laps_epochs_obj = [curr_active_pipeline.computation_results[an_epoch_name].computation_config.pf_params.computation_epochs for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name, global_any_name)] # note has global also\n",
    "(long_LR_session, long_RL_session, short_LR_session, short_RL_session) = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)] # sessions are correct at least, seems like just the computation parameters are messed up\n",
    "(long_LR_results, long_RL_results, short_LR_results, short_RL_results) = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_computation_config, long_RL_computation_config, short_LR_computation_config, short_RL_computation_config) = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_pf1D, long_RL_pf1D, short_LR_pf1D, short_RL_pf1D) = (long_LR_results.pf1D, long_RL_results.pf1D, short_LR_results.pf1D, short_RL_results.pf1D)\n",
    "(long_LR_pf2D, long_RL_pf2D, short_LR_pf2D, short_RL_pf2D) = (long_LR_results.pf2D, long_RL_results.pf2D, short_LR_results.pf2D, short_RL_results.pf2D)\n",
    "(long_LR_pf1D_Decoder, long_RL_pf1D_Decoder, short_LR_pf1D_Decoder, short_RL_pf1D_Decoder) = (long_LR_results.pf1D_Decoder, long_RL_results.pf1D_Decoder, short_LR_results.pf1D_Decoder, short_RL_results.pf1D_Decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7104fc37",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult, DirectionalLapsResult, DirectionalDecodersContinuouslyDecodedResult\n",
    "\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']   \n",
    "rank_order_results: RankOrderComputationsContainer = curr_active_pipeline.global_computation_results.computed_data.get('RankOrder', None)\n",
    "if rank_order_results is not None:\n",
    "    minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "else:        \n",
    "    ## get from parameters:\n",
    "    minimum_inclusion_fr_Hz: float = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.included_qclu_values\n",
    "\n",
    "print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "print(f'included_qclu_values: {included_qclu_values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4a6873",
   "metadata": {
    "tags": [
     "run-group-end-run"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring, HeuristicsResult\n",
    "\n",
    "a_heuristics_result: HeuristicsResult = curr_active_pipeline.global_computation_results.computed_data['Heuristics']\n",
    "a_heuristics_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a6eab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_merged_decoders_result.laps_time_bin_marginals_df\n",
    "directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00672033",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_laps_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bb2118",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result ## here is a single result, but not a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f90757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_build_individual_time_bin_decoded_posteriors_df\n",
    "\n",
    "## From `directional_merged_decoders_result`\n",
    "# transfer_column_names_list: List[str] = ['maze_id', 'lap_dir', 'lap_id']\n",
    "transfer_column_names_list: List[str] = []\n",
    "filtered_laps_time_bin_marginals_df = _perform_build_individual_time_bin_decoded_posteriors_df(curr_active_pipeline, track_templates=track_templates, all_directional_laps_filter_epochs_decoder_result=directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result, transfer_column_names_list=transfer_column_names_list)\n",
    "filtered_laps_time_bin_marginals_df['lap_id'] = filtered_laps_time_bin_marginals_df['parent_epoch_label'].astype(int) + 1\n",
    "filtered_laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4c2073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result\n",
    "\n",
    "# directional_merged_decoders_result.all_directional_decoder_dict\n",
    "directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df77e66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import PhoPaginatedMultiDecoderDecodedEpochsWindow, DecodedEpochSlicesPaginatedFigureController, EpochSelectionsObject, ClickActionCallbacks\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.ThinButtonBar.ThinButtonBarWidget import ThinButtonBarWidget\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.PaginationCtrl.PaginationControlWidget import PaginationControlWidget, PaginationControlWidgetState\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from pyphoplacecellanalysis.Resources import GuiResources, ActionIcons, silx_resources_rc\n",
    "## INPUTS filtered_decoder_filter_epochs_decoder_result_dict\n",
    "# decoder_decoded_epochs_result_dict: generic\n",
    "\n",
    "app, paginated_multi_decoder_decoded_epochs_window, pagination_controller_dict = PhoPaginatedMultiDecoderDecodedEpochsWindow.init_from_track_templates(curr_active_pipeline, track_templates,\n",
    "                                                                                                # decoder_decoded_epochs_result_dict=decoder_ripple_filter_epochs_decoder_result_dict, epochs_name='ripple',\n",
    "                                                                                                decoder_decoded_epochs_result_dict=filtered_decoder_filter_epochs_decoder_result_dict, epochs_name='ripple',\n",
    "                                                                                                # decoder_decoded_epochs_result_dict=filtered_ripple_simple_pf_pearson_merged_df, epochs_name='ripple',\n",
    "                                                                                                # decoder_decoded_epochs_result_dict=long_like_during_post_delta_only_filtered_decoder_filter_epochs_decoder_result_dict, epochs_name='ripple', title='Long-like post-Delta Ripples Only', ## RIPPLE\n",
    "                                                                                                # decoder_decoded_epochs_result_dict=decoder_laps_filter_epochs_decoder_result_dict, epochs_name='laps', ## LAPS\n",
    "                                                                                                included_epoch_indicies=None, debug_print=False,\n",
    "                                                                                                params_kwargs={'enable_per_epoch_action_buttons': False,\n",
    "                                                                                                    'skip_plotting_most_likely_positions': True, 'skip_plotting_measured_positions': True, \n",
    "                                                                                                    'enable_decoded_most_likely_position_curve': False, 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': True,\n",
    "                                                                                                    # 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': False,\n",
    "                                                                                                    # 'disable_y_label': True,\n",
    "                                                                                                    'isPaginatorControlWidgetBackedMode': True,\n",
    "                                                                                                    'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True,\n",
    "                                                                                                    # 'debug_print': True,\n",
    "                                                                                                    'max_subplots_per_page': 10,\n",
    "                                                                                                    'scrollable_figure': False,\n",
    "                                                                                                    # 'scrollable_figure': True,\n",
    "                                                                                                    # 'posterior_heatmap_imshow_kwargs': dict(vmin=0.0075),\n",
    "                                                                                                    'use_AnchoredCustomText': False,\n",
    "                                                                                                    'should_suppress_callback_exceptions': False,\n",
    "                                                                                                    # 'build_fn': 'insets_view',\n",
    "                                                                                                })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ce9677",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### attached raster viewer widget:\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.RankOrderRastersDebugger import RankOrderRastersDebugger\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import get_proper_global_spikes_df\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "\n",
    "## INPUTS: active_spikes_df\n",
    "# active_spikes_df = get_proper_global_spikes_df(curr_active_pipeline, minimum_inclusion_fr_Hz=5)\n",
    "\n",
    "active_spikes_df = get_proper_global_spikes_df(curr_active_pipeline)\n",
    "\n",
    "# PosteriorExporting._perform_export_current_epoch_marginal_and_raster_images\n",
    "\n",
    "\n",
    "\n",
    "# _out_ripple_rasters, update_attached_raster_viewer_epoch_callback = paginated_multi_decoder_decoded_epochs_window.build_attached_raster_viewer_widget(track_templates=track_templates, active_spikes_df=active_spikes_df, filtered_epochs_df=filtered_epochs_df) ## BEST\n",
    "# _out_ripple_rasters, update_attached_raster_viewer_epoch_callback = paginated_multi_decoder_decoded_epochs_window.build_attached_raster_viewer_widget(track_templates=track_templates, active_spikes_df=active_spikes_df, filtered_epochs_df=filtered_ripple_simple_pf_pearson_merged_df) # original\n",
    "_out_ripple_rasters, update_attached_raster_viewer_epoch_callback = paginated_multi_decoder_decoded_epochs_window.build_attached_raster_viewer_widget(track_templates=track_templates, active_spikes_df=active_spikes_df, filtered_epochs_df=extracted_merged_scores_df)\n",
    "# _out_ripple_rasters, update_attached_raster_viewer_epoch_callback = paginated_multi_decoder_decoded_epochs_window.build_attached_raster_viewer_widget(track_templates=track_templates, active_spikes_df=active_spikes_df, filtered_epochs_df=long_like_during_post_delta_only_filter_epochs_df) # Long-like-during-post-delta\n",
    "\n",
    "\n",
    "# all_directional_laps_filter_epochs_decoder_result_value\n",
    "# laps_filter_epochs = ensure_dataframe(deepcopy(decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)) \n",
    "# _out_ripple_rasters, update_attached_raster_viewer_epoch_callback = paginated_multi_decoder_decoded_epochs_window.build_attached_raster_viewer_widget(track_templates=track_templates, active_spikes_df=laps_spikes_df, filtered_epochs_df=filtered_laps_simple_pf_pearson_merged_df) ## LAPS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d2fead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66d41af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out_ripple_rasters: RankOrderRastersDebugger\n",
    "### Add yellow-blue marginals to `paginated_multi_decoder_decoded_epochs_window`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_decoded_epoch_slices\n",
    "from pyphocorehelpers.gui.Qt.widget_positioning_helpers import WidgetPositioningHelpers, DesiredWidgetLocation, WidgetGeometryInfo\n",
    "\n",
    "yellow_blue_trackID_marginals_plot_tuple = paginated_multi_decoder_decoded_epochs_window.build_attached_yellow_blue_track_identity_marginal_window(directional_merged_decoders_result, global_session, ripple_decoding_time_bin_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fee2d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean and max number of active aclus per time bin for each epoch (lap)\n",
    "filtered_laps_time_bin_marginals_df.groupby(['lap_id']).agg(n_unique_aclus_mean=('n_unique_aclus', 'mean'), n_unique_aclus_max=('n_unique_aclus', 'max')).reset_index()\n",
    "filtered_laps_time_bin_marginals_df.groupby(['maze_id']).agg(n_unique_aclus_mean=('n_unique_aclus', 'mean'), n_unique_aclus_max=('n_unique_aclus', 'max')).reset_index() ## per maze\n",
    "filtered_laps_time_bin_marginals_df.groupby(['maze_id', 'lap_dir']).agg(n_unique_aclus_mean=('n_unique_aclus', 'mean'), n_unique_aclus_max=('n_unique_aclus', 'max')).reset_index() # per maze x lap_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93346114",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.BatchCompletionHandler import BatchSessionCompletionHandler\n",
    "\n",
    "BatchSessionCompletionHandler.post_compute_validate(curr_active_pipeline=curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0617e7a3",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "list(directional_laps_results.directional_lap_specific_configs.keys()) # ['maze1_odd', 'maze1_even', 'maze2_odd', 'maze2_even']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912656a7",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "from neuropy.utils.indexing_helpers import NumpyHelpers\n",
    "\n",
    "if ('DirectionalDecodersEpochsEvaluations' in curr_active_pipeline.global_computation_results.computed_data) and (curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations'] is not None):\n",
    "    directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "    directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)\n",
    "\n",
    "    ## UNPACK HERE via direct property access:\n",
    "    pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "    ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "    laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "    print(f'{pos_bin_size = }, {ripple_decoding_time_bin_size = }, {laps_decoding_time_bin_size = }') # pos_bin_size = 3.8054171165052444, ripple_decoding_time_bin_size = 0.025, laps_decoding_time_bin_size = 0.2\n",
    "    decoder_laps_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict\n",
    "    decoder_ripple_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict\n",
    "    decoder_laps_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_df_dict\n",
    "    decoder_ripple_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_df_dict\n",
    "\n",
    "    # New items:\n",
    "    decoder_laps_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_extras_dict\n",
    "    decoder_ripple_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_extras_dict\n",
    "\n",
    "    # Weighted correlations:\n",
    "    laps_weighted_corr_merged_df = directional_decoders_epochs_decode_result.laps_weighted_corr_merged_df\n",
    "    ripple_weighted_corr_merged_df = directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "    decoder_laps_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_laps_weighted_corr_df_dict\n",
    "    decoder_ripple_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict\n",
    "\n",
    "    # Pearson's correlations:\n",
    "    laps_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.laps_simple_pf_pearson_merged_df\n",
    "    ripple_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df\n",
    "    \n",
    "    # for k, v in directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict.items():\n",
    "    #     print(f'{k}: v.decoding_time_bin_size: {v.decoding_time_bin_size}')\n",
    "    \n",
    "    individual_result_ripple_time_bin_sizes = [v.decoding_time_bin_size for k, v in directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict.items()]\n",
    "    if not np.allclose(ripple_decoding_time_bin_size, individual_result_ripple_time_bin_sizes):\n",
    "        individual_result_ripple_time_bin_size = individual_result_ripple_time_bin_sizes[0] # get the first\n",
    "        assert np.allclose(individual_result_ripple_time_bin_size, individual_result_ripple_time_bin_sizes), f\"`individual_result_ripple_time_bin_size ({individual_result_ripple_time_bin_size}) does not equal the individual result time bin sizes: {individual_result_ripple_time_bin_sizes}`. This can occur when there are epochs smaller than the desired size ({ripple_decoding_time_bin_size}) for the result and epochs_filtering_mode=EpochFilteringMode.ConstrainDecodingTimeBinSizeToMinimum\"\n",
    "        print(f'WARN: overriding directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size (original value: {directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size}) with individual_result_ripple_time_bin_size: {individual_result_ripple_time_bin_size}')\n",
    "        directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size = individual_result_ripple_time_bin_size # override the time_bin_size with the actually used one\n",
    "        ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "        print(f'{pos_bin_size = }, {ripple_decoding_time_bin_size = }, {laps_decoding_time_bin_size = }') # pos_bin_size = 3.8054171165052444, ripple_decoding_time_bin_size = 0.025, laps_decoding_time_bin_size = 0.2\n",
    "    else:\n",
    "        # all are close, it's good\n",
    "        pass\n",
    "\n",
    "    # assert np.allclose(ripple_decoding_time_bin_size, individual_result_ripple_time_bin_sizes), f\"`directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size ({ripple_decoding_time_bin_size}) does not equal the individual result time bin sizes: {individual_result_ripple_time_bin_sizes}`. This can occur when there are epochs smaller than the desired size ({ripple_decoding_time_bin_size}) for the result and epochs_filtering_mode=EpochFilteringMode.ConstrainDecodingTimeBinSizeToMinimum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f1c291",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dce38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directional_decoders_epochs_decode_result # DecoderDecodedEpochsResult\n",
    "# laps_weighted_corr_merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881402df",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "# active_config_name: str = 'maze_any'\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "active_config_name: str = global_epoch_name # 'maze_any'\n",
    "active_config_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b80230",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "## INPUTS: curr_active_pipeline, active_config_name\n",
    "active_peak_prominence_2d_results = curr_active_pipeline.computation_results[active_config_name].computed_data.get('RatemapPeaksAnalysis', {}).get('PeakProminence2D', None)\n",
    "if active_peak_prominence_2d_results is None:\n",
    "    curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['ratemap_peaks_prominence2d'], enabled_filter_names=None, fail_on_exception=False, debug_print=False)\n",
    "    # curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['ratemap_peaks_prominence2d'], enabled_filter_names=[short_LR_name, short_RL_name, long_any_name, short_any_name], fail_on_exception=False, debug_print=False) # or at least\n",
    "    active_peak_prominence_2d_results = curr_active_pipeline.computation_results[active_config_name].computed_data.get('RatemapPeaksAnalysis', {}).get('PeakProminence2D', None)\n",
    "    assert active_peak_prominence_2d_results is not None, f\"bad even after computation\"\n",
    "\n",
    "# active_peak_prominence_2d_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7706d485",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(active_peak_prominence_2d_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238f67cb",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all",
     "run-continuous-decoding",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalDecodersContinuouslyDecodedResult\n",
    "\n",
    "if 'DirectionalDecodersDecoded' in curr_active_pipeline.global_computation_results.computed_data:\n",
    "    directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "    all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "    pseudo2D_decoder: BasePositionDecoder = directional_decoders_decode_result.pseudo2D_decoder\n",
    "    spikes_df = directional_decoders_decode_result.spikes_df\n",
    "    continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "    previously_decoded_keys: List[float] = list(continuously_decoded_result_cache_dict.keys()) # [0.03333]\n",
    "    print(F'previously_decoded time_bin_sizes: {previously_decoded_keys}')\n",
    "    \n",
    "    time_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\n",
    "    print(f'time_bin_size: {time_bin_size}')\n",
    "    continuously_decoded_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_decode_result.most_recent_continuously_decoded_dict\n",
    "    all_directional_continuously_decoded_dict = continuously_decoded_dict or {} ## what is plotted in the `f'{a_decoder_name}_ContinuousDecode'` rows by `AddNewDirectionalDecodedEpochs_MatplotlibPlotCommand`\n",
    "    all_directional_continuously_decoded_dict\n",
    "\n",
    "    pseudo2D_decoder_continuously_decoded_result: DecodedFilterEpochsResult = continuously_decoded_dict.get('pseudo2D', None)\n",
    "    assert len(pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list) == 1\n",
    "    p_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0]\n",
    "    # p_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0]['p_x_given_n']\n",
    "    time_bin_containers = pseudo2D_decoder_continuously_decoded_result.time_bin_containers[0]\n",
    "    time_window_centers = time_bin_containers.centers\n",
    "    # p_x_given_n.shape # (62, 4, 209389)\n",
    "\n",
    "    ## Split across the 2nd axis to make 1D posteriors that can be displayed in separate dock rows:\n",
    "    assert p_x_given_n.shape[1] == 4, f\"expected the 4 pseudo-y bins for the decoder in p_x_given_n.shape[1]. but found p_x_given_n.shape: {p_x_given_n.shape}\"\n",
    "    split_pseudo2D_posteriors_dict = {k:np.squeeze(p_x_given_n[:, i, :]) for i, k in enumerate(('long_LR', 'long_RL', 'short_LR', 'short_RL'))}\n",
    "    split_pseudo2D_posteriors_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d92b4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_decoders_decode_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e1ee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_directional_pf1D_Decoder_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b4e959",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.SequenceBasedComputations import WCorrShuffle, SequenceBasedComputationsContainer\n",
    "\n",
    "wcorr_shuffle_results: SequenceBasedComputationsContainer = curr_active_pipeline.global_computation_results.computed_data.get('SequenceBased', None)\n",
    "if wcorr_shuffle_results is not None:    \n",
    "    wcorr_ripple_shuffle: WCorrShuffle = wcorr_shuffle_results.wcorr_ripple_shuffle\n",
    "    if wcorr_ripple_shuffle is not None:\n",
    "        print(f'wcorr_ripple_shuffle.n_completed_shuffles: {wcorr_ripple_shuffle.n_completed_shuffles}')\n",
    "    else:\n",
    "        print(f'SequenceBased is computed but `wcorr_shuffle_results.wcorr_ripple_shuffle` is None.')        \n",
    "else:\n",
    "    print(f'SequenceBased is not computed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e9cc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['trial_by_trial_metrics'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "directional_trial_by_trial_activity_result = curr_active_pipeline.global_computation_results.computed_data.get('TrialByTrialActivity', None) ## try again to get the result\n",
    "assert directional_trial_by_trial_activity_result is not None, f\"directional_trial_by_trial_activity_result is None even after forcing recomputation!!\"\n",
    "print(f'\\t done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d7394a",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.reliability import TrialByTrialActivity\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrialByTrialActivityResult\n",
    "\n",
    "directional_trial_by_trial_activity_result: TrialByTrialActivityResult = curr_active_pipeline.global_computation_results.computed_data.get('TrialByTrialActivity', None)\n",
    "if directional_trial_by_trial_activity_result is None:\n",
    "    # if `KeyError: 'TrialByTrialActivity'` recompute\n",
    "    print(f'TrialByTrialActivity is not computed, computing it...')\n",
    "    curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['trial_by_trial_metrics'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "    directional_trial_by_trial_activity_result = curr_active_pipeline.global_computation_results.computed_data.get('TrialByTrialActivity', None) ## try again to get the result\n",
    "    assert directional_trial_by_trial_activity_result is not None, f\"directional_trial_by_trial_activity_result is None even after forcing recomputation!!\"\n",
    "    print(f'\\t done.')\n",
    "\n",
    "## unpack either way:\n",
    "any_decoder_neuron_IDs = directional_trial_by_trial_activity_result.any_decoder_neuron_IDs\n",
    "active_pf_dt: PfND_TimeDependent = directional_trial_by_trial_activity_result.active_pf_dt\n",
    "directional_lap_epochs_dict: Dict[str, Epoch] = directional_trial_by_trial_activity_result.directional_lap_epochs_dict\n",
    "directional_active_lap_pf_results_dicts: Dict[str, TrialByTrialActivity] = directional_trial_by_trial_activity_result.directional_active_lap_pf_results_dicts\n",
    "stability_dict = {k:list(v.aclu_to_stability_score_dict.values()) for k,v in directional_active_lap_pf_results_dicts.items()}\n",
    "stability_df: pd.DataFrame = pd.DataFrame({'aclu': any_decoder_neuron_IDs, **stability_dict})\n",
    "## OUTPUTS: stability_df, stability_dict\n",
    "\n",
    "## OUTPUTS: directional_trial_by_trial_activity_result, directional_active_lap_pf_results_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fad74c",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "wcorr_shuffle_results: SequenceBasedComputationsContainer = curr_active_pipeline.global_computation_results.computed_data.get('SequenceBased', None)\n",
    "if wcorr_shuffle_results is not None:    \n",
    "    wcorr_ripple_shuffle: WCorrShuffle = wcorr_shuffle_results.wcorr_ripple_shuffle\n",
    "    if wcorr_ripple_shuffle is not None:  \n",
    "        print(f'wcorr_ripple_shuffle.n_completed_shuffles: {wcorr_ripple_shuffle.n_completed_shuffles}')\n",
    "    else:\n",
    "        print(f'SequenceBased is computed but wcorr_ripple_shuffle is None.')\n",
    "else:\n",
    "    print(f'SequenceBased is not computed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ed0870",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "run-continuous-decoding",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult, SingleEpochDecodedResult\n",
    "\n",
    "most_recent_time_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\n",
    "# most_recent_time_bin_size\n",
    "most_recent_continuously_decoded_dict = deepcopy(directional_decoders_decode_result.most_recent_continuously_decoded_dict)\n",
    "# most_recent_continuously_decoded_dict\n",
    "\n",
    "## Adds in the 'pseudo2D' decoder in:\n",
    "time_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\n",
    "# time_bin_size: float = 0.01\n",
    "print(f'time_bin_size: {time_bin_size}')\n",
    "continuously_decoded_dict = continuously_decoded_result_cache_dict[time_bin_size]\n",
    "pseudo2D_decoder_continuously_decoded_result = continuously_decoded_dict.get('pseudo2D', None)\n",
    "if pseudo2D_decoder_continuously_decoded_result is None:\n",
    "    # compute here...\n",
    "    ## Currently used for both cases to decode:\n",
    "    t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "    single_global_epoch_df: pd.DataFrame = pd.DataFrame({'start': [t_start], 'stop': [t_end], 'label': [0]}) # Build an Epoch object containing a single epoch, corresponding to the global epoch for the entire session:\n",
    "    single_global_epoch: Epoch = Epoch(single_global_epoch_df)\n",
    "    spikes_df = directional_decoders_decode_result.spikes_df\n",
    "    pseudo2D_decoder_continuously_decoded_result: DecodedFilterEpochsResult = pseudo2D_decoder.decode_specific_epochs(spikes_df=deepcopy(spikes_df), filter_epochs=single_global_epoch, decoding_time_bin_size=time_bin_size, debug_print=False)\n",
    "    continuously_decoded_dict['pseudo2D'] = pseudo2D_decoder_continuously_decoded_result\n",
    "    continuously_decoded_dict\n",
    "    \n",
    "pseudo2D_decoder_continuously_decoded_single_result: SingleEpochDecodedResult = pseudo2D_decoder_continuously_decoded_result.get_result_for_epoch(0)\n",
    "pseudo2D_decoder_continuously_decoded_single_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eab4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudo2D_decoder_continuously_decoded_single_result.epoch_info_tuple\n",
    "pseudo2D_decoder_continuously_decoded_single_result.nbins\n",
    "pseudo2D_decoder_continuously_decoded_single_result.p_x_given_n\n",
    "pseudo2D_decoder_continuously_decoded_single_result.p_x_given_n.shape # (57, 4, 29951)\n",
    "\n",
    "\n",
    "short_RL_only = pseudo2D_decoder_continuously_decoded_single_result.p_x_given_n[:, 3, :]\n",
    "np.shape(short_RL_only)\n",
    "\n",
    "debug_portion_short_RL_only = short_RL_only[:, :1000]\n",
    "\n",
    "\n",
    "plt.figure(clear=True)\n",
    "plt.imshow(debug_portion_short_RL_only)\n",
    "# plt.plot(np.sum(short_RL_only, axis=0))\n",
    "# plt.plot(np.cumsum(np.sum(short_RL_only, axis=0)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f48287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88344ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import SingleEpochDecodedResult\n",
    "\n",
    "\n",
    "only_result.p_x_given_n\n",
    "only_result.time_bin_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ee77bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo2D_decoder_continuously_decoded_result.filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2dc5fe",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "# NEW 2023-11-22 method: Get the templates (which can be filtered by frate first) and the from those get the decoders):        \n",
    "# track_templates: TrackTemplates = directional_laps_results.get_shared_aclus_only_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # shared-only\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, included_qclu_values=included_qclu_values) # non-shared-only\n",
    "long_LR_decoder, long_RL_decoder, short_LR_decoder, short_RL_decoder = track_templates.get_decoders()\n",
    "\n",
    "# Unpack all directional variables:\n",
    "## {\"even\": \"RL\", \"odd\": \"LR\"}\n",
    "long_LR_name, short_LR_name, global_LR_name, long_RL_name, short_RL_name, global_RL_name, long_any_name, short_any_name, global_any_name = ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "# Unpacking for `(long_LR_name, long_RL_name, short_LR_name, short_RL_name)`\n",
    "(long_LR_context, long_RL_context, short_LR_context, short_RL_context) = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj, global_any_laps_epochs_obj = [curr_active_pipeline.computation_results[an_epoch_name].computation_config.pf_params.computation_epochs for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name, global_any_name)] # note has global also\n",
    "(long_LR_session, long_RL_session, short_LR_session, short_RL_session) = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)] # sessions are correct at least, seems like just the computation parameters are messed up\n",
    "(long_LR_results, long_RL_results, short_LR_results, short_RL_results) = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_computation_config, long_RL_computation_config, short_LR_computation_config, short_RL_computation_config) = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_pf1D, long_RL_pf1D, short_LR_pf1D, short_RL_pf1D) = (long_LR_results.pf1D, long_RL_results.pf1D, short_LR_results.pf1D, short_RL_results.pf1D)\n",
    "(long_LR_pf2D, long_RL_pf2D, short_LR_pf2D, short_RL_pf2D) = (long_LR_results.pf2D, long_RL_results.pf2D, short_LR_results.pf2D, short_RL_results.pf2D)\n",
    "(long_LR_pf1D_Decoder, long_RL_pf1D_Decoder, short_LR_pf1D_Decoder, short_RL_pf1D_Decoder) = (long_LR_results.pf1D_Decoder, long_RL_results.pf1D_Decoder, short_LR_results.pf1D_Decoder, short_RL_results.pf1D_Decoder)\n",
    "\n",
    "if rank_order_results is not None:\n",
    "    # `LongShortStatsItem` form (2024-01-02):\n",
    "    # LR_results_real_values = np.array([(a_result_item.long_stats_z_scorer.real_value, a_result_item.short_stats_z_scorer.real_value) for epoch_id, a_result_item in rank_order_results.LR_ripple.ranked_aclus_stats_dict.items()])\n",
    "    # RL_results_real_values = np.array([(a_result_item.long_stats_z_scorer.real_value, a_result_item.short_stats_z_scorer.real_value) for epoch_id, a_result_item in rank_order_results.RL_ripple.ranked_aclus_stats_dict.items()])\n",
    "    LR_results_long_short_z_diffs = np.array([a_result_item.long_short_z_diff for epoch_id, a_result_item in rank_order_results.LR_ripple.ranked_aclus_stats_dict.items()])\n",
    "    RL_results_long_short_z_diff = np.array([a_result_item.long_short_z_diff for epoch_id, a_result_item in rank_order_results.RL_ripple.ranked_aclus_stats_dict.items()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c260739a4f36c662",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrainTestSplitResult\n",
    "\n",
    "if 'TrainTestSplit' in curr_active_pipeline.global_computation_results.computed_data:\n",
    "    directional_train_test_split_result: TrainTestSplitResult = curr_active_pipeline.global_computation_results.computed_data.get('TrainTestSplit', None)\n",
    "    training_data_portion: float = directional_train_test_split_result.training_data_portion\n",
    "    test_data_portion: float = directional_train_test_split_result.test_data_portion\n",
    "    test_epochs_dict: Dict[str, pd.DataFrame] = directional_train_test_split_result.test_epochs_dict\n",
    "    train_epochs_dict: Dict[str, pd.DataFrame] = directional_train_test_split_result.train_epochs_dict\n",
    "    train_lap_specific_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_train_test_split_result.train_lap_specific_pf1D_Decoder_dict\n",
    "    \n",
    "long_LR_name, short_LR_name, global_LR_name, long_RL_name, short_RL_name, global_RL_name, long_any_name, short_any_name, global_any_name = ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj = [curr_active_pipeline.computation_results[an_epoch_name].computation_config.pf_params.computation_epochs for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)] # note has global also\n",
    "long_LR_name, long_RL_name, short_LR_name, short_RL_name = track_templates.get_decoder_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec18cf18",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "if 'burst_detection' in curr_active_pipeline.computation_results[global_epoch_name].computed_data:\n",
    "    active_burst_intervals = curr_active_pipeline.computation_results[global_epoch_name].computed_data['burst_detection']['burst_intervals']\n",
    "# active_burst_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d31f37d",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "active_extended_stats = global_results.get('extended_stats', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9554d3bf5955d9d3",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "# Time-dependent\n",
    "long_pf1D_dt, short_pf1D_dt, global_pf1D_dt = long_results.pf1D_dt, short_results.pf1D_dt, global_results.pf1D_dt\n",
    "long_pf2D_dt, short_pf2D_dt, global_pf2D_dt = long_results.pf2D_dt, short_results.pf2D_dt, global_results.pf2D_dt\n",
    "global_pf1D_dt: PfND_TimeDependent = global_results.pf1D_dt\n",
    "global_pf2D_dt: PfND_TimeDependent = global_results.pf2D_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7a8050",
   "metadata": {},
   "outputs": [],
   "source": [
    "## long_short_endcap_analysis: checks for cells localized to the endcaps that have their placefields truncated after shortening the track\n",
    "truncation_checking_result: TruncationCheckingResults = curr_active_pipeline.global_computation_results.computed_data.long_short_endcap\n",
    "disappearing_endcap_aclus = truncation_checking_result.disappearing_endcap_aclus\n",
    "# disappearing_endcap_aclus\n",
    "trivially_remapping_endcap_aclus = truncation_checking_result.minor_remapping_endcap_aclus\n",
    "# trivially_remapping_endcap_aclus\n",
    "significant_distant_remapping_endcap_aclus = truncation_checking_result.significant_distant_remapping_endcap_aclus\n",
    "# significant_distant_remapping_endcap_aclus\n",
    "# appearing_aclus = jonathan_firing_rate_analysis_result.neuron_replay_stats_df[jonathan_firing_rate_analysis_result.neuron_replay_stats_df['track_membership'] == SplitPartitionMembership.RIGHT_ONLY].index\n",
    "# appearing_aclus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8ff5d1",
   "metadata": {},
   "source": [
    "# <a id='toc5_'></a>[1️⃣ POST-Compute:](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728c46e6",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "21"
    },
    "tags": [
     "unwrap",
     "initial",
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalDisplayFunctions\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multi_sort_raster_browser\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.RankOrderRastersDebugger import RankOrderRastersDebugger\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import paired_separately_sort_neurons, paired_incremental_sort_neurons # _display_directional_template_debugger\n",
    "from neuropy.utils.indexing_helpers import paired_incremental_sorting, union_of_arrays, intersection_of_arrays, find_desired_sort_indicies\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.ScrollBarWithSpinBox.ScrollBarWithSpinBox import ScrollBarWithSpinBox\n",
    "\n",
    "from neuropy.utils.mixins.HDF5_representable import HDF_SerializationMixin\n",
    "from pyphoplacecellanalysis.General.Model.ComputationResults import ComputedResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderAnalyses, RankOrderResult, ShuffleHelper, Zscorer, LongShortStatsTuple, DirectionalRankOrderLikelihoods, DirectionalRankOrderResult, RankOrderComputationsContainer\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import TimeColumnAliasesProtocol\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderComputationsContainer\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import DirectionalRankOrderResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "\n",
    "## Display Testing\n",
    "# from pyphoplacecellanalysis.External.pyqtgraph import QtGui\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.Extensions.pyqtgraph_helpers import pyqtplot_build_image_bounds_extent, pyqtplot_plot_image\n",
    "\n",
    "spikes_df = curr_active_pipeline.sess.spikes_df\n",
    "rank_order_results: RankOrderComputationsContainer = curr_active_pipeline.global_computation_results.computed_data.get('RankOrder', None)\n",
    "if rank_order_results is not None:\n",
    "    minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "    ripple_result_tuple, laps_result_tuple = rank_order_results.ripple_most_likely_result_tuple, rank_order_results.laps_most_likely_result_tuple\n",
    "\n",
    "else:        \n",
    "    ## get from parameters:\n",
    "    minimum_inclusion_fr_Hz: float = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.included_qclu_values\n",
    "\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, included_qclu_values=included_qclu_values) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\n",
    "print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "print(f'included_qclu_values: {included_qclu_values}')\n",
    "# ripple_result_tuple\n",
    "\n",
    "\n",
    "# directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "# directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)\n",
    "\n",
    "# pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "# ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "# laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "# decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict\n",
    "# decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict\n",
    "\n",
    "\n",
    "## Unpacks `rank_order_results`: \n",
    "# global_replays = Epoch(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].replay))\n",
    "# global_replays = TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].replay))\n",
    "# active_replay_epochs, active_epochs_df, active_selected_spikes_df = combine_rank_order_results(rank_order_results, global_replays, track_templates=track_templates)\n",
    "# active_epochs_df\n",
    "\n",
    "# ripple_result_tuple.directional_likelihoods_tuple.long_best_direction_indices\n",
    "dir_index_to_direction_name_map: Dict[int, str] = {0:'LR', 1:\"RL\"}\n",
    "\n",
    "if rank_order_results is not None:\n",
    "    ## All three DataFrames are the same number of rows, each with one row corresponding to an Epoch:\n",
    "    active_replay_epochs_df = deepcopy(rank_order_results.LR_ripple.epochs_df)\n",
    "    # active_replay_epochs_df\n",
    "\n",
    "    # Change column type to int8 for columns: 'long_best_direction_indices', 'short_best_direction_indices'\n",
    "    # directional_likelihoods_df = pd.DataFrame.from_dict(ripple_result_tuple.directional_likelihoods_tuple._asdict()).astype({'long_best_direction_indices': 'int8', 'short_best_direction_indices': 'int8'})\n",
    "    directional_likelihoods_df = ripple_result_tuple.directional_likelihoods_df\n",
    "    # directional_likelihoods_df\n",
    "\n",
    "    # 2023-12-15 - Newest method:\n",
    "    laps_merged_complete_epoch_stats_df: pd.DataFrame = rank_order_results.laps_merged_complete_epoch_stats_df ## New method\n",
    "    ripple_merged_complete_epoch_stats_df: pd.DataFrame = rank_order_results.ripple_merged_complete_epoch_stats_df ## New method\n",
    "\n",
    "\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "\n",
    "all_directional_decoder_dict_value = directional_merged_decoders_result.all_directional_decoder_dict\n",
    "all_directional_pf1D_Decoder_value = directional_merged_decoders_result.all_directional_pf1D_Decoder\n",
    "# long_directional_pf1D_Decoder_value = directional_merged_decoders_result.long_directional_pf1D_Decoder\n",
    "# long_directional_decoder_dict_value = directional_merged_decoders_result.long_directional_decoder_dict\n",
    "# short_directional_pf1D_Decoder_value = directional_merged_decoders_result.short_directional_pf1D_Decoder\n",
    "# short_directional_decoder_dict_value = directional_merged_decoders_result.short_directional_decoder_dict\n",
    "\n",
    "all_directional_laps_filter_epochs_decoder_result_value = directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result\n",
    "all_directional_ripple_filter_epochs_decoder_result_value = directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result\n",
    "\n",
    "laps_directional_marginals, laps_directional_all_epoch_bins_marginal, laps_most_likely_direction_from_decoder, laps_is_most_likely_direction_LR_dir  = directional_merged_decoders_result.laps_directional_marginals_tuple\n",
    "laps_track_identity_marginals, laps_track_identity_all_epoch_bins_marginal, laps_most_likely_track_identity_from_decoder, laps_is_most_likely_track_identity_Long = directional_merged_decoders_result.laps_track_identity_marginals_tuple\n",
    "ripple_directional_marginals, ripple_directional_all_epoch_bins_marginal, ripple_most_likely_direction_from_decoder, ripple_is_most_likely_direction_LR_dir  = directional_merged_decoders_result.ripple_directional_marginals_tuple\n",
    "ripple_track_identity_marginals, ripple_track_identity_all_epoch_bins_marginal, ripple_most_likely_track_identity_from_decoder, ripple_is_most_likely_track_identity_Long = directional_merged_decoders_result.ripple_track_identity_marginals_tuple\n",
    "\n",
    "ripple_decoding_time_bin_size: float = directional_merged_decoders_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_merged_decoders_result.laps_decoding_time_bin_size\n",
    "\n",
    "print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}, ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}')\n",
    "\n",
    "laps_all_epoch_bins_marginals_df = directional_merged_decoders_result.laps_all_epoch_bins_marginals_df\n",
    "ripple_all_epoch_bins_marginals_df = directional_merged_decoders_result.ripple_all_epoch_bins_marginals_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d2f342",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_merged_complete_epoch_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdb4ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_directional_marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753ca336",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "# from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import HeuristicReplayScoring\n",
    "from neuropy.core.epoch import find_data_indicies_from_epoch_times\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_filter_replay_epochs\n",
    "\n",
    "# filtered_epochs_df, filtered_decoder_filter_epochs_decoder_result_dict, filtered_ripple_all_epoch_bins_marginals_df = None, None, None\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-_perform_filter_replay_epochs.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "filtered_epochs_df, filtered_decoder_filter_epochs_decoder_result_dict, filtered_ripple_all_epoch_bins_marginals_df = _perform_filter_replay_epochs(curr_active_pipeline, global_epoch_name, track_templates, decoder_ripple_filter_epochs_decoder_result_dict, ripple_all_epoch_bins_marginals_df, ripple_decoding_time_bin_size=ripple_decoding_time_bin_size, should_only_include_user_selected_epochs=False)\n",
    "filtered_epochs_df\n",
    "# filtered_ripple_all_epoch_bins_marginals_df\n",
    "\n",
    "## 1m 38s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a32882",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ripple_all_epoch_bins_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92aad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_sess: DataSession = curr_active_pipeline.sess\n",
    "global_session.compute_pbe_epochs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca48dd6",
   "metadata": {},
   "source": [
    "### <a id='toc5_1_1_'></a>[2024-06-25 - Advanced Time-dependent decoding:](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c76fbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Directional Versions: 'long_LR':\n",
    "from neuropy.core.epoch import subdivide_epochs, ensure_dataframe\n",
    "\n",
    "\n",
    "## INPUTS: long_LR_epochs_obj, long_LR_results\n",
    "\n",
    "a_pf1D_dt: PfND_TimeDependent = deepcopy(long_LR_results.pf1D_dt)\n",
    "a_pf2D_dt: PfND_TimeDependent = deepcopy(long_LR_results.pf2D_dt)\n",
    "\n",
    "# Example usage\n",
    "df: pd.DataFrame = ensure_dataframe(deepcopy(long_LR_epochs_obj)) \n",
    "df['epoch_type'] = 'lap'\n",
    "df['interval_type_id'] = 666\n",
    "\n",
    "# subdivide_bin_size = 0.200  # Specify the size of each sub-epoch in seconds\n",
    "subdivide_bin_size = 0.050\n",
    "subdiv_df: pd.DataFrame = subdivide_epochs(df, subdivide_bin_size)\n",
    "# print(subdivided_df)\n",
    "\n",
    "## Evolve the ratemaps:\n",
    "_a_pf1D_dt_snapshots = a_pf1D_dt.batch_snapshotting(subdiv_df, reset_at_start=True)\n",
    "_a_pf2D_dt_snapshots = a_pf2D_dt.batch_snapshotting(subdiv_df, reset_at_start=True)\n",
    "# a_pf2D_dt.plot_ratemaps_2D()\n",
    "\n",
    "## takes about 2 mins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788d8b7e",
   "metadata": {},
   "source": [
    "# <a id='toc6_'></a>[/ 🛑 End Run Section 🛑](#toc0_)\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7433b81f",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "## Find the time series of Long-likely events\n",
    "# type(long_RL_results) # DynamicParameters\n",
    "long_LR_pf1D_Decoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d2363d",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "type(all_directional_decoder_dict_value)\n",
    "list(all_directional_decoder_dict_value.keys()) # ['long_LR', 'long_RL', 'short_LR', 'short_RL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634e6027",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "laps_all_epoch_bins_marginals_df\n",
    "laps_most_likely_direction_from_decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdabd71",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "type(ripple_result_tuple) # pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations.DirectionalRankOrderResult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fca534c",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "assert isinstance(ripple_result_tuple, DirectionalRankOrderResult) \n",
    "\n",
    "ripple_result_tuple.plot_histograms(num='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15629dae",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import DirectionalRankOrderResult\n",
    "from pyphocorehelpers.DataStructure.RenderPlots.MatplotLibRenderPlots import MatplotlibRenderPlots \n",
    "\n",
    "# @register_type_display(DirectionalRankOrderResult)\n",
    "def plot_histograms(self: DirectionalRankOrderResult, **kwargs) -> \"MatplotlibRenderPlots\":\n",
    "    \"\"\" \n",
    "    num='RipplesRankOrderZscore'\n",
    "    \"\"\"\n",
    "    print(f'.plot_histograms(..., kwargs: {kwargs})')\n",
    "    fig = plt.figure(layout=\"constrained\", **kwargs)\n",
    "    ax_dict = fig.subplot_mosaic(\n",
    "        [\n",
    "            [\"long_short_best_z_score_diff\", \"long_short_best_z_score_diff\"],\n",
    "            [\"long_best_z_scores\", \"short_best_z_scores\"],\n",
    "        ],\n",
    "    )\n",
    "    plots = (pd.DataFrame({'long_best_z_scores': self.long_best_dir_z_score_values}).hist(ax=ax_dict['long_best_z_scores'], bins=21, alpha=0.8),\n",
    "        pd.DataFrame({'short_best_z_scores': self.short_best_dir_z_score_values}).hist(ax=ax_dict['short_best_z_scores'], bins=21, alpha=0.8),\n",
    "        pd.DataFrame({'long_short_best_z_score_diff': self.long_short_best_dir_z_score_diff_values}).hist(ax=ax_dict['long_short_best_z_score_diff'], bins=21, alpha=0.8),\n",
    "    )\n",
    "    return MatplotlibRenderPlots(name='plot_histogram_figure', figures=[fig], axes=ax_dict)\n",
    "\n",
    "\n",
    "# register_type_display(plot_histograms, DirectionalRankOrderResult)\n",
    "## Call the newly added `plot_histograms` function on the `ripple_result_tuple` object which is of type `DirectionalRankOrderResult`:\n",
    "assert isinstance(ripple_result_tuple, DirectionalRankOrderResult) \n",
    "ripple_result_tuple.plot_histograms(num='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c291690",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "ripple_result_tuple.plot_histograms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b30bcb",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# 💾 CSVs \n",
    "print(f'\\t try saving to CSV...')\n",
    "merged_complete_epoch_stats_df = rank_order_results.ripple_merged_complete_epoch_stats_df ## New method\n",
    "merged_complete_epoch_stats_df\n",
    "merged_complete_ripple_epoch_stats_df_output_path = curr_active_pipeline.get_output_path().joinpath(f'{DAY_DATE_TO_USE}_merged_complete_epoch_stats_df.csv').resolve()\n",
    "merged_complete_epoch_stats_df.to_csv(merged_complete_ripple_epoch_stats_df_output_path)\n",
    "print(f'\\t saving to CSV: {merged_complete_ripple_epoch_stats_df_output_path} done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60749347",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "all",
     "active-2025-01-20"
    ]
   },
   "outputs": [],
   "source": [
    "print(f'\\tdone. building global result.')\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "selected_spikes_df = deepcopy(curr_active_pipeline.global_computation_results.computed_data['RankOrder'].LR_ripple.selected_spikes_df)\n",
    "# active_epochs = global_computation_results.computed_data['RankOrder'].ripple_most_likely_result_tuple.active_epochs\n",
    "active_epochs = deepcopy(curr_active_pipeline.global_computation_results.computed_data['RankOrder'].LR_ripple.epochs_df)\n",
    "track_templates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz)\n",
    "\n",
    "ripple_combined_epoch_stats_df, ripple_new_output_tuple = RankOrderAnalyses.pandas_df_based_correlation_computations(selected_spikes_df=selected_spikes_df, active_epochs_df=active_epochs, track_templates=track_templates, num_shuffles=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313886d9",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# new_output_tuple (output_active_epoch_computed_values, valid_stacked_arrays, real_stacked_arrays, n_valid_shuffles) = ripple_new_output_tuple\n",
    "curr_active_pipeline.global_computation_results.computed_data['RankOrder'].ripple_combined_epoch_stats_df, curr_active_pipeline.global_computation_results.computed_data['RankOrder'].ripple_new_output_tuple = ripple_combined_epoch_stats_df, ripple_new_output_tuple\n",
    "print(f'done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6f086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Display the `TrainTestSplitResult` in a `PhoPaginatedMultiDecoderDecodedEpochsWindow`\n",
    "from neuropy.core.epoch import Epoch, ensure_dataframe\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import add_laps_groundtruth_information_to_dataframe\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import PhoPaginatedMultiDecoderDecodedEpochsWindow\n",
    "\n",
    "## INPUTS: train_decoded_results_dict\n",
    "# decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs # looks like 'lap_dir' column is wrong\n",
    "\n",
    "# active_results: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(decoder_laps_filter_epochs_decoder_result_dict)\n",
    "active_results: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy({k:v.decoder_result for k, v in _out_separate_decoder_results[0].items()})\n",
    "\n",
    "laps_app, laps_paginated_multi_decoder_decoded_epochs_window, laps_pagination_controller_dict = PhoPaginatedMultiDecoderDecodedEpochsWindow.init_from_track_templates(curr_active_pipeline, track_templates,\n",
    "                            decoder_decoded_epochs_result_dict=active_results, epochs_name='laps', included_epoch_indicies=None, \n",
    "    params_kwargs={'enable_per_epoch_action_buttons': False,\n",
    "    'skip_plotting_most_likely_positions': False, 'skip_plotting_measured_positions': False, \n",
    "    # 'enable_decoded_most_likely_position_curve': False, 'enable_radon_transform_info': True, 'enable_weighted_correlation_info': False,\n",
    "    'enable_decoded_most_likely_position_curve': True, 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': False,\n",
    "    # 'disable_y_label': True,\n",
    "    # 'isPaginatorControlWidgetBackedMode': True,\n",
    "    # 'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True,\n",
    "    # 'debug_print': True,\n",
    "    'max_subplots_per_page': 10,\n",
    "    'scrollable_figure': True,\n",
    "    # 'posterior_heatmap_imshow_kwargs': dict(vmin=0.0075),\n",
    "    'use_AnchoredCustomText': False,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3d15bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_build_individual_time_bin_decoded_posteriors_df\n",
    "\n",
    "transfer_column_names_list: List[str] = ['maze_id', 'lap_dir', 'lap_id']\n",
    "filtered_laps_time_bin_marginals_df = _perform_build_individual_time_bin_decoded_posteriors_df(curr_active_pipeline, track_templates=track_templates, all_directional_laps_filter_epochs_decoder_result=all_directional_laps_filter_epochs_decoder_result, transfer_column_names_list=transfer_column_names_list)\n",
    "filtered_laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e0053b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import co_filter_epochs_and_spikes\n",
    "\n",
    "## INPUTS: all_directional_laps_filter_epochs_decoder_result\n",
    "transfer_column_names_list: List[str] = ['maze_id', 'lap_dir', 'lap_id']\n",
    "TIME_OVERLAP_PREVENTION_EPSILON: float = 1e-12\n",
    "(laps_directional_marginals_tuple, laps_track_identity_marginals_tuple, laps_non_marginalized_decoder_marginals_tuple), laps_marginals_df = all_directional_laps_filter_epochs_decoder_result.compute_marginals(epoch_idx_col_name='lap_idx', epoch_start_t_col_name='lap_start_t',\n",
    "                                                                                                                                                    additional_transfer_column_names=['start','stop','label','duration','lap_id','lap_dir','maze_id','is_LR_dir'])\n",
    "laps_directional_marginals, laps_directional_all_epoch_bins_marginal, laps_most_likely_direction_from_decoder, laps_is_most_likely_direction_LR_dir  = laps_directional_marginals_tuple\n",
    "laps_track_identity_marginals, laps_track_identity_all_epoch_bins_marginal, laps_most_likely_track_identity_from_decoder, laps_is_most_likely_track_identity_Long = laps_track_identity_marginals_tuple\n",
    "non_marginalized_decoder_marginals, non_marginalized_decoder_all_epoch_bins_marginal, most_likely_decoder_idxs, non_marginalized_decoder_all_epoch_bins_decoder_probs_df = laps_non_marginalized_decoder_marginals_tuple\n",
    "laps_time_bin_marginals_df: pd.DataFrame = all_directional_laps_filter_epochs_decoder_result.build_per_time_bin_marginals_df(active_marginals_tuple=(laps_directional_marginals, laps_track_identity_marginals, non_marginalized_decoder_marginals),\n",
    "                                                                                                                              columns_tuple=(['P_LR', 'P_RL'], ['P_Long', 'P_Short'], ['long_LR', 'long_RL', 'short_LR', 'short_RL']), transfer_column_names_list=transfer_column_names_list)\n",
    "laps_time_bin_marginals_df['start'] = laps_time_bin_marginals_df['start'] + TIME_OVERLAP_PREVENTION_EPSILON ## ENSURE NON-OVERLAPPING\n",
    "\n",
    "## INPUTS: laps_time_bin_marginals_df\n",
    "# active_min_num_unique_aclu_inclusions_requirement: int = track_templates.min_num_unique_aclu_inclusions_requirement(curr_active_pipeline, required_min_percentage_of_active_cells=0.33333333333333)\n",
    "active_min_num_unique_aclu_inclusions_requirement = None # must be none for individual `time_bin` periods\n",
    "filtered_laps_time_bin_marginals_df, active_spikes_df = co_filter_epochs_and_spikes(active_spikes_df=get_proper_global_spikes_df(curr_active_pipeline, minimum_inclusion_fr_Hz=curr_active_pipeline.global_computation_config.rank_order_shuffle_analysis.minimum_inclusion_fr_Hz),\n",
    "                                                                  active_epochs_df=laps_time_bin_marginals_df, included_aclus=track_templates.any_decoder_neuron_IDs, min_num_unique_aclu_inclusions=active_min_num_unique_aclu_inclusions_requirement,\n",
    "                                                                epoch_id_key_name='lap_individual_time_bin_id', no_interval_fill_value=-1, add_unique_aclus_list_column=True, drop_non_epoch_spikes=True)\n",
    "filtered_laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff8fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean and max number of active aclus per time bin for each epoch (lap)\n",
    "filtered_laps_time_bin_marginals_df.groupby(['lap_id']).agg(n_unique_aclus_mean=('n_unique_aclus', 'mean'), n_unique_aclus_max=('n_unique_aclus', 'max')).reset_index()\n",
    "filtered_laps_time_bin_marginals_df.groupby(['maze_id']).agg(n_unique_aclus_mean=('n_unique_aclus', 'mean'), n_unique_aclus_max=('n_unique_aclus', 'max')).reset_index() ## per maze\n",
    "filtered_laps_time_bin_marginals_df.groupby(['maze_id', 'lap_dir']).agg(n_unique_aclus_mean=('n_unique_aclus', 'mean'), n_unique_aclus_max=('n_unique_aclus', 'max')).reset_index() # per maze x lap_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e6cdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cb39d3",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# {frozenset({('desired_shared_decoding_time_bin_size', 0.025), ('minimum_event_duration', 0.05), ('use_single_time_bin_per_epoch', False)}): 0.025,\n",
    "#  frozenset({('desired_shared_decoding_time_bin_size', 0.03), ('minimum_event_duration', 0.05), ('use_single_time_bin_per_epoch', False)}): 0.03,\n",
    "#  frozenset({('desired_shared_decoding_time_bin_size', 0.044), ('minimum_event_duration', 0.05), ('use_single_time_bin_per_epoch', False)}): 0.044,\n",
    "#  frozenset({('desired_shared_decoding_time_bin_size', 0.05), ('minimum_event_duration', 0.05), ('use_single_time_bin_per_epoch', False)}): 0.05}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d4ce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_trial_by_trial_result.directional_active_lap_pf_results_dicts\n",
    "a_trial_by_trial_result.directional_lap_epochs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944c59a0",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "several_time_bin_sizes_ripple_df\n",
    "\n",
    "ripple_out_path # 'K:/scratch/collected_outputs/2024-07-05-kdiba_gor01_two_2006-6-07_16-40-19__withNewKamranExportedReplays-(ripple_marginals_df).csv'\n",
    "# 'K:/scratch/collected_outputs/2024-07-05-kdiba_gor01_two_2006-6-07_16-40-19__withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-(ripple_marginals_df).csv'\n",
    "several_time_bin_sizes_time_bin_ripple_df\n",
    "\n",
    "ripple_time_bin_marginals_out_path # 'K:/scratch/collected_outputs/2024-07-05-kdiba_gor01_two_2006-6-07_16-40-19__withNewKamranExportedReplays-(ripple_time_bin_marginals_df).csv'\n",
    "# 'K:/scratch/collected_outputs/2024-07-05-kdiba_gor01_two_2006-6-07_16-40-19__withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-(ripple_time_bin_marginals_df).csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2dfa3e",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "v: DecoderDecodedEpochsResult = list(output_directional_decoders_epochs_decode_results_dict.values())[0]\n",
    "v.add_all_extra_epoch_columns(curr_active_pipeline=curr_active_pipeline, track_templates=track_templates)\n",
    "# _out = v.export_csvs(parent_output_path=collected_outputs_path, active_context=curr_active_pipeline.get_session_context(), session_name=curr_active_pipeline.session_name, curr_session_t_delta=t_delta)\n",
    "\n",
    "# assert self.collected_outputs_path.exists()\n",
    "# curr_session_name: str = curr_active_pipeline.session_name # '2006-6-08_14-26-15'\n",
    "# CURR_BATCH_OUTPUT_PREFIX: str = f\"{self.BATCH_DATE_TO_USE}-{curr_session_name}\"\n",
    "# print(f'CURR_BATCH_OUTPUT_PREFIX: {CURR_BATCH_OUTPUT_PREFIX}')\n",
    "\n",
    "# from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_extended_computations\n",
    "# curr_active_pipeline.reload_default_computation_functions()\n",
    "# batch_extended_computations(curr_active_pipeline, include_includelist=['merged_directional_placefields'], include_global_functions=True, fail_on_exception=True, force_recompute=False)\n",
    "# directional_merged_decoders_result = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "\n",
    "# active_context = curr_active_pipeline.get_session_context()\n",
    "# _out = directional_merged_decoders_result.compute_and_export_marginals_df_csvs(parent_output_path=self.collected_outputs_path, active_context=active_context)\n",
    "# print(f'successfully exported marginals_df_csvs to {self.collected_outputs_path}!')\n",
    "# (laps_marginals_df, laps_out_path), (ripple_marginals_df, ripple_out_path) = _out\n",
    "# (laps_marginals_df, laps_out_path, laps_time_bin_marginals_df, laps_time_bin_marginals_out_path), (ripple_marginals_df, ripple_out_path, ripple_time_bin_marginals_df, ripple_time_bin_marginals_out_path) = _out\n",
    "# print(f'\\tlaps_out_path: {laps_out_path}\\n\\tripple_out_path: {ripple_out_path}\\n\\tdone.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58b6311",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa94d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "_across_session_results_extended_dict['perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260a8b74",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "## Take extra computations from `_decode_and_evaluate_epochs_using_directional_decoders` and integrate into the multi-time-bin results from `perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _compute_all_df_score_metrics\n",
    "\n",
    "should_skip_radon_transform = True\n",
    "## Recompute the epoch scores/metrics such as radon transform and wcorr:\n",
    "\n",
    "a_sweep_tuple, a_pseudo_2D_result = list(output_full_directional_merged_decoders_result.items())[0]\n",
    "a_decoder_laps_filter_epochs_decoder_result_dict = deepcopy(a_pseudo_2D_result.all_directional_laps_filter_epochs_decoder_result)\n",
    "a_decoder_ripple_filter_epochs_decoder_result_dict = deepcopy(a_pseudo_2D_result.all_directional_ripple_filter_epochs_decoder_result)\n",
    "\n",
    "(decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict), merged_df_outputs_tuple, raw_dict_outputs_tuple = _compute_all_df_score_metrics(directional_merged_decoders_result, track_templates,\n",
    "                                                                                                                                                                                    decoder_laps_filter_epochs_decoder_result_dict=a_decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict=a_decoder_ripple_filter_epochs_decoder_result_dict,\n",
    "                                                                                                                                                                                    spikes_df=deepcopy(curr_active_pipeline.sess.spikes_df),\n",
    "                                                                                                                                                                                    should_skip_radon_transform=should_skip_radon_transform)\n",
    "laps_radon_transform_merged_df, ripple_radon_transform_merged_df, laps_weighted_corr_merged_df, ripple_weighted_corr_merged_df, laps_simple_pf_pearson_merged_df, ripple_simple_pf_pearson_merged_df = merged_df_outputs_tuple\n",
    "decoder_laps_radon_transform_df_dict, decoder_ripple_radon_transform_df_dict, decoder_laps_radon_transform_extras_dict, decoder_ripple_radon_transform_extras_dict, decoder_laps_weighted_corr_df_dict, decoder_ripple_weighted_corr_df_dict = raw_dict_outputs_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfda868",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# `_perform_compute_custom_epoch_decoding`\n",
    "\n",
    "a_sweep_tuple\n",
    "# a_pseudo_2D_result.all_directional_laps_filter_epochs_decoder_result\n",
    "# a_pseudo_2D_result\n",
    "# a_pseudo_2D_result.short_directional_decoder_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9603a0",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# print_keys_if_possible('several_time_bin_sizes_laps_df', several_time_bin_sizes_laps_df)\n",
    "print_keys_if_possible('output_full_directional_merged_decoders_result', output_full_directional_merged_decoders_result, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a71abd",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# get_file_pat\n",
    "collected_outputs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c0f606",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "output_laps_decoding_accuracy_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dd6f87",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# from neuropy.utils.matplotlib_helpers import pho_jointplot\n",
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import pho_jointplot, plot_histograms\n",
    "sns.set_theme(style=\"ticks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4b238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# from neuropy.utils.matplotlib_helpers import pho_jointplot\n",
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import pho_jointplot, plot_histograms\n",
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "# def pho_jointplot(*args, **kwargs):\n",
    "# \t\"\"\" wraps sns.jointplot to allow adding titles/axis labels/etc.\"\"\"\n",
    "# \ttitle = kwargs.pop('title', None)\n",
    "# \t_out = sns.jointplot(*args, **kwargs)\n",
    "# \tif title is not None:\n",
    "# \t\tplt.suptitle(title)\n",
    "# \treturn _out\n",
    "\n",
    "common_kwargs = dict(ylim=(0,1), hue='time_bin_size') # , marginal_kws=dict(bins=25, fill=True)\n",
    "# sns.jointplot(data=a_laps_all_epoch_bins_marginals_df, x='lap_start_t', y='P_Long', kind=\"scatter\", color=\"#4CB391\")\n",
    "pho_jointplot(data=several_time_bin_sizes_laps_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Laps: per epoch') #color=\"#4CB391\")\n",
    "pho_jointplot(data=several_time_bin_sizes_ripple_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Ripple: per epoch')\n",
    "pho_jointplot(data=several_time_bin_sizes_time_bin_ripple_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Ripple: per time bin')\n",
    "pho_jointplot(data=several_time_bin_sizes_time_bin_laps_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Laps: per time bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43311ee",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import plot_histograms\n",
    "\n",
    "# You can use it like this:\n",
    "plot_histograms('Laps', 'One Session', several_time_bin_sizes_time_bin_laps_df, \"several\")\n",
    "plot_histograms('Ripples', 'One Session', several_time_bin_sizes_time_bin_ripple_df, \"several\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a33b924",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "several_time_bin_sizes_ripple_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2a9d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.displot(\n",
    "#     several_time_bin_sizes_laps_df, x=\"P_Long\", col=\"species\", row=\"time_bin_size\",\n",
    "#     binwidth=3, height=3, facet_kws=dict(margin_titles=True),\n",
    "# )\n",
    "\n",
    "sns.displot(\n",
    "    several_time_bin_sizes_laps_df, x='delta_aligned_start_t', y='P_Long', row=\"time_bin_size\",\n",
    "    binwidth=3, height=3, facet_kws=dict(margin_titles=True),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495ef2bb",
   "metadata": {},
   "source": [
    "# <a id='toc7_'></a>[🎨 2024-02-06 - Other Plotting](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5623a2",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": [
     "all",
     "run-group-display",
     "run-spike_raster_window_test",
     "run-2025-04-11_full-session_marginals",
     "run-display-launcher-widget",
     "run-group-mergedcolorplot"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.TimeSynchronizedPlacefieldsPlotter import TimeSynchronizedPlacefieldsPlotter\n",
    "\n",
    "# For PlotWidget\n",
    "pg.setConfigOptions(useOpenGL=True)\n",
    "\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "\n",
    "#  Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "curr_active_pipeline.prepare_for_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83293544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots\n",
    "\n",
    "_out = batch_perform_all_plots(curr_active_pipeline, debug_print=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86d59de",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968df7ce",
   "metadata": {
    "tags": [
     "all",
     "run-display-launcher-widget"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Display import DisplayFunctionItem\n",
    "from pyphocorehelpers.gui.Qt.tree_helpers import find_tree_item_by_text\n",
    "from pyphoplacecellanalysis.GUI.Qt.MainApplicationWindows.LauncherWidget.LauncherWidget import LauncherWidget\n",
    "\n",
    "widget = LauncherWidget()\n",
    "# widget.debug_print = True\n",
    "treeWidget = widget.mainTreeWidget # QTreeWidget\n",
    "widget.build_for_pipeline(curr_active_pipeline=curr_active_pipeline)\n",
    "widget.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e3c30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsWidgets.EpochsEditorItem import EpochsEditor # perform_plot_laps_diagnoser\n",
    "\n",
    "_out = dict()\n",
    "_out['_display_directional_laps_overview'] = curr_active_pipeline.display(display_function='_display_directional_laps_overview', active_session_configuration_context=None) # _display_directional_laps_overview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdbabf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "\n",
    "override_laps_df: Optional[pd.DataFrame] = UserAnnotationsManager.get_hardcoded_laps_override_dict().get(curr_active_pipeline.get_session_context(), None)\n",
    "if override_laps_df is not None:\n",
    "    print(f'overriding laps....')\n",
    "    display(override_laps_df)\n",
    "    did_any_change = curr_active_pipeline.override_laps(override_laps_df=override_laps_df, debug_print=True)\n",
    "    print(f'did_any_change: {did_any_change}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe53ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from neuropy.core.laps import Laps\n",
    "\n",
    "user_labeled_laps_df: pd.DataFrame = deepcopy(UserAnnotationsManager.get_hardcoded_laps_override_dict()[curr_active_pipeline.get_session_context()])\n",
    "user_labeled_laps_df['lap_id'] = user_labeled_laps_df.index + 1\n",
    "user_labeled_laps_df['label'] = user_labeled_laps_df.index\n",
    "## OUTPUTS: user_labeled_laps_df\n",
    "## INPUTS: user_labeled_laps_df\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "user_labeled_laps: Laps = Laps(laps=user_labeled_laps_df)\n",
    "user_labeled_laps.update_lap_dir_from_smoothed_velocity(pos_input=curr_active_pipeline.sess.position)\n",
    "user_labeled_laps.update_maze_id_if_needed(t_start=t_start, t_delta=t_delta, t_end=t_end)\n",
    "user_labeled_laps_df = user_labeled_laps.to_dataframe()\n",
    "\n",
    "user_labeled_laps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31506be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_labeled_laps_df.laps_accessor.to_Laps_obj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcbc3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_labeled_laps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df185a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_labeled_laps_df.laps_accessor.compute_lap_dir_from_net_displacement(global_session=curr_active_pipeline.sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388cdb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add in corrected columns to laps_df:\n",
    "user_labeled_laps_df = user_labeled_laps_df.merge(lap_displacement_df[['lap', 'is_LR_dir', 'lap_dir']], left_on='lap_id', right_on='lap', how='left')\n",
    "user_labeled_laps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e00486",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsWidgets.EpochsEditorItem import EpochsEditor # perform_plot_laps_diagnoser\n",
    "\n",
    "new_epochs_editor: EpochsEditor = EpochsEditor.init_laps_diagnoser(pos_df=curr_active_pipeline.sess.position.to_dataframe(), curr_laps_df=user_labeled_laps_df)\n",
    "new_epochs_editor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d1a3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsWidgets.EpochsEditorItem import EpochsEditor # perform_plot_laps_diagnoser\n",
    "\n",
    "new_epochs_editor: EpochsEditor = EpochsEditor.init_laps_diagnoser(pos_df=curr_active_pipeline.sess.position.to_dataframe(), curr_laps_df=curr_active_pipeline.sess.laps.to_dataframe())\n",
    "new_epochs_editor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e798969",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the user-updated laps from the EpochsEditor\n",
    "user_labeled_laps_df: pd.DataFrame = deepcopy(new_epochs_editor.get_user_labeled_epochs_df())\n",
    "user_labeled_laps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32119566",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_labeled_laps_df[['start', 'stop', 'lap_dir']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22ef94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsWidgets.EpochsEditorItem import EpochsEditor # perform_plot_laps_diagnoser\n",
    "_out = curr_active_pipeline.display_output[IdentifyingContext(format_name= 'kdiba', animal= 'gor01', exper_name= 'one', session_name= '2006-6-07_11-26-53', display_fn_name= '_display_directional_laps_overview')]\n",
    "_epochs_editor: EpochsEditor = _out['ui'][0]\n",
    "_epochs_editor\n",
    "# type(_out)\n",
    "# list(_out.keys())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282d952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_epochs_editor.set_user_labeled_epochs_df(user_labeled_laps_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7b57a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the user-updated laps from the EpochsEditor\n",
    "user_labeled_laps_df: pd.DataFrame = deepcopy(_epochs_editor.get_user_labeled_epochs_df())\n",
    "user_labeled_laps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e33a32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7543010",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_labeled_laps_df.iloc[9, 'is_LR_dir'] = False \n",
    "\n",
    "\n",
    "user_labeled_laps_df['is_LR_dir'].iloc[9] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6354d9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_labeled_laps_df = user_labeled_laps_df.sort_values(by=['start', 'stop'], ascending=True, axis='index', ignore_index=True)\n",
    "user_labeled_laps_df['lap_id'] = user_labeled_laps_df.index\n",
    "user_labeled_laps_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35bf402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_df = curr_active_pipeline.sess.position.to_dataframe()\n",
    "\n",
    "pos_df = global_session.position.to_dataframe()\n",
    "_new_epoch_editor: EpochsEditor = EpochsEditor.init_laps_diagnoser(pos_df=pos_df, curr_laps_df=user_labeled_laps_df)\n",
    "_new_epoch_editor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161e7bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.get_session_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc740956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_labeled_laps_df[['start', 'stop', 'lap_dir']].to_clipboard(excel=True, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950e3c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_labeled_laps_df[['start', 'stop', 'lap_dir']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab95f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.gui.Qt.color_helpers import ColormapHelpers\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "cmap = ColormapHelpers.create_transparent_colormap(cmap_name='Reds', lower_bound_alpha=0.01, should_return_LinearSegmentedColormap=False)\n",
    "cmap\n",
    "\n",
    "_out = dict()\n",
    "_out['_display_trial_to_trial_reliability'] = curr_active_pipeline.display(display_function='_display_trial_to_trial_reliability', active_session_configuration_context=None, cmap=cmap) # _display_trial_to_trial_reliability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a879f8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out['_display_trial_to_trial_reliability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e56dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = dict()\n",
    "_out['_display_pf_peak_prominence2d_plots'] = curr_active_pipeline.display(display_function='_display_pf_peak_prominence2d_plots', active_session_configuration_context=IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43',filter_name='maze2_odd',lap_dir='odd'),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   neuron_id=8) # _display_pf_peak_prominence2d_plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990d7f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b653dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out['_display_directional_laps_overview'] = curr_active_pipeline.display(display_function='_display_directional_laps_overview', active_session_configuration_context=None) # _display_directional_laps_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df692641",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams\n",
    "# set_yticklabels\n",
    "\n",
    "# Set major tick label size for both x and y axes\n",
    "# ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "matplotlib.rc('xtick', labelsize=5)\n",
    "matplotlib.rc('ytick', labelsize=5)\n",
    "mpl.rcParams['font.family'] = 'Arial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8a5ca1",
   "metadata": {
    "tags": [
     "run-group-publication"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.plotting.ratemaps import plot_ratemap_1D\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out = dict()\n",
    "\n",
    "fig1_common_kwargs = dict(save_figure=True, write_vector_format=True, write_png=False, prepare_for_publication=True, bbox_inches='tight', pad_inches=0, aclu_labels_strokewidth=1)\n",
    "_out['_display_directional_track_template_pf1Ds'] = curr_active_pipeline.display(display_function='_display_directional_track_template_pf1Ds', active_session_configuration_context=None, **fig1_common_kwargs) # _display_directional_track_template_pf1Ds\n",
    "_out['_display_directional_track_template_pf1Ds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9705d6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for decoder_name, an_ax in _out['_display_directional_track_template_pf1Ds'].axes_dict.items():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce79ac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import perform_add_1D_track_bounds_lines\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "_out = dict()\n",
    "_out['_display_grid_bin_bounds_validation_x'] = curr_active_pipeline.display(display_function='_display_grid_bin_bounds_validation', active_session_configuration_context=None, is_x_axis=True) # _display_grid_bin_bounds_validation\n",
    "_out['_display_grid_bin_bounds_validation_y'] = curr_active_pipeline.display(display_function='_display_grid_bin_bounds_validation', active_session_configuration_context=None, is_x_axis=False) # _display_grid_bin_bounds_validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465a1575",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfd3606",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out = dict()\n",
    "_out['_display_directional_track_remapping_diagram'] = curr_active_pipeline.display(display_function='_display_directional_track_remapping_diagram', active_session_configuration_context=None, draw_point_aclu_labels=True, use_unique_aclu_colors=False, write_vector_format=True,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t) # _display_grid_bin_bounds_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad8ae03",
   "metadata": {},
   "source": [
    "### Plots the tracks with the vertical long/short platform lines overlayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048f6f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import test_LinearTrackDimensions_2D_Matplotlib, add_vertical_track_bounds_lines\n",
    "\n",
    "session_cm_grid_bin_bounds = UserAnnotationsManager.get_hardcoded_specific_session_override_dict()[curr_active_pipeline.get_session_context()]['cm_grid_bin_bounds']\n",
    "session_cm_grid_bin_bounds = BoundsRect.init_from_grid_bin_bounds(session_cm_grid_bin_bounds)\n",
    "session_cm_grid_bin_bounds\n",
    "\n",
    "x_mid, y_mid = session_cm_grid_bin_bounds.center_point\n",
    "\n",
    "long_offset = (x_mid, y_mid)\n",
    "short_offset = (x_mid, y_mid)\n",
    "fig, ax1, ax2 = test_LinearTrackDimensions_2D_Matplotlib(long_offset=long_offset, short_offset=short_offset)\n",
    "\n",
    "grid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\n",
    "long_track_line_collection, short_track_line_collection = add_vertical_track_bounds_lines(grid_bin_bounds=deepcopy(long_pf2D.config.grid_bin_bounds), ax=ax1)\n",
    "long_track_line_collection, short_track_line_collection = add_vertical_track_bounds_lines(grid_bin_bounds=deepcopy(short_pf2D.config.grid_bin_bounds), ax=ax2)\n",
    "\n",
    "# long_notable_x_platform_positions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d59b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722390a6",
   "metadata": {
    "tags": [
     "run-group-publication"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import CellFieldRemappingModels\n",
    "\n",
    "# LS_pf_peak_x_diff = ['LS_pf_peak_x_diff']\n",
    "# active_scatter_all_neuron_stats_table[['long_LR_pf1D_peak', 'long_RL_pf1D_peak']]\n",
    "# active_scatter_all_neuron_stats_table[['short_LR_pf1D_peak', 'short_RL_pf1D_peak', 'peak_diff_LR_pf1D_peak', 'peak_diff_RL_pf1D_peak']]\n",
    "\n",
    "\n",
    "all_neuron_stats_table: pd.DataFrame = AcrossSessionsResults.build_neuron_identities_df_for_CSV(curr_active_pipeline=curr_active_pipeline)\n",
    "active_scatter_all_neuron_stats_table = CellFieldRemappingModels.fix_has_considerable_remapping_column(all_neuron_stats_table=all_neuron_stats_table)\n",
    "active_scatter_all_neuron_stats_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4dcfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_errors, best_model_name = CellFieldRemappingModels.main_evaluate_remapping_models(active_scatter_all_neuron_stats_table=active_scatter_all_neuron_stats_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1a371c",
   "metadata": {
    "tags": [
     "run-group-publication"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsResults # for .build_neuron_identities_df_for_CSV\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PhoPublicationFigureHelper\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import TrackRemappingDiagramFigure\n",
    "\n",
    "# 2025-06-09 18:22 - Added combined output helper:        \n",
    "# all_neuron_stats_table: pd.DataFrame = AcrossSessionsResults.build_neuron_identities_df_for_CSV(curr_active_pipeline=curr_active_pipeline)\n",
    "# active_scatter_all_neuron_stats_table: pd.DataFrame = deepcopy(all_neuron_stats_table).fillna(value=np.nan, inplace=False) ## fill all Pandas.NA values with np.nan so they can be correctly cast to floats\n",
    "# active_scatter_all_neuron_stats_table\n",
    "\n",
    "## INPUTS: active_scatter_all_neuron_stats_table\n",
    "use_pf2D_peaks: bool = False\n",
    "                    \n",
    "_fig_container = TrackRemappingDiagramFigure.plot_publication_bidirectional_track_remapping_diagram(all_neuron_stats_table=active_scatter_all_neuron_stats_table,\n",
    "    use_pf2D_peaks=use_pf2D_peaks, use_considerable_remapping_cells_only=False,\n",
    "    # common_circle_points_kwargs = dict(alpha=0.9, picker=False, plotnonfinite=False),\n",
    "    # common_BOTH_only_circle_points_kwargs = dict(alpha=0.6, picker=False, plotnonfinite=False, marker='o', zorder=9),\t\n",
    "    common_circle_points_kwargs = dict(alpha=0.9, picker=False, plotnonfinite=False, linewidths=0),\n",
    "    common_BOTH_only_circle_points_kwargs = dict(alpha=0.9, picker=False, plotnonfinite=False, marker='d', zorder=9),\t\t\n",
    "\n",
    "    # arrowprops_kwargs = dict(arrowstyle=\"fancy, head_length=0.25, head_width=0.25, tail_width=0.05\", alpha=0.6, zorder=1),\n",
    "    # arrowprops_kwargs = dict(arrowstyle=\"fancy, head_length=0.9, head_width=0.25, tail_width=0.01\", alpha=0.6, zorder=1),\n",
    "    # arrowprops_kwargs = dict(arrowstyle=\"fancy, head_length=0.25, head_width=0.25, tail_width=0.05\", mutation_scale=1, alpha=0.6, zorder=1),\n",
    "    arrowprops_kwargs = dict(arrowstyle=\"simple\", lw=0.01, alpha=0.6, zorder=1), # , mutation_scale=10\n",
    "\t\n",
    "    # base_1D_height = 1.0, top_bottom_padding = 0.025,  intra_track_y_spacing = 0.05, scatter_point_size = 15.0, # Defaults\n",
    "    base_1D_height = 1.0, top_bottom_padding = 0.2125,  intra_track_y_spacing = 0.25, scatter_point_size = 7.0, # Smaller\n",
    "    base_platform_additive_height = 0.1, long_height_multiplier = 1.0, common_1D_platform_height = 0.25, common_1D_track_height = 0.1, track_to_baseline_padding = 0.05,\n",
    "\tedgecolors = \"#00000000\", # should be provided here and not within `common_circle_points_kwargs` or `common_BOTH_only_circle_points_kwargs` because the real edgecolors need to have one value for each point \n",
    "\t\n",
    "    considerable_remapping_emphasis_color='red',\n",
    "    # considerable_remapping_emphasis_color=None,\n",
    "    write_vector_format=True,\n",
    "\tskip_RL_direction_tracks=True,\n",
    ")\n",
    "_fig_container\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043e463b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_fig_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b8f357",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89837555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalDisplayFunctions\n",
    "\n",
    "collector = DirectionalPlacefieldGlobalDisplayFunctions._display_directional_track_remapping_diagram(owning_pipeline_reference=curr_active_pipeline, global_computation_results=curr_active_pipeline.global_computation_results, computation_results=None, active_configs=None, save_figure=False, is_dark_mode=False)\n",
    "collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20264629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PAPER_FIGURE_figure_1_full\n",
    "\n",
    "pf1d_compare_graphics, (example_epoch_rasters_L, example_epoch_rasters_S), example_stacked_epoch_graphics, fig_1c_figures_out_dict = PAPER_FIGURE_figure_1_full(curr_active_pipeline, prepare_for_publication=True, write_vector_format=True) # did not display the pf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5507c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out = dict()\n",
    "_out['_display_pf_peak_prominence2d_plots'] = curr_active_pipeline.display(display_function='_display_pf_peak_prominence2d_plots', active_session_configuration_context=IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43',filter_name='maze1_odd',lap_dir='odd')) # _display_pf_peak_prominence2d_plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cb9f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out['3d_interactive_spike_and_behavior_browser'] = curr_active_pipeline.display(display_function='_display_3d_interactive_spike_and_behavior_browser', active_session_configuration_context=None) # _display_grid_bin_bounds_validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9039fb3",
   "metadata": {},
   "source": [
    "#### 2025-06-26 - InteractivePlaceCellDataExplorer with Long & Short Placefields - Not Finished\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f90de3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.InteractivePlaceCellDataExplorer import InteractivePlaceCellDataExplorer\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out = {}\n",
    "global_any_context = curr_active_pipeline.filtered_contexts[global_any_name]\n",
    "_out['_display_3d_interactive_tuning_curves_plotter'] = curr_active_pipeline.display(display_function='_display_3d_interactive_tuning_curves_plotter', active_session_configuration_context=global_any_context,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t separate_window = False,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t params_kwargs={'show_legend': False, 'should_display_placefield_points': False, 'should_nan_non_visited_elements': False, 'zScalingFactor': 500.0, 'debug_print': False},\n",
    "                                                                                    #  panel_controls_mode = 'Panel',\n",
    "                                                                                    # panel_controls_mode = 'Qt',\n",
    "                                                                                    panel_controls_mode = None,\n",
    "                                                                                    # debug_print=False,\n",
    "                                                                                    ) # _display_grid_bin_bounds_validation\n",
    "\n",
    "\n",
    "## Move the long-maze to -`maze_y_offset` units and the short-maze to +`maze_y_offset` units along the y-axis \n",
    "ipcDataExplorer: InteractivePlaceCellDataExplorer = _out['_display_3d_interactive_tuning_curves_plotter']['ipcDataExplorer']\n",
    "pActiveTuningCurvesPlotter = _out['_display_3d_interactive_tuning_curves_plotter']['plotter']\n",
    "pane = _out['_display_3d_interactive_tuning_curves_plotter']['pane']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbaf985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import LongShort3DPlacefieldsHelpers\n",
    "\n",
    "pane = LongShort3DPlacefieldsHelpers._plot_long_short_placefields(ipcDataExplorer=ipcDataExplorer, long_pf2D=long_pf2D, short_pf2D=short_pf2D, maze_y_offset=20.0)\n",
    "# ipcDataExplorer.p.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace9a90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in ipcDataExplorer.plots.tuningCurvePlotActors.items():\n",
    "    v.SetVisibility(0)\n",
    "    peaks = v.get('peaks', None)\n",
    "    if peaks:\n",
    "        peaks.SetVisibility(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ipcDataExplorer.plots_data['tuningCurvePlotData']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c056786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipcDataExplorer.plots.tuningCurvePlotActors[3]['long']['peaks']\n",
    "# ipcDataExplorer.plots.tuningCurvePlotActors[3]['peaks'].SetVisibility(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2eb151",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import LongShort3DPlacefieldsHelpers\n",
    "\n",
    "# active_config_name: str = short_epoch_name # 'maze_any'\n",
    "# print(f'active_config_name: {active_config_name}')\n",
    "# active_peak_prominence_2d_results = curr_active_pipeline.computation_results[active_config_name].computed_data.get('RatemapPeaksAnalysis', {}).get('PeakProminence2D', None)\n",
    "\n",
    "# # pActiveTuningCurvesPlotter = None\n",
    "# # display_output = display_output | curr_active_pipeline.display('_display_3d_interactive_tuning_curves_plotter', active_config_name, extant_plotter=display_output.get('pActiveTuningCurvesPlotter', None), panel_controls_mode='Qt', should_nan_non_visited_elements=False, zScalingFactor=2000.0) # Works now!\n",
    "# # ipcDataExplorer = display_output['ipcDataExplorer']\n",
    "# # display_output['pActiveTuningCurvesPlotter'] = display_output.pop('plotter') # rename the key from the generic \"plotter\" to \"pActiveSpikesBehaviorPlotter\" to avoid collisions with others\n",
    "# # pActiveTuningCurvesPlotter = display_output['pActiveTuningCurvesPlotter']\n",
    "# # root_dockAreaWindow, placefieldControlsContainerWidget, pf_widgets = display_output['pane'] # for Qt mode\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "# render_all_neuron_peak_prominence_2d_results_on_pyvista_plotter(ipcDataExplorer, active_peak_prominence_2d_results)\n",
    "LongShort3DPlacefieldsHelpers.render_long_short_all_neuron_peak_prominence_2d_results_on_pyvista_plotter(ipcDataExplorer,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t long_peak_prominence_2d_results=curr_active_pipeline.computation_results[long_epoch_name].computed_data.get('RatemapPeaksAnalysis', {}).get('PeakProminence2D', None),\n",
    "                                                                                                         short_peak_prominence_2d_results=curr_active_pipeline.computation_results[short_epoch_name].computed_data.get('RatemapPeaksAnalysis', {}).get('PeakProminence2D', None),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51d1e83",
   "metadata": {},
   "source": [
    "### PhoJonathan Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c430bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acd174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import PhoJonathanPlotHelpers\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import BatchPhoJonathanFiguresHelper\n",
    "from pyphocorehelpers.DataStructure.RenderPlots.MatplotLibRenderPlots import FigureCollector\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PhoPublicationFigureHelper\n",
    "\n",
    "## Get global 'jonathan_firing_rate_analysis' results:\n",
    "curr_jonathan_firing_rate_analysis = curr_active_pipeline.global_computation_results.computed_data['jonathan_firing_rate_analysis']\n",
    "neuron_replay_stats_df, rdf, aclu_to_idx, irdf = curr_jonathan_firing_rate_analysis.neuron_replay_stats_df, curr_jonathan_firing_rate_analysis.rdf.rdf, curr_jonathan_firing_rate_analysis.rdf.aclu_to_idx, curr_jonathan_firing_rate_analysis.irdf.irdf\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Batch Output of Figures                                                                                              #\n",
    "# ==================================================================================================================== #\n",
    "## 🗨️🟢 2022-11-05 - Pho-Jonathan Batch Outputs of Firing Rate Figures\n",
    "short_only_df = neuron_replay_stats_df[neuron_replay_stats_df.track_membership == SplitPartitionMembership.RIGHT_ONLY]\n",
    "short_only_aclus = short_only_df.index.values.tolist()\n",
    "long_only_df = neuron_replay_stats_df[neuron_replay_stats_df.track_membership == SplitPartitionMembership.LEFT_ONLY]\n",
    "long_only_aclus = long_only_df.index.values.tolist()\n",
    "shared_df = neuron_replay_stats_df[neuron_replay_stats_df.track_membership == SplitPartitionMembership.SHARED]\n",
    "shared_aclus = shared_df.index.values.tolist()\n",
    "print(f'shared_aclus: {shared_aclus}')\n",
    "print(f'long_only_aclus: {long_only_aclus}')\n",
    "print(f'short_only_aclus: {short_only_aclus}')\n",
    "\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'    \n",
    "## MODE: this mode creates a special folder to contain the outputs for this session.\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Output Figures to File                                                                                               #\n",
    "# ==================================================================================================================== #\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-BatchPhoJonathanFiguresHelper.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "prepare_for_publication: bool = True\n",
    "# prepare_for_publication: bool = False\n",
    "display_context = curr_active_pipeline.get_session_context()\n",
    "\n",
    "figsize = (6.5, 4)\n",
    "if prepare_for_publication:\n",
    "    from neuropy.utils.matplotlib_helpers import find_first_available_matplotlib_font_name\n",
    "\n",
    "    found_matplotlib_font_name: str = find_first_available_matplotlib_font_name(desired_fonts_list=['Arial'])\n",
    "    assert found_matplotlib_font_name, f\"found_matplotlib_font_name: {found_matplotlib_font_name} Arial was not found!\"\n",
    "else:\n",
    "    found_matplotlib_font_name = None\n",
    "\n",
    "_rc_context_kwargs = {'savefig.transparent': True, 'ps.fonttype': 42, 'pdf.fonttype': 42, }\n",
    "if prepare_for_publication:\n",
    "    assert found_matplotlib_font_name is not None\n",
    "    _rc_context_kwargs.update(PhoPublicationFigureHelper.rc_context_kwargs(prepare_for_publication=prepare_for_publication, **{'figure.dpi': '100', 'figure.frameon': False, 'figure.figsize': figsize, 'font.family': found_matplotlib_font_name})) # , 'figure.constrained_layout.use': (constrained_layout or False)\n",
    "\n",
    "\n",
    "with mpl.rc_context(_rc_context_kwargs): # 'figure.dpi': '220', 'figure.figsize': (10, 4), \n",
    "    # Create a FigureCollector instance\n",
    "    with FigureCollector(name='BatchPhoJonathanFiguresHelper', base_context=display_context) as collector:\n",
    "            \n",
    "        active_out_figures_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, n_max_page_rows=1, write_vector_format=True, write_png=True, show_only_refined_cells=False)\n",
    "                \n",
    "        # for a_ctxt, a_matlab_render_plots_obj in active_out_figures_dict.items():\n",
    "        #     collector.post_hoc_append(figures=a_matlab_render_plots_obj.figures, axes=a_matlab_render_plots_obj.axes, contexts=[a_ctxt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26df7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3c878f",
   "metadata": {},
   "source": [
    "#### Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6595b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps).trimmed_to_non_overlapping() \n",
    "global_laps_epochs_df = global_laps.to_dataframe()\n",
    "_out_ripple_rasters: RankOrderRastersDebugger = RankOrderRastersDebugger.init_rank_order_debugger(global_spikes_df, deepcopy(global_laps_epochs_df),\n",
    "                                                                                                track_templates, None,\n",
    "                                                                                                None, None,\n",
    "                                                                                                dock_add_locations = dict(zip(('long_LR', 'long_RL', 'short_LR', 'short_RL'), (['right'], ['right'], ['right'], ['right']))),\n",
    "                                                                                                )\n",
    "_out_ripple_rasters.set_top_info_bar_visibility(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87275307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import fig_remapping_cells\n",
    "\n",
    "a_fig_collector = fig_remapping_cells(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8833fd9",
   "metadata": {},
   "source": [
    "## Pseudo2D Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed34de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.Extensions.pyqtgraph_helpers import LayoutScrollability, pyqtplot_build_image_bounds_extent\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.TemplateDebugger import BaseTemplateDebuggingMixin, build_pf1D_heatmap_with_labels_and_peaks, TrackTemplates\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.BinByBinDecodingDebugger import BinByBinDecodingDebugger \n",
    "\n",
    "# Example usage:\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps).trimmed_to_non_overlapping() \n",
    "global_laps_epochs_df = global_laps.to_dataframe()\n",
    "global_laps_epochs_df\n",
    "\n",
    "## INPUTS: \n",
    "time_bin_size: float = 0.250\n",
    "a_lap_id: int = 9\n",
    "a_decoder_name = 'long_LR'\n",
    "epoch_id_col_name = 'lap_id'\n",
    "## COMPUTED: \n",
    "a_decoder_idx: int = track_templates.get_decoder_names().index(a_decoder_name)\n",
    "a_decoder = deepcopy(track_templates.long_LR_decoder)\n",
    "(_out_decoded_time_bin_edges, _out_decoded_unit_specific_time_binned_spike_counts, _out_decoded_active_unit_lists, _out_decoded_active_p_x_given_n, _out_decoded_active_plots_data) = BinByBinDecodingDebugger.build_spike_counts_and_decoder_outputs(a_decoder=a_decoder, epochs_df=global_laps_epochs_df, spikes_df=global_spikes_df, epoch_id_col_name=epoch_id_col_name, time_bin_size=time_bin_size)\n",
    "win, out_pf1D_decoder_template_objects, (_out_decoded_active_plots, _out_decoded_active_plots_data) = BinByBinDecodingDebugger.build_time_binned_decoder_debug_plots(a_decoder=a_decoder, an_epoch_id=a_lap_id, _out_decoded_time_bin_edges=_out_decoded_time_bin_edges, _out_decoded_active_p_x_given_n=_out_decoded_active_p_x_given_n,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  _out_decoded_active_unit_lists=_out_decoded_active_unit_lists, _out_decoded_active_plots_data=_out_decoded_active_plots_data, debug_print=True)\n",
    "\n",
    "## All-in-one mode:\n",
    "# win, out_pf1D_decoder_template_objects, (_out_decoded_active_plots, _out_decoded_active_plots_data) = BinByBinDecodingDebugger.plot_bin_by_bin_decoding_example(curr_active_pipeline=curr_active_pipeline, track_templates=track_templates, time_bin_size=time_bin_size, a_lap_id=a_lap_id, a_decoder_name=a_decoder_name)\n",
    "\n",
    "print(f\"Returned window: {win}\")\n",
    "print(f\"Returned decoder objects: {out_pf1D_decoder_template_objects}\")\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736f4d28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc01304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff24133e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125508a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345ec76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_cm_x_grid_bin_bounds\n",
    "\n",
    "global_session.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e03666",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pf1D_decoder_template_objects[0].plots_data.spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe2e4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lap_specific_spikes_df = _out_decoded_active_plots_data[a_lap_id].spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1529c71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = dict()\n",
    "_out['_display_directional_merged_pfs'] = curr_active_pipeline.display(display_function='_display_directional_merged_pfs', active_session_configuration_context=None) # _display_directional_merged_pfs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece249c2",
   "metadata": {},
   "source": [
    "n_epoch_time_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721d7f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "win.nextRow()\n",
    "lbl = win.addLabel(text='HUGE', colspan=n_epoch_time_bins) # , row=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a0506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the span to cover all columns in the row\n",
    "win.ci.layout.setRowStretchFactor(win.ci.rowCount() - 1, 1)  # Adjust the stretch factor for the new row\n",
    "win.ci.layout.setColumnStretchFactor(0, n_epoch_time_bins)   # Ensure it spans all columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f91cc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "spanning_plot2 = win.addPlot(title=\"Spanning Plot3\", row=1, rowspan=1, col=0, colspan=n_epoch_time_bins)  # Add the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7a808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spanning_plot2.setTitle(\"Spanning Plot - Covers Entire Width\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f611651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the span to cover all columns in the row\n",
    "win.ci.layout.setRowStretchFactor(win.ci.rowCount() - 1, 1)  # Adjust the stretch factor for the new row\n",
    "win.ci.layout.setColumnStretchFactor(0, n_epoch_time_bins)   # Ensure it spans all columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cae0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.decoder_difference import display_predicted_position_difference\n",
    "\n",
    "active_computed_data = curr_active_pipeline.computation_results[global_epoch_name]\n",
    "active_resampled_pos_df = active_computed_data.extended_stats.time_binned_position_df.copy() # active_computed_data.extended_stats.time_binned_position_df  # 1717 rows × 16 columns\n",
    "active_resampled_measured_positions = active_resampled_pos_df[['x','y']].to_numpy() # The measured positions resampled (interpolated) at the window centers. \n",
    "display_predicted_position_difference(active_one_step_decoder, active_two_step_decoder, active_resampled_measured_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd6298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(p_x_given_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1738f798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.TemplateDebugger import BaseTemplateDebuggingMixin, build_pf1D_heatmap_with_labels_and_peaks, TrackTemplates\n",
    "\n",
    "_obj = BaseTemplateDebuggingMixin.init_from_decoder(a_decoder=a_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe064948",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "curr_img, out_colors_heatmap_image_matrix = build_pf1D_heatmap_with_labels_and_peaks(pf1D_decoder=a_decoder, visible_aclus=active_bin_aclus, plot_item=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c18797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.TemplateDebugger import TemplateDebugger\n",
    "\n",
    "_out_TemplateDebugger: TemplateDebugger = TemplateDebugger.init_templates_debugger(track_templates) # , included_any_context_neuron_ids\n",
    "\n",
    "# _out_ui.root_dockAreaWindow\n",
    "# _out_ui.dock_widgets[a_decoder_name]\n",
    "\n",
    "## Plots:\n",
    "# _out_plots.pf1D_heatmaps[a_decoder_name] = visualize_heatmap_pyqtgraph(curr_curves, title=title_str, show_value_labels=False, show_xticks=False, show_yticks=False, show_colorbar=False, win=None, defer_show=True) # Sort to match first decoder (long_LR)\n",
    "# Adds aclu text labels with appropriate colors to y-axis: uses `sorted_shared_sort_neuron_IDs`:\n",
    "# curr_win, curr_img = _out_plots.pf1D_heatmaps[a_decoder_name] # win, img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eecf66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: \n",
    "a_decoder_aclu_to_color_map = deepcopy(_out_TemplateDebugger.plots_data['sort_helper_neuron_id_to_neuron_colors_dicts'][a_decoder_idx])\n",
    "a_decoder_aclu_to_color_map\n",
    "# _out_TemplateDebugger.plots_data['out_colors_heatmap_image_matrix_dicts'][a_decoder_idx]\n",
    "an_img_extents = deepcopy(_out_TemplateDebugger.plots_data['active_pfs_img_extents_dict'])[a_decoder_name] # [0.0, 0, 289.2117008543986, 35.0]\n",
    "an_img_extents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0aa9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out_TemplateDebugger.params\n",
    "# _out_TemplateDebugger.plots_data.data_keys\n",
    "\n",
    "a_decoder_name\n",
    "\n",
    "\n",
    "a_decoder_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd155ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd6e7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import easy_independent_decoding\n",
    "\n",
    "\n",
    "time_bin_size: float = 0.500 # 500ms\n",
    "t_start = 0.0\n",
    "t_end = 2093.8978568242164\n",
    "_decoded_pos_outputs, (unit_specific_time_binned_spike_counts, time_bin_edges, spikes_df) = easy_independent_decoding(long_LR_decoder, spikes_df=spikes_df, time_bin_size=time_bin_size, t_start=t_start, t_end=t_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9e1715",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_template_debugger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9851ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_t_bin_idx: int = 0\n",
    "# active_aclus_list = _out_decoded_active_unit_lists[a_row.lap_id][a_t_bin_idx]\n",
    "\n",
    "_out_TemplateDebugger.update_cell_emphasis(solo_emphasized_aclus=active_bin_aclus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4173061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_TemplateDebugger.pf1D_heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b761e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.indexing_helpers import compute_paginated_grid_config\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.pyqtplot_common import pyqtplot_common_setup\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.Extensions.pyqtgraph_helpers import LayoutScrollability, pyqtplot_build_image_bounds_extent, set_small_title\n",
    "from neuropy.utils.matplotlib_helpers import _scale_current_placefield_to_acceptable_range, _build_neuron_identity_label # for display_all_pf_2D_pyqtgraph_binned_image_rendering\n",
    "from pyphocorehelpers.gui.Qt.color_helpers import ColormapHelpers\n",
    "\n",
    "class HeatmapLayout(pg.QtWidgets.QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Create layout\n",
    "        layout = pg.QtWidgets.QVBoxLayout(self)\n",
    "        layout.setContentsMargins(0, 0, 0, 0)\n",
    "        layout.setSpacing(0)\n",
    "        \n",
    "        # Top row: variable number of heatmaps\n",
    "        self.top_row = pg.GraphicsLayoutWidget()\n",
    "        self.top_row.setContentsMargins(0, 0, 0, 0)\n",
    "        self.top_plots = []\n",
    "        layout.addWidget(self.top_row)\n",
    "\n",
    "        # Bottom row: single heatmap\n",
    "        self.bottom_row = pg.GraphicsLayoutWidget()\n",
    "        self.bottom_row.setContentsMargins(0, 0, 0, 0)\n",
    "        self.bottom_plot = self.bottom_row.addPlot()\n",
    "        self.bottom_plot.setContentsMargins(0, 0, 0, 0)\n",
    "        self.bottom_img = pg.ImageItem()\n",
    "        self.bottom_plot.addItem(self.bottom_img)\n",
    "        layout.addWidget(self.bottom_row)\n",
    "        \n",
    "        # Style plots\n",
    "        for p in [self.bottom_plot]:\n",
    "            p.showAxis('left', True)\n",
    "            p.showAxis('bottom', True)\n",
    "            p.getAxis('left').setLabel(\"Y-Axis\")\n",
    "            p.getAxis('bottom').setLabel(\"X-Axis\")\n",
    "            p.setContentsMargins(0, 0, 0, 0)\n",
    "            p.setDefaultPadding(0)\n",
    "            \n",
    "\n",
    "    def update_top_heatmaps(self, data_list):\n",
    "        self.top_row.clear()\n",
    "        self.top_plots = []\n",
    "        for data in data_list:\n",
    "            plot = self.top_row.addPlot()\n",
    "            plot.setContentsMargins(0, 0, 0, 0)\n",
    "            plot.setDefaultPadding(0)\n",
    "            img = pg.ImageItem(data)\n",
    "            plot.addItem(img)\n",
    "            plot.showAxis('left', True)\n",
    "            plot.getAxis('left').setLabel(\"Y-Axis\")\n",
    "            plot.hideAxis('bottom')\n",
    "            self.top_plots.append(plot)\n",
    "            self.top_row.nextRow()\n",
    "\n",
    "    def update_bottom_heatmap(self, data):\n",
    "        self.bottom_img.setImage(data)\n",
    "\n",
    "## Testing\n",
    "window = pg.QtWidgets.QMainWindow()\n",
    "widget = HeatmapLayout()\n",
    "\n",
    "# Example data\n",
    "top_data_list = [np.random.rand(10, 10), np.random.rand(15, 10)]\n",
    "bottom_data = np.random.rand(20, 20)\n",
    "\n",
    "widget.update_top_heatmaps(top_data_list)\n",
    "widget.update_bottom_heatmap(bottom_data)\n",
    "\n",
    "window.setCentralWidget(widget)\n",
    "window.resize(800, 600)\n",
    "window.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99251ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parent_root_widget = None\n",
    "root_render_widget = None\n",
    "# Need to go from (n_epochs, n_neurons, n_pos_bins) -> (n_neurons, n_xbins, n_ybins)\n",
    "n_epochs, n_neurons, n_pos_bins = np.shape(z_scored_tuning_map_matrix)\n",
    "images = z_scored_tuning_map_matrix.transpose(1, 2, 0) # (71, 57, 22)\n",
    "xbin_edges=active_one_step_decoder.xbin\n",
    "assert (len(xbin_edges)-1) == n_pos_bins, f\"n_pos_bins: {n_pos_bins}, len(xbin_edges): {len(xbin_edges)} \"\n",
    "# ybin_edges=active_one_step_decoder.ybin\n",
    "ybin_edges = np.arange(n_epochs+1) - 0.5 # correct ybin_edges are n_epochs\n",
    "root_render_widget, parent_root_widget, app = pyqtplot_common_setup(f'TrialByTrialActivityArray: {np.shape(images)}', app=app, parent_root_widget=parent_root_widget, root_render_widget=root_render_widget) ## 🚧 TODO: BUG: this makes a new QMainWindow to hold this item, which is inappropriate if it's to be rendered as a child of another control\n",
    "\n",
    "pg.setConfigOptions(imageAxisOrder='col-major') # this causes the placefields to be rendered horizontally, like they were in _temp_pyqtplot_plot_image_array\n",
    "\n",
    "\n",
    "\n",
    "## build pg.GraphicsLayoutWidget(...) required to hold the decoding preview\n",
    "root = pg.GraphicsLayoutWidget(title='Decoding Example')\n",
    "\n",
    "\n",
    "root.addItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b18f74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.SpecificComputationValidation import SpecificComputationValidator\n",
    "\n",
    "def _build_default_required_computation_keys_computation_validator_fn_factory():\n",
    "    def _subfn(curr_active_pipeline, computation_filter_name='maze'):\n",
    "        has_all_required_local_keys: bool = np.all(np.isin((a_fn_callable.input_requires or []),  list(curr_active_pipeline.computation_results[computation_filter_name].computed_data.keys())))\n",
    "        has_all_required_global_keys: bool = np.all(np.isin((a_fn_callable.requires_global_keys or []),  list(curr_active_pipeline.global_computation_results.computed_data.keys())))\n",
    "        has_all_required_keys: bool = (has_all_required_local_keys and has_all_required_global_keys)\n",
    "        return has_all_required_keys\n",
    "    return _subfn\n",
    "\n",
    "\n",
    "should_use_nice_display_names: bool = False\n",
    "display_function_items = widget.get_display_function_items()\n",
    "display_fn_validators_dict = {}\n",
    "\n",
    "for a_fcn_name, a_disp_fn_item in display_function_items.items():\n",
    "    # extract the info from the function:\n",
    "    # if hasattr(a_fcn, 'short_name') and a_fcn.short_name is not None:\n",
    "    #     active_name = a_fcn.short_name or a_fcn_name\n",
    "    # else:\n",
    "    #     active_name = a_fcn_name\n",
    "\n",
    "    # active_name: str = a_disp_fn_item.name\n",
    "    if should_use_nice_display_names:\n",
    "        active_name: str = a_disp_fn_item.best_display_name\n",
    "    else:\n",
    "        active_name: str = a_disp_fn_item.name # function name\n",
    "\n",
    "    a_fn_callable = a_disp_fn_item.fn_callable\n",
    "\n",
    "    if ((not hasattr(a_fn_callable, 'validate_computation_test')) or (a_fn_callable.validate_computation_test is None)):\n",
    "        a_fn_callable.validate_computation_test = _build_default_required_computation_keys_computation_validator_fn_factory()\n",
    "\n",
    "    display_fn_validators_dict[a_fcn_name] = SpecificComputationValidator.init_from_decorated_fn(a_fn_callable)\n",
    "    # a_disp_fn_item\n",
    "    # a_fn_handle = widget.curr_active_pipeline.plot.__getattr__(a_disp_fn_item.name)\n",
    "    # a_fn_handle\n",
    "\n",
    "    # a_validate_computation_test = lambda curr_active_pipeline, computation_filter_name='maze': (curr_active_pipeline.computation_results[computation_filter_name].computed_data['pf1D_Decoder'], curr_active_pipeline.computation_results[computation_filter_name].computed_data['pf2D_Decoder'])\n",
    "\n",
    "\n",
    "# display_function_items\n",
    "# a_fn_handle.\n",
    "display_fn_validators_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3bbc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "display_fn_validators_dict = {}\n",
    "\n",
    "\n",
    "{k:SpecificComputationValidator.init_from_decorated_fn(v) for k,v in self.registered_merged_computation_function_dict.items() if hasattr(v, 'validate_computation_test') and (v.validate_computation_test is not None)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d2c89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.computation_results['maze_any'].computed_data\n",
    "\n",
    "_out = curr_active_pipeline.display('_display_plot_marginal_1D_most_likely_position_comparisons', active_session_configuration_context='maze_any', most_likely_positions_mode='standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0170fae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out = dict()\n",
    "# _out['_display_1d_placefield_occupancy'] = curr_active_pipeline.display('_display_1d_placefield_occupancy') # _display_1d_placefield_occupancy\n",
    "\n",
    "# _out = dict()\n",
    "# _out['_display_1d_placefield_occupancy'] = curr_active_pipeline.display(display_function='_display_1d_placefield_occupancy', active_session_configuration_context='kdiba_gor01_one_2006-6-09_1-22-43_maze_any_any') # _display_1d_placefield_occupancy\n",
    "\n",
    "_out = dict()\n",
    "_out['_display_1d_placefield_occupancy'] = curr_active_pipeline.display(display_function='_display_1d_placefield_occupancy', active_session_configuration_context=IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43',filter_name='maze1_any',lap_dir='any'), plot_pos_bin_axes=False) # _display_1d_placefield_occupancy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce055b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsWidgets.EpochsEditorItem import EpochsEditor # perform_plot_laps_diagnoser\n",
    "\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_epoch_context, short_epoch_context, global_epoch_context = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_epoch_name, short_epoch_name, global_epoch_name)]\n",
    "long_epoch_obj, short_epoch_obj = [Epoch(curr_active_pipeline.sess.epochs.to_dataframe().epochs.label_slice(an_epoch_name.removesuffix('_any'))) for an_epoch_name in [long_epoch_name, short_epoch_name]] #TODO 2023-11-10 20:41: - [ ] Issue with getting actual Epochs from sess.epochs for directional laps: emerges because long_epoch_name: 'maze1_any' and the actual epoch label in curr_active_pipeline.sess.epochs is 'maze1' without the '_any' part.\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "\n",
    "# sess = curr_active_pipeline.sess\n",
    "sess = global_session\n",
    "\n",
    "# pos_df = sess.compute_position_laps() # ensures the laps are computed if they need to be:\n",
    "position_obj = deepcopy(sess.position)\n",
    "position_obj.compute_higher_order_derivatives()\n",
    "pos_df = position_obj.compute_smoothed_position_info(N=20) ## Smooth the velocity curve to apply meaningful logic to it\n",
    "pos_df = position_obj.to_dataframe()\n",
    "# Drop rows with missing data in columns: 't', 'velocity_x_smooth' and 2 other columns. This occurs from smoothing\n",
    "pos_df = pos_df.dropna(subset=['t', 'x_smooth', 'velocity_x_smooth', 'acceleration_x_smooth']).reset_index(drop=True)\n",
    "curr_laps_df = sess.laps.to_dataframe()\n",
    "curr_laps_df\n",
    "epochs_editor = EpochsEditor.init_laps_diagnoser(pos_df, curr_laps_df, include_velocity=True, include_accel=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1b2f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show step-by-step how the decoder works\n",
    "\n",
    "## Show pseudo2D merged placefields:\n",
    "_out = dict()\n",
    "_out['_display_directional_merged_pfs'] = curr_active_pipeline.display(display_function='_display_directional_merged_pfs', active_session_configuration_context=None) # _display_directional_merged_pfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bc2059",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsResults\n",
    "\n",
    "all_neuron_stats_table: pd.DataFrame = AcrossSessionsResults.build_neuron_identities_df_for_CSV(curr_active_pipeline=curr_active_pipeline)\n",
    "all_neuron_stats_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6c97ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.sess.neurons\n",
    "\n",
    "# co_filter_epochs_and_spikes("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed02317",
   "metadata": {},
   "source": [
    "### <a id='toc7_1_1_'></a>[2025-01-20 - Decoding step-by-step](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7d8dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import get_proper_global_spikes_df\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import easy_independent_decoding\n",
    "\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "all_directional_pf1D_Decoder: BasePositionDecoder = deepcopy(directional_merged_decoders_result.all_directional_pf1D_Decoder) # all-directions\n",
    "# directional_merged_decoders_result\n",
    "\n",
    "# a_1D_decoder: PfND = directional_merged_decoders_result.all_directional_decoder_dict['long_LR']\n",
    "\n",
    "long_LR_decoder: BasePositionDecoder = deepcopy(track_templates.long_LR_decoder)\n",
    "\n",
    "# ratemap: Ratemap = all_directional_pf1D_Decoder.ratemap\n",
    "\n",
    "## Pass in epochs to decode, for example, the laps\n",
    "laps = deepcopy(curr_active_pipeline.sess.laps)\n",
    "\n",
    "spikes_df: pd.DataFrame = deepcopy(curr_active_pipeline.sess.spikes_df)\n",
    "# spikes_df: pd.DataFrame = get_proper_global_spikes_df(curr_active_pipeline)\n",
    "# spikes_df = spikes_df.spikes.sliced_by_neuron_id(all_directional_pf1D_Decoder.neuron_IDs)\n",
    "# spikes_df\n",
    "\n",
    "## Given a list of discrete, equally-sized `time_bin_edges`, and a `spikes_df` pd.DataFrame of neuron spike times:\n",
    "\n",
    "## use the column 'aclu', which contains a distinct unit ID\n",
    "\n",
    "## count up the number of spikes occuring for each neuron (aclu-value) in each time bin, according to the column 't_rel_seconds' and collect the result in a numpy matrix `unit_specific_time_binned_spike_counts`\n",
    "\n",
    "\n",
    "# _ratemap\n",
    "# neuron_ids = deepcopy(spikes_df.spikes.neuron_ids) # array([ 5, 10, 14, 15, 24, 25, 26, 31, 32, 33, 41, 49, 50, 51, 55, 58, 64, 69, 70, 73, 74, 75, 76, 78, 82, 83, 85, 86, 90, 92, 93, 96])\n",
    "# array([  3,   4,   5,   7,   9,  10,  11,  14,  15,  16,  17,  21,  24,  25,  26,  31,  32,  33,  34,  35,  36,  37,  41,  45,  48,  49,  50,  51,  53,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  66,  67,  68,  69,  70,  71,  73,  74,  75,  76,  78,  82,  83,  84,  85,  86,  88,  89,  90,  92,  93,  96,  98, 100, 102, 107, 108])\n",
    "# neuron_ids\n",
    "# neuron_IDs = deepcopy(all_directional_pf1D_Decoder.neuron_IDs) # array([  2,   5,   8,  10,  14,  15,  23,  24,  25,  26,  31,  32,  33,  41,  49,  50,  51,  55,  58,  64,  69,  70,  73,  74,  75,  76,  78,  82,  83,  85,  86,  90,  92,  93,  96, 109])\n",
    "# neuron_IDs\n",
    "\n",
    "neuron_IDs = deepcopy(long_LR_decoder.neuron_IDs) # array([  2,   5,   8,  10,  14,  15,  23,  24,  25,  26,  31,  32,  33,  41,  49,  50,  51,  55,  58,  64,  69,  70,  73,  74,  75,  76,  78,  82,  83,  85,  86,  90,  92,  93,  96, 109])\n",
    "neuron_IDs\n",
    "\n",
    "# all_directional_pf1D_Decoder.slic\n",
    "spikes_df = spikes_df.spikes.sliced_by_neuron_id(neuron_IDs) ## filter everything down\n",
    "# all_directional_pf1D_Decoder.pf.spikes_df = deepcopy(spikes_df)\n",
    "## Need to update .pf._filtered_spikes_df now:\n",
    "\n",
    "# all_directional_pf1D_Decoder = all_directional_pf1D_Decoder.get_by_id(ids=neuron_IDs, defer_compute_all=True)\n",
    "# all_directional_pf1D_Decoder\n",
    "\n",
    "# ratemap = ratemap.get_by_id(ids=neuron_IDs)\n",
    "# all_directional_pf1D_Decoder._ratemap = ratemap\n",
    "# all_directional_pf1D_Decoder.compute()\n",
    "# ratemap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3b046d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.filtered_epochs\n",
    "time_bin_size: float = 0.025\n",
    "t_start = 0.0\n",
    "t_end = 2093.8978568242164\n",
    "time_bin_edges: NDArray = np.arange(t_start, t_end + time_bin_size, time_bin_size)\n",
    "# time_bin_edges\n",
    "unique_units = np.unique(spikes_df['aclu']) # sorted\n",
    "unit_specific_time_binned_spike_counts: NDArray = np.array([\n",
    "    np.histogram(spikes_df.loc[spikes_df['aclu'] == unit, 't_rel_seconds'], bins=time_bin_edges)[0]\n",
    "    for unit in unique_units\n",
    "])\n",
    "unit_specific_time_binned_spike_counts\n",
    " \n",
    "## OUTPUT: time_bin_edges, unit_specific_time_binned_spike_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a7916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## `easy_independent_decoding`\n",
    "_decoded_pos_outputs, (unit_specific_time_binned_spike_counts, time_bin_edges, spikes_df) = easy_independent_decoding(long_LR_decoder, spikes_df=spikes_df, time_bin_size=time_bin_size, t_start=t_start, t_end=t_end)\n",
    "most_likely_positions, p_x_given_n, most_likely_position_indicies, flat_outputs_container = _decoded_pos_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1b3216",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_x_given_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809362d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(most_likely_positions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2a6c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "_decoded_pos_outputs = long_LR_decoder.decode(unit_specific_time_binned_spike_counts=unit_specific_time_binned_spike_counts, time_bin_size=time_bin_size, output_flat_versions=True, debug_print=True)\n",
    "# _decoded_pos_outputs = all_directional_pf1D_Decoder.decode(unit_specific_time_binned_spike_counts=unit_specific_time_binned_spike_counts, time_bin_size=0.020, output_flat_versions=True, debug_print=True)\n",
    "_decoded_pos_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbae7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_directional_pf1D_Decoder.neuron_IDs # array([  2,   5,   8,  10,  14,  15,  23,  24,  25,  26,  31,  32,  33,  41,  49,  50,  51,  55,  58,  64,  69,  70,  73,  74,  75,  76,  78,  82,  83,  85,  86,  90,  92,  93,  96, 109])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ee5251",
   "metadata": {},
   "outputs": [],
   "source": [
    "_decoded_pos_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c71ddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.laps import Laps\n",
    "\n",
    "\n",
    "curr_laps_df = Laps._compute_lap_dir_from_smoothed_velocity(laps_df=curr_laps_df, global_session=global_session, replace_existing=True)\n",
    "curr_laps_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd23d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_editor.plots.lap_epoch_widgets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe294f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.get_session_context()\n",
    "\n",
    "# Context(format_name= 'kdiba', animal= 'gor01', exper_name= 'one', session_name= '2006-6-09_1-22-43')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56697b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_df = deepcopy(epochs_editor.get_user_labeled_epochs_df())\n",
    "laps_df\n",
    "laps_df.to_clipboard(sep=',', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341aaedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop the first two laps:\n",
    "laps_df = laps_df[laps_df['lap_id'] > 2].reset_index(drop=True)\n",
    "laps_df\n",
    "## re-index\n",
    "laps_df['lap_id'] = laps_df.index\n",
    "laps_df['label'] = laps_df.index\n",
    "laps_df.to_clipboard(sep=',', excel=False)\n",
    "# laps_df[['start', 'stop', 'lap_dir']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad33e3c",
   "metadata": {
    "tags": [
     "active-2025-01-13"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import override_laps\n",
    "\n",
    "override_laps_df: Optional[pd.DataFrame] = UserAnnotationsManager.get_hardcoded_laps_override_dict().get(curr_active_pipeline.get_session_context(), None)\n",
    "if override_laps_df is not None:\n",
    "    print(f'overriding laps....')\n",
    "    display(override_laps_df)\n",
    "    override_laps(curr_active_pipeline, override_laps_df=override_laps_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ea0059",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacing_computation_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff3fcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "override_laps_df\n",
    "# override_laps_obj.filtered_by_lap_flat_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c601c54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_filtered_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b80e699",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.replace_session_laps_with_estimates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2482b0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.plotting.placemaps import plot_placefield_occupancy\n",
    "\n",
    "plot_placefield_occupancy(global_pf1D, plot_pos_bin_axes=True)\n",
    "# global_pf1D.plot_occupancy(plot_pos_bin_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2808c7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to separate out the main-track vs.the platforms so that I can impose continuity constraints (for filtering replays via step-sizes) only on the bins of the main track.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd9d391",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.epochs\n",
    "# global_session.epochs\n",
    "# long_session.epochs\n",
    "# short_session.epochs\n",
    "## find first lap\n",
    "global_laps\n",
    "\n",
    "# curr_active_pipeline.sess.position.to_dataframe()\n",
    "long_session.position.to_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca411f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "active_sess_config = deepcopy(curr_active_pipeline.active_sess_config)\n",
    "# absolute_start_timestamp: float = active_sess_config.absolute_start_timestamp\n",
    "loaded_track_limits = active_sess_config.loaded_track_limits # x_midpoint, \n",
    "loaded_track_limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d8bd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "(first_valid_pos_time, last_valid_pos_time) = curr_active_pipeline.find_first_and_last_valid_position_times()\n",
    "first_valid_pos_time, last_valid_pos_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f464ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.get_all_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e68bec8",
   "metadata": {
    "tags": [
     "active",
     "great"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.plotting.figure import pretty_plot\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.placefield import plot_1d_placecell_validations\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.placefield import plot_single_cell_1D_placecell_validation\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.placefield import _subfn_plot_pf1D_placefield\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import test_plotRaw_v_time\n",
    "\n",
    "\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "\n",
    "\n",
    "# global_session.config.plotting_config\n",
    "active_config = deepcopy(curr_active_pipeline.active_configs[global_epoch_name])\n",
    "active_pf1D = deepcopy(global_pf1D)\n",
    "\n",
    "fig = plt.figure(figsize=(23, 9.7), clear=True, num='test_plotRaw_v_time')\n",
    "# Need axes:\n",
    "# Layout Subplots in Figure:\n",
    "gs = fig.add_gridspec(1, 8)\n",
    "gs.update(wspace=0, hspace=0.05) # set the spacing between axes. # `wspace=0`` is responsible for sticking the pf and the activity axes together with no spacing\n",
    "ax_activity_v_time = fig.add_subplot(gs[0, :-1]) # all except the last element are the trajectory over time\n",
    "ax_pf_tuning_curve = fig.add_subplot(gs[0, -1], sharey=ax_activity_v_time) # The last element is the tuning curve\n",
    "# if should_include_labels:\n",
    "    # ax_pf_tuning_curve.set_title('Normalized Placefield', fontsize='14')\n",
    "ax_pf_tuning_curve.set_xticklabels([])\n",
    "ax_pf_tuning_curve.set_yticklabels([])\n",
    "\n",
    "\n",
    "cellind: int = 2\n",
    "\n",
    "kwargs = {}\n",
    "# jitter the curve_value for each spike based on the time it occured along the curve:\n",
    "spikes_color_RGB = kwargs.get('spikes_color', (0, 0, 0))\n",
    "spikes_alpha = kwargs.get('spikes_alpha', 0.8)\n",
    "# print(f'spikes_color: {spikes_color_RGB}')\n",
    "should_plot_bins_grid = kwargs.get('should_plot_bins_grid', False)\n",
    "\n",
    "should_include_trajectory = kwargs.get('should_include_trajectory', True) # whether the plot should include \n",
    "should_include_labels = kwargs.get('should_include_labels', True) # whether the plot should include text labels, like the title, axes labels, etc\n",
    "should_include_plotRaw_v_time_spikes = kwargs.get('should_include_spikes', True) # whether the plot should include plotRaw_v_time-spikes, should be set to False to plot completely with the new all spikes mode\n",
    "use_filtered_positions: bool = kwargs.pop('use_filtered_positions', False)\n",
    "\n",
    "# position_plot_kwargs = {'color': '#393939c8', 'linewidth': 1.0, 'zorder':5} | kwargs.get('position_plot_kwargs', {}) # passed into `active_epoch_placefields1D.plotRaw_v_time`\n",
    "position_plot_kwargs = {'color': '#757575c8', 'linewidth': 1.0, 'zorder':5} | kwargs.get('position_plot_kwargs', {}) # passed into `active_epoch_placefields1D.plotRaw_v_time`\n",
    "\n",
    "\n",
    "# _out = test_plotRaw_v_time(active_pf1D=active_pf1D, cellind=cellind)\n",
    "# spike_plot_kwargs = {'linestyle':'none', 'markersize':5.0, 'marker': '.', 'markerfacecolor':spikes_color_RGB, 'markeredgecolor':spikes_color_RGB, 'zorder':10} ## OLDER\n",
    "spike_plot_kwargs = {'zorder':10} ## OLDER\n",
    "\n",
    "\n",
    "# active_pf1D.plotRaw_v_time(cellind, ax=ax_activity_v_time, spikes_alpha=spikes_alpha,\n",
    "# \tposition_plot_kwargs=position_plot_kwargs,\n",
    "# \tspike_plot_kwargs=spike_plot_kwargs,\n",
    "# \tshould_include_labels=should_include_labels, should_include_trajectory=should_include_trajectory, should_include_spikes=should_include_plotRaw_v_time_spikes,\n",
    "# \tuse_filtered_positions=use_filtered_positions,\n",
    "# ) # , spikes_color=spikes_color, spikes_alpha=spikes_alpha\n",
    "\n",
    "_out = test_plotRaw_v_time(active_pf1D=active_pf1D, cellind=cellind, ax=ax_activity_v_time, spikes_alpha=spikes_alpha,\n",
    "    position_plot_kwargs=position_plot_kwargs,\n",
    "    spike_plot_kwargs=spike_plot_kwargs,\n",
    "    should_include_labels=should_include_labels, should_include_trajectory=should_include_trajectory, should_include_spikes=should_include_plotRaw_v_time_spikes,\n",
    "    use_filtered_positions=use_filtered_positions,\n",
    ")\n",
    "\n",
    "_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be863cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_out = _subfn_plot_pf1D_placefield(active_epoch_placefields1D=active_pf1D, placefield_cell_index=cellind,\n",
    "                                ax_activity_v_time=ax_activity_v_time, ax_pf_tuning_curve=ax_pf_tuning_curve, pf_tuning_curve_ax_position='right')\n",
    "_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b30c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as itt\n",
    "from mpl_multitab import MplMultiTab\n",
    "\n",
    "n_cells = active_placefields1D.ratemap.n_neurons\n",
    "out_figures_list = []\n",
    "out_axes_list = []\n",
    "\n",
    "if should_save:\n",
    "    curr_parent_out_path = plotting_config.active_output_parent_dir.joinpath('1d Placecell Validation')\n",
    "    curr_parent_out_path.mkdir(parents=True, exist_ok=True)        \n",
    "    \n",
    "# Tabbed Matplotlib Figure Mode:\n",
    "ui = MplMultiTab(title='plot_1d_placecell_validations')\n",
    "\n",
    "\n",
    "for a_decoder_name, a_decoder in track_templates.get_decoders_dict().items():\n",
    "    print(f'a_decoder_name: {a_decoder}')\n",
    "    curr_pf1D = a_decoder.pf\n",
    "    curr_pf1D.    \n",
    "\n",
    "    fig = ui.add_tab(f'Dataset {c.upper()}', f'Observation {m}')\n",
    "    ax = fig.subplots()\n",
    "    \n",
    "\n",
    "\n",
    "for i in np.arange(n_cells):\n",
    "    curr_cell_id = active_placefields1D.cell_ids[i]\n",
    "    # fig = ui.add_tab(f'Dataset {modifier_string}', f'Cell {curr_cell_id}') # Tabbed mode only\n",
    "    fig = ui.add_tab(f'Cell{curr_cell_id}')\n",
    "\n",
    "    fig, axs = plot_single_cell_1D_placecell_validation(active_placefields1D, i, extant_fig=fig, **(plot_kwargs or {}))\n",
    "    out_figures_list.append(fig)\n",
    "    out_axes_list.append(axs)\n",
    "\n",
    "# once done, save out as specified\n",
    "common_basename = active_placefields1D.str_for_filename(prefix_string=modifier_string)\n",
    "if should_save:\n",
    "    common_basename = active_placefields1D.str_for_filename(prefix_string=modifier_string)\n",
    "    if save_mode == 'separate_files':\n",
    "        # make a subdirectory for this run (with these parameters and such)\n",
    "        curr_specific_parent_out_path = curr_parent_out_path.joinpath(common_basename)\n",
    "        curr_specific_parent_out_path.mkdir(parents=True, exist_ok=True)\n",
    "        print(f'Attempting to write {n_cells} separate figures to {str(curr_specific_parent_out_path)}')\n",
    "        for i in np.arange(n_cells):\n",
    "            print('Saving figure {} of {}...'.format(i, n_cells))\n",
    "            curr_cell_id = active_placefields1D.cell_ids[i]\n",
    "            fig = out_figures_list[i]\n",
    "            # curr_cell_filename = 'pf1D-' + modifier_string + _filename_for_placefield(active_placefields1D, curr_cell_id) + '.png'\n",
    "            curr_cell_basename = '-'.join([common_basename, f'cell_{curr_cell_id:02d}'])\n",
    "            # add the file extension\n",
    "            curr_cell_filename = f'{curr_cell_basename}.png'\n",
    "            active_pf_curr_cell_output_filepath = curr_specific_parent_out_path.joinpath(curr_cell_filename)\n",
    "            fig.savefig(active_pf_curr_cell_output_filepath)\n",
    "    elif save_mode == 'pdf':\n",
    "        print('saving multipage pdf...')\n",
    "        curr_cell_basename = common_basename\n",
    "        # add the file extension\n",
    "        curr_cell_filename = f'{curr_cell_basename}-multipage_pdf.pdf'\n",
    "        pdf_save_path = curr_parent_out_path.joinpath(curr_cell_filename)\n",
    "        save_to_multipage_pdf(out_figures_list, save_file_path=pdf_save_path)\n",
    "    else:\n",
    "        raise ValueError\n",
    "    print('\\t done.')\n",
    "\n",
    "\n",
    "# ui.show() # Tabbed mode only\n",
    "_final_out = MatplotlibRenderPlots(name=f'{common_basename}', figures=out_figures_list, axes=out_axes_list, ui=ui)\n",
    "## OUTPUT: _final_out\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38ee8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_pf1D.run_spk_pos\n",
    "active_pf1D.spk_pos\n",
    "active_pf1D.run_spk_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c8e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_pf1D.ratemap_spiketrains\n",
    "active_pf1D.ratemap_spiketrains_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d290ccab",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = plot_1d_placecell_validations(active_pf1D, active_config.plotting_config, modifier_string='lap_only', should_save=False)\n",
    "# _out = curr_active_pipeline.display('_display_1d_placefield_validations', 'maze_any')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f853e158",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out.ui.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71088cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib_configuration_update(\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e362334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with matplotlib_interactivity(is_interactive=True):\n",
    "_out.figures[0].show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc6123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qclu_included_aclus = curr_active_pipeline.determine_good_aclus_by_qclu(included_qclu_values=[1,2,4,9])\n",
    "qclu_included_aclus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9e4db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_neuron_ids_list = [a_decoder.pf.ratemap.neuron_ids for a_decoder in (long_LR_decoder, long_RL_decoder, short_LR_decoder, short_RL_decoder)]\n",
    "original_neuron_ids_list = [a_decoder.pf.ratemap.neuron_ids for a_decoder in track_templates.get_decoders_dict().values()]\n",
    "original_neuron_ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9a96b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_names = track_templates.get_decoder_names() # ('long_LR', 'long_RL', 'short_LR', 'short_RL')\n",
    "decoder_names = TrackTemplates.get_decoder_names() # ('long_LR', 'long_RL', 'short_LR', 'short_RL')\n",
    "\n",
    "link = #00fff7\n",
    "link_visited = #ffaaff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a46a4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_print = True\n",
    "## INPUTS: included_qclu_values\n",
    "included_qclu_values = [1, 2]\n",
    "\n",
    "# modified_neuron_ids_dict = track_templates.determine_decoder_aclus_filtered_by_qclu(included_qclu_values=included_qclu_values)\n",
    "\n",
    "# filtered_track_templates = track_templates.filtered_by_frate_and_qclu(minimum_inclusion_fr_Hz=None, included_qclu_values=None)\n",
    "# filtered_track_templates = track_templates.filtered_by_frate_and_qclu(included_qclu_values=included_qclu_values)\n",
    "filtered_track_templates = track_templates.filtered_by_frate_and_qclu(minimum_inclusion_fr_Hz=5.0, included_qclu_values=[1, 2])\n",
    "\n",
    "# modified_neuron_ids_dict\n",
    "filtered_track_templates.decoder_neuron_IDs_list\n",
    "_out = dict()\n",
    "_out['_display_short_long_firing_rate_index_comparison'] = curr_active_pipeline.display(display_function='_display_short_long_firing_rate_index_comparison', active_session_configuration_context=None) # _display_short_long_firing_rate_index_comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a1ed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_included_aclus_dict = {}\n",
    "# for a_decoder in track_templates.get_decoders_dict().values():\n",
    "    # a_decoder.pf.spikes_df\n",
    "for a_decoder_name, a_decoder in track_templates.get_decoders_dict().items():\n",
    "    neuron_identities: pd.DataFrame = deepcopy(a_decoder.pf.filtered_spikes_df).spikes.extract_unique_neuron_identities()\n",
    "    if debug_print:\n",
    "        print(f\"original {len(neuron_identities)}\")\n",
    "    filtered_neuron_identities: pd.DataFrame = neuron_identities[neuron_identities.neuron_type == NeuronType.PYRAMIDAL]\n",
    "    if debug_print:\n",
    "        print(f\"post PYRAMIDAL filtering {len(filtered_neuron_identities)}\")\n",
    "    filtered_neuron_identities = filtered_neuron_identities[['aclu', 'shank', 'cluster', 'qclu']]\n",
    "    filtered_neuron_identities = filtered_neuron_identities[np.isin(filtered_neuron_identities.qclu, included_qclu_values)] # drop [6, 7], which are said to have double fields - 80 remain\n",
    "    if debug_print:\n",
    "        print(f\"post (qclu != [6, 7]) filtering {len(filtered_neuron_identities)}\")\n",
    "    # filtered_neuron_identities\n",
    "    final_included_aclus = filtered_neuron_identities['aclu'].to_numpy()\n",
    "    final_included_aclus_dict[a_decoder_name] = final_included_aclus.tolist()\n",
    "\n",
    "\n",
    "final_included_aclus_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543a7317",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display_output_history_list\n",
    "curr_active_pipeline.display_output_last_added_context\n",
    "curr_active_pipeline.last_added_display_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd79d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_templates.any_decoder_neuron_IDs\n",
    "track_templates.decoder_neuron_IDs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acad4458",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650eea58",
   "metadata": {
    "tags": [
     "all",
     "spike_raster_window",
     "display",
     "gui",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import Spike2DRaster\n",
    "from pyphoplacecellanalysis.GUI.Qt.SpikeRasterWindows.Spike3DRasterWindowWidget import Spike3DRasterWindowWidget\n",
    "from pyphoplacecellanalysis.GUI.Qt.PlaybackControls.Spike3DRasterBottomPlaybackControlBarWidget import Spike3DRasterBottomPlaybackControlBar\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import SynchronizedPlotMode\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.spike_raster_widgets import _setup_spike_raster_window_for_debugging\n",
    "\n",
    "# For PlotWidget\n",
    "pg.setConfigOptions(useOpenGL=True)\n",
    "\n",
    "# curr_active_pipeline.reload_default_display_functions()\n",
    "# Gets the existing SpikeRasterWindow or creates a new one if one doesn't already exist:\n",
    "spike_raster_window, (active_2d_plot, active_3d_plot, main_graphics_layout_widget, main_plot_widget, background_static_scroll_plot_widget) = Spike3DRasterWindowWidget.find_or_create_if_needed(curr_active_pipeline, force_create_new=True, use_docked_pyqtgraph_plots=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f87367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.SpikeRasterWindows.Spike3DRasterWindowWidget import Spike3DRasterWindowWidget\n",
    "# active_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.plot._display_spike_rasters_pyqtplot_2D(**kwargs).values()\n",
    "\n",
    "\n",
    "active_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.display('_display_spike_rasters_pyqtplot_2D', active_session_configuration_context='maze_any')\n",
    "# active_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.dsiplay('_display_spike_rasters_window')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2bce24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.SpikeRasterWindows.Spike3DRasterWindowWidget import Spike3DRasterWindowWidget\n",
    "\n",
    "# spike_raster_window, (active_2d_plot, active_3d_plot, main_graphics_layout_widget, main_plot_widget, background_static_scroll_plot_widget) = Spike3DRasterWindowWidget.find_or_create_if_needed(curr_active_pipeline, force_create_new=False)\n",
    "spike_raster_window, (active_2d_plot, active_3d_plot, *_out_args) = Spike3DRasterWindowWidget.find_or_create_if_needed(curr_active_pipeline, force_create_new=False)\n",
    "\n",
    "active_2d_plot\n",
    "active_3d_plot\n",
    "spike_raster_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcd6c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_2d_plot.find_matplotlib_render_plot_widget('interval_overview')\n",
    "intervals_overview_dock, intervals_overview_time_sync_pyqtgraph_widget = active_2d_plot.find_dock_item_tuple(identifier='interval_overview')\n",
    "# root_graphics_layout_widget = active_2d_plot.ui.matplotlib_view_widgets[name].getRootGraphicsLayoutWidget()\n",
    "# plot_item = active_2d_plot.ui.matplotlib_view_widgets[name].getRootPlotItem()\n",
    "intervals_overview_root_graphics_layout_widget = intervals_overview_time_sync_pyqtgraph_widget.getRootGraphicsLayoutWidget()\n",
    "intervals_overview_plot_item = intervals_overview_time_sync_pyqtgraph_widget.getRootPlotItem()\n",
    "\n",
    "\n",
    "# intervals_overview_plot_item.set\n",
    "# intervals_plot_item.setXRange(self.spikes_window.active_window_start_time, self.spikes_window.active_window_end_time, padding=0)\n",
    "\n",
    "intervals_overview_plot_item.setXRange(active_2d_plot.spikes_window.total_data_start_time, active_2d_plot.spikes_window.total_data_end_time, padding=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0c8093",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_overview_plot_item.setClipToView(True) # Usually default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac0b331",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.get_leaf_only_flat_dock_identifiers_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd7284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_docked_pyqtgraph_plots_mode: bool = spike_raster_window.params.use_docked_pyqtgraph_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a46242",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_global_menus_actionsDict, global_flat_action_dict, _all_outputs_dict = _setup_spike_raster_window_for_debugging(spike_raster_window, wants_docked_raster_window_track=True, enable_interval_overview_track=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39cfd03",
   "metadata": {
    "tags": [
     "run-group-mergedcolorplot",
     "run-spike_raster_window_test"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import Spike2DRaster\n",
    "from pyphoplacecellanalysis.GUI.Qt.SpikeRasterWindows.Spike3DRasterWindowWidget import Spike3DRasterWindowWidget\n",
    "from pyphoplacecellanalysis.GUI.Qt.PlaybackControls.Spike3DRasterBottomPlaybackControlBarWidget import Spike3DRasterBottomPlaybackControlBar\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import SynchronizedPlotMode\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.spike_raster_widgets import _setup_spike_raster_window_for_debugging\n",
    "\n",
    "# For PlotWidget\n",
    "pg.setConfigOptions(useOpenGL=True)\n",
    "# pg.setConfigOptions(useOpenGL=False)\n",
    "\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-Spike3DRasterWindowWidget.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "# Gets the existing SpikeRasterWindow or creates a new one if one doesn't already exist:\n",
    "spike_raster_window, (active_2d_plot, active_3d_plot, _all_outputs_dict) = Spike3DRasterWindowWidget.find_or_create_if_needed(curr_active_pipeline, force_create_new=True,\n",
    "    wants_docked_raster_window_track=True, enable_interval_overview_track=True, allow_replace_hardcoded_main_plots_with_tracks=True,\n",
    ")\n",
    "main_graphics_layout_widget = _all_outputs_dict['main_graphics_layout_widget'] \n",
    "main_plot_widget = _all_outputs_dict['main_plot_widget']\n",
    "background_static_scroll_plot_widget = _all_outputs_dict['background_static_scroll_plot_widget']\n",
    "\n",
    "all_global_menus_actionsDict = _all_outputs_dict['all_global_menus_actionsDict']\n",
    "global_flat_action_dict = _all_outputs_dict['global_flat_action_dict']\n",
    "# all_global_menus_actionsDict, global_flat_action_dict, _all_outputs_dict = _setup_spike_raster_window_for_debugging(spike_raster_window, wants_docked_raster_window_track=True, enable_interval_overview_track=True, allow_replace_hardcoded_main_plots_with_tracks=False)\n",
    "# all_global_menus_actionsDict, global_flat_action_dict, _all_outputs_dict = _setup_spike_raster_window_for_debugging(spike_raster_window, wants_docked_raster_window_track=True, enable_interval_overview_track=True, allow_replace_hardcoded_main_plots_with_tracks=False)\n",
    "\n",
    "# # preview_overview_scatter_plot: pg.ScatterPlotItem  = active_2d_plot.plots.preview_overview_scatter_plot # ScatterPlotItem \n",
    "# # preview_overview_scatter_plot.setDownsampling(auto=True, method='subsample', dsRate=10)\n",
    "# main_graphics_layout_widget: pg.GraphicsLayoutWidget = active_2d_plot.ui.main_graphics_layout_widget\n",
    "# wrapper_layout: pg.QtWidgets.QVBoxLayout = active_2d_plot.ui.wrapper_layout\n",
    "# main_content_splitter = active_2d_plot.ui.main_content_splitter # QSplitter\n",
    "# layout = active_2d_plot.ui.layout\n",
    "# background_static_scroll_window_plot = active_2d_plot.plots.background_static_scroll_window_plot # PlotItem\n",
    "# main_plot_widget = active_2d_plot.plots.main_plot_widget # PlotItem\n",
    "# active_window_container_layout = active_2d_plot.ui.active_window_container_layout # GraphicsLayout, first item of `main_graphics_layout_widget` -- just the active raster window I think, there is a strange black space above it\n",
    "# bottom_bar: Spike3DRasterBottomPlaybackControlBar = spike_raster_window.bottom_playback_control_bar_widget\n",
    "# # bottom_bar.log_print('test manual log entry')\n",
    "# bottom_bar.add_log_line('test manual log entry')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ed0bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spike_raster_window.on_crosshair_trace_toggled()\n",
    "active_2d_plot.layout_dockGroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7009ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "# decoding_time_bin_size = 0.025\n",
    "# filter_epochs_decoder_result, active_filter_epochs, default_figure_name = long_results['specific_epochs_decoding'][('Ripples', decoding_time_bin_size)]\n",
    "\n",
    "_out = dict()\n",
    "_out['_display_plot_decoded_epoch_slices'] = curr_active_pipeline.display(display_function='_display_plot_decoded_epoch_slices', active_session_configuration_context=IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43',filter_name='maze2_any',lap_dir='any'), filter_epochs='replay') # _display_plot_decoded_epoch_slices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e54270",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import _build_additional_window_menus\n",
    "## Build the additional menus:\n",
    "output_references = _build_additional_window_menus(spike_raster_window, owning_pipeline_reference=curr_active_pipeline, computation_result, active_display_fn_identifying_ctx) ## the menus on the other hand take the entire pipeline, because they might need that valuable DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38054838",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recompute the one and two-step decoding computations continuously\n",
    "\n",
    "# ['_perform_position_decoding_computation', '_perform_two_step_position_decoding_computation']\n",
    "# ['position_decoding', 'position_decoding_two_step']\n",
    "\n",
    "debug_print: bool = False\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_perform_position_decoding_computation', '_perform_two_step_position_decoding_computation'],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t  computation_kwargs_list=[{'override_decoding_time_bin_size': 0.025, 'debug_print': debug_print}, {'debug_print': debug_print}],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t  enabled_filter_names=None, fail_on_exception=True, debug_print=debug_print)\n",
    "\n",
    "active_one_step_decoder = curr_active_pipeline.computation_results[active_config_name].computed_data.get('pf2D_Decoder', None)\n",
    "\n",
    "\n",
    "assert active_one_step_decoder is not None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b8665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_one_step_decoder.flat_p_x_given_n.shape # (472, 66151)\n",
    "np.shape(active_one_step_decoder.p_x_given_n) # (59, 8, 66151)\n",
    "np.shape(active_one_step_decoder.P_x) # (472, 1)\n",
    "active_one_step_decoder.original_position_data_shape # (59, 8)\n",
    "active_one_step_decoder.flat_position_size # 472\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e690d756",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_perform_two_step_position_decoding_computation'],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t  computation_kwargs_list=[{'ndim': 2, 'debug_print': debug_print}],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t  enabled_filter_names=None, fail_on_exception=True, debug_print=debug_print)\n",
    "\n",
    "active_two_step_decoder = curr_active_pipeline.computation_results[active_config_name].computed_data.get('pf2D_TwoStepDecoder', None)\n",
    "assert active_two_step_decoder is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb672a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_one_step_decoder.xbin\n",
    "active_one_step_decoder.ybin\n",
    "\n",
    "active_two_step_decoder.xbin\n",
    "active_two_step_decoder.ybin\n",
    "\n",
    "# active_two_step_decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a82d026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import AddNewDecodedPosition_MatplotlibPlotCommand, AddNewLongShortDecodedEpochSlices_MatplotlibPlotCommand, AddNewTrackTemplatesDecodedEpochSlicesRows_MatplotlibPlotCommand # for add matplotlib plot action\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import AddNewDirectionalDecodedEpochs_MatplotlibPlotCommand, AddNewDecodedPosteriors_MatplotlibPlotCommand, AddNewDecodedEpochMarginal_MatplotlibPlotCommand\n",
    "from pyphoplacecellanalysis.GUI.Qt.Menus.SpecificMenus.CreateLinkedWidget_MenuProvider import CreateNewTimeSynchronizedPlotterCommand, CreateNewTimeSynchronizedCombinedPlotterCommand\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.TimeSynchronizedPositionDecoderPlotter import TimeSynchronizedPositionDecoderPlotter\n",
    "\n",
    "active_config_name = None # kwargs.get('active_config_name', None)\n",
    "active_config_name = global_any_name\n",
    "active_context = None\n",
    "display_output = {}\n",
    "active_pf_2D_dt = curr_active_pipeline.computation_results[active_config_name].computed_data.get('pf2D_dt', None)\n",
    "active_one_step_decoder = curr_active_pipeline.computation_results[active_config_name].computed_data.get('pf2D_Decoder', None)\n",
    "active_two_step_decoder = curr_active_pipeline.computation_results[active_config_name].computed_data.get('pf2D_TwoStepDecoder', None)\n",
    "_out = CreateNewTimeSynchronizedPlotterCommand(spike_raster_window, active_pf_2D_dt=active_pf_2D_dt, plotter_type='decoder', curr_active_pipeline=curr_active_pipeline, active_context=active_context, active_config_name=active_config_name, display_output=display_output, action_identifier='actionTimeSynchronizedDecoderPlotter')\n",
    "_out.execute()\n",
    "a_plotter_obj, _a_conn = display_output['synchronizedPlotter_decoder']\n",
    "active_ax = a_plotter_obj.ui.root_plot\n",
    "a_plotter_obj: TimeSynchronizedPositionDecoderPlotter = a_plotter_obj # TimeSynchronizedPositionDecoderPlotter \n",
    "(long_rects_outputs, short_rects_outputs) = a_plotter_obj.add_track_shapes()\n",
    "a_plotter_obj.update(t=active_2d_plot.active_window_start_time, defer_render=False)\n",
    "\n",
    "## OUTPUTS: active_ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fd0483",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_one_step_decoder.xbin\n",
    "active_one_step_decoder.ybin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ea8f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_plotter_obj.params.x_range\n",
    "a_plotter_obj.params.y_range\n",
    "a_plotter_obj.params.image_bounds_extent # [0.0, 86.33093525179856, 287.7697841726619, 115.10791366906471]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e38ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import LinearTrackDimensions, test_LinearTrackDimensions_2D_pyqtgraph\n",
    "\n",
    "long_track_dims = LinearTrackDimensions(track_length=170.0)\n",
    "short_track_dims = LinearTrackDimensions(track_length=100.0)\n",
    "\n",
    "app, w, cw, (ax0, ax1), (long_track_dims, long_rect_items, long_rects), (short_track_dims, short_rect_items, short_rects) = test_LinearTrackDimensions_2D_pyqtgraph(long_track_dims, short_track_dims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ae2b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import LinearTrackInstance\n",
    "from neuropy.utils.mixins.dict_representable import overriding_dict_with\n",
    "\n",
    "loaded_track_limits = {'long_xlim': np.array([59.0774, 228.69]),\n",
    "    'long_unit_xlim': np.array([0.205294, 0.794698]),\n",
    "    'short_xlim': np.array([94.0156, 193.757]),\n",
    "    'short_unit_xlim': np.array([0.326704, 0.673304]),\n",
    "    'long_ylim': np.array([138.164, 146.12]),\n",
    "    'long_unit_ylim': np.array([0.48012, 0.507766]),\n",
    "    'short_ylim': np.array([138.021, 146.263]),\n",
    "    'short_unit_ylim': np.array([0.479622, 0.508264]),\n",
    "}\n",
    "\n",
    "## INPUTS: active_ax\n",
    "\n",
    "long_track_inst, short_track_inst = LinearTrackInstance.init_LS_tracks_from_loaded_track_limits(loaded_track_limits=loaded_track_limits)\n",
    "# long_rects_outputs, short_rects_outputs = \n",
    "# long_track_inst\n",
    "# # Centered above and below the y=0.0 line:\n",
    "# long_offset = (long_track_inst.grid_bin_bounds.center_point[0], 0.75)\n",
    "# short_offset = (short_track_inst.grid_bin_bounds.center_point[0], -0.75)\n",
    "\n",
    "# active_ax = a_plotter_obj.ui.root_plot\n",
    "\n",
    "\n",
    "# long_track_combined_collection, long_rect_items, long_rects = long_track_inst.plot_rects(active_ax)\n",
    "# short_track_combined_collection, short_rect_items, short_rects = short_track_inst.plot_rects(active_ax)\n",
    "\n",
    "# long_epoch_matplotlib_config = long_short_display_config_manager.long_epoch_config.as_matplotlib_kwargs()\n",
    "# long_kwargs = deepcopy(long_epoch_matplotlib_config)\n",
    "long_kwargs = dict(edgecolor='#0000FFFF', facecolor=\"#0000FFB7\")\n",
    "# long_kwargs = dict(edgecolor='#000000ff', facecolor='#000000ff')\n",
    "# long_rects_outputs = long_track_inst.plot_rects(active_ax, offset=long_offset, matplotlib_rect_kwargs_override=overriding_dict_with(lhs_dict=long_kwargs, **dict(linewidth=2, zorder=-99)))\n",
    "long_rects_outputs = long_track_inst.plot_rects(active_ax, matplotlib_rect_kwargs_override=overriding_dict_with(lhs_dict=long_kwargs, **dict(linewidth=2, zorder=-99)))\n",
    "\n",
    "# short_epoch_matplotlib_config = long_short_display_config_manager.short_epoch_config.as_matplotlib_kwargs()\n",
    "# short_kwargs = deepcopy(short_epoch_matplotlib_config)\n",
    "short_kwargs = dict(edgecolor='#FF0000FF', facecolor=\"#FF0000B7\")\n",
    "# short_kwargs = dict(edgecolor='#000000ff', facecolor='#000000ff')\n",
    "# short_rects_outputs = short_track_inst.plot_rects(active_ax, offset=short_offset, matplotlib_rect_kwargs_override=overriding_dict_with(lhs_dict=short_kwargs, **dict(linewidth=2, zorder=-99)))\n",
    "short_rects_outputs = short_track_inst.plot_rects(active_ax, matplotlib_rect_kwargs_override=overriding_dict_with(lhs_dict=short_kwargs, **dict(linewidth=2, zorder=-99)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11968a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.Mixins.InteractivePlotterMixins import InteractivePyvistaPlotter_PointAndPathPlottingMixin\n",
    "from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.InteractivePlaceCellDataExplorer import InteractivePlaceCellDataExplorer\n",
    "\n",
    "_out = dict()\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out['_display_3d_interactive_spike_and_behavior_browser'] = curr_active_pipeline.display(display_function='_display_3d_interactive_spike_and_behavior_browser', active_session_configuration_context=IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19',filter_name='maze_any',lap_dir='any')) # _display_3d_interactive_spike_and_behavior_browser\n",
    "_out['_display_3d_interactive_spike_and_behavior_browser']\n",
    "ipspikesDataExplorer = _out['_display_3d_interactive_spike_and_behavior_browser']['ipspikesDataExplorer']\n",
    "p = _out['_display_3d_interactive_spike_and_behavior_browser']['plotter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40395133",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipspikesDataExplorer.animal_current_location_point ## actor\n",
    "ipspikesDataExplorer.plots_data['animal_current_location_point']\n",
    "ipspikesDataExplorer.plots['animal_current_location_point']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06df5a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipspikesDataExplorer.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af35fc52",
   "metadata": {},
   "source": [
    "## Adding Grid_bin_bound position validations as tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff98bb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_man = curr_active_pipeline.get_output_manager()\n",
    "fig_man.get_figure_output_parent_and_basename(final_context=curr_active_pipeline.get_session_context(), make_folder_if_needed=False)\n",
    "\n",
    "# FileOutputManager(figure_output_location=<FigureOutputLocation.DAILY_PROGRAMMATIC_OUTPUT_FOLDER: 'daily_programmatic_output_folder'>, context_to_path_mode=<ContextToPathMode.HIERARCHY_UNIQUE: 'hierarchy_unique'>, override_output_parent_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efd0cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import SynchronizedPlotMode\n",
    "\n",
    "## Add to timeline\n",
    "active_2d_plot: Spike2DRaster = active_2d_plot\n",
    "\n",
    "\n",
    "_bounds_validation_track_axs = {}\n",
    "a_dock_identifier: str = 'BoundsValidation_x'\n",
    "_bounds_validation_track_axs[a_dock_identifier] = active_2d_plot.add_new_matplotlib_render_plot_widget(name=a_dock_identifier, sync_mode=SynchronizedPlotMode.TO_GLOBAL_DATA)[2][0]\n",
    "\n",
    "a_dock_identifier: str = 'BoundsValidation_y'\n",
    "_bounds_validation_track_axs[a_dock_identifier] = active_2d_plot.add_new_matplotlib_render_plot_widget(name=a_dock_identifier, sync_mode=SynchronizedPlotMode.TO_GLOBAL_DATA)[2][0]\n",
    "_bounds_validation_track_axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa3dcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, ax in _bounds_validation_track_axs.items():\n",
    "\tax.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2a0dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_out = dict()\n",
    "_out['_display_grid_bin_bounds_validation_x'] = curr_active_pipeline.display(display_function='_display_grid_bin_bounds_validation', active_session_configuration_context=None, is_x_axis=True, ax=_bounds_validation_track_axs['BoundsValidation_x']) # _display_grid_bin_bounds_validation\n",
    "_out['_display_grid_bin_bounds_validation_y'] = curr_active_pipeline.display(display_function='_display_grid_bin_bounds_validation', active_session_configuration_context=None, is_x_axis=False, ax=_bounds_validation_track_axs['BoundsValidation_y']) # _display_grid_bin_bounds_validation\n",
    "\n",
    "## sync only after so the grid_bin_bounds lines extend across the whole thing\n",
    "active_2d_plot.sync_matplotlib_render_plot_widget('BoundsValidation_x', sync_mode=SynchronizedPlotMode.TO_WINDOW)\n",
    "active_2d_plot.sync_matplotlib_render_plot_widget('BoundsValidation_y', sync_mode=SynchronizedPlotMode.TO_WINDOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1ba555",
   "metadata": {},
   "source": [
    "## Other from pre-2025-07-02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b952fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_rects_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fe14e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_one_step_decoder.P_x.shape # active_one_step_decoder.P_x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f12a92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_plotter_obj.params.image_bounds_extent\n",
    "a_plotter_obj.params.x_range\n",
    "a_plotter_obj.params.y_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bee998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_plotter_obj.params.posterior_variable_to_render = 'p_x_given_n'\n",
    "a_plotter_obj.posterior_variable_to_render = 'p_x_given_n_and_x_prev'\n",
    "a_plotter_obj.update(t=active_2d_plot.active_window_start_time, defer_render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfc5daa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf50adb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.params.enable_non_marginalized_raw_result = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7bcfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_plotter_obj.time_window_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca93e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.active_window_start_time\n",
    "# active_2d_plot.animation_active_time_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc81db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "on_window_changed(self, start_t, end_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab851679",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca040e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_flat_action_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6a535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: global_flat_action_dict\n",
    "\n",
    "menu_commands = [\n",
    "    # 'AddTimeCurves.Position', ## 2025-03-11 02:32 Running this too soon after launching the window causes weird black bars on the top and bottom of the window\n",
    "    'AddTimeCurves.ThetaPhase',\n",
    "    # 'DockedWidgets.LongShortDecodedEpochsDockedMatplotlibView',\n",
    "    # 'DockedWidgets.DirectionalDecodedEpochsDockedMatplotlibView',\n",
    "    # 'DockedWidgets.TrackTemplatesDecodedEpochsDockedMatplotlibView',\n",
    "    # 'DockedWidgets.Pseudo2DDecodedEpochsDockedMatplotlibView', # [/c:/Users/pho/repos/Spike3DWorkEnv/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/Qt/Menus/SpecificMenus/DockedWidgets_MenuProvider.py:141](vscode://file/c:/Users/pho/repos/Spike3DWorkEnv/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/Qt/Menus/SpecificMenus/DockedWidgets_MenuProvider.py:141)`'actionPseudo2DDecodedEpochsDockedMatplotlibView': AddNewDecodedPosteriors_MatplotlibPlotCommand`\n",
    "    #  'DockedWidgets.ContinuousPseudo2DDecodedMarginalsDockedMatplotlibView',\n",
    "]\n",
    "# menu_commands = ['actionPseudo2DDecodedEpochsDockedMatplotlibView', 'actionContinuousPseudo2DDecodedMarginalsDockedMatplotlibView'] # , 'AddTimeIntervals.SessionEpochs'\n",
    "\n",
    "# Run after a 0.5 second delay\n",
    "for a_command in menu_commands:\n",
    "    # all_global_menus_actionsDict[a_command].trigger()\n",
    "    global_flat_action_dict[a_command].trigger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce46022",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.clear_all_3D_time_curves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b6ad1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.update_3D_time_curves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17552aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_time_curves_datasource = active_2d_plot.params.time_curves_datasource\n",
    "active_time_curves_datasource.merge(on='t', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac52164",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.plots.time_curves['default_plot_datasource.y position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1a31e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_plot_item = list(active_2d_plot.plots.time_curves.values())[0]\n",
    "\n",
    "## override theta phase pen:\n",
    "## firing statistics to bins instead of boolean masking by those meeting criteria\n",
    "spikes_df: pd.DataFrame = get_proper_global_spikes_df(curr_active_pipeline)\n",
    "theta_phase_radians = spikes_df['theta_phase_radians'].to_numpy()\n",
    "\n",
    "\n",
    "cmap = pg.colormap.get('CET-C2s') # rainbow\n",
    "\n",
    "# Example 1: Gradient pen\n",
    "# cmap = pg.colormap.get('CET-L17') # prepare a linear color map\n",
    "# cmap.reverse()                    # reverse it to put light colors at the top \n",
    "pen = cmap.getPen(span=(0.0, (2.0*np.pi)), width=5) # gradient from blue (y=0) to white (y=1)\n",
    "# plot a curve drawn with a pen colored according to y value:\n",
    "curve1 = pg.PlotDataItem(y=y_data1, pen=pen)\n",
    "\n",
    "\n",
    "theta_cmap = cmap.map(theta_phase_radians, mode='qcolor') # List[QColor]\n",
    "theta_cmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997b5694",
   "metadata": {},
   "outputs": [],
   "source": [
    "pen = pg.mkPen(theta_cmap, width=2)\n",
    "\n",
    "# for i in range(len(x)-1):\n",
    "#     t = i/(len(x)-1)\n",
    "#     pen = pg.mkPen(cmap.map(t, mode='qcolor'), width=2)    \n",
    "    \n",
    "# pen = pg.mkPen(\n",
    "#     color='red',           # Color: string, tuple (R,G,B), or QColor\n",
    "#     width=2,              # Line width in pixels\n",
    "#     style=QtCore.Qt.DashLine,  # Line style: SolidLine, DashLine, DotLine, etc.\n",
    "#     cosmetic=True,        # Whether line width scales with zoom\n",
    "#     capStyle=QtCore.Qt.RoundCap,  # End cap style\n",
    "#     joinStyle=QtCore.Qt.RoundJoin  # Join style for corners\n",
    "# )\n",
    "a_plot_item.setPen(pen)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f08cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = pg.mkQApp()\n",
    "w = pg.PlotWidget()\n",
    "\n",
    "x = np.linspace(0, 10, 200)\n",
    "y = np.sin(x)                       # or any “value” array\n",
    "cmap = pg.colormap.get('CET-C2s')       # rainbow\n",
    "\n",
    "for i in range(len(x)-1):\n",
    "    t = i/(len(x)-1)\n",
    "    pen = pg.mkPen(cmap.map(t, mode='qcolor'), width=2)\n",
    "    w.plot(x[i:i+2], y[i:i+2], pen=pen)\n",
    "\n",
    "w.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0101d1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import FixedCustomColormaps\n",
    "\n",
    "# active_cmap = FixedCustomColormaps.get_custom_greyscale_with_low_values_dropped_cmap(low_value_cutoff=0.01, full_opacity_threshold=0.25, invert_for_black_bg=True)\n",
    "active_cmap = FixedCustomColormaps.get_custom_greyscale_with_low_values_dropped_cmap(low_value_cutoff=0.01, full_opacity_threshold=0.25, invert_for_black_bg=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742ae0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_2d_plot.dock_manager_widget\n",
    "active_dockGroup_dock_dict = active_2d_plot.get_dockGroup_dock_dict()\n",
    "# active_dockGroup_dock_dict['ContinuousDecode_ - t_bin_size: 0.025']\n",
    "\n",
    "active_dockGroup_dock_dict['ContinuousDecode_ - t_bin_size: 0.025']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e4e5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_2d_plot.root_window.ui.menus.global_window_menus.docked_widgets\n",
    "\n",
    "active_2d_plot.ui.menus.global_window_menus.docked_widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3832eac4",
   "metadata": {},
   "source": [
    "#### Testing a Matplotlib-backed widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada6c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.PyqtgraphTimeSynchronizedWidget import PyqtgraphTimeSynchronizedWidget  \n",
    "\n",
    "active_2d_plot: Spike2DRaster = active_2d_plot  \n",
    "\n",
    "\n",
    "a_dock_id: str = 'ContinuousDecode_long_LR - t_bin_size: 0.025'\n",
    "# a_dock, widget = active_2d_plot.find_dock_item_tuple(identifier='ContinuousDecode_long_LR')\n",
    "# a_dock, widget = active_2d_plot.find_dock_item_tuple(identifier='ContinuousDecode_long_RL')\n",
    "a_dock, widget = active_2d_plot.find_dock_item_tuple(identifier=a_dock_id)\n",
    "# widget.plots\n",
    "# widget.plots_data\n",
    "# img.set_cmap('viridis')  # or any \n",
    "an_ax = widget.ax\n",
    "# widget\n",
    "an_ax.set_facecolor('black')  # Set axes background to black\n",
    "# an_ax.set_facecolor('white')  # Set axes background to white\n",
    "\n",
    "\n",
    "# img.set_cmap('viridis')  # or any valid colormap name\n",
    "# widget.getRootPlotItem().setXRange(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time, padding=0) ## global frame  \n",
    "# widget.update(None)  \n",
    "\n",
    "im_posterior_x = widget.plots.im_posterior_x\n",
    "# im_posterior_x.set_cmap(active_cmap)  # or any valid colormap name\n",
    "# widget.update()\n",
    "# widget\n",
    "# plt.draw()\n",
    "im_posterior_x # AxesImage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff5bcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.PyqtgraphTimeSynchronizedWidget import PyqtgraphTimeSynchronizedWidget  \n",
    "\n",
    "active_2d_plot: Spike2DRaster = active_2d_plot  \n",
    "\n",
    "\n",
    "a_dock_id: str = 'ContinuousDecode_long_LR - t_bin_size: 0.025'\n",
    "# a_dock, widget = active_2d_plot.find_dock_item_tuple(identifier='ContinuousDecode_long_LR')\n",
    "# a_dock, widget = active_2d_plot.find_dock_item_tuple(identifier='ContinuousDecode_long_RL')\n",
    "a_dock, widget = active_2d_plot.find_dock_item_tuple(identifier=a_dock_id)\n",
    "# widget.plots\n",
    "# widget.plots_data\n",
    "# img.set_cmap('viridis')  # or any \n",
    "an_ax = widget.ax\n",
    "# widget\n",
    "an_ax.set_facecolor('black')  # Set axes background to black\n",
    "# an_ax.set_facecolor('white')  # Set axes background to white\n",
    "\n",
    "\n",
    "# img.set_cmap('viridis')  # or any valid colormap name\n",
    "# widget.getRootPlotItem().setXRange(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time, padding=0) ## global frame  \n",
    "# widget.update(None)  \n",
    "\n",
    "im_posterior_x = widget.plots.im_posterior_x\n",
    "# im_posterior_x.set_cmap(active_cmap)  # or any valid colormap name\n",
    "# widget.update()\n",
    "# widget\n",
    "# plt.draw()\n",
    "im_posterior_x # AxesImage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bbad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.temporal_axis_length\n",
    "active_2d_plot.active_time_window\n",
    "\n",
    "np.diff(active_2d_plot.active_time_window)\n",
    "\n",
    "active_2d_plot.active_window_duration\n",
    "active_2d_plot.render_window_duration\n",
    "(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e063fd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "widget.plots\n",
    "# widget.plots_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e86d20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images = an_ax.get_images()\n",
    "images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884493a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_img = images[0]\n",
    "an_img\n",
    "an_img.set_cmap(active_cmap)  # or any valid colormap name\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5599478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import FigureToImageHelpers\n",
    "\n",
    "## INPUTS: im_posterior_x\n",
    "relative_data_output_parent_folder = Path('data').resolve()\n",
    "Assert.path_exists(relative_data_output_parent_folder)\n",
    "\n",
    "output_pdf_path: Path = relative_data_output_parent_folder.joinpath('timeline_exported.pdf')\n",
    "# FigureToImageHelpers.export_axesimage_to_paged_pdf(ax_image=im_posterior_x, x_extent=(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time), chunk_width=active_2d_plot.active_window_duration, output_pdf_path=output_pdf_path, figsize=(8, 11), dpi=150, override_cmap=None, debug_max_num_pages=5)\n",
    "FigureToImageHelpers.export_wrapped_axesimage_to_paged_pdf(ax_image=im_posterior_x, x_extent=(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time), chunk_width=active_2d_plot.active_window_duration, output_pdf_path=output_pdf_path, figsize=(8, 11), dpi=150,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\trows_per_page=5, debug_max_num_pages=25,\t\t    \n",
    "                                                # rows_per_page=15, debug_max_num_pages=3,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e5764e",
   "metadata": {},
   "source": [
    "#### Testing multiple matplotlib tracks at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74cc8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "\n",
    "formatted_title_strings_dict = DisplayColorsEnum.get_matplotlib_formatted_title_dict()\n",
    "decoder_names_list: List[str] = list(formatted_title_strings_dict.keys())\n",
    "\n",
    "## get the whole stack\n",
    "active_dockGroup_dock_dict = active_2d_plot.get_dockGroup_dock_dict()\n",
    "_curr_active_dock_group = active_dockGroup_dock_dict['ContinuousDecode_ - t_bin_size: 0.025'] # {'long_LR': 'Long◀', 'long_RL': 'Long▶', 'short_LR': 'Short◀', 'short_RL': 'Short▶'}\n",
    "_curr_decoders_dock_item_names_list: List[str] = [v.name() for v in _curr_active_dock_group] # ['ContinuousDecode_long_LR - t_bin_size: 0.025', 'ContinuousDecode_long_RL - t_bin_size: 0.025', 'ContinuousDecode_short_LR - t_bin_size: 0.025', 'ContinuousDecode_short_RL - t_bin_size: 0.025']\n",
    "im_posterior_x_stack = [v.widgets[0].plots.im_posterior_x for v in _curr_active_dock_group]\n",
    "\n",
    "_curr_decoder_name_to_decoders_dock_item_name_map = {}\n",
    "_remaining_dock_names = set(_curr_decoders_dock_item_names_list)\n",
    "\n",
    "# _curr_decoders_dock_item_names_list\n",
    "for a_decoder_name in decoder_names_list:\n",
    "\tfor a_dock_name in _remaining_dock_names: #_curr_decoders_dock_item_names_list:\n",
    "\t\tif (a_decoder_name in a_dock_name):\n",
    "\t\t\t_curr_decoder_name_to_decoders_dock_item_name_map[a_decoder_name] = a_dock_name\n",
    "\t\t\t_remaining_dock_names.remove(a_dock_name)\n",
    "\t\t\tbreak\n",
    "\n",
    "assert len(_curr_decoder_name_to_decoders_dock_item_name_map) == len(decoder_names_list), f\"decoder_names_list: {decoder_names_list} != list(_curr_decoder_name_to_decoders_dock_item_name_map.keys()): {_curr_decoder_name_to_decoders_dock_item_name_map}\"\n",
    "track_labels: List[str] = [formatted_title_strings_dict[a_decoder_name] for a_decoder_name, a_dock_name in _curr_decoder_name_to_decoders_dock_item_name_map.items()]\n",
    "track_labels\n",
    "\n",
    "## OUTPUTS: im_posterior_x_stack, track_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ff81d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import FigureToImageHelpers\n",
    "\n",
    "## INPUTS: im_posterior_x_stack, track_labels, \n",
    "output_pdf_path: Path = relative_data_output_parent_folder.joinpath('timeline_exported_stack.pdf')\n",
    "FigureToImageHelpers.export_wrapped_axesimage_to_paged_pdf(ax_image=im_posterior_x_stack, x_extent=(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time), chunk_width=active_2d_plot.active_window_duration, output_pdf_path=output_pdf_path, figsize=(8, 11), dpi=150,\n",
    "        \t\t\t\t\t\t\t\t\t\t\t\trows_per_page=5, debug_max_num_pages=3,\t\t    \n",
    "                                                        # rows_per_page=15, debug_max_num_pages=3,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\ttrack_labels=track_labels,\n",
    "                                                    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6bc040",
   "metadata": {},
   "source": [
    "#### Testing a Pyqtgraph-backed widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1552576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.PyqtgraphTimeSynchronizedWidget import PyqtgraphTimeSynchronizedWidget  \n",
    "\n",
    "active_2d_plot: Spike2DRaster = active_2d_plot  \n",
    "\n",
    "\n",
    "a_dock_id: str = 'intervals'\n",
    "a_dock, widget = active_2d_plot.find_dock_item_tuple(identifier=a_dock_id)\n",
    "# widget.plots\n",
    "# widget.plots_data\n",
    "# img.set_cmap('viridis')  # or any \n",
    "widget: PyqtgraphTimeSynchronizedWidget = widget\n",
    "root_plot_item: pg.PlotItem = widget.getRootPlotItem()\n",
    "root_plot_item\n",
    "# an_ax = widget\n",
    "# an_ax\n",
    "# widget\n",
    "# an_ax.set_facecolor('black')  # Set axes background to black\n",
    "# an_ax.set_facecolor('white')  # Set axes background to white\n",
    "\n",
    "\n",
    "# img.set_cmap('viridis')  # or any valid colormap name\n",
    "# widget.getRootPlotItem().setXRange(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time, padding=0) ## global frame  \n",
    "# widget.update(None)  \n",
    "\n",
    "# im_posterior_x = widget.plots.im_posterior_x\n",
    "# im_posterior_x.set_cmap(active_cmap)  # or any valid colormap name\n",
    "# widget.update()\n",
    "# widget\n",
    "# plt.draw()\n",
    "# im_posterior_x # AxesImage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07b3ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import FigureToImageHelpers\n",
    "\n",
    "## INPUTS: root_plot_item\n",
    "relative_data_output_parent_folder = Path('data').resolve()\n",
    "Assert.path_exists(relative_data_output_parent_folder)\n",
    "\n",
    "output_pdf_path: Path = relative_data_output_parent_folder.joinpath('timeline_exported_pyqtgraph.pdf')\n",
    "FigureToImageHelpers.export_wrapped_pyqtgraph_to_paged_pdf(plot_item=root_plot_item, x_extent=(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time), chunk_width=active_2d_plot.active_window_duration, output_pdf_path=output_pdf_path, figsize=(8, 11), dpi=150,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\trows_per_page=5, debug_max_num_pages=25,\t\t    \n",
    "                                                # rows_per_page=15, debug_max_num_pages=3,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e5afc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_outputs_path.joinpath('timeline_exported.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cb96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.SpecificDockWidgetManipulatingMixin import SpecificDockWidgetManipulatingMixin\n",
    "\n",
    "\n",
    "\n",
    "## measured positions\n",
    "## INPUTS: curr_active_pipeline, an_ax, \n",
    "measured_position_df: pd.DataFrame = deepcopy(curr_active_pipeline.sess.position.to_dataframe())\n",
    "\n",
    "widget.plots_data.measured_position_df = None\n",
    "widget.plots.measured_position_artists = None\n",
    "if measured_position_df is not None:\n",
    "    widget.plots_data.measured_position_df = measured_position_df\n",
    "    _out_artists = SpecificDockWidgetManipulatingMixin._perform_overlay_measured_position(matplotlib_fig_axes=[an_ax], measured_position_df=measured_position_df)\n",
    "    widget.plots.measured_position_artists = _out_artists\n",
    "    widget.draw() # alternative to accessing through full path?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d493184",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.dock_manager_widget.get_leaf_only_flat_dock_identifiers_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9a8974",
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_window = spike_raster_window.spikes_window # SpikesDataframeWindow; pyphoplacecellanalysis.General.Model.TimeWindow.TimeWindow\n",
    "spikes_window.update_window_start_end(451.8908457518555, 451.9895490613999) ## Works but does not trigger refresh/update of the window. The changes are reflected as soon as you try to scroll at all though.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c6ec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a203ce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_commands = ['AddTimeIntervals.Replays', 'AddTimeIntervals.Laps', 'AddTimeIntervals.SessionEpochs'] # , 'AddTimeIntervals.SessionEpochs', 'AddTimeIntervals.PBEs', 'AddTimeIntervals.Ripples',\n",
    "for a_command in menu_commands:\n",
    "    assert a_command in global_flat_action_dict, f\"a_command: '{a_command}' is not present in global_flat_action_dict: {list(global_flat_action_dict.keys())}\"\n",
    "    # add_renderables_menu[a_command].trigger()\n",
    "    global_flat_action_dict[a_command].trigger()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f895e3",
   "metadata": {},
   "source": [
    "main_content_splitter (QSplitter)\n",
    "\tmain_graphics_layout_widget (CustomGraphicsLayoutWidget)\n",
    "\t\tqt_scrollarea_hcontainer (QWidget)\n",
    "\t\t\tUnnamed (QScrollBar)\n",
    "\t\tqt_scrollarea_vcontainer (QWidget)\n",
    "\t\t\tUnnamed (QScrollBar)\n",
    "\t\tUnnamed (QOpenGLWidget)\n",
    "\twrapper_widget (QWidget)\n",
    "\t\tdynamic_docked_widget_container (NestedDockAreaWidget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbac1ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "from PyQt5.QtWidgets import QAbstractScrollArea\n",
    "from PyQt5.QtWidgets import QSizePolicy\n",
    "\n",
    "from pyphoplacecellanalysis.General.Mixins.DisplayHelpers import debug_widget_geometry\n",
    "from pyphocorehelpers.gui.Qt.TopLevelWindowHelper import print_widget_hierarchy\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.spike_raster_widgets import _get_required_static_layout_height\n",
    "\n",
    "main_graphics_layout_widget: pg.GraphicsLayoutWidget = active_2d_plot.ui.main_graphics_layout_widget\n",
    "wrapper_layout: pg.QtWidgets.QVBoxLayout = active_2d_plot.ui.wrapper_layout\n",
    "main_content_splitter = active_2d_plot.ui.main_content_splitter # QSplitter\n",
    "\n",
    "## Tracks\n",
    "dynamic_docked_widget_container = active_2d_plot.ui.dynamic_docked_widget_container\n",
    "dynamic_docked_widget_container_parent_wrapper = dynamic_docked_widget_container.parentWidget() # 'wrapper_widget'\n",
    "\n",
    "## Hard-coded\n",
    "layout = active_2d_plot.ui.layout\n",
    "background_static_scroll_window_plot = active_2d_plot.plots.background_static_scroll_window_plot # PlotItem\n",
    "\n",
    "main_plot_widget = active_2d_plot.plots.main_plot_widget # PlotItem\n",
    "\n",
    "root_layout: pg.GraphicsLayout = active_2d_plot.plots.background_static_scroll_window_plot.parentWidget()\n",
    "static_children_bounding_rect = root_layout.childrenBoundingRect() # QRectF\n",
    "required_static_children_bounding_rect_height: float = static_children_bounding_rect.height()\n",
    "required_static_children_bounding_rect_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d567bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_2d_plot.ui.dynamic_docked_widget_container\n",
    "# dynamic_docked_widget_container.parent().objectName()\n",
    "# dynamic_docked_widget_container.parentWidget().objectName()\n",
    "\n",
    "debug_widget_geometry(dynamic_docked_widget_container, widget_name='dynamic_docked_widget_container')\n",
    "debug_widget_geometry(dynamic_docked_widget_container_parent_wrapper, widget_name='dynamic_docked_widget_container_parent_wrapper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81954f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_docked_widget_container_parent_wrapper.setSizePolicy(QtGui.QSizePolicy.Expanding, QtGui.QSizePolicy.Expanding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eccdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.spike_raster_widgets import _get_required_static_layout_height\n",
    "\n",
    "required_static_children_bounding_rect_height: float = _get_required_static_layout_height(active_2d_plot=active_2d_plot)\n",
    "print(f'required_static_children_bounding_rect_height: {required_static_children_bounding_rect_height}')\n",
    "main_graphics_layout_widget.setMaximumHeight(required_static_children_bounding_rect_height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd68cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_widget_geometry(main_graphics_layout_widget, widget_name='main_graphics_layout_widget')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ed1a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_widget_hierarchy(main_graphics_layout_widget)\n",
    "\n",
    "# PyQt5.QtCore.QRect(0, 221, 1855, 640)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f0cb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.spike_raster_widgets import _get_required_static_layout_height\n",
    "\n",
    "main_graphics_layout_widget.setSizeAdjustPolicy(QAbstractScrollArea.SizeAdjustPolicy.AdjustToContentsOnFirstShow)                    \n",
    "required_static_children_bounding_rect_height: float = _get_required_static_layout_height(active_2d_plot=active_2d_plot)\n",
    "print(f'required_static_children_bounding_rect_height: {required_static_children_bounding_rect_height}')\n",
    "# main_graphics_layout_widget.setMaximumHeight(required_static_children_bounding_rect_height)\n",
    "\n",
    "# main_graphics_layout_widget.resize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60210451",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_widget_hierarchy(active_2d_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ebf4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.print_helpers import strip_type_str_to_classname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e035fa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5.QtWidgets import QOpenGLWidget\n",
    "\n",
    "main_graphics_layout_widget.childrenRect()\n",
    "\n",
    "open_gl_widget: QOpenGLWidget = main_graphics_layout_widget.children()[-1]\n",
    "open_gl_widget.childrenRect()\n",
    "open_gl_widget.contentsRect()\n",
    "# open_gl_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54c3c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_layout: pg.GraphicsLayout = main_plot_widget.parentWidget()\n",
    "main_layout\n",
    "# main_plot_widget.parent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8fb146",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_layout.childrenBoundingRect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd819d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_layout.parentWidget().parentWidget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d433e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_widget_geometry(main_plot_widget)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fe9c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5.QtWidgets import QAbstractScrollArea\n",
    "from PyQt5.QtWidgets import QSizePolicy\n",
    "\n",
    "main_graphics_layout_widget.setSizeAdjustPolicy(QAbstractScrollArea.SizeAdjustPolicy.AdjustToContentsOnFirstShow)\n",
    "# main_graphics_layout_widget.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Preferred)\n",
    "# main_graphics_layout_widget.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Preferred)\n",
    "main_graphics_layout_widget.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bbe298",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_layout: pg.GraphicsLayout = active_2d_plot.plots.background_static_scroll_window_plot.parentWidget()\n",
    "static_children_bounding_rect = root_layout.childrenBoundingRect() # QRectF\n",
    "required_static_children_bounding_rect_height: float = static_children_bounding_rect.height()\n",
    "\n",
    "main_graphics_layout_widget.setMaximumHeight(required_static_children_bounding_rect_height)\n",
    "# main_graphics_layout_widget.setMaximumSize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5378254",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_docked_widget_container_parent_wrapper.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)\n",
    "dynamic_docked_widget_container.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b41680",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_static_scroll_plot_widget = active_2d_plot.plots.get('background_static_scroll_plot_widget', None) # PlotItem\n",
    "if background_static_scroll_plot_widget is not None:\n",
    "    background_static_scroll_plot_widget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009e00df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "background_static_scroll_window_plot = active_2d_plot.plots.get('background_static_scroll_window_plot', None) # PlotItem\n",
    "if background_static_scroll_window_plot is not None:\n",
    "    # background_static_scroll_window_plot # PlotItem\n",
    "    plot_data_item.setDownsampling(auto=True, ds=1, mode='subsample')\n",
    "    plot_data_item.setClipToView(True)\n",
    "    \n",
    "    # background_static_scroll_window_plot.setClipToView(True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cddd357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# background_static_scroll_window_plot.parent()\n",
    "background_static_scroll_window_plot.dataItems[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577cbb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_overview_scatter_plot = active_2d_plot.plots.get('preview_overview_scatter_plot', None) # ScatterPlotItem\n",
    "preview_overview_scatter_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d975c61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "debug_widget_geometry(preview_overview_scatter_plot, widget_name='preview_overview_scatter_plot')\n",
    "print_widget_hierarchy(preview_overview_scatter_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1525b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "main_plot_widget.scatterPlot().setClipToView(True) # Usually default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6932cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "main_content_splitter.size()\n",
    "main_content_splitter.sizes()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e19af68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.gui.Qt.TopLevelWindowHelper import print_widget_hierarchy\n",
    "\n",
    "print_widget_hierarchy(main_content_splitter, indent_level_chars='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9950a936",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_static_children_bounding_rect_height: float = _get_required_static_layout_height(active_2d_plot=active_2d_plot)\n",
    "main_graphics_layout_widget.setMaximumHeight(required_static_children_bounding_rect_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac259d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: main_content_splitter\n",
    "\n",
    "original_sizes = np.array(main_content_splitter.sizes())\n",
    "original_sizes\n",
    "\n",
    "## INPUTS: required_static_children_bounding_rect_height\n",
    "extra_v_height = (original_sizes[-1] - required_static_children_bounding_rect_height)\n",
    "extra_v_height\n",
    "\n",
    "desired_sizes = deepcopy(original_sizes)\n",
    "desired_sizes[-1] = required_static_children_bounding_rect_height\n",
    "desired_sizes[0] = desired_sizes[0] + extra_v_height\n",
    "\n",
    "assert np.sum(desired_sizes) == np.sum(original_sizes)\n",
    "\n",
    "\n",
    "main_content_splitter.setSizes(desired_sizes.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655af96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_content_splitter.children()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed1caa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import Spike2DRaster\n",
    "from pyphoplacecellanalysis.GUI.Qt.SpikeRasterWindows.Spike3DRasterWindowWidget import Spike3DRasterWindowWidget\n",
    "from pyphoplacecellanalysis.GUI.Qt.PlaybackControls.Spike3DRasterBottomPlaybackControlBarWidget import Spike3DRasterBottomPlaybackControlBar\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import SynchronizedPlotMode\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.spike_raster_widgets import _setup_spike_raster_window_for_debugging\n",
    "\n",
    "all_global_menus_actionsDict, global_flat_action_dict, _all_outputs_dict = _setup_spike_raster_window_for_debugging(spike_raster_window, wants_docked_raster_window_track=True, enable_interval_overview_track=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f18a66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61246c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import SynchronizedPlotMode\n",
    "\n",
    "\n",
    "with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-prepare_pyqtgraph_rasterPlot_track_with_sync.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "    # _raster_overview_tracks_out_dict = active_2d_plot.prepare_pyqtgraph_rasterPlot_track(name_modifier_suffix='raster_overview', should_link_to_main_plot_widget=False, sync_mode=SynchronizedPlotMode.TO_GLOBAL_DATA, downsampling_rate=5)\n",
    "    _raster_overview_tracks_out_dict = active_2d_plot.prepare_pyqtgraph_rasterPlot_track(name_modifier_suffix='raster_overview', should_link_to_main_plot_widget=False, sync_mode=SynchronizedPlotMode.NO_SYNC, downsampling_rate=5)\n",
    "    raster_overview_dock_config, raster_overview_time_sync_pyqtgraph_widget, raster_overview_root_graphics_layout_widget, raster_overview_plot_item, raster_overview_display_outputs_tuple = _raster_overview_tracks_out_dict['rasters[raster_overview]']\n",
    "    active_2d_plot.sync_matplotlib_render_plot_widget('rasters[raster_overview]', sync_mode=SynchronizedPlotMode.NO_SYNC) # disable continued sync\n",
    "    \n",
    "    # _all_outputs_dict['_raster_tracks_out_dict'] = _raster_tracks_out_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87237fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a623c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.sync_matplotlib_render_plot_widget('rasters[raster_overview]', sync_mode=SynchronizedPlotMode.TO_GLOBAL_DATA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fdfc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(_raster_overview_tracks_out_dict.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d47ca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_overview_dock_config, raster_overview_time_sync_pyqtgraph_widget, raster_overview_root_graphics_layout_widget, raster_overview_plot_item, raster_overview_display_outputs_tuple = _raster_overview_tracks_out_dict['raster_overview']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9223c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add scroller:\n",
    "\n",
    "def _add_scroll_region(active_2d_plot, parent_plot, clipItem=None, should_connect=False):\n",
    "    \"\"\" adds the scroll region control to the specified raster plot\n",
    "    \n",
    "    scroll_window_region, _conn = _add_scroll_region(active_2d_plot, parent_plot=background_static_scroll_window_plot, clipItem=active_2d_plot.plots.preview_overview_scatter_plot)\n",
    "    \n",
    "    active_2d_plot.ui.scroll_window_region = scroll_window_region\n",
    "    \"\"\"\n",
    "    from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsObjects.CustomLinearRegionItem import CustomLinearRegionItem\n",
    "    if clipItem is None:\n",
    "        clipItem = active_2d_plot.plots.preview_overview_scatter_plot\n",
    "        \n",
    "    # linear_region_display_kwargs = dict(pen=pg.mkPen('#ffffff'), brush=pg.mkBrush('#f004'), hoverBrush=pg.mkBrush('#fff4'), hoverPen=pg.mkPen('#f00'))\n",
    "    # linear_region_display_kwargs = dict(pen=pg.mkPen('#1d0000f8', width=2), brush=pg.mkBrush('#00000090'), hoverBrush=pg.mkBrush('#fff40090'), hoverPen=pg.mkPen('#f00000ff', width=2.5))\n",
    "    # linear_region_display_kwargs = dict(pen=pg.mkPen('#1d0000f8'), brush=pg.mkBrush('#ffffff90'), hoverBrush=pg.mkBrush('#fff40090'), hoverPen=pg.mkPen('#fffffff4'))\n",
    "    linear_region_display_kwargs = dict(pen=pg.mkPen('#ffffffe2', width=1.0), brush=pg.mkBrush('#ffffff90'), hoverBrush=pg.mkBrush('#fff40090'), hoverPen=pg.mkPen('#ff0505f4', width=1.5))\n",
    "\n",
    "\t# Add the linear region overlay:\n",
    "    scroll_window_region = CustomLinearRegionItem(**linear_region_display_kwargs, clipItem=clipItem) # bound the LinearRegionItem to the plotted data\n",
    "    scroll_window_region.setObjectName('scroll_window_region')\n",
    "    scroll_window_region.setZValue(10)\n",
    "    \n",
    "    ## Set position from spikes_window:\n",
    "    confirmed_valid_window_start_t = active_2d_plot.spikes_window.total_data_start_time\n",
    "    if (active_2d_plot.spikes_window.window_duration == 0.0):\n",
    "        # invalid window length, just choose something reasonable the user can grab, say 5% of the total window data\n",
    "        total_data_duration = active_2d_plot.spikes_window.total_data_end_time - active_2d_plot.spikes_window.total_data_start_time\n",
    "        reasonable_active_window_duration = float(total_data_duration) * 0.05 # 5%\n",
    "        ## UGHH, it works but please note that the final window is actually going to be MORE than 5% of the total data duration because of the temporal_zoom_factor > 1.0. \n",
    "    else:\n",
    "        reasonable_active_window_duration = float(active_2d_plot.spikes_window.window_duration)        \n",
    "    # Compute the final reasonable window end_t:\n",
    "    confirmed_valid_window_end_t = confirmed_valid_window_start_t + reasonable_active_window_duration\n",
    "        \n",
    "    scroll_window_region.setRegion([confirmed_valid_window_start_t, confirmed_valid_window_end_t]) # adjust scroll control\n",
    "    \n",
    "    # Add the LinearRegionItem to the ViewBox, but tell the ViewBox to exclude this item when doing auto-range calculations.\n",
    "    parent_plot.addItem(scroll_window_region, ignoreBounds=True)\n",
    "    if should_connect:\n",
    "        _conn = scroll_window_region.sigRegionChanged.connect(active_2d_plot._Render2DScrollWindowPlot_on_linear_region_item_update)\n",
    "    else:\n",
    "        _conn = None\n",
    "        \n",
    "    return scroll_window_region, _conn\n",
    "\n",
    "\n",
    "# scroll_window_region, _conn = _add_scroll_region(active_2d_plot=active_2d_plot, parent_plot=background_static_scroll_window_plot, clipItem=active_2d_plot.plots.preview_overview_scatter_plot)\n",
    "\n",
    "scroll_window_region, _conn = _add_scroll_region(active_2d_plot=active_2d_plot, parent_plot=raster_overview_plot_item, clipItem=raster_overview_plot_item)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42f2298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scroll_window_region.remove()\n",
    "\n",
    "\n",
    "raster_overview_plot_item.removeItem(scroll_window_region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993a507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scroll_window_region.sigRegionChanged.disconnect(_conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd43fc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## teardown `background_static_scroll_window_plot`\n",
    "background_static_scroll_window_plot.hide()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c0c871",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.ui.scroll_window_region.disconnect()\n",
    "active_2d_plot.ui.scroll_window_region.hide()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b577453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOPS BETTER START COOKING'243_22562_220-pycharm-support-libs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0b3b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_plot_widget = _all_outputs_dict.get('main_plot_widget', None)\n",
    "if main_plot_widget is not None:\n",
    "    main_plot_widget.hide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a28499",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_window_container_layout = _all_outputs_dict.get('active_window_container_layout', None)\n",
    "if active_window_container_layout is not None:\n",
    "    active_window_container_layout.setVisible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c186676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_static_scroll_window_plot = _all_outputs_dict.get('background_static_scroll_window_plot', None)\n",
    "background_static_scroll_window_plot.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5f9dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_global_menus_actionsDict, global_flat_action_dict = spike_raster_window.build_all_menus_actions_dict()\n",
    "global_flat_action_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48715b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.decod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2bc7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add Renderables ____________________________________________________________________________________________________ #\n",
    "# add_renderables_menu = active_2d_plot.ui.menus.custom_context_menus.add_renderables[0].programmatic_actions_dict\n",
    "menu_commands = ['AddTimeIntervals.Replays', 'AddTimeIntervals.Laps', 'AddTimeIntervals.SessionEpochs'] # , 'AddTimeIntervals.SessionEpochs', 'AddTimeIntervals.PBEs', 'AddTimeIntervals.Ripples',\n",
    "for a_command in menu_commands:\n",
    "    assert a_command in global_flat_action_dict, f\"a_command: '{a_command}' is not present in global_flat_action_dict: {list(global_flat_action_dict.keys())}\"\n",
    "    # add_renderables_menu[a_command].trigger()\n",
    "    global_flat_action_dict[a_command].trigger()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae14b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feb774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccad938",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(spike_raster_window.spike_raster_plt_2d.params.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743a2479",
   "metadata": {},
   "outputs": [],
   "source": [
    "_raster_tracks_out_dict = active_2d_plot.prepare_pyqtgraph_rasterPlot_track(name_modifier_suffix='raster_window', should_link_to_main_plot_widget=False, )\n",
    "dock_config, time_sync_pyqtgraph_widget, raster_root_graphics_layout_widget, raster_plot_item, rasters_display_outputs_tuple = list(_raster_tracks_out_dict.values())[0]\n",
    "an_app, a_win, a_plots, a_plots_data = rasters_display_outputs_tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae4fada",
   "metadata": {},
   "outputs": [],
   "source": [
    "_interval_tracks_out_dict = active_2d_plot.prepare_pyqtgraph_intervalPlot_tracks(enable_interval_overview_track=True, should_remove_all_and_re_add=True, should_link_to_main_plot_widget=False)\n",
    "interval_window_dock_config, intervals_dock, intervals_time_sync_pyqtgraph_widget, intervals_root_graphics_layout_widget, intervals_plot_item = _interval_tracks_out_dict['intervals']\n",
    "if 'interval_overview' in _interval_tracks_out_dict:\n",
    "    interval_overview_window_dock_config, intervals_overview_dock, intervals_overview_time_sync_pyqtgraph_widget, intervals_overview_root_graphics_layout_widget, intervals_overview_plot_item = _interval_tracks_out_dict['interval_overview']\n",
    "    intervals_overview_plot_item.setXRange(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time, padding=0) ## global frame\n",
    "    # intervals_overview_time_sync_pyqtgraph_widget.setMaximumHeight(39)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f2fcb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a016e6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_dock.setMaximumHeight(39)\n",
    "intervals_overview_dock.setMaximumHeight(39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b35efdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_time_sync_pyqtgraph_widget.setMaximumHeight(39)\n",
    "intervals_overview_time_sync_pyqtgraph_widget.setMaximumHeight(39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e413f522",
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_window = spike_raster_window.spikes_window # SpikesDataframeWindow; pyphoplacecellanalysis.General.Model.TimeWindow.TimeWindow\n",
    "spikes_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aded71e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.total_data_start_time\n",
    "spike_raster_window.total_data_end_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51bfa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.total_data_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2d9eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setXLink\n",
    "# a_win # CustomGraphicsLayoutWidget \n",
    "# time_sync_pyqtgraph_widget # PyqtgraphTimeSynchronizedWidget \n",
    "# raster_plot_item\n",
    "\n",
    "### Zoom to entire data time range:\n",
    "# active_2d_plot\n",
    "raster_plot_item.setXLink(None)\n",
    "raster_plot_item.setXRange(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time, padding=0) ## global frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c754c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_dock_ids_list = active_2d_plot.get_group_only_flat_dock_identifiers_list()\n",
    "leaf_dock_ids_list = active_2d_plot.get_leaf_only_flat_dock_identifiers_list()\n",
    "group_dock_ids_list\n",
    "\n",
    "\n",
    "group_dock_raw_identifiers_list = [v.lstrip('GROUP[').rstrip(']') for v in group_dock_ids_list] # 'GROUP[ContinuousDecode_0.03]' -> 'ContinuousDecode_0.03'\n",
    "group_dock_raw_identifiers_list\n",
    "# spike_raster_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb984228",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_group_container_id: str = group_dock_ids_list[0] # 'GROUP[ContinuousDecode_0.03]'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e70360",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dock_items_dict: Dict[str, List[Dock]] = active_2d_plot.get_dockGroup_dock_dict()\n",
    "grouped_dock_items_dict\n",
    "\n",
    "# {'ContinuousDecode_ - t_bin_size: 0.025': [<Dock ContinuousDecode_long_LR - t_bin_size: 0.025 (65, 200)>,\n",
    "#   <Dock ContinuousDecode_long_RL - t_bin_size: 0.025 (65, 200)>,\n",
    "#   <Dock ContinuousDecode_short_LR - t_bin_size: 0.025 (65, 200)>,\n",
    "#   <Dock ContinuousDecode_short_RL - t_bin_size: 0.025 (65, 200)>],\n",
    "#  'ContinuousDecode_0.03': [<Dock DirectionalDecodersDecoded[long_LR]0.03 (65, 200)>,\n",
    "#   <Dock DirectionalDecodersDecoded[long_RL]0.03 (65, 200)>,\n",
    "#   <Dock DirectionalDecodersDecoded[short_LR]0.03 (65, 200)>,\n",
    "#   <Dock DirectionalDecodersDecoded[short_RL]0.03 (65, 200)>]}\n",
    "\n",
    "a_group_container_id: str = group_dock_ids_list[0]\n",
    "a_group_id: str = group_dock_raw_identifiers_list[0]\n",
    "flat_group_dockitems_list: List[Dock] = grouped_dock_items_dict[a_group_id]\n",
    "flat_group_dockitems_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba94a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup children:\n",
    "for a_dock in flat_group_dockitems_list:\n",
    "    # a_dock_identifier: str = a_dock.name()\n",
    "    # ## format nested child docks:\n",
    "    # a_dock.config.showCloseButton = False\n",
    "    # a_dock.config.showCollapseButton = False\n",
    "    # a_dock.config.showGroupButton = False\n",
    "    # a_dock.config.corner_radius='0px'\n",
    "    # a_dock.updateStyle()\n",
    "    active_2d_plot.dock_manager_widget.displayDockArea.addDock(dock=a_dock) ## move the dock items as children to the new container\n",
    "    # active_2d_plot.displayDockArea.moveDock(\n",
    "    # nested_dynamic_docked_widget_container.displayDockArea.addDock(dock=a_dock) ## move the dock items as children to the new container\n",
    "    \n",
    "## remove the group\n",
    "active_2d_plot.dock_manager_widget.remove_display_dock(identifier=a_group_container_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d570e8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.dock_manager_widget.unwrap_docks_in_nested_dock_area(dock_group_name='ContinuousDecode_0.03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fa4144",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dock all Grouped results from `'DockedWidgets.Pseudo2DDecodedEpochsDockedMatplotlibView'`\n",
    "## INPUTS: active_2d_plot\n",
    "nested_dock_items, nested_dynamic_docked_widget_container_widgets = active_2d_plot.ui.dynamic_docked_widget_container.layout_dockGroups()\n",
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()\n",
    "## OUTPUTS: nested_dock_items, nested_dynamic_docked_widget_container_widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8362a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import add_continuous_decoded_posterior\n",
    "\n",
    "(nested_dock_items, nested_dynamic_docked_widget_container_widgets), (a_continuously_decoded_dict, pseudo2D_decoder, all_directional_pf1D_Decoder_dict) = add_continuous_decoded_posterior(spike_raster_window=spike_raster_window, curr_active_pipeline=curr_active_pipeline, desired_time_bin_size=0.05, debug_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967df72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Increase the window duration centered\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import plot_attached_BinByBinDecodingDebugger\n",
    "\n",
    "## INPUTS: a_decoder, a_decoded_result\n",
    "win, out_pf1D_decoder_template_objects, (plots_container, plots_data), _on_update_fcn = plot_attached_BinByBinDecodingDebugger(spike_raster_window, curr_active_pipeline, a_decoder=a_decoder, a_decoded_result=a_decoded_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62a8afa",
   "metadata": {
    "tags": [
     "active-2025-02-25"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import plot_attached_BinByBinDecodingDebugger\n",
    "## Plot one of the continuous results for the most recently computed time_bin_size:\n",
    "\n",
    "\n",
    "# all_directional_pf1D_Decoder_dict\n",
    "a_decoder_name: str = 'long'\n",
    "a_decoder = results1D.decoders[a_decoder_name]\n",
    "a_decoded_result = results1D.continuous_results[a_decoder_name]\n",
    "\n",
    "## INPUTS: a_decoder, a_decoded_result\n",
    "win, out_pf1D_decoder_template_objects, (plots_container, plots_data), _on_update_fcn = plot_attached_BinByBinDecodingDebugger(spike_raster_window, curr_active_pipeline, a_decoder=a_decoder, a_decoded_result=a_decoded_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a20a893",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_main_raster_plot: bool = (active_2d_plot.plots.main_plot_widget is not None)\n",
    "_raster_tracks_out_dict = active_2d_plot.prepare_pyqtgraph_rasterPlot_track(name_modifier_suffix='raster_window', should_link_to_main_plot_widget=has_main_raster_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcbc56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.External.pyqtgraph.dockarea.Dock import Dock, DockDisplayConfig\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import FigureWidgetDockDisplayConfig\n",
    "\n",
    "flat_dock_item_tuple_dict: Dict[str, Tuple] = active_2d_plot.get_flat_dock_item_tuple_dict()\n",
    "group_only_flat_dockwidgets_dict = {k:a_widget for k, (a_dock, a_widget) in flat_dock_item_tuple_dict.items() if ('GROUP' == a_dock.config.additional_metadata.get('type', 'LEAF')) }\n",
    "leaf_only_flat_dockwidgets_dict = {k:a_widget for k, (a_dock, a_widget) in flat_dock_item_tuple_dict.items() if ('LEAF' == a_dock.config.additional_metadata.get('type', 'LEAF')) }\n",
    "group_only_flat_dockwidgets_dict\n",
    "leaf_only_flat_dockwidgets_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea403e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "active_2d_plot.get_flat_dockitems_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff28fdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import AddNewDecodedPosteriors_MatplotlibPlotCommand\n",
    "from pyphoplacecellanalysis.External.pyqtgraph.dockarea.Dock import Dock, DockDisplayConfig\n",
    "\n",
    "flat_dock_item_tuple_dict: Dict[str, Tuple] = active_2d_plot.get_flat_dock_item_tuple_dict()\n",
    "flat_dock_item_tuple_dict\n",
    "\n",
    "# flat_docks_dict = {k:a_dock for k, (a_dock, a_widget) in flat_dock_item_tuple_dict.items() if ('ContinuousDecode_ - t_bin_size: 0.025' in a_dock.config.dock_group_names) }\n",
    "flat_dockwidgets_dict = {k:a_widget for k, (a_dock, a_widget) in flat_dock_item_tuple_dict.items() if ('ContinuousDecode_ - t_bin_size: 0.025' in a_dock.config.dock_group_names) }\n",
    "flat_dockwidgets_dict\n",
    "\n",
    "# flat_dock_item_tuple_dict = {k:a_widget if a_dock.grou for k, (a_dock, a_widget) in flat_dock_item_tuple_dict.items()}\n",
    "\n",
    "# flat_dockwidgets_list = active_2d_plot.get_flat_widgets_list()\n",
    "# flat_dockwidgets_list\n",
    "# active_2d_plot.get_dock_groups()\n",
    "\n",
    "_all_tracks_out_artists = {}\n",
    "for k, a_widget in flat_dockwidgets_dict.items():\n",
    "    _out_artists = AddNewDecodedPosteriors_MatplotlibPlotCommand._perform_overlay_measured_position(identifier_name=k, widget=a_widget, matplotlib_fig=a_widget.fig, matplotlib_fig_axes=a_widget.axes, measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()))\n",
    "    _all_tracks_out_artists[k] = _out_artists\n",
    "    a_widget.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8fc993",
   "metadata": {},
   "outputs": [],
   "source": [
    "_all_tracks_out_artists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8580701",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, a_widget in flat_dockwidgets_dict.items():\n",
    "    a_widget.plots.measured_position_artists = _all_tracks_out_artists[k]\n",
    "    \n",
    "    # a_widget.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21b7f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_playback_control_bar_widget = spike_raster_window.bottom_playback_control_bar_widget # Spike3DRasterBottomPlaybackControlBar \n",
    "comboActiveJumpTargetSeries = bottom_playback_control_bar_widget.ui.comboActiveJumpTargetSeries # QComboBox \n",
    "comboActiveJumpTargetSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd1d42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Dock all Grouped results from `'DockedWidgets.Pseudo2DDecodedEpochsDockedMatplotlibView'`\n",
    "## INPUTS: active_2d_plot\n",
    "nested_dock_items, nested_dynamic_docked_widget_container_widgets = active_2d_plot.ui.dynamic_docked_widget_container.layout_dockGroups()\n",
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()\n",
    "## OUTPUTS: nested_dock_items, nested_dynamic_docked_widget_container_widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191b20f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()\n",
    "grouped_dock_items_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8084d27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.ui.dynamic_docked_widget_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53ed9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.NestedDockAreaWidget import NestedDockAreaWidget\n",
    "\n",
    "dock_manager_widget: NestedDockAreaWidget = active_2d_plot.dock_manager_widget\n",
    "grouped_dock_items_dict = dock_manager_widget.get_dockGroup_dock_dict()\n",
    "grouped_dock_items_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3ee32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dock_items_dict = active_2d_plot.dock_manager_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c521a076",
   "metadata": {},
   "outputs": [],
   "source": [
    "comboActiveJumpTargetSeries.setCurrentText('Laps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5ebfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.Specific2DRenderTimeEpochs import General2DRenderTimeEpochs, Replays_2DRenderTimeEpochs, Ripples_2DRenderTimeEpochs, SessionEpochs2DRenderTimeEpochs, PBE_2DRenderTimeEpochs, Laps2DRenderTimeEpochs, SpikeBurstIntervals_2DRenderTimeEpochs, NewNonPBE_2DRenderTimeEpochs # Time Intervals/Epochs\n",
    "\n",
    "background_static_scroll_window_plot = active_2d_plot.plots.background_static_scroll_window_plot # PlotItem\n",
    "main_plot_widget = active_2d_plot.plots.main_plot_widget # PlotItem\n",
    "\n",
    "for an_interval_rendering_plot in active_2d_plot.interval_rendering_plots:\n",
    "    _out = NewNonPBE_2DRenderTimeEpochs.add_render_time_epochs(curr_sess=curr_active_pipeline.sess.non_pbe, destination_plot=an_interval_rendering_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f45c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.params.debug_print = True\n",
    "spike_raster_window.enable_debug_print = True\n",
    "active_2d_plot.params.debug_print = True\n",
    "# active_2d_plot.debug_print = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61371822",
   "metadata": {},
   "outputs": [],
   "source": [
    "extant_conn = spike_raster_window.ui.additional_connections.get('spike_3d_to_2d_window_crosshair_connection', None)\n",
    "extant_conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7200fc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.ui.left_side_bar_connections = spike_raster_window.SpikeRasterLeftSidebarControlsMixin_connectSignals(spike_raster_window.ui.leftSideToolbarWidget)\n",
    "spike_raster_window.ui.left_side_bar_connections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0491ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fix window title to display the session context post-hoc\n",
    "desired_window_title: str = curr_active_pipeline.get_complete_session_identifier_string() # 'kdiba_gor01_two_2006-6-07_16-40-19__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 8, 9]-frateThresh_5.0'\n",
    "spike_raster_window.window().setWindowTitle(desired_window_title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b12684",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.params.is_crosshair_trace_enabled = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c0c6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_crosshairs to `active_2d_plot`\n",
    "active_time_sync_pyqtgraph_widgets: Dict[str, PyqtgraphTimeSynchronizedWidget] = {identifier:active_matplotlib_view_widget for identifier, active_matplotlib_view_widget in active_2d_plot.ui.matplotlib_view_widgets.items() if active_matplotlib_view_widget.is_pyqtgraph_based()}\n",
    "active_time_sync_pyqtgraph_widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da93cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_name, a_time_sync_widget in active_2d_plot.ui.matplotlib_view_widgets.items():\n",
    "    print(f'a_name: {a_name}')\n",
    "    # a_time_sync_widget.plots_data\n",
    "    a_time_sync_widget.plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd315de",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_side_bar_controls = spike_raster_window.ui.leftSideToolbarWidget\n",
    "left_side_bar_controls.crosshair_trace_time = \"test\"\n",
    "\n",
    "left_side_bar_controls.ui.lblCrosshairTraceStaticLabel.setVisible(True)\n",
    "left_side_bar_controls.ui.lblCrosshairTraceValue.setVisible(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d4effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.PyqtgraphTimeSynchronizedWidget import PyqtgraphTimeSynchronizedWidget\n",
    "\n",
    "def on_crosshair_updated_signal(self, name, trace_value):\n",
    "    print(f'on_crosshair_updated_signal(self: {self}, name: \"{name}\", trace_value: \"{trace_value}\")')\n",
    "    left_side_bar_controls = spike_raster_window.ui.leftSideToolbarWidget\n",
    "    left_side_bar_controls.crosshair_trace_time = trace_value\n",
    "    \n",
    "    # self.ui.lblCrosshairTraceStaticLabel.setVisible(True)\n",
    "    # self.ui.lblCrosshairTraceValue.setVisible(True)\n",
    "\n",
    "\n",
    "for a_name, a_time_sync_widget in active_2d_plot.ui.matplotlib_view_widgets.items():\n",
    "    print(f'a_name: {a_name}')\n",
    "    try:\n",
    "        a_time_sync_widget.update_crosshair_trace(wants_crosshairs_trace=True)\n",
    "        a_time_sync_widget.sigCrosshairsUpdated.connect(on_crosshair_updated_signal)\n",
    "    except KeyError as e:\n",
    "        # KeyError: 'connections'\n",
    "        pass\n",
    "        print(f'\\tfailed.')\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6843c773",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_time_sync_pyqtgraph_widgets['new_curves_separate_plot'].update_crosshair_trace(wants_crosshairs_trace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76ab4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277a736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4254723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(spike_raster_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05d7666",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.plots.main_plot_widget\n",
    "\n",
    "main_plot_widget = active_2d_plot.plots.main_plot_widget # PlotItem\n",
    "main_plot_widget.setMinimumHeight(20.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9cf1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_window_container_layout\n",
    "# main_graphics_layout_widget.ci # GraphicsLayout\n",
    "main_graphics_layout_widget.ci.childItems()\n",
    "# main_graphics_layout_widget.setHidden(True) ## hides too much\n",
    "main_graphics_layout_widget.setHidden(False)\n",
    "\n",
    "# main_graphics_layout_widget\n",
    "\n",
    "active_window_container_layout.setBorder(pg.mkPen('yellow', width=4.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7399378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_window_container_layout.allChildItems()\n",
    "active_window_container_layout.setPreferredHeight(200.0)\n",
    "active_window_container_layout.setMaximumHeight(800.0)\n",
    "active_window_container_layout.setSpacing(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a6aaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set stretch factors to control priority\n",
    "main_graphics_layout_widget.ci.layout.setRowStretchFactor(0, 400)  # Plot1: lowest priority\n",
    "main_graphics_layout_widget.ci.layout.setRowStretchFactor(1, 2)  # Plot2: mid priority\n",
    "main_graphics_layout_widget.ci.layout.setRowStretchFactor(2, 2)  # Plot3: highest priority\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5f61dd",
   "metadata": {
    "tags": [
     "_perform_plot_multi_decoder_meas_pred_position_track",
     "active-2025-01-16"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalDecodersContinuouslyDecodedResult\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import SynchronizedPlotMode\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_1D_most_likely_position_comparsions\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DecoderIdentityColors\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_plot_multi_decoder_meas_pred_position_track\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "\n",
    "## Build the new dock track:\n",
    "dock_identifier: str = 'Continuous Decoding Performance'\n",
    "ts_widget, fig, ax, dDisplayItem = active_2d_plot.add_new_matplotlib_render_plot_widget(name=dock_identifier)\n",
    "\n",
    "## Get the needed data:\n",
    "directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "previously_decoded_keys: List[float] = list(continuously_decoded_result_cache_dict.keys()) # [0.03333]\n",
    "print(F'previously_decoded time_bin_sizes: {previously_decoded_keys}')\n",
    "\n",
    "time_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\n",
    "print(f'time_bin_size: {time_bin_size}')\n",
    "continuously_decoded_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_decode_result.most_recent_continuously_decoded_dict\n",
    "all_directional_continuously_decoded_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = {k:v for k, v in (continuously_decoded_dict or {}).items() if k in TrackTemplates.get_decoder_names()} ## what is plotted in the `f'{a_decoder_name}_ContinuousDecode'` rows by `AddNewDirectionalDecodedEpochs_MatplotlibPlotCommand`\n",
    "## OUT: all_directional_continuously_decoded_dict\n",
    "## Draw the position meas/decoded on the plot widget\n",
    "## INPUT: fig, ax_list, all_directional_continuously_decoded_dict, track_templates\n",
    "\n",
    "_out_artists =  _perform_plot_multi_decoder_meas_pred_position_track(curr_active_pipeline, fig, ax_list, desired_time_bin_size=1.0, enable_flat_line_drawing=True)\n",
    "\n",
    "## sync up the widgets\n",
    "active_2d_plot.sync_matplotlib_render_plot_widget(dock_identifier, sync_mode=SynchronizedPlotMode.TO_WINDOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b589d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Need to figure out what the heck is going on, why are they all decoding to the same position?\n",
    "curr_active_pipeline.find_validators_providing_results(probe_provided_result_keys=['DirectionalDecodersDecoded'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb84d393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders'] # uses `DirectionalMergedDecoders`.\n",
    "\n",
    "# all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_merged_decoders_result.all_directional_decoder_dict # This does not work, because the values in the returned dictionary are PfND, not 1D decoders\n",
    "all_directional_pf1D_Decoder_value = directional_merged_decoders_result.all_directional_pf1D_Decoder\n",
    "\n",
    "pseudo2D_decoder: BasePositionDecoder = all_directional_pf1D_Decoder_value\n",
    "pseudo2D_decoder.xbin_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6256a7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder2D_result: DecodedFilterEpochsResult = continuously_decoded_dict['pseudo2D']\n",
    "decoder2D_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcd9f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder2D_result.filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a618e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_name:types.DecoderName = 'long_LR'\n",
    "\n",
    "\n",
    "result: DecodedFilterEpochsResult = all_directional_continuously_decoded_dict[decoder_name]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5477803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.binning_helpers import BinningContainer\n",
    "\n",
    "time_binning_container: BinningContainer = result.time_bin_containers[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd34e905",
   "metadata": {},
   "outputs": [],
   "source": [
    "marginals_out = result.compute_marginals()\n",
    "marginals_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677f13f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_x_given_n = result.p_x_given_n_list[0]\n",
    "p_x_given_n.shape # (63, 36101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1dbc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow, LayoutScrollability\n",
    "\n",
    "out = BasicBinnedImageRenderingWindow(p_x_given_n.T, xbins=time_binning_container.centers, ybins=pseudo2D_decoder.xbin_centers, name='p_x_given_n', title=\"Continuously Decoded Position Posterior\", variable_label='p_x_given_n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38325e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df['truth_decoder_name'] = pos_df['truth_decoder_name'].fillna('')\n",
    "pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bed9c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_color_dict: Dict[types.DecoderName, str] = DecoderIdentityColors.build_decoder_color_dict()\n",
    "\n",
    "decoded_pos_line_kwargs = dict(lw=1.0, color='gray', alpha=0.8, marker='+', markersize=6, animated=False)\n",
    "inactive_decoded_pos_line_kwargs = dict(lw=0.3, alpha=0.2, marker='.', markersize=2, animated=False)\n",
    "active_decoded_pos_line_kwargs = dict(lw=1.0, alpha=0.8, marker='+', markersize=6, animated=False)\n",
    "\n",
    "\n",
    "_out_data = {}\n",
    "_out_data_plot_kwargs = {}\n",
    "# curr_active_pipeline.global_computation_results.t\n",
    "for a_decoder_name, a_decoder in track_templates.get_decoders_dict().items():\n",
    "    a_continuously_decoded_result = all_directional_continuously_decoded_dict[a_decoder_name]\n",
    "    a_decoder_color = decoder_color_dict[a_decoder_name]\n",
    "    \n",
    "    assert len(a_continuously_decoded_result.p_x_given_n_list) == 1\n",
    "    p_x_given_n = a_continuously_decoded_result.p_x_given_n_list[0]\n",
    "    # p_x_given_n = a_continuously_decoded_result.p_x_given_n_list[0]['p_x_given_n']\n",
    "    time_bin_containers = a_continuously_decoded_result.time_bin_containers[0]\n",
    "    time_window_centers = time_bin_containers.centers\n",
    "    # p_x_given_n.shape # (62, 4, 209389)\n",
    "    a_marginal_x = a_continuously_decoded_result.marginal_x_list[0]\n",
    "    # active_time_window_variable = a_decoder.active_time_window_centers\n",
    "    active_time_window_variable = time_window_centers\n",
    "    active_most_likely_positions_x = a_marginal_x['most_likely_positions_1D'] # a_decoder.most_likely_positions[:,0].T\n",
    "    _out_data[a_decoder_name] = pd.DataFrame({'t': time_window_centers, 'x': active_most_likely_positions_x, 'binned_time': np.arange(len(time_window_centers))})\n",
    "    _out_data[a_decoder_name] = _out_data[a_decoder_name].position.adding_lap_info(laps_df=laps_df, inplace=False)\n",
    "    _out_data[a_decoder_name] = _out_data[a_decoder_name].time_point_event.adding_true_decoder_identifier(t_start=t_start, t_delta=t_delta, t_end=t_end) ## ensures ['maze_id', 'is_LR_dir']\n",
    "    _out_data[a_decoder_name]['is_active_decoder_time'] = (_out_data[a_decoder_name]['truth_decoder_name'].fillna('', inplace=False) == a_decoder_name)\n",
    "\n",
    "    # is_active_decoder_time = (_out_data[a_decoder_name]['truth_decoder_name'] == a_decoder_name)\n",
    "    active_decoder_time_points = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] == a_decoder_name]['t'].to_numpy()\n",
    "    active_decoder_most_likely_positions_x = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] == a_decoder_name]['x'].to_numpy()\n",
    "    active_decoder_inactive_time_points = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] != a_decoder_name]['t'].to_numpy()\n",
    "    active_decoder_inactive_most_likely_positions_x = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] != a_decoder_name]['x'].to_numpy()\n",
    "    ## could fill y with np.nan instead of getting shorter?\n",
    "    _out_data_plot_kwargs[a_decoder_name] = (dict(x=active_decoder_time_points, y=active_decoder_most_likely_positions_x, color=a_decoder_color, **active_decoded_pos_line_kwargs), dict(x=active_decoder_inactive_time_points, y=active_decoder_inactive_most_likely_positions_x, color=a_decoder_color, **inactive_decoded_pos_line_kwargs))\n",
    "\n",
    "_out_data_plot_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8972db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out_data[a_decoder_name] = _out_data[a_decoder_name].position.adding_lap_info(laps_df=laps_df, inplace=False)\n",
    "# _out_data[a_decoder_name] = _out_data[a_decoder_name].time_point_event.adding_true_decoder_identifier(t_start=t_start, t_delta=t_delta, t_end=t_end) ## ensures ['maze_id', 'is_LR_dir']\n",
    "\n",
    "# is_active_decoder_time = (_out_data[a_decoder_name]['truth_decoder_name'] == a_decoder_name)\n",
    "active_decoder_time_points = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] == a_decoder_name]['t'].to_numpy()\n",
    "active_decoder_most_likely_positions_x = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] == a_decoder_name]['x'].to_numpy()\n",
    "active_decoder_inactive_time_points = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] != a_decoder_name]['t'].to_numpy()\n",
    "active_decoder_inactive_most_likely_positions_x = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] != a_decoder_name]['x'].to_numpy()\n",
    "\n",
    "_out_data[a_decoder_name] = ((active_decoder_time_points, active_decoder_most_likely_positions_x), (active_decoder_inactive_time_points, active_decoder_inactive_most_likely_positions_x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dd7358",
   "metadata": {},
   "outputs": [],
   "source": [
    "partitioned_dfs = partition_df_dict(pos_df, partitionColumn='truth_decoder_name')\n",
    "\n",
    "a_decoder_name: str = 'short_LR'\n",
    "a_binned_time_grouped_df = partitioned_dfs[a_decoder_name].groupby('binned_time', axis='index', dropna=True)\n",
    "a_binned_time_grouped_df = a_binned_time_grouped_df.median().dropna(axis='index', subset=['x']) ## without the `.dropna(axis='index', subset=['x'])` part it gets an exhaustive df for all possible values of 'binned_time', even those not listed\n",
    "\n",
    "a_matching_binned_times = a_binned_time_grouped_df.reset_index(drop=False)['binned_time']\n",
    "a_matching_binned_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f61fd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "## split into two dfs for each decoder -- the supported and the unsupported\n",
    "partition\n",
    "\n",
    "PandasHelpers.safe_pandas_get_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f2e753",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df.dropna(axis='index', subset=['lap', 'truth_decoder_name'], inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604e0329",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_df: pd.DataFrame = global_laps_obj.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990b67c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import find_epochs_overlapping_other_epochs\n",
    "\n",
    "## INPUTS: global_laps\n",
    "_out_split_pseudo2D_posteriors_dict = {}\n",
    "_out_split_pseudo2D_out_dict = {}\n",
    "pre_filtered_col_names = ['pre_filtered_most_likely_position_indicies', 'pre_filtered_most_likely_position'] # 'pre_filtered_time_bin_containers', 'pre_filtered_p_x_given_n', \n",
    "post_filtered_col_names = [a_col_name.removeprefix('pre_filtered_') for a_col_name in pre_filtered_col_names] # ['time_bin_containers', 'most_likely_position_indicies', 'most_likely_position']\n",
    "print(post_filtered_col_names)\n",
    "for a_time_bin_size, pseudo2D_decoder_continuously_decoded_result in continuously_decoded_pseudo2D_decoder_dict.items():\n",
    "    print(f'a_time_bin_size: {a_time_bin_size}')\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size] = {'pre_filtered_p_x_given_n': None, 'pre_filtered_time_bin_containers': None, 'pre_filtered_most_likely_position_indicies': None, 'pre_filtered_most_likely_position': None, \n",
    "                                                     'is_timebin_included': None, 'p_x_given_n': None} # , 'time_window_centers': None\n",
    "    # pseudo2D_decoder_continuously_decoded_result: DecodedFilterEpochsResult = continuously_decoded_dict.get('pseudo2D', None)\n",
    "    assert len(pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list) == 1\n",
    "    p_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0]\n",
    "    # p_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0]['p_x_given_n']\n",
    "    time_bin_containers = pseudo2D_decoder_continuously_decoded_result.time_bin_containers[0]\n",
    "    # time_window_centers = time_bin_containers.centers\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position_indicies'] = deepcopy(pseudo2D_decoder_continuously_decoded_result.most_likely_position_indicies_list[0])\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position'] = deepcopy(pseudo2D_decoder_continuously_decoded_result.most_likely_positions_list[0])\n",
    "    ## INPUTS: time_bin_containers, global_laps\n",
    "    left_edges = deepcopy(time_bin_containers.left_edges)\n",
    "    right_edges = deepcopy(time_bin_containers.right_edges)\n",
    "    continuous_time_binned_computation_epochs_df: pd.DataFrame = pd.DataFrame({'start': left_edges, 'stop': right_edges, 'label': np.arange(len(left_edges))})\n",
    "    is_timebin_included: NDArray = find_epochs_overlapping_other_epochs(epochs_df=continuous_time_binned_computation_epochs_df, epochs_df_required_to_overlap=deepcopy(global_laps))\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_p_x_given_n'] = p_x_given_n\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_time_bin_containers'] = time_bin_containers\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['is_timebin_included'] = is_timebin_included\n",
    "    # continuous_time_binned_computation_epochs_df['is_in_laps'] = is_timebin_included\n",
    "    ## filter by whether it's included or not:\n",
    "    p_x_given_n = p_x_given_n[:, :, is_timebin_included]\n",
    "    # time_window_centers = \n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['p_x_given_n'] = p_x_given_n\n",
    "    # _out_split_pseudo2D_out_dict[a_time_bin_size]['time_window_centers'] = time_window_centers[is_timebin_included]\n",
    "    # p_x_given_n.shape # (62, 4, 209389)\n",
    "\n",
    "    ## Split across the 2nd axis to make 1D posteriors that can be displayed in separate dock rows:\n",
    "    assert p_x_given_n.shape[1] == 4, f\"expected the 4 pseudo-y bins for the decoder in p_x_given_n.shape[1]. but found p_x_given_n.shape: {p_x_given_n.shape}\"\n",
    "    # split_pseudo2D_posteriors_dict = {k:np.squeeze(p_x_given_n[:, i, :]) for i, k in enumerate(('long_LR', 'long_RL', 'short_LR', 'short_RL'))}\n",
    "    _out_split_pseudo2D_posteriors_dict[a_time_bin_size] = deepcopy(p_x_given_n)\n",
    "    \n",
    "    # for a_col_name in pre_filtered_col_names:\n",
    "    #     filtered_col_name = a_col_name.removeprefix('pre_filtered_')\n",
    "    #     print(f'a_col_name: {a_col_name}, filtered_col_name: {filtered_col_name}, shape: {np.shape(_out_split_pseudo2D_out_dict[a_time_bin_size][a_col_name])}')\n",
    "    #     _out_split_pseudo2D_out_dict[a_time_bin_size][filtered_col_name] = _out_split_pseudo2D_out_dict[a_time_bin_size][a_col_name][is_timebin_included, :]\n",
    "        \n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['most_likely_position_indicies'] = _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position_indicies'][:, is_timebin_included]\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['most_likely_position'] = _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position'][is_timebin_included, :]\n",
    "    \n",
    "\n",
    "p_x_given_n.shape # (n_position_bins, n_decoding_models, n_time_bins) - (57, 4, 29951)\n",
    "\n",
    "## OUTPUTS: _out_split_pseudo2D_posteriors_dict, _out_split_pseudo2D_out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d25155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_most_likely_position_comparsions\n",
    "\n",
    "# fig, axs = plot_most_likely_position_comparsions(pho_custom_decoder, axs=ax, sess.position.to_dataframe())\n",
    "fig, axs = plot_most_likely_position_comparsions(computation_result.computed_data['pf2D_Decoder'], computation_result.sess.position.to_dataframe(), **overriding_dict_with(lhs_dict={'show_posterior':True, 'show_one_step_most_likely_positions_plots':True}, **kwargs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0cf8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93036009",
   "metadata": {},
   "source": [
    "### <a id='toc7_1_2_'></a>[🔝 Dock Track Widgets](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67f05bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.add_new_embedded_pyqtgraph_render_plot_widget("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f78e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_main_raster_plot = False\n",
    "_interval_tracks_out_dict = active_2d_plot.prepare_pyqtgraph_intervalPlot_tracks(enable_interval_overview_track=False, should_link_to_main_plot_widget=has_main_raster_plot)\n",
    "interval_window_dock_config, interval_dock_item, intervals_time_sync_pyqtgraph_widget, intervals_root_graphics_layout_widget, intervals_plot_item = _interval_tracks_out_dict['intervals']\n",
    "# dock_config, interval_overview_dock_item, intervals_overview_time_sync_pyqtgraph_widget, intervals_overview_root_graphics_layout_widget, intervals_overview_plot_item = _interval_tracks_out_dict['interval_overview']\n",
    "interval_window_dock_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2042a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_dock_item.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cc9d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_dock_item.setMaximumHeight(89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9865df",
   "metadata": {},
   "outputs": [],
   "source": [
    "_interval_tracks_out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4637029",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.dock_manager_widget.add_display_dock("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9f3acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.get_flat_dockitems_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f946a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.layout_dockGroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb8dc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.get_group_only_flat_dock_identifiers_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d822fa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.get_leaf_only_flat_dock_identifiers_list()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd739ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_dock in active_2d_plot.get_flat_dockitems_list():\n",
    "    a_dock.showTitleBar()\n",
    "    # a_dock.updateStyle()\n",
    "    a_dock.config\n",
    "    a_dock.setOrientation('horizontal', force=True)\n",
    "    a_dock.updateStyle()\n",
    "    a_dock.update() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f51940",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dock Tree Widget should register with `dock_manager_widget` (DynamicDockDisplayAreaContentMixin) so that it recieves and issues updates when dock items are added/changed/closed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fc1767",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import DockDisplayColors, CustomDockDisplayConfig\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.NestedDockAreaWidget import NestedDockAreaWidget\n",
    "\n",
    "name='group_dock_widget'\n",
    "dockSize=(500,50*4)\n",
    "dockAddLocationOpts=['bottom']\n",
    "\n",
    "display_config = CustomDockDisplayConfig(showCloseButton=True, showCollapseButton=True, showGroupButton=True, orientation='horizontal')\n",
    "## Add the container to hold dynamic matplotlib plot widgets:\n",
    "nested_dynamic_docked_widget_container = NestedDockAreaWidget()\n",
    "nested_dynamic_docked_widget_container.setObjectName(\"nested_dynamic_docked_widget_container\")\n",
    "nested_dynamic_docked_widget_container.setSizePolicy(pg.QtGui.QSizePolicy.Expanding, pg.QtGui.QSizePolicy.Preferred)\n",
    "nested_dynamic_docked_widget_container.setMinimumHeight(40)\n",
    "nested_dynamic_docked_widget_container.setContentsMargins(0, 0, 0, 0)\n",
    "_, dDisplayItem = active_2d_plot.ui.dynamic_docked_widget_container.add_display_dock(name, dockSize=dockSize, display_config=display_config, widget=nested_dynamic_docked_widget_container, dockAddLocationOpts=dockAddLocationOpts, autoOrientation=False)\n",
    "dDisplayItem.setOrientation('horizontal', force=True)\n",
    "dDisplayItem.updateStyle()\n",
    "dDisplayItem.update() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0aea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_docked_widget_container: NestedDockAreaWidget  = active_2d_plot.ui.dynamic_docked_widget_container\n",
    "# dynamic_docked_widget_container.dynamic_display_dict\n",
    "\n",
    "name_list = ['intervals', 'rasters[raster_window]', 'new_curves_separate_plot']\n",
    "for a_name in name_list:\n",
    "    a_dock = dynamic_docked_widget_container.find_display_dock(a_name)\n",
    "    a_dock\n",
    "    a_dock.hideTitleBar()\n",
    "    # a_dock.labelHidden = True\n",
    "    a_dock.updateStyle()\n",
    "    \n",
    "\n",
    "\n",
    "# dynamic_docked_widget_container.find_display_dock('intervals').hideTitleBar()\n",
    "# dynamic_docked_widget_container.find_display_dock('rasters[raster_window]').hideTitleBar()\n",
    "# dynamic_docked_widget_container.find_display_dock('new_curves_separate_plot').hideTitleBar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9939b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_print_dock_sizes(active_2d_plot):\n",
    "    \"\"\" prints the size variables for each Dock item \n",
    "    \"\"\"\n",
    "    from pyphoplacecellanalysis.General.Mixins.DisplayHelpers import debug_widget_geometry\n",
    "\n",
    "    flat_dockitems_list = active_2d_plot.ui.dynamic_docked_widget_container.get_flat_dockitems_list()\n",
    "    for a_dock in flat_dockitems_list:\n",
    "        print(f'a_dock: {a_dock}')\n",
    "        debug_widget_geometry(a_dock)\n",
    "        \n",
    "    print('\\tdone.')\n",
    "        \n",
    "\n",
    "debug_print_dock_sizes(active_2d_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c932dcce",
   "metadata": {
    "tags": [
     "dock-widgets"
    ]
   },
   "outputs": [],
   "source": [
    "flat_widgets_list = active_2d_plot.ui.dynamic_docked_widget_container.get_flat_widgets_list()\n",
    "flat_dockitems_list = active_2d_plot.ui.dynamic_docked_widget_container.get_flat_dockitems_list()\n",
    "flat_dock_identifiers_list = active_2d_plot.ui.dynamic_docked_widget_container.get_flat_dock_identifiers_list()\n",
    "# flat_dockitems_list\n",
    "flat_dock_identifiers_list\n",
    "# flat_widgets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03657d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "rasters_dock = active_2d_plot.ui.dynamic_docked_widget_container.find_display_dock('rasters[raster_window]')\n",
    "rasters_dock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98199475",
   "metadata": {},
   "outputs": [],
   "source": [
    "rasters_dock.stretch()\n",
    "rasters_dock.setStretch(y=240)\n",
    "rasters_dock.stretch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4405ffad",
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_dock_items = {}\n",
    "nested_dynamic_docked_widget_container_widgets = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fd4da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()\n",
    "# flat_widgets_list = active_2d_plot.ui.dynamic_docked_widget_container.get_flat_widgets_list()\n",
    "# dock_group_name: str = 'ContinuousDecode_ - t_bin_size: 0.025'\n",
    "dock_group_name: str = 'ContinuousDecode_ - t_bin_size: 0.05'\n",
    "flat_group_dockitems_list = grouped_dock_items_dict[dock_group_name]\n",
    "dDisplayItem, nested_dynamic_docked_widget_container = active_2d_plot.ui.dynamic_docked_widget_container.build_wrapping_nested_dock_area(flat_group_dockitems_list, dock_group_name=dock_group_name)\n",
    "nested_dock_items[dock_group_name] = dDisplayItem\n",
    "nested_dynamic_docked_widget_container_widgets[dock_group_name] = nested_dynamic_docked_widget_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432310ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: active_2d_plot\n",
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()\n",
    "nested_dock_items = {}\n",
    "nested_dynamic_docked_widget_container_widgets = {}\n",
    "for dock_group_name, flat_group_dockitems_list in grouped_dock_items_dict.items():\n",
    "    dDisplayItem, nested_dynamic_docked_widget_container = active_2d_plot.ui.dynamic_docked_widget_container.build_wrapping_nested_dock_area(flat_group_dockitems_list, dock_group_name=dock_group_name)\n",
    "    nested_dock_items[dock_group_name] = dDisplayItem\n",
    "    nested_dynamic_docked_widget_container_widgets[dock_group_name] = nested_dynamic_docked_widget_container\n",
    "\n",
    "## OUTPUTS: nested_dock_items, nested_dynamic_docked_widget_container_widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d095b42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_wrapping_nested_dock_area\n",
    "\n",
    "dynamic_docked_widget_container = active_2d_plot.ui.dynamic_docked_widget_container # NestedDockAreaWidget \n",
    "dynamic_docked_widget_container.build_wrapping_nested_dock_area(f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0f9b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_crosshairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85366f3c",
   "metadata": {},
   "source": [
    "## <a id='toc7_2_'></a>[2025-02-17 - Dock Item \"Track\" sizing](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f80e740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.NestedDockAreaWidget import NestedDockAreaWidget\n",
    "\n",
    "dock_manager_widget: NestedDockAreaWidget  = active_2d_plot.dock_manager_widget\n",
    "dock_manager_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7954acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()\n",
    "grouped_dock_items_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbc4bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_dock_items, nested_dynamic_docked_widget_container_widgets = dock_manager_widget.layout_dockGroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9b64d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dock_manager_widget.get_flat_dockitems_list()\n",
    "\n",
    "flat_dockitems_list = dock_manager_widget.get_flat_dockitems_list() ## get the non-grouped dockitems\n",
    "flat_dockitems_list\n",
    "# flat_dockitems_list[0].widgets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497f2289",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dock: Dock = flat_dockitems_list[-1]\n",
    "a_dock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9496b8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_dock_stretch_sizes_list = [a_dock.stretch() for a_dock in flat_dockitems_list] # [(500, 40), (500, 50), (65, 200), (65, 200), (65, 200), (65, 200), (500, 321), (500, 25)]\n",
    "flat_dock_stretch_sizes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d0b1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_dock_stretch_sizes = np.array(flat_dock_stretch_sizes_list)\n",
    "total_height: float = np.sum(flat_dock_stretch_sizes, axis=0)[-1] ## total height of all docks\n",
    "total_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c6c246",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_dock_configs_list = [a_dock.config for a_dock in flat_dockitems_list]\n",
    "flat_dock_configs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dad856",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dock: Dock = flat_dockitems_list[0]\n",
    "a_dock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71138bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_keys_if_possible(curr_key='dynamic_display_dict', curr_value=dock_manager_widget.dynamic_display_dict, max_depth=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb42af97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.External.pyqtgraph.dockarea.Dock import Dock, DockDisplayConfig, DockLabel\n",
    "\n",
    "print(f'active_2d_plot.get_leaf_only_flat_dock_identifiers_list(): {active_2d_plot.get_leaf_only_flat_dock_identifiers_list()}')\n",
    "leaf_only_flat_docks_dict: Dict[str, Dock] = {k:active_2d_plot.find_display_dock(k) for k in active_2d_plot.get_leaf_only_flat_dock_identifiers_list()}\n",
    "print(f'leaf_only_flat_docks_dict: {leaf_only_flat_docks_dict}')\n",
    "\n",
    "leaf_only_flat_docks_geometry_size_list = [(a_dock.width(), a_dock.height()) for k, a_dock in leaf_only_flat_docks_dict.items()] # [(1855, 69), (1855, 69), (1855, 71), (1855, 71), (1855, 71), (1855, 73), (1855, 64), (1855, 85), (1855, 30)]\n",
    "leaf_only_flat_docks_geometry_sizes = np.vstack(leaf_only_flat_docks_geometry_size_list)\n",
    "leaf_only_flat_docks_geometry_sizes\n",
    "\n",
    "\n",
    "single_track_height_unit: int = 30 ## how tall a single track height unit is, determining the minimum height of a track\n",
    "\n",
    "\n",
    "total_leaf_only_flat_docks_geometry_size = np.sum(leaf_only_flat_docks_geometry_sizes, axis=0)\n",
    "total_leaf_only_flat_docks_geometry_size\n",
    "\n",
    "leaf_only_flat_docks_stretch_list = [a_dock.stretch() for k, a_dock in leaf_only_flat_docks_dict.items()] # [(500, 40), (500, 50), (65, 200), (65, 200), (65, 200), (65, 200), (10, 4), (10, 4), (10, 1)]\n",
    "leaf_only_flat_docks_stretchs = np.vstack(leaf_only_flat_docks_stretch_list)\n",
    "leaf_only_flat_docks_stretchs\n",
    "\n",
    "# leaf_only_flat_docks_dict\n",
    "\n",
    "# active_2d_plot.get_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb50aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_only_flat_docks_dict['intervals'].setStretch(x=10, y=4)\n",
    "\n",
    "leaf_only_flat_docks_dict['new_curves_separate_plot'].setStretch(x=10, y=4)\n",
    "for a_name in ['ContinuousDecode_long_LR - t_bin_size: 0.025', 'ContinuousDecode_long_RL - t_bin_size: 0.025', 'ContinuousDecode_short_LR - t_bin_size: 0.025', 'ContinuousDecode_short_RL - t_bin_size: 0.025']:\n",
    "\tleaf_only_flat_docks_dict[a_name].setStretch(x=10, y=4)\n",
    "\tleaf_only_flat_docks_dict[a_name].setMinimumHeight(30)  # Set a smaller minimum height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591bd986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.External.pyqtgraph.dockarea.Dock import debug_widget_geometry\n",
    "\n",
    "# active_2d_plot.get_leaf_only_flat_dock_identifiers_list()\n",
    "\n",
    "dock_items_dict = {k:v[-1] for k, v in output_dict.items()}\n",
    "# dock_items_dict = {k:v[-1] for k, v in MASKED_output_dict.items()}\n",
    "dock_items_dict\n",
    "\n",
    "a_dock_item = dock_items_dict['PBE_marginal_over_track_ID']\n",
    "a_dock_item.setStretch(x=10, y=1)  # Same larger height stretch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b0acc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for k, v in dock_items_dict.items():\n",
    "    print(f'k: {k}')\n",
    "    # debug_widget_geometry(v, widget_name=k)\n",
    "    # Allow one dock to be smaller than its minimum size hint\n",
    "    v.widgetArea.setMinimumHeight(30)  # Set a smaller minimum height\n",
    "    \n",
    "    v.debug_print(widget_name=k)\n",
    "    # Assuming you have three docks\n",
    "    # v.stretch()  # Small height stretch\n",
    "\n",
    "    # smallDock.setStretch(x=10, y=1)  # Small height stretch\n",
    "    # tallDock1.setStretch(x=10, y=3)  # Larger height stretch\n",
    "    # tallDock2.setStretch(x=10, y=3)  # Same larger height stretch\n",
    "\n",
    "    # v.label.debug_print(label_name=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3fe261",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.dissolve_all_dockGroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db33f073",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.layout_dockGroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c45eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dock_items_dict: Dict[str, List[Dock]] = active_2d_plot.get_dockGroup_dock_dict()\n",
    "grouped_dock_items_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693f5fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.dock_manager_widget.nested_dock_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9046712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a_group_id, a_group_dock in active_2d_plot.dock_manager_widget.nested_dock_items.items():\n",
    "# \ta_group_container_id: str = f'GROUP[{a_group_id}]'\n",
    "# \tdel active_2d_plot.dock_manager_widget.nested_dock_items[a_group_id]\n",
    "\t\n",
    "# active_2d_plot.dock_manager_widget.nested_dock_items.clear()\n",
    "active_2d_plot.dock_manager_widget.nested_dock_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99688c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_dock_ids_list = active_2d_plot.get_group_only_flat_dock_identifiers_list()\n",
    "group_dock_ids_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14beb813",
   "metadata": {},
   "source": [
    "## 🎯🔜 Adjust SpikeRaster2D default plot sizings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184de423",
   "metadata": {
    "tags": [
     "2025-05-12"
    ]
   },
   "outputs": [],
   "source": [
    "## extract the components so the `background_static_scroll_window_plot` scroll bar is the right size:\n",
    "active_2d_plot = spike_raster_window.spike_raster_plt_2d\n",
    "preview_overview_scatter_plot: pg.ScatterPlotItem  = active_2d_plot.plots.preview_overview_scatter_plot # ScatterPlotItem\n",
    "# preview_overview_scatter_plot.setDownsampling(auto=True, method='subsample', dsRate=10)\n",
    "main_graphics_layout_widget: pg.GraphicsLayoutWidget = active_2d_plot.ui.main_graphics_layout_widget\n",
    "wrapper_layout: pg.QtWidgets.QVBoxLayout = active_2d_plot.ui.wrapper_layout\n",
    "main_content_splitter = active_2d_plot.ui.main_content_splitter # QSplitter\n",
    "active_window_container_layout = active_2d_plot.ui.active_window_container_layout\n",
    "layout = active_2d_plot.ui.layout\n",
    "\n",
    "has_main_raster_plot: bool = (active_2d_plot.plots.main_plot_widget is not None)\n",
    "if has_main_raster_plot:\n",
    "    main_plot_widget = active_2d_plot.plots.main_plot_widget # PlotItem\n",
    "    main_plot_widget.setMinimumHeight(20.0)\n",
    "else:\n",
    "    active_window_container_layout.setVisible(False)\n",
    "\n",
    "background_static_scroll_window_plot = active_2d_plot.plots.background_static_scroll_window_plot # PlotItem\n",
    "background_static_scroll_window_plot.setMinimumHeight(50.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a139fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_plot_widget.size()\n",
    "main_plot_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee18a487",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_plot_widget.hide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dc5dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_static_scroll_window_plot.size()\n",
    "background_static_scroll_window_plot.setMaximumHeight(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ce21ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "_raster_tracks_out_dict = active_2d_plot.prepare_pyqtgraph_rasterPlot_track(name_modifier_suffix='raster_window', should_link_to_main_plot_widget=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6059b40a",
   "metadata": {},
   "source": [
    "#### <a id='toc7_2_1_1_'></a>[Spike3DRasterWindow - Right Sidebar Widgets](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eff235",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.on_update_right_sidebar_visible_interval_info_tables()\n",
    "spike_raster_window.build_dock_area_managing_tree_widget()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9d696e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.EpochRenderConfigWidget.EpochRenderConfigWidget import EpochRenderConfigWidget, EpochRenderConfigsListWidget\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import DockDisplayColors, CustomDockDisplayConfig\n",
    "\n",
    "an_epochs_display_list_widget: EpochRenderConfigsListWidget = spike_raster_window.build_epoch_intervals_visual_configs_widget()\n",
    "an_epochs_display_list_widget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549f454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_raster_plot.ui.epochs_render_configs_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa59d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.build_neuron_visual_configs_widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3738059c",
   "metadata": {},
   "source": [
    "## <a id='toc7_3_'></a>[💯 2025-01-22 - Add Selection Widget for SpikeRaster3DWindow](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bb8383",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_plt_2d: Spike2DRaster = spike_raster_window.spike_raster_plt_2d\n",
    "a_range_selection_widget, range_selection_root_graphics_layout_widget, range_selection_plot_item, range_selection_dDisplayItem = spike_raster_plt_2d.add_new_embedded_pyqtgraph_render_plot_widget(name='range_selection_capture_widget', dockSize=(500,25))\n",
    "range_selection_dDisplayItem.setMaximumHeight(25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cde7d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c1edcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attrs import define, field, Factory\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsObjects.CustomInfiniteLine import CustomInfiniteLine\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsObjects.CustomLinearRegionItem import CustomLinearRegionItem\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsObjects.CustomIntervalRectsItem import CustomIntervalRectsItem\n",
    "\n",
    "\n",
    "@define(slots=False)\n",
    "class UserTimelineSelections:\n",
    "    point_selections: List[pg.TargetItem] = field(default=Factory(list))\n",
    "    line_selections: List[CustomInfiniteLine] = field(default=Factory(list))\n",
    "    range_selections: List[CustomLinearRegionItem] = field(default=Factory(list))\n",
    "    \n",
    "\n",
    "selections: UserTimelineSelections = UserTimelineSelections()\n",
    "selections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af0c666",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Add three infinite lines with labels\n",
    "inf1 = pg.InfiniteLine(movable=True, angle=90, label='x={value:0.2f}', \n",
    "                       labelOpts={'position':0.1, 'color': (200,200,100), 'fill': (200,200,200,50), 'movable': True})\n",
    "inf2 = pg.InfiniteLine(movable=True, angle=0, pen=(0, 0, 200), bounds = [-20, 20], hoverPen=(0,200,0), label='y={value:0.2f}mm', \n",
    "                       labelOpts={'color': (200,0,0), 'movable': True, 'fill': (0, 0, 200, 100)})\n",
    "inf3 = pg.InfiniteLine(movable=True, angle=45, pen='g', label='diagonal',\n",
    "                       labelOpts={'rotateAxis': [1, 0], 'fill': (0, 200, 0, 100), 'movable': True})\n",
    "inf1.setPos([2,2])\n",
    "p1.addItem(inf1)\n",
    "p1.addItem(inf2)\n",
    "p1.addItem(inf3)\n",
    "\n",
    "targetItem1 = pg.TargetItem()\n",
    "\n",
    "targetItem2 = pg.TargetItem(\n",
    "    pos=(30, 5),\n",
    "    size=20,\n",
    "    symbol=\"star\",\n",
    "    pen=\"#F4511E\",\n",
    "    label=\"vert={1:0.2f}\",\n",
    "    labelOpts={\n",
    "        \"offset\": QtCore.QPoint(15, 15)\n",
    "    }\n",
    ")\n",
    "targetItem2.label().setAngle(45)\n",
    "\n",
    "targetItem3 = pg.TargetItem(\n",
    "    pos=(10, 10),\n",
    "    size=10,\n",
    "    symbol=\"x\",\n",
    "    pen=\"#00ACC1\",\n",
    ")\n",
    "targetItem3.setLabel(\n",
    "    \"Third Label\",\n",
    "    {\n",
    "        \"anchor\": QtCore.QPointF(0.5, 0.5),\n",
    "        \"offset\": QtCore.QPointF(30, 0),\n",
    "        \"color\": \"#558B2F\",\n",
    "        \"rotateAxis\": (0, 1)\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "def callableFunction(x, y):\n",
    "    return f\"Square Values: ({x**2:.4f}, {y**2:.4f})\"\n",
    "\n",
    "targetItem4 = pg.TargetItem(\n",
    "    pos=(10, -10),\n",
    "    label=callableFunction\n",
    ")\n",
    "\n",
    "p1.addItem(targetItem1)\n",
    "p1.addItem(targetItem2)\n",
    "p1.addItem(targetItem3)\n",
    "p1.addItem(targetItem4)\n",
    "\n",
    "# Add a linear region with a label\n",
    "lr = pg.LinearRegionItem(values=[70, 80])\n",
    "p1.addItem(lr)\n",
    "label = pg.InfLineLabel(lr.lines[1], \"region 1\", position=0.95, rotateAxis=(1,0), anchor=(1, 1))\n",
    "\n",
    "\n",
    "\n",
    "vb=DragSelectViewBox()\n",
    "plotItem=pg.PlotItem(viewBox=vb)\n",
    "plotWidget=pg.PlotWidget(plotItem=plotItem)\n",
    "plotWidget.plot([0,1,2,3],[10,5,7,3],pen='b')\n",
    "plotWidget.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be99f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QMainWindow, QVBoxLayout, QWidget\n",
    "import pyqtgraph as pg\n",
    "\n",
    "@function_attributes(short_name=None, tags=['pyqtgraph', 'selection', 'interactive'], input_requires=[], output_provides=[], uses=[], used_by=[], creation_date='2025-06-16 10:26', related_items=[])\n",
    "class PlotWithSelection(pg.PlotWidget):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        # Initialize variables to track the selection\n",
    "        self.start_pos = None\n",
    "        self.end_pos = None\n",
    "        self.is_selecting = False\n",
    "        \n",
    "        # Disable default panning\n",
    "        self.setMouseTracking(True)\n",
    "        self.plotItem.vb.setMouseEnabled(x=False, y=False)  # Disable default panning/zooming\n",
    "\n",
    "    def mousePressEvent(self, event):\n",
    "        if event.button() == Qt.LeftButton:\n",
    "            # Get the position where the mouse was clicked\n",
    "            pos = self.plotItem.vb.mapSceneToView(event.pos())\n",
    "            self.start_pos = pos.x()\n",
    "            self.is_selecting = True\n",
    "        else:\n",
    "            super().mousePressEvent(event)\n",
    "\n",
    "    def mouseMoveEvent(self, event):\n",
    "        if self.is_selecting:\n",
    "            # Update the end position while dragging\n",
    "            pos = self.plotItem.vb.mapSceneToView(event.pos())\n",
    "            self.end_pos = pos.x()\n",
    "            self.update_selection()\n",
    "        else:\n",
    "            super().mouseMoveEvent(event)\n",
    "\n",
    "    def mouseReleaseEvent(self, event):\n",
    "        if event.button() == Qt.LeftButton and self.is_selecting:\n",
    "            # Get the final position where the mouse was released\n",
    "            pos = self.plotItem.vb.mapSceneToView(event.pos())\n",
    "            self.end_pos = pos.x()\n",
    "\n",
    "            # Ensure that the start and end positions are valid\n",
    "            if self.start_pos is not None and self.end_pos is not None:\n",
    "                # Create a new LinearRegionItem\n",
    "                region = pg.LinearRegionItem(values=(min(self.start_pos, self.end_pos), max(self.start_pos, self.end_pos)))\n",
    "                self.addItem(region)\n",
    "\n",
    "            # Reset the selection state\n",
    "            self.start_pos = None\n",
    "            self.end_pos = None\n",
    "            self.is_selecting = False\n",
    "        else:\n",
    "            super().mouseReleaseEvent(event)\n",
    "\n",
    "    def update_selection(self):\n",
    "        # Optionally, you can draw a temporary selection line here\n",
    "        pass\n",
    "\n",
    "# Example usage\n",
    "win = QMainWindow()\n",
    "central_widget = QWidget()\n",
    "layout = QVBoxLayout(central_widget)\n",
    "\n",
    "plot_widget = PlotWithSelection()\n",
    "plot_widget.plot([1, 5, 2, 4, 3], pen='r')  # Example data\n",
    "\n",
    "layout.addWidget(plot_widget)\n",
    "win.setCentralWidget(central_widget)\n",
    "win.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599e7a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_selection_plot_item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ded6097",
   "metadata": {},
   "source": [
    "### 2025-06-16 - Matplotlib `SpanSelector` approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c613cd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.widgets import SpanSelector\n",
    "\n",
    "dock_titles = ['ContinuousDecode_long_LR - t_bin_size: 0.025', 'ContinuousDecode_long_RL - t_bin_size: 0.025', 'ContinuousDecode_short_LR - t_bin_size: 0.025', 'ContinuousDecode_short_RL - t_bin_size: 0.025']\n",
    "for a_dock_title in dock_titles:\n",
    "    a_dock, widget = active_2d_plot.find_dock_item_tuple(identifier=a_dock_title)\n",
    "    # widget.plots_data\n",
    "    widget.params.user_selections = [] ## empty selections to start\n",
    "    widget.ui.span_selector = None\n",
    "    widget.ui.span_selector_fn = None\n",
    "\n",
    "    def onselect(xmin, xmax):\n",
    "        \"\"\" captures: widget, y, line2, ax2, fig, \n",
    "        \"\"\"\n",
    "        indmin, indmax = np.searchsorted(widget.plots_data.time_window_centers, (xmin, xmax))\n",
    "        indmax = min(len(widget.plots_data.time_window_centers) - 1, indmax)\n",
    "        region_x = widget.plots_data.time_window_centers[indmin:indmax]\n",
    "        # region_y = widget.plots_data.xbin[indmin:indmax]\n",
    "        if len(region_x) >= 2:\n",
    "            widget.params.user_selections.append(region_x)            \n",
    "            # line2.set_data(region_x, region_y)\n",
    "            # ax2.set_xlim(region_x[0], region_x[-1])\n",
    "            # ax2.set_ylim(region_y.min(), region_y.max())\n",
    "            # fig.canvas.draw_idle()\n",
    "            \n",
    "    widget.ui.span_selector_fn = onselect\n",
    "\n",
    "    widget.ui.span_selector = SpanSelector(\n",
    "        widget.ax,\n",
    "        widget.ui.span_selector_fn,\n",
    "        \"horizontal\",\n",
    "        useblit=True,\n",
    "        props=dict(alpha=0.5, facecolor=\"tab:blue\"),\n",
    "        interactive=True,\n",
    "        drag_from_anywhere=True\n",
    "    )\n",
    "    # Set useblit=True on most backends for enhanced performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94b0209",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dock, widget = active_2d_plot.find_dock_item_tuple(identifier='ContinuousDecode_long_RL - t_bin_size: 0.025')\n",
    "\n",
    "# widget.plots_data.xbin\n",
    "# widget.plots_data.time_\n",
    "widget.params.user_selections # [array([548.812, 548.838, 548.862, 548.888]), array([549.062, 549.088, 549.112, 549.138]), array([548.213, 548.237, 548.263, 548.288])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fcda63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [array([548.812, 548.838, 548.862, 548.888]), array([549.062, 549.088, 549.112, 549.138]), array([548.213, 548.237, 548.263, 548.288])]\n",
    "# 5 skip bins\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316fdc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.widgets import SpanSelector\n",
    "\n",
    "\n",
    "# class StatefulSpanSelector(SpanSelector):\n",
    "#     \"\"\" a version of MAtplotlib's SpanSelector widget that contains its selection state, callback function, and related information to provide a more object-oriented approach\n",
    "#     \"\"\"\n",
    "#     def onselect(self, xmin, xmax):\n",
    "#         indmin, indmax = np.searchsorted(x, (xmin, xmax))\n",
    "#         indmax = min(len(x) - 1, indmax)\n",
    "\n",
    "#         region_x = x[indmin:indmax]\n",
    "#         region_y = y[indmin:indmax]\n",
    "\n",
    "#         if len(region_x) >= 2:\n",
    "#             line2.set_data(region_x, region_y)\n",
    "#             ax2.set_xlim(region_x[0], region_x[-1])\n",
    "#             ax2.set_ylim(region_y.min(), region_y.max())\n",
    "#             fig.canvas.draw_idle()\n",
    "\n",
    "\n",
    "\n",
    "# Fixing random state for reproducibility\n",
    "np.random.seed(19680801)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(8, 6))\n",
    "\n",
    "x = np.arange(0.0, 5.0, 0.01)\n",
    "y = np.sin(2 * np.pi * x) + 0.5 * np.random.randn(len(x))\n",
    "\n",
    "ax1.plot(x, y)\n",
    "ax1.set_ylim(-2, 2)\n",
    "ax1.set_title('Press left mouse button and drag '\n",
    "              'to select a region in the top graph')\n",
    "\n",
    "line2, = ax2.plot([], [])\n",
    "\n",
    "\n",
    "def onselect(xmin, xmax):\n",
    "    \"\"\" captures: x, y, line2, ax2, fig, \n",
    "    \"\"\"\n",
    "    indmin, indmax = np.searchsorted(x, (xmin, xmax))\n",
    "    indmax = min(len(x) - 1, indmax)\n",
    "\n",
    "    region_x = x[indmin:indmax]\n",
    "    region_y = y[indmin:indmax]\n",
    "\n",
    "    if len(region_x) >= 2:\n",
    "        line2.set_data(region_x, region_y)\n",
    "        ax2.set_xlim(region_x[0], region_x[-1])\n",
    "        ax2.set_ylim(region_y.min(), region_y.max())\n",
    "        fig.canvas.draw_idle()\n",
    "        \n",
    "\n",
    "\n",
    "span = SpanSelector(\n",
    "    ax1,\n",
    "    onselect,\n",
    "    \"horizontal\",\n",
    "    useblit=True,\n",
    "    props=dict(alpha=0.5, facecolor=\"tab:blue\"),\n",
    "    interactive=True,\n",
    "    drag_from_anywhere=True\n",
    ")\n",
    "# Set useblit=True on most backends for enhanced performance.\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8736da11",
   "metadata": {},
   "source": [
    "# <a id='toc10_'></a>[Other Misc Plotting Stuff](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521bba12",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.plot._display_directional_template_debugger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb5ba90",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_template_debugger')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e9208a",
   "metadata": {},
   "source": [
    "### <a id='toc10_1_1_'></a>[Resume display stuff](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50f2ef8",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from flexitext import flexitext\n",
    "from neuropy.utils.matplotlib_helpers import FormattedFigureText, FigureMargins ## flexitext version\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out = curr_active_pipeline.display('_display_directional_track_template_pf1Ds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d2b444",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# _restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080c1041",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_two_step_decoder_prediction_error_2D', global_epoch_context, variable_name='p_x_given_n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e05b045",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_plot_most_likely_position_comparisons', global_epoch_context) # , variable_name='p_x_given_n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddebd9e",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_laps_overview')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d805c37",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_laps_overview')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3c3cea",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "'_display_directional_laps_overview'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb98e796",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# '_display_directional_merged_pfs'\n",
    "_out = curr_active_pipeline.display('_display_directional_merged_pfs', plot_all_directions=False, plot_long_directional=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47076a61",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "'_display_1d_placefield_occupancy'\n",
    "'_display_placemaps_pyqtplot_2D'\n",
    " '_display_2d_placefield_occupancy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481df233",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_2d_placefield_occupancy', global_any_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694d0a20",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_grid_bin_bounds_validation')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fbe6ee",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "_out = curr_active_pipeline.display('_display_running_and_replay_speeds_over_time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58951b11",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.utils.matplotlib_helpers import add_rectangular_selector, add_range_selector\n",
    "\n",
    "\n",
    "# epoch_name = global_any_name\n",
    "epoch_name = short_epoch_name\n",
    "computation_result = curr_active_pipeline.computation_results[epoch_name]\n",
    "grid_bin_bounds = computation_result.computation_config['pf_params'].grid_bin_bounds\n",
    "epoch_context = curr_active_pipeline.filtered_contexts[epoch_name]\n",
    "print(grid_bin_bounds)     \n",
    "fig, ax = computation_result.computed_data.pf2D.plot_occupancy(identifier_details_list=[epoch_name], active_context=epoch_context) \n",
    "\n",
    "# rect_selector, set_extents, reset_extents = add_rectangular_selector(fig, ax, initial_selection=grid_bin_bounds) # (24.82, 257.88), (125.52, 149.19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada4720b",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import add_vertical_track_bounds_lines\n",
    "\n",
    "grid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\n",
    "long_track_line_collection, short_track_line_collection = add_vertical_track_bounds_lines(grid_bin_bounds=grid_bin_bounds, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b862a66",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.peak_location_representing import compute_placefield_center_of_mass_positions\n",
    "\n",
    "\n",
    "epoch_name = global_any_name\n",
    "computation_result = curr_active_pipeline.computation_results[epoch_name]\n",
    "grid_bin_bounds = deepcopy(computation_result.computation_config['pf_params'].grid_bin_bounds)\n",
    "epoch_context = curr_active_pipeline.filtered_contexts[epoch_name]\n",
    "\n",
    "grid_bin_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65654f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5905e90b",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "grid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\n",
    "grid_bin_bounds\n",
    "long_pf2D.xbin\n",
    "long_pf2D.ybin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befc3d1d",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "occupancy = deepcopy(long_pf2D.occupancy) # occupancy.shape # (60, 15)\n",
    "xbin = deepcopy(long_pf2D.xbin)\n",
    "ybin = deepcopy(long_pf2D.ybin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0416d4",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from scipy import ndimage # used for `compute_placefield_center_of_masses`\n",
    "from neuropy.utils.mixins.peak_location_representing import compute_occupancy_center_of_mass_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6352663",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "occupancy_x_center_dict = {k:compute_occupancy_center_of_mass_positions(v.pf.occupancy, xbin=v.pf.xbin, ybin=v.pf.ybin).item() for k, v in track_templates.get_decoders_dict().items()}\n",
    "occupancy_x_center_dict # {'long_LR': 162.99271603199625, 'long_RL': 112.79866056603696, 'short_LR': 138.45611791646, 'short_RL': 130.78889937230684}\n",
    "\n",
    "occupancy_mask_x_center_dict = {k:compute_occupancy_center_of_mass_positions(v.pf.visited_occupancy_mask, xbin=v.pf.xbin, ybin=v.pf.ybin).item() for k, v in track_templates.get_decoders_dict().items()}\n",
    "occupancy_mask_x_center_dict # {'long_LR': 135.66781520875904, 'long_RL': 130.0042755113645, 'short_LR': 133.77996864296085, 'short_RL': 143.21920147195175}\n",
    "\n",
    "\n",
    "# {k:compute_occupancy_center_of_mass_positions(v.pf.occupancy, xbin=v.pf.xbin, ybin=v.pf.ybin).item() for k, v in track_templates.get_decoders_dict().items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb029d8",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "occupancy = deepcopy(long_pf2D.occupancy) # occupancy.shape # (60, 15)\n",
    "xbin = deepcopy(long_pf2D.xbin)\n",
    "ybin = deepcopy(long_pf2D.ybin)\n",
    "\n",
    "# masked_nonzero_occupancy = deepcopy(long_pf2D.nan_never_visited_occupancy)\n",
    "\n",
    "masked_nonzero_occupancy = deepcopy(long_pf2D.visited_occupancy_mask)\n",
    "\n",
    "# occupancy_CoM_positions = compute_occupancy_center_of_mass_positions(occupancy, xbin=long_pf2D.xbin, ybin=long_pf2D.ybin)\n",
    "occupancy_CoM_positions = compute_occupancy_center_of_mass_positions(masked_nonzero_occupancy, xbin=long_pf2D.xbin, ybin=long_pf2D.ybin) # array([127.704, 145.63])\n",
    "occupancy_CoM_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097c3b06",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "long_pf2D.nan_never_visited_occupancy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4caa06",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_display_function_docs_dict# '_display_grid_bin_bounds_validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f963a7",
   "metadata": {
    "tags": [
     "all",
     "2025-01-23"
    ]
   },
   "outputs": [],
   "source": [
    "## Extracting on 2024-02-06 to display the LR/RL directions instead of the All/Long/Short pfs:\n",
    "def _display_directional_merged_pfs(owning_pipeline_reference, global_computation_results, computation_results, active_configs, include_includelist=None, save_figure=True, included_any_context_neuron_ids=None,\n",
    "                                    plot_all_directions=True, plot_long_directional=False, plot_short_directional=False, **kwargs):\n",
    "    \"\"\" Plots the merged pseduo-2D pfs/ratemaps. Plots: All-Directions, Long-Directional, Short-Directional in seperate windows. \n",
    "    \n",
    "    History: this is the Post 2022-10-22 display_all_pf_2D_pyqtgraph_binned_image_rendering-based method:\n",
    "    \"\"\"\n",
    "    from pyphoplacecellanalysis.Pho2D.PyQtPlots.plot_placefields import pyqtplot_plot_image_array, display_all_pf_2D_pyqtgraph_binned_image_rendering\n",
    "    from pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow \n",
    "    from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import LayoutScrollability\n",
    "\n",
    "    defer_render = kwargs.pop('defer_render', False)\n",
    "    directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "    active_merged_pf_plots_data_dict = {} #empty dict\n",
    "    \n",
    "    if plot_all_directions:\n",
    "        active_merged_pf_plots_data_dict[owning_pipeline_reference.build_display_context_for_session(track_config='All-Directions', display_fn_name='display_all_pf_2D_pyqtgraph_binned_image_rendering')] = directional_merged_decoders_result.all_directional_pf1D_Decoder.pf # all-directions\n",
    "    if plot_long_directional:\n",
    "        active_merged_pf_plots_data_dict[owning_pipeline_reference.build_display_context_for_session(track_config='Long-Directional', display_fn_name='display_all_pf_2D_pyqtgraph_binned_image_rendering')] = directional_merged_decoders_result.long_directional_pf1D_Decoder.pf # Long-only\n",
    "    if plot_short_directional:\n",
    "        active_merged_pf_plots_data_dict[owning_pipeline_reference.build_display_context_for_session(track_config='Short-Directional', display_fn_name='display_all_pf_2D_pyqtgraph_binned_image_rendering')] = directional_merged_decoders_result.short_directional_pf1D_Decoder.pf # Short-only\n",
    "\n",
    "    out_plots_dict = {}\n",
    "    \n",
    "    for active_context, active_pf_2D in active_merged_pf_plots_data_dict.items():\n",
    "        # figure_format_config = {} # empty dict for config\n",
    "        neuron_values = deepcopy(active_pf_2D.peak_tuning_curve_center_of_mass_bin_coordinates)\n",
    "        sort_indices = np.lexsort((neuron_values[:, 1], neuron_values[:, 0]))\n",
    "        figure_format_config = {'scrollability_mode': LayoutScrollability.NON_SCROLLABLE, 'included_unit_indicies': sort_indices} # kwargs # kwargs as default figure_format_config\n",
    "        out_all_pf_2D_pyqtgraph_binned_image_fig: BasicBinnedImageRenderingWindow  = display_all_pf_2D_pyqtgraph_binned_image_rendering(active_pf_2D, figure_format_config) # output is BasicBinnedImageRenderingWindow\n",
    "    \n",
    "        # Set the window title from the context\n",
    "        out_all_pf_2D_pyqtgraph_binned_image_fig.setWindowTitle(f'{active_context.get_description()}')\n",
    "        out_plots_dict[active_context] = out_all_pf_2D_pyqtgraph_binned_image_fig\n",
    "\n",
    "        # Tries to update the display of the item:\n",
    "        names_list = [v for v in list(out_all_pf_2D_pyqtgraph_binned_image_fig.plots.keys()) if v not in ('name', 'context')]\n",
    "        for a_name in names_list:\n",
    "            # Adjust the size of the text for the item by passing formatted text\n",
    "            a_plot: pg.PlotItem = out_all_pf_2D_pyqtgraph_binned_image_fig.plots[a_name].mainPlotItem # PlotItem \n",
    "            # no clue why 2 is a good value for this...\n",
    "            a_plot.titleLabel.setMaximumHeight(2)\n",
    "            a_plot.layout.setRowFixedHeight(0, 2)\n",
    "            a_plot.layout.setRowFixedHeight(1, 10)\n",
    "            plot_viewbox = a_plot.getViewBox()\n",
    "            # plot_viewbox.setMinimumHeight(200)  # Set a reasonable minimum height\n",
    "            plot_viewbox.setMaximumHeight(15)  # Set a fixed height to prevent stretching\n",
    "            plot_viewbox.setBorder(None)  # Remove the border\n",
    "            plot_viewbox.setBackgroundColor(None)\n",
    "                        \n",
    "            # # Add a spacer at the bottom\n",
    "            # spacer = pg.QtWidgets.QGraphicsWidget()\n",
    "            # spacer.setSizePolicy(pg.QtWidgets.QSizePolicy.Expanding, pg.QtWidgets.QSizePolicy.Expanding)  # Flexible spacer\n",
    "            # # Add the spacer to the layout\n",
    "            # row_count = a_plot.layout.rowCount()  # Get current row count\n",
    "            # a_plot.layout.addItem(spacer, row_count, 0, 1, a_plot.layout.columnCount())  # Add spacer to the last row\n",
    "            \n",
    "\n",
    "        if not defer_render:\n",
    "            out_all_pf_2D_pyqtgraph_binned_image_fig.show()\n",
    "\n",
    "    return out_plots_dict\n",
    "\n",
    "\n",
    "out_plots_dict = _display_directional_merged_pfs(curr_active_pipeline, curr_active_pipeline.global_computation_results, computation_results=None, active_configs=None, include_includelist=None, save_figure=True, included_any_context_neuron_ids=None,\n",
    "                                    plot_all_directions=True, plot_long_directional=False, plot_short_directional=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15824da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_all_pf_2D_pyqtgraph_binned_image_fig: BasicBinnedImageRenderingWindow = list(out_plots_dict.values())[0]\n",
    "# Tries to update the display of the item:\n",
    "names_list = [v for v in list(out_all_pf_2D_pyqtgraph_binned_image_fig.plots.keys()) if v not in ('name', 'context')]\n",
    "for a_name in names_list:\n",
    "    # Adjust the size of the text for the item by passing formatted text\n",
    "    a_plot: pg.PlotItem = out_all_pf_2D_pyqtgraph_binned_image_fig.plots[a_name].mainPlotItem # PlotItem \n",
    "    # no clue why 2 is a good value for this...\n",
    "    a_plot.titleLabel.setMaximumHeight(2)\n",
    "    a_plot.layout.setRowFixedHeight(0, 2)\n",
    "    a_plot.getViewBox().setBorder(None)  # Remove the border\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c38fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_plot.layoutDirection()\n",
    "a_plot.layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f36e973",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyphocorehelpers.gui.Qt.color_helpers import ColormapHelpers\n",
    "        \n",
    "ColormapHelpers.mpl_to_pg_colormap(color_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf715bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_pf2D = directional_merged_decoders_result.all_directional_pf1D_Decoder.pf # all-directions\n",
    "active_pf2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054feb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.shape()\n",
    "\n",
    "neuron_values = deepcopy(active_pf2D.peak_tuning_curve_center_of_mass_bin_coordinates)\n",
    "\n",
    "sort_indices = np.lexsort((neuron_values[:, 1], neuron_values[:, 0]))\n",
    "sort_indices\n",
    "\n",
    "neuron_values[sort_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfeb03c",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "# _out = curr_active_pipeline.display('_display_directional_merged_pfs', plot_all_directions=True, plot_long_directional=False, plot_short_directional=False)\n",
    "_out = curr_active_pipeline.display('_display_directional_merged_pf_decoded_epochs') # scrollable_figure=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb499f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_merged_pf_decoded_epochs_marginals') # scrollable_figure=True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cce23e",
   "metadata": {},
   "source": [
    "# <a id='toc21_'></a>[✅ `batch_user_completion_helpers` Batch Computation Testing](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ecbe84",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_2_'></a>[Call `export_rank_order_results_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22800b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import export_rank_order_results_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "# _across_session_results_extended_dict = {}\n",
    "\n",
    "# additional_session_context = None\n",
    "# try:\n",
    "#     if custom_suffix is not None:\n",
    "#         additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "#         print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "# except NameError as err:\n",
    "#     additional_session_context = None\n",
    "#     print(f'NO CUSTOM SUFFIX.')    \n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | export_rank_order_results_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                # # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None)\n",
    "                                                should_save_pkl=False, should_save_CSV=True,\n",
    "                                                )\n",
    "\n",
    "\n",
    "callback_outputs = _across_session_results_extended_dict['export_rank_order_results_completion_function']\n",
    "merged_complete_ripple_epoch_stats_df_output_path = callback_outputs['merged_complete_ripple_epoch_stats_df_output_path']\n",
    "minimum_inclusion_fr_Hz = callback_outputs['minimum_inclusion_fr_Hz']\n",
    "included_qclu_values = callback_outputs['included_qclu_values']\n",
    "print(f'merged_complete_ripple_epoch_stats_df_output_path: {merged_complete_ripple_epoch_stats_df_output_path}') # \"2024-11-15_Lab-2006-6-09_1-22-43_merged_complete_epoch_stats_df.csv\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34757ebd",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_3_'></a>[Call `compute_and_export_session_wcorr_shuffles_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf5cc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_session_wcorr_shuffles_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "# additional_session_context = None\n",
    "# try:\n",
    "#     if custom_suffix is not None:\n",
    "#         additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "#         print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "# except NameError as err:\n",
    "#     additional_session_context = None\n",
    "#     print(f'NO CUSTOM SUFFIX.')    \n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_session_wcorr_shuffles_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                # # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None)\n",
    "                                                )\n",
    "\n",
    "\n",
    "callback_outputs = _across_session_results_extended_dict['compute_and_export_session_wcorr_shuffles_completion_function']\n",
    "wcorr_shuffles_data_output_filepath = callback_outputs['wcorr_shuffles_data_output_filepath']\n",
    "standalone_MAT_filepath = callback_outputs['standalone_MAT_filepath']\n",
    "ripple_WCorrShuffle_df_export_CSV_path = callback_outputs['ripple_WCorrShuffle_df_export_CSV_path']\n",
    "print(f'wcorr_shuffles_data_output_filepath: {wcorr_shuffles_data_output_filepath}') # \"2024-11-15_Lab-2006-6-09_1-22-43_merged_complete_epoch_stats_df.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5693589d",
   "metadata": {},
   "source": [
    "### Call `compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fd5080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _subfn_compute_complete_df_metrics\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "try:\n",
    "    if _across_session_results_extended_dict is not None:\n",
    "        pass\n",
    "    else:\n",
    "        _across_session_results_extended_dict = {}\n",
    "except NameError as err:\n",
    "    _across_session_results_extended_dict = {}\n",
    "    \n",
    "additional_session_context = None\n",
    "try:\n",
    "    if custom_suffix is not None:\n",
    "        additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "        print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "except NameError as err:\n",
    "    additional_session_context = None\n",
    "    print(f'NO CUSTOM SUFFIX.')    \n",
    "\n",
    "# ripple_decoding_time_bin_size_override = 0.058\n",
    "ripple_decoding_time_bin_size_override = 0.025\n",
    "laps_decoding_time_bin_size_override = 0.025\n",
    "# ripple_decoding_time_bin_size_override = 0.050\n",
    "# laps_decoding_time_bin_size_override = 0.050\n",
    "\n",
    "needs_recompute_heuristics = True\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                ripple_decoding_time_bin_size_override=ripple_decoding_time_bin_size_override,\n",
    "                                                laps_decoding_time_bin_size_override=laps_decoding_time_bin_size_override,\n",
    "                                                needs_recompute_heuristics=needs_recompute_heuristics, allow_append_to_session_h5_file=False, save_hdf=True, force_recompute_all_decoding=True, \n",
    "                                                )\n",
    "\n",
    "callback_outputs = _across_session_results_extended_dict['compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function']\n",
    "ripple_decoding_time_bin_size_override = callback_outputs['ripple_decoding_time_bin_size_override']\n",
    "print(f'ripple_decoding_time_bin_size_override: {ripple_decoding_time_bin_size_override}')\n",
    "output_csv_paths = callback_outputs['output_csv_paths']\n",
    "print(f'output_csv_paths: {output_csv_paths}')\n",
    "output_hdf_paths = callback_outputs['output_hdf_paths']\n",
    "print(f'output_hdf_paths: {output_hdf_paths}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c82f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benedict import benedict\n",
    "\n",
    "_across_session_results_extended_dict = benedict(_across_session_results_extended_dict)\n",
    "out_ripple_all_scores_merged_df_csv = Path(_across_session_results_extended_dict['compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function.output_csv_paths.ripple_all_scores_merged_df']).resolve()\n",
    "Assert.path_exists(out_ripple_all_scores_merged_df_csv)\n",
    "\n",
    "out_ripple_all_scores_merged_df_csv.parent\n",
    "'C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2025-03-08_Apogee-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 8, 9]-frateThresh_5.0-(ripple_all_scores_merged_df)_tbin-0.025.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286f1cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_across_session_results_extended_dict['compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8daa277",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_ripple_all_scores_merged_hdf5_files = [Path(v).resolve() for v in _across_session_results_extended_dict['compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function.output_hdf_paths']]\n",
    "Assert.path_exists(out_ripple_all_scores_merged_hdf5_files[0])\n",
    "print(f'out_ripple_all_scores_merged_hdf5_files[0]: \"{out_ripple_all_scores_merged_hdf5_files[0].as_posix()}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101d7d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_path = '/home/halechr/FastData/collected_outputs/2024-11-22_Lab-kdiba_gor01_one_2006-6-12_15-55-31__withNormalComputedReplays-qclu_[1, 2]-frateThresh_5.0-(ripple_all_scores_merged_df)_tbin-0.025.csv'\n",
    "csv_path = '/home/halechr/FastData/collected_outputs/2024-11-22_Lab-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0-(ripple_all_scores_merged_df)_tbin-0.016.csv'\n",
    "test_df = pd.read_csv(csv_path)\n",
    "test_df\n",
    "\n",
    "\n",
    "test_df[np.logical_not(test_df['short_best_jump'].isnull())]['short_best_jump']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121efeb3",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_5_'></a>[Call `perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5732d32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _subfn_compute_complete_df_metrics\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "return_full_decoding_results: bool = True\n",
    "save_hdf: bool = False\n",
    "save_csvs:bool = False\n",
    "# _across_session_results_extended_dict = {}\n",
    "\n",
    "try:\n",
    "    if _across_session_results_extended_dict is not None:\n",
    "        pass\n",
    "    else:\n",
    "        _across_session_results_extended_dict = {}\n",
    "except NameError as err:\n",
    "    _across_session_results_extended_dict = {}\n",
    "    \n",
    "additional_session_context = None\n",
    "try:\n",
    "    if custom_suffix is not None:\n",
    "        additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "        print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "except NameError as err:\n",
    "    additional_session_context = None\n",
    "    print(f'NO CUSTOM SUFFIX.')\n",
    "\n",
    "# %pdb on\n",
    "## Combine the output of `perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function` into two dataframes for the laps, one per-epoch and one per-time-bin\n",
    "# desired_shared_decoding_time_bin_sizes = np.linspace(start=0.030, stop=0.5, num=10)\n",
    "# desired_shared_decoding_time_bin_sizes = np.linspace(start=0.005, stop=0.03, num=10)\n",
    "# _across_session_results_extended_dict = _across_session_results_extended_dict | perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function(a_dummy, None,\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\tcurr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\tacross_session_results_extended_dict=_across_session_results_extended_dict, save_hdf=save_hdf, return_full_decoding_results=return_full_decoding_results,\n",
    "#                                                 desired_shared_decoding_time_bin_sizes=desired_shared_decoding_time_bin_sizes,\n",
    "#                                                 )\n",
    "\n",
    "# desired_laps_decoding_time_bin_size = [None] # doesn't work\n",
    "# desired_laps_decoding_time_bin_size = [1.5] # large so it doesn't take long\n",
    "# desired_ripple_decoding_time_bin_size = [0.010, 0.020]\n",
    "# desired_ripple_decoding_time_bin_size = [0.010, 0.020, 0.025]\n",
    "\n",
    "# desired_shared_decoding_time_bin_sizes = np.array([0.025, 0.030, 0.044, 0.050, 0.058, 0.072, 0.086, 0.100])\n",
    "# desired_shared_decoding_time_bin_sizes = np.array([0.025, 0.030, 0.044, 0.050, 0.058,])\n",
    "# desired_shared_decoding_time_bin_sizes = np.array([0.010, 0.025, 0.058,])\n",
    "desired_shared_decoding_time_bin_sizes = np.array([0.025, 0.050,])\n",
    "# desired_shared_decoding_time_bin_sizes = np.array([0.058,])\n",
    "# custom_all_param_sweep_options, param_sweep_option_n_values = parameter_sweeps(desired_laps_decoding_time_bin_size=desired_laps_decoding_time_bin_size,\n",
    "#                                                                                 desired_ripple_decoding_time_bin_size=desired_ripple_decoding_time_bin_size,\n",
    "#                                                                         use_single_time_bin_per_epoch=[False],\n",
    "#                                                                         minimum_event_duration=[desired_ripple_decoding_time_bin_size[-1]])\n",
    "\n",
    "# Shared time bin sizes\n",
    "custom_all_param_sweep_options, param_sweep_option_n_values = parameter_sweeps(desired_shared_decoding_time_bin_size=desired_shared_decoding_time_bin_sizes, use_single_time_bin_per_epoch=[False], minimum_event_duration=[desired_shared_decoding_time_bin_sizes[-1]]) # with Ripples\n",
    "\n",
    "\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict, save_hdf=save_hdf, save_csvs=save_csvs, return_full_decoding_results=return_full_decoding_results,\n",
    "                                                # desired_shared_decoding_time_bin_sizes = np.linspace(start=0.030, stop=0.5, num=4),\n",
    "                                                custom_all_param_sweep_options=custom_all_param_sweep_options, # directly provide the parameter sweeps\n",
    "                                                # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None)\n",
    "                                                additional_session_context = None,\n",
    "                                                )\n",
    "\n",
    "\n",
    "if return_full_decoding_results:\n",
    "    # with `return_full_decoding_results == True`\n",
    "    out_path, output_laps_decoding_accuracy_results_df, output_extracted_result_tuples, combined_multi_timebin_outputs_tuple, output_full_directional_merged_decoders_result, output_directional_decoders_epochs_decode_results_dict, output_saved_individual_sweep_files_dict = _across_session_results_extended_dict['perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function']\n",
    "    # validate the result:\n",
    "    {k:v.all_directional_laps_filter_epochs_decoder_result.decoding_time_bin_size for k,v in output_full_directional_merged_decoders_result.items()}\n",
    "    # assert np.all([np.isclose(dict(k)['desired_shared_decoding_time_bin_size'], v.all_directional_laps_filter_epochs_decoder_result.decoding_time_bin_size) for k,v in output_full_directional_merged_decoders_result.items()]), f\"the desired time_bin_size in the parameters should match the one used that will appear in the decoded result\"\n",
    "\n",
    "else:\n",
    "    # with `return_full_decoding_results == False`\n",
    "    out_path, output_laps_decoding_accuracy_results_df, output_extracted_result_tuples, combined_multi_timebin_outputs_tuple, output_saved_individual_sweep_files_dict = _across_session_results_extended_dict['perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function']\n",
    "    output_full_directional_merged_decoders_result = None\n",
    "\n",
    "\n",
    "(several_time_bin_sizes_laps_df, laps_out_path, several_time_bin_sizes_time_bin_laps_df, laps_time_bin_marginals_out_path), (several_time_bin_sizes_ripple_df, ripple_out_path, several_time_bin_sizes_time_bin_ripple_df, ripple_time_bin_marginals_out_path) = combined_multi_timebin_outputs_tuple\n",
    "\n",
    "#  exported files: {'laps_out_path': WindowsPath('K:/scratch/collected_outputs/2024-09-27-kdiba_gor01_two_2006-6-07_16-40-19_None-(laps_marginals_df).csv'), 'laps_time_bin_marginals_out_path': WindowsPath('K:/scratch/collected_outputs/2024-09-27-kdiba_gor01_two_2006-6-07_16-40-19_None-(laps_time_bin_marginals_df).csv'), 'ripple_out_path': WindowsPath('K:/scratch/collected_outputs/2024-09-27-kdiba_gor01_two_2006-6-07_16-40-19_None-(ripple_marginals_df).csv'), 'ripple_time_bin_marginals_out_path': WindowsPath('K:/scratch/collected_outputs/2024-09-27-kdiba_gor01_two_2006-6-07_16-40-19_None-(ripple_time_bin_marginals_df).csv')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fc9d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.get_all_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc64a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_saved_individual_sweep_files_dict\n",
    "# combined_multi_timebin_outputs_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcd8258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import DisplaySpecifyingIdentifyingContext, CollisionOutcome\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Computation import PipelineWithComputedPipelineStageMixin\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Computation import session_context_filename_formatting_fn\n",
    "from pyphocorehelpers.print_helpers import get_now_day_str, get_now_rounded_time_str\n",
    "\n",
    "curr_active_pipeline.session_name\n",
    "# complete_session_context, (curr_session_context,  additional_session_context) = curr_active_pipeline.get_complete_session_context(parts_separator='_')\n",
    "\n",
    "# complete_session_context.get_description(separator='|') # 'kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays_qclu_[1, 2, 4, 6, 7, 9]_frateThresh_5.0'\n",
    "# complete_session_context.get_specific_purpose_description(specific_purpose='filename_formatting') # 'kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays_qclu_[1, 2, 4, 6, 7, 9]_frateThresh_5.0'\n",
    "# curr_active_pipeline.get_complete_session_identifier_string(parts_separator='_', sub_parts_separator='|') # 'kdiba-gor01-one-2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0'\n",
    "curr_active_pipeline.get_complete_session_identifier_string(parts_separator='_', custom_parameter_keyvalue_parts_separator='-', session_identity_parts_separator='_')\n",
    "\n",
    "# \"kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_1.0\"\n",
    "\n",
    "out_path, out_filename, out_basename = curr_active_pipeline.build_complete_session_identifier_filename_string(output_date_str=None, data_identifier_str=\"(ripple_WCorrShuffle_df)\", parent_output_path=None, out_extension='.csv', extra_parts=None, ensure_no_duplicate_parts=False)\n",
    "out_filename # '2024-11-19_0148AM-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0-(ripple_WCorrShuffle_df).csv'\n",
    "# out_path, out_filename, out_basename = curr_active_pipeline.build_complete_session_identifier_filename_string(output_date_str=get_now_rounded_time_str(), data_identifier_str=\"(ripple_WCorrShuffle_df)\", parent_output_path=None, out_extension='.csv', extra_parts=None, ensure_no_duplicate_parts=False)\n",
    "# out_path, out_filename, out_basename = curr_active_pipeline.build_complete_session_identifier_filename_string(data_identifier_str=\"(ripple_WCorrShuffle_df)\", parent_output_path=None, out_extension='.csv', extra_parts=None, ensure_no_duplicate_parts=True)\n",
    "out_path, out_filename, out_basename = curr_active_pipeline.build_complete_session_identifier_filename_string(data_identifier_str=\"(ripple_WCorrShuffle_df)\", parent_output_path=None, out_extension='.csv', suffix_string='_tbin-0.025')\n",
    "out_filename  # '2024-11-19_0148AM-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0-(ripple_WCorrShuffle_df)_tbin-0.025.csv'\n",
    "\n",
    "# \"2024-11-18_1020PM-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_1.0-(ripple_WCorrShuffle_df)_tbin-0.025.csv\"\n",
    "# \"2024-11-19_0125AM-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0-(ripple_WCorrShuffle_df).csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8b1579",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_session_context.get_raw_identifying_context()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a21cabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_session_context\n",
    "\n",
    "# ['format_name', 'animal', 'exper_name', 'session_name']\n",
    "curr_session_context.get_description()\n",
    "curr_session_context.get_specific_purpose_description(specific_purpose='filename_formatting')\n",
    "\n",
    "curr_session_context.to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82ac92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_test_complete_session_context: DisplaySpecifyingIdentifyingContext = DisplaySpecifyingIdentifyingContext.init_from_context(a_context=curr_active_pipeline.get_session_context(), \n",
    "        specific_purpose_display_dict={'filename_formatting': session_context_filename_formatting_fn,},\n",
    "        #  display_dict={'epochs_source': lambda k, v: to_filename_conversion_dict[v],\n",
    "        #         'included_qclu_values': lambda k, v: f\"qclu_{v}\",\n",
    "        #         'minimum_inclusion_fr_Hz': lambda k, v: f\"frateThresh_{v:.1f}\",\n",
    "        # },\n",
    "    )\n",
    "_test_complete_session_context\n",
    "_test_complete_session_context.get_description()\n",
    "_test_complete_session_context.get_specific_purpose_description(specific_purpose='filename_formatting')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ef185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "additional_session_context.get_description()\n",
    "additional_session_context.get_specific_purpose_description(specific_purpose='filename_formatting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c4da3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _test_complete_session_context: DisplaySpecifyingIdentifyingContext = curr_session_context.adding_context(collision_prefix='_additional', strategy=CollisionOutcome.FAIL_IF_DIFFERENT, **additional_session_context.to_dict())\n",
    "_test_complete_session_context: DisplaySpecifyingIdentifyingContext = curr_session_context.adding_context(collision_prefix='_additional', strategy=CollisionOutcome.FAIL_IF_DIFFERENT, **additional_session_context.get_raw_identifying_context().to_dict())\n",
    "\n",
    "\n",
    "_test_complete_session_context\n",
    "_test_complete_session_context.get_description()\n",
    "_test_complete_session_context.get_specific_purpose_description(specific_purpose='filename_formatting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5026a5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.get_complete_session_identifier_string(parts_separator='_')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14a1e08",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_6_'></a>[Call `compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb60e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import DisplaySpecifyingIdentifyingContext, IdentifyingContext\n",
    "# from pyphoplacecellanalysis.General.Pipeline.Stages.Computation import PipelineWithComputedPipelineStageMixin\n",
    "\n",
    "complete_session_context, (session_context, additional_session_context) = curr_active_pipeline.get_complete_session_context()\n",
    "session_context\n",
    "additional_session_context\n",
    "complete_session_context\n",
    "\n",
    "\n",
    "session_context.get_description()\n",
    "additional_session_context.get_description()\n",
    "complete_session_context.get_description()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0d9a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_session_context.get_specific_purpose_description(specific_purpose='filename_formatting') # additional_session_context.get_specific_purpose_description(specific_purpose='filename_formatting')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76164cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_session_context.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e58214",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_session_context.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c303453",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_session_context.get_specific_purpose_description(specific_purpose='filename_formatting') # '-_withNormalComputedReplays-frateThresh_5.0-qclu_[1, 2, 4, 6, 7, 9]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9185d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_session_context.get_description() # 'kdiba_gor01_two_2006-6-12_16-53-46__withNormalComputedReplays_qclu_[1, 2, 4, 6, 7, 9]_frateThresh_5.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a789e08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_context = complete_session_context\n",
    "active_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc10c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "active_context.get_description()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497465d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "# return_full_decoding_results: bool = True\n",
    "# save_hdf: bool = True\n",
    "# save_csvs:bool = True\n",
    "\n",
    "try:\n",
    "    _across_session_results_extended_dict\n",
    "except NameError as e:\n",
    "    _across_session_results_extended_dict = {} # initialize\n",
    "\n",
    "additional_session_context = None\n",
    "try:\n",
    "    if custom_suffix is not None:\n",
    "        additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "        print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "except NameError as err:\n",
    "    additional_session_context = None\n",
    "    print(f'NO CUSTOM SUFFIX.')    \n",
    "    \n",
    "rank_order_results = curr_active_pipeline.global_computation_results.computed_data.get('RankOrder', None)\n",
    "if rank_order_results is not None:\n",
    "    minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "else:        \n",
    "    ## get from parameters:\n",
    "    minimum_inclusion_fr_Hz: float = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.included_qclu_values\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict, included_qclu_values=included_qclu_values, minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, drop_previous_result_and_compute_fresh=True, num_wcorr_shuffles=1024,\n",
    "                                                # # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None)\n",
    "                                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb49fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function' in _across_session_results_extended_dict\n",
    "compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_output = deepcopy(_across_session_results_extended_dict['compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function'])\n",
    "# compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_output\n",
    "callback_outputs = deepcopy(_across_session_results_extended_dict['compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function'])\n",
    "\n",
    "custom_suffix = callback_outputs['custom_suffix']\n",
    "replay_epoch_variations = callback_outputs['replay_epoch_variations']\n",
    "replay_epoch_outputs = callback_outputs['replay_epoch_outputs']\n",
    "\n",
    "replay_epoch_name = 'normal_computed'\n",
    "a_replay_epoch_variation: Epoch = replay_epoch_variations[replay_epoch_name]\n",
    "a_replay_epoch_outputs = replay_epoch_outputs[replay_epoch_name]\n",
    "\n",
    "## Unpack `a_replay_epoch_outputs`\n",
    "exported_evt_file_path = a_replay_epoch_outputs['exported_evt_file_path']\n",
    "did_change = a_replay_epoch_outputs['did_change']\n",
    "custom_save_filenames = a_replay_epoch_outputs['custom_save_filenames']\n",
    "custom_save_filepaths = a_replay_epoch_outputs['custom_save_filepaths']\n",
    "custom_suffix = a_replay_epoch_outputs['custom_suffix']\n",
    "wcorr_ripple_shuffle_all_df = a_replay_epoch_outputs['wcorr_ripple_shuffle_all_df']\n",
    "all_shuffles_only_best_decoder_wcorr_df = a_replay_epoch_outputs['all_shuffles_only_best_decoder_wcorr_df']\n",
    "standalone_pkl_filepath = a_replay_epoch_outputs['standalone_pkl_filepath']\n",
    "standalone_mat_filepath = a_replay_epoch_outputs['standalone_mat_filepath']\n",
    "active_context = a_replay_epoch_outputs['active_context']\n",
    "export_files_dict = a_replay_epoch_outputs['export_files_dict']\n",
    "# params_description_str = a_replay_epoch_outputs['params_description_str']\n",
    "# footer_annotation_text = a_replay_epoch_outputs['footer_annotation_text']\n",
    "# out_hist_fig_result = a_replay_epoch_outputs['out_hist_fig_result']\n",
    "\n",
    "\n",
    "custom_save_filenames\n",
    "custom_save_filepaths\n",
    "export_files_dict\n",
    "# print_keys_if_possible('callback_outputs', compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_output, max_depth=3)\n",
    "# a_replay_epoch_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d41b45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_strs = []\n",
    "for k, v in a_replay_epoch_outputs.items():\n",
    "    code_strs.append(f\"{k} = a_replay_epoch_outputs['{k}']\")\n",
    "\n",
    "print('\\n'.join(code_strs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6d6e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_output['export_files_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8beeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_epoch_outputs = deepcopy(compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_output['replay_epoch_outputs'])\n",
    "# replay_epoch_outputs\n",
    "\n",
    "normal_computed_replay_epoch_outputs = replay_epoch_outputs['normal_computed']\n",
    "normal_computed_replay_epoch_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a3bfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(replay_epoch_outputs.keys())\n",
    "\n",
    "export_files_dict = normal_computed_replay_epoch_outputs['export_files_dict']\n",
    "export_files_dict\n",
    "\n",
    "export_file_path_ripple_WCorrShuffle_df = export_files_dict['ripple_WCorrShuffle_df'] # 'W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-11-18_1020PM-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_1.0-(ripple_WCorrShuffle_df)_tbin-0.025.csv'\n",
    "export_file_path_ripple_WCorrShuffle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a46edd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_save_filepaths = normal_computed_replay_epoch_outputs['custom_save_filepaths'] ## these seem to be misnamed AND redundant\n",
    "custom_save_filepaths\n",
    "\n",
    "ripple_csv_out_path = custom_save_filepaths['ripple_csv_out_path'] # 'K:/scratch/collected_outputs/2024-11-18-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_1.0_withNormalComputedReplays-frateThresh_1.0-qclu_[1, 2, 4, 6, 7, 9]-(ripple_marginals_df).csv'\n",
    "ripple_csv_out_path\n",
    "\n",
    "ripple_csv_time_bin_marginals = custom_save_filepaths['ripple_csv_time_bin_marginals'] # 'K:/scratch/collected_outputs/2024-11-18-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_1.0_withNormalComputedReplays-frateThresh_1.0-qclu_[1, 2, 4, 6, 7, 9]-(ripple_time_bin_marginals_df).csv'\n",
    "ripple_csv_time_bin_marginals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3f496b",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_7_'></a>[Call `compute_and_export_session_trial_by_trial_performance_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be44b166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_session_trial_by_trial_performance_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "return_full_decoding_results: bool = True\n",
    "save_hdf: bool = True\n",
    "save_csvs:bool = True\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "additional_session_context = None\n",
    "try:\n",
    "    if custom_suffix is not None:\n",
    "        additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "        print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "except NameError as err:\n",
    "    additional_session_context = None\n",
    "    print(f'NO CUSTOM SUFFIX.')    \n",
    "    \n",
    "active_laps_decoding_time_bin_size: float = 0.025\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_session_trial_by_trial_performance_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict, active_laps_decoding_time_bin_size=active_laps_decoding_time_bin_size,\n",
    "                                                # # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None)\n",
    "                                                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e427751",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_outputs = _across_session_results_extended_dict['compute_and_export_session_trial_by_trial_performance_completion_function']\n",
    "a_trial_by_trial_result: TrialByTrialActivityResult = callback_outputs['a_trial_by_trial_result']\n",
    "subset_neuron_IDs_dict = callback_outputs['subset_neuron_IDs_dict']\n",
    "subset_decode_results_dict = callback_outputs['subset_decode_results_dict']\n",
    "subset_decode_results_track_id_correct_performance_dict = callback_outputs['subset_decode_results_track_id_correct_performance_dict']\n",
    "directional_active_lap_pf_results_dicts: Dict[types.DecoderName, TrialByTrialActivity] = a_trial_by_trial_result.directional_active_lap_pf_results_dicts\n",
    "_out_subset_decode_results_track_id_correct_performance_dict = callback_outputs['subset_decode_results_track_id_correct_performance_dict']\n",
    "_out_subset_decode_results_dict = callback_outputs['subset_decode_results_dict']\n",
    "neuron_group_split_stability_dfs_tuple = callback_outputs['neuron_group_split_stability_dfs_tuple']\n",
    "neuron_group_split_stability_aclus_tuple = callback_outputs['neuron_group_split_stability_aclus_tuple']\n",
    "\n",
    "appearing_stability_df, disappearing_stability_df, appearing_or_disappearing_stability_df, stable_both_stability_df, stable_neither_stability_df, stable_long_stability_df, stable_short_stability_df = neuron_group_split_stability_dfs_tuple\n",
    "appearing_aclus, disappearing_aclus, appearing_or_disappearing_aclus, stable_both_aclus, stable_neither_aclus, stable_long_aclus, stable_short_aclus = neuron_group_split_stability_aclus_tuple\n",
    "# (complete_decoded_context_correctness_tuple, laps_marginals_df, all_directional_pf1D_Decoder, all_test_epochs_df, test_all_directional_decoder_result, all_directional_laps_filter_epochs_decoder_result, _out_separate_decoder_results)  = _out_subset_decode_results_dict['any_decoder'] ## get the result for all cells\n",
    "# filtered_laps_time_bin_marginals_df: pd.DataFrame = callback_outputs['subset_decode_results_time_bin_marginals_df_dict']['filtered_laps_time_bin_marginals_df']\n",
    "# active_results: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy({k:v.decoder_result for k, v in _out_separate_decoder_results[0].items()})\n",
    "# active_results: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy({k:v for k, v in _out_separate_decoder_results[1].items()})\n",
    "# filtered_laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dcdbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_group_split_stability_dfs_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a95b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aTbyT:TrialByTrialActivity = a_trial_by_trial_result.directional_active_lap_pf_results_dicts['long_LR']\n",
    "aTbyT.C_trial_by_trial_correlation_matrix.shape # (40, 21, 21)\n",
    "aTbyT.z_scored_tuning_map_matrix.shape # (21, 40, 57) (n_epochs, n_neurons, n_pos_bins)\n",
    "\n",
    "(directional_viewer, directional_image_layer_dict, custom_direction_split_layers_dict) = aTbyT.plot_napari_trial_by_trial_correlation_matrix(directional_active_lap_pf_results_dicts=a_trial_by_trial_result.directional_active_lap_pf_results_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3305a31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a_trial_by_trial_result.any_decoder_neuron_IDs)\n",
    "a_trial_by_trial_result.any_decoder_neuron_IDs[37] # 58\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bbad28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directional_viewer.Config()\n",
    "directional_viewer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276588e6",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_8_'></a>[Call `compute_and_export_cell_first_spikes_characteristics_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a69538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_cell_first_spikes_characteristics_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "try:\n",
    "    _across_session_results_extended_dict\n",
    "except NameError as e:\n",
    "    _across_session_results_extended_dict = {} # initialize\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_cell_first_spikes_characteristics_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                # # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None)\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855bd06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import figures_plot_cell_first_spikes_characteristics_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "try:\n",
    "    _across_session_results_extended_dict\n",
    "except NameError as e:\n",
    "    _across_session_results_extended_dict = {} # initialize\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | figures_plot_cell_first_spikes_characteristics_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                # # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None),\n",
    "                                                later_appearing_cell_lap_start_id=4,\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4624b606",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_9_'></a>[Call `kdiba_session_post_fixup_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef1b68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyphoplacecellanalysis.General.type_aliases as types\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import PostHocPipelineFixup, kdiba_session_post_fixup_completion_function, SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "# additional_session_context = None\n",
    "# try:\n",
    "#     if custom_suffix is not None:\n",
    "#         additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "#         print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "# except NameError as err:\n",
    "#     additional_session_context = None\n",
    "#     print(f'NO CUSTOM SUFFIX.')    \n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | kdiba_session_post_fixup_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                force_recompute=False, is_dry_run=False,\n",
    "                                                )\n",
    "\n",
    "\n",
    "# callback_outputs = _across_session_results_extended_dict['kdiba_session_post_fixup_completion_function'] # 'PostHocPipelineFixup'\n",
    "# loaded_track_limits = callback_outputs['loaded_track_limits']\n",
    "# a_config_dict = callback_outputs['a_config_dict']\n",
    "# print(f'loaded_track_limits: {loaded_track_limits}') \n",
    "    \n",
    "\n",
    "#  'computation_results[\"maze_any\"]': False, 'filtered_sessions[\"maze1_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze1_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze1_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze1_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze2_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze2_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze2_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze2_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze1_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_even\"].config.pix2cm': False, 'filtered_sessions[\"maze1_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.grid_bin': True, 'filtered_sessions[\"maze1_even\"].config.track_start_t': True, 'filtered_sessions[\"maze1_even\"].config.track_end_t': True, 'filtered_sessions[\"maze2_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_even\"].config.pix2cm': False, 'filtered_sessions[\"maze2_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.grid_bin': True, 'filtered_sessions[\"maze2_even\"].config.track_start_t': True, 'filtered_sessions[\"maze2_even\"].config.track_end_t': True, 'filtered_sessions[\"maze_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze_even\"].config.pix2cm': False, 'filtered_sessions[\"maze_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.grid_bin': True, 'filtered_sessions[\"maze_even\"].config.track_start_t': True, 'filtered_sessions[\"maze_even\"].config.track_end_t': True, 'filtered_sessions[\"maze1_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_any\"].config.pix2cm': False, 'filtered_sessions[\"maze1_any\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.grid_bin': True, 'filtered_sessions[\"maze1_any\"].config.track_start_t': True, 'filtered_sessions[\"maze1_any\"].config.track_end_t': True, 'filtered_sessions[\"maze2_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_any\"].config.pix2cm': False, 'filtered_sessions[\"maze2_any\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.grid_bin': True, 'filtered_sessions[\"maze2_any\"].config.track_start_t': True, 'filtered_sessions[\"maze2_any\"].config.track_end_t': True, 'filtered_sessions[\"maze_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze_any\"].config.pix2cm': False, 'filtered_sessions[\"maze_any\"].config.real_unit_grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.real_cm_grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.grid_bin': True, 'filtered_sessions[\"maze_any\"].config.track_start_t': False, 'filtered_sessions[\"maze_any\"].config.track_end_t': False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdfd908",
   "metadata": {},
   "outputs": [],
   "source": [
    "_across_session_results_extended_dict\n",
    "\n",
    "# 'filtered_sessions[\"maze1_odd\"].loaded_track_limits': False,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.pix2cm': False,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.real_unit_grid_bin_bounds': True,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.real_cm_grid_bin_bounds': True,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.grid_bin_bounds': True,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.grid_bin': True,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.track_start_t': True,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.track_end_t': True,\n",
    "\n",
    "['real_unit_grid_bin_bounds', 'real_cm_grid_bin_bounds', 'grid_bin_bounds', 'grid_bin', 'track_start_t', 'track_end_t']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c43d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.filtered_sessions[\"maze1_odd\"].config.real_unit_grid_bin_bounds\n",
    "curr_active_pipeline.filtered_sessions[\"maze_even\"].config.grid_bin_bounds\n",
    "curr_active_pipeline.filtered_sessions[\"maze1_odd\"].config.grid_bin_bounds\n",
    "curr_active_pipeline.filtered_sessions[\"maze1_odd\"].config.loaded_track_limits\n",
    "curr_active_pipeline.filtered_sessions[\"maze1_odd\"].config.track_start_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650ee1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.filtered_sessions['maze1_even'].config.real_unit_grid_bin_bounds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a3bd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# extended_computations_include_includelist=['ratemap_peaks_prominence2d', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring',] # do only specified\n",
    "computation_functions_name_includelist = ['_perform_baseline_placefield_computation', '_perform_time_dependent_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_time_dependent_pf_sequential_surprise_computation_perform_two_step_position_decoding_computation']\n",
    " #['rank_order_shuffle_analysis', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'ratemap_peaks_prominence2d', ] # do only specified\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=computation_functions_name_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=False, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=True)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963bf33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_include_function_names # {'_perform_pf_find_ratemap_peaks_computation': False, '_perform_time_dependent_pf_sequential_surprise_computation_perform_two_step_position_decoding_computation': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3d93e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=computation_functions_name_includelist, computation_kwargs_list=None, enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b70e5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# curr_active_pipeline.perform_computations(computation_functions_name_includelist=computation_functions_name_includelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2bc08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# curr_active_pipeline.active_configs # Dict[types.FilterContextName, InteractivePlaceCellConfig]\n",
    "# curr_active_pipeline.computation_results # Dict[types.FilterContextName, ComputationResult]\n",
    "\n",
    "# curr_active_pipeline.computation_results['maze1_odd'].computation_config # DynamicContainer\n",
    "# curr_active_pipeline.computation_results['maze1_odd'].computation_config.pf_params # PlacefieldComputationParameters\n",
    "\n",
    "\n",
    "grid_bin_bounds = deepcopy(curr_active_pipeline.computation_results['maze1_odd'].computation_config.pf_params.grid_bin_bounds) # ((0.0, 287.7697841726619), (115.10791366906477, 172.66187050359713))\n",
    "\n",
    "grid_bin = deepcopy(curr_active_pipeline.computation_results['maze1_odd'].computation_config.pf_params.grid_bin) # (3.8054171165052444, 1.4477079927649104)\n",
    "\n",
    "grid_bin_bounds\n",
    "# long_any_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98c40c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'DirectionalDecodersEpochsEvaluations' via compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05538438",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1885e4bc",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_10_'></a>[Call `generalized_decode_epochs_dict_and_export_results_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a876004",
   "metadata": {
    "tags": [
     "run-2025-04-11_full-session_marginals",
     "run-group-transition-matricies"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext, DisplaySpecifyingIdentifyingContext, set_context_print_options\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "\n",
    "# Usage example:\n",
    "reset_printer = set_context_print_options(include_property_names=True)\n",
    "\n",
    "# Later to restore default behavior:\n",
    "# reset_printer()\n",
    "\n",
    "import pyphoplacecellanalysis.General.type_aliases as types\n",
    "from neuropy.utils.mixins.binning_helpers import BinningContainer, BinningInfo\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import generalized_decode_epochs_dict_and_export_results_completion_function, SimpleBatchComputationDummy\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult #, KnownNamedDecoderTrainedComputeEpochsType, KnownNamedDecodingEpochsType, MaskedTimeBinFillType, DataTimeGrain, GenericResultTupleIndexType\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "# epochs_decoding_time_bin_size: float = 0.050\n",
    "epochs_decoding_time_bin_size: float = 0.025\n",
    "## Settings:\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-generalized_decode_epochs_dict_and_export_results_completion_function.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | generalized_decode_epochs_dict_and_export_results_completion_function(a_dummy, None,\n",
    "                                                    curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                    across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                    force_recompute=True,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tepochs_decoding_time_bin_size=epochs_decoding_time_bin_size,\n",
    "                                                )\n",
    "\n",
    "callback_outputs = _across_session_results_extended_dict['generalized_decode_epochs_dict_and_export_results_completion_function'] # 'PostHocPipelineFixup'\n",
    "a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult = callback_outputs['a_new_fully_generic_result']\n",
    "csv_save_paths_dict: Dict[str, Path] = callback_outputs['csv_save_paths_dict']\n",
    "a_new_fully_generic_result\n",
    "\n",
    "# a_config_dict = callback_outputs['a_config_dict']\n",
    "# print(f'loaded_track_limits: {loaded_track_limits}') \n",
    "\n",
    "## OUTPUTS: a_new_fully_generic_result\n",
    " \n",
    "#  'computation_results[\"maze_any\"]': False, 'filtered_sessions[\"maze1_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze1_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze1_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze1_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze2_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze2_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze2_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze2_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze1_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_even\"].config.pix2cm': False, 'filtered_sessions[\"maze1_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.grid_bin': True, 'filtered_sessions[\"maze1_even\"].config.track_start_t': True, 'filtered_sessions[\"maze1_even\"].config.track_end_t': True, 'filtered_sessions[\"maze2_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_even\"].config.pix2cm': False, 'filtered_sessions[\"maze2_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.grid_bin': True, 'filtered_sessions[\"maze2_even\"].config.track_start_t': True, 'filtered_sessions[\"maze2_even\"].config.track_end_t': True, 'filtered_sessions[\"maze_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze_even\"].config.pix2cm': False, 'filtered_sessions[\"maze_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.grid_bin': True, 'filtered_sessions[\"maze_even\"].config.track_start_t': True, 'filtered_sessions[\"maze_even\"].config.track_end_t': True, 'filtered_sessions[\"maze1_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_any\"].config.pix2cm': False, 'filtered_sessions[\"maze1_any\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.grid_bin': True, 'filtered_sessions[\"maze1_any\"].config.track_start_t': True, 'filtered_sessions[\"maze1_any\"].config.track_end_t': True, 'filtered_sessions[\"maze2_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_any\"].config.pix2cm': False, 'filtered_sessions[\"maze2_any\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.grid_bin': True, 'filtered_sessions[\"maze2_any\"].config.track_start_t': True, 'filtered_sessions[\"maze2_any\"].config.track_end_t': True, 'filtered_sessions[\"maze_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze_any\"].config.pix2cm': False, 'filtered_sessions[\"maze_any\"].config.real_unit_grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.real_cm_grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.grid_bin': True, 'filtered_sessions[\"maze_any\"].config.track_start_t': False, 'filtered_sessions[\"maze_any\"].config.track_end_t': False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773b4b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_context = IdentifyingContext(pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='ignore', data_grain='per_time_bin')\n",
    "search_context = IdentifyingContext(pfND_ndim=2, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='ignore', data_grain='per_time_bin')\n",
    "a_ctxt, a_result, a_decoder, _ = a_new_fully_generic_result.get_results_matching_contexts(context_query=search_context, return_multiple_matches=False, debug_print=True)\n",
    "a_ctxt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4d37a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import DecodingResultND\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import ComputeGlobalEpochBase\n",
    "\n",
    "a_new_global_epoch_base_obj: ComputeGlobalEpochBase = ComputeGlobalEpochBase.init_from_pipeline(curr_active_pipeline=curr_active_pipeline)\n",
    "results1D, results2D = ComputeGlobalEpochBase.compute_all(curr_active_pipeline, single_global_epoch=a_new_global_epoch_base_obj.single_global_epoch_df,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   epochs_decoding_time_bin_size=0.025,\n",
    "                                                        #    frame_divide_bin_size=0.50,\n",
    "                                                           frame_divide_bin_size=10.00,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   compute_1D=False, compute_2D=True)\n",
    "results2D\n",
    "## 7.5m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1424139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BasePositionDecoder\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import SingleEpochDecodedResult\n",
    "\n",
    "## INPUTS: results2D\n",
    "global_pos_df: pd.DataFrame = deepcopy(results2D.pos_df) # computation_result.sess.position.to_dataframe()\n",
    "a_new_global2D_decoder: BasePositionDecoder = deepcopy(results2D.a_new_global2D_decoder)\n",
    "a_result2D: DecodedFilterEpochsResult = deepcopy(results2D.a_result2D)\n",
    "active_two_step_result, _OLD_two_step_decoder_result = BasePositionDecoder.perform_compute_two_step_decoder(active_decoder=a_new_global2D_decoder, active_one_step_result=a_result2D, pos_df=global_pos_df)\n",
    "# two_step_decoder_result\n",
    "active_two_step_result\n",
    "\n",
    "## OUTPUTS: active_two_step_result: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cfeed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_result2D: DecodedFilterEpochsResult = deepcopy(results2D.a_result2D)\n",
    "masked_a_result2D, _mask_index_tuple = a_result2D.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), min_num_spikes_per_bin_to_be_considered_active=5, min_num_unique_active_neurons_per_time_bin=1, masked_bin_fill_mode='ignore')\n",
    "# masked_a_result2D, _mask_index_tuple = a_result2D.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), min_num_spikes_per_bin_to_be_considered_active=5, min_num_unique_active_neurons_per_time_bin=1, masked_bin_fill_mode='nan_filled')\n",
    "# masked_a_result2D, _mask_index_tuple = a_result2D.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), min_num_spikes_per_bin_to_be_considered_active=5, min_num_unique_active_neurons_per_time_bin=1, masked_bin_fill_mode='last_valid')\n",
    "a_result2D = masked_a_result2D ## overwrite a_result2D\n",
    "## get 1D marginals to compare to 1D decoder:\n",
    "n_timebins, flat_time_bin_containers, timebins_p_x_given_n = a_result2D.flatten()\n",
    "flat_time_window_centers = np.hstack([v.centers for v in flat_time_bin_containers])\n",
    "timebins_marginal_x_p_x_given_n: NDArray = np.concatenate([a_marginal_x['p_x_given_n'] for a_marginal_x in masked_a_result2D.marginal_x_list], axis=-1) # (59, 83756) - (n_x_bins, n_flat_t_bins)\n",
    "assert np.shape(timebins_marginal_x_p_x_given_n)[-1] == n_timebins, f\"timebins_marginal_x_p_x_given_n.shape: {np.shape(timebins_marginal_x_p_x_given_n)}'s last dimension should equal n_timebins: {n_timebins}\"\n",
    "assert len(flat_time_window_centers) == n_timebins, f\"len(flat_time_window_centers): {len(flat_time_window_centers)} should equal n_timebins: {n_timebins}\"\n",
    "\n",
    "## OUTPUTS: flat_time_window_centers, timebins_marginal_x_p_x_given_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7863e0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import DockDisplayColors, CustomDockDisplayConfig\n",
    "\n",
    "## INPUTS: active_2d_plot\n",
    "\n",
    "## Do separately for the long/short epochs instead of using the global decoder built across all data:\n",
    "# masked_bin_fill_mode = 'ignore'\n",
    "masked_bin_fill_mode = 'nan_filled'\n",
    "# masked_bin_fill_mode = 'last_valid'\n",
    "_mask_kwargs = dict(min_num_spikes_per_bin_to_be_considered_active=2, min_num_unique_active_neurons_per_time_bin=1, masked_bin_fill_mode=masked_bin_fill_mode)\n",
    "\n",
    "for a_track_length in ['long', 'short']:\n",
    "    a_decoder: BasePositionDecoder = results2D.decoders[a_track_length]\n",
    "    a_result2D: DecodedFilterEpochsResult = deepcopy(results2D.continuous_results[a_track_length])\n",
    "    masked_a_result2D, _mask_index_tuple = a_result2D.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), **_mask_kwargs)\n",
    "    a_result2D = masked_a_result2D ## overwrite a_result2D\n",
    "    ## get 1D marginals to compare to 1D decoder:\n",
    "    n_timebins, flat_time_bin_containers, timebins_p_x_given_n = a_result2D.flatten()\n",
    "    flat_time_window_centers: NDArray = np.hstack([v.centers for v in flat_time_bin_containers])\n",
    "    timebins_marginal_x_p_x_given_n: NDArray = np.concatenate([a_marginal_x['p_x_given_n'] for a_marginal_x in masked_a_result2D.marginal_x_list], axis=-1) # (59, 83756) - (n_x_bins, n_flat_t_bins)\n",
    "    assert np.shape(timebins_marginal_x_p_x_given_n)[-1] == n_timebins, f\"timebins_marginal_x_p_x_given_n.shape: {np.shape(timebins_marginal_x_p_x_given_n)}'s last dimension should equal n_timebins: {n_timebins}\"\n",
    "    assert len(flat_time_window_centers) == n_timebins, f\"len(flat_time_window_centers): {len(flat_time_window_centers)} should equal n_timebins: {n_timebins}\"\n",
    "\n",
    "    ## OUTPUTS: flat_time_window_centers, timebins_marginal_x_p_x_given_n\n",
    "    ## INPUTS: flat_time_window_centers, timebins_marginal_x_p_x_given_n, a_new_global2D_decoder, global_pos_df\n",
    "    active_time_bin_size: float = a_result2D.decoding_time_bin_size\n",
    "    info_string: str = f'{active_time_bin_size:.3f}'\n",
    "    dock_group_sep_character: str = '_'\n",
    "    showCloseButton = True\n",
    "    _common_dock_config_kwargs = {'dock_group_names': [dock_group_sep_character.join([f'Result2D_MarginalX', info_string])], 'showCloseButton': showCloseButton, 'showTimelineSyncModeButton': True}\n",
    "\n",
    "    # dock_configs: Dict[str, CustomDockDisplayConfig] = {k:deepcopy(CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_global_dock_colors, **_common_dock_config_kwargs)) for k in unique_decoder_names}\n",
    "    # dock_configs: Dict[str, CustomDockDisplayConfig] = {k:deepcopy(CustomDockDisplayConfig(custom_get_colors_callback_fn=DockDisplayColors.get_random_dock_colors_for_key_fn(key=k), **_common_dock_config_kwargs)) for k in unique_decoder_names}\n",
    "    # pf1D_Decoder_dict = {k:deepcopy(v) for k, v in a_decoder.items() if k in unique_decoder_names}\n",
    "    # pf1D_Decoder_dict = {k:deepcopy(a_decoder) for k in unique_decoder_names} ## this is dumb, but it provides xlims!\n",
    "    # output_dict = active_2d_plot.add_docked_decoded_results_dict_tracks(name=f'LapsDecode', a_decoded_result_dict=a_pseudo2D_split_to_1D_continuous_results_dict, dock_configs=dock_configs,\n",
    "    #                                                                                             pf1D_Decoder_dict=pf1D_Decoder_dict,\n",
    "    #                                                                                             measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "    #                                                                                             extended_dock_title_info=info_string)\n",
    "\n",
    "\n",
    "    # # pf1D_Decoder_dict = {k:deepcopy(v) for k, v in a_decoder.items() if k in unique_decoder_names\n",
    "    key_name: str = f'Result2D_MarginalX[{a_track_length}]'\n",
    "    ## a_1D_continuous_decoded_result: SingleEpochDecodedResult\n",
    "    a_dock_config = CustomDockDisplayConfig(custom_get_colors_callback_fn=DockDisplayColors.get_random_dock_colors_for_key_fn(key=key_name), **_common_dock_config_kwargs)\n",
    "    # a_1D_decoder: BasePositionDecoder = pf1D_Decoder_dict[a_decoder_name]\n",
    "    # add_docked_decoded_posterior_track(name=name, time_window_centers=a_1D_decoded_result.time_bin_container.centers, a_1D_posterior=a_1D_decoded_result.p_x_given_n, xbin=xbin, measured_position_df=measured_position_df, **kwargs)\n",
    "    # _out_tuple = active_2d_plot.add_docked_decoded_posterior_track_from_result(name=f'{name}[{a_decoder_name}]', a_dock_config=a_dock_config, a_1D_decoded_result=a_1D_decoded_result,\n",
    "    #                                                                                         xbin = deepcopy(a_1D_decoder.xbin), measured_position_df=deepcopy(measured_position_df), **kwargs) # , should_defer_render=False\n",
    "\n",
    "    _out_tuple = active_2d_plot.add_docked_decoded_posterior_track(name=key_name, a_dock_config=a_dock_config, time_window_centers=flat_time_window_centers, a_1D_posterior=timebins_marginal_x_p_x_given_n,\n",
    "                                                                                            xbin = deepcopy(a_new_global2D_decoder.xbin), measured_position_df=deepcopy(global_pos_df)) # , should_defer_render=False\n",
    "    identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = _out_tuple\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59283a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import DockDisplayColors, CustomDockDisplayConfig\n",
    "\n",
    "## INPUTS: flat_time_window_centers, timebins_marginal_x_p_x_given_n, a_new_global2D_decoder, global_pos_df\n",
    "active_time_bin_size: float = a_result2D.decoding_time_bin_size\n",
    "info_string: str = f'{active_time_bin_size:.3f}'\n",
    "dock_group_sep_character: str = '_'\n",
    "showCloseButton = True\n",
    "_common_dock_config_kwargs = {'dock_group_names': [dock_group_sep_character.join([f'Result2D_MarginalX', info_string])], 'showCloseButton': showCloseButton, 'showTimelineSyncModeButton': True}\n",
    "\n",
    "# dock_configs: Dict[str, CustomDockDisplayConfig] = {k:deepcopy(CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_global_dock_colors, **_common_dock_config_kwargs)) for k in unique_decoder_names}\n",
    "# dock_configs: Dict[str, CustomDockDisplayConfig] = {k:deepcopy(CustomDockDisplayConfig(custom_get_colors_callback_fn=DockDisplayColors.get_random_dock_colors_for_key_fn(key=k), **_common_dock_config_kwargs)) for k in unique_decoder_names}\n",
    "# pf1D_Decoder_dict = {k:deepcopy(v) for k, v in a_decoder.items() if k in unique_decoder_names}\n",
    "# pf1D_Decoder_dict = {k:deepcopy(a_decoder) for k in unique_decoder_names} ## this is dumb, but it provides xlims!\n",
    "# output_dict = active_2d_plot.add_docked_decoded_results_dict_tracks(name=f'LapsDecode', a_decoded_result_dict=a_pseudo2D_split_to_1D_continuous_results_dict, dock_configs=dock_configs,\n",
    "#                                                                                             pf1D_Decoder_dict=pf1D_Decoder_dict,\n",
    "#                                                                                             measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "#                                                                                             extended_dock_title_info=info_string)\n",
    "\n",
    "\n",
    "# # pf1D_Decoder_dict = {k:deepcopy(v) for k, v in a_decoder.items() if k in unique_decoder_names\n",
    "key_name: str = f'Result2D_MarginalX[{a_track_length}]'\n",
    "## a_1D_continuous_decoded_result: SingleEpochDecodedResult\n",
    "a_dock_config = CustomDockDisplayConfig(custom_get_colors_callback_fn=DockDisplayColors.get_random_dock_colors_for_key_fn(key=key_name), **_common_dock_config_kwargs)\n",
    "# a_1D_decoder: BasePositionDecoder = pf1D_Decoder_dict[a_decoder_name]\n",
    "# add_docked_decoded_posterior_track(name=name, time_window_centers=a_1D_decoded_result.time_bin_container.centers, a_1D_posterior=a_1D_decoded_result.p_x_given_n, xbin=xbin, measured_position_df=measured_position_df, **kwargs)\n",
    "# _out_tuple = active_2d_plot.add_docked_decoded_posterior_track_from_result(name=f'{name}[{a_decoder_name}]', a_dock_config=a_dock_config, a_1D_decoded_result=a_1D_decoded_result,\n",
    "#                                                                                         xbin = deepcopy(a_1D_decoder.xbin), measured_position_df=deepcopy(measured_position_df), **kwargs) # , should_defer_render=False\n",
    "\n",
    "_out_tuple = active_2d_plot.add_docked_decoded_posterior_track(name=key_name, a_dock_config=a_dock_config, time_window_centers=flat_time_window_centers, a_1D_posterior=timebins_marginal_x_p_x_given_n,\n",
    "                                                                                        xbin = deepcopy(a_new_global2D_decoder.xbin), measured_position_df=deepcopy(global_pos_df)) # , should_defer_render=False\n",
    "\n",
    "\n",
    "identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = _out_tuple\n",
    "# ## Add `a_decoded_result` to the plots_data\n",
    "# widget.plots_data.a_decoded_result = a_1D_decoded_result\n",
    "# widget.plots_data.a_decoder = deepcopy(a_1D_decoder)\n",
    "# output_dict[a_decoder_name] = (identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem) ## add again\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a177899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_result2D.marginal_x_list\n",
    "(epochs_directional_marginals_tuple, epochs_track_identity_marginals_tuple, epochs_non_marginalized_decoder_marginals_tuple), epochs_marginals_df = a_result2D.compute_marginals(additional_transfer_column_names=['start','stop','label','duration','lap_id','lap_dir'])\n",
    "epochs_directional_marginals, epochs_directional_all_epoch_bins_marginal, epochs_most_likely_direction_from_decoder, epochs_is_most_likely_direction_LR_dir  = epochs_directional_marginals_tuple\n",
    "epochs_track_identity_marginals, epochs_track_identity_all_epoch_bins_marginal, epochs_most_likely_track_identity_from_decoder, epochs_is_most_likely_track_identity_Long = epochs_track_identity_marginals_tuple\n",
    "non_marginalized_decoder_marginals, non_marginalized_decoder_all_epoch_bins_marginal, most_likely_decoder_idxs, non_marginalized_decoder_all_epoch_bins_decoder_probs_df = epochs_non_marginalized_decoder_marginals_tuple\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0a80c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export to images output folder:\n",
    "from pyphocorehelpers.plotting.media_output_helpers import save_array_as_image, save_array_as_video\n",
    "\n",
    "# image, out_path = save_array_as_image(timebins_p_x_given_n, desired_height=512, desired_width=None, skip_img_normalization=True, out_path='')\n",
    "# image\n",
    "\n",
    "timebins_p_x_given_n_for_video = deepcopy(timebins_p_x_given_n) # timebins_p_x_given_n.shape: (59, 8, 83756) - (n_x_bins, n_y_bins, n_t_bins)\n",
    "timebins_p_x_given_n_for_video = timebins_p_x_given_n_for_video.transpose((2, 1, 0)) # (n_frames, n_height_bins, n_width_bins)\n",
    "video_out_path = save_array_as_video(array=timebins_p_x_given_n_for_video, video_filename='output/videos/2025-06-30_global2D_decoder.avi', isColor=False)\n",
    "print(f'video_out_path: {video_out_path}')\n",
    "reveal_in_system_file_manager(video_out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb9668",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timebins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9099e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_export_path = Path('data').resolve()\n",
    "\n",
    "an_export_basepath = parent_export_path.joinpath(f'{BATCH_DATE_TO_USE}_{epochs_decoding_time_bin_size}_results2D')\n",
    "out_PKL_export_path: Path = an_export_basepath.with_suffix('.pkl').resolve()\n",
    "out_HDF5_export_path: Path = an_export_basepath.with_suffix('.hdf').resolve()\n",
    "\n",
    "print(f'out_PKL_export_path: {out_PKL_export_path}')\n",
    "results2D.save(pkl_output_path=out_PKL_export_path)\n",
    "\n",
    "\n",
    "# print(f'out_HDF5_export_path: {out_HDF5_export_path}')\n",
    "# active_two_step_result: DecodedFilterEpochsResult = active_two_step_result\n",
    "# active_two_step_result.to_hdf(out_HDF5_export_path, key='active_two_step_result')\n",
    "# out_HDF5_export_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb72536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_export_path = Path('data').resolve()\n",
    "\n",
    "a_new_active_two_step_result_export_basepath = parent_export_path.joinpath(f'{BATCH_DATE_TO_USE}_{epochs_decoding_time_bin_size}_active_two_step_result')\n",
    "# a_new_fully_generic_result_HDF5_export_path: Path = a_new_fully_generic_result_export_basepath.with_suffix('.h5').resolve()\n",
    "# a_new_fully_generic_result.to_hdf(file_path=a_new_fully_generic_result_HDF5_export_path, key='a_new_fully_generic_result', debug_print=True, OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True) # , OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True\n",
    "\n",
    "# out_PKL_export_path: Path = a_new_active_two_step_result_export_basepath.with_suffix('.pkl').resolve()\n",
    "out_HDF5_export_path: Path = a_new_active_two_step_result_export_basepath.with_suffix('.hdf').resolve()\n",
    "\n",
    "# print(f'out_PKL_export_path: {out_PKL_export_path}')\n",
    "# a_new_fully_generic_result.save(pkl_output_path=out_PKL_export_path)\n",
    "\n",
    "print(f'out_HDF5_export_path: {out_HDF5_export_path}')\n",
    "active_two_step_result: DecodedFilterEpochsResult = active_two_step_result\n",
    "active_two_step_result.to_hdf(out_HDF5_export_path, key='active_two_step_result')\n",
    "out_HDF5_export_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45966b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_export_path = Path('data').resolve()\n",
    "\n",
    "a_new_fully_generic_result_export_basepath = parent_export_path.joinpath(f'{BATCH_DATE_TO_USE}_{epochs_decoding_time_bin_size}_a_new_fully_generic_result')\n",
    "# a_new_fully_generic_result_HDF5_export_path: Path = a_new_fully_generic_result_export_basepath.with_suffix('.h5').resolve()\n",
    "# a_new_fully_generic_result.to_hdf(file_path=a_new_fully_generic_result_HDF5_export_path, key='a_new_fully_generic_result', debug_print=True, OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True) # , OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True\n",
    "\n",
    "out_PKL_export_path: Path = a_new_fully_generic_result_export_basepath.with_suffix('.pkl').resolve()\n",
    "# out_HDF5_export_path: Path = a_new_fully_generic_result_export_basepath.with_suffix('.hdf').resolve()\n",
    "\n",
    "# print(f'out_PKL_export_path: {out_PKL_export_path}')\n",
    "a_new_fully_generic_result.save(pkl_output_path=out_PKL_export_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f924bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import LinearTrackInstance, _perform_plot_matplotlib_2D_tracks\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.mixins.decoder_plotting_mixins import DecodedTrajectoryMatplotlibPlotter\n",
    "from neuropy.utils.matplotlib_helpers import perform_update_title_subtitle\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.mixins.decoder_plotting_mixins import multi_DecodedTrajectoryMatplotlibPlotter_side_by_side\n",
    "\n",
    "n_axes: int = 10\n",
    "posterior_masking_value: float = 0.02 # for 2D\n",
    "a_decoded_traj_plotter, (fig, axs, decoded_epochs_pages) = multi_DecodedTrajectoryMatplotlibPlotter_side_by_side(a_result2D=results2D.a_result2D, a_new_global_decoder2D=results2D.a_new_global2D_decoder,\n",
    "                                                                                                                global_session=global_session, n_axes=n_axes, posterior_masking_value=posterior_masking_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f63c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_keys_if_possible('a_result2D', a_result2D, max_depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd837ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_keys_if_possible('a_result2D', a_result2D, max_depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c85d700",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_step_decoder_result['all_scaling_factors_k'] = Zhang_Two_Step.compute_scaling_factor_k(prev_one_step_bayesian_decoder.flat_p_x_given_n)\n",
    "_perform_two_step_position_decoding_computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bc6a92",
   "metadata": {
    "tags": [
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "# Save To pickle:\n",
    "## INPUTS: a_new_fully_generic_result\n",
    "# BATCH_DATE_TO_USE: str = f'2025-04-11_Apogee'\n",
    "# BATCH_DATE_TO_USE: str = f'2025-04-11_GL_{epochs_decoding_time_bin_size}'\n",
    "\n",
    "# parent_export_path = Path('/home/halechr/repos/Spike3D/data').resolve()\n",
    "parent_export_path = Path('data').resolve()\n",
    "\n",
    "a_new_fully_generic_result_export_basepath = parent_export_path.joinpath(f'{BATCH_DATE_TO_USE}_{epochs_decoding_time_bin_size}_a_new_fully_generic_result')\n",
    "# a_new_fully_generic_result_HDF5_export_path: Path = a_new_fully_generic_result_export_basepath.with_suffix('.h5').resolve()\n",
    "# a_new_fully_generic_result.to_hdf(file_path=a_new_fully_generic_result_HDF5_export_path, key='a_new_fully_generic_result', debug_print=True, OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True) # , OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True\n",
    "\n",
    "out_PKL_export_path: Path = a_new_fully_generic_result_export_basepath.with_suffix('.pkl').resolve()\n",
    "print(f'out_PKL_export_path: {out_PKL_export_path}')\n",
    "a_new_fully_generic_result.save(pkl_output_path=out_PKL_export_path)\n",
    "# \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca9a6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyphoplacecellanalysis.General.type_aliases as types\n",
    "from neuropy.utils.mixins.binning_helpers import BinningContainer, BinningInfo\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import generalized_decode_epochs_dict_and_export_results_completion_function, SimpleBatchComputationDummy\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult #, KnownNamedDecoderTrainedComputeEpochsType, KnownNamedDecodingEpochsType, MaskedTimeBinFillType, DataTimeGrain, GenericResultTupleIndexType\n",
    "\n",
    "## Load from previous pickle:\n",
    "# input_path = Path(f'/home/halechr/repos/Spike3D/data/2025-04-11_Apogee_a_new_fully_generic_result.pkl').resolve()\n",
    "input_path = Path(f'data/2025-04-11_Apogee_a_new_fully_generic_result.pkl').resolve()\n",
    "Assert.path_exists(input_path)\n",
    "a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult = GenericDecoderDictDecodedEpochsDictResult.from_file(pkl_path=input_path)\n",
    "a_new_fully_generic_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532ec01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.time_slicing import TimeColumnAliasesProtocol\n",
    "\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "epochs_decoding_time_bin_size = 0.025\n",
    "# epochs_decoding_time_bin_size = 0.050\n",
    "\n",
    "## ensure all optional fields are present before output:\n",
    "# Add the maze_id to the active_filter_epochs so we can see how properties change as a function of which track the replay event occured on:\n",
    "for k in list(a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict.keys()):\n",
    "    a_df = a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict[k]\n",
    "    ## note in per-epoch mode we use the start of the epoch (because for example laps are long and we want to see as soon as it starts) but for time bins we use the center time.\n",
    "    time_column_name: str = TimeColumnAliasesProtocol.find_first_extant_suitable_columns_name(a_df, col_connonical_name='t', required_columns_synonym_dict={\"t\":{'t_bin_center', 'lap_start_t', 'ripple_start_t', 'epoch_start_t'}}, should_raise_exception_on_fail=True)\n",
    "    assert time_column_name in a_df\n",
    "    a_df['delta_aligned_start_t'] = a_df[time_column_name] - t_delta ## subtract off t_delta\n",
    "    a_df = a_df.across_session_identity.add_session_df_columns(session_name=session_name, time_bin_size=epochs_decoding_time_bin_size, curr_session_t_delta=t_delta, time_col=time_column_name)\n",
    "    a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict[k] = a_df\n",
    "    # display(a_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64837420",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export to CSVs:\n",
    "csv_save_paths = {}\n",
    "active_export_parent_output_path = a_dummy.collected_outputs_path.resolve()\n",
    "# Assert.path_exists(parent_output_path)\n",
    "\n",
    "## INPUTS: collected_outputs_path\n",
    "decoding_time_bin_size: float = epochs_decoding_time_bin_size\n",
    "\n",
    "complete_session_context, (session_context, additional_session_context) = curr_active_pipeline.get_complete_session_context()\n",
    "active_context = complete_session_context ## This context isn't enough! Easiest to build using `curr_active_pipeline` directly.\n",
    "\n",
    "def _subfn_custom_export_df_to_csv(export_df: pd.DataFrame, data_identifier_str: str = f'(laps_marginals_df)', parent_output_path: Path=None):\n",
    "    \"\"\" captures CURR_BATCH_DATE_TO_USE, `curr_active_pipeline`\n",
    "    \"\"\"\n",
    "    output_date_str: str = get_now_rounded_time_str(rounded_minutes=10)\n",
    "    out_path, out_filename, out_basename = curr_active_pipeline.build_complete_session_identifier_filename_string(output_date_str=output_date_str, data_identifier_str=data_identifier_str, parent_output_path=parent_output_path, out_extension='.csv')\n",
    "    export_df.to_csv(out_path)\n",
    "    return out_path \n",
    "\n",
    "\n",
    "custom_export_df_to_csv_fn = _subfn_custom_export_df_to_csv\n",
    "\n",
    "\n",
    "# build_complete_session_identifier_filename_string\n",
    "\n",
    "\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "earliest_delta_aligned_t_start, t_delta, latest_delta_aligned_t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "# tbin_values_dict={'laps': decoding_time_bin_size, 'pbe': decoding_time_bin_size, 'non_pbe': decoding_time_bin_size, 'FAT': decoding_time_bin_size}\n",
    "\n",
    "# csv_save_paths_dict = GenericDecoderDictDecodedEpochsDictResult._perform_export_dfs_dict_to_csvs(extracted_dfs_dict=a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict,\n",
    "csv_save_paths_dict = a_new_fully_generic_result.export_csvs(\n",
    "                                        parent_output_path=active_export_parent_output_path.resolve(),\n",
    "                                        active_context=active_context, session_name=session_name, #curr_active_pipeline=curr_active_pipeline,\n",
    "                                        decoding_time_bin_size=decoding_time_bin_size,\n",
    "                                        curr_session_t_delta=t_delta, \n",
    "                                        custom_export_df_to_csv_fn=custom_export_df_to_csv_fn,\n",
    "                                        )\n",
    "\n",
    "print(f'csv_save_paths_dict: {csv_save_paths_dict}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1269a3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_new_fully_generic_result.get_matching_contexts(IdentifyingContext(), return_multiple_matches=True, ) ## this only returns 3 results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97171718",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get old results\n",
    "# decoder_laps_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict)\n",
    "# all_directional_ripple_filter_epochs_decoder_result: DecodedFilterEpochsResult = directional_merged_decoders_result.laps_all_epoch_bins_marginals_df\n",
    "# decoder_laps_filter_epochs_decoder_result_dict.compute_marginals()\n",
    "laps_all_epoch_bins_marginals_df = deepcopy(directional_merged_decoders_result.laps_all_epoch_bins_marginals_df)\n",
    "laps_all_epoch_bins_marginals_df\n",
    "\n",
    "\n",
    "# active_marginals=ripple_track_identity_marginals, columns=['P_LR', 'P_RL']\n",
    "# active_marginals=ripple_track_identity_marginals, columns=['P_Long', 'P_Short']\n",
    "# _build_multiple_per_time_bin_marginals(a_decoder_result=decoder_laps_filter_epochs_decoder_result_dict, active_marginals_tuple=(laps_directional_all_epoch_bins_marginal, laps_track_identity_all_epoch_bins_marginal), columns_tuple=(['P_LR', 'P_RL'], ['P_Long', 'P_Short']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d1bf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get new results\n",
    "best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_matching_contexts(context_query=IdentifyingContext(trained_compute_epochs='laps', time_bin_size=0.025, known_named_decoding_epochs_type='laps', decoder_identifier='pseudo2D', masked_time_bin_fill_type='ignore'), debug_print=True, return_multiple_matches=False)\n",
    "\n",
    "## Plot them against each other for comparison\n",
    "a_decoded_marginal_posterior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3de43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_result.decoding_time_bin_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7788f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_laps_filter_epochs_decoder_result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff79ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "\n",
    "curr_active_pipeline.reload_default_computation_functions()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552cdd7d",
   "metadata": {},
   "source": [
    "### Call `compute_and_export_session_extended_placefield_peak_information_completion_function`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f93d69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext, DisplaySpecifyingIdentifyingContext, set_context_print_options\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "\n",
    "# Usage example:\n",
    "reset_printer = set_context_print_options(include_property_names=True)\n",
    "\n",
    "# Later to restore default behavior:\n",
    "# reset_printer()\n",
    "\n",
    "import pyphoplacecellanalysis.General.type_aliases as types\n",
    "from neuropy.utils.mixins.binning_helpers import BinningContainer, BinningInfo\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_session_extended_placefield_peak_information_completion_function, SimpleBatchComputationDummy\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult #, KnownNamedDecoderTrainedComputeEpochsType, KnownNamedDecodingEpochsType, MaskedTimeBinFillType, DataTimeGrain, GenericResultTupleIndexType\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-compute_and_export_session_extended_placefield_peak_information_completion_function.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_session_extended_placefield_peak_information_completion_function(a_dummy, None,\n",
    "                                                    curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                    across_session_results_extended_dict=_across_session_results_extended_dict, save_csv=True, save_json=False\n",
    "                                                )\n",
    "\n",
    "callback_outputs = _across_session_results_extended_dict['compute_and_export_session_extended_placefield_peak_information_completion_function'] # 'PostHocPipelineFixup'\n",
    "csv_output_path: str = callback_outputs['csv_output_path']\n",
    "csv_output_path\n",
    "\n",
    "# a_config_dict = callback_outputs['a_config_dict']\n",
    "# print(f'loaded_track_limits: {loaded_track_limits}') \n",
    "\n",
    "## OUTPUTS: a_new_fully_generic_result\n",
    " \n",
    "#  'computation_results[\"maze_any\"]': False, 'filtered_sessions[\"maze1_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze1_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze1_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze1_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze2_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze2_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze2_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze2_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze1_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_even\"].config.pix2cm': False, 'filtered_sessions[\"maze1_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.grid_bin': True, 'filtered_sessions[\"maze1_even\"].config.track_start_t': True, 'filtered_sessions[\"maze1_even\"].config.track_end_t': True, 'filtered_sessions[\"maze2_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_even\"].config.pix2cm': False, 'filtered_sessions[\"maze2_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.grid_bin': True, 'filtered_sessions[\"maze2_even\"].config.track_start_t': True, 'filtered_sessions[\"maze2_even\"].config.track_end_t': True, 'filtered_sessions[\"maze_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze_even\"].config.pix2cm': False, 'filtered_sessions[\"maze_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.grid_bin': True, 'filtered_sessions[\"maze_even\"].config.track_start_t': True, 'filtered_sessions[\"maze_even\"].config.track_end_t': True, 'filtered_sessions[\"maze1_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_any\"].config.pix2cm': False, 'filtered_sessions[\"maze1_any\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.grid_bin': True, 'filtered_sessions[\"maze1_any\"].config.track_start_t': True, 'filtered_sessions[\"maze1_any\"].config.track_end_t': True, 'filtered_sessions[\"maze2_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_any\"].config.pix2cm': False, 'filtered_sessions[\"maze2_any\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.grid_bin': True, 'filtered_sessions[\"maze2_any\"].config.track_start_t': True, 'filtered_sessions[\"maze2_any\"].config.track_end_t': True, 'filtered_sessions[\"maze_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze_any\"].config.pix2cm': False, 'filtered_sessions[\"maze_any\"].config.real_unit_grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.real_cm_grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.grid_bin': True, 'filtered_sessions[\"maze_any\"].config.track_start_t': False, 'filtered_sessions[\"maze_any\"].config.track_end_t': False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd91f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save To pickle:\n",
    "## INPUTS: a_new_fully_generic_result\n",
    "# BATCH_DATE_TO_USE: str = f'2025-04-11_Apogee'\n",
    "# BATCH_DATE_TO_USE: str = f'2025-04-11_GL_{epochs_decoding_time_bin_size}'\n",
    "\n",
    "# parent_export_path = Path('/home/halechr/repos/Spike3D/data').resolve()\n",
    "parent_export_path = Path('data').resolve()\n",
    "\n",
    "a_new_fully_generic_result_export_basepath = parent_export_path.joinpath(f'{BATCH_DATE_TO_USE}_{epochs_decoding_time_bin_size}_a_new_fully_generic_result')\n",
    "# a_new_fully_generic_result_HDF5_export_path: Path = a_new_fully_generic_result_export_basepath.with_suffix('.h5').resolve()\n",
    "# a_new_fully_generic_result.to_hdf(file_path=a_new_fully_generic_result_HDF5_export_path, key='a_new_fully_generic_result', debug_print=True, OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True) # , OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True\n",
    "\n",
    "out_PKL_export_path: Path = a_new_fully_generic_result_export_basepath.with_suffix('.pkl').resolve()\n",
    "print(f'out_PKL_export_path: {out_PKL_export_path}')\n",
    "a_new_fully_generic_result.save(pkl_output_path=out_PKL_export_path)\n",
    "# \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d523ee",
   "metadata": {},
   "source": [
    "# 2025-06-05 - Theta Phase Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859549d4",
   "metadata": {
    "tags": [
     "2025-06-05_thetaphaseanalysis"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.TimeCurves.SpecificTimeCurves import PositionRenderTimeCurves, ConfigurableRenderTimeCurves, ThetaPhaseRenderTimeCurves\n",
    "\n",
    "\n",
    "def circular_diff(angles):\n",
    "    \"\"\"\n",
    "    Calculate circular difference for angular data.\n",
    "    Handles wrap-around at 2π.\n",
    "    \"\"\"\n",
    "    diff = np.diff(angles)\n",
    "    # Wrap differences to [-π, π]\n",
    "    diff = (diff + np.pi) % (2 * np.pi) - np.pi\n",
    "    return np.abs(diff)\n",
    "\n",
    "\n",
    "## firing statistics to bins instead of boolean masking by those meeting criteria\n",
    "spikes_df: pd.DataFrame = get_proper_global_spikes_df(curr_active_pipeline)\n",
    "spikes_df['accel'] = spikes_df['speed'].diff().abs() / spikes_df['t_rel_seconds'].diff()\n",
    "spikes_df['theta_phase_radians_per_sec'] = spikes_df['theta_phase_radians'].diff().abs() / spikes_df['t_rel_seconds'].diff()\n",
    "\n",
    "# Handle circular statistics for theta phase\n",
    "theta_phase_circular_diff = circular_diff(spikes_df['theta_phase_radians'].to_numpy())\n",
    "time_diff = spikes_df['t_rel_seconds'].diff().iloc[1:].to_numpy()  # Skip first NaN\n",
    "spikes_df['theta_phase_radians_per_sec'] = np.concatenate([[np.nan], theta_phase_circular_diff / time_diff])\n",
    "\n",
    "\n",
    "theta_phase_radians = spikes_df['theta_phase_radians'].to_numpy()\n",
    "spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41f9fe9",
   "metadata": {
    "tags": [
     "2025-05-27_theta-phase-added",
     "2025-06-05_thetaphaseanalysis"
    ]
   },
   "outputs": [],
   "source": [
    "# active_2d_plot.get_leaf_only_flat_dock_identifiers_list()\n",
    "a_time_sync_pyqtgraph_widget, root_graphics_layout_widget, plot_item, dDisplayItem = active_2d_plot.add_new_embedded_pyqtgraph_render_plot_widget(name='thetaPhase', dockSize=(1, 4), sync_mode=SynchronizedPlotMode.TO_WINDOW)\n",
    "theta_phase_line_actor = plot_item.plot(spikes_df['t_rel_seconds'].to_numpy(), spikes_df['theta_phase_radians'].to_numpy(), pen='#FFFFFF', symbolBrush='#FFFFFF', symbolPen='#FFFFFF', symbol='o', symbolSize=2, name=\"theta_phase\")\n",
    "# theta_phase_line_actor = plot_item.scatterPlot(spikes_df['t_rel_seconds'].to_nump+y(), spikes_df['theta_phase_radians'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb3fb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "spikes_df.plot.scatter(x='speed', y='theta_phase_radians', title='Speed v. Theta Phase')\n",
    "# .corrcoef(\n",
    "spikes_df[['speed','theta_phase_radians']].corr(method='pearson')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2407cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUITS: spikes_df\n",
    "spikes_df.plot.scatter(x='x', y='theta_phase_radians_per_sec', title='x (pos) v. Theta-freq (rad/sec)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf0dbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUITS: spikes_df\n",
    "spikes_df.plot.scatter(x='speed', y='theta_phase_radians_per_sec', title='Speed v. Theta-freq (rad/sec)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dd4756",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## INPUITS: spikes_df\n",
    "spikes_df.plot.scatter(x='accel', y='theta_phase_radians_per_sec', title='Accel v. Theta-freq (rad/sec)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ff4de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spikes_df[['x','theta_phase_radians']].corr(method='pearson')\n",
    "# spikes_df[['speed','theta_phase_radians']].corr(method='pearson')\n",
    "# spikes_df[['accel','theta_phase_radians']].corr(method='pearson')\n",
    "\n",
    "filtered_spikes_df = deepcopy(spikes_df)\n",
    "filtered_spikes_df = filtered_spikes_df.dropna(how='any', subset=['x', 'speed', 'accel', 'theta_phase_radians_per_sec']) \n",
    "filtered_spikes_df\n",
    "np.corrcoef(filtered_spikes_df['x'].dropna().to_numpy(), filtered_spikes_df['theta_phase_radians_per_sec'].to_numpy())[1, 0]\n",
    "np.corrcoef(filtered_spikes_df['speed'].dropna().to_numpy(), filtered_spikes_df['theta_phase_radians_per_sec'].to_numpy())[1, 0]\n",
    "np.corrcoef(filtered_spikes_df['accel'].dropna().to_numpy(), filtered_spikes_df['theta_phase_radians_per_sec'].to_numpy())[1, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4d6290",
   "metadata": {},
   "outputs": [],
   "source": [
    "x: -0.01011012051718423\n",
    "speed: 0.06179871169990722\n",
    "accel: 0.01011012051718423"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f1a8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.clear_all_3D_time_curves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062d587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.params.time_curves_datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0168c821",
   "metadata": {
    "tags": [
     "2025-06-05_thetaphaseanalysis"
    ]
   },
   "outputs": [],
   "source": [
    "_out = PositionRenderTimeCurves.add_render_time_curves(curr_sess=global_session, destination_plot=active_2d_plot)\n",
    "_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d5149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out.active_data_column_names\n",
    "_out.df\n",
    "_out._data_series_specs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcff71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.params.use_docked_pyqtgraph_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed012e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_docked_pyqtgraph_plots: bool = active_2d_plot.params.use_docked_pyqtgraph_plots\n",
    "use_docked_pyqtgraph_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f57ef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.ui.main_time_curves_view_widget # PlotItem \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed7fcaf",
   "metadata": {
    "tags": [
     "2025-06-05_thetaphaseanalysis"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c806e672",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9738b9d5",
   "metadata": {
    "tags": [
     "2025-06-05_thetaphaseanalysis"
    ]
   },
   "outputs": [],
   "source": [
    "a_widget.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e065c5",
   "metadata": {
    "tags": [
     "2025-06-05_thetaphaseanalysis"
    ]
   },
   "outputs": [],
   "source": [
    "spikes_df['t_rel_seconds'].to_numpy(), spikes_df['theta_phase_radians'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2aa502",
   "metadata": {
    "tags": [
     "2025-06-05_thetaphaseanalysis"
    ]
   },
   "outputs": [],
   "source": [
    "# 'theta_phase_radians'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1beeb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "# %aimport pyphoplacecellanalysis.Analysis.Decoder.context_dependent\n",
    "\n",
    "## Get a specific context to plot: \n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=2, decoder_identifier='long_LR', time_bin_size=0.025, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore')\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', time_bin_size=0.025, known_named_decoding_epochs_type='pbe') # , decoder_identifier='long_LR', masked_time_bin_fill_type='ignore', pfND_ndim=2\n",
    "\n",
    "best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, debug_print=True)\n",
    "print(f'best_matching_context: {best_matching_context}')\n",
    "# a_decoded_marginal_posterior_df\n",
    "## OUTPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder\n",
    "a_decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19730492",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "\n",
    "a_new_fully_generic_result = a_new_fully_generic_result.compute_continuous_fn(curr_active_pipeline=curr_active_pipeline, debug_print=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ba7dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(a_new_fully_generic_result.decoders.keys())\n",
    "\n",
    "\n",
    "search_context = IdentifyingContext(pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global') # , data_grain= 'per_time_bin -- not really relevant: ['masked_time_bin_fill_type', 'known_named_decoding_epochs_type', 'data_grain']\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=search_context, return_multiple_matches=True, debug_print=True)\n",
    "# a_context, a_result, a_decoder, _ = a_new_fully_generic_result.get_results_matching_contexts(context_query=search_context, return_multiple_matches=False, debug_print=True)\n",
    "# a_decoder\n",
    "flat_context_list\n",
    "# flat_decoder_context_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef17ee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get a specific context to plot:\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='long_LR', time_bin_size=0.025, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore')\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore') # , decoder_identifier='long_LR'\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, known_named_decoding_epochs_type='laps') # , masked_time_bin_fill_type='ignore', decoder_identifier='long_LR'\n",
    "\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', time_bin_size=0.025) # , known_named_decoding_epochs_type='laps'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "flat_context_list\n",
    "## OUTPUTS: flat_context_list: List[IdentifyingContext], flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict\n",
    "## OUTPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e64168",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', time_bin_size=0.025) # , known_named_decoding_epochs_type='laps'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "flat_context_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5977a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import build_single_plotly_marginal_scatter_and_hist_over_time\n",
    "\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "epochs_decoding_time_bin_size: float = 0.025\n",
    "\n",
    "#INPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder\n",
    "_flat_out_figs_dict = {}\n",
    "\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "flat_context_list\n",
    "\n",
    "for a_ctxt, a_decoded_marginal_posterior_df in flat_decoded_marginal_posterior_df_context_dict.items():\n",
    "    print(a_ctxt)\n",
    "    \n",
    "    # Add the maze_id to the active_filter_epochs so we can see how properties change as a function of which track the replay event occured on:\n",
    "    a_decoded_marginal_posterior_df = a_decoded_marginal_posterior_df.across_session_identity.add_session_df_columns(session_name=session_name, time_bin_size=epochs_decoding_time_bin_size, curr_session_t_delta=t_delta) # , time_col='t'\n",
    "        \n",
    "    a_fig, a_figure_context = build_single_plotly_marginal_scatter_and_hist_over_time(a_decoded_posterior_df=a_decoded_marginal_posterior_df, a_target_context=a_ctxt)\n",
    "    a_fig = a_fig.update_layout(height=300, margin=dict(t=20, b=0),  # Set top and bottom margins to 0\n",
    "                        )  # Set your desired height\n",
    "    _flat_out_figs_dict[a_figure_context] = a_fig\n",
    "\n",
    "    a_fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eac0c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _plot_plotly_stack_marginal_scatter_and_hist_over_time\n",
    "\n",
    "\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "epochs_decoding_time_bin_size: float = 0.025\n",
    "\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type='laps', data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "_flat_out_figs_dict = _plot_plotly_stack_marginal_scatter_and_hist_over_time(flat_decoded_marginal_posterior_df_context_dict=flat_decoded_marginal_posterior_df_context_dict, session_name=session_name, t_delta=t_delta, epochs_decoding_time_bin_size=epochs_decoding_time_bin_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307e4bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='non_pbe', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type='pbe', data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "_flat_out_figs_dict = _plot_plotly_stack_marginal_scatter_and_hist_over_time(flat_decoded_marginal_posterior_df_context_dict=flat_decoded_marginal_posterior_df_context_dict, session_name=session_name, t_delta=t_delta, epochs_decoding_time_bin_size=epochs_decoding_time_bin_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ff5846",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ensure all optional fields are present before output:\n",
    "# Add the maze_id to the active_filter_epochs so we can see how properties change as a function of which track the replay event occured on:\n",
    "for k in list(a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict.keys()):\n",
    "    a_df = a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict[k]\n",
    "    ## note in per-epoch mode we use the start of the epoch (because for example laps are long and we want to see as soon as it starts) but for time bins we use the center time.\n",
    "    time_column_name: str = TimeColumnAliasesProtocol.find_first_extant_suitable_columns_name(a_df, col_connonical_name='t', required_columns_synonym_dict={\"t\":{'t_bin_center', 'lap_start_t', 'ripple_start_t', 'epoch_start_t'}}, should_raise_exception_on_fail=True)\n",
    "    assert time_column_name in a_df\n",
    "    a_df['delta_aligned_start_t'] = a_df[time_column_name] - t_delta ## subtract off t_delta\n",
    "    a_df = a_df.across_session_identity.add_session_df_columns(session_name=session_name, time_bin_size=epochs_decoding_time_bin_size, curr_session_t_delta=t_delta, time_col=time_column_name)\n",
    "    a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict[k] = a_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4819748",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='non_pbe', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size= 0.025, data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps', known_named_decoding_epochs_type='pbe'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "_flat_out_figs_dict = _plot_plotly_stack_marginal_scatter_and_hist_over_time(flat_decoded_marginal_posterior_df_context_dict=flat_decoded_marginal_posterior_df_context_dict, session_name=session_name, t_delta=t_delta, epochs_decoding_time_bin_size=epochs_decoding_time_bin_size)\n",
    "# flat_decoded_marginal_posterior_df_context_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61b7ea0",
   "metadata": {},
   "source": [
    "#### 🟢🟢⚓🟢🟢 Add to SpikeRaster2D as tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fd2c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot = spike_raster_window.spike_raster_plt_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1b9486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=0.025, masked_time_bin_fill_type='last_valid', data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps'\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=0.025, masked_time_bin_fill_type='ignore', data_grain='per_time_bin', known_named_decoding_epochs_type= 'global') # , known_named_decoding_epochs_type='laps'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "# print(f'flat_context_list: {flat_context_list}')\n",
    "flat_decoded_marginal_posterior_df_context_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963dd30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, DockDisplayColors\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "\n",
    "\n",
    "# search_context = IdentifyingContext(pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global') # , data_grain= 'per_time_bin -- not really relevant: ['masked_time_bin_fill_type', 'known_named_decoding_epochs_type', 'data_grain']\n",
    "# flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=search_context, return_multiple_matches=True, debug_print=True)\n",
    "# # a_context, a_result, a_decoder, _ = a_new_fully_generic_result.get_results_matching_contexts(context_query=search_context, return_multiple_matches=False, debug_print=True)\n",
    "# # a_decoder\n",
    "# flat_context_list\n",
    "# flat_decoder_context_dict\n",
    "\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=0.025, masked_time_bin_fill_type='ignore', data_grain='per_time_bin', known_named_decoding_epochs_type= 'global') # , known_named_decoding_epochs_type='laps'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "# print(f'flat_context_list: {flat_context_list}')\n",
    "flat_decoded_marginal_posterior_df_context_dict\n",
    "\n",
    "unique_decoder_names_map: Dict = {'laps': ['long_LR', 'long_RL', 'short_LR', 'short_RL'], 'non_pbe': ['long', 'short']}\n",
    "\n",
    "\n",
    "for a_ctxt, a_result in flat_result_context_dict.items():\n",
    "    ## INPUTS: laps_pseudo2D_continuous_specific_decoded_result: DecodedFilterEpochsResult\n",
    "    a_decoder = flat_decoder_context_dict[a_ctxt]\n",
    "    \n",
    "    unique_decoder_names = unique_decoder_names_map[a_ctxt.get('trained_compute_epochs', None)] # ['long', 'short']\n",
    "    unique_decoder_names = [f\"{a_ctxt}[{k}]\" for k in unique_decoder_names]\n",
    "    \n",
    "    a_pseudo2D_split_to_1D_continuous_results_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = a_result.split_pseudo2D_result_to_1D_result(pseudo2D_decoder_names_list=unique_decoder_names)    \n",
    "    a_pseudo2D_split_to_1D_continuous_results_dict = {k:v for k, (_o, v) in zip(unique_decoder_names, a_pseudo2D_split_to_1D_continuous_results_dict.items())} ## change to the long unique indicies so they match the decoders\n",
    "    \n",
    "    # a_pseudo2D_split_to_1D_continuous_results_dict\n",
    "    \n",
    "    active_time_bin_size: float = a_result.decoding_time_bin_size\n",
    "    info_string: str = f'{active_time_bin_size:.3f}'\n",
    "    dock_group_sep_character: str = '_'\n",
    "    showCloseButton = True\n",
    "    _common_dock_config_kwargs = {'dock_group_names': [dock_group_sep_character.join([f'LapsDecode', info_string])], 'showCloseButton': showCloseButton, 'showTimelineSyncModeButton': True}\n",
    "\n",
    "    # dock_configs: Dict[str, CustomDockDisplayConfig] = {k:deepcopy(CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_global_dock_colors, **_common_dock_config_kwargs)) for k in unique_decoder_names}\n",
    "    dock_configs: Dict[str, CustomDockDisplayConfig] = {k:deepcopy(CustomDockDisplayConfig(custom_get_colors_callback_fn=DockDisplayColors.get_random_dock_colors_for_key_fn(key=k), **_common_dock_config_kwargs)) for k in unique_decoder_names}\n",
    "    \n",
    "    # flat_decoder_context_dict\n",
    "\n",
    "    # pf1D_Decoder_dict = {k:deepcopy(v) for k, v in a_decoder.items() if k in unique_decoder_names}\n",
    "\n",
    "    pf1D_Decoder_dict = {k:deepcopy(a_decoder) for k in unique_decoder_names} ## this is dumb, but it provides xlims!\n",
    "\n",
    "    output_dict = active_2d_plot.add_docked_decoded_results_dict_tracks(name=f'LapsDecode', a_decoded_result_dict=a_pseudo2D_split_to_1D_continuous_results_dict, dock_configs=dock_configs,\n",
    "                                                                                                pf1D_Decoder_dict=pf1D_Decoder_dict,\n",
    "                                                                                                measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "                                                                                                extended_dock_title_info=info_string)\n",
    "\n",
    "\n",
    "    # # pf1D_Decoder_dict = {k:deepcopy(v) for k, v in a_decoder.items() if k in unique_decoder_names}\n",
    "\n",
    "    # ## a_1D_continuous_decoded_result: SingleEpochDecodedResult\n",
    "    # a_dock_config = dock_configs[a_decoder_name]\n",
    "    # a_1D_decoder: BasePositionDecoder = pf1D_Decoder_dict[a_decoder_name]\n",
    "    # _out_tuple = self.add_docked_decoded_posterior_track_from_result(name=f'{name}[{a_decoder_name}]', a_dock_config=a_dock_config, a_1D_decoded_result=a_1D_decoded_result,\n",
    "    #                                                                                         xbin = deepcopy(a_1D_decoder.xbin), measured_position_df=deepcopy(measured_position_df), **kwargs) # , should_defer_render=False\n",
    "    # identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = _out_tuple\n",
    "    # ## Add `a_decoded_result` to the plots_data\n",
    "    # widget.plots_data.a_decoded_result = a_1D_decoded_result\n",
    "    # widget.plots_data.a_decoder = deepcopy(a_1D_decoder)\n",
    "    # output_dict[a_decoder_name] = (identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem) ## add again\n",
    "\n",
    "\n",
    "# output_dict = active_2d_plot.add_docked_decoded_results_dict_tracks(name=f'LapsDecode', a_decoded_result_dict=a_pseudo2D_split_to_1D_continuous_results_dict, dock_configs=dock_configs, pf1D_Decoder_dict=flat_decoder_context_dict,\n",
    "#                                                                                             measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "#                                                                                             extended_dock_title_info=info_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f0c8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dock_item.sigToggleTimelineSyncModeClicked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31e8981",
   "metadata": {},
   "outputs": [],
   "source": [
    "dock_item.sigToggleTimelineSyncModeClicked.disconnect(_conn)\n",
    "dock_item.sigToggleTimelineSyncModeClicked.disconnect_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bd65ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.sync_matplotlib_render_plot_widget(identifier_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfc623b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, DockDisplayColors\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import SynchronizedPlotMode\n",
    "\n",
    "# epochs_decoding_time_bin_size: float = 0.025\n",
    "epochs_decoding_time_bin_size: float = 0.050\n",
    "# # search_context = IdentifyingContext(pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type= 'nan_filled') # , data_grain= 'per_time_bin -- not really relevant: ['masked_time_bin_fill_type', 'known_named_decoding_epochs_type', 'data_grain']\n",
    "# search_context = IdentifyingContext(pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type= 'ignore')\n",
    "# flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=search_context, return_multiple_matches=True, debug_print=True)\n",
    "# # a_context, a_result, a_decoder, _ = a_new_fully_generic_result.get_results_matching_contexts(context_query=search_context, return_multiple_matches=False, debug_print=True)\n",
    "# # a_decoder\n",
    "# # flat_context_list\n",
    "# flat_decoded_marginal_posterior_df_context_dict\n",
    "\n",
    "for a_ctxt, a_df in flat_decoded_marginal_posterior_df_context_dict.items():\n",
    "    time_bin_size = epochs_decoding_time_bin_size\n",
    "    info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "    plot_row_identifier: str = a_ctxt.get_description(subset_includelist=['known_named_decoding_epochs_type', 'masked_time_bin_fill_type'], include_property_names=True, key_value_separator=':', separator='|', replace_separator_in_property_names='-')\n",
    "    a_time_window_centers = a_df['t_bin_center'].to_numpy() \n",
    "    a_1D_posterior = a_df[['P_Long', 'P_Short']].to_numpy().T\n",
    "\n",
    "    identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dock_item = active_2d_plot.add_docked_marginal_track(name=plot_row_identifier, time_window_centers=a_time_window_centers, a_1D_posterior=a_1D_posterior, extended_dock_title_info=info_string, sync_mode=SynchronizedPlotMode.TO_GLOBAL_DATA)\n",
    "    active_2d_plot.sync_matplotlib_render_plot_widget(identifier=identifier_name, sync_mode=SynchronizedPlotMode.TO_GLOBAL_DATA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdabf069",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.sync_matplotlib_render_plot_widget(identifier=identifier_name, sync_mode=SynchronizedPlotMode.TO_GLOBAL_DATA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa923b9e",
   "metadata": {},
   "source": [
    "### Figures via `figures_plot_generalized_decode_epochs_dict_and_export_results_completion_function`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b3284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.SpecificComputationValidation import DependencyGraph, SpecificComputationValidator, SpecificComputationResultsSpecification\n",
    "# from pyphoplacecellanalysis.General.Model.SpecificComputationValidation import plan_computation_execution\n",
    "\n",
    "# # _comp_specifiers_dict: Dict[str, SpecificComputationValidator] = curr_active_pipeline.get_merged_computation_function_validators()\n",
    "# # validators = deepcopy(_comp_specifiers_dict) # { ... }  # Your validators here\n",
    "# # print(validators)\n",
    "# # graph = DependencyGraph(validators)\n",
    "\n",
    "# # Get the execution plan for a specific computation\n",
    "# computation_plan = plan_computation_execution(curr_active_pipeline, ['directional_decoders_decode_continuous'], debug_print=True)\n",
    "\n",
    "# # Print the execution order\n",
    "# print(\"Functions to execute in order:\")\n",
    "# for i, func_name in enumerate(computation_plan['execution_order']):\n",
    "#     print(f\"{i+1}. {func_name}\")\n",
    "\n",
    "\n",
    "# owning_pipeline_reference.stage.resolve_and_execute_full_required_computation_plan(computation_functions_name_includelist=['directional_decoders_decode_continuous'],\n",
    "#                                         computation_kwargs_list=[{'time_bin_size': time_bin_size, 'should_disable_cache':False}], \n",
    "#                                         enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75be131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: computation_kwargs_list=[{'num_shuffles': 100, 'skip_laps': False, 'minimum_inclusion_fr_Hz':2.0, 'included_qclu_values':[1,2,4,5,6,7]}]\n",
    "computation_kwargs_list=[{'num_shuffles': 100, 'skip_laps': False, 'minimum_inclusion_fr_Hz':2.0, 'included_qclu_values':[1,2,4,5,6,7]}]\n",
    "\n",
    "\n",
    "## Resolve all required pre-req dependencies to execute this function:\n",
    "ordered_required_dependent_computation_fn_names: List[str] = DependencyGraph.resolve_computation_dependencies(curr_active_pipeline, ['directional_decoders_decode_continuous'])\n",
    "# ordered_computation_functions # ['_split_to_directional_laps', '_build_merged_directional_placefields', '_decode_continuous_using_directional_decoders']\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=ordered_required_dependent_computation_fn_names, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=False, force_recompute_override_computations_includelist=[], debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "\n",
    "## OUTPUTS: needs_computation_output_dict\n",
    "if len(remaining_include_function_names) > 0:\n",
    "\tprint(f'have {len(remaining_include_function_names)} functions to compute: {remaining_include_function_names}')\n",
    "\tcurr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=remaining_include_function_names, computation_kwargs_list=computation_kwargs_list, enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "else:\n",
    "\tprint(f'not computations required, have all required keys!')\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6625e5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "active_computation_functions = self.find_registered_computation_functions(computation_functions_name_includelist, search_mode=FunctionsSearchMode.ANY) # find_registered_computation_functions is a pipeline.stage property\n",
    "contains_any_global_functions = np.any([v.is_global for v in active_computation_functions])\n",
    "## INPUTS: computation_kwargs_list=[{'num_shuffles': 100, 'skip_laps': False, 'minimum_inclusion_fr_Hz':2.0, 'included_qclu_values':[1,2,4,5,6,7]}]\n",
    "computation_kwargs_list=[{'num_shuffles': 100, 'skip_laps': False, 'minimum_inclusion_fr_Hz':2.0, 'included_qclu_values':[1,2,4,5,6,7]}]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09bc311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_computed_results_output_list\n",
    "remaining_include_function_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f70cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the execution order\n",
    "print(\"Functions to execute in order:\")\n",
    "for i, func_name in enumerate(computation_plan['execution_order']):\n",
    "    print(f\"{i+1}. {func_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365ee233",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# required_global_computation_results = ['EpochComputations', 'EpochComputations']\n",
    "\n",
    "\n",
    "## Does this not perform the required pre-req computations if they're missing? For example this function requires: `requires_global_keys=['DirectionalLaps', 'DirectionalMergedDecoders']`, so does it do those if they're missing, or not because they aren't in the computations list?\n",
    "owning_pipeline_reference.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'],\n",
    "                                        computation_kwargs_list=[{'time_bin_size': time_bin_size, 'should_disable_cache':False}], \n",
    "                                        enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048c713f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import figures_plot_generalized_decode_epochs_dict_and_export_results_completion_function, SimpleBatchComputationDummy\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult #, KnownNamedDecoderTrainedComputeEpochsType, KnownNamedDecodingEpochsType, MaskedTimeBinFillType, DataTimeGrain, GenericResultTupleIndexType\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "## Settings:\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-generalized_decode_epochs_dict_and_export_results_completion_function.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "\n",
    "complete_session_context, (session_context, additional_session_context) = curr_active_pipeline.get_complete_session_context()\n",
    "\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-figures_plot_generalized_decode_epochs_dict_and_export_results_completion_function.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | figures_plot_generalized_decode_epochs_dict_and_export_results_completion_function(a_dummy, None,\n",
    "                                                    # curr_session_context=curr_active_pipeline.get_session_context(),\n",
    "                                                    curr_session_context=complete_session_context,\n",
    "                                                    curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                    across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                    # extreme_threshold=0.5, opacity_max=0.7, thickness_ramping_multiplier=35,\n",
    "                                                    # extreme_threshold=0.8, opacity_max=0.7, thickness_ramping_multiplier=100,\n",
    "                                                    # extreme_threshold=0.5, included_figures_names=['_display_decoded_trackID_marginal_hairy_position'],\n",
    "                                                    included_figures_names=['_display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay'],\n",
    "                                                    # included_figures_names=['_display_generalized_decoded_yellow_blue_marginal_epochs', '_display_decoded_trackID_marginal_hairy_position', '_display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay'],\n",
    "                                                    # included_figures_names=['_display_directional_merged_pf_decoded_stacked_epoch_slices', '_display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay'],\n",
    "                                                )\n",
    "\n",
    "# _across_session_results_extended_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f011fdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.indexing_helpers import flatten_dict\n",
    "from benedict import benedict\n",
    "\n",
    "## INPUTS: out_custom_formats_dict\n",
    "\n",
    "# _flattened_paths_dict = {} ## Outputs:\n",
    "\n",
    "_out_dict = _across_session_results_extended_dict.get('figures_plot_generalized_decode_epochs_dict_and_export_results_completion_function', {}).get('_display_directional_merged_pf_decoded_stacked_epoch_slices', {}) \n",
    "out_custom_formats_dict = _out_dict['out_custom_formats_dict']\n",
    "## UPDATES: out_custom_formats_dict\n",
    "# out_custom_formats_dict.merge(_out_dict['out_custom_formats_dict'])\n",
    "# save_paths_dict.merge(_out_dict.get('out_paths', {}))\n",
    "\n",
    "export_paths = _out_dict['export_paths']\n",
    "save_paths_dict = benedict(_out_dict.get('export_paths', {}))\n",
    "parent_specific_session_output_folder = _out_dict['parent_specific_session_output_folder']\n",
    "\n",
    "# save_paths_dict = _out_dict.get('out_paths', {})\n",
    "# for epoch_name, a_variant_paths_dict in save_paths_dict.items():\n",
    "# \t## loop over all variants:\n",
    "#     for a_variant_name, a_path in a_variant_paths_dict.items():\n",
    "#         if a_path is not None:\n",
    "#             _curr_key = f\"{epoch_name}.{a_variant_name}\"\n",
    "#             _flattened_paths_dict[_curr_key] = a_path\n",
    "\n",
    "\n",
    "# _flattened_paths_dict\n",
    "\n",
    "# {'laps.psuedo2D_nan_filled': Path('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/array_to_images/2025-05-16/gor01_one_2006-6-08_14-26-15_trackID_weighted_position_posterior/laps/psuedo2D_nan_filled'),\n",
    "#  'ripple.psuedo2D_nan_filled': Path('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/array_to_images/2025-05-16/gor01_one_2006-6-08_14-26-15_trackID_weighted_position_posterior/ripple/psuedo2D_nan_filled')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d173192",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.image_helpers import ImageHelpers\n",
    "from pyphocorehelpers.plotting.media_output_helpers import vertical_image_stack, horizontal_image_stack, image_grid # used in `_subfn_build_combined_output_images`\n",
    "\n",
    "def build_horizontally_concatenated_images_from_export_folder(image_folder_path: Path, image_glob: str = \"*.png\", x_padding: int = 2, canvas_image_node_scale: float=None, max_num_to_add: int = 1000, combined_img_padding=4, combined_img_separator_color=None, debug_print = False):\n",
    "    \"\"\" Adds the images matching the glob in the `image_folder_path` to the canvas, or creates a new canvas, as needed\n",
    "    \n",
    "    Usage:\n",
    "    \n",
    "        img_export_folder = Path('K:/scratch/collected_outputs/figures/_temp_individual_posteriors/2025-06-03/gor01_two_2006-6-12_16-53-46/ripple/combined/multi').resolve()\n",
    "        Assert.path_exists(img_export_folder)\n",
    "        _img_path, _single_epoch_combined_img = build_horizontally_concatenated_images_from_export_folder(image_folder_path=img_export_folder, image_glob=\"p_x_given_n*.png\",\n",
    "                                                                                                        #    combined_img_padding=8, combined_img_separator_color='#1eff00',\n",
    "                                                                                                        combined_img_padding=8, combined_img_separator_color='#061304',\n",
    "                                                                                                        )\n",
    "        _img_path\n",
    "\n",
    "    \"\"\"\n",
    "    from pyphocorehelpers.image_helpers import ImageHelpers\n",
    "    from pyphocorehelpers.plotting.media_output_helpers import vertical_image_stack, horizontal_image_stack, image_grid # used in `_subfn_build_combined_output_images`\n",
    "    \n",
    "\n",
    "    def _subfn_get_img_obsidian_global_unique_name(an_img_path: Path) -> str:    \n",
    "        \"\"\" from my personal export path conventions, builds a globally unique image name (which has to be the case for a canvas)\"\"\"\n",
    "        \n",
    "        img_path_name_parts = an_img_path.parts\n",
    "        date_part_index = next((i for i, part in enumerate(img_path_name_parts) if re.match(r'^\\d{4}-\\d{2}-\\d{2}', part)), None)\n",
    "        session_part_index: int = date_part_index + 1\n",
    "        img_out_context_parts: List[str] = img_path_name_parts[session_part_index:] # ('gor01_two_2006-6-07_16-40-19_normal_computed_[1, 2]_5.0', 'ripple', 'psuedo2D_nan_filled', 'raw_rgba', 'p_x_given_n[9].png')\n",
    "        return '-'.join(img_out_context_parts) # 'gor01_two_2006-6-07_16-40-19_normal_computed_[1, 2]_5.0-ripple-psuedo2D_nan_filled-raw_rgba-p_x_given_n[9].png'\n",
    "\n",
    "\n",
    "    # ==================================================================================================================================================================================================================================================================================== #\n",
    "    # BEGIN FUNCTION BODY                                                                                                                                                                                                                                                                  #\n",
    "    # ==================================================================================================================================================================================================================================================================================== #\n",
    "    images_dict: Dict = ImageHelpers.load_png_images_pathlib(image_folder_path, image_glob=image_glob)\n",
    "    n_images: int = len(images_dict)\n",
    "    # Print the loaded images\n",
    "    print(f\"Loaded {len(images_dict)} PNG images from '{image_folder_path}'.\")\n",
    "\n",
    "    _output_combined_dir = image_folder_path # joinpath(joined_export_folder_name, custom_export_format_series_name).resolve()\n",
    "    # _output_combined_dir.mkdir(parents=True, exist_ok=True)\n",
    "    _output_combined_image_save_dirs = []\n",
    "\n",
    "    n_added: int = 0\n",
    "    \n",
    "    # text_node = TextNode(x=initial_x, y=initial_y, width=200, height=100, text=f\"#{image_group_name}\")\n",
    "    # target_canvas.add_node(text_node)\n",
    "    flat_image_list = []\n",
    "    if canvas_image_node_scale is None:\n",
    "        canvas_image_node_scale = 1.0\n",
    "        \n",
    "    image_sizes = np.vstack([(int(round(canvas_image_node_scale * float(an_img.size[0]))), int(round(canvas_image_node_scale * float(an_img.size[1])))) for i, (img_name, an_img) in enumerate(images_dict.items())]) # (n_images, 2)\n",
    "    # if debug_print:\n",
    "    #     print(f'image_sizes: {np.shape(image_sizes)}, max_img_sizes: {np.max(image_sizes, axis=0)}')\n",
    "\n",
    "    # total_grouped_image_size = np.sum(image_sizes, axis=0)\n",
    "    \n",
    "    if debug_print:\n",
    "        print(f'max_img_sizes: {np.max(image_sizes, axis=0)}')\n",
    "\n",
    "    total_grouped_image_size = (np.sum(image_sizes[:, 0], axis=0), np.max(image_sizes[:, 1], axis=0))  ## since being stacked horizontally, use the sum of the widths, but the max of the heights\n",
    "    total_grouped_images_padding = (int(round(float(x_padding)*float(n_images-1))), 0)\n",
    "\n",
    "    group_padding = np.array((50, 30))\n",
    "    total_group_size = total_grouped_image_size + np.array(total_grouped_images_padding) + (2 * group_padding)\n",
    "    # group_offset = np.array((initial_x, initial_y)) - group_padding\n",
    "        \n",
    "    a_found_filename: Optional[str] = None\n",
    "    for i, (img_name, an_img) in enumerate(images_dict.items()):\n",
    "        if i < max_num_to_add:\n",
    "            an_img_path: Path = image_folder_path.joinpath(f'{img_name}.png')\n",
    "            assert an_img_path.exists(), f\"an_img_path: {an_img_path} does not exist\"        \n",
    "            if a_found_filename is None:\n",
    "                a_found_filename = deepcopy(an_img_path.stem)\n",
    "            # global_unique_image_filename: str = f\"{_subfn_get_img_obsidian_global_unique_name(an_img_path=an_img_path)}\"\n",
    "            an_img_width, an_img_height = an_img.size            \n",
    "            if canvas_image_node_scale is not None:\n",
    "                an_img_width = int(round(canvas_image_node_scale * float(an_img_width)))\n",
    "                an_img_height = int(round(canvas_image_node_scale * float(an_img_height)))\n",
    "            # node_url_str: str = vault_relative_image_dir_filepath\n",
    "            # node_url_str: str = an_img_vault_filepath.relative_to(obsidian_vault_root_path).as_posix()\n",
    "            # file_node = FileNode(x=initial_x, y=initial_y, width=an_img_width, height=an_img_height, file=node_url_str)\n",
    "            # target_canvas.add_node(file_node)\n",
    "            flat_image_list.append(an_img)\n",
    "            # initial_x = initial_x + an_img_width + x_padding\n",
    "            n_added = n_added + 1\n",
    "            \n",
    "        else:\n",
    "            # print(f'skipping because max_num_to_add: {max_num_to_add}')\n",
    "            pass\n",
    "        \n",
    "    # END for i, (img_name, an_i...\n",
    "    print(f'added {n_added} images to canvas.')\n",
    "    \n",
    "    ## OUTPUT: flat_image_list\n",
    "    \n",
    "    _single_epoch_combined_img = horizontal_image_stack(flat_image_list, padding=combined_img_padding, separator_color=combined_img_separator_color)\n",
    "    _single_epoch_combined_img\n",
    "    \n",
    "    ## Save the image:\n",
    "    _img_path = _output_combined_dir.joinpath(f'merged_{a_found_filename}.png').resolve()\n",
    "    _single_epoch_combined_img.save(_img_path)\n",
    "    # _output_combined_image_save_dirs.append(_img_path)\n",
    "\n",
    "    return _img_path, _single_epoch_combined_img\n",
    "\n",
    "\n",
    "img_export_folder = Path('K:/scratch/collected_outputs/figures/_temp_individual_posteriors/2025-06-03/gor01_two_2006-6-12_16-53-46/ripple/combined/multi').resolve()\n",
    "Assert.path_exists(img_export_folder)\n",
    "_img_path, _single_epoch_combined_img = build_horizontally_concatenated_images_from_export_folder(image_folder_path=img_export_folder, image_glob=\"p_x_given_n*.png\",\n",
    "                                                                                                #    combined_img_padding=8, combined_img_separator_color='#1eff00',\n",
    "                                                                                                   combined_img_padding=8, combined_img_separator_color='#061304',\n",
    "                                                                                                   )\n",
    "_img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c86190",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# _flattened_paths_dict = {} ## Outputs:\n",
    "\n",
    "_out_dict = _across_session_results_extended_dict.get('figures_plot_generalized_decode_epochs_dict_and_export_results_completion_function', {}).get('_display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay', {}) # FigureCollector \n",
    "save_paths_dict = _out_dict.get('out_paths', {})\n",
    "out_custom_formats_dict = _out_dict['out_custom_formats_dict']\n",
    "\n",
    "# out_custom_formats_dict = benedict(_out_dict['out_custom_formats_dict'])\n",
    "parent_output_folder = _out_dict['parent_output_folder']\n",
    "_parent_save_context = _out_dict['parent_save_context']\n",
    "\n",
    "parent_output_folder\n",
    "_parent_save_context\n",
    "\n",
    "_specific_session_output_folder = _out_dict['parent_specific_session_output_folder']\n",
    "_specific_session_output_folder\n",
    "# {'laps.psuedo2D_nan_filled': Path('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/array_to_images/2025-05-16/gor01_one_2006-6-08_14-26-15_trackID_weighted_position_posterior/laps/psuedo2D_nan_filled'),\n",
    "#  'ripple.psuedo2D_nan_filled': Path('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/array_to_images/2025-05-16/gor01_one_2006-6-08_14-26-15_trackID_weighted_position_posterior/ripple/psuedo2D_nan_filled')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd430d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "\n",
    "out_custom_formats_dict = _out_dict.get('out_custom_formats_dict', None)\n",
    "if out_custom_formats_dict is not None:\n",
    "    _out_final_merged_image_save_paths, _out_final_merged_images = PosteriorExporting.post_export_build_combined_images(out_custom_formats_dict=out_custom_formats_dict)\n",
    "    _out_dict['final_merged_image_save_paths'] = deepcopy(_out_final_merged_image_save_paths)\n",
    "    # across_session_results_extended_dict['figures_plot_generalized_decode_epochs_dict_and_export_results_completion_function'].update({\n",
    "    #     '_display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay': _out,\n",
    "    # })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fda2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_dict['final_merged_image_save_paths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b417db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_custom_formats_dict = benedict(out_custom_formats_dict)\n",
    "\n",
    "save_paths_dict.keypaths()\n",
    "save_paths_dict.flatten(separator='|')\n",
    "# list(out_custom_formats_dict.keys())\n",
    "# out_custom_formats_dict.keypaths()\n",
    "# out_custom_formats_dict.merge()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cf4e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_custom_formats_dict['ripple'].keypaths()\n",
    "\n",
    "active_decoder_names = ['long_LR', 'long_RL', 'short_LR', 'short_RL', 'psuedo2D_ignore']\n",
    "out_custom_formats_dict['ripple.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70609d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.plotting.media_output_helpers import vertical_image_stack, horizontal_image_stack, image_grid\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "\n",
    "_out_final_merged_image_save_paths, _out_final_merged_images = PosteriorExporting.post_export_build_combined_images(out_custom_formats_dict=out_cusstom_formats_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e39fa1f",
   "metadata": {},
   "source": [
    "### Export to image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31ee8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.data_exporting import HeatmapExportConfig\n",
    "from benedict import benedict\n",
    "\n",
    "# Run an export function again _______________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________ #\n",
    "pseudo2D_split_to_1D_custom_export_formats: Dict[str, HeatmapExportConfig] = {\n",
    "    # 'greyscale_shared_norm': HeatmapExportConfig.init_greyscale(desired_height=desired_height, post_render_image_functions_builder_fn=ImagePostRenderFunctionSets._build_no_op_image_export_functions_dict),\n",
    "    'viridis_shared_norm': HeatmapExportConfig(colormap='viridis', vmin=0.0, vmax=1.0, export_kind=HeatmapExportKind.COLORMAPPED, desired_height=desired_height, post_render_image_functions_builder_fn=ImagePostRenderFunctionSets._build_no_op_image_export_functions_dict),\n",
    "}\n",
    "\n",
    "\n",
    "pseudo2D_split_to_1D_out_paths, pseudo2D_split_to_1D_out_custom_formats_dict = PosteriorExporting.perform_export_all_decoded_posteriors_as_images(decoder_laps_filter_epochs_decoder_result_dict=None,\n",
    "                                                                                                            decoder_ripple_filter_epochs_decoder_result_dict=a_pseudo2D_split_to_1D_continuous_results_dict, ## just the ripples\n",
    "                                                                                                        _save_context=_parent_save_context, parent_output_folder=_specific_session_output_folder,\n",
    "                                                                                                        desired_height=desired_height, custom_export_formats=pseudo2D_split_to_1D_custom_export_formats, combined_img_padding=6, combined_img_separator_color=(0, 0, 0, 0))\n",
    "if not isinstance(graphics_output_dict['out_paths'], benedict):\n",
    "    graphics_output_dict['out_paths'] = benedict(graphics_output_dict['out_paths']) # 'out_paths': out_paths\n",
    "# graphics_output_dict['out_paths'].merge(pseudo2D_split_to_1D_out_paths)\n",
    "graphics_output_dict['out_paths'].merge({k:v for k, v in pseudo2D_split_to_1D_out_paths.items() if (v is not None)})\n",
    "\n",
    "if not isinstance(graphics_output_dict['out_custom_formats_dict'], benedict):\n",
    "    graphics_output_dict['out_custom_formats_dict'] = benedict(graphics_output_dict['out_custom_formats_dict']) # 'out_paths': out_paths\n",
    "# graphics_output_dict['out_custom_formats_dict'].merge(pseudo2D_split_to_1D_out_custom_formats_dict)\n",
    "graphics_output_dict['out_custom_formats_dict'].merge({k:v for k, v in pseudo2D_split_to_1D_out_custom_formats_dict.items() if (v is not None)})\n",
    "\n",
    "# print(f'\\tout_paths: {pseudo2D_split_to_1D_out_paths}')\n",
    "print(f'done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b704eaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo2D_split_to_1D_out_paths = benedict(pseudo2D_split_to_1D_out_paths)\n",
    "pseudo2D_split_to_1D_out_custom_formats_dict = benedict(pseudo2D_split_to_1D_out_custom_formats_dict)\n",
    "# pseudo2D_split_to_1D_out_paths\n",
    "pseudo2D_split_to_1D_out_custom_formats_dict.keypaths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9767c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo2D_split_to_1D_out_custom_formats_dict['laps/long_LR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1e68a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo2D_split_to_1D_out_custom_formats_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbee9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.plotting.media_output_helpers import vertical_image_stack, horizontal_image_stack, image_grid\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "\n",
    "_out_final_merged_image_save_paths, _out_final_merged_images = PosteriorExporting.post_export_build_combined_images(pseudo2D_split_to_1D_out_custom_formats_dict)\n",
    "_out_final_merged_image_save_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f6be07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "an_active_img.reduce(factor=(4, 1)) ## scale image down by 1/4 in height but leave the original width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960a6580",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_posterior_saved_path\n",
    "merged_dir\n",
    "a_merged_posterior_export_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e86294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_final_merged_image_save_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b2a66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_final_merged_images[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837c717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_paths_dict.keypaths()\n",
    "save_paths_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22507ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_custom_formats_dict.keypaths()\n",
    "# out_custom_formats_dict.flatten()\n",
    "# out_custom_formats_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b414b333",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c014e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_paths = benedict(_out_dict['export_paths'])\n",
    "flat_export_paths = export_paths.flatten(separator='|')\n",
    "flat_export_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9f4712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d631bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_generalized_decoded_yellow_blue_marginal_epochs', curr_active_pipeline.get_session_context(), defer_render=True, save_figure=True, is_dark_mode=False) # , override_fig_man=custom_fig_man\n",
    "collector = _out['collector'] # FigureCollector \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62b582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "\n",
    "_out = curr_active_pipeline.display('_display_decoded_trackID_marginal_hairy_position', curr_active_pipeline.get_session_context(), defer_render=False, save_figure=False,\n",
    "\t\t\t\t\t\t\t\t\t#  extreme_threshold=0.5, \n",
    "                                    # opacity_max=0.7, thickness_ramping_multiplier=35,\n",
    "\t\t\t\t\t\t\t\t\textreme_threshold=0.8, opacity_max=0.7, thickness_ramping_multiplier=50,\n",
    "                                    #  prob_to_thickness_ramping_function= lambda p: max(0.0, (p - 0.5) * 15),\n",
    "                                    #  extreme_threshold=0.9, prob_to_thickness_ramping_function= lambda p: 6.0, ## constant for all probabilities\n",
    "\t\t\t\t\t\t\t\t\t#  extreme_threshold=0.1, prob_to_thickness_ramping_function= lambda p: (5.0 * p), \n",
    "\t\t\t\t\t\t\t\t\t#  ax = \n",
    "\t\t\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t\t\t ) # , override_fig_man=custom_fig_man\n",
    "collector = _out['collector'] # FigureCollector \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0a34b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed96530e",
   "metadata": {},
   "source": [
    "### Figures via `figures_plot_generalized_decode_epochs_dict_and_export_results_completion_function`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcece57",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_10_'></a>[Call `export_session_h5_file_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e847ed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyphoplacecellanalysis.General.type_aliases as types\n",
    "from neuropy.utils.mixins.binning_helpers import BinningContainer, BinningInfo\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import export_session_h5_file_completion_function, SimpleBatchComputationDummy\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult #, KnownNamedDecoderTrainedComputeEpochsType, KnownNamedDecodingEpochsType, MaskedTimeBinFillType, DataTimeGrain, GenericResultTupleIndexType\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | export_session_h5_file_completion_function(a_dummy, None,\n",
    "                                                    curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                    across_session_results_extended_dict=_across_session_results_extended_dict)\n",
    "\n",
    "callback_outputs = _across_session_results_extended_dict['export_session_h5_file_completion_function']\n",
    "hdf5_output_path: Dict[str, Path] = callback_outputs['hdf5_output_path']\n",
    "Assert.path_exists(hdf5_output_path)\n",
    "hdf5_output_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e2705a",
   "metadata": {},
   "source": [
    "# <a id='toc24_'></a>[2025-03-04 - Final Histogram](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7a94ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benedict import benedict\n",
    "filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict = benedict(a_general_decoder_dict_decoded_epochs_dict_result.filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict)\n",
    "filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict.keypaths() # ['laps', 'laps.ignore', 'laps.last_valid', 'laps.nan_filled', 'non_pbe', 'non_pbe.ignore', 'non_pbe.last_valid', 'non_pbe.nan_filled', 'pbe', 'pbe.ignore', 'pbe.last_valid', 'pbe.nan_filled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cb49e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "template: str = 'plotly_dark' # set plotl template\n",
    "pio.templates.default = template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed73ff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_export_path = Path(r'K:\\scratch\\output').resolve()\n",
    "non_pbe_marginals_PKL_export_path: Path = non_pbe_marginals_export_basepath.with_suffix('.pkl').resolve()\n",
    "a_general_decoder_dict_decoded_epochs_dict_result.save(pkl_output_path=non_pbe_marginals_PKL_export_path)\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26590c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_a_general_decoder_dict_decoded_epochs_dict_result: GeneralDecoderDictDecodedEpochsDictResult =  GeneralDecoderDictDecodedEpochsDictResult.from_file(pkl_path=non_pbe_marginals_PKL_export_path)\n",
    "loaded_a_general_decoder_dict_decoded_epochs_dict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fde2b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_pbe_marginals_export_basepath = parent_export_path.joinpath(f'{BATCH_DATE_TO_USE}_non_pbe_marginals_export')\n",
    "non_pbe_marginals_HDF5_export_path: Path = non_pbe_marginals_export_basepath.with_suffix('.h5').resolve()\n",
    "a_general_decoder_dict_decoded_epochs_dict_result.to_hdf(file_path=non_pbe_marginals_HDF5_export_path, key='a_general_decoder_dict_decoded_epochs_dict_result', debug_print=True) # , OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c933ae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: a_new_fully_generic_result\n",
    "BATCH_DATE_TO_USE: str = f'2025-04-11_Apogee'\n",
    "\n",
    "# parent_export_path = Path('/home/halechr/repos/Spike3D/data').resolve()\n",
    "parent_export_path = Path('data').resolve()\n",
    "\n",
    "a_new_fully_generic_result_export_basepath = parent_export_path.joinpath(f'{BATCH_DATE_TO_USE}_a_new_fully_generic_result')\n",
    "# a_new_fully_generic_result_HDF5_export_path: Path = a_new_fully_generic_result_export_basepath.with_suffix('.h5').resolve()\n",
    "# a_new_fully_generic_result.to_hdf(file_path=a_new_fully_generic_result_HDF5_export_path, key='a_new_fully_generic_result', debug_print=True, OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True) # , OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True\n",
    "\n",
    "out_PKL_export_path: Path = a_new_fully_generic_result_export_basepath.with_suffix('.pkl').resolve()\n",
    "print(f'out_PKL_export_path: {out_PKL_export_path}')\n",
    "a_new_fully_generic_result.save(pkl_output_path=out_PKL_export_path)\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a003258",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loaded_a_general_decoder_dict_decoded_epochs_dict_result: GeneralDecoderDictDecodedEpochsDictResult =  GeneralDecoderDictDecodedEpochsDictResult.from_file(pkl_path=out_PKL_export_path)\n",
    "loaded_a_general_decoder_dict_decoded_epochs_dict_result\n",
    "non_pbe_marginals_export_basepath = parent_export_path.joinpath(f'{BATCH_DATE_TO_USE}_non_pbe_marginals_export')\n",
    "non_pbe_marginals_HDF5_export_path: Path = non_pbe_marginals_export_basepath.with_suffix('.h5').resolve()\n",
    "a_general_decoder_dict_decoded_epochs_dict_result.to_hdf(file_path=non_pbe_marginals_HDF5_export_path, key='a_general_decoder_dict_decoded_epochs_dict_result', debug_print=True) # , OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02555045",
   "metadata": {},
   "outputs": [],
   "source": [
    "## OUTPUTS: flat_context_list: List[IdentifyingContext], flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict\n",
    "## OUTPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc27e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute and plot the new tracks:\n",
    "# non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict, non_PBE_marginal_over_track_ID, (time_bin_containers, time_window_centers) = nonPBE_results._build_merged_joint_placefields_and_decode(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)))\n",
    "unique_added_track_identifiers = nonPBE_results.add_to_SpikeRaster2D_tracks(active_2d_plot=active_2d_plot, non_PBE_all_directional_pf1D_Decoder=non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result=pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict=continuous_decoded_results_dict, non_PBE_marginal_over_track_ID=non_PBE_marginal_over_track_ID, time_window_centers=time_window_centers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8a218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.enable_interaction_events_debug_print = True\n",
    "spike_raster_window.enable_debug_print = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645e0aa6",
   "metadata": {
    "tags": [
     "active-2025-03-11"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import build_single_plotly_marginal_scatter_and_hist_over_time\n",
    "\n",
    "#INPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder\n",
    "_flat_out_figs_dict = {}\n",
    "a_fig, a_figure_context = build_single_plotly_marginal_scatter_and_hist_over_time(a_decoded_posterior_df=a_decoded_marginal_posterior_df, a_target_context=a_target_context)\n",
    "_flat_out_figs_dict[a_figure_context] = a_fig\n",
    "\n",
    "a_fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d39b4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoded_marginal_posterior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69dd71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = a_general_decoder_dict_decoded_epochs_dict_result.build_plotly_marginal_scatter_and_hist_over_time()\n",
    "\n",
    "# _flat_out_figs_dict = a_general_decoder_dict_decoded_epochs_dict_result.build_plotly_marginal_scatter_and_hist_over_time(debug_print=False)\n",
    "\n",
    "# display(list(_flat_out_figs_dict.values())[0])\n",
    "\n",
    "# Display all figures in the dictionary\n",
    "for fig in _flat_out_figs_dict.values():\n",
    "    display(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33e4ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_pre_post_delta_scatter\n",
    "## INPUTS: a_general_decoder_dict_decoded_epochs_dict_result\n",
    "\n",
    "histogram_bins: int = 25\n",
    "debug_print = False\n",
    "# 'masked_laps': 'Laps (Masked)', 'masked_laps': 'Laps (Nan-masked)')\n",
    "# masked_bin_fill_modes: ['ignore', 'last_valid', 'nan_filled', 'dropped']\n",
    "\n",
    "_flat_out_figs_dict = {}\n",
    "\n",
    "for a_known_decoded_epochs_type, a_decoded_posterior_dfs_dict in a_general_decoder_dict_decoded_epochs_dict_result.filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict.items():\n",
    "    if debug_print:\n",
    "        print(f'a_known_decoded_epochs_type: \"{a_known_decoded_epochs_type}\"')\n",
    "    for masking_bin_fill_mode, a_decoded_posterior_df in a_decoded_posterior_dfs_dict.items():\n",
    "        if debug_print:\n",
    "            print(f'\\tmasking_bin_fill_mode: \"{masking_bin_fill_mode}\"')\n",
    "        plot_row_identifier: str = f'{a_known_decoded_epochs_type.capitalize()} - {masking_bin_fill_mode.capitalize()} decoder' # should be like 'Laps (Masked) from Non-PBE decoder'\n",
    "        \n",
    "        fig, figure_context = plotly_pre_post_delta_scatter(data_results_df=deepcopy(a_decoded_posterior_df), out_scatter_fig=None, \n",
    "                                        histogram_variable_name='P_Short', hist_kwargs=dict(), histogram_bins=histogram_bins,\n",
    "                                        common_plot_kwargs=dict(),\n",
    "                                        px_scatter_kwargs = dict(x='delta_aligned_start_t', y='P_Short', title=plot_row_identifier))\n",
    "        _flat_out_figs_dict[figure_context] = fig\n",
    "        \n",
    "# ['laps', 'non_PBE']\n",
    "# ['a', 'masked', 'dropping_masked']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b1d063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(list(_flat_out_figs_dict.values())[0])\n",
    "\n",
    "# # Display all figures in the dictionary\n",
    "# for fig in _flat_out_figs_dict.values():\n",
    "#     display(fig)\n",
    "\n",
    "from pyphoplacecellanalysis.External.pyqtgraph.Qt import QtWidgets\n",
    "from pyphoplacecellanalysis.External.pyqtgraph.dockarea import DockArea, Dock\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.PlotlyFigurePyQtWidget import PlotlyDockContainer, PlotlyWidget\n",
    "\n",
    "## INPUTS: _flat_out_figs_dict\n",
    "# Create the container\n",
    "container: PlotlyDockContainer = PlotlyDockContainer()\n",
    "# Display all figures in the dictionary\n",
    "for a_fig_context, fig in _flat_out_figs_dict.items():\n",
    "    container.add_figure(fig, name=f\"{a_fig_context}\", position='bottom')\n",
    "\n",
    "# Show the container\n",
    "container.resize(1200, 800)\n",
    "container.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d06c39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bf036ef",
   "metadata": {},
   "source": [
    "### <a id='toc24_1_1_'></a>[Plotting Tracks on Spike2DRaster](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b821068",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Never used: all at once:\n",
    "a_dock_config = None\n",
    "_out_tuple = active_2d_plot.add_docked_decoded_posterior_track_from_result(name=f'laps_pseudo2D_continuous_specific_decoded_result', a_dock_config=a_dock_config, a_1D_decoded_result=laps_pseudo2D_continuous_specific_decoded_result,\n",
    "                                                                                xbin = deepcopy(non_PBE_all_directional_pf1D_Decoder.xbin), measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "                                                                                extended_dock_title_info='test')\n",
    "active_2d_plot.sync_matplotlib_render_plot_widget(identifier=identifier_name, sync_mode=SynchronizedPlotMode.TO_GLOBAL_DATA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb37b1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, DockDisplayColors\n",
    "\n",
    "active_time_bin_size: float = pseudo2D_continuous_specific_decoded_result.decoding_time_bin_size\n",
    "info_string: str = f'{active_time_bin_size:.3f}'\n",
    "dock_group_sep_character: str = '_'\n",
    "showCloseButton = True\n",
    "_common_dock_config_kwargs = {'dock_group_names': [dock_group_sep_character.join([f'LapsDecode', info_string])], 'showCloseButton': showCloseButton}\n",
    "dock_configs: Dict[str, CustomDockDisplayConfig] = dict(zip(unique_decoder_names,\n",
    "                        (CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_long_dock_colors, **_common_dock_config_kwargs),\n",
    "                        CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_short_dock_colors, **_common_dock_config_kwargs))))\n",
    "                        \n",
    "\n",
    "pf1D_Decoder_dict = {k:deepcopy(v) for k, v in results1D.decoders.items() if k in unique_decoder_names}\n",
    "\n",
    "output_dict = active_2d_plot.add_docked_decoded_results_dict_tracks(name=f'LapsDecode', a_decoded_result_dict=laps_pseudo2D_split_to_1D_continuous_results_dict, dock_configs=dock_configs, pf1D_Decoder_dict=pf1D_Decoder_dict,\n",
    "                                                                                            measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "                                                                                            extended_dock_title_info=info_string, dockSize=(10, 4))\n",
    "\n",
    "a_dock_config = CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_global_dock_colors, **_common_dock_config_kwargs)\n",
    "marginal_y_p_x_given_n_list = [deepcopy(v.p_x_given_n) for v in laps_pseudo2D_continuous_specific_decoded_result.marginal_y_list]\n",
    "_out_tuple = active_2d_plot.add_docked_decoded_posterior_slices_track(name=f'PBE_marginal_over_track_ID', a_dock_config=a_dock_config,\n",
    "                                                                                slices_time_window_centers=laps_pseudo2D_continuous_specific_decoded_result.time_window_centers, slices_posteriors=marginal_y_p_x_given_n_list,\n",
    "                                                                                xbin=None, xbin_labels=unique_decoder_names, measured_position_df=None, extended_dock_title_info=info_string, posterior_heatmap_imshow_kwargs=dict(), dockSize=(10, 1))\n",
    "output_dict['PBE_marginal_over_track_ID'] = _out_tuple\n",
    "# active_2d_plot.layout_dockGroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44547381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "\n",
    "## INPUTS: masked_laps_pseudo2D_split_to_1D_continuous_results_dict, masked_laps_pseudo2D_continuous_specific_decoded_result\n",
    "_common_dock_config_kwargs = {'dock_group_names': [dock_group_sep_character.join([f'MASKED_LapsDecode', info_string])], 'showCloseButton': showCloseButton}\n",
    "masked_dock_configs: Dict[str, CustomDockDisplayConfig] = dict(zip(unique_decoder_names,\n",
    "                        (CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_long_dock_colors, **_common_dock_config_kwargs),\n",
    "                        CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_short_dock_colors, **_common_dock_config_kwargs))))\n",
    "                        \n",
    "\n",
    "pf1D_Decoder_dict = {k:deepcopy(v) for k, v in results1D.decoders.items() if k in unique_decoder_names}\n",
    "\n",
    "MASKED_output_dict = active_2d_plot.add_docked_decoded_results_dict_tracks(name=f'MASKED_LapsDecode', a_decoded_result_dict=masked_laps_pseudo2D_split_to_1D_continuous_results_dict, dock_configs=masked_dock_configs, pf1D_Decoder_dict=pf1D_Decoder_dict,\n",
    "                                                                                            measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "                                                                                            extended_dock_title_info=info_string, dockSize=(10, 4))\n",
    "\n",
    "a_dock_config = CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_global_dock_colors, **_common_dock_config_kwargs)\n",
    "marginal_y_p_x_given_n_list = [deepcopy(v.p_x_given_n) for v in masked_laps_pseudo2D_continuous_specific_decoded_result.marginal_y_list]\n",
    "_masked_out_tuple = active_2d_plot.add_docked_decoded_posterior_slices_track(name=f'MASKED_PBE_marginal_over_track_ID', a_dock_config=a_dock_config,\n",
    "                                                                                slices_time_window_centers=masked_laps_pseudo2D_continuous_specific_decoded_result.time_window_centers, slices_posteriors=marginal_y_p_x_given_n_list,\n",
    "                                                                                xbin=None, xbin_labels=unique_decoder_names, measured_position_df=None, extended_dock_title_info=info_string, posterior_heatmap_imshow_kwargs=dict(), dockSize=(10, 1))\n",
    "MASKED_output_dict['MASKED_PBE_marginal_over_track_ID'] = _masked_out_tuple\n",
    "# active_2d_plot.layout_dockGroups()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7abd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flat_time_window_centers, flat_marginal_y_p_x_given_n = laps_pseudo2D_continuous_specific_decoded_result.get_pseudo2D_result_to_pseudo2D_marginalization_result(pseudo2D_decoder_names_list=unique_decoder_names) ## this is wrong\n",
    "time_bin_size = epochs_decoding_time_bin_size\n",
    "info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "# identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dock_item = active_2d_plot.add_docked_marginal_track(name='non-PBE_marginal_over_track_ID',\n",
    "#                                                                                         time_window_centers=flat_time_window_centers, a_1D_posterior=flat_marginal_y_p_x_given_n, extended_dock_title_info=info_string)\n",
    "\n",
    "marginal_y_p_x_given_n_list = [deepcopy(v.p_x_given_n) for v in laps_pseudo2D_continuous_specific_decoded_result.marginal_y_list]\n",
    "_out_tuple = active_2d_plot.add_docked_decoded_posterior_slices_track(name=f'PBE_marginal_over_track_ID', a_dock_config=None,\n",
    "                                                                                slices_time_window_centers=laps_pseudo2D_continuous_specific_decoded_result.time_window_centers, slices_posteriors=marginal_y_p_x_given_n_list,\n",
    "                                                                                xbin=None, measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "                                                                                extended_dock_title_info=info_string, posterior_heatmap_imshow_kwargs=dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05b98bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_pseudo2D_continuous_specific_decoded_result.p_x_given_n_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcb7eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timebins, flat_time_bin_containers, timebins_p_x_given_n = laps_pseudo2D_continuous_specific_decoded_result.flatten()\n",
    "\n",
    "desired_total_n_timebins, updated_is_masked_bin, updated_time_bin_containers, updated_timebins_p_x_given_n = laps_pseudo2D_continuous_specific_decoded_result.flatten_to_masked_values()\n",
    "\n",
    "# flat_time_bin_containers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e43cb3",
   "metadata": {},
   "source": [
    "### <a id='toc24_1_2_'></a>[Plotting Histograms Directly](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff6b535",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot: directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_pre_post_delta_scatter\n",
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import plot_histograms\n",
    "\n",
    "## INPUTS: masked_pseudo2D_continuous_specific_decoded_result\n",
    "masked_pseudo2D_continuous_specific_decoded_result = deepcopy(masked_pseudo2D_continuous_specific_decoded_result)\n",
    "ripple_weighted_corr_merged_df\n",
    "\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "## INPUTS: track_marginal_posterior_df\n",
    "\n",
    "# You can use it like this:\n",
    "_out0: \"MatplotlibRenderPlots\" = plot_histograms(data_type='Laps', session_spec='1 Session', data_results_df=track_marginal_posterior_df, time_bin_duration_str=\"25 ms\")\n",
    "# _out1: \"MatplotlibRenderPlots\" = plot_histograms(data_type='Ripples', session_spec='All Sessions', data_results_df=all_sessions_ripple_time_bin_df, time_bin_duration_str=\"75 ms\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01af1de8",
   "metadata": {},
   "source": [
    "# 'DirectionalDecodersEpochsEvaluations' Manipulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20af0225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "\n",
    "if ('DirectionalDecodersEpochsEvaluations' in curr_active_pipeline.global_computation_results.computed_data) and (curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations'] is not None):\n",
    "    directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "    directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)\n",
    "\n",
    "    ## UNPACK HERE via direct property access:\n",
    "    pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "    ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "    laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "    print(f'{pos_bin_size = }, {ripple_decoding_time_bin_size = }, {laps_decoding_time_bin_size = }') # pos_bin_size = 3.8054171165052444, ripple_decoding_time_bin_size = 0.025, laps_decoding_time_bin_size = 0.2\n",
    "    decoder_laps_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict\n",
    "    decoder_ripple_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict\n",
    "    decoder_laps_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_df_dict\n",
    "    decoder_ripple_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_df_dict\n",
    "\n",
    "    # New items:\n",
    "    decoder_laps_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_extras_dict\n",
    "    decoder_ripple_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_extras_dict\n",
    "\n",
    "    # Weighted correlations:\n",
    "    laps_weighted_corr_merged_df = directional_decoders_epochs_decode_result.laps_weighted_corr_merged_df\n",
    "    ripple_weighted_corr_merged_df = directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "    decoder_laps_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_laps_weighted_corr_df_dict\n",
    "    decoder_ripple_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict\n",
    "\n",
    "    # Pearson's correlations:\n",
    "    laps_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.laps_simple_pf_pearson_merged_df\n",
    "    ripple_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603edd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_session_name: str = curr_active_pipeline.session_name # '2006-6-08_14-26-15'\n",
    "CURR_BATCH_OUTPUT_PREFIX: str = f\"{BATCH_DATE_TO_USE}-{curr_session_name}\"\n",
    "print(f'CURR_BATCH_OUTPUT_PREFIX: {CURR_BATCH_OUTPUT_PREFIX}')\n",
    "\n",
    "# active_context = curr_active_pipeline.get_session_context().adding_context_if_missing(custom_\n",
    "\n",
    "# session_name: str = curr_active_pipeline.session_name\n",
    "\n",
    "active_context = curr_active_pipeline.get_session_context()\n",
    "session_name: str = f\"{curr_active_pipeline.session_name}{custom_suffix}\" ## appending this here is a hack, but it makes the correct filename\n",
    "active_context = active_context.adding_context_if_missing(suffix=custom_suffix)\n",
    "session_ctxt_key:str = active_context.get_description(separator='|', subset_includelist=(IdentifyingContext._get_session_context_keys() + ['suffix']))\n",
    "\n",
    "earliest_delta_aligned_t_start, t_delta, latest_delta_aligned_t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "active_context\n",
    "session_ctxt_key\n",
    "# Shifts the absolute times to delta-relative values, as would be needed to draw on a 'delta_aligned_start_t' axis:\n",
    "delta_relative_t_start, delta_relative_t_delta, delta_relative_t_end = np.array([earliest_delta_aligned_t_start, t_delta, latest_delta_aligned_t_end]) - t_delta\n",
    "# decoder_user_selected_epoch_times_dict, any_good_selected_epoch_times = DecoderDecodedEpochsResult.load_user_selected_epoch_times(curr_active_pipeline)\n",
    "# any_good_selected_epoch_indicies = filtered_ripple_simple_pf_pearson_merged_df.epochs.matching_epoch_times_slice(any_good_selected_epoch_times)\n",
    "# df = filter_epochs_dfs_by_annotation_times(curr_active_pipeline, any_good_selected_epoch_times, ripple_decoding_time_bin_size=ripple_decoding_time_bin_size, filtered_ripple_simple_pf_pearson_merged_df, ripple_weighted_corr_merged_df)\n",
    "# df\n",
    "\n",
    "# collected_outputs_path = self.collected_outputs_path.resolve()\n",
    "\n",
    "collected_outputs_path = collected_outputs_path.resolve()\n",
    "\n",
    "## Export CSVs:\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d550bf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "def _update_ripple_df(a_ripple_df):\n",
    "    \"\"\" captures: session_name, t_start, t_delta, t_end, ripple_decoding_time_bin_size \"\"\"\n",
    "    if ('time_bin_size' not in a_ripple_df.columns) and (ripple_decoding_time_bin_size is not None):\n",
    "        ## add the column\n",
    "        a_ripple_df['time_bin_size'] = ripple_decoding_time_bin_size\n",
    "    # Add the maze_id to the active_filter_epochs so we can see how properties change as a function of which track the replay event occured on:\n",
    "    a_ripple_df = DecoderDecodedEpochsResult.add_session_df_columns(a_ripple_df, session_name=session_name, time_bin_size=None, t_start=t_start, curr_session_t_delta=t_delta, t_end=t_end, time_col='ripple_start_t')\n",
    "    return a_ripple_df\n",
    "\n",
    "directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df = _update_ripple_df(directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df)\n",
    "directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df = _update_ripple_df(directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df)\n",
    "    \n",
    "ripple_weighted_corr_merged_df = directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "ripple_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df\n",
    "\n",
    "## UPDATES: directional_decoders_epochs_decode_result\n",
    "## OUTPUTS: ripple_simple_pf_pearson_merged_df, ripple_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127cd14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_simple_pf_pearson_merged_df\n",
    "ripple_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec606dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "# directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict # vector for each decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161d321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_pseudo2D_continuous_specific_decoded_result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fa02d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot: directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_pre_post_delta_scatter\n",
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import plot_histograms\n",
    "\n",
    "## INPUTS: masked_pseudo2D_continuous_specific_decoded_result\n",
    "masked_pseudo2D_continuous_specific_decoded_result = deepcopy(masked_pseudo2D_continuous_specific_decoded_result)\n",
    "ripple_weighted_corr_merged_df\n",
    "\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "# You can use it like this:\n",
    "_out0: \"MatplotlibRenderPlots\" = plot_histograms(data_type='Continuous', session_spec='1 Session', data_results_df=masked_pseudo2D_continuous_specific_decoded_result, time_bin_duration_str=\"25 ms\")\n",
    "# _out1: \"MatplotlibRenderPlots\" = plot_histograms(data_type='Ripples', session_spec='All Sessions', data_results_df=all_sessions_ripple_time_bin_df, time_bin_duration_str=\"75 ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e17e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram_bins = 'auto'\n",
    "histogram_bins: int = 25\n",
    "\n",
    "# ripple_weighted_corr_merged_df = ripple_weighted_corr_merged_df[['P_Short','delta_aligned_start_t', 'time_bin_size']]\n",
    "ripple_weighted_corr_merged_df = ripple_weighted_corr_merged_df[['P_Short','delta_aligned_start_t', 'time_bin_size']]\n",
    "new_ripple_fig, new_ripple_fig_context = plotly_pre_post_delta_scatter(data_results_df=ripple_weighted_corr_merged_df, out_scatter_fig=None, histogram_bins=histogram_bins,\n",
    "                                                                        px_scatter_kwargs=dict(title='Ripple'), histogram_variable_name='P_Short')\n",
    "\n",
    "# new_laps_fig = new_laps_fig.update_layout(fig_size_kwargs, \n",
    "#     xaxis_title=\"X Axis Title\",\n",
    "#     yaxis_title=\"Y Axis Title\",\n",
    "#     legend_title=\"Legend Title\",\n",
    "#     font=dict(\n",
    "#         family=\"Courier New, monospace\",\n",
    "#         size=18,\n",
    "#         color=\"RebeccaPurple\"\n",
    "#     ),\n",
    "# )\n",
    "# Update x-axis labels\n",
    "# new_laps_fig.update_xaxes(title_text=\"Num Time Bins\", row=1, col=1)\n",
    "# new_laps_fig.update_xaxes(title_text=\"Delta-aligned Event Time (seconds)\", row=1, col=2)\n",
    "# new_laps_fig.update_xaxes(title_text=\"Num Time Bins\", row=1, col=3)\n",
    "\n",
    "\n",
    "_extras_output_dict = {}\n",
    "_extras_output_dict[\"y_mid_line\"] = new_ripple_fig.add_hline(y=0.5, line=dict(color=\"rgba(0.8,0.8,0.8,.75)\", width=2), row='all', col='all')\n",
    "\n",
    "new_ripple_fig\n",
    "\n",
    "\n",
    "\n",
    "# # Update layout to add a title to the legend\n",
    "# new_fig_ripples.update_layout(\n",
    "#     legend_title_text='Is User Selected'  # Add a title to the legend\n",
    "# )\n",
    "\n",
    "# fig_to_clipboard(new_fig_ripples, **fig_size_kwargs)\n",
    "\n",
    "# new_laps_fig_context: IdentifyingContext = new_laps_fig_context.adding_context_if_missing(epoch='withNewKamranExportedReplays', num_sessions=num_sessions, plot_type='scatter+hist', comparison='pre-post-delta', variable_name=variable_name)\n",
    "# figure_out_paths = save_plotly(a_fig=new_laps_fig, a_fig_context=new_laps_fig_context)\n",
    "# new_laps_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59a55fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_PBE_marginal_over_track_ID # (2, 44887) - which track it's using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a48222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import find_epochs_overlapping_other_epochs\n",
    "\n",
    "# INPUTS: track_marginal_posterior_df\n",
    "\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "global_session = curr_active_pipeline.filtered_sessions[global_epoch_name]\n",
    "\n",
    "# global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps) # .trimmed_to_non_overlapping()\n",
    "global_laps_epochs_df = global_laps.to_dataframe()\n",
    "# active_test_epochs_df: pd.DataFrame = deepcopy(global_laps_epochs_df)\n",
    "global_laps_epochs_df\n",
    "\n",
    "\n",
    "# global_laps_epochs_df\n",
    "is_included: NDArray = find_epochs_overlapping_other_epochs(epochs_df=track_marginal_posterior_df, epochs_df_required_to_overlap=deepcopy(global_laps_epochs_df))\n",
    "track_marginal_posterior_df['is_in_laps'] = is_included\n",
    "track_marginal_posterior_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ad6c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_PBE_marginal_over_track_ID.shape # (2, 44887) - which track it's using\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01fe90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window_centers.shape # (44887,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9176dca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build into a marginal df like `all_sessions_laps_df`:\n",
    "track_marginal_posterior_df : pd.DataFrame = pd.DataFrame({'t':deepcopy(time_window_centers), 'P_Long': np.squeeze(non_PBE_marginal_over_track_ID[0, :]), 'P_Short': np.squeeze(non_PBE_marginal_over_track_ID[1, :]), 'time_bin_size': pseudo2D_continuous_specific_decoded_result.decoding_time_bin_size})\n",
    "track_marginal_posterior_df['delta_aligned_start_t'] = track_marginal_posterior_df['t'] - t_delta ## subtract off t_delta\n",
    "track_marginal_posterior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af44479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "template: str = 'plotly_dark' # set plotl template\n",
    "pio.templates.default = template\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_pre_post_delta_scatter\n",
    "\n",
    "\n",
    "histogram_bins: int = 25\n",
    "\n",
    "# new_laps_fig = plotly_pre_post_delta_scatter(data_results_df=deepcopy(all_sessions_laps_df), out_scatter_fig=fig_laps, histogram_bins=histogram_bins, px_scatter_kwargs = dict(title='Laps'))\n",
    "fig, figure_context = plotly_pre_post_delta_scatter(data_results_df=deepcopy(track_marginal_posterior_df)[['delta_aligned_start_t', 'P_Long', 'time_bin_size']], out_scatter_fig=None, histogram_bins=histogram_bins, px_scatter_kwargs = dict(title='Continuous'))\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3b13c7",
   "metadata": {},
   "source": [
    "### <a id='toc25_1_1_'></a>[🚧🔜 2025-02-26 -  Plot 1D pseudo2D Continuous Decodings and their marginals over TrackID on SpikeRaster2D track - uses `AddNewDecodedPosteriors_MatplotlibPlotCommand.prepare_and_perform_custom_decoder_decoded_epochs(...)`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9569f931",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_bin_size = epochs_decoding_time_bin_size\n",
    "info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dock_item = active_2d_plot.add_docked_marginal_track(name='non-PBE_marginal_over_track_ID',\n",
    "                                                                                        time_window_centers=time_window_centers, a_1D_posterior=non_PBE_marginal_over_track_ID, extended_dock_title_info=info_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfd6308",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_decoded_results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94401b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AddNewDecodedEpochMarginal_MatplotlibPlotCommand._perform_add_new_decoded_posterior_marginal_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4f1cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dock all Grouped results from `'DockedWidgets.Pseudo2DDecodedEpochsDockedMatplotlibView'`\n",
    "## INPUTS: active_2d_plot\n",
    "nested_dock_items, nested_dynamic_docked_widget_container_widgets = active_2d_plot.ui.dynamic_docked_widget_container.layout_dockGroups()\n",
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e99ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d58a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_ax.remove(line_measured_position)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6931df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_results = curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['non_PBE_epochs_results'], computation_kwargs_list=[dict(epochs_decoding_time_bin_size=0.025, frame_divide_bin_size=5.0, compute_1D=True, compute_2D=False, drop_previous_result_and_compute_fresh=True, skip_training_test_split=False)],\n",
    "                                                                                                                                            enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3232a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['non_PBE_epochs_results'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb2b869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs_decoding_time_bin_size = 0.050\n",
    "# subdivide_bin_size = 0.250\n",
    "\n",
    "epochs_decoding_time_bin_size = 1.0\n",
    "subdivide_bin_size = 1.0\n",
    "\n",
    "_out_results = curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['non_PBE_epochs_results'], computation_kwargs_list=[dict(epochs_decoding_time_bin_size=epochs_decoding_time_bin_size, frame_divide_bin_size=subdivide_bin_size, compute_1D=True, compute_2D=True, drop_previous_result_and_compute_fresh=False)],\n",
    "                                                                                                                                            enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b103e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [np.shape(v) for v in a_result.p_x_given_n_list]\n",
    "\n",
    "np.sum([np.prod(np.shape(v)) for v in a_result.p_x_given_n_list])\n",
    "\n",
    "# np.vstack([np.shape(v) for v in a_result.p_x_given_n_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464af0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData, loadData\n",
    "\n",
    "# output_save_parent_path: Path = Path(r\"C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\data\").resolve()\n",
    "output_save_parent_path: Path = curr_active_pipeline.get_output_path().resolve()\n",
    "# hdf5_output_path: Path = curr_active_pipeline.get_output_path().joinpath('2025-02-14_results_nonPBEDecoding_2D.h5')\n",
    "# pkl_output_path: Path = output_save_parent_path.joinpath('2025-02-18_results_EpochComputations_nonPBEDecoding.pkl')\n",
    "pkl_output_path: Path = output_save_parent_path.joinpath('2025-02-20_results_EpochComputations_nonPBEDecoding.pkl')\n",
    "print(f'pkl_output_path: \"{pkl_output_path}\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5d8014",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "saveData(pkl_output_path, nonPBE_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad5e355",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load from pickle:\n",
    "print(f'pkl_output_path: {pkl_output_path}')\n",
    "nonPBE_results = loadData(pkl_path=pkl_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b617c11",
   "metadata": {},
   "source": [
    "## <a id='toc32_2_'></a>[Get 1D representations of the Pseudo2D track (4 decoders) so they can be plotted on seperate tracks and bin-debugged independently.](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b821104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "\n",
    "epochs_decoding_time_bin_size: float = 0.050\n",
    "\n",
    "# output_dict = active_2d_plot.compute_if_needed_and_add_continuous_decoded_posterior(curr_active_pipeline=curr_active_pipeline, desired_time_bin_size=0.025, debug_print=True)\n",
    "output_dict = active_2d_plot.compute_if_needed_and_add_continuous_decoded_posterior(curr_active_pipeline=curr_active_pipeline, desired_time_bin_size=epochs_decoding_time_bin_size, debug_print=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2e7918",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d23c891",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "\n",
    "\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "directional_merged_decoders_result.laps_all_epoch_bins_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d035e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "\n",
    "\n",
    "# epochs_decoding_time_bin_size: float = 0.025\n",
    "\n",
    "## get the result data:\n",
    "try:\n",
    "    ## Uses the `global_computation_results.computed_data['DirectionalDecodersDecoded']`\n",
    "    directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "    # pseudo2D_decoder: BasePositionDecoder = directional_decoders_decode_result.pseudo2D_decoder\n",
    "    all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "    a_continuously_decoded_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_decode_result.continuously_decoded_result_cache_dict.get(epochs_decoding_time_bin_size, None)\n",
    "    all_time_bin_sizes_output_dict: Dict[float, Dict[types.DecoderName, SingleEpochDecodedResult]] = directional_decoders_decode_result.split_pseudo2D_continuous_result_to_1D_continuous_result()\n",
    "    a_split_pseudo2D_continuous_result_to_1D_continuous_result_dict: Dict[types.DecoderName, SingleEpochDecodedResult] = all_time_bin_sizes_output_dict.get(epochs_decoding_time_bin_size, None)\n",
    "    \n",
    "    assert a_continuously_decoded_dict is not None, f\"a_continuously_decoded_dict is None even after recomputing!\"\n",
    "    assert a_split_pseudo2D_continuous_result_to_1D_continuous_result_dict is not None, f\"a_split_pseudo2D_continuous_result_to_1D_continuous_result_dict is None even after recomputing!\"\n",
    "    info_string: str = f\" - t_bin_size: {epochs_decoding_time_bin_size:.3f}\"\n",
    "    \n",
    "    _a_continuously_decoded_pseudo2D_result: DecodedFilterEpochsResult = deepcopy(a_continuously_decoded_dict['pseudo2D'])\n",
    "    assert _a_continuously_decoded_pseudo2D_result is not None\n",
    "    all_time_bin_decoded_pseudo2D_result: SingleEpochDecodedResult = _a_continuously_decoded_pseudo2D_result.get_result_for_epoch(0)\n",
    "\n",
    "\n",
    "except (KeyError, AttributeError) as e:\n",
    "    # KeyError: 'DirectionalDecodersDecoded'\n",
    "    print(f'add_all_computed_time_bin_sizes_pseudo2D_decoder_decoded_epochs(...) failed to add any tracks, perhaps because the pipeline is missing any computed \"DirectionalDecodersDecoded\" global results. Error: \"{e}\". Skipping.')\n",
    "    a_continuously_decoded_dict = None\n",
    "    pseudo2D_decoder = None        \n",
    "    pass\n",
    "\n",
    "except Exception as e:\n",
    "    raise\n",
    "\n",
    "\n",
    "## OUTPUTS: all_time_bin_decoded_pseudo2D_result\n",
    "np.shape(all_time_bin_decoded_pseudo2D_result.p_x_given_n) # (59, 4, 34744)\n",
    "\n",
    "marginal_x = deepcopy(all_time_bin_decoded_pseudo2D_result.marginal_x['p_x_given_n'])\n",
    "marginal_y = deepcopy(all_time_bin_decoded_pseudo2D_result.marginal_y['p_x_given_n'])\n",
    "\n",
    "\n",
    "np.shape(marginal_x) # (59, 34744)\n",
    "np.shape(marginal_y) # (4, 34744) -- marginalization of position bins\n",
    "\n",
    "\n",
    "## OUTPUTS: a_continuously_decoded_dict, a_split_pseudo2D_continuous_result_to_1D_continuous_result_dict\n",
    "# a_continuously_decoded_pseudo2D_result.build_per_time_bin_marginals_df(active_marginals_tuple=(laps_directional_all_epoch_bins_marginal, laps_track_identity_all_epoch_bins_marginal), columns_tuple=(['P_LR', 'P_RL'], ['P_Long', 'P_Short']))\n",
    "\n",
    "\n",
    "# a_split_pseudo2D_continuous_result_to_1D_continuous_result_dict\n",
    "all_time_bin_decoded_pseudo2D_result.time_bin_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95ec3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame('t': all_time_bin_decoded_pseudo2D_result.time_bin_edges.to_numpy(), })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d672dc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: all_time_bin_decoded_pseudo2D_result\n",
    "\n",
    "unique_decoder_names = ['long_LR', 'long_RL', 'short_LR', 'short_RL']\n",
    "# unique_decoder_names = ['long', 'short']\n",
    "\n",
    "# a_pseudo2D_split_to_1D_continuous_results_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = all_time_bin_decoded_pseudo2D_result.split_pseudo2D_result_to_1D_result(pseudo2D_decoder_names_list=unique_decoder_names)\n",
    "a_non_PBE_marginal_over_track_ID, a_non_PBE_marginal_over_track_ID_posterior_df = DirectionalPseudo2DDecodersResult.build_generalized_non_marginalized_raw_posteriors(_a_continuously_decoded_pseudo2D_result, unique_decoder_names=unique_decoder_names) #[0]['p_x_given_n']\n",
    "\n",
    "a_non_PBE_marginal_over_track_ID_posterior_df['t_bin_center'] = a_non_PBE_marginal_over_track_ID_posterior_df['t']\n",
    "## Add the combined columns:\n",
    "### TrackID:\n",
    "a_non_PBE_marginal_over_track_ID_posterior_df['P_Long'] = (a_non_PBE_marginal_over_track_ID_posterior_df['P_Long_lr'] + a_non_PBE_marginal_over_track_ID_posterior_df['P_Long_rl'])\n",
    "a_non_PBE_marginal_over_track_ID_posterior_df['P_Short'] = (a_non_PBE_marginal_over_track_ID_posterior_df['P_Short_lr'] + a_non_PBE_marginal_over_track_ID_posterior_df['P_Short_rl'])\n",
    "### Direction:\n",
    "a_non_PBE_marginal_over_track_ID_posterior_df['P_LR'] = (a_non_PBE_marginal_over_track_ID_posterior_df['P_Long_lr'] + a_non_PBE_marginal_over_track_ID_posterior_df['P_Short_lr'])\n",
    "a_non_PBE_marginal_over_track_ID_posterior_df['P_RL'] = (a_non_PBE_marginal_over_track_ID_posterior_df['P_Long_rl'] + a_non_PBE_marginal_over_track_ID_posterior_df['P_Short_rl'])\n",
    "\n",
    "a_non_PBE_marginal_over_track_ID_posterior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53513e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ctxt = IdentifyingContext()\n",
    "\n",
    "a_df = deepcopy(a_non_PBE_marginal_over_track_ID_posterior_df)\n",
    "## INPUTS: a_df\n",
    "\n",
    "time_bin_size = epochs_decoding_time_bin_size\n",
    "info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "plot_row_identifier: str = a_ctxt.get_description(subset_includelist=['known_named_decoding_epochs_type', 'masked_time_bin_fill_type'], include_property_names=True, key_value_separator=':', separator='|', replace_separator_in_property_names='-')\n",
    "a_time_window_centers = a_df['t_bin_center'].to_numpy() \n",
    "a_1D_posterior = a_df[['P_Long', 'P_Short']].to_numpy().T\n",
    "\n",
    "identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dock_item = active_2d_plot.add_docked_marginal_track(name=plot_row_identifier, time_window_centers=a_time_window_centers, a_1D_posterior=a_1D_posterior, extended_dock_title_info=info_string)\n",
    "_all_tracks_out_artists[identifier_name] = widget\n",
    "matplotlib_fig_axes[0].set_xlim(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time)\n",
    "widget.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474d2414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae4b6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalDecodersContinuouslyDecodedResult, DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import SingleEpochDecodedResult\n",
    "\n",
    "## INPUTS: laps_pseudo2D_continuous_specific_decoded_result: DecodedFilterEpochsResult\n",
    "unique_decoder_names = ['long', 'short']\n",
    "laps_pseudo2D_split_to_1D_continuous_results_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = laps_pseudo2D_continuous_specific_decoded_result.split_pseudo2D_result_to_1D_result(pseudo2D_decoder_names_list=unique_decoder_names)\n",
    "masked_laps_pseudo2D_split_to_1D_continuous_results_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = masked_laps_pseudo2D_continuous_specific_decoded_result.split_pseudo2D_result_to_1D_result(pseudo2D_decoder_names_list=unique_decoder_names)\n",
    "\n",
    "# OUTPUTS: laps_pseudo2D_split_to_1D_continuous_results_dict, masked_laps_pseudo2D_split_to_1D_continuous_results_dict\n",
    "\n",
    "# active_marginals=ripple_track_identity_marginals, columns=['P_LR', 'P_RL'] \n",
    "# active_marginals=ripple_track_identity_marginals, columns=['P_Long', 'P_Short']\n",
    "# laps_track_identity_all_epoch_bins_marginal\n",
    "\n",
    "## INPUTS: laps_pseudo2D_continuous_specific_decoded_result: DecodedFilterEpochsResult\n",
    "flat_time_window_centers, flat_marginal_y_p_x_given_n = laps_pseudo2D_continuous_specific_decoded_result.get_pseudo2D_result_to_pseudo2D_marginalization_result(pseudo2D_decoder_names_list=unique_decoder_names)\n",
    "flat_marginal_y_p_x_given_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904527b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_all_tracks_out_artists = {}\n",
    "for a_ctxt, a_df in flat_decoded_marginal_posterior_df_context_dict.items():\n",
    "    time_bin_size = epochs_decoding_time_bin_size\n",
    "    info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "    plot_row_identifier: str = a_ctxt.get_description(subset_includelist=['known_named_decoding_epochs_type', 'masked_time_bin_fill_type'], include_property_names=True, key_value_separator=':', separator='|', replace_separator_in_property_names='-')\n",
    "    a_time_window_centers = a_df['t_bin_center'].to_numpy() \n",
    "    a_1D_posterior = a_df[['P_Long', 'P_Short']].to_numpy().T\n",
    "\n",
    "    identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dock_item = active_2d_plot.add_docked_marginal_track(name=plot_row_identifier, time_window_centers=a_time_window_centers, a_1D_posterior=a_1D_posterior, extended_dock_title_info=info_string)\n",
    "    _all_tracks_out_artists[identifier_name] = widget\n",
    "    intervals_overview_plot_item.setXRange(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time, padding=0) ## global frame\n",
    "    matplotlib_fig_axes[0].set_xlim(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time)\n",
    "    widget.draw()\n",
    "\n",
    "\n",
    "## Make a new matplotlib figure (in a new window) that contains a copy of `matplotlib_fig_axes` inserted \n",
    "\n",
    "\n",
    "\n",
    "# active_2d_plot.add_docked_marginal_track("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3c784d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.indexing_helpers import get_dict_subset\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalDecodersContinuouslyDecodedResult, DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import SingleEpochDecodedResult\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, DockDisplayColors\n",
    "\n",
    "debug_print = True\n",
    "\n",
    "## Uses the `global_computation_results.computed_data['DirectionalDecodersDecoded']`\n",
    "directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "pseudo2D_decoder: BasePositionDecoder = directional_decoders_decode_result.pseudo2D_decoder  # merged pseudo2D decoder\n",
    "all_directional_pf1D_Decoder_dict: Dict[types.DecoderName, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict ## separate 1D decoders\n",
    "\n",
    "continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "\n",
    "\n",
    "all_time_bin_sizes_output_dict: Dict[float, Dict[types.DecoderName, SingleEpochDecodedResult]] = directional_decoders_decode_result.split_pseudo2D_continuous_result_to_1D_continuous_result()\n",
    "## OUTPUTS: all_directional_pf1D_Decoder_dict, all_time_bin_sizes_output_dict, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50c1170",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uses `AddNewDecodedPosteriors_MatplotlibPlotCommand._perform_add_new_decoded_posterior_row(...)` to build the 4 tracks from the split result:\n",
    "# active_2d_plot.add_new_embedded_pyqtgraph_render_plot_widget(\n",
    "\"\"\"\n",
    "add_new_matplotlib_render_plot_widget\n",
    "add_new_matplotlib_render_plot_widget\n",
    "add_new_embedded_pyqtgraph_render_plot_widget\n",
    "\"\"\"\n",
    "## INPUTS: all_time_bin_sizes_output_dict\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import AddNewDecodedPosteriors_MatplotlibPlotCommand\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, DockDisplayColors\n",
    "\n",
    "## plot only a single time bin for now:\n",
    "cached_decoded_time_bin_size_list = list(all_time_bin_sizes_output_dict.keys())\n",
    "assert len(cached_decoded_time_bin_size_list) > 0\n",
    "active_time_bin_size: float = cached_decoded_time_bin_size_list[0]\n",
    "info_string: str = f'{active_time_bin_size:.2f}'\n",
    "## one for each of the four decoders:\n",
    "a_split_pseudo2D_continuous_result_to_1D_continuous_result_dict: Dict[types.DecoderName, SingleEpochDecodedResult] = all_time_bin_sizes_output_dict[active_time_bin_size]\n",
    "dock_group_sep_character: str = '_'\n",
    "showCloseButton = True\n",
    "_common_dock_config_kwargs = {'dock_group_names': [dock_group_sep_character.join([f'ContinuousDecode', info_string])], 'showCloseButton': showCloseButton}\n",
    "dock_configs = dict(zip(('long_LR', 'long_RL', 'short_LR', 'short_RL'),\n",
    "\t\t\t\t\t\t(CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Laps.get_LR_dock_colors, **_common_dock_config_kwargs),\n",
    "                        CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Laps.get_RL_dock_colors, **_common_dock_config_kwargs),\n",
    "                        CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Laps.get_LR_dock_colors, **_common_dock_config_kwargs),\n",
    "                        CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Laps.get_RL_dock_colors, **_common_dock_config_kwargs))))\n",
    "\n",
    "\n",
    "## all at once:\n",
    "output_dict = active_2d_plot.add_docked_decoded_results_dict_tracks(name=f'DirectionalDecodersDecoded', a_decoded_result_dict=a_split_pseudo2D_continuous_result_to_1D_continuous_result_dict, dock_configs=dock_configs, pf1D_Decoder_dict=all_directional_pf1D_Decoder_dict,\n",
    "                                                                                            measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "                                                                                            extended_dock_title_info=info_string)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6828e1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Need all_directional_pf1D_Decoder_dict\n",
    "output_dict = {}\n",
    "for a_decoder_name, a_1D_continuous_decoded_result in a_split_pseudo2D_continuous_result_to_1D_continuous_result_dict.items():\n",
    "    ## a_1D_continuous_decoded_result: SingleEpochDecodedResult\n",
    "    a_dock_config = dock_configs[a_decoder_name]\n",
    "    a_1D_decoder: BasePositionDecoder = all_directional_pf1D_Decoder_dict[a_decoder_name]\n",
    "    # _out_tuple = AddNewDecodedPosteriors_MatplotlibPlotCommand._perform_add_new_decoded_posterior_row(curr_active_pipeline=curr_active_pipeline, active_2d_plot=active_2d_plot, a_dock_config=a_dock_config, a_decoder_name=a_decoder_name, a_position_decoder=a_1D_decoder,\n",
    "    #                                                             time_window_centers=a_1D_continuous_decoded_result.time_bin_container.centers, a_1D_posterior=a_1D_continuous_decoded_result.p_x_given_n, extended_dock_title_info=info_string)\n",
    "    _out_tuple = active_2d_plot.add_docked_decoded_posterior_track(name=f'DirectionalDecodersDecoded[{a_decoder_name}]', a_dock_config=a_dock_config,\n",
    "                                                                                            time_window_centers=a_1D_continuous_decoded_result.time_bin_container.centers, a_1D_posterior=a_1D_continuous_decoded_result.p_x_given_n,\n",
    "                                                                                            xbin = deepcopy(a_1D_decoder.xbin), measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "                                                                                            extended_dock_title_info=info_string)\n",
    "\n",
    "    identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = _out_tuple\n",
    "    ## Add `a_decoded_result` to the plots_data\n",
    "    widget.plots_data.a_decoded_result = a_1D_continuous_decoded_result\n",
    "    widget.plots_data.a_decoder = deepcopy(a_1D_decoder)\n",
    "    output_dict[a_decoder_name] = _out_tuple\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56538c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_decoder_name, an_out_tuple in output_dict.items():\n",
    "    identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = an_out_tuple\n",
    "    print(f'a_decoder_name: {a_decoder_name} -- identifier_name: \"{identifier_name}\"')\n",
    "\n",
    "    # dDisplayItem.orientation\n",
    "    dDisplayItem.autoOrient = False\n",
    "    # dDisplayItem.setOrientation('horizontal', force=True)\n",
    "    dDisplayItem.setOrientation('vertical', force=True)\n",
    "    dDisplayItem.label.relayout_text()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f833550",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_decoder_name, an_out_tuple in output_dict.items():\n",
    "    identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = an_out_tuple\n",
    "    print(f'a_decoder_name: {a_decoder_name} -- identifier_name: \"{identifier_name}\"')\n",
    "    # widget.plots_data.data_keys\n",
    "    widget.plots_data.a_decoded_result = a_1D_continuous_decoded_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450d37f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import plot_attached_BinByBinDecodingDebugger\n",
    "\n",
    "a_decoder_name: types.DecoderName = 'long_LR'\n",
    "identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = output_dict[a_decoder_name]\n",
    "a_1D_continuous_decoded_result = widget.plots_data.a_decoded_result\n",
    "a_decoder = widget.plots_data.a_decoder\n",
    "## INPUTS: a_decoder, a_decoded_result\n",
    "win, out_pf1D_decoder_template_objects, (plots_container, plots_data), _on_update_fcn = plot_attached_BinByBinDecodingDebugger(spike_raster_window, curr_active_pipeline, a_decoder=a_decoder, a_decoded_result=a_1D_continuous_decoded_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b217f221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_1D_continuous_decoded_result.epoch_info_tuple\n",
    "a_1D_continuous_decoded_result.time_bin_container.center_info.step\n",
    "a_1D_continuous_decoded_result.time_bin_container.edge_info.step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c4a72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, CustomCyclicColorsDockDisplayConfig, NamedColorScheme\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import new_plot_raster_plot #, NewSimpleRaster, paired_separately_sort_neurons\n",
    "\n",
    "_raster_tracks_out_dict = {}\n",
    "## Enables creating a new pyqtgraph-based track to display the intervals/epochs\n",
    "dock_config = CustomCyclicColorsDockDisplayConfig(named_color_scheme=NamedColorScheme.grey, showCloseButton=True, showCollapseButton=False, showGroupButton=False, corner_radius=\"0px\", hideTitleBar=True)\n",
    "name = f'rasters[{name_modifier_suffix}]'\n",
    "time_sync_pyqtgraph_widget, raster_root_graphics_layout_widget, raster_plot_item, raster_dock = self.add_new_embedded_pyqtgraph_render_plot_widget(name=name, dockSize=(500, 120), display_config=dock_config)\n",
    "\n",
    "if raster_plot_item not in self.params.custom_interval_rendering_plots:\n",
    "    self.params.custom_interval_rendering_plots.append(raster_plot_item) ## this signals that it should recieve updates for its intervals somewhere else\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15a97f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# all_time_bin_sizes_output_dict = {'non_marginalized_raw_result': [], 'marginal_over_direction': [], 'marginal_over_track_ID': []}\n",
    "# flat_all_time_bin_sizes_output_tuples_list: List[Tuple] = []\n",
    "\n",
    "for time_bin_size, a_continuously_decoded_dict in continuously_decoded_result_cache_dict.items():\n",
    "    ## Each iteration here adds 4 more tracks -- one for each decoding context\n",
    "    \n",
    "    # a_continuously_decoded_dict: Dict[str, DecodedFilterEpochsResult]\n",
    "    if debug_print:\n",
    "        print(f'time_bin_size: {time_bin_size}')\n",
    "\n",
    "    info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "    \n",
    "    ## Uses the `global_computation_results.computed_data['DirectionalDecodersDecoded']`\n",
    "    # all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "    # continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "\n",
    "    continuously_decoded_dict = a_continuously_decoded_dict\n",
    "    \n",
    "\n",
    "    # continuously_decoded_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(directional_decoders_decode_result.most_recent_continuously_decoded_dict)\n",
    "    assert continuously_decoded_dict is not None\n",
    "\n",
    "    ## Get the separate 1D results, these are ready-to-go:\n",
    "    all_directional_pf1D_Decoder_continuous_results_dict: Dict[types.DecoderName, SingleEpochDecodedResult] = {k:v.get_result_for_epoch(0) for k, v in get_dict_subset(continuously_decoded_dict, subset_includelist=None, subset_excludelist=['pseudo2D']).items()}\n",
    "    \n",
    "\n",
    "    ## Extract the Pseudo2D results as separate 1D tracks\n",
    "    ## INPUTS: most_recent_continuously_decoded_dict: Dict[str, DecodedFilterEpochsResult], info_string\n",
    "    \n",
    "    # all_directional_continuously_decoded_dict = most_recent_continuously_decoded_dict or {}\n",
    "    pseudo2D_decoder_continuously_decoded_result: DecodedFilterEpochsResult = continuously_decoded_dict.get('pseudo2D', None)\n",
    "    assert len(pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list) == 1\n",
    "    single_pseudo2D_decoder_continuously_decoded_result: SingleEpochDecodedResult = pseudo2D_decoder_continuously_decoded_result.get_result_for_epoch(0)\n",
    "    \n",
    "\n",
    "    p_x_given_n = single_pseudo2D_decoder_continuously_decoded_result.p_x_given_n ## continuous -- meaning single epoch\n",
    "    # p_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0]['p_x_given_n']\n",
    "    time_bin_container = single_pseudo2D_decoder_continuously_decoded_result.time_bin_container\n",
    "    time_window_centers = time_bin_container.centers\n",
    "    \n",
    "\n",
    "    # p_x_given_n.shape # (62, 4, 209389)\n",
    "\n",
    "    ## Split across the 2nd axis to make 1D posteriors that can be displayed in separate dock rows:\n",
    "    assert p_x_given_n.shape[1] == 4, f\"expected the 4 pseudo-y bins for the decoder in p_x_given_n.shape[1]. but found p_x_given_n.shape: {p_x_given_n.shape}\"\n",
    "    split_pseudo2D_posteriors_dict = {k:np.squeeze(p_x_given_n[:, i, :]) for i, k in enumerate(('long_LR', 'long_RL', 'short_LR', 'short_RL'))}\n",
    "\n",
    "    # Need all_directional_pf1D_Decoder_dict\n",
    "    output_dict = {}\n",
    "    output_pseudo2D_split_to_1D_continuous_results_dict: Dict[types.DecoderName, SingleEpochDecodedResult] = {}\n",
    "\n",
    "    # for a_decoder_name, a_1D_posterior in split_pseudo2D_posteriors_dict.items():\n",
    "    for i, a_decoder_name in enumerate(('long_LR', 'long_RL', 'short_LR', 'short_RL')):\n",
    "        ## make separate `SingleEpochDecodedResult` objects\n",
    "        \n",
    "        # all_directional_pf1D_Decoder_continuous_results_dict\n",
    "        output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name] = deepcopy(single_pseudo2D_decoder_continuously_decoded_result) ## copy the whole pseudo2D result\n",
    "        # output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].p_x_given_n = a_1D_posterior ## or could squish them here\n",
    "        output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].p_x_given_n = np.squeeze(output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].p_x_given_n[:, i, :]) ## or could squish them here\n",
    "        \n",
    "        # _out_tuple = dict(a_decoder_name=a_decoder_name, a_position_decoder=pseudo2D_decoder, time_window_centers=time_window_centers, a_1D_posterior=a_1D_posterior)\n",
    "        # identifier_name, widget, matplotlib_fig, matplotlib_fig_axes = _out_tuple\n",
    "        # output_dict[a_decoder_name] = _out_tuple\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## OUTPUTS: all_directional_pf1D_Decoder_dict: Dict[types.DecoderName, BasePositionDecoder], all_directional_pf1D_Decoder_continuous_results_dict: Dict[types.DecoderName, SingleEpochDecodedResult]\n",
    "## OUTPUTS: pseudo2D_decoder: BasePositionDecoder, single_pseudo2D_decoder_continuously_decoded_result: SingleEpochDecodedResult, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea54c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].p_x_given_n.shape\n",
    "# output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].most_likely_positions\n",
    "\n",
    "# output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name]._test_find_fields_by_shape_metadata()\n",
    "\n",
    "## Marginals are wrong afterwards, and most-likely positions have too many dimensions\n",
    "\n",
    "\n",
    "# pseudo2D_decoder_continuously_decoded_result.perform_compute_marginals\n",
    "output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].most_likely_positions\n",
    "output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].marginal_x\n",
    "\n",
    "output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].marginal_x['p_x_given_n'].shape ## these are okay, (n_x_bins, n_t_bins)\n",
    "output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].marginal_y['p_x_given_n'].shape ## these are bad, (n_decoder_names, n_t_bins)\n",
    "\n",
    "\n",
    "output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].most_likely_positions["
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522aab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo2D_decoder_continuously_decoded_result.pos_bin_edges\n",
    "pseudo2D_decoder_continuously_decoded_result.n_pos_bins\n",
    "continuously_decoded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566c4c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_bin_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1687f8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_pseudo2D_decoder_continuously_decoded_result.to_hdf(\n",
    "import h5py\n",
    "\n",
    "hdf5_output_path: Path = curr_active_pipeline.get_output_path().joinpath('test_data.h5')\n",
    "with h5py.File(hdf5_output_path, 'w') as f: ## open the path as a HDF5 file handle:\n",
    "    single_pseudo2D_decoder_continuously_decoded_result.to_hdf(f, key='single_pseudo2D_decoder_continuously_decoded_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5b63de",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_pseudo2D_decoder_continuously_decoded_result\n",
    "single_pseudo2D_decoder_continuously_decoded_result.marginal_y['p_x_given_n'].shape\n",
    "single_pseudo2D_decoder_continuously_decoded_result.marginal_x['p_x_given_n'].shape\n",
    "\n",
    "\n",
    "\n",
    "# single_pseudo2D_decoder_continuously_decoded_result.epoch_info_tuple\n",
    "single_pseudo2D_decoder_continuously_decoded_result.p_x_given_n.shape # (59, 4, 69487)\n",
    "# single_pseudo2D_decoder_continuously_decoded_result.get_posterior_as_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66ce480",
   "metadata": {},
   "source": [
    "# <a id='toc34_'></a>[General Decoding Record with Frozen Decoding Parameters Tuples](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0889b292",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dict of decoding results, where the decoders used for decoding are built from: nonPBE_Long, nonPBE_Short, Laps_LongLR, Laps_LongRL, Laps_ShortLR, Laps_ShortRL\n",
    "## qclu, frHz\n",
    "# All Decoders should be continuous (decoding the entire session as a single epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e6797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import EpochsAccessor, Epoch, ensure_dataframe, ensure_Epoch\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import EpochComputationFunctions, EpochComputationsComputationsContainer, DecodingResultND, Compute_NonPBE_Epochs, KnownFilterEpochs\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import GeneralDecoderDictDecodedEpochsDictResult, GenericResultTupleIndexType, KnownNamedDecodingEpochsType, MaskedTimeBinFillType\n",
    "\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "\n",
    "## Unpack from pipeline:\n",
    "nonPBE_results: EpochComputationsComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['EpochComputations']\n",
    "a_new_NonPBE_Epochs_obj: Compute_NonPBE_Epochs = nonPBE_results.a_new_NonPBE_Epochs_obj\n",
    "results1D: DecodingResultND = nonPBE_results.results1D\n",
    "results2D: DecodingResultND = nonPBE_results.results2D\n",
    "\n",
    "epochs_decoding_time_bin_size = nonPBE_results.epochs_decoding_time_bin_size\n",
    "frame_divide_bin_size = nonPBE_results.frame_divide_bin_size\n",
    "\n",
    "print(f'{epochs_decoding_time_bin_size = }, {frame_divide_bin_size = }')\n",
    "\n",
    "assert (results1D is not None)\n",
    "# assert (results2D is not None)\n",
    "\n",
    "## New computed properties:\n",
    "a_general_decoder_dict_decoded_epochs_dict_result: GeneralDecoderDictDecodedEpochsDictResult = nonPBE_results.a_general_decoder_dict_decoded_epochs_dict_result ## get the pre-decoded result\n",
    "a_general_decoder_dict_decoded_epochs_dict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098dbf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# 2025-02-20 20:06 New `nonPBE_results._build_merged_joint_placefields_and_decode` method                              #\n",
    "# ==================================================================================================================== #\n",
    "non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict, non_PBE_marginal_over_track_ID, (time_bin_containers, time_window_centers, track_marginal_posterior_df) = nonPBE_results._build_merged_joint_placefields_and_decode(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)))\n",
    "masked_pseudo2D_continuous_specific_decoded_result, _mask_index_tuple = pseudo2D_continuous_specific_decoded_result.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)))\n",
    "## OUTPUTS: pseudo2D_continuous_specific_decoded_result, non_PBE_marginal_over_track_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1ffbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'DirectionalMergedDecoders' in curr_active_pipeline.global_computation_results.computed_data:\n",
    "    # DirectionalMergedDecoders: Get the result after computation:\n",
    "    directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "    a_new_fully_generic_result = a_new_fully_generic_result.adding_directional_pseudo2D_decoder_results_filtered_by_spikes_per_t_bin_masked(directional_merged_decoders_result=directional_merged_decoders_result)\n",
    "else:\n",
    "    print('WARN: missing \"DirectionalMergedDecoders\" global result. Skipping.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f11aef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.get_complete_session_context()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37a4b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict, non_PBE_marginal_over_track_ID, (time_bin_containers, time_window_centers, track_marginal_posterior_df), masked_pseudo2D_continuous_specific_decoded_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf7487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_attributes(short_name=None, tags=['WORKING'], input_requires=[], output_provides=[], uses=[], used_by=[], creation_date='2025-03-04 11:36', related_items=[])\n",
    "def add_decoded_posterior_row(active_2d_plot, identifier_name: str, a_decoder: BasePositionDecoder, a_decoded_result: DecodedFilterEpochsResult, extended_dock_title_info: Optional[str]=None):\n",
    "    \"\"\" adds a new decoder track to the active_2d_plot \n",
    "    \"\"\"\n",
    "    from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import SynchronizedPlotMode\n",
    "    from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_1D_most_likely_position_comparsions\n",
    "    from neuropy.utils.matplotlib_helpers import get_heatmap_cmap\n",
    "    from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import FixedCustomColormaps\n",
    "    from pyphocorehelpers.gui.Qt.color_helpers import ColormapHelpers\n",
    "\n",
    "    ## ✅ Add a new row for each of the four 1D directional decoders:\n",
    "    # identifier_name: str = f'ContinuousDecode_{a_decoder_name}'\n",
    "    if extended_dock_title_info is not None:\n",
    "        identifier_name += extended_dock_title_info ## add extra info like the time_bin_size in ms\n",
    "    # print(f'identifier_name: {identifier_name}')\n",
    "\n",
    "    # print(f'identifier_name: {identifier_name}')\n",
    "    widget, matplotlib_fig, matplotlib_fig_axes, dock_item = active_2d_plot.add_new_matplotlib_render_plot_widget(name=identifier_name, dockSize=(65, 200), display_config=None, sync_mode=SynchronizedPlotMode.TO_WINDOW)\n",
    "    an_ax = matplotlib_fig_axes[0]\n",
    "\n",
    "    active_decoder = deepcopy(a_decoder)\n",
    "    assert a_decoded_result is not None, f\"a_decoded_result should not be None anymore.\"\n",
    "\n",
    "    if a_decoded_result is not None:\n",
    "        active_result = deepcopy(a_decoded_result) # already decoded\n",
    "        assert (active_result.num_filter_epochs == 1), f\"currently only supports decoded results (DecodedFilterEpochsResult) computed with a single epoch for all time bins, but active_result.num_filter_epochs: {active_result.num_filter_epochs}\"\n",
    "        active_marginals = active_result.marginal_x_list[0]\n",
    "    else:\n",
    "        # no previously decoded result, fallback to the decoder's internal properties        \n",
    "        active_marginals = active_decoder.marginal.x\n",
    "        \n",
    "\n",
    "    variable_name='x'\n",
    "    active_bins = deepcopy(active_decoder.xbin)\n",
    "    time_window_centers = deepcopy(active_result.time_bin_containers[0].centers)\n",
    "    # active_most_likely_positions = active_marginals.most_likely_positions_1D # Raw decoded positions\n",
    "    active_most_likely_positions = None\n",
    "    active_posterior = active_marginals.p_x_given_n\n",
    "\n",
    "    # active_posterior = deepcopy(a_1D_posterior)\n",
    "    \n",
    "    # most_likely_positions_mode: 'standard'|'corrected'\n",
    "    # fig, curr_ax = curr_active_pipeline.display('_display_plot_marginal_1D_most_likely_position_comparisons', _active_config_name, variable_name='x', most_likely_positions_mode='corrected', ax=an_ax) # ax=active_2d_plot.ui.matplotlib_view_widget.ax\n",
    "    posterior_heatmap_imshow_kwargs = dict(\n",
    "        cmap = get_heatmap_cmap(cmap='viridis', bad_color='black', under_color='white', over_color='red'),\n",
    "    )\n",
    "\n",
    "    measured_position_df = None # Note: for some reason setting `measured_position_df` to anything other than None here messes up the plotting entirely. Set it to None now, and if we want measured positions plot them after\n",
    "    ## Actual plotting portion:\n",
    "    fig, an_ax = plot_1D_most_likely_position_comparsions(measured_position_df=None, time_window_centers=time_window_centers, xbin=active_bins,\n",
    "                                                            posterior=active_posterior,\n",
    "                                                            active_most_likely_positions_1D=active_most_likely_positions,\n",
    "                                                            ax=an_ax, variable_name=variable_name, debug_print=True, enable_flat_line_drawing=False,\n",
    "                                                            posterior_heatmap_imshow_kwargs=posterior_heatmap_imshow_kwargs)\n",
    "\n",
    "\n",
    "\n",
    "    widget.plots_data.active_decoder = active_decoder\n",
    "    widget.plots_data.a_decoded_result = a_decoded_result\n",
    "\n",
    "    # active_bins = active_decoder.xbin\n",
    "\n",
    "    # # active_most_likely_positions = active_marginals.most_likely_positions_1D # Raw decoded positions\n",
    "    # active_most_likely_positions = None\n",
    "    # active_posterior = active_marginals.p_x_given_n\n",
    "    return widget, matplotlib_fig, an_ax, dock_item\n",
    "\n",
    "\n",
    "add_decoded_posterior_row(active_2d_plot, identifier_name=f'Masked Non-PBE Pseudo2D', a_decoder=deepcopy(non_PBE_all_directional_pf1D_Decoder), a_decoded_result=masked_pseudo2D_continuous_specific_decoded_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb796232",
   "metadata": {},
   "source": [
    "# <a id='toc36_'></a>[2025-03-11 Apply the masking strategy introduced with the non-PBE epoch analyses on the other `DecodedFilterEpochsResult`s produced by the lap-constructed decoders (TrackTemplates)](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342da66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from neuropy.core.epoch import ensure_dataframe, ensure_Epoch\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring\n",
    "from neuropy.utils.result_context import DisplaySpecifyingIdentifyingContext\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import EpochFilteringMode, _compute_proper_filter_epochs\n",
    "\n",
    "KnownNamedDecoderTrainedComputeEpochsType = Literal['laps', 'non_pbe']\n",
    "# nonPBE_results = non\n",
    "\n",
    "filtered_epochs_df = None\n",
    "\n",
    "## INPUTS: curr_active_pipeline, track_templates, a_decoded_filter_epochs_decoder_result_dict\n",
    "\n",
    "## INPUTS: directional_decoders_epochs_decode_result, filtered_epochs_df\n",
    "\n",
    "\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = deepcopy(curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']) ## GENERAL\n",
    "# a_new_fully_generic_result = _subfn_add_spikes_per_t_bin_masked_variants(a_new_fully_generic_result, directional_decoders_epochs_decode_result=directional_decoders_epochs_decode_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ba386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict, non_PBE_marginal_over_track_ID, (time_bin_containers, time_window_centers, track_marginal_posterior_df) = nonPBE_results._build_merged_joint_placefields_and_decode(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)))\n",
    "masked_pseudo2D_continuous_specific_decoded_result, _mask_index_tuple = pseudo2D_continuous_specific_decoded_result.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)))\n",
    "# (all_time_bin_indicies, last_valid_indicies) = _mask_index_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5739b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from typing import Literal\n",
    "# Define a type that can only be one of these specific strings\n",
    "KnownNamedDecodingEpochsType = Literal['laps', 'replay', 'ripple', 'pbe', 'non_pbe']\n",
    "# Define a type that can only be one of these specific strings\n",
    "MaskedTimeBinFillType = Literal['ignore', 'last_valid', 'nan_filled', 'dropped'] ## used in `DecodedFilterEpochsResult.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(...)` to specify how invalid bins (due to too few spikes) are treated.\n",
    "\n",
    "GenericResultTupleIndexType: TypeAlias = IdentifyingContext # an template/stand-in variable that aims to abstract away the unique-hashable index of a single result computed with a given set of parameters. Not yet fully implemented 2025-03-09 17:50 \n",
    "\n",
    "test_identifier: IdentifyingContext = IdentifyingContext(known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='last_valid')\n",
    "\n",
    "test_identifier.get_description(include_property_names=True, separator=\"|\", key_value_separator=':') # , replace_separator_in_property_names='|'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828384eb",
   "metadata": {
    "tags": [
     "active-2025-03-11"
    ]
   },
   "outputs": [],
   "source": [
    "## OUTPUTS:\n",
    "# a_new_fully_generic_result\n",
    "\n",
    "for a_context, a_marginal_df in a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict.items():\n",
    "    param_sep_str: str = '¦'\n",
    "    # param_sep_str: str = ''\n",
    "    # param_sep_str: str = ' ⁖'\n",
    "    key_val_sep_str: str = ':'\n",
    "    a_ctxt_str: str = a_context.get_description(separator=param_sep_str, replace_separator_in_property_names='_', include_property_names=True, key_value_separator=key_val_sep_str)\n",
    "    # a_ctxt_str: str = a_context.get_initialization_code_string()\n",
    "    print(f'a_context: \"<{a_ctxt_str}>\" - np.shape(a_marginal_df): {np.shape(a_marginal_df)}')\n",
    "    \n",
    "\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:laps¦masked_time_bin_fill_type:ignore\" - np.shape(a_marginal_df): (14350, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:laps¦masked_time_bin_fill_type:last_valid\" - np.shape(a_marginal_df): (14350, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:laps¦masked_time_bin_fill_type:nan_filled\" - np.shape(a_marginal_df): (14350, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:pbe¦masked_time_bin_fill_type:ignore\" - np.shape(a_marginal_df): (1569, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:pbe¦masked_time_bin_fill_type:last_valid\" - np.shape(a_marginal_df): (1569, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:pbe¦masked_time_bin_fill_type:nan_filled\" - np.shape(a_marginal_df): (1569, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:non_pbe¦masked_time_bin_fill_type:ignore\" - np.shape(a_marginal_df): (43377, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:non_pbe¦masked_time_bin_fill_type:last_valid\" - np.shape(a_marginal_df): (43377, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:non_pbe¦masked_time_bin_fill_type:nan_filled\" - np.shape(a_marginal_df): (43377, 9)\n",
    "# a_context: \"trained_compute_epochs:laps¦pfND_ndim:1¦decoder_identifier:pseudo2D¦time_bin_size:0.025¦known_named_decoding_epochs_type:laps¦masked_time_bin_fill_type:ignore¦data_grain:per_time_bin\" - np.shape(a_marginal_df): (14350, 15)\n",
    "# a_context: \"trained_compute_epochs:laps¦pfND_ndim:1¦decoder_identifier:pseudo2D¦time_bin_size:0.025¦known_named_decoding_epochs_type:laps¦masked_time_bin_fill_type:ignore¦data_grain:per_epoch\" - np.shape(a_marginal_df): (74, 6)\n",
    "# a_context: \"trained_compute_epochs:laps¦pfND_ndim:1¦decoder_identifier:pseudo2D¦time_bin_size:0.025¦known_named_decoding_epochs_type:pbe¦masked_time_bin_fill_type:ignore¦data_grain:per_time_bin\" - np.shape(a_marginal_df): (1165, 15)\n",
    "# a_context: \"trained_compute_epochs:laps¦pfND_ndim:1¦decoder_identifier:pseudo2D¦time_bin_size:0.025¦known_named_decoding_epochs_type:pbe¦masked_time_bin_fill_type:ignore¦data_grain:per_epoch\" - np.shape(a_marginal_df): (133, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188ef752",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a_new_fully_generic_result.filter_epochs_pseudo2D_continuous_specific_decoded_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38476959",
   "metadata": {},
   "source": [
    "##### <a id='toc36_1_1_1_1_'></a>[2025-03-11 11:13 not sure if this is the old version or if it adds something to the `a_new_fully_generic_result`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f9ccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Common/shared for all decoded epochs:\n",
    "unique_decoder_names = ['long', 'short']\n",
    "non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict, non_PBE_marginal_over_track_ID, (time_bin_containers, time_window_centers, track_marginal_posterior_df) = nonPBE_results._build_merged_joint_placefields_and_decode(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline))) # , filter_epochs=deepcopy(global_any_laps_epochs_obj)\n",
    "\n",
    "## from dict of filter_epochs to decode:\n",
    "global_replays_df: pd.DataFrame = TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].replay))\n",
    "filter_epochs_to_decode_dict: Dict[KnownNamedDecodingEpochsType, Epoch] = {'laps': ensure_Epoch(deepcopy(global_any_laps_epochs_obj)),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   'pbe': ensure_Epoch(deepcopy(global_session.pbe.get_non_overlapping())),\n",
    "\t\t\t\t\t\t\t\t#  'ripple': ensure_Epoch(deepcopy(global_session.ripple)),\n",
    "\t\t\t\t\t\t\t\t#   'replay': ensure_Epoch(deepcopy(global_replays_df)),\n",
    "\t\t\t\t\t\t\t\t  'non_pbe': ensure_Epoch(deepcopy(global_session.non_pbe)),\n",
    "\t\t\t\t\t\t\t\t  }\n",
    "# filter_epochs_to_decode_dict\n",
    "\n",
    "## Perform the decoding and masking as needed for invalid bins:\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "a_general_decoder_dict_decoded_epochs_dict_result: GeneralDecoderDictDecodedEpochsDictResult = EpochComputationsComputationsContainer._build_output_decoded_posteriors(non_PBE_all_directional_pf1D_Decoder=non_PBE_all_directional_pf1D_Decoder, # pseudo2D_continuous_specific_decoded_result=pseudo2D_continuous_specific_decoded_result,\n",
    "    filter_epochs_to_decode_dict=filter_epochs_to_decode_dict,\n",
    "    unique_decoder_names=unique_decoder_names, spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), epochs_decoding_time_bin_size=epochs_decoding_time_bin_size,\n",
    "    session_name=session_name, t_start=t_start, t_delta=t_delta, t_end=t_end,\n",
    ")\n",
    "\n",
    "\n",
    "## OUTPUTS: filter_epochs_pseudo2D_continuous_specific_decoded_result, filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict\n",
    "# 58sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d05ac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# filter_epochs_pseudo2D_continuous_specific_decoded_result, filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict\n",
    "retro_general_decoder_dict_decoded_epochs_dict_result: GeneralDecoderDictDecodedEpochsDictResult = EpochComputationsComputationsContainer._build_output_decoded_posteriors(non_PBE_all_directional_pf1D_Decoder=non_PBE_all_directional_pf1D_Decoder, # pseudo2D_continuous_specific_decoded_result=pseudo2D_continuous_specific_decoded_result,\n",
    "    filter_epochs_to_decode_dict=filter_epochs_to_decode_dict,\n",
    "    unique_decoder_names=unique_decoder_names, spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), epochs_decoding_time_bin_size=epochs_decoding_time_bin_size,\n",
    "    session_name=session_name, t_start=t_start, t_delta=t_delta, t_end=t_end,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021b0ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try fresh 2025-03-11-style decoding of the TrackTemplates:\n",
    "global_session = curr_active_pipeline.filtered_sessions[global_epoch_name]\n",
    "\n",
    "## from dict of filter_epochs to decode:\n",
    "global_replays_df: pd.DataFrame = TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(deepcopy(global_session.replay))\n",
    "global_any_laps_epochs_obj = curr_active_pipeline.computation_results[global_epoch_name].computation_config.pf_params.computation_epochs # global_session.get\n",
    "filter_epochs_to_decode_dict: Dict[KnownNamedDecodingEpochsType, Epoch] = {'laps': ensure_Epoch(deepcopy(global_any_laps_epochs_obj)),\n",
    "                                                                        'pbe': ensure_Epoch(deepcopy(global_session.pbe.get_non_overlapping())),\n",
    "                                #  'ripple': ensure_Epoch(deepcopy(global_session.ripple)),\n",
    "                                #   'replay': ensure_Epoch(deepcopy(global_replays_df)),\n",
    "                                'non_pbe': ensure_Epoch(deepcopy(global_session.non_pbe)),\n",
    "                                }\n",
    "# filter_epochs_to_decode_dict\n",
    "\n",
    "## constrain all epochs to be at least two decoding time bins long, or drop them entirely:\n",
    "filter_epochs_to_decode_dict = {k:_compute_proper_filter_epochs(epochs_df=v, desired_decoding_time_bin_size=epochs_decoding_time_bin_size, minimum_event_duration=(2.0 * epochs_decoding_time_bin_size), mode=EpochFilteringMode.DropShorter)[0] for k, v in filter_epochs_to_decode_dict.items()} # `[0]` gets just the dataframe, as in DropShorter mode the time_bin_size is unchanged\n",
    "\n",
    "## Perform the decoding and masking as needed for invalid bins:\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6a401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_decoders_epochs_decode_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41fef63",
   "metadata": {},
   "source": [
    "# 2025-03-24 Get the old result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8652f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = deepcopy(curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']) ## GENERAL\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = deepcopy(curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders'])\n",
    "spikes_df = deepcopy(get_proper_global_spikes_df(curr_active_pipeline))\n",
    "\n",
    "laps_all_epoch_bins_marginals_df: pd.DataFrame = deepcopy(directional_merged_decoders_result.laps_all_epoch_bins_marginals_df)\n",
    "laps_time_bin_marginals_df: pd.DataFrame = deepcopy(directional_merged_decoders_result.laps_time_bin_marginals_df)\n",
    "laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf31bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "laps_time_bin_marginals_df = laps_time_bin_marginals_df.across_session_identity.add_session_df_columns(session_name=session_name, time_bin_size=0.025, t_start=t_start, curr_session_t_delta=t_delta, t_end=t_end)\n",
    "laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03d3caf",
   "metadata": {},
   "source": [
    "# 2025-03-24 11:19 TimeBinAggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36957842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "\n",
    "# INPUT: a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult \n",
    "a_new_fully_generic_result.get_matching_contexts(context_query=IdentifyingContext(data_grain= 'per_epoch'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a5eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_new_fully_generic_result.get_matching_contexts(context_query=IdentifyingContext())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f289430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "a_new_fully_generic_result.get_matching_contexts(context_query=IdentifyingContext(trained_compute_epochs='laps', decoder_identifier='pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type='laps',\n",
    "    masked_time_bin_fill_type='ignore',\n",
    "    # masked_time_bin_fill_type='dropped',\n",
    "    data_grain= 'per_time_bin'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51118ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get all non-global, `data_grain= 'per_time_bin'`\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=IdentifyingContext(trained_compute_epochs='laps', decoder_identifier='pseudo2D', time_bin_size=0.025,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t known_named_decoding_epochs_type=['pbe', 'laps'],\n",
    "    masked_time_bin_fill_type='ignore',\n",
    "    # masked_time_bin_fill_type='dropped',\n",
    "    data_grain= 'per_time_bin'))        \n",
    "        \n",
    "flat_decoded_marginal_posterior_df_context_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8390426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_matching_context, a_result, a_decoder, a_decoded_time_bin_marginal_posterior_df = a_new_fully_generic_result.get_results_matching_contexts(context_query=IdentifyingContext(trained_compute_epochs='laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'global', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'), return_multiple_matches=False)\n",
    "best_matching_context, a_result, a_decoder, a_decoded_time_bin_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=IdentifyingContext(trained_compute_epochs='laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type='laps',\n",
    "    masked_time_bin_fill_type='ignore',\n",
    "    # masked_time_bin_fill_type='dropped',\n",
    "    data_grain= 'per_time_bin'))\n",
    "\n",
    "a_decoded_time_bin_marginal_posterior_df\n",
    "\n",
    "## OUTPUTS: a_decoded_time_bin_marginal_posterior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592a128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_matching_context, a_result, a_decoder, a_decoded_time_bin_marginal_posterior_df = a_new_fully_generic_result.get_results_matching_contexts(context_query=IdentifyingContext(trained_compute_epochs='laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'global', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'), return_multiple_matches=False)\n",
    "best_matching_context, a_result, a_decoder, a_decoded_time_bin_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=IdentifyingContext(trained_compute_epochs='laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type='pbe',\n",
    "    masked_time_bin_fill_type='ignore',\n",
    "    # masked_time_bin_fill_type='dropped',\n",
    "    data_grain= 'per_time_bin'))\n",
    "\n",
    "a_decoded_time_bin_marginal_posterior_df\n",
    "\n",
    "## OUTPUTS: a_decoded_time_bin_marginal_posterior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729d8a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(list(a_decoded_time_bin_marginal_posterior_df.columns)) # ['P_LR', 'P_RL', 'P_Long', 'P_Short', 'long_LR', 'long_RL', 'short_LR', 'short_RL', 'result_t_bin_idx', 'epoch_df_idx', 'parent_epoch_label', 'label', 'start', 't_bin_center', 'stop', 'delta_aligned_start_t', 'session_name', 'time_bin_size', 'pre_post_delta_category', 'trained_compute_epochs', 'pfND_ndim', 'decoder_identifier', 'known_named_decoding_epochs_type', 'masked_time_bin_fill_type', 'data_grain', 'is_t_bin_center_fake', 'rolling_avg_P_Short', 'mean_P_Short']\n",
    "broken_columns_dict = {IdentifyingContext(known_named_decoding_epochs_type= 'global', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'): ['result_t_bin_idx', 'epoch_df_idx', 'parent_epoch_label'],\n",
    "                      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses.time_bin_aggregation import TimeBinAggregation\n",
    "\n",
    "## INPUTS: a_decoded_time_bin_marginal_posterior_df\n",
    "\n",
    "n_rolling_avg_window_tbins: int = 3\n",
    "# Create a copy to avoid modifying the original\n",
    "result_df = a_decoded_time_bin_marginal_posterior_df.copy()\n",
    "epoch_partitioned_dfs_dict = a_decoded_time_bin_marginal_posterior_df.pho.partition_df_dict(partitionColumn='parent_epoch_label')\n",
    "\n",
    "# Process each partition\n",
    "for k, df in epoch_partitioned_dfs_dict.items():\n",
    "    rolling_avg = TimeBinAggregation.ToPerEpoch.peak_rolling_avg(df=df, column='P_Short', window=n_rolling_avg_window_tbins)    \n",
    "    # Calculate the mean of P_Short for this group\n",
    "    mean_p_short = TimeBinAggregation.ToPerEpoch.mean(df=df, column='P_Short')\n",
    "\n",
    "    # Get indices from this partition\n",
    "    indices = df.index\n",
    "    # Assign the result to the corresponding rows in the result dataframe\n",
    "    result_df.loc[indices, 'rolling_avg_P_Short'] = rolling_avg\n",
    "    result_df.loc[indices, 'mean_P_Short'] = mean_p_short  # Same mean value for all rows in group\n",
    "    \n",
    "    # result_df.loc[indices\n",
    "\n",
    "## OUTPUTS: result_df\n",
    "\n",
    "a_decoded_time_bin_marginal_posterior_df = deepcopy(result_df)\n",
    "a_decoded_time_bin_marginal_posterior_df\n",
    "\n",
    "# Then keep only the first entry for each 'parent_epoch_label'\n",
    "a_decoded_per_epoch_marginals_df = a_decoded_time_bin_marginal_posterior_df.groupby('parent_epoch_label').first().reset_index()\n",
    "a_decoded_per_epoch_marginals_df\n",
    "\n",
    "## OUTPUTS: a_decoded_time_bin_marginal_posterior_df, a_decoded_per_epoch_marginals_df\n",
    "## Columns of interest: 'rolling_avg_P_Short'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bc734a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses.time_bin_aggregation import TimeBinAggregation\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "\n",
    "a_decoded_per_epoch_marginals_df, a_decoded_time_bin_marginal_posterior_df = GenericDecoderDictDecodedEpochsDictResult._perform_per_epoch_time_bin_aggregation(a_decoded_time_bin_marginal_posterior_df=a_decoded_time_bin_marginal_posterior_df, probabilitY_column_to_aggregate='P_Short', n_rolling_avg_window_tbins=3)\n",
    "\n",
    "a_decoded_time_bin_marginal_posterior_df\n",
    "a_decoded_per_epoch_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae48cb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext, CollisionOutcome\n",
    "from neuropy.analyses.time_bin_aggregation import TimeBinAggregation\n",
    "\n",
    "## get all non-global, `data_grain= 'per_time_bin'`\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=IdentifyingContext(trained_compute_epochs='laps', decoder_identifier='pseudo2D', time_bin_size=0.025,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t known_named_decoding_epochs_type=['pbe', 'laps'],\n",
    "    masked_time_bin_fill_type=('ignore', 'dropped'),\n",
    "    # masked_time_bin_fill_type='dropped',\n",
    "    data_grain= 'per_time_bin'))        \n",
    "\n",
    "\n",
    "\n",
    "_newly_updated_values_tuple = a_new_fully_generic_result.compute_all_per_epoch_aggregations_from_per_time_bin_results(flat_decoded_marginal_posterior_df_context_dict=flat_decoded_marginal_posterior_df_context_dict)\n",
    "per_time_bin_to_per_epoch_context_map_dict, flat_decoded_marginal_posterior_df_per_epoch_marginals_df_context_dict, flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict = _newly_updated_values_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fdc5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if TimeBinAggegreations are performed:\n",
    "per_time_bin_flat_context_list, per_time_bin_flat_result_context_dict, per_time_bin_flat_decoder_context_dict, per_time_bin_flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=IdentifyingContext(trained_compute_epochs='laps', decoder_identifier='pseudo2D', known_named_decoding_epochs_type=['pbe', 'laps'], data_grain= 'per_time_bin'))        \n",
    "per_time_bin_keys = list(per_time_bin_flat_decoded_marginal_posterior_df_context_dict.keys())\n",
    "\n",
    "## get all non-global, `data_grain= 'per_time_bin'`\n",
    "per_epoch_flat_context_list, per_epoch_flat_result_context_dict, per_epoch_flat_decoder_context_dict, per_epoch_flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=IdentifyingContext(trained_compute_epochs='laps', decoder_identifier='pseudo2D', known_named_decoding_epochs_type=['pbe', 'laps'], data_grain= 'per_epoch'))        \n",
    "per_epoch_keys = list(per_epoch_flat_decoded_marginal_posterior_df_context_dict.keys())\n",
    "len(per_time_bin_keys) == len(per_epoch_keys)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5a33a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## INPUTS: flat_decoded_marginal_posterior_df_context_dict\n",
    "per_time_bin_to_per_epoch_context_map_dict = {}\n",
    "flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict = {}\n",
    "flat_decoded_marginal_posterior_df_per_epoch_marginals_df_context_dict = {}\n",
    "for a_per_time_bin_ctxt, a_decoded_time_bin_marginal_posterior_df in flat_decoded_marginal_posterior_df_context_dict.items():\n",
    "    a_decoded_per_epoch_marginals_df, a_decoded_time_bin_marginal_posterior_df = GenericDecoderDictDecodedEpochsDictResult._perform_per_epoch_time_bin_aggregation(a_decoded_time_bin_marginal_posterior_df=a_decoded_time_bin_marginal_posterior_df, probabilitY_column_to_aggregate='P_Short', n_rolling_avg_window_tbins=3)\n",
    "    a_per_epoch_ctxt = TimeBinAggregation.ToPerEpoch.get_per_epoch_ctxt_from_per_time_bin_ctxt(a_per_time_bin_ctxt=a_per_time_bin_ctxt)\n",
    "    per_time_bin_to_per_epoch_context_map_dict[a_per_time_bin_ctxt] = a_per_epoch_ctxt\n",
    "    flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict[a_per_time_bin_ctxt] = deepcopy(a_decoded_time_bin_marginal_posterior_df)\n",
    "    flat_decoded_marginal_posterior_df_per_epoch_marginals_df_context_dict[a_per_epoch_ctxt] = a_decoded_per_epoch_marginals_df\n",
    "\n",
    "\n",
    "## OUTPUTS: per_time_bin_to_per_epoch_context_map_dict, flat_decoded_marginal_posterior_df_per_epoch_marginals_df_context_dict, flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict\n",
    "flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict\n",
    "flat_decoded_marginal_posterior_df_per_epoch_marginals_df_context_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f9ca7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: per_time_bin_to_per_epoch_context_map_dict, flat_decoded_marginal_posterior_df_per_epoch_marginals_df_context_dict, flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict\n",
    "# flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict\n",
    "# flat_decoded_marginal_posterior_df_per_epoch_marginals_df_context_dict\n",
    "\n",
    "for a_per_time_bin_ctxt, a_decoded_time_bin_marginal_posterior_df in flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict.items():\n",
    "    a_per_epoch_ctxt = per_time_bin_to_per_epoch_context_map_dict[a_per_time_bin_ctxt]\n",
    "    a_decoded_time_bin_marginal_posterior_df = flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict[a_per_time_bin_ctxt]\n",
    "    a_decoded_per_epoch_marginals_df = flat_decoded_marginal_posterior_df_per_epoch_marginals_df_context_dict[a_per_epoch_ctxt]\n",
    "    a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict[a_per_time_bin_ctxt] = a_decoded_time_bin_marginal_posterior_df\n",
    "    a_best_matching_context, a_result, a_decoder, a_decoded_time_bin_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(a_per_time_bin_ctxt)\n",
    "    # a_best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_matching_context(a_per_time_bin_ctxt, return_multiple_matches=False)\n",
    "    # a_result\n",
    "    print(f'updating: \"{a_per_epoch_ctxt}\"')\n",
    "    print(f\"\\tWARN: TODO 2025-04-07 19:22: - [ ] a_result is wrong, it's the per-time-bin version not the per-epoch version\") #TODO 2025-04-07 19:22: - [ ] a_result is wrong, it's the per-time-bin version not the per-epoch version\n",
    "\n",
    "    ## need to get updated a_decoder, a_result\n",
    "    \n",
    "    # a_dropping_masked_pseudo2D_continuous_specific_decoded_result, _dropping_mask_index_tuple = a_result.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(spikes_df=deepcopy(spikes_df), masked_bin_fill_mode=a_masked_bin_fill_mode) ## Masks the low-firing bins so they don't confound the analysis.\n",
    "    # ## Computes marginals for `dropping_masked_laps_pseudo2D_continuous_specific_decoded_result`\n",
    "    # a_dropping_masked_decoded_marginal_posterior_df = DirectionalPseudo2DDecodersResult.perform_compute_specific_marginals(a_result=a_dropping_masked_pseudo2D_continuous_specific_decoded_result, marginal_context=a_masked_updated_context)\n",
    "    a_new_fully_generic_result.updating_results_for_context(new_context=a_per_epoch_ctxt, a_result=deepcopy(a_result), a_decoder=deepcopy(a_decoder), a_decoded_marginal_posterior_df=deepcopy(a_decoded_per_epoch_marginals_df)) ## update using the result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd3ce45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a_new_fully_generic_result.updating_results_for_context(new_context=a_masked_updated_context, a_result=deepcopy(a_dropping_masked_pseudo2D_continuous_specific_decoded_result), a_decoder=deepcopy(a_decoder), a_decoded_marginal_posterior_df=deepcopy(a_dropping_masked_decoded_marginal_posterior_df)) ## update using the result\n",
    "\n",
    "\n",
    "## INPUTS: a_new_fully_generic_result\n",
    "base_contexts_list = [IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=time_bin_size, known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='ignore', data_grain='per_time_bin'),\n",
    "                    IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=time_bin_size, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore', data_grain='per_time_bin'),\n",
    "                    IdentifyingContext(trained_compute_epochs='non_pbe', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=time_bin_size, known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='ignore', data_grain='per_time_bin'),\n",
    "                    IdentifyingContext(trained_compute_epochs='non_pbe', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=time_bin_size, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore', data_grain='per_time_bin')]\n",
    "masked_contexts_dict = {}\n",
    "\n",
    "for a_base_context in base_contexts_list:\n",
    "\n",
    "    a_best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_matching_contexts(a_base_context, return_multiple_matches=False)\n",
    "    ## `a_decoder` is None for some reason?`\n",
    "    ## INPUTS: a_result, masked_bin_fill_mode\n",
    "    a_masked_updated_context: IdentifyingContext = deepcopy(a_best_matching_context).overwriting_context(masked_time_bin_fill_type=a_masked_bin_fill_mode, data_grain='per_time_bin')\n",
    "    masked_contexts_dict[a_base_context] = a_masked_updated_context\n",
    "    if debug_print:\n",
    "        print(f'a_masked_updated_context: {a_masked_updated_context}')\n",
    "    \n",
    "    ## MASKED with NaNs (no backfill):\n",
    "    a_dropping_masked_pseudo2D_continuous_specific_decoded_result, _dropping_mask_index_tuple = a_result.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(spikes_df=deepcopy(spikes_df), masked_bin_fill_mode=a_masked_bin_fill_mode) ## Masks the low-firing bins so they don't confound the analysis.\n",
    "    ## Computes marginals for `dropping_masked_laps_pseudo2D_continuous_specific_decoded_result`\n",
    "    a_dropping_masked_decoded_marginal_posterior_df = DirectionalPseudo2DDecodersResult.perform_compute_specific_marginals(a_result=a_dropping_masked_pseudo2D_continuous_specific_decoded_result, marginal_context=a_masked_updated_context)\n",
    "    a_new_fully_generic_result.updating_results_for_context(new_context=a_masked_updated_context, a_result=deepcopy(a_dropping_masked_pseudo2D_continuous_specific_decoded_result), a_decoder=deepcopy(a_decoder), a_decoded_marginal_posterior_df=deepcopy(a_dropping_masked_decoded_marginal_posterior_df)) ## update using the result\n",
    "    \n",
    "## OUTPUTS: masked_contexts_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4273d42a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c76f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import build_single_plotly_marginal_scatter_and_hist_over_time\n",
    "\n",
    "## INPUTS: a_decoded_time_bin_marginal_posterior_df\n",
    "#INPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder\n",
    "_flat_out_figs_dict = {}\n",
    "# a_target_context = curr_active_pipeline.build_display_context_for_filtered_session(filtered_session_name='maze_any', display_fn_name='DirectionalMergedDecoders')\n",
    "a_target_context = curr_active_pipeline.build_display_context_for_session(display_fn_name='a_decoded_time_bin_marginal_posterior_df', time_bin_size=0.025)\n",
    "a_fig, a_figure_context = build_single_plotly_marginal_scatter_and_hist_over_time(a_decoded_posterior_df=a_decoded_time_bin_marginal_posterior_df, a_target_context=a_target_context, y='P_Short')\n",
    "_flat_out_figs_dict[a_figure_context] = a_fig\n",
    "\n",
    "a_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d75da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import build_single_plotly_marginal_scatter_and_hist_over_time\n",
    "\n",
    "## INPUTS: a_decoded_per_epoch_marginals_df\n",
    "#INPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder\n",
    "y_var_name: str = 'rolling_avg_P_Short'\n",
    "_flat_out_figs_dict = {}\n",
    "# a_target_context = curr_active_pipeline.build_display_context_for_filtered_session(filtered_session_name='maze_any', display_fn_name='DirectionalMergedDecoders')\n",
    "a_target_context = curr_active_pipeline.build_display_context_for_session(display_fn_name='a_decoded_per_epoch_marginals_df', time_bin_size=0.025)\n",
    "a_fig, a_figure_context = build_single_plotly_marginal_scatter_and_hist_over_time(a_decoded_posterior_df=a_decoded_per_epoch_marginals_df, a_target_context=a_target_context, y=y_var_name)\n",
    "_flat_out_figs_dict[a_figure_context] = a_fig\n",
    "\n",
    "a_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ce3de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder\n",
    "_flat_out_figs_dict = {}\n",
    "# a_target_context = curr_active_pipeline.build_display_context_for_filtered_session(filtered_session_name='maze_any', display_fn_name='DirectionalMergedDecoders')\n",
    "a_target_context = curr_active_pipeline.build_display_context_for_session(display_fn_name='laps_per_epoch_marginals_df', time_bin_size=0.025)\n",
    "a_fig, a_figure_context = build_single_plotly_marginal_scatter_and_hist_over_time(a_decoded_posterior_df=laps_per_epoch_marginals_df, a_target_context=a_target_context)\n",
    "_flat_out_figs_dict[a_figure_context] = a_fig\n",
    "\n",
    "a_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a467e0bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca9e4656",
   "metadata": {},
   "source": [
    "# 2025-04-11 - Full-session decoded marginal outputs as yellow-blue plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421fcd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _plot_all_time_decoded_marginal_figures\n",
    "\n",
    "\n",
    "## INPUTS: a_new_fully_generic_result\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='nan_filled', data_grain='per_time_bin')\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='ignore', data_grain='per_time_bin')\n",
    "best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=a_target_context, debug_print=False)\n",
    "epochs_decoding_time_bin_size = best_matching_context.get('time_bin_size', None)\n",
    "assert epochs_decoding_time_bin_size is not None\n",
    "\n",
    "## INPUTS: spike_raster_window, active_2d_plot\n",
    "_all_tracks_active_out_figure_paths, _all_tracks_out_artists, _all_tracks_out_axes = _plot_all_time_decoded_marginal_figures(curr_active_pipeline=curr_active_pipeline, best_matching_context=best_matching_context, a_decoded_marginal_posterior_df=a_decoded_marginal_posterior_df, spike_raster_window=spike_raster_window, active_2d_plot=active_2d_plot, epochs_decoding_time_bin_size=epochs_decoding_time_bin_size)\n",
    "_all_tracks_active_out_figure_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d24974",
   "metadata": {},
   "source": [
    "# 🔶 2025-01-15 - Lap Transition Matrix Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b1c34e",
   "metadata": {
    "tags": [
     "run-group-transition-matricies"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import TransitionMatrixComputations\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalDecodersContinuouslyDecodedResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import plot_blocked_transition_matrix\n",
    "from neuropy.utils.matplotlib_helpers import perform_update_title_subtitle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import _perform_plot_P_Context_State_Transition_Matrix, _perform_plot_position_Transition_Matrix\n",
    "\n",
    "# desired_time_bin_size = 0.050 # 50ms\n",
    "desired_time_bin_size = 0.025 # 25ms\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'], computation_kwargs_list=[{'time_bin_size': desired_time_bin_size, 'should_disable_cache': False}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "\n",
    "\n",
    "## Uses the `global_computation_results.computed_data['DirectionalDecodersDecoded']`\n",
    "directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "# all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "pseudo2D_decoder: BasePositionDecoder = directional_decoders_decode_result.pseudo2D_decoder\n",
    "\n",
    "# all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "continuously_decoded_pseudo2D_decoder_dict = directional_decoders_decode_result.continuously_decoded_pseudo2D_decoder_dict\n",
    "# continuously_decoded_result_cache_dict\n",
    "continuously_decoded_pseudo2D_decoder_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab688a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import EpochComputationFunctions, EpochComputationsComputationsContainer\n",
    "from neuropy.utils.mixins.binning_helpers import BinningContainer, BinningInfo\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import complete_all_transition_matricies, build_transition_matricies\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import split_transition_matricies_results_pre_post_delta_category\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import LongShortTrackDataframeAccessor\n",
    "\n",
    "valid_EpochComputations_result: EpochComputationsComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['EpochComputations']\n",
    "a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult = valid_EpochComputations_result.a_generic_decoder_dict_decoded_epochs_dict_result\n",
    "\n",
    "\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.050, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore') # , decoder_identifier='long_LR'\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore', data_grain='per_epoch') # , time_bin_size=0.050, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore', decoder_identifier='long_LR'\n",
    "\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='ignore', data_grain='per_epoch') ## Laps\n",
    "# any_matching_contexts_list, result_context_dict, decoder_context_dict, decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context)\n",
    "\n",
    "# common_constraint_dict = dict(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, masked_time_bin_fill_type='ignore')\n",
    "common_constraint_dict = dict(trained_compute_epochs='laps', time_bin_size=0.025, masked_time_bin_fill_type='nan_filled') # , pfND_ndim=1\n",
    "\n",
    "## Laps context:\n",
    "a_laps_target_context: IdentifyingContext = IdentifyingContext(known_named_decoding_epochs_type='laps', **common_constraint_dict, data_grain='per_epoch') ## Laps\n",
    "laps_target_context_results = complete_all_transition_matricies(a_new_fully_generic_result=a_new_fully_generic_result, a_target_context=a_laps_target_context)\n",
    "laps_matched_result_tuple_context_dict, (laps_time_bin_container_context_dict, laps_position_transition_matrix_context_dict, laps_context_state_transition_matrix_context_dict, laps_combined_transition_matrix_context_dict), (laps_mean_context_state_transition_matrix_context_dict, laps_mean_position_transition_matrix_context_dict) = laps_target_context_results\n",
    "# a_best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = out_matched_result_tuple_context_dict[a_ctxt]\n",
    "a_laps_best_matching_context, a_laps_result, a_laps_decoder, a_laps_decoded_marginal_posterior_df = list(laps_matched_result_tuple_context_dict.values())[0] # [-1]\n",
    "\n",
    "## PBEs context:\n",
    "a_PBEs_target_context: IdentifyingContext = IdentifyingContext(known_named_decoding_epochs_type='pbe', **common_constraint_dict, data_grain='per_epoch') ## Laps\n",
    "pbes_target_context_results = complete_all_transition_matricies(a_new_fully_generic_result=a_new_fully_generic_result, a_target_context=a_PBEs_target_context)\n",
    "pbes_matched_result_tuple_context_dict, (pbes_time_bin_container_context_dict, pbes_position_transition_matrix_context_dict, pbes_context_state_transition_matrix_context_dict, pbes_combined_transition_matrix_context_dict), (pbes_mean_context_state_transition_matrix_context_dict, pbes_mean_position_transition_matrix_context_dict) = pbes_target_context_results\n",
    "a_pbes_best_matching_context, a_pbes_result, a_pbes_decoder, a_pbes_decoded_marginal_posterior_df = list(pbes_matched_result_tuple_context_dict.values())[0] # [-1] # pbes_matched_result_tuple_context_dict[a_PBEs_target_context]\n",
    "## INPUTS: laps_context_state_transition_matrix_context_dict\n",
    "out_context_state_transition_matrix_context_dict = deepcopy(laps_context_state_transition_matrix_context_dict)\n",
    "out_matched_result_tuple_context_dict = deepcopy(laps_matched_result_tuple_context_dict)\n",
    "\n",
    "an_out_best_matching_context, an_out_result, an_out_decoder, an_out_decoded_marginal_posterior_df = list(out_matched_result_tuple_context_dict.values())[0] # [-1]\n",
    "a_context_state_transition_matrix_list: List[NDArray] = list(out_context_state_transition_matrix_context_dict.values())[0]\n",
    "\n",
    "## INPUTS: an_out_decoded_marginal_posterior_df, a_context_state_transition_matrix_list\n",
    "a_mean_context_state_transition_matrix_dict = split_transition_matricies_results_pre_post_delta_category(an_out_decoded_marginal_posterior_df=an_out_decoded_marginal_posterior_df, a_context_state_transition_matrix_list=a_context_state_transition_matrix_list)\n",
    "a_mean_context_state_transition_matrix_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66cab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_laps_decoder: BasePositionDecoder = deepcopy(a_laps_decoder)\n",
    "a_laps_decoder.pf.plot_occupancy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4337b537",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.plotting.placemaps import plot_placefield_occupancy, perform_plot_occupancy\n",
    "\n",
    "valid_EpochComputations_result: EpochComputationsComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['EpochComputations']\n",
    "a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult = valid_EpochComputations_result.a_generic_decoder_dict_decoded_epochs_dict_result\n",
    "\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.050, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore') # , decoder_identifier='long_LR'\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore', data_grain='per_epoch') # , time_bin_size=0.050, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore', decoder_identifier='long_LR'\n",
    "\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='ignore', data_grain='per_epoch') ## Laps\n",
    "# any_matching_contexts_list, result_context_dict, decoder_context_dict, decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context)\n",
    "\n",
    "# common_constraint_dict = dict(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, masked_time_bin_fill_type='ignore')\n",
    "common_constraint_dict = dict(trained_compute_epochs='laps', time_bin_size=0.025, masked_time_bin_fill_type='nan_filled') # , pfND_ndim=1\n",
    "\n",
    "## Laps context:\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(known_named_decoding_epochs_type='laps', data_grain='per_time_bin', **common_constraint_dict) ## Laps , data_grain='per_epoch'\n",
    "best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=a_target_context)\n",
    "\n",
    "# ## Global context:\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(known_named_decoding_epochs_type='global', data_grain='per_time_bin', **common_constraint_dict) ## Laps , data_grain='per_epoch'\n",
    "best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=a_target_context)\n",
    "\n",
    "\n",
    "\n",
    "# # a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=0.025, masked_time_bin_fill_type='last_valid', data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps'\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=0.025, masked_time_bin_fill_type='ignore', data_grain='per_time_bin', known_named_decoding_epochs_type= 'global') # , known_named_decoding_epochs_type='laps'\n",
    "# flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "# # print(f'flat_context_list: {flat_context_list}')\n",
    "# flat_decoded_marginal_posterior_df_context_dict\n",
    "\n",
    "\n",
    "# best_matching_context\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d0e184",
   "metadata": {},
   "source": [
    "## 2025-05-15 - Decoded vs Measured Occupancy\n",
    "- [ ] wrap in normal matplotlib-specific decoration/output code to add session_name footer, enable saving to file, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3bf977",
   "metadata": {
    "tags": [
     "2025-05-15_decoded_vs_measured_occupancy"
    ]
   },
   "outputs": [],
   "source": [
    "# MeasuredVsDecodedOccupancy._display_measured_vs_decoded_occupancy_distributions(owning_pipeline_reference=curr_active_pipeline, \n",
    "\n",
    "# _display_measured_vs_decoded_occupancy_distributions\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "_out = curr_active_pipeline.display('_display_measured_vs_decoded_occupancy_distributions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75adb632",
   "metadata": {},
   "source": [
    "## ⚓🎯 2025-05-15 - Within-epoch transition and run-length sequence analyis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00371dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import WithinEpochTimeBinDynamics, TimeBinCategorization\n",
    "\n",
    "\n",
    "sequence_dwell_epochs_df = WithinEpochTimeBinDynamics.analyze_subsequence_temporal_dynamics(curr_active_pipeline, time_bin_size=0.025)\n",
    "# sequence_dwell_epochs_df = WithinEpochTimeBinDynamics.analyze_subsequence_temporal_dynamics(curr_active_pipeline, time_bin_size=0.050)\n",
    "# int_column_names = [k for k in sequence_dwell_epochs_df.columns if k.startswith('n_')]\n",
    "\n",
    "# sequence_dwell_epochs_df.infer_objects()\n",
    "sequence_dwell_epochs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ba557a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(sequence_dwell_epochs_df.columns)) # ['epoch_start_t', 'epoch_end_t', 'epoch_label', 'pre_post_delta_category', 'pre_post_delta_id', 'delta_aligned_start_t', 'n_t_bins', 'n_transitions', 'mean_len.pLONG', 'mean_len.pSHORT', 'mean_len.MIXED', 'var_len.pLONG', 'var_len.pSHORT', 'var_len.MIXED', 'n_bins.pLONG', 'n_bins.pSHORT', 'n_bins.MIXED', 'lengths', 'bins_ratio.pLONG', 'bins_ratio.pSHORT', 'bins_ratio.MIXED']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0d796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_post_split_sequence_dwell_epochs_df_dict = sequence_dwell_epochs_df.pho.partition_df_dict('pre_post_delta_category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232c86a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_post_split_sequence_dwell_epochs_df_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1307d2d3",
   "metadata": {},
   "source": [
    "I have a df `sequence_dwell_epochs_df` with many numeric columns that I want to compare histograms for, based on their category in column 'pre_post_delta_category' (with a histogram plotted for each value in this column, for each variable)\n",
    "\n",
    "numeric_col_of_interest_names = ['n_t_bins', 'n_transitions', 'mean_len.pLONG', 'mean_len.pSHORT', 'mean_len.MIXED', 'var_len.pLONG', 'var_len.pSHORT', 'var_len.MIXED', 'n_bins.pLONG', 'n_bins.pSHORT', 'n_bins.MIXED', 'bins_ratio.pLONG', 'bins_ratio.pSHORT', 'bins_ratio.MIXED']\n",
    "\n",
    "write valid python code to plot a stack of these histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9695fc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "numeric_col_of_interest_names = ['n_t_bins', 'n_transitions', 'mean_len.pLONG', 'mean_len.pSHORT', 'mean_len.MIXED', 'var_len.pLONG', 'var_len.pSHORT', 'var_len.MIXED', 'n_bins.pLONG', 'n_bins.pSHORT', 'n_bins.MIXED', 'bins_ratio.pLONG', 'bins_ratio.pSHORT', 'bins_ratio.MIXED']\n",
    "\n",
    "cols=numeric_col_of_interest_names\n",
    "cats=sequence_dwell_epochs_df['pre_post_delta_category'].dropna().unique()\n",
    "fig, axes=plt.subplots(len(cols),1,figsize=(8,2*len(cols)), num='temporal_decoding_dynamics_within_bins', clear=True)\n",
    "\n",
    "for ax, col in zip(axes,cols):\n",
    "    for cat in cats:\n",
    "        ax.hist(sequence_dwell_epochs_df.loc[sequence_dwell_epochs_df['pre_post_delta_category']==cat,col].dropna(), \n",
    "                alpha=0.5,label=cat, bins=25)\n",
    "    ax.set_title(col)\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3573ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# render_scrollable_colored_table_from_dataframe(sequence_dwell_epochs_df, cmap_name='plasma', max_height=500, width='80%') # , cmap_name=cmap_name, max_height=max_height, width=width, **kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2c6523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch_split_df_dict    \n",
    "\n",
    "results\n",
    "\n",
    "# epoch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7c3549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "from scipy.stats import mannwhitneyu, poisson, fisher_exact\n",
    "\n",
    "def compare_epoch_dynamics(cond1: List[Dict], cond2: List[Dict]) -> Dict:\n",
    "    \"\"\"\n",
    "    Given two lists of analyze_epoch_dynamics outputs (one per condition),\n",
    "    computes:\n",
    "      - mean±sem of n_transitions\n",
    "      - Mann–Whitney U test on n_transitions\n",
    "      - pooled dwell times per state and MWU test per state\n",
    "    Returns dict with stats.\n",
    "    \"\"\"\n",
    "    def sem(x): return np.std(x, ddof=1)/np.sqrt(len(x))\n",
    "    \n",
    "    # extract transitions\n",
    "    t1 = np.array([e['transitions'] for e in cond1])\n",
    "    t2 = np.array([e['transitions'] for e in cond2])\n",
    "    \n",
    "    # extract dwell times per state\n",
    "    def gather(cond, state):\n",
    "        return np.concatenate([e['subsequences'][state] for e in cond]) or np.array([])\n",
    "    stats = {'transitions': {\n",
    "                 'cond1_mean_sem': (t1.mean(), sem(t1)),\n",
    "                 'cond2_mean_sem': (t2.mean(), sem(t2)),\n",
    "                 'mw_u': mannwhitneyu(t1, t2, alternative='two-sided').statistic,\n",
    "                 'mw_p': mannwhitneyu(t1, t2, alternative='two-sided').pvalue\n",
    "             }}\n",
    "    \n",
    "    for state in ['pure.Long','pure.Short','mixed']:\n",
    "        d1 = gather(cond1, state)\n",
    "        d2 = gather(cond2, state)\n",
    "        u, p = mannwhitneyu(d1, d2, alternative='two-sided')\n",
    "        stats[state] = {\n",
    "            'cond1_n': len(d1), 'cond2_n': len(d2),\n",
    "            'cond1_mean_sem': (d1.mean() if d1.size else np.nan, sem(d1) if d1.size>1 else np.nan),\n",
    "            'cond2_mean_sem': (d2.mean() if d2.size else np.nan, sem(d2) if d2.size>1 else np.nan),\n",
    "            'mw_u': u, 'mw_p': p\n",
    "        }\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80999256",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_result['parent_epoch_label']\n",
    "\n",
    "a_decoded_marginal_posterior_df\n",
    "P_Long_df = a_decoded_marginal_posterior_df[['start', 'stop', 'P_Long']]\n",
    "P_Long_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46a5fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = analyze_epoch_dynamics(p_long=p_long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44323891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0bfebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b85914ba",
   "metadata": {},
   "source": [
    "## -[ ] Lap Transition Matrix vs. PBEs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09796af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_time_bin_container.centers\n",
    "a_time_bin_container.left_edges\n",
    "a_time_bin_container.right_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7458e721",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_context_state_transition_matrix: NDArray = np.stack(out_context_state_transition_matrix_context_dict[a_ctxt]) # np.stack(out_context_state_transition_matrix_context_dict[a_ctxt]).shape\n",
    "a_mean_context_state_transition_matrix: NDArray = np.nanmean(a_context_state_transition_matrix, axis=0) #.shape (4, 4)\n",
    "a_mean_context_state_transition_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312814dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs_decoding_time_bin_size: float = 0.025\n",
    "epochs_decoding_time_bin_size: float = 0.025\n",
    "\n",
    "_all_tracks_out_artists = {}\n",
    "for a_ctxt, a_df in flat_decoded_marginal_posterior_df_context_dict.items():\n",
    "    time_bin_size = epochs_decoding_time_bin_size\n",
    "    info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "    plot_row_identifier: str = a_ctxt.get_description(subset_includelist=['known_named_decoding_epochs_type', 'masked_time_bin_fill_type'], include_property_names=True, key_value_separator=':', separator='|', replace_separator_in_property_names='-')\n",
    "    a_time_window_centers = a_df['t_bin_center'].to_numpy() \n",
    "    a_1D_posterior = a_df[['P_Long', 'P_Short']].to_numpy().T\n",
    "\n",
    "    identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dock_item = active_2d_plot.add_docked_marginal_track(name=plot_row_identifier, time_window_centers=a_time_window_centers, a_1D_posterior=a_1D_posterior, extended_dock_title_info=info_string)\n",
    "    _all_tracks_out_artists[identifier_name] = widget\n",
    "    intervals_overview_plot_item.setXRange(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time, padding=0) ## global frame\n",
    "    matplotlib_fig_axes[0].set_xlim(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time)\n",
    "    widget.draw()\n",
    "\n",
    "\n",
    "## Make a new matplotlib figure (in a new window) that contains a copy of `matplotlib_fig_axes` inserted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58d8df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _perform_compute_transition_matrix(continuously_decoded_pseudo2D_decoder_dict):\n",
    "    \"\"\" Computes the context state transition matrix from the continuous posteriors\n",
    "    \n",
    "    Usage:\n",
    "    \n",
    "    ## Uses the `global_computation_results.computed_data['DirectionalDecodersDecoded']`\n",
    "    directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "    # all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "    pseudo2D_decoder: BasePositionDecoder = directional_decoders_decode_result.pseudo2D_decoder\n",
    "\n",
    "    # all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "    continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "    continuously_decoded_pseudo2D_decoder_dict = directional_decoders_decode_result.continuously_decoded_pseudo2D_decoder_dict\n",
    "    # continuously_decoded_result_cache_dict\n",
    "    continuously_decoded_pseudo2D_decoder_dict\n",
    "\n",
    "    output_transition_matrix_dict = _perform_compute_transition_matrix(continuously_decoded_pseudo2D_decoder_dict=continuously_decoded_pseudo2D_decoder_dict)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    output_transition_matrix_dict = {}\n",
    "    \n",
    "    for a_time_bin_size, a_pseudo2D_decoder_continuously_decoded_result in continuously_decoded_pseudo2D_decoder_dict.items():\n",
    "        print(f'a_time_bin_size: {a_time_bin_size}')\n",
    "        # a_pseudo2D_decoder_continuously_decoded_result.active_filter_epochs\n",
    "        assert len(a_pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list) == 1\n",
    "        a_p_x_given_n = deepcopy(a_pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0])\n",
    "        ## OUTPUTS: a_p_x_given_n\n",
    "        \n",
    "        ## INPUTS: a_p_x_given_n\n",
    "        n_position_bins, n_decoding_models, n_time_bins = a_p_x_given_n.shape\n",
    "        \n",
    "        # 1. Determine the most likely model for each time bin\n",
    "        sum_over_positions = a_p_x_given_n.sum(axis=0)  # (n_decoding_models, n_time_bins)\n",
    "        best_model_each_bin = sum_over_positions.argmax(axis=0)  # (n_time_bins,)\n",
    "        print(f'best_model_each_bin.shape: {np.shape(best_model_each_bin)}')\n",
    "        # sum_over_positions.shape # (4, n_time_bins)\n",
    "        \n",
    "        sum_over_positions.shape\n",
    "        \n",
    "        # 2. Determine the most likely position for each time bin (conditional on chosen model)\n",
    "        best_position_each_bin = np.array([\n",
    "            p_x_given_n[:, best_model_each_bin[t], t].argmax()\n",
    "            for t in range(n_time_bins)\n",
    "        ])\n",
    "\n",
    "        print(f'best_position_each_bin: {np.shape(best_position_each_bin)}')\n",
    "        \n",
    "        # 2. Determine the most likely position for each time bin (conditional on chosen model)\n",
    "        a_model_p_x_given_n = np.array([\n",
    "            sum_over_positions[best_model_each_bin[t], t] / np.sum(sum_over_positions[:, t])\n",
    "            for t in range(n_time_bins)\n",
    "        ])\n",
    "\n",
    "\n",
    "        marginal_p_x_given_n_over_positions = deepcopy(sum_over_positions).T\n",
    "        print(f'marginal_p_x_given_n_over_positions: {np.shape(marginal_p_x_given_n_over_positions)}')\n",
    "        # marginal_p_x_given_n_over_positions = marginal_p_x_given_n_over_positions / np.nansum(marginal_p_x_given_n_over_positions, axis=-1, keepdims=True)\n",
    "        # marginal_p_x_given_n_over_positions\n",
    "        \n",
    "        # # Verify normalization (should be very close to 1.0 for all rows)\n",
    "        # verification = np.sum(marginal_p_x_given_n_over_positions, axis=-1)\n",
    "        # print(f\"Normalized sums: min={verification.min()}, max={verification.max()}\")\n",
    "\n",
    "\n",
    "        # Check for zeros or NaNs before normalization\n",
    "        sum_before_norm = np.nansum(marginal_p_x_given_n_over_positions, axis=-1, keepdims=True)\n",
    "        print(f\"Before normalization - min sum: {np.min(sum_before_norm)}, has NaNs: {np.isnan(sum_before_norm).any()}\")\n",
    "\n",
    "        # Safe normalization with handling for zeros\n",
    "        # Replace zeros with ones in the denominator to avoid division by zero\n",
    "        safe_sums = np.where(sum_before_norm == 0, 1.0, sum_before_norm)\n",
    "        marginal_p_x_given_n_over_positions = marginal_p_x_given_n_over_positions / safe_sums\n",
    "\n",
    "        # For rows that summed to zero, set all values to equal probabilities (e.g., 1/n)\n",
    "        zero_sum_rows = (sum_before_norm == 0).squeeze()\n",
    "        if np.any(zero_sum_rows):\n",
    "            n_models = marginal_p_x_given_n_over_positions.shape[-1]\n",
    "            equal_probs = np.ones(n_models) / n_models\n",
    "            # Apply equal probabilities to rows with zero sums\n",
    "            if zero_sum_rows.ndim > 0:  # If it's not a scalar\n",
    "                marginal_p_x_given_n_over_positions[zero_sum_rows] = equal_probs\n",
    "            else:\n",
    "                # Handle the case where there's only one row\n",
    "                marginal_p_x_given_n_over_positions[:] = equal_probs\n",
    "\n",
    "        # Verify normalization\n",
    "        verification = np.sum(marginal_p_x_given_n_over_positions, axis=-1)\n",
    "        print(f\"Normalized sums: min={verification.min()}, max={verification.max()}, has NaNs: {np.isnan(verification).any()}\")\n",
    "\n",
    "\n",
    "        ## OUTPUTS: marginal_p_x_given_n_over_positions (normalized)\n",
    "\n",
    "        # best_model_each_bin\n",
    "        # a_model_p_x_given_n = sum_over_positions[np.squeeze(best_model_each_bin), :]\n",
    "        # a_model_p_x_given_n.shape\n",
    "        # a_model_p_x_given_n\n",
    "        # transition_matrix: NDArray = TransitionMatrixComputations.estimate_transition_matrix_weighted_avg(state_probs=best_model_each_bin)\n",
    "        transition_matrix: NDArray = TransitionMatrixComputations.estimate_transition_matrix_weighted_avg(state_probs=marginal_p_x_given_n_over_positions)\n",
    "        \n",
    "        output_transition_matrix_dict[a_time_bin_size] = transition_matrix\n",
    "        # A_position, A_model, A_combined = TransitionMatrixComputations.build_position_by_decoder_transition_matrix(a_p_x_given_n)\n",
    "\n",
    "        # len(A_position)\n",
    "        # A_position[0].shape\n",
    "        # A_position[1].shape\n",
    "        # A_combined.shape\n",
    "        # A_model.shape\n",
    "        \n",
    "        ## Plotting:\n",
    "        # # plt.figure(figsize=(8,6)); sns.heatmap(A_big, cmap='viridis'); plt.title(\"Transition Matrix A_big\"); plt.show()\n",
    "        # plt.figure(figsize=(8,6)); sns.heatmap(A_position, cmap='viridis'); plt.title(\"Transition Matrix A_position\"); plt.show()\n",
    "        # plt.figure(figsize=(8,6)); sns.heatmap(A_model, cmap='viridis'); plt.title(\"Transition Matrix A_model\"); plt.show()\n",
    "\n",
    "        # plot_blocked_transition_matrix(A_combined, n_position_bins, n_decoding_models)\n",
    "\n",
    "    return output_transition_matrix_dict\n",
    "\n",
    "\n",
    "output_transition_matrix_dict = _perform_compute_transition_matrix(continuously_decoded_pseudo2D_decoder_dict=continuously_decoded_pseudo2D_decoder_dict)\n",
    "output_transition_matrix_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3740ad1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6)); sns.heatmap(output_transition_matrix_dict[0.05], cmap='viridis'); plt.title(\"Transition Matrix P_Context State\"); \n",
    "plt.xlabel('P[t+1]')\n",
    "plt.ylabel('P[t]')\n",
    "state_labels = ['Long_LR', 'Long_RL', 'Short_LR', 'Short_RL']\n",
    "plt.xticks(ticks=(np.arange(len(state_labels))+0.5), labels=state_labels)\n",
    "plt.yticks(ticks=(np.arange(len(state_labels))+0.5), labels=state_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b4ae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('P[t+1]')\n",
    "plt.ylabel('P[t]')\n",
    "\n",
    "state_labels = ['Long_LR', 'Long_RL', 'Short_LR', 'Short_RL']\n",
    "plt.xticks(ticks=(np.arange(len(state_labels))+0.5), labels=state_labels)\n",
    "plt.yticks(ticks=(np.arange(len(state_labels))+0.5), labels=state_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bd10f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "global_session = curr_active_pipeline.filtered_sessions[global_epoch_name]\n",
    "\n",
    "# global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps) # .trimmed_to_non_overlapping()\n",
    "global_laps_epochs_df = global_laps.to_dataframe()\n",
    "# active_test_epochs_df: pd.DataFrame = deepcopy(global_laps_epochs_df)\n",
    "global_laps_epochs_df\n",
    "debug_print = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fcdcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import find_epochs_overlapping_other_epochs\n",
    "\n",
    "## INPUTS: global_laps, continuously_decoded_pseudo2D_decoder_dict\n",
    "_out_split_pseudo2D_posteriors_dict = {}\n",
    "_out_split_pseudo2D_out_dict = {}\n",
    "pre_filtered_col_names = ['pre_filtered_most_likely_position_indicies', 'pre_filtered_most_likely_position'] # 'pre_filtered_time_bin_containers', 'pre_filtered_p_x_given_n', \n",
    "post_filtered_col_names = [a_col_name.removeprefix('pre_filtered_') for a_col_name in pre_filtered_col_names] # ['time_bin_containers', 'most_likely_position_indicies', 'most_likely_position']\n",
    "print(post_filtered_col_names)\n",
    "for a_time_bin_size, pseudo2D_decoder_continuously_decoded_result in continuously_decoded_pseudo2D_decoder_dict.items():\n",
    "    print(f'a_time_bin_size: {a_time_bin_size}')\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size] = {'pre_filtered_p_x_given_n': None, 'pre_filtered_time_bin_containers': None, 'pre_filtered_most_likely_position_indicies': None, 'pre_filtered_most_likely_position': None, \n",
    "                                                     'is_timebin_included': None, 'p_x_given_n': None} # , 'time_window_centers': None\n",
    "    # pseudo2D_decoder_continuously_decoded_result: DecodedFilterEpochsResult = continuously_decoded_dict.get('pseudo2D', None)\n",
    "    assert len(pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list) == 1\n",
    "    p_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0]\n",
    "    # p_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0]['p_x_given_n']\n",
    "    time_bin_containers = pseudo2D_decoder_continuously_decoded_result.time_bin_containers[0]\n",
    "    # time_window_centers = time_bin_containers.centers\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position_indicies'] = deepcopy(pseudo2D_decoder_continuously_decoded_result.most_likely_position_indicies_list[0])\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position'] = deepcopy(pseudo2D_decoder_continuously_decoded_result.most_likely_positions_list[0])\n",
    "    ## INPUTS: time_bin_containers, global_laps\n",
    "    left_edges = deepcopy(time_bin_containers.left_edges)\n",
    "    right_edges = deepcopy(time_bin_containers.right_edges)\n",
    "    continuous_time_binned_computation_epochs_df: pd.DataFrame = pd.DataFrame({'start': left_edges, 'stop': right_edges, 'label': np.arange(len(left_edges))})\n",
    "    is_timebin_included: NDArray = find_epochs_overlapping_other_epochs(epochs_df=continuous_time_binned_computation_epochs_df, epochs_df_required_to_overlap=deepcopy(global_laps))\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_p_x_given_n'] = p_x_given_n\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_time_bin_containers'] = time_bin_containers\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['is_timebin_included'] = is_timebin_included\n",
    "    continuous_time_binned_computation_epochs_df['is_in_laps'] = is_timebin_included\n",
    "    ## filter by whether it's included or not:\n",
    "    p_x_given_n = p_x_given_n[:, :, is_timebin_included]\n",
    "    # time_window_centers = \n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['p_x_given_n'] = p_x_given_n\n",
    "    # _out_split_pseudo2D_out_dict[a_time_bin_size]['time_window_centers'] = time_window_centers[is_timebin_included]\n",
    "    # p_x_given_n.shape # (62, 4, 209389)\n",
    "\n",
    "    ## Split across the 2nd axis to make 1D posteriors that can be displayed in separate dock rows:\n",
    "    assert p_x_given_n.shape[1] == 4, f\"expected the 4 pseudo-y bins for the decoder in p_x_given_n.shape[1]. but found p_x_given_n.shape: {p_x_given_n.shape}\"\n",
    "    # split_pseudo2D_posteriors_dict = {k:np.squeeze(p_x_given_n[:, i, :]) for i, k in enumerate(('long_LR', 'long_RL', 'short_LR', 'short_RL'))}\n",
    "    _out_split_pseudo2D_posteriors_dict[a_time_bin_size] = deepcopy(p_x_given_n)\n",
    "    \n",
    "    # for a_col_name in pre_filtered_col_names:\n",
    "    #     filtered_col_name = a_col_name.removeprefix('pre_filtered_')\n",
    "    #     print(f'a_col_name: {a_col_name}, filtered_col_name: {filtered_col_name}, shape: {np.shape(_out_split_pseudo2D_out_dict[a_time_bin_size][a_col_name])}')\n",
    "    #     _out_split_pseudo2D_out_dict[a_time_bin_size][filtered_col_name] = _out_split_pseudo2D_out_dict[a_time_bin_size][a_col_name][is_timebin_included, :]\n",
    "        \n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['most_likely_position_indicies'] = _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position_indicies'][:, is_timebin_included]\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['most_likely_position'] = _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position'][is_timebin_included, :]\n",
    "    \n",
    "\n",
    "p_x_given_n.shape # (n_position_bins, n_decoding_models, n_time_bins) - (57, 4, 29951)\n",
    "\n",
    "## OUTPUTS: _out_split_pseudo2D_posteriors_dict, _out_split_pseudo2D_out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e652de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo2D_decoder_continuously_decoded_result.most_likely_position_indicies_list[0].shape # (2, 6948)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69a7e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_split_pseudo2D_out_dict_p_x_given_x = {k:v['pre_filtered_p_x_given_n'] for k, v in _out_split_pseudo2D_out_dict.items()}\n",
    "_out_split_pseudo2D_out_dict_p_x_given_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d83ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_time_binned_computation_epochs_df = continuous_time_binned_computation_epochs_df[continuous_time_binned_computation_epochs_df['is_in_laps']].drop(columns=['is_in_laps'])\n",
    "continuous_time_binned_computation_epochs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b84b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import build_position_by_decoder_transition_matrix, plot_blocked_transition_matrix\n",
    "from neuropy.utils.matplotlib_helpers import perform_update_title_subtitle\n",
    "\n",
    "## INPUTS: _out_split_pseudo2D_posteriors_dict\n",
    "# a_time_bin_size: float = 0.025\n",
    "a_time_bin_size: float = 0.050\n",
    "# a_time_bin_size: float = 0.058\n",
    "# a_time_bin_size: float = 0.250\n",
    "# a_time_bin_size: float = 0.500\n",
    "# a_time_bin_size: float = 0.750\n",
    "\n",
    "print(f'{list(_out_split_pseudo2D_posteriors_dict.keys())}')\n",
    "\n",
    "p_x_given_n = _out_split_pseudo2D_posteriors_dict[a_time_bin_size]\n",
    "is_timebin_included = _out_split_pseudo2D_out_dict[a_time_bin_size]['is_timebin_included']\n",
    "pre_filtered_p_x_given_n = _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_p_x_given_n']\n",
    "pre_filtered_time_bin_containers = _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_time_bin_containers']\n",
    "pre_filtered_most_likely_position_indicies = _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position_indicies']\n",
    "most_likely_position_indicies = _out_split_pseudo2D_out_dict[a_time_bin_size]['most_likely_position_indicies']\n",
    "\n",
    "\n",
    "did_change = np.diff(is_timebin_included, n=1)\n",
    "split_indicies = np.where(did_change)[0] + 1 # the +1 compensates for the 0-based nature of the indicies, indicating we want to split BEFORE the specified index\n",
    "\n",
    "# lap_split_p_x_given_n_list = np.split(p_x_given_n, split_indicies, axis=-1) # split along the time-bin axis (-1)\n",
    "lap_split_p_x_given_n_list: List[NDArray] = np.split(pre_filtered_p_x_given_n, split_indicies, axis=-1) # split along the time-bin axis (-1)\n",
    "# lap_split_p_x_given_n_list\n",
    "\n",
    "pre_filtered_most_likely_position_indicies_x = np.squeeze(pre_filtered_most_likely_position_indicies[0, :])\n",
    "most_likely_position_indicies_x = np.squeeze(most_likely_position_indicies[0, :])\n",
    "# most_likely_position_indicies_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7fa3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6)); sns.histplot(pre_filtered_most_likely_position_indicies_x); perform_update_title_subtitle(title_string=f\"hist: pre_filtered_most_likely_position_indicies_x - t_bin: {a_time_bin_size}\"); plt.show();\n",
    "plt.figure(figsize=(8,6)); sns.histplot(most_likely_position_indicies_x); perform_update_title_subtitle(title_string=f\"hist: most_likely_position_indicies_x - t_bin: {a_time_bin_size}\"); plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3aa025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13514771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1441d2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: p_x_given_n\n",
    "n_position_bins, n_decoding_models, n_time_bins = p_x_given_n.shape\n",
    "\n",
    "out_tuples = [build_position_by_decoder_transition_matrix(a_p_x_given_n) for a_p_x_given_n in lap_split_p_x_given_n_list]\n",
    "\n",
    "A_position = [v[0] for i, v in enumerate(out_tuples) if (i % 2 == 1)]\n",
    "A_model = [v[1] for i, v in enumerate(out_tuples) if (i % 2 == 1)]\n",
    "A_big = [v[2] for i, v in enumerate(out_tuples) if (i % 2 == 1)]\n",
    "\n",
    "len(A_position)\n",
    "A_position[0].shape\n",
    "A_position[1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8802e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import TransitionMatrixComputations\n",
    "\n",
    "# Visualization ______________________________________________________________________________________________________ #\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow, LayoutScrollability\n",
    "\n",
    "binned_x_transition_matrix_higher_order_list_dict: Dict[types.DecoderName, NDArray] = track_templates.compute_decoder_transition_matricies(n_powers=3)\n",
    "out = TransitionMatrixComputations.plot_transition_matricies(decoders_dict=track_templates.get_decoders_dict(), binned_x_transition_matrix_higher_order_list_dict=binned_x_transition_matrix_higher_order_list_dict)\n",
    "# out\n",
    "\n",
    "\n",
    "# binned_x_transition_matrix_higher_order_list_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92be3631",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_position_overall = np.sum(np.stack(A_position), axis=0) #.shape # (81, 57, 57)\n",
    "# A_position_overall.shape\n",
    "plt.figure(figsize=(8,6)); sns.heatmap(A_position_overall, cmap='viridis'); perform_update_title_subtitle(title_string=f\"Transition Matrix A_position_overall - t_bin: {a_time_bin_size}\"); plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55148899",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(A_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92508cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example data: linear array\n",
    "# data = [np.random.rand(10, 10) for _ in range(12)]  # 12 heatmaps of size 10x10\n",
    "data = A_position[:20]\n",
    "columns = 5  # Number of columns in the grid\n",
    "\n",
    "# Compute grid dimensions\n",
    "rows = -(-len(data) // columns)  # Ceiling division for number of rows\n",
    "print(f'rows: {rows}, columns: {columns}')\n",
    "\n",
    "# Plot the grid\n",
    "fig, axes = plt.subplots(rows, columns, figsize=(15, 3 * rows))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < len(data):\n",
    "        heatmap = data[i]\n",
    "        # im = ax.imshow(heatmap, cmap='viridis')\n",
    "        sns.heatmap(heatmap, cmap='viridis', ax=ax) ## position\n",
    "        ax.set_title(f\"Heatmap {i + 1}\")\n",
    "    else:\n",
    "        ax.axis('off')  # Turn off unused axes\n",
    "\n",
    "# fig.colorbar(im, ax=axes, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5830bd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\"D\" is E\"pic\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00295aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_position, A_model, A_big = build_position_by_decoder_transition_matrix(p_x_given_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447625fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# plt.figure(figsize=(8,6)); sns.heatmap(A_big, cmap='viridis'); plt.title(\"Transition Matrix A_big\"); plt.show()\n",
    "plt.figure(figsize=(8,6)); sns.heatmap(A_position, cmap='viridis'); perform_update_title_subtitle(title_string=f\"Transition Matrix A_position - t_bin: {a_time_bin_size}\"); plt.show(); \n",
    "plt.figure(figsize=(8,6)); sns.heatmap(A_model, cmap='viridis'); perform_update_title_subtitle(title_string=f\"Transition Matrix A_model - t_bin: {a_time_bin_size}\"); plt.show()\n",
    "\n",
    "_out = plot_blocked_transition_matrix(A_big, n_position_bins, n_decoding_models, extra_title_suffix=f' - t_bin: {a_time_bin_size}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0065a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuously_decoded_result_cache_dict[0.025]['pseudo2D'] # DecodedFilterEpochsResult"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aec3e1",
   "metadata": {},
   "source": [
    "# 2025-04-29 - Simple P(Long) (joint) over position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf1aa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import EpochComputationFunctions, EpochComputationsComputationsContainer\n",
    "from neuropy.utils.mixins.binning_helpers import BinningContainer, BinningInfo\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import complete_all_transition_matricies, build_transition_matricies\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import split_transition_matricies_results_pre_post_delta_category\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import LongShortTrackDataframeAccessor\n",
    "\n",
    "valid_EpochComputations_result: EpochComputationsComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['EpochComputations']\n",
    "a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult = valid_EpochComputations_result.a_generic_decoder_dict_decoded_epochs_dict_result\n",
    "\n",
    "\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.050, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore') # , decoder_identifier='long_LR'\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore', data_grain='per_epoch') # , time_bin_size=0.050, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore', decoder_identifier='long_LR'\n",
    "\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='ignore', data_grain='per_epoch') ## Laps\n",
    "# any_matching_contexts_list, result_context_dict, decoder_context_dict, decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context)\n",
    "\n",
    "# common_constraint_dict = dict(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, masked_time_bin_fill_type='ignore')\n",
    "common_constraint_dict = dict(trained_compute_epochs='laps', time_bin_size=0.025, masked_time_bin_fill_type='nan_filled') # , pfND_ndim=1\n",
    "\n",
    "\n",
    "## Laps context:\n",
    "a_laps_target_context: IdentifyingContext = IdentifyingContext(known_named_decoding_epochs_type='laps', **common_constraint_dict, data_grain='per_epoch') ## Laps\n",
    "laps_target_context_results = complete_all_transition_matricies(a_new_fully_generic_result=a_new_fully_generic_result, a_target_context=a_laps_target_context)\n",
    "laps_matched_result_tuple_context_dict, (laps_time_bin_container_context_dict, laps_position_transition_matrix_context_dict, laps_context_state_transition_matrix_context_dict, laps_combined_transition_matrix_context_dict), (laps_mean_context_state_transition_matrix_context_dict, laps_mean_position_transition_matrix_context_dict) = laps_target_context_results\n",
    "# a_best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = out_matched_result_tuple_context_dict[a_ctxt]\n",
    "a_laps_best_matching_context, a_laps_result, a_laps_decoder, a_laps_decoded_marginal_posterior_df = list(laps_matched_result_tuple_context_dict.values())[0] # [-1]\n",
    "\n",
    "## PBEs context:\n",
    "a_PBEs_target_context: IdentifyingContext = IdentifyingContext(known_named_decoding_epochs_type='pbe', **common_constraint_dict, data_grain='per_epoch') ## Laps\n",
    "pbes_target_context_results = complete_all_transition_matricies(a_new_fully_generic_result=a_new_fully_generic_result, a_target_context=a_PBEs_target_context)\n",
    "pbes_matched_result_tuple_context_dict, (pbes_time_bin_container_context_dict, pbes_position_transition_matrix_context_dict, pbes_context_state_transition_matrix_context_dict, pbes_combined_transition_matrix_context_dict), (pbes_mean_context_state_transition_matrix_context_dict, pbes_mean_position_transition_matrix_context_dict) = pbes_target_context_results\n",
    "a_pbes_best_matching_context, a_pbes_result, a_pbes_decoder, a_pbes_decoded_marginal_posterior_df = list(pbes_matched_result_tuple_context_dict.values())[0] # [-1] # pbes_matched_result_tuple_context_dict[a_PBEs_target_context]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a40bdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_post_delta_a_laps_decoded_marginal_posterior_df_dict = a_laps_decoded_marginal_posterior_df.pho.partition_df_dict('pre_post_delta_category') # pre_post_delta_category\n",
    "# pre_post_delta_a_laps_decoded_marginal_posterior_df_dict['pre-delta']\n",
    "# pre_post_delta_a_laps_decoded_marginal_posterior_df_dict['post-delta']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fdfa19",
   "metadata": {},
   "source": [
    "## 2025-05-01 - Get Pre/Post Delta Split Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d818e15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import LongShortTrackDataframeAccessor\n",
    "from typing import Dict, List, Tuple, Optional, Callable, Union, Any, TypeVar\n",
    "from typing_extensions import TypeAlias\n",
    "import nptyping as ND\n",
    "from nptyping import NDArray\n",
    "# import neuropy.utils.type_aliases as types\n",
    "import pyphoplacecellanalysis.General.type_aliases as types\n",
    "from neuropy.utils.mixins.time_slicing import TimeColumnAliasesProtocol\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import build_decoder_prob_as_a_function_of_position\n",
    "\n",
    "## INPUTS: a_laps_decoder, a_laps_result, a_pbes_result\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "epochs_result_dict: Dict[types.KnownNamedDecodingEpochsType, DecodedFilterEpochsResult] = {'laps': deepcopy(a_laps_result),\n",
    "\t\t\t\t\t  'pbe': deepcopy(a_pbes_result),\n",
    "}\n",
    "# epochs_result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f4bc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_dict, epoch_name_by_pre_post_delta_category_output_dict_dict, epoch_name_by_probability_values_output_dict_dict = build_decoder_prob_as_a_function_of_position(epochs_result_dict=epochs_result_dict, xbin_centers=deepcopy(a_laps_decoder.xbin_centers), t_delta=t_delta, grid_bin_bounds=deepcopy(a_laps_decoder.pf.config.grid_bin_bounds), is_split_by_all_decoders=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dc58c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_dict, epoch_name_by_pre_post_delta_category_output_dict_dict, epoch_name_by_probability_values_output_dict_dict = build_decoder_prob_as_a_function_of_position(epochs_result_dict=epochs_result_dict, xbin_centers=deepcopy(a_laps_decoder.xbin_centers), t_delta=t_delta, grid_bin_bounds=deepcopy(a_laps_decoder.pf.config.grid_bin_bounds), is_split_by_all_decoders=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aa6bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_name_by_probability_values_output_dict_dict['laps']['long']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4efd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ndarray_preview height=500, width=None, include_plaintext_repr=False, include_shape=False, horizontal_layout=True\n",
    "# %%ndarray_preview height=500, width=200, include_plaintext_repr=False, include_shape=False, horizontal_layout=True\n",
    "# summary_values_dict['all'].shape # .shape (59, 4, 1349)  (n_pos_bins, 4, n_t_bins)\n",
    "# np.nansum(summary_values_dict['all'], axis=0) # .shape (4, n_t_bins)\n",
    "\n",
    "full_joint_p = deepcopy(summary_values_dict['all']) # .shape (n_pos_bins, 4, n_t_bins)\n",
    "full_joint_p = np.nan_to_num(full_joint_p, copy=True, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "full_joint_p\n",
    "\n",
    "any_decoder_p = np.nansum(full_joint_p, axis=1) # .shape (n_pos_bins, n_t_bins)\n",
    "any_decoder_p = np.nan_to_num(any_decoder_p, copy=True, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "any_decoder_p\n",
    "\n",
    "any_decoder_all_t_bins_p = np.nansum(any_decoder_p, axis=-1) # .shape (n_pos_bins)\n",
    "any_decoder_all_t_bins_p = np.nan_to_num(any_decoder_all_t_bins_p, copy=True, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "any_decoder_all_t_bins_p\n",
    "\n",
    "# summary_values_dict['all'][:,:,4]\n",
    "\n",
    "# np.nansum(summary_values_dict['all'][:,:,4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bf8330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any_decoder_p\n",
    "\n",
    "single_decoder_p = full_joint_p[:, 0, :] / any_decoder_p # .shape (n_pos_bins, n_t_bins)\n",
    "single_decoder_p = np.nan_to_num(single_decoder_p, copy=True, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "single_decoder_p = single_decoder_p / np.nansum(single_decoder_p, axis=0) # all positions should normalize to 1.0\n",
    "single_decoder_p = np.nan_to_num(single_decoder_p, copy=True, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "single_decoder_p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dbd0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nansum(single_decoder_p, axis=-1)\n",
    "np.nansum(single_decoder_p, axis=0) # all positions should normalize to 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903e39e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "any_decoder_p = np.nan_to_num(any_decoder_p, copy=True, nan=0.0, posinf=1.0, neginf=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94176f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ndarray_preview height=500, width=None, include_plaintext_repr=False, include_shape=False, horizontal_layout=True\n",
    "\n",
    "np.nansum(summary_values_dict['all'], axis=-1) # .shape (59, 4) (n_pos_bins, 4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19747dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "summary_values_dict['long'].shape # .shape (n_pos_bins, n_t_bins)\n",
    "\n",
    "\n",
    "# np.nansum(summary_values_dict['long'], axis=0) # .shape (n_t_bins)\n",
    "np.nansum(summary_values_dict['long'], axis=1) # .shape (n_pos_bins)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e05f166",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_laps_decoder.xbin_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216f7766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_bin_bounds\n",
    "# long_results.pf1D.config.grid_bin_bounds\n",
    "\n",
    "a_laps_decoder.pf.config.grid_bin_bounds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e02152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: a_laps_decoded_marginal_posterior_df\n",
    "# a_laps_decoded_marginal_posterior_df\n",
    "a_laps_decoded_marginal_posterior_df\n",
    "a_laps_decoded_marginal_posterior_df = LongShortTrackDataframeAccessor.add_pre_post_delta_category_column_if_needed(epochs_df=a_laps_decoded_marginal_posterior_df, t_delta=t_delta, start_time_col_name='lap_start_t')\n",
    "a_laps_decoded_marginal_posterior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27cd6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS\n",
    "Assert.same_length(an_out_result.filter_epochs, an_out_result.p_x_given_n_list)\n",
    "# an_out_result.filter_epochs\n",
    "len(an_out_result.p_x_given_n_list)\n",
    "\n",
    "pre_post_delta_a_laps_decoded_marginal_posterior_df_dict = a_laps_decoded_marginal_posterior_df.pho.partition_df_dict('pre_post_delta_category') # pre_post_delta_category\n",
    "# pre_post_delta_a_laps_decoded_marginal_posterior_df_dict['pre-delta']\n",
    "# pre_post_delta_a_laps_decoded_marginal_posterior_df_dict['post-delta']\n",
    "\n",
    "an_out_result_dict: Dict[str, DecodedFilterEpochsResult] = {'pre-delta': an_out_result.filtered_by_epoch_times(pre_post_delta_a_laps_decoded_marginal_posterior_df_dict['pre-delta']['lap_start_t']),\n",
    "\t\t\t\t\t  'post-delta': an_out_result.filtered_by_epoch_times(pre_post_delta_a_laps_decoded_marginal_posterior_df_dict['post-delta']['lap_start_t']),\n",
    "}\n",
    "an_out_result_dict['pre-delta']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc3e75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import plot_linearized_position_probability\n",
    "\n",
    "# Example usage\n",
    "# fig, prob_values = plot_linearized_position_probability(an_out_result)\n",
    "\n",
    "fig1, ax1, prob_values1 = plot_linearized_position_probability(an_out_result=an_out_result_dict['pre_delta'], figure_title='pre-delta Linearized Position Probability')\n",
    "fig2, ax2, prob_values2 = plot_linearized_position_probability(an_out_result=an_out_result_dict['post_delta'], figure_title='post-delta Linearized Position Probability', ax=ax1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e773f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [v['p_x_given_n'].shape for v in an_out_result.marginal_x_list]\n",
    "# [v.shape for v in an_out_result.p_x_given_n_list]\n",
    "\n",
    "SUMMRY_WUMY = np.squeeze(np.hstack([np.squeeze(v[:,0,:]) for v in an_out_result.p_x_given_n_list])) + np.squeeze(np.hstack([np.squeeze(v[:,1,:]) for v in an_out_result.p_x_given_n_list]))\n",
    "gay_GARRAYU = np.nansum(SUMMRY_WUMY, axis=-1)\n",
    "NORMY_WARMY = np.nansum(gay_GARRAYU)\n",
    "gay_GARRAYU = gay_GARRAYU / NORMY_WARMY\n",
    "gay_GARRAYU\n",
    "\n",
    "\n",
    "plt.figure(num='INNOPCUOUS FIGHURE')\n",
    "plt.scatter(x=np.arange(len(gay_GARRAYU)), y=gay_GARRAYU)\n",
    "plt.ylabel('P(LONG)')\n",
    "plt.xlabel('Position <linearized>')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303c3e45",
   "metadata": {},
   "source": [
    "#### Pre 2025-05-01 Simple way of doing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1846ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.stack(an_out_result.p_x_given_n_list, axis=1)\n",
    "# np.hstack(an_out_result.p_x_given_n_list)\n",
    "\n",
    "    # an_out_result.p_x_given_n_lis\n",
    "\n",
    "gay_GARRAYU=np.nansum(np.hstack([v['p_x_given_n'] for v in an_out_result.marginal_x_list]), axis=-1)\n",
    "NORMY_WARMY = np.nansum(gay_GARRAYU)\n",
    "gay_GARRAYU = gay_GARRAYU / NORMY_WARMY\n",
    "\n",
    "\n",
    "plt.figure(num='PUPPY FIGHURE')\n",
    "plt.scatter(x=np.arange(len(gay_GARRAYU)), y=gay_GARRAYU)\n",
    "plt.ylabel('P(LONG)')\n",
    "plt.xlabel('Position <linearized>')\n",
    "\n",
    "\n",
    "# np.nansum(, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaccf1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import _perform_plot_P_Context_State_Transition_Matrix, _perform_plot_position_Transition_Matrix\n",
    "\n",
    "## INPUTS: laps_context_state_transition_matrix_context_dict\n",
    "# out_transition_matrix_context_dict = deepcopy(pbes_context_state_transition_matrix_context_dict)\n",
    "out_transition_matrix_context_dict = deepcopy(pbes_position_transition_matrix_context_dict)\n",
    "out_matched_result_tuple_context_dict = deepcopy(pbes_matched_result_tuple_context_dict)\n",
    "\n",
    "an_out_best_matching_context, an_out_result, an_out_decoder, an_out_decoded_marginal_posterior_df = list(out_matched_result_tuple_context_dict.values())[0] # [-1]\n",
    "a_transition_matrix_list: List[NDArray] = list(out_transition_matrix_context_dict.values())[0]\n",
    "\n",
    "## INPUTS: an_out_decoded_marginal_posterior_df, a_context_state_transition_matrix_list\n",
    "# 2024-03-04 - Filter out the epochs based on the criteria:\n",
    "# _, _, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "# filtered_epochs_df, active_spikes_df = filter_and_update_epochs_and_spikes(curr_active_pipeline, global_epoch_name, track_templates, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1)\n",
    "# filtered_valid_epoch_times = filtered_epochs_df[['start', 'stop']].to_numpy()\n",
    "# required_min_percentage_of_active_cells: float = 0.333333 # 20% of active cells\n",
    "# active_min_num_unique_aclu_inclusions_requirement: int = track_templates.min_num_unique_aclu_inclusions_requirement(curr_active_pipeline, required_min_percentage_of_active_cells=required_min_percentage_of_active_cells)\n",
    "# Update epochs and spikes\n",
    "# an_out_decoded_marginal_posterior_df, active_spikes_df = co_filter_epochs_and_spikes(active_spikes_df=active_spikes_df, active_epochs_df=an_out_decoded_marginal_posterior_df, included_aclus=track_templates.any_decoder_neuron_IDs, min_num_unique_aclu_inclusions=active_min_num_unique_aclu_inclusions_requirement, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1, add_unique_aclus_list_column=False, drop_non_epoch_spikes=True)\n",
    "# pbes_mean_context_state_transition_matrix_dict = split_transition_matricies_results_pre_post_delta_category(an_out_decoded_marginal_posterior_df=an_out_decoded_marginal_posterior_df, a_context_state_transition_matrix_list=a_transition_matrix_list)\n",
    "\n",
    "\n",
    "pbes_mean_context_state_transition_matrix_dict = split_transition_matricies_results_pre_post_delta_category(an_out_decoded_marginal_posterior_df=an_out_decoded_marginal_posterior_df, a_context_state_transition_matrix_list=list(deepcopy(pbes_context_state_transition_matrix_context_dict).values())[0])\n",
    "pbes_mean_position_transition_matrix_dict = split_transition_matricies_results_pre_post_delta_category(an_out_decoded_marginal_posterior_df=an_out_decoded_marginal_posterior_df, a_context_state_transition_matrix_list=list(deepcopy(pbes_position_transition_matrix_context_dict).values())[0])\n",
    "\n",
    "pbes_mean_context_state_transition_matrix_dict\n",
    "pbes_mean_position_transition_matrix_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da7552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import _perform_plot_P_Context_State_Transition_Matrix, _perform_plot_position_Transition_Matrix\n",
    "\n",
    "\n",
    "for pre_post_delta_value, a_mean_context_state_transition_matrix in pbes_mean_context_state_transition_matrix_dict.items():\n",
    "    # _perform_plot_P_Context_State_Transition_Matrix(context_state_transition_matrix=a_mean_context_state_transition_matrix, num=f'laps')\n",
    "    _perform_plot_P_Context_State_Transition_Matrix(context_state_transition_matrix=a_mean_context_state_transition_matrix, num=f'PBEs: Context ({pre_post_delta_value})')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9e865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pre_post_delta_value, a_mean_position_transition_matrix in pbes_mean_position_transition_matrix_dict.items():\n",
    "    # _perform_plot_P_Context_State_Transition_Matrix(context_state_transition_matrix=a_mean_context_state_transition_matrix, num=f'laps')\n",
    "    _perform_plot_position_Transition_Matrix(a_position_transition_matrix=a_mean_position_transition_matrix, num=f'PBEs: Positions ({pre_post_delta_value})')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9c7980",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert 'pre_post_delta_category' in an_out_decoded_marginal_posterior_df\n",
    "is_pre_delta = (an_out_decoded_marginal_posterior_df['pre_post_delta_category'] == 'pre-delta')\n",
    "\n",
    "a_context_state_transition_matrix: NDArray = np.stack(a_context_state_transition_matrix_list) # np.stack(out_context_state_transition_matrix_context_dict[a_ctxt]).shape\n",
    "\n",
    "## split on first index:\n",
    "a_context_state_transition_matrix_dict = {'pre-delta': a_context_state_transition_matrix[is_pre_delta], 'post-delta': a_context_state_transition_matrix[np.logical_not(is_pre_delta)]}\n",
    "a_mean_context_state_transition_matrix_dict = {k:np.nanmean(v, axis=0) for k, v in a_context_state_transition_matrix_dict.items()}\n",
    "\n",
    "# np.shape(a_context_state_transition_matrix) # (84, 4, 4) - (n_epochs, n_states, n_states)\n",
    "# a_mean_context_state_transition_matrix: NDArray = np.nanmean(a_context_state_transition_matrix, axis=0) #.shape (4, 4)\n",
    "# a_mean_context_state_transition_matrix\n",
    "a_mean_context_state_transition_matrix_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c28ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_pbes_decoded_marginal_posterior_df[a_pbes_decoded_marginal_posterior_df['pre_post_delta_category'] == 'pre-delta'] # (partitionColumn='pre_post_delta_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92968ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(laps_matched_result_tuple_context_dict.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96268dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_laps_decoded_marginal_posterior_df\n",
    "a_pbes_best_matching_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a869e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_mean_context_state_transition_matrix_context_dict[a_laps_best_matching_context]\n",
    "laps_mean_position_transition_matrix_context_dict[a_laps_best_matching_context]\n",
    "\n",
    "pbes_mean_context_state_transition_matrix_context_dict[a_pbes_best_matching_context]\n",
    "pbes_mean_position_transition_matrix_context_dict[a_pbes_best_matching_context]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa45f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_mean_context_state_transition_matrix_context_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea666e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import _perform_plot_P_Context_State_Transition_Matrix, _perform_plot_position_Transition_Matrix\n",
    "\n",
    "_perform_plot_P_Context_State_Transition_Matrix(context_state_transition_matrix=laps_mean_context_state_transition_matrix_context_dict[a_laps_best_matching_context], num='laps')\n",
    "_perform_plot_P_Context_State_Transition_Matrix(context_state_transition_matrix=pbes_mean_context_state_transition_matrix_context_dict[a_pbes_best_matching_context], num='PBEs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a3036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import _perform_plot_P_Context_State_Transition_Matrix, _perform_plot_position_Transition_Matrix\n",
    "\n",
    "_perform_plot_position_Transition_Matrix(a_position_transition_matrix=laps_mean_position_transition_matrix_context_dict[a_laps_best_matching_context], num='laps')\n",
    "_perform_plot_position_Transition_Matrix(a_position_transition_matrix=pbes_mean_position_transition_matrix_context_dict[a_pbes_best_matching_context], num='PBEs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a3258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# plt.figure(figsize=(8,6)); sns.heatmap(A_big, cmap='viridis'); plt.title(\"Transition Matrix A_big\"); plt.show()\n",
    "# plt.figure(figsize=(8,6)); sns.heatmap(A_position, cmap='viridis'); perform_update_title_subtitle(title_string=f\"Transition Matrix A_position - t_bin: {a_time_bin_size}\"); plt.show(); \n",
    "# plt.figure(figsize=(8,6)); sns.heatmap(A_model, cmap='viridis'); perform_update_title_subtitle(title_string=f\"Transition Matrix A_model - t_bin: {a_time_bin_size}\"); plt.show()\n",
    "\n",
    "n_position_bins = 59\n",
    "n_decoding_models = 4\n",
    "_out = plot_blocked_transition_matrix(pbes_mean_position_transition_matrix_context_dict[a_pbes_best_matching_context], n_position_bins, n_decoding_models, extra_title_suffix=f' - t_bin: {a_time_bin_size}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7d6da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "FAT_df: pd.DataFrame = deepcopy(a_new_fully_generic_result.single_FAT_df)\n",
    "# len(all_contexts)\n",
    "FAT_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1589048",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# all_contexts\n",
    "unique_values_dict = FAT_df.neuropy.get_column_unique_values_dict(columns_include_subset=['trained_compute_epochs', 'known_named_decoding_epochs_type', 'masked_time_bin_fill_type', 'data_grain', 'decoding_time_bin_size']) # , 'masked_time_bin_fill_type'\n",
    "unique_values_dict\n",
    "\n",
    "# [Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'non_pbe_endcaps', masked_time_bin_fill_type= 'dropped', data_grain= 'per_time_bin', decoding_time_bin_size= 0.025),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_epoch'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'non_pbe', masked_time_bin_fill_type= 'last_valid'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'pbe'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'non_pbe'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'dropped', data_grain= 'per_time_bin'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'dropped', data_grain= 'per_time_bin'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_epoch'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'nan_filled'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'non_pbe_endcaps', masked_time_bin_fill_type= 'last_valid', data_grain= 'per_time_bin', decoding_time_bin_size= 0.025),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'dropped', data_grain= 'per_epoch'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'ignore'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_time_bin'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'ignore'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'non_pbe_endcaps', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin', decoding_time_bin_size= 0.025),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'last_valid'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'nan_filled'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'non_pbe', masked_time_bin_fill_type= 'nan_filled'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'global', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_time_bin'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'non_pbe_endcaps', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_time_bin', decoding_time_bin_size= 0.025),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'ignore', data_grain= 'per_epoch'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'non_pbe', masked_time_bin_fill_type= 'ignore'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'last_valid'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore', data_grain= 'per_epoch'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'dropped', data_grain= 'per_time_bin'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'laps'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'dropped', data_grain= 'per_epoch'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'nan_filled'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'dropped', data_grain= 'per_time_bin'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'nan_filled'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'global', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_time_bin')]\n",
    "\n",
    "possible_unique_values_dict = {'trained_compute_epochs': ['non_pbe', 'laps'],\n",
    " 'known_named_decoding_epochs_type': ['laps', 'pbe', 'non_pbe', 'global', 'non_pbe_endcaps'],\n",
    " 'masked_time_bin_fill_type': ['ignore', 'last_valid', 'nan_filled', 'dropped'],\n",
    " 'data_grain': ['per_time_bin', 'per_epoch'],\n",
    " 'decoding_time_bin_size': [0.025]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d746d004",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.050, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore') # , decoder_identifier='long_LR'\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore', data_grain='per_epoch') # , time_bin_size=0.050, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore', decoder_identifier='long_LR'\n",
    "\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='ignore', data_grain='per_epoch') ## Laps\n",
    "# any_matching_contexts_list, result_context_dict, decoder_context_dict, decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context)\n",
    "\n",
    "# common_constraint_dict = dict(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, masked_time_bin_fill_type='ignore')\n",
    "common_constraint_dict = dict(trained_compute_epochs='laps', time_bin_size=0.025, masked_time_bin_fill_type='nan_filled') # , pfND_ndim=1\n",
    "\n",
    "\n",
    "## Laps context:\n",
    "a_laps_target_context: IdentifyingContext = IdentifyingContext(known_named_decoding_epochs_type='laps', **common_constraint_dict, data_grain='per_epoch') ## Laps\n",
    "laps_target_context_results = complete_all_transition_matricies(a_new_fully_generic_result=a_new_fully_generic_result, a_target_context=a_laps_target_context)\n",
    "laps_matched_result_tuple_context_dict, (laps_time_bin_container_context_dict, laps_position_transition_matrix_context_dict, laps_context_state_transition_matrix_context_dict, laps_combined_transition_matrix_context_dict), (laps_mean_context_state_transition_matrix_context_dict, laps_mean_position_transition_matrix_context_dict) = laps_target_context_results\n",
    "# a_best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = out_matched_result_tuple_context_dict[a_ctxt]\n",
    "a_laps_best_matching_context, a_laps_result, a_laps_decoder, a_laps_decoded_marginal_posterior_df = list(laps_matched_result_tuple_context_dict.values())[0] # [-1]\n",
    "\n",
    "## PBEs context:\n",
    "a_PBEs_target_context: IdentifyingContext = IdentifyingContext(known_named_decoding_epochs_type='pbe', **common_constraint_dict, data_grain='per_epoch') ## Laps\n",
    "pbes_target_context_results = complete_all_transition_matricies(a_new_fully_generic_result=a_new_fully_generic_result, a_target_context=a_PBEs_target_context)\n",
    "pbes_matched_result_tuple_context_dict, (pbes_time_bin_container_context_dict, pbes_position_transition_matrix_context_dict, pbes_context_state_transition_matrix_context_dict, pbes_combined_transition_matrix_context_dict), (pbes_mean_context_state_transition_matrix_context_dict, pbes_mean_position_transition_matrix_context_dict) = pbes_target_context_results\n",
    "a_pbes_best_matching_context, a_pbes_result, a_pbes_decoder, a_pbes_decoded_marginal_posterior_df = list(pbes_matched_result_tuple_context_dict.values())[0] # [-1] # pbes_matched_result_tuple_context_dict[a_PBEs_target_context]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bb3795",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values_dict = FAT_df.neuropy.get_column_unique_values_dict(columns_include_subset=['custom_replay_name', 'included_qclu_values', 'minimum_inclusion_fr_Hz', 'time_bin_size']) # , 'masked_time_bin_fill_type'\n",
    "unique_values_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f75ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0fe9b90",
   "metadata": {},
   "source": [
    "# 2025-05-04 - Add interpolated position to any decoded result df with (P_Long, P_Short, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40962ef9",
   "metadata": {},
   "source": [
    "### Active manual adding of position columns to obtained global result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a360cd",
   "metadata": {
    "tags": [
     "active-2025-05-05"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _helper_add_interpolated_position_columns_to_decoded_result_df\n",
    "# from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import _perform_plot_hairy_overlayed_position\n",
    "\n",
    "## INPUTS: a_new_fully_generic_result\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='nan_filled', data_grain='per_time_bin')\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='ignore', data_grain='per_time_bin')\n",
    "best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=a_target_context, debug_print=False)\n",
    "## OUTPUTS: a_result, a_decoder, a_decoded_marginal_posterior_df\n",
    "## INPUTS: curr_active_pipeline, a_result, a_decoder, a_decoded_marginal_posterior_df\n",
    "global_measured_position_df: pd.DataFrame = deepcopy(curr_active_pipeline.sess.position.to_dataframe())\n",
    "a_decoded_marginal_posterior_df: pd.DataFrame = _helper_add_interpolated_position_columns_to_decoded_result_df(a_result=a_result, a_decoder=a_decoder, a_decoded_marginal_posterior_df=a_decoded_marginal_posterior_df,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  global_measured_position_df=global_measured_position_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c843f5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _helper_add_interpolated_position_columns_to_decoded_result_df\n",
    "# from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import _perform_plot_hairy_overlayed_position\n",
    "\n",
    "\n",
    "\n",
    "## INPUTS: a_new_fully_generic_result\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='nan_filled', data_grain='per_time_bin')\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type='ignore', data_grain='per_time_bin') # , known_named_decoding_epochs_type='global'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True)\n",
    "\n",
    "# flat_context_list\n",
    "flat_decoded_marginal_posterior_df_context_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2338f685",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=a_target_context, debug_print=False)\n",
    "## OUTPUTS: a_result, a_decoder, a_decoded_marginal_posterior_df\n",
    "## INPUTS: curr_active_pipeline, a_result, a_decoder, a_decoded_marginal_posterior_df\n",
    "global_measured_position_df: pd.DataFrame = deepcopy(curr_active_pipeline.sess.position.to_dataframe())\n",
    "a_decoded_marginal_posterior_df: pd.DataFrame = _helper_add_interpolated_position_columns_to_decoded_result_df(a_result=a_result, a_decoder=a_decoder, a_decoded_marginal_posterior_df=a_decoded_marginal_posterior_df,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  global_measured_position_df=global_measured_position_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d68ac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## now check the histogram for `a_decoded_marginal_posterior_df`\n",
    "a_decoded_marginal_posterior_df: pd.DataFrame = a_decoded_marginal_posterior_df\n",
    "a_decoded_marginal_posterior_df\n",
    "# a_decoded_marginal_posterior_df['binned_x_meas'].hist()\n",
    "a_decoded_marginal_posterior_df.to_csv('output/2025-05-05_decoded_marginal_posterior_df_with_meas_pos.csv')\n",
    "\n",
    "## OUTPUTS: a_decoded_marginal_posterior_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8625601",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c1ef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _helper_add_interpolated_position_columns_to_decoded_result_df\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import _perform_plot_hairy_overlayed_position\n",
    "from neuropy.utils.matplotlib_helpers import draw_epoch_regions\n",
    "\n",
    "## INPUTS: a_decoded_marginal_posterior_df\n",
    "\n",
    "# ## plot the basic lap-positions (measured) over time figure:\n",
    "# _out = dict()\n",
    "# _out['_display_grid_bin_bounds_validation'] = curr_active_pipeline.display(display_function='_display_grid_bin_bounds_validation', active_session_configuration_context=None, include_includelist=[], save_figure=False) # _display_grid_bin_bounds_validation\n",
    "# fig = _out['_display_grid_bin_bounds_validation'].figures[0]\n",
    "# out_axes_list =_out['_display_grid_bin_bounds_validation'].axes\n",
    "# out_plot_data =_out['_display_grid_bin_bounds_validation'].plot_data\n",
    "# ## get the lines2D object to turn off the default position lines:\n",
    "# position_lines_2D = out_plot_data['position_lines_2D']\n",
    "# ## hide all inactive lines:\n",
    "# for a_line in position_lines_2D:\n",
    "#     a_line.set_visible(False)\n",
    "\n",
    "# ax = out_axes_list[0]\n",
    "\n",
    "\n",
    "ax = None\n",
    "    \n",
    "an_pos_line_artist, df_viz = _perform_plot_hairy_overlayed_position(df=deepcopy(a_decoded_marginal_posterior_df), ax=ax, extreme_threshold=0.7) # , thickness_ramping_multiplier=5\n",
    "# df_viz\n",
    "# _out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b126a652",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_pos_line_artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad91da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add epoch indicators:\n",
    "\n",
    "## INPUTS: ax\n",
    "\n",
    "from neuropy.utils.matplotlib_helpers import draw_epoch_regions\n",
    "\n",
    "# epochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, defer_render=False, debug_print=False)\n",
    "# epochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.laps, ax, defer_render=False, debug_print=True)\n",
    "\n",
    "y_height_fraction: float = 0.05\n",
    "n_epoch_types: int = 3\n",
    "relative_y_positions_list = [((float(i)*y_height_fraction), (float(i+1)*y_height_fraction)) for i in np.arange(n_epoch_types)]  # [(0.0, 0.05), (0.05, 0.1), (0.1, 0.15000000000000002)]\n",
    "relative_y_positions_list\n",
    "\n",
    "# relative_y_positions_list = [(0.1, 0.15), (0.15, 0.2)]\n",
    "\n",
    "\n",
    "# relative_y_positions_list = [(0.0, 0.2)]\n",
    "\n",
    "# relative_y_positions=[[0.0, 0.05], [0.05, 0.10], \n",
    "epoch_collection_artists_list_dict = {}\n",
    "\n",
    "common_kwargs = dict(alpha=0.2, linewidths=None)\n",
    "# epochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, facecolor=('red','cyan'), edgecolors=None, labels_kwargs={'y_offset': -0.05, 'size': 14}, **common_kwargs, relative_y_positions=relative_y_positions_list[0], defer_render=True, debug_print=False)\n",
    "# laps_epochs_collection, laps_epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.laps.as_epoch_obj(), ax, facecolor='red', edgecolors='black', labels_kwargs={'y_offset': -16.0, 'size':8}, **common_kwargs, relative_y_positions=relative_y_positions_list[0], defer_render=True, debug_print=False)\n",
    "# replays_epochs_collection, replays_epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.pbe, ax, facecolor='orange', edgecolors=None, labels_kwargs=None, **common_kwargs, relative_y_positions=relative_y_positions_list[0], defer_render=False, debug_print=False)\n",
    "\n",
    "# # epochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, facecolor=('red','cyan'), edgecolors=None, **common_kwargs, relative_y_positions=relative_y_positions_list[0], defer_render=True, debug_print=False)\n",
    "# epoch_collection_artists_list_dict['laps'] = draw_epoch_regions(curr_active_pipeline.sess.laps.as_epoch_obj(), ax, facecolor='red', edgecolors='black', **common_kwargs, relative_y_positions=relative_y_positions_list[0], defer_render=False, debug_print=True)\n",
    "# # epoch_collection_artists_list_dict['replays'] = draw_epoch_regions(curr_active_pipeline.sess.pbe, ax, facecolor='purple', edgecolors=None, **common_kwargs, relative_y_positions=relative_y_positions_list[1], defer_render=False, debug_print=False)\n",
    "\n",
    "\n",
    "# epoch_collection_artists_list_dict['delta'] = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, facecolor=('red','cyan'), edgecolors=None, **common_kwargs, defer_render=False, debug_print=True)\n",
    "epoch_collection_artists_list_dict['laps'] = draw_epoch_regions(curr_active_pipeline.sess.laps.as_epoch_obj(), ax, facecolor='red', edgecolors=None, **common_kwargs, defer_render=False, debug_print=True)\n",
    "epoch_collection_artists_list_dict['replays'] = draw_epoch_regions(curr_active_pipeline.sess.pbe, ax, facecolor='purple', edgecolors=None, **common_kwargs, defer_render=False, debug_print=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aa7934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_all_epoch_artists(epoch_collection_artists_list_dict):\n",
    "    for a_name, a_list in epoch_collection_artists_list_dict.items():\n",
    "        for an_item in a_list:\n",
    "            if an_item is not None:\n",
    "                an_item.remove() ## remove the artist\n",
    "    epoch_collection_artists_list_dict = {} ## clear\n",
    "    return epoch_collection_artists_list_dict\n",
    "\n",
    "\n",
    "epoch_collection_artists_list_dict = remove_all_epoch_artists(epoch_collection_artists_list_dict=epoch_collection_artists_list_dict)\n",
    "\n",
    "\n",
    "# laps_epochs_collection.remove()\n",
    "# laps_epoch_labels.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd57669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, facecolor=[(255, 0, 0), (0, 255, 0)], edgecolors=(0,0,0), labels_kwargs={'y_offset': -16.0, 'size':8, 'rotation':90}, defer_render=False, debug_print=False)\n",
    "\n",
    "epochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, facecolor=[(255, 0, 0), (0, 255, 0)], edgecolors=(0,0,0), labels_kwargs={'y_offset': -16.0, 'size':8, 'rotation':90}, defer_render=False, debug_print=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d8e569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs_collection.remove()\n",
    "# epoch_labels.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a187527",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out = curr_active_pipeline.display(display_function='_display_decoded_trackID_marginal_hairy_position', active_session_configuration_context=None, include_includelist=[], save_figure=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8286a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz[['P_Long', 'P_Short']].sum(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d66e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(a_decoded_marginal_posterior_df_viz) - 1):\n",
    "    row0 = a_decoded_marginal_posterior_df_viz.iloc[i]\n",
    "    row1 = a_decoded_marginal_posterior_df_viz.iloc[i + 1]\n",
    "    if row0['P_Long'] > 0.9 and row1['P_Long'] > 0.9:\n",
    "        ax.plot([row0['t'], row1['t']], [row0['x_meas'], row1['x_meas']],\n",
    "                color=(1, 0, 0, min(row0['P_Long_Opacity'], row1['P_Long_Opacity'])),\n",
    "                linewidth=max(row0['P_Long_Score'], row1['P_Long_Score']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952b9ec8",
   "metadata": {},
   "source": [
    "# 2025-05-04 - Posterior Example Images Export to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25144acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from pyphocorehelpers.plotting.media_output_helpers import ImageOperationsAndEffects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6a21c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out_paths = curr_active_pipeline.display('_display_directional_merged_pf_decoded_stacked_epoch_slices')\n",
    "_out_paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681e725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.assertion_helpers import Assert\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import HeatmapExportConfig, PosteriorExporting\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd08158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a_params_kwargs = {}\n",
    "display_context = curr_active_pipeline.build_display_context_for_session(display_fn_name='trackID_weighted_position_posterior')\n",
    "_out = curr_active_pipeline.display('_display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay', display_context, defer_render=True, save_figure=True,\n",
    "                                    # override_fig_man=custom_fig_man, \n",
    "                                    # parent_output_folder=custom_figure_output_path,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bfe9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out['out_paths']\n",
    "\n",
    "# {'laps': {'psuedo2D_ignore': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/array_to_images/2025-05-30/gor01_one_2006-6-12_15-55-31_trackID_weighted_position_posterior/laps/psuedo2D_ignore'),\n",
    "#   'psuedo2D_nan_filled': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/array_to_images/2025-05-30/gor01_one_2006-6-12_15-55-31_trackID_weighted_position_posterior/laps/psuedo2D_nan_filled')},\n",
    "#  'ripple': {'psuedo2D_ignore': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/array_to_images/2025-05-30/gor01_one_2006-6-12_15-55-31_trackID_weighted_position_posterior/ripple/psuedo2D_ignore'),\n",
    "#   'psuedo2D_nan_filled': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/array_to_images/2025-05-30/gor01_one_2006-6-12_15-55-31_trackID_weighted_position_posterior/ripple/psuedo2D_nan_filled')}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4db4eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_parent_save_paths = _out['flat_parent_save_paths']\n",
    "flat_parent_save_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550217b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out['flat_merged_image_paths']\n",
    "_out['parent_output_folder']\n",
    "flat_parent_save_paths = _out['flat_parent_save_paths']\n",
    "flat_parent_save_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d5931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_path in flat_parent_save_paths:\n",
    "    # file_uri_from_path(a_path)\n",
    "    fullwidth_path_widget(a_path=a_path, file_name_label=\"epoch_specific_folder:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6ca625",
   "metadata": {
    "tags": [
     "heu"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _plot_heuristic_evaluation_epochs\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_filter_replay_epochs\n",
    "\n",
    "force_refilter = False\n",
    "# force_refilter = True\n",
    "\n",
    "needs_refilter = False\n",
    "try:\n",
    "    filtered_decoder_filter_epochs_decoder_result_dict\n",
    "    filtered_epochs_df\n",
    "    filtered_ripple_all_epoch_bins_marginals_df\n",
    "    if filtered_decoder_filter_epochs_decoder_result_dict is not None:\n",
    "        needs_refilter = False\n",
    "except NameError:\n",
    "    needs_refilter = True\n",
    "    \n",
    "if needs_refilter or force_refilter:\n",
    "    filtered_epochs_df, filtered_decoder_filter_epochs_decoder_result_dict, filtered_ripple_all_epoch_bins_marginals_df = _perform_filter_replay_epochs(curr_active_pipeline, global_epoch_name, track_templates, decoder_ripple_filter_epochs_decoder_result_dict, ripple_all_epoch_bins_marginals_df, ripple_decoding_time_bin_size=ripple_decoding_time_bin_size, should_only_include_user_selected_epochs=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2146f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)\n",
    "# for k, v in filtered_decoder_filter_epochs_decoder_result_dict.items():\n",
    "# \tdirectional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc5b1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _plot_heuristic_evaluation_epochs\n",
    "\n",
    "\n",
    "# filtered_epochs_df\n",
    "# filtered_ripple_all_epoch_bins_marginals_df\n",
    "\n",
    "## 1m 38s\n",
    "\n",
    "ripple_merged_complete_epoch_stats_df['is_valid_epoch'] = True\n",
    "## INPUTS: curr_active_pipeline, track_templates, filtered_decoder_filter_epochs_decoder_result_dict, ripple_merged_complete_epoch_stats_df\n",
    "app, (high_heuristic_paginated_multi_decoder_decoded_epochs_window, high_heuristic_pagination_controller_dict), (low_heuristic_paginated_multi_decoder_decoded_epochs_window, low_heuristic_pagination_controller_dict) = _plot_heuristic_evaluation_epochs(curr_active_pipeline, track_templates, filtered_decoder_filter_epochs_decoder_result_dict, ripple_merged_complete_epoch_stats_df=ripple_merged_complete_epoch_stats_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dc8bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.RankOrderRastersDebugger import RankOrderRastersDebugger\n",
    "\n",
    "__out_ripple_rasters, update_attached_raster_viewer_epoch_callback = paginated_multi_decoder_decoded_epochs_window.build_attached_raster_viewer_widget(track_templates=track_templates, active_spikes_df=active_spikes_df, filtered_epochs_df=long_like_during_post_delta_only_filter_epochs_df) # Long-like-during-post-delta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45522cb0",
   "metadata": {},
   "source": [
    "# <a id='toc12_'></a>[🖼️🎨`PhoPaginatedMultiDecoderDecodedEpochsWindow.plot_full_paginated_decoded_epochs_window(..)` combined windows](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf897ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_decoding_time_bin_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1add4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neuropy.core.epoch import ensure_dataframe\n",
    "# from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import PhoPaginatedMultiDecoderDecodedEpochsWindow, DecodedEpochSlicesPaginatedFigureController, EpochSelectionsObject, ClickActionCallbacks\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import co_filter_epochs_and_spikes, get_proper_global_spikes_df\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.TemplateDebugger import TemplateDebugger\n",
    "\n",
    "# from neuropy.utils.matplotlib_helpers import get_heatmap_cmap\n",
    "# from pyphocorehelpers.gui.Qt.color_helpers import ColormapHelpers, ColorFormatConverter\n",
    "# from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import FixedCustomColormaps\n",
    "# from pyphoplacecellanalysis.GUI.Qt.Widgets.ThinButtonBar.ThinButtonBarWidget import ThinButtonBarWidget\n",
    "# from pyphoplacecellanalysis.GUI.Qt.Widgets.PaginationCtrl.PaginationControlWidget import PaginationControlWidget, PaginationControlWidgetState\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from pyphoplacecellanalysis.Resources import GuiResources, ActionIcons, silx_resources_rc\n",
    "from neuropy.utils.indexing_helpers import flatten, NumpyHelpers, PandasHelpers\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicThresholdFiltering\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _plot_heuristic_evaluation_epochs\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_filter_replay_epochs\n",
    "\n",
    "\n",
    "should_only_include_user_selected_epochs = False\n",
    "# should_only_include_user_selected_epochs = True\n",
    "\n",
    "# required_min_percentage_of_active_cells: float = 0.33333333 ## default\n",
    "required_min_percentage_of_active_cells: float = 0.20 # min_num_unique_aclu_inclusions: 10\n",
    "\n",
    "force_refilter = False\n",
    "# force_refilter = True\n",
    "\n",
    "needs_refilter = False\n",
    "try:\n",
    "    filtered_decoder_filter_epochs_decoder_result_dict\n",
    "    filtered_epochs_df\n",
    "    filtered_ripple_all_epoch_bins_marginals_df\n",
    "    if filtered_decoder_filter_epochs_decoder_result_dict is not None:\n",
    "        needs_refilter = False\n",
    "except NameError:\n",
    "    needs_refilter = True\n",
    "    \n",
    "if needs_refilter or force_refilter:\n",
    "    filtered_epochs_df, filtered_decoder_filter_epochs_decoder_result_dict, filtered_ripple_all_epoch_bins_marginals_df = _perform_filter_replay_epochs(curr_active_pipeline, global_epoch_name, track_templates, decoder_ripple_filter_epochs_decoder_result_dict, ripple_all_epoch_bins_marginals_df, ripple_decoding_time_bin_size=ripple_decoding_time_bin_size, should_only_include_user_selected_epochs=should_only_include_user_selected_epochs)\n",
    "\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "# directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=required_min_percentage_of_active_cells, debug_print=False) # min_num_unique_aclu_inclusions: 16 seems too high\n",
    "directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=required_min_percentage_of_active_cells, debug_print=False) # min_num_unique_aclu_inclusions: 16 seems too high\n",
    "\n",
    "# for k, v in filtered_decoder_filter_epochs_decoder_result_dict.items():\n",
    "# \tdirectional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=required_min_percentage_of_active_cells, debug_print=False)\n",
    "\n",
    "\n",
    "## INPUTS: directional_decoders_epochs_decode_result, filtered_epochs_df\n",
    "decoder_ripple_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "unfiltered_epochs_df = deepcopy(decoder_ripple_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)\n",
    "filtered_decoder_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(filtered_epochs_df[['start', 'stop']].to_numpy()) for a_name, a_result in decoder_ripple_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "\n",
    "ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "print(f'{pos_bin_size = }, {ripple_decoding_time_bin_size = }')\n",
    "\n",
    "## OUTPUTS: unfiltered_epochs_df, decoder_ripple_filter_epochs_decoder_result_dict\n",
    "## OUTPUTS: filtered_epochs_df, filtered_decoder_filter_epochs_decoder_result_dict\n",
    "\n",
    "# posterior_heatmap_imshow_kwargs = {'cmap': orange_posterior_cmap}\n",
    "\n",
    "## pos_bin_size = 4.877453969028168, ripple_decoding_time_bin_size = 0.016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174b423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directional_decoders_evaluate_epochs\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_evaluate_epochs'], computation_kwargs_list=[{'should_skip_radon_transform': False}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43059e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import FixedCustomColormaps\n",
    "\n",
    "## INPUTS: included_ripple_start_times\n",
    "# 1D_search (only for start times):\n",
    "# matching_specific_start_ts_only_filtered_decoder_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(included_ripple_start_times) for a_name, a_result in filtered_decoder_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "# matching_specific_start_ts_only_filtered_decoder_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:deepcopy(a_result) for a_name, a_result in filtered_decoder_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "# # matching_specific_start_ts_only_filtered_decoder_filter_epochs_decoder_result_dict\n",
    "# matching_specific_start_ts_only_filter_epochs_df = deepcopy(matching_specific_start_ts_only_filtered_decoder_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)\n",
    "# matching_specific_start_ts_only_filter_epochs_df\n",
    "\n",
    "# # 2024-03-04 - Filter out the epochs based on the criteria:\n",
    "\n",
    "active_spikes_df = get_proper_global_spikes_df(curr_active_pipeline)\n",
    "# active_min_num_unique_aclu_inclusions_requirement: int = track_templates.min_num_unique_aclu_inclusions_requirement(curr_active_pipeline, required_min_percentage_of_active_cells=0.333333333)\n",
    "# matching_specific_start_ts_only_filter_epochs_df, active_spikes_df = co_filter_epochs_and_spikes(active_spikes_df=active_spikes_df, active_epochs_df=matching_specific_start_ts_only_filter_epochs_df, included_aclus=track_templates.any_decoder_neuron_IDs, min_num_unique_aclu_inclusions=active_min_num_unique_aclu_inclusions_requirement, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1, add_unique_aclus_list_column=True, drop_non_epoch_spikes=True)\n",
    "# filtered_epochs_ripple_simple_pf_pearson_merged_df, active_spikes_df = co_filter_epochs_and_spikes(active_spikes_df=active_spikes_df, active_epochs_df=ripple_simple_pf_pearson_merged_df, included_aclus=track_templates.any_decoder_neuron_IDs, min_num_unique_aclu_inclusions=active_min_num_unique_aclu_inclusions_requirement, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1, add_unique_aclus_list_column=True, drop_non_epoch_spikes=True)\n",
    "# matching_specific_start_ts_only_filter_epochs_df, active_spikes_df = co_filter_epochs_and_spikes(active_spikes_df=active_spikes_df, active_epochs_df=matching_specific_start_ts_only_filter_epochs_df, included_aclus=track_templates.any_decoder_neuron_IDs, min_num_unique_aclu_inclusions=active_min_num_unique_aclu_inclusions_requirement, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1, add_unique_aclus_list_column=True, drop_non_epoch_spikes=True)\n",
    "\n",
    "# filtered_epochs_ripple_simple_pf_pearson_merged_df\n",
    "\n",
    "# ## INPUTS: directional_decoders_epochs_decode_result, filtered_epochs_df\n",
    "# decoder_ripple_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "# unfiltered_epochs_df = deepcopy(decoder_ripple_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)\n",
    "# filtered_decoder_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(filtered_epochs_df[['start', 'stop']].to_numpy()) for a_name, a_result in decoder_ripple_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "\n",
    "## INPUTS: filtered_decoder_filter_epochs_decoder_result_dict\n",
    "\n",
    "pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "\n",
    "\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# BEGIN FCN BODY                                                                                                       #\n",
    "# ==================================================================================================================== #\n",
    "## INPUTS filtered_decoder_filter_epochs_decoder_result_dict\n",
    "# decoder_decoded_epochs_result_dict: generic\n",
    "active_cmap = FixedCustomColormaps.get_custom_greyscale_with_low_values_dropped_cmap(low_value_cutoff=0.01, full_opacity_threshold=0.25)\n",
    "\n",
    "# Replay/PBEs ________________________________________________________________________________________________________ #\n",
    "active_decoder_decoded_epochs_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(filtered_decoder_filter_epochs_decoder_result_dict)\n",
    "active_filter_epochs_df: pd.DataFrame = deepcopy(active_decoder_decoded_epochs_result_dict['long_LR'].filter_epochs) # deepcopy(matching_specific_start_ts_only_filter_epochs_df)\n",
    "epochs_name='ripple'\n",
    "title='Filtered PBEs'\n",
    "known_epochs_type = 'ripple'\n",
    "ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "active_decoding_time_bin_size: float = ripple_decoding_time_bin_size\n",
    "\n",
    "\n",
    "# # Laps _______________________________________________________________________________________________________________ #\n",
    "# ## INPUTS: decoder_laps_filter_epochs_decoder_result_dict, \n",
    "# active_decoder_decoded_epochs_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(decoder_laps_filter_epochs_decoder_result_dict)\n",
    "# active_filter_epochs_df: pd.DataFrame = deepcopy(active_decoder_decoded_epochs_result_dict['long_LR'].filter_epochs) # deepcopy(matching_specific_start_ts_only_filter_epochs_df)\n",
    "# epochs_name='laps'\n",
    "# title='Laps'\n",
    "# known_epochs_type = 'laps'\n",
    "# laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "# active_decoding_time_bin_size: float = laps_decoding_time_bin_size\n",
    "\n",
    "print(f'{pos_bin_size = }, {active_decoding_time_bin_size = }')\n",
    "## INPUTS: active_decoder_decoded_epochs_result_dict, active_filter_epochs_df, directional_decoders_epochs_decode_result, curr_active_pipeline, track_templates, active_spikes_df\n",
    "\n",
    "active_spikes_df = get_proper_global_spikes_df(curr_active_pipeline)\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations'] ## GENERAL\n",
    "(app, paginated_multi_decoder_decoded_epochs_window, pagination_controller_dict), ripple_rasters_plot_tuple, yellow_blue_trackID_marginals_plot_tuple = PhoPaginatedMultiDecoderDecodedEpochsWindow.plot_full_paginated_decoded_epochs_window(curr_active_pipeline=curr_active_pipeline, track_templates=track_templates, active_spikes_df=active_spikes_df,\n",
    "                                                                                                                                                                                                   active_decoder_decoded_epochs_result_dict=deepcopy(active_decoder_decoded_epochs_result_dict), # epochs_name='ripple',\n",
    "                                                                                                                                                                                                   directional_decoders_epochs_decode_result=deepcopy(directional_decoders_epochs_decode_result),\n",
    "                                                                                                                                                                                                   active_filter_epochs_df=active_filter_epochs_df, known_epochs_type=known_epochs_type, title=title,\n",
    "                                                                                                params_kwargs={'enable_per_epoch_action_buttons': False,\n",
    "                                                                                                    'skip_plotting_most_likely_positions': True, 'skip_plotting_measured_positions': True, \n",
    "                                                                                                    'enable_decoded_most_likely_position_curve': False, \n",
    "                                                                                                    'enable_decoded_sequence_and_heuristics_curve': True, 'show_pre_merged_debug_sequences': False, 'show_heuristic_criteria_filter_epoch_inclusion_status': True,\n",
    "                                                                                                     'enable_radon_transform_info': False, 'enable_weighted_correlation_info': True, 'enable_weighted_corr_data_provider_modify_axes_rect': False,\n",
    "                                                                                                    # 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': False,\n",
    "                                                                                                    # 'disable_y_label': True,\n",
    "                                                                                                    'isPaginatorControlWidgetBackedMode': True,\n",
    "                                                                                                    'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True,\n",
    "                                                                                                    # 'debug_print': True,\n",
    "                                                                                                    'max_subplots_per_page': 9,\n",
    "                                                                                                    # 'scrollable_figure': False,\n",
    "                                                                                                    'scrollable_figure': True,\n",
    "                                                                                                    # 'posterior_heatmap_imshow_kwargs': dict(vmin=0.0075),\n",
    "                                                                                                    'use_AnchoredCustomText': False,\n",
    "                                                                                                    'should_suppress_callback_exceptions': False,\n",
    "                                                                                                    # 'build_fn': 'insets_view',\n",
    "                                                                                                    'track_length_cm_dict': deepcopy(track_templates.get_track_length_dict()),\n",
    "                                                                                                    'posterior_heatmap_imshow_kwargs': dict(cmap=active_cmap), # , vmin=0.1, vmax=1.0\n",
    "                                                                                                    'data_overlay_heuristic_kwargs': dict(same_thresh_fraction_of_track=0.001, max_jump_distance_cm=360.0, max_ignore_bins=25),\n",
    "                                                                                                })\n",
    "attached_yellow_blue_marginals_viewer_widget: DecodedEpochSlicesPaginatedFigureController = paginated_multi_decoder_decoded_epochs_window.attached_yellow_blue_marginals_viewer_widget\n",
    "attached_ripple_rasters_widget: RankOrderRastersDebugger = paginated_multi_decoder_decoded_epochs_window.attached_ripple_rasters_widget\n",
    "attached_directional_template_pfs_debugger: TemplateDebugger = paginated_multi_decoder_decoded_epochs_window.attached_directional_template_pfs_debugger\n",
    "\n",
    "## OUTPUTS: directional_merged_decoders_result\n",
    "# user_interactivity_instructions_dict = {'left-click':'toggle is_good annotation', 'right-click':'select epoch row', 'MMB click':'get clicked time to clipboard'}\n",
    "# user_interactivity_instructions_message: str = ', '.join([f'{k}:{v}' for k, v in user_interactivity_instructions_dict.items()])\n",
    "# print(f'user_interactivity_instructions_message: \"{user_interactivity_instructions_message}\"')\n",
    "# paginated_multi_decoder_decoded_epochs_window.show_message(user_interactivity_instructions_message, durationMs=4000)\n",
    "\n",
    "# add_data_overlays(...): decoder_track_length is None so skipping heuristics plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f91bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paginated_multi_decoder_decoded_epochs_window.attached_yellow_blue_marginals_viewer_widget.plots_data.all_attributes # ['name', 'epoch_slices', 'global_pos_df', 'filter_epochs_decoder_result', 'active_marginal_fn', 'paginator', 'highlighted_epoch_time_bin_idx', 'decoded_position_curves_data', 'marginal_labels_data']\n",
    "\n",
    "filter_epochs_decoder_result: DecodedFilterEpochsResult = paginated_multi_decoder_decoded_epochs_window.attached_yellow_blue_marginals_viewer_widget.plots_data.filter_epochs_decoder_result\n",
    "filter_epochs_decoder_result.nbins\n",
    "filter_epochs: pd.DataFrame = deepcopy(filter_epochs_decoder_result.filter_epochs)\n",
    "filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4ae8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_epochs['n_time_bins'] = filter_epochs_decoder_result.nbins\n",
    "filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea0292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_epochs['est_n_t_bins'] = filter_epochs['duration'] / 0.025\n",
    "filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6f9c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_epochs[filter_epochs['label'] == '370']\n",
    "\n",
    "\n",
    "# filter_epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0155968",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_epochs[filter_epochs['start'] > 1505.164]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fea1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_add_data_overlays = paginated_multi_decoder_decoded_epochs_window.add_data_overlays()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a9c497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import SubsequencesPartitioningResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import DecodedSequenceAndHeuristicsPlotData\n",
    "\n",
    "decoded_sequence_and_heuristics_curves_data_dict: Dict[types.DecoderName, Dict[float, DecodedSequenceAndHeuristicsPlotData]] = paginated_multi_decoder_decoded_epochs_window.get_children_props(prop_path='plots_data.decoded_sequence_and_heuristics_curves_data')\n",
    "decoded_sequence_and_heuristics_partition_results_dict: Dict[types.DecoderName, Dict[float, SubsequencesPartitioningResult]] = {a_name:{k:v.partition_result for k, v in a_data_dict.items()} for a_name, a_data_dict in decoded_sequence_and_heuristics_curves_data_dict.items()}\n",
    "# decoded_sequence_and_heuristics_curves_data_dict\n",
    "decoded_sequence_and_heuristics_partition_results_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c285e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_sequence_and_heuristics_curves_data_dict ## OUTPUT\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb39e357",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.get_children_props(prop_path='params.data_overlay_heuristic_kwargs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046f2b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.set_children_props(prop_path='params.data_overlay_heuristic_kwargs', value=dict(same_thresh_fraction_of_track=0.005, max_jump_distance_cm=360.0, max_ignore_bins=22))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952d4716",
   "metadata": {},
   "source": [
    "# 🖼️ `export_current_epoch_marginal_and_raster_images` to export rasters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8838a34b",
   "metadata": {},
   "source": [
    "#### Batch (all) epochs export via `export_current_epoch_marginal_and_raster_images`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2a64ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import PhoPaginatedMultiDecoderDecodedEpochsWindow\n",
    "\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders'] # uses `DirectionalMergedDecoders`.\n",
    "\n",
    "# root_export_path: Path = Path(r\"/media/halechr/MAX/cloud/University of Michigan Dropbox/Pho Hale/Pho Diba Paper 2023/array_as_image\").resolve() # Lab\n",
    "# root_export_path: Path = Path(r'K:/scratch/collected_outputs/figures/array_as_image').resolve()\n",
    "\n",
    "root_export_path: Path = Path(r'K:/scratch/collected_figures/qclu_1246789/array_as_image').resolve()\n",
    "\n",
    "\n",
    "# root_export_path: Path = Path(r'C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\EXTERNAL\\Screenshots\\ProgrammaticDisplayFunctionTesting\\array_as_image').resolve()\n",
    "root_export_path.mkdir(exist_ok=True)\n",
    "Assert.path_exists(root_export_path)\n",
    "\n",
    "complete_session_context, (session_context, additional_session_context) = curr_active_pipeline.get_complete_session_context()\n",
    "_out_path_tuples_dict = paginated_multi_decoder_decoded_epochs_window.export_all_epoch_marginal_and_raster_images(directional_merged_decoders_result=directional_merged_decoders_result, root_export_path=root_export_path, active_context=complete_session_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541163df",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(_out_path_tuples_dict.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9019b4cd",
   "metadata": {},
   "source": [
    "#### Single epoch export via `export_current_epoch_marginal_and_raster_images`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58d46c3",
   "metadata": {
    "tags": [
     "2025-05-16_working-posterior-and-raster-stack-image-saving"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "\n",
    "## INPUTS: \n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders'] # uses `DirectionalMergedDecoders`.\n",
    "\n",
    "\n",
    "# root_export_path: Path = Path(r\"/media/halechr/MAX/cloud/University of Michigan Dropbox/Pho Hale/Pho Diba Paper 2023/array_as_image\").resolve() # Lab\n",
    "root_export_path: Path = Path(r'K:/scratch/collected_outputs/figures/array_as_image').resolve()\n",
    "# root_export_path: Path = Path(r'C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\EXTERNAL\\Screenshots\\ProgrammaticDisplayFunctionTesting\\array_as_image').resolve()\n",
    "root_export_path.mkdir(exist_ok=True)\n",
    "Assert.path_exists(root_export_path)\n",
    "\n",
    "complete_session_context, (session_context, additional_session_context) = curr_active_pipeline.get_complete_session_context()\n",
    "epoch_specific_folder, (out_image_save_tuple_dict, _out_rasters_save_paths, merged_img_save_path) = paginated_multi_decoder_decoded_epochs_window.export_current_epoch_marginal_and_raster_images(directional_merged_decoders_result=directional_merged_decoders_result, root_export_path=root_export_path, active_context=complete_session_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795876fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: paginated_multi_decoder_decoded_epochs_window\n",
    "attached_ripple_rasters_widget: RankOrderRastersDebugger = paginated_multi_decoder_decoded_epochs_window.attached_ripple_rasters_widget\n",
    "_out_ripple_rasters = paginated_multi_decoder_decoded_epochs_window\n",
    "epoch_specific_folder, (out_image_save_tuple_dict, _out_rasters_save_paths, merged_img_save_path) = PosteriorExporting._perform_export_current_epoch_marginal_and_raster_images(_out_ripple_rasters=_out_ripple_rasters, directional_merged_decoders_result=directional_merged_decoders_result, \n",
    "    filtered_decoder_filter_epochs_decoder_result_dict=decoder_ripple_filter_epochs_decoder_result_dict, epoch_id_identifier_str='ripple',\n",
    "    # filtered_decoder_filter_epochs_decoder_result_dict=decoder_laps_filter_epochs_decoder_result_dict, epoch_id_identifier_str='lap',\n",
    "    active_session_context=curr_context, \n",
    "    root_export_path = root_export_path,\n",
    ")\n",
    "\n",
    "file_uri_from_path(epoch_specific_folder)\n",
    "fullwidth_path_widget(a_path=epoch_specific_folder, file_name_label=\"epoch_specific_folder:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996c72e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders'] # uses `DirectionalMergedDecoders`.\n",
    "\n",
    "# root_export_path: Path = Path(r'C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\EXTERNAL\\Screenshots\\ProgrammaticDisplayFunctionTesting\\array_as_image').resolve()\n",
    "root_export_path: Path = Path(r'K:/scratch/collected_outputs/figures/array_as_image').resolve()\n",
    "root_export_path.mkdir(exist_ok=True)\n",
    "Assert.path_exists(root_export_path)\n",
    "\n",
    "complete_session_context, (session_context, additional_session_context) = curr_active_pipeline.get_complete_session_context()\n",
    "\n",
    "## INPUTS: paginated_multi_decoder_decoded_epochs_window\n",
    "attached_ripple_rasters_widget: RankOrderRastersDebugger = paginated_multi_decoder_decoded_epochs_window.attached_ripple_rasters_widget\n",
    "_out_ripple_rasters = paginated_multi_decoder_decoded_epochs_window\n",
    "epoch_specific_folder, (out_image_save_tuple_dict, _out_rasters_save_paths, merged_img_save_path) = PosteriorExporting._perform_export_current_epoch_marginal_and_raster_images(_out_ripple_rasters=attached_ripple_rasters_widget, directional_merged_decoders_result=directional_merged_decoders_result, \n",
    "    filtered_decoder_filter_epochs_decoder_result_dict=decoder_ripple_filter_epochs_decoder_result_dict, epoch_id_identifier_str='ripple',\n",
    "    # filtered_decoder_filter_epochs_decoder_result_dict=decoder_laps_filter_epochs_decoder_result_dict, epoch_id_identifier_str='lap',\n",
    "    active_session_context=complete_session_context, \n",
    "    root_export_path = root_export_path,\n",
    ")\n",
    "\n",
    "file_uri_from_path(epoch_specific_folder)\n",
    "fullwidth_path_widget(a_path=epoch_specific_folder, file_name_label=\"epoch_specific_folder:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7051885",
   "metadata": {},
   "source": [
    "### <a id='toc12_1_4_'></a>[2024-02-29 3pm - Get the active user-annotated epoch times from the `paginated_multi_decoder_decoded_epochs_window` and use these to filter `filtered_ripple_simple_pf_pearson_merged_df`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767317a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inputs: paginated_multi_decoder_decoded_epochs_window\n",
    "any_good_selected_epoch_times = deepcopy(paginated_multi_decoder_decoded_epochs_window.any_good_selected_epoch_times)\n",
    "any_good_selected_epoch_indicies = deepcopy(paginated_multi_decoder_decoded_epochs_window.find_data_indicies_from_epoch_times(paginated_multi_decoder_decoded_epochs_window.any_good_selected_epoch_times))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bc2a41",
   "metadata": {},
   "source": [
    "## <a id='toc12_2_'></a>[:✅:🎯 2024-09-27 - Test programmatic/background saving of stacked decoded epoch figures](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7d0436",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_laps_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict)\n",
    "unfiltered_laps_epochs_df = deepcopy(decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)\n",
    "filtered_decoder_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(filtered_epochs_df[['start', 'stop']].to_numpy()) for a_name, a_result in decoder_ripple_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "\n",
    "laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "print(f'{pos_bin_size = }, {laps_decoding_time_bin_size = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae48eec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using: perform_export_all_decoded_posteriors_as_images\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import HeatmapExportConfig, PosteriorExporting\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import HeatmapExportKind\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import Assert\n",
    "\n",
    "## INPUTS:: filtered_decoder_filter_epochs_decoder_result_dict, long_like_during_post_delta_only_filter_epochs\n",
    "active_epochs_decoder_result_dict = deepcopy(filtered_decoder_filter_epochs_decoder_result_dict)\n",
    "parent_output_folder = Path('output/array_to_images').resolve()\n",
    "\n",
    "# active_epochs_decoder_result_dict = deepcopy(long_like_during_post_delta_only_filtered_decoder_filter_epochs_decoder_result_dict)\n",
    "# parent_output_folder = Path('output/long_like_during_post_delta').resolve()\n",
    "\n",
    "\n",
    "# active_epochs_decoder_result_dict = deepcopy(filtered_decoder_filter_epochs_decoder_result_dict)\n",
    "\n",
    "\n",
    "## Laps:\n",
    "active_epochs_decoder_result_dict = deepcopy(decoder_laps_filter_epochs_decoder_result_dict)\n",
    "\n",
    "\n",
    "\n",
    "parent_output_folder.mkdir(exist_ok=True)\n",
    "Assert.path_exists(parent_output_folder)\n",
    "posterior_out_folder = parent_output_folder.joinpath(DAY_DATE_TO_USE).resolve()\n",
    "posterior_out_folder.mkdir(parents=True, exist_ok=True)\n",
    "save_path = posterior_out_folder.resolve()\n",
    "_parent_save_context: IdentifyingContext = curr_active_pipeline.build_display_context_for_session('perform_export_all_decoded_posteriors_as_images')\n",
    "_specific_session_output_folder = save_path.joinpath(active_context.get_description(subset_excludelist=['format_name'])).resolve()\n",
    "_specific_session_output_folder.mkdir(parents=True, exist_ok=True)\n",
    "print(f'\\tspecific_session_output_folder: \"{_specific_session_output_folder}\"')\n",
    "\n",
    "custom_export_formats: Dict[str, HeatmapExportConfig] = {\n",
    "    # 'greyscale': HeatmapExportConfig.init_greyscale(desired_height=1200),\n",
    "    'color': HeatmapExportConfig.init_for_export_kind(export_kind=HeatmapExportKind.COLORMAPPED, colormap='Oranges', desired_height=1200),\n",
    "    # 'color': HeatmapExportConfig(colormap=additional_cmaps['long_LR']),\n",
    "    # 'color': HeatmapExportConfig(colormap=cmap1, desired_height=200),\n",
    "\t# 'raw_rgba': HeatmapExportConfig.init_for_export_kind(export_kind=HeatmapExportKind.RAW_RGBA, lower_bound_alpha=0.1, drop_below_threshold=1e-2, desired_height=1200),\n",
    "\t# 'raw_rgba': HeatmapExportConfig.init_for_export_kind(export_kind=HeatmapExportKind.RAW_RGBA, \n",
    "    #                                                     raw_RGBA_only_parameters = dict(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), xbin=deepcopy(a_decoder.xbin), lower_bound_alpha=0.1, drop_below_threshold=1e-2, t_bin_size=0.025),\n",
    "    #                                                     desired_height=1200),\n",
    "}\n",
    "# custom_export_formats = None\n",
    "\n",
    "\n",
    "# `raw_RGBA_only_parameters` dict with keys: ['spikes_df', 'xbin', 'lower_bound_alpha', 'drop_below_threshold', 't_bin_size']\n",
    "\n",
    "\n",
    "out_paths, out_custom_formats_dict = PosteriorExporting.perform_export_all_decoded_posteriors_as_images(decoder_laps_filter_epochs_decoder_result_dict=None, decoder_ripple_filter_epochs_decoder_result_dict=active_epochs_decoder_result_dict,\n",
    "# out_paths, out_custom_formats_dict = PosteriorExporting.perform_export_all_decoded_posteriors_as_images(decoder_laps_filter_epochs_decoder_result_dict=deepcopy(decoder_laps_filter_epochs_decoder_result_dict), decoder_ripple_filter_epochs_decoder_result_dict=None,\n",
    "                                                                                                            _save_context=_parent_save_context, parent_output_folder=_specific_session_output_folder,\n",
    "                                                                                                            desired_height=1200, custom_export_formats=custom_export_formats, combined_img_padding=6, combined_img_separator_color=(0, 0, 0, 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51933623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26558aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_uri_from_path(_specific_session_output_folder)\n",
    "fullwidth_path_widget(a_path=_specific_session_output_folder, file_name_label=\"epoch_specific_folder:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fcf49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_new_fully_generic_result.get_results_matching_contexts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58598b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['generalized_specific_epochs_decoding'],\n",
    "                        computation_kwargs_list=[{'epochs_decoding_time_bin_size': time_bin_size, 'drop_previous_result_and_compute_fresh': True, 'force_recompute': False}], \n",
    "                        enabled_filter_names=None, fail_on_exception=True, debug_print=False) \n",
    "\n",
    "# 11m 5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8607a51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# pbe_trained_decoder_search_context = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type=('ignore', 'nan_filled', 'dropped'), data_grain='per_time_bin') # , decoder_identifier='pseudo2D', data_grain= 'per_time_bin -- not really relevant: ['masked_time_bin_fill_type', 'known_named_decoding_epochs_type', 'data_grain']\n",
    "# laps_trained_decoder_search_context = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='dropped', data_grain='per_time_bin')\n",
    "pbe_trained_decoder_search_context = IdentifyingContext()\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=pbe_trained_decoder_search_context, return_multiple_matches=True, debug_print=False)\n",
    "flat_context_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0924b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "[Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_time_bin'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'nan_filled'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'dropped', data_grain= 'per_epoch'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'non_pbe_endcaps', masked_time_bin_fill_type= 'dropped', data_grain= 'per_time_bin', decoding_time_bin_size= 0.025),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'non_pbe', masked_time_bin_fill_type= 'last_valid'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'global', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'nan_filled'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'ignore'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'dropped', data_grain= 'per_time_bin'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'non_pbe_endcaps', masked_time_bin_fill_type= 'last_valid', data_grain= 'per_time_bin', decoding_time_bin_size= 0.025),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_epoch'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'global', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_time_bin'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'non_pbe_endcaps', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin', decoding_time_bin_size= 0.025),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'non_pbe', masked_time_bin_fill_type= 'ignore'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'non_pbe_endcaps', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_time_bin', decoding_time_bin_size= 0.025),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'ignore'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'last_valid'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'dropped', data_grain= 'per_epoch'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'laps'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'nan_filled'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'ignore', data_grain= 'per_epoch'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_time_bin'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'dropped', data_grain= 'per_time_bin'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'nan_filled'),\n",
    " Context(trained_compute_epochs= 'non_pbe', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'dropped', data_grain= 'per_time_bin'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_epoch'),\n",
    " Context(trained_compute_epochs= 'non_pbe', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore', data_grain= 'per_epoch'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'non_pbe', masked_time_bin_fill_type= 'nan_filled'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'non_pbe'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'pbe'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'dropped', data_grain= 'per_time_bin'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'last_valid')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2ceb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_epoch_specific_decoded_results1D_dict, continuous_specific_decoded_results1D_dict, new_decoder1D_dict, new_pf1Ds_dict = self.recompute(curr_active_pipeline=curr_active_pipeline, pfND_ndim=1, epochs_decoding_time_bin_size=epochs_decoding_time_bin_size, skip_training_test_split=skip_training_test_split)\n",
    "frame_divided_epochs_specific_decoded_results1D_dict = {a_name:a_new_decoder.decode_specific_epochs(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), filter_epochs=deepcopy(global_frame_divided_epochs_obj), decoding_time_bin_size=epochs_decoding_time_bin_size, debug_print=False) for a_name, a_new_decoder in new_decoder1D_dict.items()}\n",
    "results1D = DecodingResultND(ndim=1, \n",
    "    test_epoch_results=test_epoch_specific_decoded_results1D_dict, \n",
    "    continuous_results=continuous_specific_decoded_results1D_dict,\n",
    "    decoders=new_decoder1D_dict, pfs=new_pf1Ds_dict,\n",
    "    frame_divided_epochs_results=frame_divided_epochs_specific_decoded_results1D_dict, \n",
    "    frame_divided_epochs_df=deepcopy(global_frame_divided_epochs_df), pos_df=global_pos_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5807baf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get epochs to decode:\n",
    "\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "global_session = curr_active_pipeline.filtered_sessions[global_epoch_name]\n",
    "\n",
    "# global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "global_laps = ensure_Epoch(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps.to_dataframe())) # .trimmed_to_non_overlapping()\n",
    "global_PBEs = ensure_Epoch(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].pbe)) # .trimmed_to_non_overlapping()\n",
    "\n",
    "epochs_to_decode_dict: Dict = {'laps': global_laps, 'pbe': global_PBEs}\n",
    "## OUTPUTS: epochs_to_decode_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01da635",
   "metadata": {
    "tags": [
     "2025-05-30"
    ]
   },
   "outputs": [],
   "source": [
    "## INPUTS: curr_active_pipeline, epochs_decoding_time_bin_size, epochs_to_decode_dict, a_new_fully_generic_result\n",
    "\n",
    "## UPDATES: a_new_fully_generic_result\n",
    "\n",
    "decoders_dict: Dict[types.DecoderName, BasePositionDecoder] = deepcopy(track_templates.get_decoders_dict())\n",
    "laps_trained_decoder_search_context = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, masked_time_bin_fill_type='ignore', data_grain='per_time_bin') # , data_grain= 'per_time_bin -- not really relevant: ['masked_time_bin_fill_type', 'known_named_decoding_epochs_type', 'data_grain']\n",
    "\n",
    "## Can add:     known_named_decoding_epochs_type='laps', \n",
    "out_dict = {}\n",
    "\n",
    "for a_decoder_name, a_decoder in decoders_dict.items():\n",
    "    ## for each decoder\n",
    "    for an_epoch_to_decode_name, an_epochs_to_decode_obj in epochs_to_decode_dict.items():\n",
    "        ## for each epoch to decode\n",
    "        a_context: IdentifyingContext = deepcopy(laps_trained_decoder_search_context).overwriting_context(decoder_identifier=a_decoder_name, known_named_decoding_epochs_type=an_epoch_to_decode_name)        \n",
    "        a_result: DecodedFilterEpochsResult = a_decoder.decode_specific_epochs(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), filter_epochs=deepcopy(an_epochs_to_decode_obj), decoding_time_bin_size=epochs_decoding_time_bin_size, debug_print=False)\n",
    "        a_new_fully_generic_result.updating_results_for_context(new_context=a_context, a_result=a_result, a_decoder=deepcopy(a_decoder), a_decoded_marginal_posterior_df=None, an_epoch_to_decode=deepcopy(an_epochs_to_decode_obj)) ## update using the result\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b1a689",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict[a_context]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c6757c",
   "metadata": {},
   "source": [
    "# ❌ 2025-05-04 - 11am - New Overlayed plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8880f92f",
   "metadata": {
    "tags": [
     "run-group-mergedcolorplot"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _helper_add_interpolated_position_columns_to_decoded_result_df\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import MultiDecoderColorOverlayedPosteriors\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import EpochComputationFunctions, EpochComputationsComputationsContainer\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import SingleEpochDecodedResult\n",
    "\n",
    "\n",
    "valid_EpochComputations_result: EpochComputationsComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['EpochComputations']\n",
    "a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult = valid_EpochComputations_result.a_generic_decoder_dict_decoded_epochs_dict_result\n",
    "all_decoder_colors_dict = {'long': '#4169E1', 'short': '#DC143C', 'long_LR': '#4169E1', 'long_RL': '#607B00', 'short_LR': '#DC143C', 'short_RL': '#990099'} ## Just hardcoded version of `additional_cmap_names`\n",
    "\n",
    "## INPUTS: a_new_fully_generic_result\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='nan_filled', data_grain='per_time_bin')\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='ignore', data_grain='per_time_bin')\n",
    "best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=a_target_context, debug_print=False)\n",
    "## OUTPUTS: a_result, a_decoder, a_decoded_marginal_posterior_df\n",
    "## INPUTS: curr_active_pipeline, a_result, a_decoder, a_decoded_marginal_posterior_df\n",
    "global_measured_position_df: pd.DataFrame = deepcopy(curr_active_pipeline.sess.position.to_dataframe())\n",
    "a_decoded_marginal_posterior_df: pd.DataFrame = _helper_add_interpolated_position_columns_to_decoded_result_df(a_result=a_result, a_decoder=a_decoder, a_decoded_marginal_posterior_df=a_decoded_marginal_posterior_df, global_measured_position_df=global_measured_position_df)\n",
    "\n",
    "global_decoded_result: SingleEpochDecodedResult = a_result.get_result_for_epoch(0)\n",
    "p_x_given_n: NDArray[ND.Shape[\"N_POS_BINS, 4, N_TIME_BINS\"], np.floating] = deepcopy(global_decoded_result.p_x_given_n) # .shape # (59, 4, 69488)\n",
    "time_bin_centers: NDArray[ND.Shape[\"N_TIME_BINS\"], np.floating] = deepcopy(global_decoded_result.time_bin_container.centers)\n",
    "xbin: NDArray[ND.Shape[\"N_POS_BINS\"], np.floating] = deepcopy(a_decoder.xbin)\n",
    "\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-MultiDecoderColorOverlayedPosteriors.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "multi_decoder_color_overlay: MultiDecoderColorOverlayedPosteriors = MultiDecoderColorOverlayedPosteriors(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), p_x_given_n=p_x_given_n, time_bin_centers=time_bin_centers, xbin=xbin, lower_bound_alpha=0.0, drop_below_threshold=1e-3, t_bin_size=0.025)\n",
    "multi_decoder_color_overlay.compute_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a846a220",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = multi_decoder_color_overlay.add_tracks_to_spike_raster_window(active_2d_plot=active_2d_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77b4a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ccd339",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb62af58",
   "metadata": {},
   "source": [
    "# :🔝💯🟢🖼️ 2025-05-16 - Export Overlayed Plots for Pseudo2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ce6986",
   "metadata": {},
   "source": [
    "### Main Figure Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ef555b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'],\n",
    "                                                  # computation_kwargs_list=[{'time_bin_size': 0.016, 'should_disable_cache':False}], \n",
    "                                                  computation_kwargs_list=[{'time_bin_size': 0.025, 'should_disable_cache':True}], \n",
    "                                                  # computation_kwargs_list=[{'time_bin_size': 0.058, 'should_disable_cache':False}], \n",
    "                                                  enabled_filter_names=None, fail_on_exception=True, debug_print=True)\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'], computation_kwargs_list=[{'time_bin_size': 0.058}], #computation_kwargs_list=[{'time_bin_size': 0.025}], \n",
    "#                                                   enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0506efaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import EpochComputationDisplayFunctions\n",
    "import pyphoplacecellanalysis.General.type_aliases as types\n",
    "\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "\n",
    "time_bin_size: float = 0.025\n",
    "_out = EpochComputationDisplayFunctions._display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay(curr_active_pipeline, None, None, None, include_includelist=None, save_figure=True, parent_output_folder=collected_outputs_path, time_bin_size=time_bin_size)\n",
    "\n",
    "# curr_active_pipeline.plot\n",
    "# curr_active_pipeline.registered_display_function_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b2f7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization ______________________________________________________________________________________________________ #\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow, LayoutScrollability\n",
    "from pyphocorehelpers.plotting.media_output_helpers import vertical_image_stack, horizontal_image_stack, image_grid # used in `_subfn_build_combined_output_images`\n",
    "from pyphocorehelpers.image_helpers import ImageHelpers\n",
    "\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import HeatmapExportConfig, HeatmapExportKind\n",
    "\n",
    "out_paths: Dict[types.KnownNamedDecoderTrainedComputeEpochsType, Dict[types.DecoderName, Path]] = _out['out_paths']\n",
    "out_custom_formats_dict: Dict[types.KnownNamedDecodingEpochsType, Dict[types.DecoderName, Dict[str, List[HeatmapExportConfig]]]] = _out['out_custom_formats_dict']\n",
    "\n",
    "out_custom_formats_dict: Dict = _out['out_custom_formats_dict']\n",
    "\n",
    "# flat_imgs = []\n",
    "\n",
    "flat_imgs_dict: Dict[IdentifyingContext, List] = {}\n",
    "flat_merged_images = {}\n",
    "\n",
    "\n",
    "for a_series_name, v_dict in out_custom_formats_dict.items():\n",
    "    # a_series_name: ['laps', 'ripple']\n",
    "    for a_decoder_name, a_rendered_configs_dict in v_dict.items():\n",
    "        \n",
    "        for a_config_name, a_rendered_config_list in a_rendered_configs_dict.items():\n",
    "            # 'raw_rgba'\n",
    "            # print(a_rendered_config_list)\n",
    "            # len(a_rendered_config_list)\n",
    "            \n",
    "            a_ctxt = IdentifyingContext(series=a_series_name, decoder=a_decoder_name, config=a_config_name)\n",
    "            flat_imgs = []\n",
    "            \n",
    "            for i, a_config in enumerate(a_rendered_config_list):      \n",
    "                # posterior_save_path = a_config.posterior_saved_path\n",
    "                _posterior_image = a_config.posterior_saved_image\n",
    "                flat_imgs.append(_posterior_image)\n",
    "                \n",
    "                # print(F'a_rendered_config: {type(a_rendered_config)}')\n",
    "                # type(a_rendered_config_list[0])\n",
    "                # print(F'a_rendered_config: {list(a_rendered_config.keys())}')\n",
    "                # file_uri_from_path(a_path)\n",
    "                # fullwidth_path_widget(a_path=a_path, file_name_label=f\"{a_series_name}[{a_decoder_name}]:\")\n",
    "                # flat_img_out_paths.append(a_path)\n",
    "            ## END  for i, a_config in enum...\n",
    "            ## OUTPUTS: flat_imgs\n",
    "            _merged_img = horizontal_image_stack(flat_imgs, padding=10, separator_color='white')\n",
    "            flat_merged_images[a_series_name] = _merged_img\n",
    "            flat_imgs_dict[a_ctxt] = flat_imgs\n",
    "            \n",
    "\n",
    "# flat_img_out_paths\n",
    "flat_merged_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9328b4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_imgs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398079d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flat_merged_images['laps'].show()\n",
    "\n",
    "flat_merged_images['ripple'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fabb1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show output paths:\n",
    "\n",
    "flat_img_out_paths = []\n",
    "out_paths = deepcopy(_out['out_paths'])\n",
    "for a_series_name, v_dict in out_paths.items():\n",
    "    # a_series_name: ['laps', 'ripple']\n",
    "    for a_decoder_name, a_path in v_dict.items():\n",
    "        file_uri_from_path(a_path)\n",
    "        fullwidth_path_widget(a_path=a_path, file_name_label=f\"{a_series_name}[{a_decoder_name}]:\")\n",
    "        flat_img_out_paths.append(a_path)\n",
    "        \n",
    "flat_img_out_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c852e01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benedict import benedict\n",
    "\n",
    "out_custom_formats_dict = benedict(out_custom_formats_dict)\n",
    "out_custom_formats_dict.keypaths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee530a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = dict()\n",
    "_out['trackID_weighted_position_posterior'] = curr_active_pipeline.display(display_function='_display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay', active_session_configuration_context=None) # _display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d60a631",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# _out = curr_active_pipeline.display('_display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay')\n",
    "_out = curr_active_pipeline.display('trackID_weighted_position_posterior')\n",
    "\n",
    "# 'trackID_weighted_position_posterior'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e387d7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using: perform_export_all_decoded_posteriors_as_images\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import HeatmapExportConfig, PosteriorExporting\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import HeatmapExportKind\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import Assert\n",
    "\n",
    "## INPUTS:: filtered_decoder_filter_epochs_decoder_result_dict, long_like_during_post_delta_only_filter_epochs\n",
    "# active_epochs_decoder_result_dict = deepcopy(filtered_decoder_filter_epochs_decoder_result_dict)\n",
    "parent_output_folder = Path('output/array_to_images').resolve()\n",
    "\n",
    "## Build a makeshift dict with just the pseudo2D in it:\n",
    "## INPUTS:\n",
    "a_decoder = deepcopy(flat_decoder_context_dict[active_ctxts[0]])\n",
    "# a_decoder = deepcopy(a_laps_trained_decoder)\n",
    "\n",
    "## INPUTS: active_epochs_decoder_result_dict\n",
    "\n",
    "parent_output_folder.mkdir(exist_ok=True)\n",
    "Assert.path_exists(parent_output_folder)\n",
    "posterior_out_folder = parent_output_folder.joinpath(DAY_DATE_TO_USE).resolve()\n",
    "posterior_out_folder.mkdir(parents=True, exist_ok=True)\n",
    "save_path = posterior_out_folder.resolve()\n",
    "_parent_save_context: IdentifyingContext = curr_active_pipeline.build_display_context_for_session('perform_export_all_decoded_posteriors_as_images')\n",
    "_specific_session_output_folder = save_path.joinpath(active_context.get_description(subset_excludelist=['format_name'])).resolve()\n",
    "_specific_session_output_folder.mkdir(parents=True, exist_ok=True)\n",
    "print(f'\\tspecific_session_output_folder: \"{_specific_session_output_folder}\"')\n",
    "\n",
    "custom_export_formats: Dict[str, HeatmapExportConfig] = {\n",
    "\t# 'raw_rgba': HeatmapExportConfig.init_for_export_kind(export_kind=HeatmapExportKind.RAW_RGBA, lower_bound_alpha=0.1, drop_below_threshold=1e-2, desired_height=1200),\n",
    "\t'raw_rgba': HeatmapExportConfig.init_for_export_kind(export_kind=HeatmapExportKind.RAW_RGBA, \n",
    "                                                        raw_RGBA_only_parameters = dict(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), xbin=deepcopy(a_decoder.xbin), lower_bound_alpha=0.1, drop_below_threshold=1e-2, t_bin_size=0.025,  use_four_decoders_version=False),\n",
    "                                                        desired_height=1200),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\t# 'raw_rgba_four_decoders': HeatmapExportConfig.init_for_export_kind(export_kind=HeatmapExportKind.RAW_RGBA, \n",
    "    #                                                     raw_RGBA_only_parameters = dict(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), xbin=deepcopy(a_decoder.xbin), lower_bound_alpha=0.1, drop_below_threshold=1e-2, t_bin_size=0.025,  use_four_decoders_version=True),\n",
    "    #                                                     desired_height=1200),\n",
    "\n",
    "}\n",
    "# custom_export_formats = None\n",
    "\n",
    "out_paths, out_custom_formats_dict = PosteriorExporting.perform_export_all_decoded_posteriors_as_images(decoder_laps_filter_epochs_decoder_result_dict=decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict=decoder_ripple_filter_epochs_decoder_result_dict,\n",
    "# out_paths, out_custom_formats_dict = PosteriorExporting.perform_export_all_decoded_posteriors_as_images(decoder_laps_filter_epochs_decoder_result_dict=deepcopy(decoder_laps_filter_epochs_decoder_result_dict), decoder_ripple_filter_epochs_decoder_result_dict=None,\n",
    "                                                                                                            _save_context=_parent_save_context, parent_output_folder=_specific_session_output_folder,\n",
    "                                                                                                            desired_height=1200, custom_export_formats=custom_export_formats, combined_img_padding=6, combined_img_separator_color=(0, 0, 0, 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cde5cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_uri_from_path(_specific_session_output_folder)\n",
    "fullwidth_path_widget(a_path=_specific_session_output_folder, file_name_label=\"epoch_specific_folder:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a74abe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v_dict in out_paths.items():\n",
    "    for a_decoder_name, a_path in v_dict.items():\n",
    "        file_uri_from_path(a_path)\n",
    "        fullwidth_path_widget(a_path=a_path, file_name_label=f\"{k}[{a_decoder_name}]:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceec6d6",
   "metadata": {},
   "source": [
    "## 2025-05-19 - Re-loading the exported images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48521d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "from neuropy.utils.result_context import DisplaySpecifyingIdentifyingContext\n",
    "from pyphocorehelpers.assertion_helpers import Assert\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorPlottingDatasource, LoadedPosteriorContainer\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import H5FileAggregator\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "from neuropy.utils.result_context import DisplaySpecifyingIdentifyingContext\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import LoadedPosteriorContainer\n",
    "from neuropy.utils.indexing_helpers import flatten, flatten_dict\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionIdentityDataframeAccessor\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.computer_vision import ComputerVisionComputations\n",
    "\n",
    "# Visualization ______________________________________________________________________________________________________ #\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow, LayoutScrollability\n",
    "from pyphocorehelpers.plotting.media_output_helpers import vertical_image_stack, horizontal_image_stack, image_grid # used in `_subfn_build_combined_output_images`\n",
    "from pyphocorehelpers.image_helpers import ImageHelpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ab168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Using pathlib (more modern approach)\n",
    "\n",
    "# Example usage:\n",
    "a_path = flat_img_out_paths[0].joinpath('raw_rgba').resolve()\n",
    "Assert.path_exists(a_path)\n",
    "print(f'a_path: {a_path}')\n",
    "# parent_output_folder = Path('output/array_to_images').resolve()\n",
    "images_dict = ImageHelpers.load_png_images_pathlib(a_path)\n",
    "\n",
    "# Print the loaded images\n",
    "print(f\"Loaded {len(images_dict)} PNG images:\")\n",
    "# for name, img in images_dict.items():\n",
    "#     print(f\"{name}: {img.format}, {img.size}, {img.mode}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22664bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "\n",
    "# specific_epochs_posterior_out_folder = Path('outputs/arr_as_image').resolve()\n",
    "# Assert.path_exists(specific_epochs_posterior_out_folder)\n",
    "\n",
    "_single_epoch_combined_img = horizontal_image_stack(list(images_dict.values()), padding=4, separator_color='white')\n",
    "_single_epoch_combined_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17f3a95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83e1970",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "try:\n",
    "    for custom_export_format_series_name in list(out_custom_export_formats_results_dict[list(out_custom_export_formats_results_dict.keys())[0]].keys()):\n",
    "        _output_combined_dir, _output_combined_image_save_dirs = PosteriorExporting._subfn_build_combined_output_images(single_known_epoch_type_dict=out_custom_export_formats_results_dict, specific_epochs_posterior_out_folder=specific_epochs_posterior_out_folder,\n",
    "                                                                                                    known_epoch_type_name=epochs_name, custom_export_format_series_name=custom_export_format_series_name,\n",
    "                                                                                                    combined_img_padding=4, combined_img_separator_color=None)\n",
    "        \n",
    "except (AssertionError, ValueError) as e:\n",
    "    print(f'WARN: failed to merge images to combined images at the end with error: {e}')\n",
    "except Exception as e:\n",
    "    print(f'WARN: failed to merge images to combined images at the end with error: {e}')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948252f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v_dict in out_paths.items():\n",
    "    for a_decoder_name, a_path in v_dict.items():\n",
    "        file_uri_from_path(a_path)\n",
    "        fullwidth_path_widget(a_path=a_path, file_name_label=f\"{k}[{a_decoder_name}]:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0944bb",
   "metadata": {},
   "source": [
    "## 2025-05-19 - Heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc020b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring, HeuristicsResult\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import SerializationHelper_AllCustomDecodingResults, SerializationHelper_CustomDecodingResults\n",
    "from numpy import ma\n",
    "from neuropy.core.epoch import ensure_dataframe\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "\n",
    "## INPUTS: track_templates, a_decoded_filter_epochs_decoder_result_dict\n",
    "decoder_track_length_dict = track_templates.get_track_length_dict() # {'long_LR': 214.0, 'long_RL': 214.0, 'short_LR': 144.0, 'short_RL': 144.0}\n",
    "same_thresh_fraction_of_track: float = 0.05 ## up to 5.0% of the track\n",
    "same_thresh_cm: float = {k:(v * same_thresh_fraction_of_track) for k, v in decoder_track_length_dict.items()}\n",
    "a_same_thresh_cm: float = same_thresh_cm['long_LR']\n",
    "max_jump_distance_cm: float = 60.0\n",
    "print(f'a_same_thresh_cm: {a_same_thresh_cm}')\n",
    "print(f'max_jump_distance_cm: {max_jump_distance_cm}')\n",
    "# print(list(HeuristicReplayScoring.build_all_score_computations_fn_dict().keys())) # ['jump', 'max_jump_cm', 'max_jump_cm_per_sec', 'ratio_jump_valid_bins', 'travel', 'coverage', 'sequential_correlation', 'monotonicity_score', 'laplacian_smoothness']\n",
    "\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps'] # DirectionalLapsResult\n",
    "# a_name: str = 'long_LR'\n",
    "# a_directional_decoders_epochs_decode_result: DecodedFilterEpochsResult = a_decoded_filter_epochs_decoder_result_dict[a_name]\n",
    "\n",
    "## INPUTS: curr_active_pipeline, track_templates, a_decoded_filter_epochs_decoder_result_dict\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = deepcopy(curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']) ## GENERAL\n",
    "a_decoded_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "a_decoded_filter_epochs_decoder_result_dict, _out_new_scores, partition_result_dict = HeuristicReplayScoring.compute_all_heuristic_scores(track_templates=track_templates, a_decoded_filter_epochs_decoder_result_dict=a_decoded_filter_epochs_decoder_result_dict,\n",
    "                                                                                                                                            max_ignore_bins=2, same_thresh_cm=a_same_thresh_cm, max_jump_distance_cm=max_jump_distance_cm)\n",
    "# # a_decoded_filter_epochs_decoder_result_dict\n",
    "a_heuristics_result = HeuristicsResult(heuristic_scores_df_dict=_out_new_scores, partition_result_dict=partition_result_dict)\n",
    "\n",
    "directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict = deepcopy(a_decoded_filter_epochs_decoder_result_dict)\n",
    "# directional_decoders_epochs_decode_result.build_complete_all_scores_merged_df\n",
    "curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations'] = directional_decoders_epochs_decode_result ## MIGHT NEED SAVING\n",
    "print(f'PIPELINE MIGHT NEED SAVING')\n",
    "## INPUTS: curr_active_pipeline, track_templates, a_decoded_filter_epochs_decoder_result_dict\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = deepcopy(curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']) ## GENERAL\n",
    "## INPUTS: directional_decoders_epochs_decode_result, filtered_epochs_df\n",
    "\n",
    "decoder_ripple_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "unfiltered_epochs_df = deepcopy(decoder_ripple_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a0c9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "unfiltered_epochs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb89ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_epochs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed89365",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _plot_heuristic_evaluation_epochs\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_filter_replay_epochs\n",
    "\n",
    "# force_refilter = False\n",
    "force_refilter = True\n",
    "\n",
    "needs_refilter = False\n",
    "try:\n",
    "    filtered_decoder_filter_epochs_decoder_result_dict\n",
    "    filtered_epochs_df\n",
    "    filtered_ripple_all_epoch_bins_marginals_df\n",
    "    if filtered_decoder_filter_epochs_decoder_result_dict is not None:\n",
    "        needs_refilter = False\n",
    "except NameError:\n",
    "    needs_refilter = True\n",
    "    \n",
    "if needs_refilter or force_refilter:\n",
    "    filtered_epochs_df, filtered_decoder_filter_epochs_decoder_result_dict, filtered_ripple_all_epoch_bins_marginals_df = _perform_filter_replay_epochs(curr_active_pipeline, global_epoch_name, track_templates, decoder_ripple_filter_epochs_decoder_result_dict, ripple_all_epoch_bins_marginals_df, ripple_decoding_time_bin_size=ripple_decoding_time_bin_size, should_only_include_user_selected_epochs=True)\n",
    "\n",
    "## INPUTS: `filtered_epochs_df`\n",
    "if filtered_epochs_df is not None:\n",
    "    ## filter\n",
    "    filtered_decoder_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(filtered_epochs_df[['start', 'stop']].to_numpy()) for a_name, a_result in decoder_ripple_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "    high_heuristic_only_filtered_decoder_filter_epochs_decoder_result_dict = deepcopy(filtered_decoder_filter_epochs_decoder_result_dict)\n",
    "else:\n",
    "    filtered_decoder_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(unfiltered_epochs_df[['start', 'stop']].to_numpy()) for a_name, a_result in decoder_ripple_filter_epochs_decoder_result_dict.items()} # working unfiltered\n",
    "\n",
    "ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "print(f'{pos_bin_size = }, {ripple_decoding_time_bin_size = }')\n",
    "\n",
    "## OUTPUT: filtered_decoder_filter_epochs_decoder_result_dict, \n",
    "\n",
    "## 3m 2.2s\n",
    "# 59.1s\n",
    "\n",
    "# same_thresh_cm\n",
    "# a_result: DecodedFilterEpochsResult, an_epoch_idx: int, a_decoder_track_length: float, pos_bin_edges: NDArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fc5774",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_decoder_filter_epochs_decoder_result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c3f4fa",
   "metadata": {},
   "source": [
    "## <a id='toc11_2_'></a>[Find indicies that are included in `high_heuristic_only_filtered_decoder_filter_epochs_decoder_result_dict` from `filtered_decoder_filter_epochs_decoder_result_dict`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e894afe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: high_heuristic_only_filtered_decoder_filter_epochs_decoder_result_dict, filtered_decoder_filter_epochs_decoder_result_dict\n",
    "# INPUTS: included_heuristic_ripple_start_times, high_heuristic_only_filtered_decoder_filter_epochs_decoder_result_dict, excluded_heuristic_ripple_start_times, low_heuristic_only_filtered_decoder_filter_epochs_decoder_result_dict\n",
    "\n",
    "example_decoder_name = 'long_LR'\n",
    "all_epoch_result: DecodedFilterEpochsResult = deepcopy(filtered_decoder_filter_epochs_decoder_result_dict[example_decoder_name])\n",
    "all_filter_epochs_df: pd.DataFrame = deepcopy(all_epoch_result.filter_epochs)\n",
    "\n",
    "included_filter_epoch_result: DecodedFilterEpochsResult = deepcopy(high_heuristic_only_filtered_decoder_filter_epochs_decoder_result_dict[example_decoder_name])\n",
    "# included_filter_epoch_result: DecodedFilterEpochsResult = deepcopy(low_heuristic_only_filtered_decoder_filter_epochs_decoder_result_dict[example_decoder_name])\n",
    "\n",
    "included_filter_epochs_df: pd.DataFrame = deepcopy(included_filter_epoch_result.filter_epochs)\n",
    "included_filter_epochs_df\n",
    "\n",
    "# included_filter_epoch_times = included_filter_epochs_df[['start', 'stop']].to_numpy() # Both 'start', 'stop' column matching\n",
    "included_filter_epoch_times = included_filter_epochs_df['start'].to_numpy() # Both 'start', 'stop' column matching\n",
    "\n",
    "included_filter_epoch_times_to_all_epoch_index_map = included_filter_epoch_result.find_epoch_times_to_data_indicies_map(epoch_times=included_filter_epoch_times)\n",
    "included_filter_epoch_times_to_all_epoch_index_arr: NDArray = included_filter_epoch_result.find_data_indicies_from_epoch_times(epoch_times=included_filter_epoch_times)\n",
    "len(included_filter_epoch_times_to_all_epoch_index_arr)\n",
    "\n",
    "## OUTPUTS: all_filter_epochs_df, all_filter_epochs_df\n",
    "## OUTPUTS: included_filter_epoch_times_to_all_epoch_index_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f31556",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a12dd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = dict()\n",
    "\n",
    "included_filter_epochs_df: pd.DataFrame = deepcopy(high_heuristic_only_filtered_decoder_filter_epochs_decoder_result_dict[example_decoder_name].filter_epochs)\n",
    "included_filter_epochs_df\n",
    "_out['trackID_weighted_position_posterior'] = curr_active_pipeline.display(display_function='_display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay', active_session_configuration_context=None, time_bin_size=0.025,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t    filter_epochs_ripple_df=deepcopy(included_filter_epochs_df),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t) # _display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72824473",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out['trackID_weighted_position_posterior']['out_paths']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b4dfb5",
   "metadata": {},
   "source": [
    "## <a id='toc11_3_'></a>[Add the high-heuristic PBEs as an interval-rect dataseries to the continuous viewer](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b130769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: included_filter_epochs_df\n",
    "\n",
    "## Extract the specific results:\n",
    "# included_filter_epochs_df\n",
    "\n",
    "\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.Specific2DRenderTimeEpochs import General2DRenderTimeEpochs, inline_mkColor\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import Spike2DRaster\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.EpochRenderingMixin import EpochRenderingMixin, RenderedEpochsItemsContainer\n",
    "from pyphoplacecellanalysis.General.Model.Datasources.IntervalDatasource import IntervalsDatasource\n",
    "from neuropy.utils.mixins.time_slicing import TimeColumnAliasesProtocol\n",
    "\n",
    "\n",
    "## Use the three dataframes as separate Epoch series:\n",
    "updated_epochs_dfs_dict = {\n",
    "    'HighHeuristic': included_filter_epochs_df,\n",
    "}\n",
    "\n",
    "updated_epochs_formatting_dict = {\n",
    "    'HighHeuristic':dict(y_location=-10.0, height=7.5, pen_color=inline_mkColor('green', 0.8), brush_color=inline_mkColor('green', 0.5)),\n",
    "}\n",
    "\n",
    "required_vertical_offsets, required_interval_heights = EpochRenderingMixin.build_stacked_epoch_layout([1.0], epoch_render_stack_height=40.0, interval_stack_location='below') # ratio of heights to each interval\n",
    "stacked_epoch_layout_dict = {interval_key:dict(y_location=y_location, height=height) for interval_key, y_location, height in zip(list(updated_epochs_formatting_dict.keys()), required_vertical_offsets, required_interval_heights)} # Build a stacked_epoch_layout_dict to update the display\n",
    "# stacked_epoch_layout_dict # {'LapsAll': {'y_location': -3.6363636363636367, 'height': 3.6363636363636367}, 'LapsTrain': {'y_location': -21.818181818181817, 'height': 18.18181818181818}, 'LapsTest': {'y_location': -40.0, 'height': 18.18181818181818}}\n",
    "\n",
    "# replaces 'y_location', 'position' for each dict:\n",
    "updated_epochs_formatting_dict = {k:(v|stacked_epoch_layout_dict[k]) for k, v in updated_epochs_formatting_dict.items()}\n",
    "updated_epochs_formatting_dict\n",
    "\n",
    "# OUTPUTS: updated_epochs_dfs_dict, updated_epochs_formatting_dict\n",
    "## INPUTS: updated_epochs_dfs_dict\n",
    "updated_epochs_dfs_dict = {k:TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(df=v, required_columns_synonym_dict=IntervalsDatasource._time_column_name_synonyms) for k, v in updated_epochs_dfs_dict.items()}\n",
    "\n",
    "## Build interval datasources for them:\n",
    "updated_epochs_dfs_datasources_dict = {k:General2DRenderTimeEpochs.build_render_time_epochs_datasource(v) for k, v in updated_epochs_dfs_dict.items()}\n",
    "## INPUTS: active_2d_plot, train_test_split_laps_epochs_formatting_dict, train_test_split_laps_dfs_datasources_dict\n",
    "assert len(updated_epochs_formatting_dict) == len(updated_epochs_dfs_datasources_dict)\n",
    "for k, an_interval_ds in updated_epochs_dfs_datasources_dict.items():\n",
    "    an_interval_ds.update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, **(updated_epochs_formatting_dict[k] | kwargs)))\n",
    "\n",
    "## Full output: updated_epochs_dfs_datasources_dict\n",
    "# actually add the epochs:\n",
    "for k, an_interval_ds in updated_epochs_dfs_datasources_dict.items():\n",
    "    active_2d_plot.add_rendered_intervals(an_interval_ds, name=f'{k}', debug_print=False) # adds the interval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070d1bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94db2b0f",
   "metadata": {},
   "source": [
    "# TODONO - 2025-06-04 - Paper 2025 Figure Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37e253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.BatchCompletionHandler import BatchSessionCompletionHandler\n",
    "from neuropy.utils.matplotlib_helpers import matplotlib_file_only\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import main_complete_figure_generations\n",
    "\n",
    "\n",
    "# self.try_complete_figure_generation_to_file(curr_active_pipeline, enable_default_neptune_plots=self.should_generate_all_plots)\n",
    "fail_on_exception: bool = False\n",
    "enable_default_neptune_plots = False\n",
    "completed_good: bool = False\n",
    "\n",
    "try:\n",
    "    ## To file only:\n",
    "    with matplotlib_file_only():\n",
    "        # Perform non-interactive Matplotlib operations with 'AGG' backend\n",
    "        # neptuner = batch_perform_all_plots(curr_active_pipeline, enable_neptune=True, neptuner=None)\n",
    "        main_complete_figure_generations(curr_active_pipeline, enable_default_neptune_plots=enable_default_neptune_plots, save_figures_only=True, save_figure=True)\n",
    "\n",
    "    # IF thst's done, clear all the plots:\n",
    "    # from matplotlib import pyplot as plt\n",
    "    # plt.close('all') # this takes care of the matplotlib-backed figures.\n",
    "    curr_active_pipeline.clear_display_outputs()\n",
    "    curr_active_pipeline.clear_registered_output_files()\n",
    "    completed_good = True # completed successfully (without raising an error at least).\n",
    "\n",
    "except Exception as e:\n",
    "    completed_good =  False\n",
    "    raise\n",
    "    # exception_info = sys.exc_info()\n",
    "    # e = CapturedException(e, exception_info)\n",
    "    # print(f'main_complete_figure_generations failed with exception: {e}')\n",
    "    # if fail_on_exception:\n",
    "    #     raise e.exc\n",
    "\n",
    "\n",
    "\n",
    "## OUTPUTS: completed_good\n",
    "print(f'completed_good: {completed_good}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736407dd",
   "metadata": {},
   "source": [
    "# 2025-06-13 - Heuristic Scores used continuously as replay detection \n",
    "[/c:/Users/pho/repos/Spike3DWorkEnv/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/heuristic_replay_scoring.py:3187](vscode://file/c:/Users/pho/repos/Spike3DWorkEnv/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/heuristic_replay_scoring.py:3187)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3c4676",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get global/continuous result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5df166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _helper_add_interpolated_position_columns_to_decoded_result_df\n",
    "\n",
    "## Run heuristic continuously to determine when to split sequences and thus where replays are\n",
    "\n",
    "valid_EpochComputations_result: EpochComputationsComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['EpochComputations']\n",
    "a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult = valid_EpochComputations_result.a_generic_decoder_dict_decoded_epochs_dict_result\n",
    "\n",
    "## INPUTS: a_new_fully_generic_result\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='nan_filled', data_grain='per_time_bin')\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='ignore', data_grain='per_time_bin')\n",
    "best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=a_target_context, debug_print=False)\n",
    "## OUTPUTS: a_result, a_decoder, a_decoded_marginal_posterior_df\n",
    "## INPUTS: curr_active_pipeline, a_result, a_decoder, a_decoded_marginal_posterior_df\n",
    "global_measured_position_df: pd.DataFrame = deepcopy(curr_active_pipeline.sess.position.to_dataframe())\n",
    "a_decoded_marginal_posterior_df: pd.DataFrame = _helper_add_interpolated_position_columns_to_decoded_result_df(a_result=a_result, a_decoder=a_decoder, a_decoded_marginal_posterior_df=a_decoded_marginal_posterior_df, global_measured_position_df=global_measured_position_df)\n",
    "\n",
    "global_decoded_result: SingleEpochDecodedResult = a_result.get_result_for_epoch(0)\n",
    "p_x_given_n: NDArray[ND.Shape[\"N_POS_BINS, 4, N_TIME_BINS\"], np.floating] = deepcopy(global_decoded_result.p_x_given_n) # .shape # (59, 4, 69488)\n",
    "time_bin_centers: NDArray[ND.Shape[\"N_TIME_BINS\"], np.floating] = deepcopy(global_decoded_result.time_bin_container.centers)\n",
    "xbin: NDArray[ND.Shape[\"N_POS_BINS\"], np.floating] = deepcopy(a_decoder.xbin)\n",
    "p_x_given_n.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370d7665",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unpack from pipeline:\n",
    "valid_EpochComputations_result: EpochComputationsComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['EpochComputations'] # owning_pipeline_reference.global_computation_results.computed_data['EpochComputations']\n",
    "assert valid_EpochComputations_result is not None\n",
    "epochs_decoding_time_bin_size: float = valid_EpochComputations_result.epochs_decoding_time_bin_size ## just get the standard size. Currently assuming all things are the same size!\n",
    "print(f'epochs_decoding_time_bin_size: {epochs_decoding_time_bin_size}')\n",
    "assert epochs_decoding_time_bin_size == valid_EpochComputations_result.epochs_decoding_time_bin_size, f\"\\tERROR: nonPBE_results.epochs_decoding_time_bin_size: {valid_EpochComputations_result.epochs_decoding_time_bin_size} != epochs_decoding_time_bin_size: {epochs_decoding_time_bin_size}\"\n",
    "a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult = valid_EpochComputations_result.a_generic_decoder_dict_decoded_epochs_dict_result ## get existing\n",
    "\n",
    "active_time_bin_size: float = 0.025\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', masked_time_bin_fill_type='dropped', data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps', time_bin_size=0.025\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='nan_filled', data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps', time_bin_size=0.025\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=active_time_bin_size, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='ignore', data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps', time_bin_size=0.025\n",
    "best_matching_context, a_pseudo2D_result, a_pseudo2D_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=a_target_context, debug_print=False)\n",
    "# print(f'best_matching_context: {best_matching_context}')\n",
    "best_matching_context\n",
    "\n",
    "print(f'a_pseudo2D_result: {a_pseudo2D_result}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a748bd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attrs import asdict\n",
    "from neuropy.utils.indexing_helpers import PandasHelpers\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring, HeuristicScoresTuple, SubsequencesPartitioningResultScoringComputations\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import SubsequencesPartitioningResult\n",
    "\n",
    "\n",
    "## INPUTS: a_pseudo2D_result\n",
    "unique_decoder_names = ['long_LR', 'long_RL', 'short_LR', 'short_RL'] # ['long', 'short']\n",
    "a_pseudo2D_split_to_1D_continuous_results_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = a_pseudo2D_result.split_pseudo2D_result_to_1D_result(pseudo2D_decoder_names_list=unique_decoder_names, a_pseudo2D_decoder=a_pseudo2D_decoder )\n",
    "a_decoded_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(a_pseudo2D_split_to_1D_continuous_results_dict)\n",
    "a_decoded_filter_epochs_decoder_result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b612a680",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: track_templates, a_pseudo2D_split_to_1D_continuous_results_dict \n",
    "# pos_bin_edges: NDArray = deepcopy(xbin)\n",
    "# track_templates: TrackTemplates\n",
    "use_bin_units_instead_of_realworld:bool=False\n",
    "# max_ignore_bins:float = 2 ## for PBEs\n",
    "max_ignore_bins:float = 9 ## for Laps\n",
    "# 5 skip bins\n",
    "# same_thresh_cm: float = 6.0\n",
    "same_thresh_cm: float = 60.0\n",
    "# max_jump_distance_cm: float = 60.0\n",
    "max_jump_distance_cm: float = 200.0\n",
    "debug_print=False\n",
    "\n",
    "# pos_bounds = [np.min([track_templates.long_LR_decoder.xbin, track_templates.short_LR_decoder.xbin]), np.max([track_templates.long_LR_decoder.xbin, track_templates.short_LR_decoder.xbin])] # [37.0773897438341, 253.98616538463315]\n",
    "num_pos_bins: int = track_templates.long_LR_decoder.n_xbin_centers\n",
    "xbin_edges: NDArray = deepcopy(track_templates.long_LR_decoder.xbin)\n",
    "decoder_track_length_dict = track_templates.get_track_length_dict()  # {'long_LR': 214.0, 'long_RL': 214.0, 'short_LR': 144.0, 'short_RL': 144.0}\n",
    "\n",
    "# computation_fn_kwargs_dict: passed to each score function to specify additional required parameters\n",
    "computation_fn_kwargs_dict = {\n",
    "    'main_contiguous_subsequence_len': dict(same_thresh_cm=same_thresh_cm, max_ignore_bins=max_ignore_bins, same_thresh_fraction_of_track=None, max_jump_distance_cm=max_jump_distance_cm, pos_bin_edges=deepcopy(xbin_edges)),\n",
    "    'continuous_seq_len_ratio_no_repeats': dict(same_thresh_cm=same_thresh_cm, max_ignore_bins=max_ignore_bins, same_thresh_fraction_of_track=None, max_jump_distance_cm=max_jump_distance_cm, pos_bin_edges=deepcopy(xbin_edges)),\n",
    "    'continuous_seq_sort': dict(same_thresh_cm=same_thresh_cm, max_ignore_bins=max_ignore_bins, same_thresh_fraction_of_track=None, max_jump_distance_cm=max_jump_distance_cm, pos_bin_edges=deepcopy(xbin_edges)),\n",
    "    'sweep_score':  dict(same_thresh_cm=same_thresh_cm, max_ignore_bins=max_ignore_bins, same_thresh_fraction_of_track=None, max_jump_distance_cm=max_jump_distance_cm, num_pos_bins=num_pos_bins, pos_bin_edges=deepcopy(xbin_edges)),\n",
    "    'track_coverage_score':  dict(same_thresh_cm=same_thresh_cm, max_ignore_bins=max_ignore_bins, same_thresh_fraction_of_track=None, max_jump_distance_cm=max_jump_distance_cm, pos_bin_edges=deepcopy(xbin_edges)),\n",
    "    'total_distance_traveled': dict(same_thresh_cm=same_thresh_cm, max_ignore_bins=max_ignore_bins, same_thresh_fraction_of_track=None, max_jump_distance_cm=max_jump_distance_cm, pos_bin_edges=deepcopy(xbin_edges)),\n",
    "} | {k:deepcopy(dict(same_thresh_cm=same_thresh_cm, max_ignore_bins=max_ignore_bins, same_thresh_fraction_of_track=None, max_jump_distance_cm=max_jump_distance_cm, pos_bin_edges=deepcopy(xbin_edges))) for k in ['mseq_len', 'mseq_len_ignoring_intrusions',\n",
    "                                                                                                                                                                                                                    'mseq_len_ignoring_intrusions_and_repeats', 'mseq_len_ratio_ignoring_intrusions_and_repeats', 'mseq_tcov', 'mseq_dtrav']}\n",
    "# computation_fn_kwargs_dict: passed to each score function to specify additional required parameters\n",
    "if computation_fn_kwargs_dict is None:\n",
    "    raise NotImplementedError(f'YOU BETTER PASS ONE! 2024-12-05')\n",
    "\n",
    "all_subseq_partitioning_score_computations_fn_dict = SubsequencesPartitioningResultScoringComputations.build_all_bin_wise_subseq_partitioning_computation_fn_dict()\n",
    "\n",
    "# BEGIN EXPAND cls._run_all_score_computations _______________________________________________________________________ #\n",
    "\n",
    "## INPUTS: a_decoded_filter_epochs_decoder_result_dict, decoder_track_length_dict\n",
    "partition_result_dict: Dict[types.DecoderName, List[SubsequencesPartitioningResult]] = {} # SubsequencesPartitioningResult\n",
    "# END for `a_decoded_filter_epochs_decoder_result_dict`\n",
    "## OUTPUTS: all_epochs_scores_dict, all_epochs_scores_df\n",
    "# all_epochs_scores_df = pd.DataFrame(all_epochs_scores_dict)\n",
    "\n",
    "_out_new_scores: Dict[str, pd.DataFrame] = {}\n",
    "\n",
    "for a_name, a_result in a_decoded_filter_epochs_decoder_result_dict.items():\n",
    "    ## all four decoders are guaranteed to be independent\n",
    "    # Performs the score computations specified in `all_score_computations_fn_dict` \n",
    "    # Idea is to have a general format for the functions that can be ran, and this function loops through all of them passing them what they need to run (all decoders, all epochs) and then collects their outputs to get simple DataFrames of scores for each epoch.\n",
    "\n",
    "    a_decoder_track_length: float = decoder_track_length_dict[a_name]\n",
    "\n",
    "    _all_epochs_scores_dict = {} # holds a single flat dataframe with scores from across all decoders\n",
    "    _separate_decoder_new_scores_df = {} # holds one df for each decoder name in a_decoded_filter_epochs_decoder_result_dict\n",
    "    _a_separate_decoder_new_scores_dict = {}\n",
    "    # _a_separate_decoder_partition_result_dict: Dict[types.DecoderName, List[SubsequencesPartitioningResult]] = {} # SubsequencesPartitioningResult\n",
    "\n",
    "    partition_result_dict[a_name] = [SubsequencesPartitioningResultScoringComputations._META_build_epoch_SubsequencesPartitioningResult(a_result=a_result, an_epoch_idx=an_epoch_idx, a_decoder_track_length=a_decoder_track_length, same_thresh_cm=same_thresh_cm, max_ignore_bins=int(max_ignore_bins), same_thresh_fraction_of_track=None, max_jump_distance_cm=max_jump_distance_cm, pos_bin_edges=deepcopy(xbin_edges)) for an_epoch_idx in np.arange(a_result.num_filter_epochs)]\n",
    "\n",
    "    ## compute all `subseq_partitioning` scores for this decoder:\n",
    "    for score_computation_name, computation_fn in all_subseq_partitioning_score_computations_fn_dict.items():\n",
    "        score_name: str = score_computation_name # bin_wise_position_difference.short_name or bin_wise_position_difference.__name__\n",
    "        single_decoder_column_name = f\"{score_name}\"\n",
    "        unique_full_decoder_score_column_name: str = f\"{score_name}_{a_name}\"\n",
    "\n",
    "        # 'main_contiguous_subsequence_len_short_LR'\n",
    "        _all_epochs_scores_dict[unique_full_decoder_score_column_name] = [computation_fn(partition_result=a_partition_result, a_result=a_result, an_epoch_idx=an_epoch_idx, a_decoder_track_length=a_decoder_track_length, pos_bin_edges=xbin_edges) for an_epoch_idx, a_partition_result in enumerate(partition_result_dict[a_name])]\n",
    "        _a_separate_decoder_new_scores_dict[single_decoder_column_name] = deepcopy(_all_epochs_scores_dict[unique_full_decoder_score_column_name]) # a single column, all epochs\n",
    "    # END for all_subseq_partitioning_score_computations_fn_dict\n",
    "\n",
    "\n",
    "    ## once done with all scores for this decoder, have `_a_separate_decoder_new_scores_dict`:\n",
    "    _separate_decoder_new_scores_df[a_name] =  pd.DataFrame(_a_separate_decoder_new_scores_dict)\n",
    "    assert np.shape(_separate_decoder_new_scores_df[a_name])[0] == np.shape(a_result.filter_epochs)[0], f\"np.shape(separate_decoder_new_scores_df[a_name])[0]: {np.shape(_separate_decoder_new_scores_df[a_name])[0]} != np.shape(a_result.filter_epochs)[0]: {np.shape(a_result.filter_epochs)[0]}\"\n",
    "    a_result.filter_epochs = PandasHelpers.adding_additional_df_columns(original_df=a_result.filter_epochs, additional_cols_df=_separate_decoder_new_scores_df[a_name]) # update the filter_epochs with the new columns\n",
    "\n",
    "    _out_new_scores[a_name] =  pd.DataFrame([asdict(HeuristicReplayScoring.compute_pho_heuristic_replay_scores(a_result=a_result, an_epoch_idx=an_epoch_idx, pos_bin_edges=deepcopy(xbin_edges), use_bin_units_instead_of_realworld=use_bin_units_instead_of_realworld, max_ignore_bins=max_ignore_bins, same_thresh_cm=same_thresh_cm, max_jump_distance_cm=max_jump_distance_cm), filter=lambda a, v: a.name not in ['position_derivatives_df']) for an_epoch_idx in np.arange(a_result.num_filter_epochs)])\n",
    "    assert np.shape(_out_new_scores[a_name])[0] == np.shape(a_result.filter_epochs)[0], f\"np.shape(_out_new_scores[a_name])[0]: {np.shape(_out_new_scores[a_name])[0]} != np.shape(a_result.filter_epochs)[0]: {np.shape(a_result.filter_epochs)[0]}\"\n",
    "    a_result.filter_epochs = PandasHelpers.adding_additional_df_columns(original_df=a_result.filter_epochs, additional_cols_df=_out_new_scores[a_name]) # update the filter_epochs with the new columns\n",
    "# END for a_name, a_result in....\n",
    "\n",
    "## OUTPUTS: a_decoded_filter_epochs_decoder_result_dict, _out_new_scores, partition_result_dict\n",
    "partition_result_dict = {k:v[0] for k, v in partition_result_dict.items()} ## there's only one entry in this list\n",
    "\n",
    "# _out_new_scores = {k:v[0] for k, v in _out_new_scores.items()}\n",
    "# _out_new_scores\n",
    "\n",
    "# ~1m5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17f65d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Single decoder test:\n",
    "a_partition_result: SubsequencesPartitioningResult = deepcopy(partition_result_dict[a_name])\n",
    "a_partition_result\n",
    "bin_width, (x_starts, x_centers, x_ends), x_bins = a_partition_result.get_flat_time_bins_info()\n",
    "\n",
    "# a_partition_result.merged_split_position_flatindicies_arrays\n",
    "subsequences_df: pd.DataFrame = deepcopy(a_partition_result.subsequences_df)\n",
    "subsequences_df\n",
    "\n",
    "high_heuristic_only_subsequences_df: pd.DataFrame = subsequences_df[subsequences_df['len_excluding_intrusions'] > 6]\n",
    "high_heuristic_only_subsequences_df\n",
    "\n",
    "\n",
    "# high_heuristic_only_subsequences_df: pd.DataFrame = subsequences_df[subsequences_df['len_excluding_both'] > 5]\n",
    "# high_heuristic_only_subsequences_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0909440",
   "metadata": {},
   "source": [
    "### Add `high_heuristic_only_subsequences_df` as epoch Intervals (rectangles) on the Spike2DRaster interval timeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cee425",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.interval_rendering_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b9a31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add `high_heuristic_only_subsequences_df` as epochs on the Spike2DRaster interval timeline\n",
    "interval_info = active_2d_plot.list_all_rendered_intervals()\n",
    "interval_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff56cfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_display_configs = active_2d_plot.extract_interval_display_config_lists()\n",
    "# epoch_display_configs\n",
    "# active_2d_plot.interval_datasources # RenderPlotsData\n",
    "# datasource_to_update\n",
    "\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.mixins.epochs_plotting_mixins import EpochDisplayConfig\n",
    "\n",
    "out_configs_df = []\n",
    "# rendered_epoch_names = self.interval_datasource_names\n",
    "for a_name, a_config_list in epoch_display_configs.items():\n",
    "    num_configs: int = len(a_config_list)\n",
    "    for (i, a_config) in enumerate(a_config_list):\n",
    "        if num_configs > 1:\n",
    "            config_name: str = f'{a_name}[{i}]'\n",
    "        else:\n",
    "            config_name: str = a_name\n",
    "        # a_config\n",
    "        out_config_dict = {'name': config_name} | deepcopy(a_config.to_dict())\n",
    "        out_configs_df.append(out_config_dict) # [a_name] = result\n",
    "    \n",
    "\n",
    "out_configs_df: pd.DataFrame = pd.DataFrame(out_configs_df)\n",
    "out_configs_df['y0_location'] = out_configs_df['y_location']\n",
    "out_configs_df['y1_location'] = out_configs_df['y0_location'] + out_configs_df['height']\n",
    "out_configs_df\n",
    "any_interval_ymin = np.min(out_configs_df['y0_location'])\n",
    "any_interval_ymax = np.max(out_configs_df['y1_location'])\n",
    "\n",
    "## OUTPUTS: out_configs_df, any_interval_ymin, any_interval_ymax\n",
    "any_interval_ymin, any_interval_ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71f72bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_x_min, curr_x_max, curr_y_min, curr_y_max = active_2d_plot.get_render_intervals_plot_range()\n",
    "(curr_x_min, curr_x_max, curr_y_min, curr_y_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c6fd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_series_positioning_dfs, all_series_compressed_positioning_dfs, all_series_compressed_positioning_update_dicts = active_2d_plot.recover_interval_datasources_positioning_properties()\n",
    "all_series_compressed_positioning_dfs\n",
    "# all_series_compressed_positioning_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1078e89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.Specific2DRenderTimeEpochs import General2DRenderTimeEpochs, inline_mkColor\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.EpochRenderingMixin import EpochRenderingMixin\n",
    "from pyphoplacecellanalysis.General.Model.Datasources.IntervalDatasource import IntervalsDatasource\n",
    "from neuropy.utils.mixins.time_slicing import TimeColumnAliasesProtocol\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DecoderIdentityColors\n",
    "\n",
    "decoder_color_dict: Dict[types.DecoderName, str] = DecoderIdentityColors.build_decoder_color_dict()\n",
    "\n",
    "\n",
    "## INPUTS: partition_result_dict, any_interval_ymin\n",
    "_out_epochs_formatting_dict = {}\n",
    "# interval_y_height: float = 0.9\n",
    "# interval_y_padding: float = 0.1\n",
    "# for i, (a_decoder_name, v) in enumerate(partition_result_dict.items()):\n",
    "#     curr_interval_total_y_offset: float = (-float(i) * (interval_y_padding + interval_y_height)) + any_interval_ymin\n",
    "#     _out_epochs_formatting_dict[f\"HSeq_{a_decoder_name}\"] = dict(y_location=curr_interval_total_y_offset, height=interval_y_height, pen_color=inline_mkColor('white', 0.8), brush_color=inline_mkColor('white', 0.5))\n",
    "\n",
    "interval_y_height: float = 0.9\n",
    "interval_y_padding: float = 0.1\n",
    "required_vertical_offsets = []\n",
    "required_interval_heights = []\n",
    "for i, (a_decoder_name, v) in enumerate(partition_result_dict.items()):\n",
    "    # curr_interval_total_y_offset: float = (-float(i) * (interval_y_padding + interval_y_height)) + any_interval_ymin\n",
    "    curr_interval_total_y_offset: float =  -(interval_y_padding + interval_y_height) + any_interval_ymin\n",
    "    _out_epochs_formatting_dict[f\"HSeq_{a_decoder_name}\"] = dict(y_location=curr_interval_total_y_offset, height=interval_y_height,\n",
    "                                                                #   pen_color=inline_mkColor('white', 0.8),\n",
    "                                                                    pen_color=inline_mkColor(decoder_color_dict[a_decoder_name], 0.8),\n",
    "                                                                    brush_color=inline_mkColor('white', 0.5))\n",
    "    required_vertical_offsets.append(curr_interval_total_y_offset)\n",
    "    required_interval_heights.append(interval_y_height)\n",
    "# _out_epochs_formatting_dict = {'HSeq_long_LR': {'y_location': -4.0, 'height': 0.9, 'pen_color': inline_mkColor('white', 0.8), 'brush_color': inline_mkColor('white', 0.5)},\n",
    "#  'HSeq_long_RL': {'y_location': -4.0, 'height': 0.9, 'pen_color': inline_mkColor('white', 0.8), 'brush_color': inline_mkColor('white', 0.5)},\n",
    "#  'HSeq_short_LR': {'y_location': -4.0, 'height': 0.9, 'pen_color': inline_mkColor('white', 0.8), 'brush_color': inline_mkColor('white', 0.5)},\n",
    "#  'HSeq_short_RL': {'y_location': -4.0, 'height': 0.9, 'pen_color': inline_mkColor('white', 0.8), 'brush_color': inline_mkColor('white', 0.5)}}\n",
    "\n",
    "## OUTPUTS: _out_epochs_formatting_dict\n",
    "_out_epochs_formatting_dict\n",
    "\n",
    "required_columns_synonym_dict = {\"start\":{'start_t','begin','start_t'}, \"stop\":['end_t', 'end','stop_t']}\n",
    "# required_vertical_offsets, required_interval_heights = EpochRenderingMixin.build_stacked_epoch_layout([0.23, 0.23, 0.23, 0.23], epoch_render_stack_height=1.0, interval_stack_location='below') # ratio of heights to each interval\n",
    "# required_vertical_offsets, required_interval_heights\n",
    "\n",
    "stacked_epoch_layout_dict = {interval_key:dict(y_location=y_location, height=height) for interval_key, y_location, height in zip(list(_out_epochs_formatting_dict.keys()), required_vertical_offsets, required_interval_heights)} # Build a stacked_epoch_layout_dict to update the display\n",
    "# stacked_epoch_layout_dict # {'LapsAll': {'y_location': -3.6363636363636367, 'height': 3.6363636363636367}, 'LapsTrain': {'y_location': -21.818181818181817, 'height': 18.18181818181818}, 'LapsTest': {'y_location': -40.0, 'height': 18.18181818181818}}\n",
    "\n",
    "# replaces 'y_location', 'position' for each dict:\n",
    "_out_epochs_formatting_dict = {k:(v|stacked_epoch_layout_dict[k]) for k, v in _out_epochs_formatting_dict.items()}\n",
    "_out_epochs_formatting_dict\n",
    "\n",
    "\n",
    "# a_partition_result: SubsequencesPartitioningResult = deepcopy(partition_result_dict[a_name])\n",
    "# a_partition_result\n",
    "# bin_width, (x_starts, x_centers, x_ends), x_bins = a_partition_result.get_flat_time_bins_info()\n",
    "# train_test_split_laps_dfs_dict = {k:TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(df=v, required_columns_synonym_dict=IntervalsDatasource._time_column_name_synonyms) for k, v in partition_result_dict.items()}\n",
    "## Build interval datasources for them:\n",
    "# train_test_split_laps_dfs_datasources_dict = {k:General2DRenderTimeEpochs.build_render_time_epochs_datasource(v) for k, v in train_test_split_laps_dfs_dict.items()}\n",
    "## INPUTS: active_2d_plot, _out_epochs_formatting_dict, train_test_split_laps_dfs_datasources_dict\n",
    "for a_decoder_name, a_partition_result in partition_result_dict.items():\n",
    "    a_heuristic_result_name: str = f\"HSeq_{a_decoder_name}\"\n",
    "    subsequences_df: pd.DataFrame = deepcopy(a_partition_result.subsequences_df)\n",
    "    high_heuristic_only_subsequences_df: pd.DataFrame = subsequences_df[subsequences_df['len_excluding_both'] > 5]\n",
    "    high_heuristic_only_subsequences_df = TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(df=high_heuristic_only_subsequences_df, required_columns_synonym_dict=required_columns_synonym_dict)\n",
    "    if 't_duration' not in high_heuristic_only_subsequences_df.columns:\n",
    "        high_heuristic_only_subsequences_df['t_duration'] = high_heuristic_only_subsequences_df['stop'] - high_heuristic_only_subsequences_df['start']\n",
    "    an_interval_ds = General2DRenderTimeEpochs.build_render_time_epochs_datasource(high_heuristic_only_subsequences_df)\n",
    "\n",
    "    an_interval_ds.update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, **(_out_epochs_formatting_dict[a_heuristic_result_name] | kwargs)))\n",
    "    active_2d_plot.add_rendered_intervals(an_interval_ds, name=a_heuristic_result_name, debug_print=False) # adds the interval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9890ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21ae8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_heuristic_only_subsequences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9016a2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_partition_result.position_bins_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c908a41d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674d5fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_new_scores['long_LR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48fa7a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a88d296",
   "metadata": {},
   "source": [
    "# 2025-06-16 - Need to update heuristic to work on behavioral-scale (laps) movement sequences\\\n",
    "- [ ] Ignore theta-scale oscilations/regressions in decoded position\n",
    "- [ ] Recognize the majority of lap position bins as beloning to the same sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d04b6f",
   "metadata": {},
   "source": [
    "## Compute heuristics for current laps objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748d2bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import TimeColumnAliasesProtocol\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring, HeuristicsResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "\n",
    "## 2025-06-16 14:22 Copied from `pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions._decoded_epochs_heuristic_scoring` but generalized for laps\n",
    "same_thresh_fraction_of_track: float = 0.05\n",
    "max_ignore_bins:float = 9\n",
    "# max_jump_distance_cm: float = 60.0\n",
    "max_jump_distance_cm: float = 260.0\n",
    "use_bin_units_instead_of_realworld:bool = False\n",
    "\n",
    "\n",
    "# 🟪 2024-02-29 - `compute_pho_heuristic_replay_scores` ______________________________________________________________ #\n",
    "minimum_inclusion_fr_Hz: float = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.minimum_inclusion_fr_Hz\n",
    "included_qclu_values: List[int] = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.included_qclu_values\n",
    "\n",
    "# rank_order_results = global_computation_results.computed_data['RankOrder'] # : \"RankOrderComputationsContainer\"\n",
    "# minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "# included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, included_qclu_values=included_qclu_values) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\n",
    "# print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "# print(f'included_qclu_values: {included_qclu_values}')\n",
    "\n",
    "decoder_track_length_dict = track_templates.get_track_length_dict() # {'long_LR': 214.0, 'long_RL': 214.0, 'short_LR': 144.0, 'short_RL': 144.0}\n",
    "\n",
    "# same_thresh_fraction_of_track: float = 0.025 ## up to 2.5% of the track -- notably worse\n",
    "# same_thresh_fraction_of_track: float = 0.05 ## up to 5.0% of the track\n",
    "\n",
    "# same_thresh_fraction_of_track: float = 0.15 ## up to 15% of the track\n",
    "same_thresh_cm_dict: Dict[types.DecoderName, float] = {k:(v * same_thresh_fraction_of_track) for k, v in decoder_track_length_dict.items()}\n",
    "# same_thresh_n_bin_units: float = {k:(v * same_thresh_fraction_of_track) for k, v in decoder_track_length_dict.items()}\n",
    "\n",
    "a_same_thresh_cm: float = same_thresh_cm_dict['long_LR'] # ALWAYS USE THE SAME FOR ALL TRACKS/DECODERS\n",
    "# a_same_thresh_cm: float = 0.0\n",
    "print(f'same_thresh_cm: {a_same_thresh_cm}')\n",
    "\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "ripple_decoding_time_bin_size: float = directional_merged_decoders_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_merged_decoders_result.laps_decoding_time_bin_size\n",
    "\n",
    "# DirectionalDecodersEpochsEvaluations\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict\n",
    "# decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict\n",
    "\n",
    "decoder_laps_filter_epochs_decoder_result_dict, _laps_out_new_scores, _laps_partition_result_dict = HeuristicReplayScoring.compute_all_heuristic_scores(track_templates=track_templates, a_decoded_filter_epochs_decoder_result_dict=decoder_laps_filter_epochs_decoder_result_dict,\n",
    "                                                            same_thresh_cm=a_same_thresh_cm, max_ignore_bins=max_ignore_bins, max_jump_distance_cm=max_jump_distance_cm, use_bin_units_instead_of_realworld=use_bin_units_instead_of_realworld)\n",
    "a_laps_heuristics_result: HeuristicsResult = HeuristicsResult(is_global=True, heuristic_scores_df_dict=_laps_out_new_scores, partition_result_dict=_laps_partition_result_dict)\n",
    "## OUTPUTS: a_laps_heuristics_result, decoder_laps_filter_epochs_decoder_result_dict, (_laps_out_new_scores, _laps_partition_result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314523c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import SerializationHelper_AllCustomDecodingResults\n",
    "\n",
    "## Serialize the output:\n",
    "output_path = Path(r'K:\\scratch\\output').resolve()\n",
    "Assert.path_exists(output_path)\n",
    "heuristics_pkl_output_path = output_path.joinpath('heuristics_pkl.pkl').resolve()\n",
    "a_laps_heuristics_result.save(pkl_output_path=heuristics_pkl_output_path, status_print=True)\n",
    "heuristics_pkl_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c2d038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import SerializationHelper_AllCustomDecodingResults\n",
    "\n",
    "save_path = curr_active_pipeline.get_output_path().joinpath(f\"{DAY_DATE_TO_USE}_AllCustomDecodingResults.pkl\").resolve()\n",
    "save_path = SerializationHelper_AllCustomDecodingResults.save(track_templates=track_templates, a_directional_decoders_epochs_decode_result=directional_decoders_epochs_decode_result, \n",
    "                                        #    a_decoded_filter_epochs_decoder_result_dict=deepcopy(a_decoded_filter_epochs_decoder_result_dict),\n",
    "                                           pos_bin_size=directional_decoders_epochs_decode_result.pos_bin_size,\n",
    "\t\t\t\t\t\t\t\t\t\t   laps_decoding_time_bin_size=directional_decoders_epochs_decode_result.laps_decoding_time_bin_size,\n",
    "\t\t\t\t\t\t\t\t\t\t   #  ripple_decoding_time_bin_size=directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size,\n",
    "\t\t\t\t\t\t\t\t\t\t    save_path=save_path)\n",
    "save_path\n",
    "\n",
    "\n",
    "# load_path = Path(\"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2025-06-16_AllCustomDecodingResults.pkl\")\n",
    "# track_templates, directional_decoders_epochs_decode_result, xbin, xbin_centers =  SerializationHelper_AllCustomDecodingResults.save(load_path=load_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d05c048",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5747f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_decoder_decoded_epochs_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(decoder_laps_filter_epochs_decoder_result_dict)\n",
    "active_filter_epochs_df: pd.DataFrame = deepcopy(active_decoder_decoded_epochs_result_dict['long_LR'].filter_epochs) # deepcopy(matching_specific_start_ts_only_filter_epochs_df)\n",
    "active_filter_epochs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93affb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get laps\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "global_session = curr_active_pipeline.filtered_sessions[global_epoch_name]\n",
    "# global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps) # .trimmed_to_non_overlapping()\n",
    "global_laps_epochs_df = global_laps.to_dataframe()\n",
    "# active_test_epochs_df: pd.DataFrame = deepcopy(global_laps_epochs_df)\n",
    "global_laps_epochs_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e6b56d",
   "metadata": {},
   "source": [
    "## Test Plot Heuristic Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185607cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Silx.EpochHeuristicPosteriorDebuggerWidget import EpochHeuristicDebugger\n",
    "\n",
    "\n",
    "# a_decoder_decoded_epochs_result: DecodedFilterEpochsResult = deepcopy(directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict['long_LR'])\n",
    "a_decoder_decoded_epochs_result: DecodedFilterEpochsResult = deepcopy(directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict['long_LR'])\n",
    "\n",
    "p_x_given_n_masked = deepcopy(a_decoder_decoded_epochs_result.p_x_given_n_list[5])\n",
    "p_x_given_n_masked\n",
    "\n",
    "dbgr = EpochHeuristicDebugger(p_x_given_n_masked=deepcopy(p_x_given_n_masked))\n",
    "dbgr.build_ui()\n",
    "\n",
    "slider = widgets.IntSlider(value=12, min=0, max=(a_decoder_decoded_epochs_result.num_filter_epochs-1))\n",
    "slider.observe(dbgr.on_slider_change, names='value')\n",
    "display(slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7ebc43",
   "metadata": {},
   "source": [
    "## 2025-06-16 - Simple 2D plot with Long Track Shape drawn under the x-axis and the Short Track Shape drawn to the left of the y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a68477",
   "metadata": {
    "tags": [
     "todo-2025-06-16"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import create_long_v_short_track_plot_figure\n",
    "\n",
    "active_config = global_session.config\n",
    "fig, ax_dict, long_inst, short_inst, long_out, short_out = create_long_v_short_track_plot_figure(active_config)\n",
    "\n",
    "# Add your data to the main plot\n",
    "# ax_dict[\"ax_main\"].scatter(x_data, y_data)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b732fe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.geometry_helpers import BoundsRect\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import LinearTrackDimensions, LinearTrackInstance\n",
    "\n",
    "platform_side_length:float=22.0\n",
    "# a_sess_config = deepcopy(active_config)\n",
    "# loaded_track_limits = deepcopy(a_sess_config.loaded_track_limits) # {'long_xlim': array([59.0774, 228.69]), 'short_xlim': array([94.0156, 193.757]), 'long_ylim': array([138.164, 146.12]), 'short_ylim': array([138.021, 146.263])}\n",
    "loaded_track_limits = {'long_xlim': np.array([59.0774, 228.69]),\n",
    " 'long_unit_xlim': np.array([0.205294, 0.794698]),\n",
    " 'short_xlim': np.array([94.0156, 193.757]),\n",
    " 'short_unit_xlim': np.array([0.326704, 0.673304]),\n",
    " 'long_ylim': np.array([138.164, 146.12]),\n",
    " 'long_unit_ylim': np.array([0.48012, 0.507766]),\n",
    " 'short_ylim': np.array([138.021, 146.263]),\n",
    " 'short_unit_ylim': np.array([0.479622, 0.508264])}\n",
    "\n",
    "loaded_track_limits\n",
    "# x_midpoint: float = a_sess_config.x_midpoint\n",
    "# pix2cm: float = a_sess_config.pix2cm\n",
    "\n",
    "long_xlim = loaded_track_limits['long_xlim']\n",
    "long_ylim = loaded_track_limits['long_ylim']\n",
    "\n",
    "## if we have short, build that one too:\n",
    "short_xlim = loaded_track_limits['short_xlim']\n",
    "short_ylim = loaded_track_limits['short_ylim']\n",
    "\n",
    "LONG_from_mat_lims_grid_bin_bounds = BoundsRect(xmin=(long_xlim[0]-platform_side_length), xmax=(long_xlim[1]+platform_side_length), ymin=long_ylim[0], ymax=long_ylim[1])\n",
    "SHORT_from_mat_lims_grid_bin_bounds = BoundsRect(xmin=(short_xlim[0]-platform_side_length), xmax=(short_xlim[1]+platform_side_length), ymin=short_ylim[0], ymax=short_ylim[1])\n",
    "\n",
    "long_track_inst = LinearTrackInstance(LinearTrackDimensions.init_from_grid_bin_bounds(LONG_from_mat_lims_grid_bin_bounds), grid_bin_bounds=LONG_from_mat_lims_grid_bin_bounds)\n",
    "short_track_inst = LinearTrackInstance(LinearTrackDimensions.init_from_grid_bin_bounds(SHORT_from_mat_lims_grid_bin_bounds), grid_bin_bounds=SHORT_from_mat_lims_grid_bin_bounds)\n",
    "\n",
    "## OUTPUTS: long_track_inst, short_track_inst\n",
    "fig, ax_dict, long_inst, short_inst, long_out, short_out = create_long_v_short_track_plot_figure(long_track_inst=long_track_inst, short_track_inst=short_track_inst)\n",
    "\n",
    "# Add your data to the main plot\n",
    "# ax_dict[\"ax_main\"].scatter(x_data, y_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366abba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import create_long_v_short_track_plot_figure_from_loaded_track_limits\n",
    "\n",
    "loaded_track_limits = {'long_xlim': np.array([59.0774, 228.69]),\n",
    " 'long_unit_xlim': np.array([0.205294, 0.794698]),\n",
    " 'short_xlim': np.array([94.0156, 193.757]),\n",
    " 'short_unit_xlim': np.array([0.326704, 0.673304]),\n",
    " 'long_ylim': np.array([138.164, 146.12]),\n",
    " 'long_unit_ylim': np.array([0.48012, 0.507766]),\n",
    " 'short_ylim': np.array([138.021, 146.263]),\n",
    " 'short_unit_ylim': np.array([0.479622, 0.508264])}\n",
    "\n",
    "fig, ax_dict, long_inst, short_inst, long_out, short_out = create_long_v_short_track_plot_figure_from_loaded_track_limits(loaded_track_limits=loaded_track_limits)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8237a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_track_limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874f4d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50010259",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_figures_script_paths = [Path(v) for v in ['C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts\\\\run_kdiba_gor01_one_2006-6-07_11-26-53\\\\figures_kdiba_gor01_one_2006-6-07_11-26-53.py',\n",
    " 'C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts\\\\run_kdiba_gor01_one_2006-6-08_14-26-15\\\\figures_kdiba_gor01_one_2006-6-08_14-26-15.py',\n",
    " 'C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts\\\\run_kdiba_gor01_one_2006-6-09_1-22-43\\\\figures_kdiba_gor01_one_2006-6-09_1-22-43.py',\n",
    " 'C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts\\\\run_kdiba_gor01_one_2006-6-12_15-55-31\\\\figures_kdiba_gor01_one_2006-6-12_15-55-31.py',\n",
    " 'C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts\\\\run_kdiba_gor01_two_2006-6-07_16-40-19\\\\figures_kdiba_gor01_two_2006-6-07_16-40-19.py',\n",
    " 'C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts\\\\run_kdiba_gor01_two_2006-6-08_21-16-25\\\\figures_kdiba_gor01_two_2006-6-08_21-16-25.py',\n",
    " 'C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts\\\\run_kdiba_gor01_two_2006-6-09_22-24-40\\\\figures_kdiba_gor01_two_2006-6-09_22-24-40.py',\n",
    " 'C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts\\\\run_kdiba_gor01_two_2006-6-12_16-53-46\\\\figures_kdiba_gor01_two_2006-6-12_16-53-46.py',\n",
    " 'C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts\\\\run_kdiba_vvp01_one_2006-4-09_17-29-30\\\\figures_kdiba_vvp01_one_2006-4-09_17-29-30.py',\n",
    " 'C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts\\\\run_kdiba_vvp01_one_2006-4-10_12-25-50\\\\figures_kdiba_vvp01_one_2006-4-10_12-25-50.py',\n",
    " 'C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts\\\\run_kdiba_vvp01_two_2006-4-09_16-40-54\\\\figures_kdiba_vvp01_two_2006-4-09_16-40-54.py',\n",
    " 'C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts\\\\run_kdiba_vvp01_two_2006-4-10_12-58-3\\\\figures_kdiba_vvp01_two_2006-4-10_12-58-3.py',\n",
    " 'C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts\\\\run_kdiba_pin01_one_11-02_17-46-44\\\\figures_kdiba_pin01_one_11-02_17-46-44.py',\n",
    " 'C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts\\\\run_kdiba_pin01_one_11-02_19-28-0\\\\figures_kdiba_pin01_one_11-02_19-28-0.py',\n",
    " 'C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts\\\\run_kdiba_pin01_one_11-03_12-3-25\\\\figures_kdiba_pin01_one_11-03_12-3-25.py',\n",
    " 'C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts\\\\run_kdiba_pin01_one_fet11-01_12-58-54\\\\figures_kdiba_pin01_one_fet11-01_12-58-54.py']]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# generate_figures_script_paths\n",
    "# gen_scripts_fig_paths = [Path(r'K:\\scratch\\gen_scripts').joinpath(Path(k).parent.relative_to('C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts')) for k in generate_figures_script_paths]\n",
    "gen_scripts_sess_folder_paths = [Path(r'K:\\scratch\\gen_scripts').joinpath(Path(k).parent.relative_to('C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts')) for k in generate_figures_script_paths]\n",
    "gen_scripts_sess_folder_paths\n",
    "# gen_scripts_fig_paths\n",
    "gen_scripts_sess_folder_paths = [v for v in gen_scripts_sess_folder_paths if v.exists()]\n",
    "\n",
    "gen_scripts_fig_paths = [Path(k).parent.joinpath('EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2025-07-02').resolve() for k in gen_scripts_sess_folder_paths]\n",
    "\n",
    "gen_scripts_sess_folder_paths\n",
    "gen_scripts_fig_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1840ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_scripts_fig_paths = [Path(k).parent.joinpath('EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2025-07-02').resolve() for k in generate_figures_script_paths]\n",
    "\n",
    "gen_scripts_fig_paths = [v for v in gen_scripts_fig_paths if v.exists()]\n",
    "gen_scripts_fig_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ff32be",
   "metadata": {},
   "source": [
    "# 2025-07-08 - Quantitative LxC/SxC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d483de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# track_templates.get_decoder_aclu_peak_map_dict(peak_mode='peaks')\n",
    "\n",
    "# track_templates.long_LR_decoder.\n",
    "\n",
    "## Just needs laps\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps).trimmed_to_non_overlapping() \n",
    "global_laps_epochs_df = global_laps.to_dataframe()\n",
    "global_laps_epochs_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300212ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# peaks_results_df: pd.DataFrame = track_templates.long_LR_decoder.get_tuning_curve_peak_df(peak_mode='peaks')\n",
    "\n",
    "\n",
    "# peaks_results_df: pd.DataFrame = track_templates.long_LR_decoder.pf.tuning_curves_dict\n",
    "\n",
    "\n",
    "filtered_spikes_df: pd.DataFrame = track_templates.long_LR_decoder.pf.filtered_spikes_df\n",
    "filtered_spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e211b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_counts_dict = {a_decoder_name:deepcopy(a_decoder.pf.filtered_spikes_df['aclu']).value_counts().to_dict() for a_decoder_name, a_decoder in track_templates.get_decoders_dict().items()}\n",
    "any_decoder_aclus_list = deepcopy(track_templates.any_decoder_neuron_IDs)\n",
    "any_decoder_aclus_list ## this somehow loses the short-only cells?!?! Such as [3, 4, 8, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d01cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import PhoJonathanPlotHelpers\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import BatchPhoJonathanFiguresHelper\n",
    "\n",
    "## Get global 'jonathan_firing_rate_analysis' results:\n",
    "curr_jonathan_firing_rate_analysis = curr_active_pipeline.global_computation_results.computed_data['jonathan_firing_rate_analysis']\n",
    "neuron_replay_stats_df, rdf, aclu_to_idx, irdf = curr_jonathan_firing_rate_analysis.neuron_replay_stats_df, curr_jonathan_firing_rate_analysis.rdf.rdf, curr_jonathan_firing_rate_analysis.rdf.aclu_to_idx, curr_jonathan_firing_rate_analysis.irdf.irdf\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Batch Output of Figures                                                                                              #\n",
    "# ==================================================================================================================== #\n",
    "## 🗨️🟢 2022-11-05 - Pho-Jonathan Batch Outputs of Firing Rate Figures\n",
    "short_only_df = neuron_replay_stats_df[neuron_replay_stats_df.track_membership == SplitPartitionMembership.RIGHT_ONLY]\n",
    "short_only_aclus = short_only_df.index.values.tolist()\n",
    "long_only_df = neuron_replay_stats_df[neuron_replay_stats_df.track_membership == SplitPartitionMembership.LEFT_ONLY]\n",
    "long_only_aclus = long_only_df.index.values.tolist()\n",
    "shared_df = neuron_replay_stats_df[neuron_replay_stats_df.track_membership == SplitPartitionMembership.SHARED]\n",
    "shared_aclus = shared_df.index.values.tolist()\n",
    "print(f'shared_aclus: {shared_aclus}')\n",
    "print(f'long_only_aclus: {long_only_aclus}')\n",
    "print(f'short_only_aclus: {short_only_aclus}')\n",
    "\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'    \n",
    "## MODE: this mode creates a special folder to contain the outputs for this session.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c54a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates\n",
    "\n",
    "decoders_total_num_spikes_df, (LxC_cells_df, SxC_cells_df) = TrackTemplates.perform_determine_quant_cell_eXclusivities(track_templates=track_templates)\n",
    "# decoders_total_num_spikes_df['aclu'] = decoders_total_num_spikes_df.index\n",
    "decoders_total_num_spikes_df: pd.DataFrame = deepcopy(decoders_total_num_spikes_df)\n",
    "# decoders_total_num_spikes_df = decoders_total_num_spikes_df.neuron_identity.make_neuron_indexed_df_global(curr_active_pipeline.get_session_context(), add_expanded_session_context_keys=False, add_extended_aclu_identity_columns=True)\n",
    "# decoders_total_num_spikes_df\n",
    "# LxC_cells_df, SxC_cells_df\n",
    "\n",
    "# print(decoders_total_num_spikes_df.columns.to_list()) # ['long_LR_n_spikes', 'long_RL_n_spikes', 'short_LR_n_spikes', 'short_RL_n_spikes', 'long_n_spikes', 'short_n_spikes', 'total_n_spikes', 'pct_long_n_spikes', 'pct_short_n_spikes', 'is_n_spikes_LxC', 'is_n_spikes_SxC']\n",
    "# ['long_LR_lap_dur', 'long_RL_lap_dur', 'short_LR_lap_dur', 'short_RL_lap_dur', 'long_lap_dur', 'short_lap_dur', 'total_lap_dur', 'long_fr_Hz', 'short_fr_Hz', 'total_fr_Hz', 'pct_long_fr_Hz', 'pct_short_fr_Hz', 'is_fr_Hz_LxC', 'is_fr_Hz_SxC']\n",
    "decoders_total_num_spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b229cc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoders_total_num_spikes_df[decoders_total_num_spikes_df['is_fr_Hz_LxC']]\n",
    "decoders_total_num_spikes_df[decoders_total_num_spikes_df['is_fr_Hz_SxC']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad25c9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_templates.long_LR_decoder.pf.epochs\n",
    "\n",
    "total_duration_dict = {k:deepcopy(v.pf.epochs.duration).sum() for k, v in track_templates.get_decoders_dict().items()}\n",
    "total_duration_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab36cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03f08bdd",
   "metadata": {},
   "source": [
    "# 2025-07-09 - Computation Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10755e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout, _master_params_dict = curr_active_pipeline.get_all_parameters(allow_update_global_computation_config=False, get_panel_gui_widget=True)\n",
    "layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60ee562",
   "metadata": {},
   "outputs": [],
   "source": [
    "_master_params_dict['preprocessing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b725c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.parameters import ParametersContainer\n",
    "\n",
    "# After user makes changes, get updated values:\n",
    "current_params = deepcopy(curr_active_pipeline.global_computation_results.computation_config.to_dict())\n",
    "current_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f9fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import ast\n",
    "\n",
    "# Create widgets\n",
    "minimum_fr_widget = widgets.IntText(\n",
    "    value=2,\n",
    "    description='Min FR (Hz):',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='200px')\n",
    ")\n",
    "\n",
    "qclu_text_widget = widgets.Text(\n",
    "    value='[1, 2, 4, 6, 7, 8, 9]',\n",
    "    description='QClu Values:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='300px')\n",
    ")\n",
    "\n",
    "# Button to get values\n",
    "get_values_button = widgets.Button(\n",
    "    description='Get Current Values',\n",
    "    button_style='info'\n",
    ")\n",
    "\n",
    "# Output area\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_button_click(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        \n",
    "        # Parse the qclu values from text\n",
    "        try:\n",
    "            qclu_values = ast.literal_eval(qclu_text_widget.value)\n",
    "            if not isinstance(qclu_values, list):\n",
    "                qclu_values = [qclu_values]\n",
    "        except:\n",
    "            print(\"Error: Invalid format for QClu Values. Please use format: [1, 2, 3, ...]\")\n",
    "            return\n",
    "            \n",
    "        values = {\n",
    "            'minimum_inclusion_fr_Hz': minimum_fr_widget.value,\n",
    "            'included_qclu_values': qclu_values\n",
    "        }\n",
    "        print(\"Selected values:\", values)\n",
    "\n",
    "get_values_button.on_click(on_button_click)\n",
    "\n",
    "# Display interface\n",
    "interface = widgets.VBox([\n",
    "    minimum_fr_widget,\n",
    "    qclu_text_widget,\n",
    "    get_values_button,\n",
    "    output\n",
    "])\n",
    "\n",
    "display(interface)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c586ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preprocessing_parameters: ParametersContainer = deepcopy(curr_active_pipeline.active_sess_config)\n",
    "preprocessing_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fdeaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\t\t\t\t\t\t\t\t\t\n",
    "# long_pf1D.config # {'speed_thresh': 10.0, 'grid_bin': (4.877453969028168, 14.388489208633093), 'grid_bin_bounds': ((0.0, 287.7697841726619), (86.33093525179856, 201.4388489208633)), 'smooth': (2.0, 2.0), 'frate_thresh': 1.0, 'is_directional': False}\n",
    "track_templates.long_LR_decoder.pf.config # {'speed_thresh': 10.0, 'grid_bin': (4.877453969028168, 14.388489208633093), 'grid_bin_bounds': ((0.0, 287.7697841726619), (86.33093525179856, 201.4388489208633)), 'smooth': (2.0, 2.0), 'frate_thresh': 1.0, 'is_directional': False}\n",
    "\n",
    "{'speed_thresh': 10.0, 'grid_bin': (4.877453969028168, 14.388489208633093), 'grid_bin_bounds': ((0.0, 287.7697841726619), (86.33093525179856, 201.4388489208633)), 'smooth': (2.0, 2.0), 'frate_thresh': 1.0, 'is_directional': False} ## Kamran used 1.44cm^2 Pseudo2D bins\n",
    "\n",
    "\n",
    "long_pf2D.config\n",
    "# [/c:/Users/pho/repos/Spike3DWorkEnv/NeuroPy/neuropy/core/session/Formats/BaseDataSessionFormats.py:279](vscode://file/c:/Users/pho/repos/Spike3DWorkEnv/NeuroPy/neuropy/core/session/Formats/BaseDataSessionFormats.py:279)\n",
    "# ```python\n",
    "# # From `core.session.Formats.BaseDataSessionFormats.build_default_computation_configs`\n",
    "# 'speed_thresh': 10.0, 'grid_bin': cls.compute_position_grid_bin_size(sess.position.x, sess.position.y, num_bins=(64, 64)), 'grid_bin_bounds': None, 'smooth': (2.0, 2.0), 'frate_thresh': 1.0, 'time_bin_size': 0.1, \n",
    "# ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2738436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import FigureOutputLocation, ContextToPathMode, FileOutputManager\n",
    "\n",
    "out_man: FileOutputManager = curr_active_pipeline.get_output_manager(figure_output_location=FigureOutputLocation.CUSTOM, context_to_path_mode=ContextToPathMode.GLOBAL_UNIQUE, override_output_parent_path=collected_outputs_path)\n",
    "\n",
    "\n",
    "# FileOutputManager(figure_output_location=figure_output_location, context_to_path_mode=context_to_path_mode, override_output_parent_path=override_output_parent_path)\n",
    "\n",
    "out_man"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_UV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
