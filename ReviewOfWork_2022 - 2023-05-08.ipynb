{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0056bc66-7629-4ef7-8c87-f28f8fcd9dc8",
   "metadata": {
    "autorun": true,
    "tags": [
     "imports",
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "build_module_logger(module_name=\"Spike3D.pipeline\"):\n",
      "\t Module logger com.PhoHale.Spike3D.pipeline has file logging enabled and will log to EXTERNAL\\TESTING\\Logging\\debug_com.PhoHale.Spike3D.pipeline.log\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "# %load_ext viztracer\n",
    "# from viztracer import VizTracer\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "from copy import deepcopy\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pho's Formatting Preferences\n",
    "# from pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\n",
    "# set_pho_preferences_concise()\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.general_helpers import CodeConversion\n",
    "from pyphocorehelpers.function_helpers import function_attributes\n",
    "from pyphocorehelpers.print_helpers import print_keys_if_possible, print_value_overview_only, document_active_variables, objsize, print_object_memory_usage, debug_dump_object_member_shapes, TypePrintMode\n",
    "from pyphocorehelpers.print_helpers import get_now_day_str, get_now_time_str, get_now_time_precise_str\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "# from neuropy import core\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.core.epoch import NamedTimerange, Epoch\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.BapunDataSessionFormat import BapunDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.RachelDataSessionFormat import RachelDataSessionFormat\n",
    "from neuropy.core.session.Formats.Specific.HiroDataSessionFormat import HiroDataSessionFormatRegisteredClass\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveWrapper import batch_load_session, batch_extended_computations, SessionBatchProgress, batch_programmatic_figures, batch_extended_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap\n",
    "\n",
    "# from PendingNotebookCode import _perform_batch_plot, _build_batch_plot_kwargs\n",
    "\n",
    "session_batch_status = {}\n",
    "session_batch_errors = {}\n",
    "enable_saving_to_disk = False\n",
    "\n",
    "global_data_root_parent_path = find_first_extant_path([Path(r'W:\\Data'), Path(r'/media/MAX/Data'), Path(r'/Volumes/MoverNew/data'), Path(r'/home/halechr/turbo/Data')])\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1538e2a-4e39-4d11-90b5-a9fef9258058",
   "metadata": {
    "tags": [
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "source": [
    "# Load Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f917bad9-8fe7-4882-b83b-71cf878fffd2",
   "metadata": {
    "tags": [
     "load",
     "REQUIRED"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_session_names_list: ['2006-6-07_11-26-53', '2006-6-08_14-26-15', '2006-6-09_1-22-43', '2006-6-09_3-23-37', '2006-6-12_15-55-31', '2006-6-13_14-42-6']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-07_11-26-53'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-08_14-26-15'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_3-23-37'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-12_15-55-31'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-13_14-42-6'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Load Data                                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "active_data_mode_name = 'kdiba'\n",
    "\n",
    "## Data must be pre-processed using the MATLAB script located here: \n",
    "#     neuropy/data_session_pre_processing_scripts/KDIBA/IIDataMat_Export_ToPython_2022_08_01.m\n",
    "# From pre-computed .mat files:\n",
    "\n",
    "local_session_root_parent_context = IdentifyingContext(format_name=active_data_mode_name) # , animal_name='', configuration_name='one', session_name=self.session_name\n",
    "local_session_root_parent_path = global_data_root_parent_path.joinpath('KDIBA')\n",
    "\n",
    "# # Animal `gor01`:\n",
    "local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='gor01', exper_name='one') # IdentifyingContext<('kdiba', 'gor01', 'one')>\n",
    "local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name) # 'gor01', 'one'\n",
    "local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=['PhoHelpers', 'Spike3D-Minimal-Test', 'Unused'])\n",
    "\n",
    "# local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='gor01', exper_name='two')\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name)\n",
    "# local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=[])\n",
    "\n",
    "# ## Animal `vvp01`:\n",
    "# local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='vvp01', exper_name='one')\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name)\n",
    "# local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=[])\n",
    "\n",
    "# local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='vvp01', exper_name='two')\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name)\n",
    "# local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=[])\n",
    "\n",
    "# ### Animal `pin01`:\n",
    "# local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='pin01', exper_name='one')\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name) # no exper_name ('one' or 'two') folders for this animal.\n",
    "# local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=['redundant','showclus','sleep','tmaze'])\n",
    "\n",
    "## Build session contexts list:\n",
    "local_session_contexts_list = [local_session_parent_context.adding_context(collision_prefix='sess', session_name=a_name) for a_name in local_session_names_list] # [IdentifyingContext<('kdiba', 'gor01', 'one', '2006-6-07_11-26-53')>, ..., IdentifyingContext<('kdiba', 'gor01', 'one', '2006-6-13_14-42-6')>]\n",
    "\n",
    "## Initialize `session_batch_status` with the NOT_STARTED status if it doesn't already have a different status\n",
    "for curr_session_basedir in local_session_paths_list:\n",
    "    curr_session_status = session_batch_status.get(curr_session_basedir, None)\n",
    "    if curr_session_status is None:\n",
    "        session_batch_status[curr_session_basedir] = SessionBatchProgress.NOT_STARTED # set to not started if not present\n",
    "        # session_batch_status[curr_session_basedir] = SessionBatchProgress.COMPLETED # set to not started if not present\n",
    "\n",
    "session_batch_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d13e68b4-03e0-4388-a35c-87a352a6e6b3",
   "metadata": {
    "tags": [
     "load",
     "single_session",
     "REQUIRED"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "basedir: W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\n",
      "Loading loaded session pickle file results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\loadedSessPickle.pkl... done.\n",
      "Loading pickled pipeline success: W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\loadedSessPickle.pkl.\n",
      "property already present in pickled version. No need to save.\n",
      "WARNING: changed_filters_names_list > 0!: ['maze1', 'maze2', 'maze'] but these filters are in the changed_filters_ignore_list: ['maze1', 'maze2', 'maze']\n",
      "ignored_changed_filters_list: ['maze1', 'maze2', 'maze']\n",
      "using provided computation_functions_name_whitelist: ['_perform_baseline_placefield_computation', '_perform_time_dependent_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_time_dependent_pf_sequential_surprise_computation_perform_two_step_position_decoding_computation']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the blacklist/whitelist or computation function definitions change. Rework so that this is smarter.\n",
      "updating computation_results...\n",
      "done.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the blacklist/whitelist or computation function definitions change. Rework so that this is smarter.\n",
      "updating computation_results...\n",
      "done.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the blacklist/whitelist or computation function definitions change. Rework so that this is smarter.\n",
      "updating computation_results...\n",
      "done.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n"
     ]
    }
   ],
   "source": [
    "%pdb off\n",
    "# %%viztracer\n",
    "basedir = local_session_paths_list[1] # NOT 3\n",
    "print(f'basedir: {str(basedir)}')\n",
    "\n",
    "# Read if possible:\n",
    "saving_mode = PipelineSavingScheme.SKIP_SAVING\n",
    "force_reload = False\n",
    "\n",
    "# # Force write:\n",
    "# saving_mode = PipelineSavingScheme.OVERWRITE_IN_PLACE\n",
    "# force_reload = True\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "# epoch_name_whitelist = ['maze']\n",
    "epoch_name_whitelist = None\n",
    "active_computation_functions_name_whitelist=['_perform_baseline_placefield_computation', '_perform_time_dependent_placefield_computation', '_perform_extended_statistics_computation',\n",
    "                                        '_perform_position_decoding_computation', \n",
    "                                        '_perform_firing_rate_trends_computation',\n",
    "                                        # '_perform_pf_find_ratemap_peaks_computation',\n",
    "                                        '_perform_time_dependent_pf_sequential_surprise_computation'\n",
    "                                        '_perform_two_step_position_decoding_computation',\n",
    "                                        # '_perform_recursive_latent_placefield_decoding'\n",
    "                                    ]\n",
    "curr_active_pipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_whitelist=epoch_name_whitelist,\n",
    "                                          computation_functions_name_whitelist=active_computation_functions_name_whitelist,\n",
    "                                          saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                          skip_extended_batch_computations=True, debug_print=False, fail_on_exception=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e403d1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sane_midpoint_x: 119.48022705218361, hardcoded_track_midpoint_x: None, track_min_max_x: (22.736279243974774, 261.696733348342)\n",
      "hardcoded_track_midpoint_x is None, falling back to sane_midpoint_x... 119.48022705218361\n",
      "desc_crossings_x: (20,), asc_crossings_x: (20,)\n",
      "setting new computation epochs because laps changed.\n"
     ]
    }
   ],
   "source": [
    "from neuropy.analyses.placefields import PfND\n",
    "from PendingNotebookCode import constrain_to_laps\n",
    "from PendingNotebookCode import compute_short_long_constrained_decoders\n",
    "\n",
    "curr_active_pipeline = constrain_to_laps(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dda48261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (16389,) should be less than time_window_edges: (35888,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (16389,) should be less than time_window_edges: (35888,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (19183,) should be less than time_window_edges: (25983,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (19183,) should be less than time_window_edges: (25983,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "self will be re-binned to match target_pf...\n",
      "done.\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (19183,) should be less than time_window_edges: (25983,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (19183,) should be less than time_window_edges: (25983,)!\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (16389,) should be less than time_window_edges: (35888,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (16389,) should be less than time_window_edges: (35888,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (19183,) should be less than time_window_edges: (25983,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (19183,) should be less than time_window_edges: (25983,)!\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "self will be re-binned to match target_one_step_decoder...\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (19183,) should be less than time_window_edges: (25983,)!\n",
      "WARNING: PREVIOUSLY ASSERT: \n",
      "\t spikes_df[time_variable_name]: (19183,) should be less than time_window_edges: (25983,)!\n",
      "computing estimated replay epochs for session...\n",
      "\n",
      "\t using KnownFilterEpochs.PBE as surrogate replays...\n",
      "computing estimated replay epochs for session...\n",
      "\n",
      "\t using KnownFilterEpochs.PBE as surrogate replays...\n",
      "computing estimated replay epochs for session...\n",
      "\n",
      "\t using KnownFilterEpochs.PBE as surrogate replays...\n"
     ]
    }
   ],
   "source": [
    "(long_one_step_decoder_1D, short_one_step_decoder_1D), (long_one_step_decoder_2D, short_one_step_decoder_2D) = compute_short_long_constrained_decoders(curr_active_pipeline, recalculate_anyway=True)\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_epoch_context, short_epoch_context, global_epoch_context = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_epoch_name, short_epoch_name, global_epoch_name)]\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "long_pf2D, short_pf2D, global_pf2D = long_results.pf2D, short_results.pf2D, global_results.pf2D\n",
    "decoding_time_bin_size = long_one_step_decoder_1D.time_bin_size # 1.0/30.0 # 0.03333333333333333\n",
    "\n",
    "# Backup and replace loaded replays with computed ones:\n",
    "long_replays, short_replays, global_replays = [a_session.replace_session_replays_with_estimates(require_intersecting_epoch=None, debug_print=False) for a_session in [long_session, short_session, global_session]]\n",
    "# 3m 40.3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d60973fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "included whitelist is specified: ['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "jonathan_firing_rate_analysis already computed.\n",
      "\tforce_recompute is true so recomputing anyway\n",
      "jonathan_firing_rate_analysis missing.\n",
      "\t Recomputing jonathan_firing_rate_analysis...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pho\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\spike3d-WtdfU5rp-py3.9\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\pho\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\spike3d-WtdfU5rp-py3.9\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t done.\n",
      "long_short_fr_indicies_analyses already computed.\n",
      "\tforce_recompute is true so recomputing anyway\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "\t done.\n",
      "done with all batch_extended_computations(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\MultiContextComputationFunctions\\MultiContextComputationFunctions.py:1253: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return ((long_fr - short_fr) / (long_fr + short_fr))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import create_daily_programmatic_display_function_testing_folder_if_needed, session_context_to_relative_path\n",
    "# 2023-01-* - Call extended computations to build `_display_short_long_firing_rate_index_comparison` figures:\n",
    "extended_computations_include_whitelist=['long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis'] # do only specifiedl\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_whitelist=extended_computations_include_whitelist, include_global_functions=True, fail_on_exception=True, progress_print=True, force_recompute=True, debug_print=False)\n",
    "newly_computed_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf6ed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.spikes_df.spikes.neuron_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f004af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aclu</th>\n",
       "      <th>neuron_type</th>\n",
       "      <th>laps</th>\n",
       "      <th>replays</th>\n",
       "      <th>skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>NeuronType.PYRAMIDAL</td>\n",
       "      <td>-0.980522</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.980522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89</td>\n",
       "      <td>NeuronType.PYRAMIDAL</td>\n",
       "      <td>-0.343649</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.343649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>NeuronType.PYRAMIDAL</td>\n",
       "      <td>-0.626530</td>\n",
       "      <td>-0.846932</td>\n",
       "      <td>0.739764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79</td>\n",
       "      <td>NeuronType.CONTAMINATED</td>\n",
       "      <td>-0.323449</td>\n",
       "      <td>-0.748029</td>\n",
       "      <td>0.432402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>NeuronType.PYRAMIDAL</td>\n",
       "      <td>-0.483127</td>\n",
       "      <td>-0.738485</td>\n",
       "      <td>0.654214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>73</td>\n",
       "      <td>NeuronType.PYRAMIDAL</td>\n",
       "      <td>0.782512</td>\n",
       "      <td>0.779007</td>\n",
       "      <td>1.004499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>97</td>\n",
       "      <td>NeuronType.INTERNEURONS</td>\n",
       "      <td>0.943472</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.943472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>28</td>\n",
       "      <td>NeuronType.PYRAMIDAL</td>\n",
       "      <td>0.723802</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.723802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2</td>\n",
       "      <td>NeuronType.PYRAMIDAL</td>\n",
       "      <td>0.924596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.924596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>24</td>\n",
       "      <td>NeuronType.PYRAMIDAL</td>\n",
       "      <td>-0.675480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     aclu              neuron_type      laps   replays      skew\n",
       "0       4     NeuronType.PYRAMIDAL -0.980522 -1.000000  0.980522\n",
       "1      89     NeuronType.PYRAMIDAL -0.343649 -1.000000  0.343649\n",
       "2      25     NeuronType.PYRAMIDAL -0.626530 -0.846932  0.739764\n",
       "3      79  NeuronType.CONTAMINATED -0.323449 -0.748029  0.432402\n",
       "4      56     NeuronType.PYRAMIDAL -0.483127 -0.738485  0.654214\n",
       "..    ...                      ...       ...       ...       ...\n",
       "103    73     NeuronType.PYRAMIDAL  0.782512  0.779007  1.004499\n",
       "104    97  NeuronType.INTERNEURONS  0.943472  1.000000  0.943472\n",
       "105    28     NeuronType.PYRAMIDAL  0.723802  1.000000  0.723802\n",
       "106     2     NeuronType.PYRAMIDAL  0.924596  1.000000  0.924596\n",
       "107    24     NeuronType.PYRAMIDAL -0.675480       NaN       NaN\n",
       "\n",
       "[108 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "\n",
    "# Add Right-click > 'Insert reference' in the \"WATCH\" panel of \"RUN AND DEBUG\" to insert a reference to that variable in the notebook. Could also have a \"Copy reference\".\n",
    "\t# Currently has a \"Copy Value\" option that is close but only copies the value.\n",
    "\t# DISCOVERY: It already exists under the normal \"VARIABLES\" section, and is called \"Copy as Expression\"!!\n",
    "\n",
    "rr_aclus = np.array(list(curr_active_pipeline.global_computation_results.computed_data.long_short_fr_indicies_analysis.y_frs_index.keys()))\n",
    "rr_neuron_type = np.array([global_session.neurons.aclu_to_neuron_type_map[aclu] for aclu in rr_aclus])\n",
    "rr_laps = np.array(list(curr_active_pipeline.global_computation_results.computed_data.long_short_fr_indicies_analysis.y_frs_index.values()))\n",
    "rr_replays = np.array(list(curr_active_pipeline.global_computation_results.computed_data.long_short_fr_indicies_analysis.x_frs_index.values()))\n",
    "rr_skew = rr_laps / rr_replays\n",
    "\n",
    "## Sort on 'rr_replays'\n",
    "sort_indicies = np.argsort(rr_replays)\n",
    "\n",
    "## Sort all the variables:\n",
    "rr_aclus = rr_aclus[sort_indicies]\n",
    "rr_neuron_type = rr_neuron_type[sort_indicies]\n",
    "rr_laps = rr_laps[sort_indicies]\n",
    "rr_replays = rr_replays[sort_indicies]\n",
    "rr_skew = rr_skew[sort_indicies]\n",
    "\n",
    "# Build dataframe:\n",
    "rate_remapping_df = pd.DataFrame({'aclu': rr_aclus, 'neuron_type': rr_neuron_type, 'laps': rr_laps, 'replays': rr_replays, 'skew': rr_skew})\n",
    "rate_remapping_df\n",
    "# rate_remapping_df.to_clipboard()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40c6762f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#e97373'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from neuropy.core.neurons import NeuronType\n",
    "\n",
    "# Get color corresponding to each neuron type:\n",
    "a_neuron_type: NeuronType = rr_neuron_type[0]\n",
    "a_neuron_type\n",
    "\n",
    "a_neuron_type.renderColor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b0f3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.MultiContextComparingDisplayFunctions import plot_rr_aclu\n",
    "\n",
    "## Single plot\n",
    "n_debug_limit = 20\n",
    "fig, ax, sort_indicies = plot_rr_aclu([str(aclu) for aclu in rr_aclus[:n_debug_limit]], rr_laps=rr_laps[:n_debug_limit], rr_replays=rr_replays[:n_debug_limit], rr_neuron_type=rr_neuron_type[:n_debug_limit])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79483e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.MultiContextComparingDisplayFunctions.RateRemappingPaginatedFigureController at 0x2393c8551f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot using Paginator:\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "from pyphocorehelpers.indexing_helpers import Paginator\n",
    "from pyphoplacecellanalysis.GUI.Qt.Mixins.PaginationMixins import PaginatedFigureController\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.MultiContextComparingDisplayFunctions import RateRemappingPaginatedFigureController\n",
    "\n",
    "## Paginated multi-plot\n",
    "# Provide a tuple or list containing equally sized sequences of items:\n",
    "a_paginator = Paginator.init_from_data((rr_aclus, rr_laps, rr_replays, rr_neuron_type), max_num_columns=1, max_subplots_per_page=20, data_indicies=None, last_figure_subplots_same_layout=False)\n",
    "\n",
    "## Build GUI components:\n",
    "_out_rr_pagination_controller = RateRemappingPaginatedFigureController.init_from_paginator(a_paginator, a_name='TestRateRemappingPaginatedFigureController')\n",
    "_out_rr_pagination_controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd8fd5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of pybursts failed: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pho\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\spike3d-WtdfU5rp-py3.9\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 271, in check\n",
      "    superreload(m, reload, self.old_objects, self.shell)\n",
      "  File \"c:\\Users\\pho\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\spike3d-WtdfU5rp-py3.9\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 471, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\Users\\pho\\.pyenv\\pyenv-win\\versions\\3.9.13\\lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 613, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 850, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\n",
      "  File \"c:\\Users\\pho\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\spike3d-WtdfU5rp-py3.9\\lib\\site-packages\\pybursts\\__init__.py\", line 2, in <module>\n",
      "    from pybursts import *\n",
      "AttributeError: module 'pybursts' has no attribute 'pybursts'\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "active_identifying_ctx_string: \"kdiba|gor01|one|2006-6-08_14-26-15|plot_rr_aclu|shared|1of6|[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\"\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'RateRemappingPaginatedFigureController' object has no attribute 'curr_page_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mactive_identifying_ctx_string: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mactive_identifying_ctx_string\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     36\u001b[0m active_figure_save_basename \u001b[39m=\u001b[39m build_figure_basename_from_display_context(final_context)\n\u001b[1;32m---> 37\u001b[0m _out_rr_pagination_controller\u001b[39m.\u001b[39;49mcurr_page_index\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RateRemappingPaginatedFigureController' object has no attribute 'curr_page_index'"
     ]
    }
   ],
   "source": [
    "from neuropy.utils.misc import split_list_of_dicts\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import build_figure_basename_from_display_context, session_context_to_relative_path, create_daily_programmatic_display_function_testing_folder_if_needed\n",
    "\n",
    "\n",
    "## paginated outputs for shared cells\n",
    "included_unit_indicies_pages = [[curr_included_unit_index for (a_linear_index, curr_row, curr_col, curr_included_unit_index) in v] for page_idx, v in enumerate(a_paginator.included_combined_indicies_pages)] # a list of length `num_pages` containing up to 10 items\n",
    "\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context()\n",
    "paginated_shared_cells_kwarg_list = [dict(active_identifying_ctx=active_identifying_session_ctx.adding_context(collision_prefix='_RateRemapping_plot_test', display_fn_name='plot_rr_aclu', plot_result_set='shared', page=f'{page_idx+1}of{a_paginator.num_pages}', aclus=f\"{curr_included_unit_indicies}\"),\n",
    "\tfignum=f'shared_{page_idx}', fig_idx=page_idx, n_max_page_rows=a_paginator.max_num_items_per_page) for page_idx, curr_included_unit_indicies in enumerate(included_unit_indicies_pages)]\n",
    "\n",
    "\n",
    "# Can build a list of keyword arguments that will be provided to the function of interest ahead of time\n",
    "# paginated_shared_cells_kwarg_list = [dict(included_unit_neuron_IDs=curr_included_unit_indicies,\n",
    "# \tactive_identifying_ctx=active_identifying_session_ctx.adding_context(collision_prefix='_RateRemapping_plot_test', display_fn_name='RateRemapping_plot_test', plot_result_set='shared', page=f'{page_idx+1}of{a_paginator.num_pages}', aclus=f\"{curr_included_unit_indicies}\"),\n",
    "# \tfignum=f'shared_{page_idx}', fig_idx=page_idx, n_max_page_rows=a_paginator.max_num_items_per_page) for page_idx, curr_included_unit_indicies in enumerate(included_unit_indicies_pages)]\n",
    "\n",
    "paginated_dict_of_lists = split_list_of_dicts(paginated_shared_cells_kwarg_list)\n",
    "active_identifying_ctxs, fignums, fig_idxs = paginated_dict_of_lists['active_identifying_ctx'], paginated_dict_of_lists['fignum'], paginated_dict_of_lists['fig_idx']\n",
    "\n",
    "\n",
    "# figures_parent_out_path = create_daily_programmatic_display_function_testing_folder_if_needed()\n",
    "# active_session_figures_out_path = session_context_to_relative_path(figures_parent_out_path, active_identifying_session_ctx)\n",
    "# print(f'curr_session_parent_out_path: {active_session_figures_out_path}')\n",
    "# active_session_figures_out_path.mkdir(parents=True, exist_ok=True) # make folder if needed\n",
    "\n",
    "# # # Add in the desired display variable:\n",
    "# active_identifying_ctx = active_identifying_display_ctx.adding_context('filter_epochs', **active_display_fn_kwargs) # , filter_epochs='ripple' ## TODO: this is only right for a single function!\n",
    "\n",
    "active_identifying_ctx = active_identifying_ctxs[0]\n",
    "final_context = active_identifying_ctx # Display/Variable context mode\n",
    "\n",
    "active_identifying_ctx_string = final_context.get_description(separator='|') # Get final discription string\n",
    "print(f'active_identifying_ctx_string: \"{active_identifying_ctx_string}\"')\n",
    "\n",
    "active_figure_save_basename = build_figure_basename_from_display_context(final_context)\n",
    "_out_rr_pagination_controller.curr_page_index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd0866c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "_out_rr_pagination_controller.ui.mw.ui.paginator_controller_widget.current_page_idx\n",
    "# curr_page_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5d7529",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "active_identifying_ctx = active_identifying_ctxs[0]\n",
    "final_context = active_identifying_ctx # Display/Variable context mode\n",
    "\n",
    "active_identifying_ctx_string = final_context.get_description(separator='|') # Get final discription string\n",
    "print(f'active_identifying_ctx_string: \"{active_identifying_ctx_string}\"')\n",
    "\n",
    "build_figure_basename_from_display_context(final_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9344a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using these values:\n",
    "\n",
    "fig.suptitle(active_identifying_ctx.get_description()) # 'kdiba_2006-6-08_14-26-15_[4, 13, 36, 58, 60]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239d43ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sequencesToShow = (*a_paginator.sequencesToShow, active_identifying_ctxs, fignums, fig_idxs)\n",
    "# new_sequencesToShow\n",
    "a_paginator.sequencesToShow = new_sequencesToShow # update the sequences to show:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183508e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE) # AttributeError: 'PfND_TimeDependent' object has no attribute '_included_thresh_neurons_indx'\n",
    "# TypeError: cannot pickle 'MplMultiTab' object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17e4b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.OVERWRITE_IN_PLACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16a3469",
   "metadata": {},
   "outputs": [],
   "source": [
    "_plot_obj = curr_active_pipeline.plot\n",
    "_plot_obj._display_spike_rasters_window()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e03a92c8",
   "metadata": {},
   "source": [
    "# 2023-03-16 - Explore passing in long/short decoders specifically to `perform_full_session_leave_one_out_decoding_analysis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26804fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BasePositionDecoder, BayesianPlacemapPositionDecoder\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import perform_full_session_leave_one_out_decoding_analysis\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import SurpriseAnalysisResult\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import build_neurons_color_map # for plot_short_v_long_pf1D_comparison\n",
    "\n",
    "# Get existing long/short decoders from the cell under \"# 2023-02-24 Decoders\"\n",
    "long_decoder, short_decoder = deepcopy(long_one_step_decoder_1D), deepcopy(short_one_step_decoder_1D)\n",
    "assert np.all(long_decoder.xbin == short_decoder.xbin)\n",
    "\n",
    "# Backup and replace loaded replays with computed ones:\n",
    "long_replays, short_replays, global_replays = [a_session.replace_session_replays_with_estimates(require_intersecting_epoch=None, debug_print=False) for a_session in [long_session, short_session, global_session]]\n",
    "\n",
    "### Need to prune to only the cells active in both epochs ahead of time:\n",
    "# Prune to the shared aclus in both epochs (short/long):\n",
    "long_shared_aclus_only_decoder, short_shared_aclus_only_decoder = [BasePositionDecoder.init_from_stateful_decoder(a_decoder) for a_decoder in (long_decoder, short_decoder)]\n",
    "shared_aclus, (long_shared_aclus_only_decoder, short_shared_aclus_only_decoder), long_short_pf_neurons_diff = BasePositionDecoder.prune_to_shared_aclus_only(long_shared_aclus_only_decoder, short_shared_aclus_only_decoder)\n",
    "n_neurons = len(shared_aclus)\n",
    "# for plotting purposes, build colors only for the common (present in both, the intersection) neurons:\n",
    "neurons_colors_array = build_neurons_color_map(n_neurons, sortby=None, cmap=None)\n",
    "print(f'{n_neurons = }, {neurons_colors_array.shape =}')\n",
    "# from viztracer import VizTracer\n",
    "\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-full_session_LOO_decoding_analysis.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "long_results_obj = perform_full_session_leave_one_out_decoding_analysis(global_session, original_1D_decoder=long_shared_aclus_only_decoder, decoding_time_bin_size = 0.025, cache_suffix = '_long', perform_cache_load=False) # , perform_cache_load=False\n",
    "short_results_obj = perform_full_session_leave_one_out_decoding_analysis(global_session, original_1D_decoder=short_shared_aclus_only_decoder, decoding_time_bin_size = 0.025, cache_suffix = '_short', perform_cache_load=False) # , perform_cache_load=False\n",
    "\n",
    "# 4m 22.4s"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a7742482",
   "metadata": {},
   "source": [
    "## 2023-05-01 - Test my interneuron hypothesis by looking at interneurons across the long/short divide\n",
    "\n",
    " 1. Interneuron identity should be best determinant of active environment.\n",
    "\n",
    " 2. Do people know anything about interneurons that activate in a given environment? For example, to interneurons activate alongside pyramidal cells when replaying a given environment?\n",
    "\n",
    " 3. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe17e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_results.pf1D_dt.reset()\n",
    "# global_results.pf2D_dt.reset()\n",
    "# global_results.all_attributes\n",
    "\n",
    "list(curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.keys())\n",
    "\n",
    "curr_active_pipeline.global_computation_results.computed_data.long_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b7df38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1. Interneuron identity should be best determinant of active environment.\n",
    "\n",
    "# 2. Do people know anything about interneurons that activate in a given environment? For example, to interneurons activate alongside pyramidal cells when replaying a given environment?\n",
    "\n",
    "# 3. \n",
    "# global_results.pf1D_dt.reset()\n",
    "# global_results.pf2D_dt.reset()\n",
    "# global_results.all_attributes\n",
    "\n",
    "list(curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.keys())\n",
    "\n",
    "curr_active_pipeline.global_computation_results.computed_data.long_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2d06a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.MultiContextComputationFunctions import JonathanFiringRateAnalysisResult\n",
    "\n",
    "jonathan_firing_rate_analysis_result = JonathanFiringRateAnalysisResult(**curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.to_dict())\n",
    "\n",
    "jonathan_firing_rate_analysis_result.neuron_replay_stats_df.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ac6c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.rdf.rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc9c2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.time_binned_instantaneous_unit_specific_spike_rate.time_bins #.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785ca961",
   "metadata": {},
   "outputs": [],
   "source": [
    "instantaneous_fr_df = deepcopy(jonathan_firing_rate_analysis_result.time_binned_instantaneous_unit_specific_spike_rate.instantaneous_unit_specific_spike_rate_values)\n",
    "instantaneous_fr_df['t'] = jonathan_firing_rate_analysis_result.time_binned_instantaneous_unit_specific_spike_rate.time_bins\n",
    "instantaneous_fr_df.plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345b3cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "instantaneous_fr_df.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee81000",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.neurons import NeuronType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8016a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ff9bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Require placefield presence on either the long or the short\n",
    "jonathan_firing_rate_analysis_result.neuron_replay_stats_df = jonathan_firing_rate_analysis_result.neuron_replay_stats_df[np.logical_or(jonathan_firing_rate_analysis_result.neuron_replay_stats_df['has_long_pf'], jonathan_firing_rate_analysis_result.neuron_replay_stats_df['has_short_pf'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87851fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.neuron_replay_stats_df[np.logical_or(jonathan_firing_rate_analysis_result.neuron_replay_stats_df['has_long_pf'], jonathan_firing_rate_analysis_result.neuron_replay_stats_df['has_short_pf'])].index.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8566f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.neuron_replay_stats_df.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0504f8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.indexing_helpers import partition\n",
    "\n",
    "# Split the replay stats based on the neuron types:\n",
    "unique_included_neuron_types, (pyr_neuron_replay_stats_df, contaminated_neuron_replay_stats_df, interneuron_neuron_replay_stats_df) = partition(jonathan_firing_rate_analysis_result.neuron_replay_stats_df, 'neuron_type')\n",
    "pyr_neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7524856f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.neurons import NeuronType\n",
    "\n",
    "%matplotlib qt\n",
    "# Look at replays during ripples vs. those not during ripples. Also potentially PBEs vs. not PBEs.\n",
    "\n",
    "# NeuronType.from_any_string_series(['pyr','intr'])\n",
    "'pyr','cont','intr'\n",
    "\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "curr_active_pipeline.display('_display_jonathan_interactive_replay_firing_rate_comparison', active_identifying_session_ctx, included_neuron_types=NeuronType.from_any_string_series(['pyr'])) # only the pyramidal neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7ebf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f61971",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display('_display_jonathan_interactive_replay_firing_rate_comparison', active_identifying_session_ctx, included_neuron_types=NeuronType.from_any_string_series(['intr']), require_placefield=False) # only the pyramidal neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0859e13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import build_replays_custom_scatter_markers, CustomScatterMarkerMode\n",
    "\n",
    "_curr_included_aclus = jonathan_firing_rate_analysis_result.neuron_replay_stats_df[np.logical_or(jonathan_firing_rate_analysis_result.neuron_replay_stats_df['has_long_pf'], jonathan_firing_rate_analysis_result.neuron_replay_stats_df['has_short_pf'])].index.to_numpy()\n",
    "_curr_output = curr_active_pipeline.display('_display_batch_pho_jonathan_replay_firing_rate_comparison', active_identifying_session_ctx, included_unit_neuron_IDs=_curr_included_aclus, marker_split_mode=CustomScatterMarkerMode.NoSplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603a7ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_curr_fig = _curr_output['fig']\n",
    "_curr_axes = _curr_output['axs']\n",
    "\n",
    "for ax_dict in _curr_axes:\n",
    "    for k, ax in ax_dict.items():\n",
    "\t    ax.set_rasterized(True)\n",
    "    \n",
    "# _curr_fig.set_rasterized(True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d69eed8a",
   "metadata": {},
   "source": [
    "## 2023-04-13 - Shuffled Surprise\n",
    "\"\"\" \n",
    "Relevant Functions:\n",
    "`perform_full_session_leave_one_out_decoding_analysis`:\n",
    "\t`perform_leave_one_aclu_out_decoding_analysis`:\tfrom pyphoplacecellanalysis.Analysis.Decoder.decoder_result import perform_leave_one_aclu_out_decoding_analysis\n",
    "\t`_analyze_leave_one_out_decoding_results`: from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.DefaultComputationFunctions import _analyze_leave_one_out_decoding_results\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aac42d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023-04-18 - Refactored into decoder_result\n",
    "result, result_df, result_df_grouped = long_results_obj.result, long_results_obj.result_df, long_results_obj.result_df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c61634",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfe57a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c107570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import DiagnosticDistanceMetricFigure\n",
    "\n",
    "## Render the internactive slider that allows selecting the timebin index to debug\n",
    "n_timebins = np.sum(long_results_obj.all_epochs_num_epoch_time_bins)\n",
    "timebinned_neuron_info = long_results_obj.timebinned_neuron_info\n",
    "result = long_results_obj.new_result\n",
    "active_fig_obj, update_function = DiagnosticDistanceMetricFigure.build_interactive_diagnostic_distance_metric_figure(long_results_obj, timebinned_neuron_info, result)\n",
    "active_fig_obj.integer_slider(n_timebins=n_timebins, update_func=update_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7670bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Get set of cells active in a given time bin, for each compute the surprise of its placefield with the leave-one-out decoded posterior.\n",
    "\n",
    "# 2. From the remainder of cells (those not active), randomly choose one to grab the placefield of and compute the surprise with that and the same posterior.\n",
    "\n",
    "# Expectation: The cells that are included in the time bin are expected to have a lower surprise (be less correlated with) the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ff50bc",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.Extensions.pyqtgraph_helpers import build_pyqtgraph_epoch_indicator_regions # Add session indicators to pyqtgraph plot\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.MultiContextComparingDisplayFunctions import _helper_add_long_short_session_indicator_regions\n",
    "\n",
    "from pyphocorehelpers.print_helpers import generate_html_string\n",
    "# Long Short\n",
    "# TODO 2023-04-18 - Can Refactor in terms of `plot_long_short_any_values`?\n",
    "\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "# 'time_bin_indices': valid_time_bin_indicies, 'posterior_to_pf_mean_surprise': one_left_out_posterior_to_pf_surprises_mean, 'posterior_to_scrambled_pf_mean_surprise': one_left_out_posterior_to_scrambled_pf_surprises_mean}\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.MultiContextComparingDisplayFunctions import plot_long_short_expected_vs_observed_firing_rates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae2e695",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "win, plots_tuple, legend = plot_long_short_expected_vs_observed_firing_rates(long_results_obj, short_results_obj)\n",
    "long_epoch_indicator_region_items, short_epoch_indicator_region_items = _helper_add_long_short_session_indicator_regions(win, long_epoch=curr_active_pipeline.filtered_epochs[long_epoch_name], short_epoch=curr_active_pipeline.filtered_epochs[short_epoch_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4efa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_long_short_surprise_difference_plot(long_results_obj, short_results_obj):\n",
    "\t\"\"\" captures `curr_active_pipeline` \"\"\"\n",
    "\t# Private Subfunctions _______________________________________________________________________________________________ #\n",
    "\tdef _subfn_add_difference_plot_series(win, plots, result_df_grouped, series_suffix, **kwargs):\n",
    "\t\t\"\"\" captures nothing\n",
    "\t\tmodifies `plots` \"\"\"\n",
    "\t\tx=result_df_grouped.time_bin_centers.to_numpy()\n",
    "\t\ty=result_df_grouped['surprise_diff'].to_numpy()\n",
    "\t\tseries_id_str = f'difference_{series_suffix}'\n",
    "\t\tplots[series_id_str] = win.plot(x=x, y=y, name=series_id_str, alpha=0.5, **kwargs) #  symbolBrush=pg.intColor(i,6,maxValue=128) , symbol=curr_symbol, symbolBrush=cell_color_symbol_brush[unit_IDX]\n",
    "\n",
    "\t# BEGIN FUNCTION BODY ________________________________________________________________________________________________ #\n",
    "\n",
    "\t# make a separate symbol_brush color for each cell:\n",
    "\t# cell_color_symbol_brush = [pg.intColor(i,hues=9, values=3, alpha=180) for i, aclu in enumerate(long_results_obj.original_1D_decoder.neuron_IDs)] # maxValue=128\n",
    "\t# All properties in common:\n",
    "\twin = pg.plot() # PlotWidget\n",
    "\twin.setWindowTitle('Long Sanity Check - Leave-one-out Custom Surprise Plot')\n",
    "\t# legend_size = (80,60) # fixed size legend\n",
    "\tlegend_size = None # auto-sizing legend to contents\n",
    "\tlegend = pg.LegendItem(legend_size, offset=(-1,0)) # do this instead of # .addLegend\n",
    "\tlegend.setParentItem(win.graphicsItem())\n",
    "\n",
    "\tplots = {}\n",
    "\tlabel_prefix_list = ['normal', 'scrambled']\n",
    "\tlong_short_symbol_list = ['t', 'o'] # note: 's' is a square. 'o', 't1': triangle pointing upwards0\n",
    "\n",
    "\t# Use mean time_bin and surprise for each epoch\n",
    "\t# plots['normal'] = win.plot(x=valid_time_bin_indicies, y=one_left_out_posterior_to_pf_surprises_mean, pen=None, symbol='t', symbolBrush=pg.intColor(1,6,maxValue=128), name=f'normal', alpha=0.5) #  symbolBrush=pg.intColor(i,6,maxValue=128) , symbol=curr_symbol, symbolBrush=cell_color_symbol_brush[unit_IDX]\n",
    "\t# plots['scrambled'] = win.plot(x=valid_time_bin_indicies, y=one_left_out_posterior_to_scrambled_pf_surprises_mean, pen=None, symbol='t', symbolBrush=pg.intColor(2,6,maxValue=128), name=f'scrambled', alpha=0.5) #  symbolBrush=pg.intColor(i,6,maxValue=128) , symbol=curr_symbol, symbolBrush=cell_color_symbol_brush[unit_IDX]\n",
    "\n",
    "\t# curr_surprise_difference = one_left_out_posterior_to_scrambled_pf_surprises_mean - one_left_out_posterior_to_pf_surprises_mean\n",
    "\n",
    "\t# x=valid_time_bin_indicies\n",
    "\t# y=curr_surprise_difference\n",
    "\t# x=result_df_grouped.time_bin_indices.to_numpy()\n",
    "\n",
    "\t\n",
    "\t_subfn_add_difference_plot_series(win, plots, long_results_obj.result_df_grouped, series_suffix='_long', **dict(pen=None, symbol='t', symbolBrush=pg.intColor(2,6,maxValue=128), clickable=True, hoverable=True, hoverSize=7))\n",
    "\n",
    "\t_subfn_add_difference_plot_series(win, plots, short_results_obj.result_df_grouped, series_suffix='_short', **dict(pen=None, symbol='o', symbolBrush=pg.intColor(3,6,maxValue=128), clickable=True))\n",
    "\n",
    "\t# dict(pen=None, symbol='t', symbolBrush=pg.intColor(2,6,maxValue=128))\n",
    "\n",
    "\n",
    "\t# x=result_df_grouped.time_bin_centers.to_numpy()\n",
    "\t# y=result_df_grouped['surprise_diff'].to_numpy()\n",
    "\t# plots['difference'] = win.plot(x=x, y=y, pen=None, symbol='t', symbolBrush=pg.intColor(2,6,maxValue=128), name=f'difference', alpha=0.5) #  symbolBrush=pg.intColor(i,6,maxValue=128) , symbol=curr_symbol, symbolBrush=cell_color_symbol_brush[unit_IDX]\n",
    "\n",
    "\t# long_results_obj.result, long_results_obj.result_df, long_results_obj.result_df_grouped\n",
    "\n",
    "\t# short_results_obj.result, short_results_obj.result_df, short_results_obj.result_df_grouped\n",
    "\n",
    "\n",
    "\tfor k, v in plots.items():\n",
    "\t\tlegend.addItem(v, f'{k}')\n",
    "\n",
    "\twin.graphicsItem().setLabel(axis='left', text='Normal v. Random - Surprise (Custom)')\n",
    "\twin.graphicsItem().setLabel(axis='bottom', text='time')\n",
    "\n",
    "\twin.showGrid(True, True)  # Show grid for reference\n",
    "\n",
    "\t# Emphasize the y=0 crossing by drawing a horizontal line at y=0\n",
    "\tvline = pg.InfiniteLine(pos=0, angle=0, movable=False, pen=pg.mkPen(color='w', width=2, style=pg.QtCore.Qt.DashLine))\n",
    "\twin.addItem(vline)\n",
    "\n",
    "\t# Add session indicators to pyqtgraph plot\n",
    "\tlong_epoch = curr_active_pipeline.filtered_epochs[long_epoch_name]\n",
    "\tshort_epoch = curr_active_pipeline.filtered_epochs[short_epoch_name]\n",
    "\tlong_epoch_indicator_region_items, short_epoch_indicator_region_items = _helper_add_long_short_session_indicator_regions(win, long_epoch, short_epoch)\n",
    "\n",
    "\t# epoch_linear_region, epoch_region_label = build_pyqtgraph_epoch_indicator_regions(win, t_start=curr_active_pipeline.filtered_epochs[long_epoch_name].t_start, t_stop=curr_active_pipeline.filtered_epochs[long_epoch_name].t_stop, epoch_label='long', **dict(pen=pg.mkPen('#0b0049'), brush=pg.mkBrush('#0099ff42'), hoverBrush=pg.mkBrush('#fff400'), hoverPen=pg.mkPen('#00ff00')))\n",
    "\t# epoch_linear_region, epoch_region_label = build_pyqtgraph_epoch_indicator_regions(win, t_start=curr_active_pipeline.filtered_epochs[short_epoch_name].t_start, t_stop=curr_active_pipeline.filtered_epochs[short_epoch_name].t_stop, epoch_label='short', **dict(pen=pg.mkPen('#490000'), brush=pg.mkBrush('#f5161659'), hoverBrush=pg.mkBrush('#fff400'), hoverPen=pg.mkPen('#00ff00')))\n",
    "\n",
    "\ti_str = generate_html_string('i', color='white', bold=True)\n",
    "\tj_str = generate_html_string('j', color='red', bold=True)\n",
    "\ttitle_str = generate_html_string(f'JSD(p_x_given_n, pf[{i_str}]) - JSD(p_x_given_n, pf[{j_str}]) where {j_str} non-firing')\n",
    "\twin.setTitle(title_str)\n",
    "\n",
    "\twin.setWindowTitle('Long Sanity Check - Leave-one-out Custom Surprise Plot - JSD')\n",
    "\n",
    "\treturn win, plots\n",
    "\n",
    "win, self.plots = plot_long_short_surprise_difference_plot(long_results_obj, short_results_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a84888",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_plot = self.plots['difference__long']  # PlotDataItem \n",
    "a_curve = a_plot.curve # PlotCurveItem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8e78da",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_plot.sigPointsClicked\n",
    "# a_plot.sigPointsHovered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe350d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curve.curve.setClickable(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2377c753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will make all plots clickable\n",
    "clickedPen = pg.mkPen('#DDD', width=2)\n",
    "lastClicked = []\n",
    "def _test_scatter_plot_clicked(plot, points):\n",
    "\tglobal lastClicked\n",
    "\tfor p in lastClicked:\n",
    "\t\tp.resetPen()\n",
    "\tprint(\"clicked points\", points)\n",
    "\tfor p in points:\n",
    "\t\tp.setPen(clickedPen)\n",
    "\tlastClicked = points\n",
    "\n",
    "main_scatter_clicked_connection = a_plot.sigClicked.connect(_test_scatter_plot_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e83d358",
   "metadata": {},
   "outputs": [],
   "source": [
    "lastClicked, clickedPen, (main_scatter_hovered_connection, main_scatter_clicked_connection) = _helper_make_scatterplot_clickable(a_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d54370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to map from time_bin_indicies to times\n",
    "a_plot = self.plots['difference'] # PlotDataItem \n",
    "# a_plot.setLa\n",
    "# win.graphicsItem().setLabel(axis='left', text='Normal v. Random - Surprise (Custom)')\n",
    "\n",
    "# # Set the plot title with a LaTeX formula\n",
    "# title = pg.LabelItem(justify='center')\n",
    "# title.setText(r'<font size=\"4\">JSD Surprise Diff: $\\fn{JSD}{\\matr{pf}_{i}, \\Pr{\\vec{x}_{t}|\\vec{n}_{t}}} - \\fn{JSD}{\\matr{pf}_{j}, \\Pr{\\vec{x}_{t}|\\vec{n}_{t}}}$</font>')\n",
    "# win.addItem(title)\n",
    "\n",
    "# win.graphicsItem().setLabel(axis='top', text=r'$\\fn{JSD}{\\matr{pf}_{i}, \\Pr{\\vec{x}_{t}|\\vec{n}_{t}}} - \\fn{JSD}{\\matr{pf}_{j}, \\Pr{\\vec{x}_{t}|\\vec{n}_{t}}}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f55bb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot # works pretty well seemingly\n",
    "\n",
    "export_pyqtgraph_plot(win)\n",
    "# pg.setConfigOption('leftTitle', 'MathText')\n",
    "# win.setTitle(r'JSD(p_x_given_n, pf[<font size=\"4\"><b><span style=\"color:red;\">i</span></b></font>]) - JSD(p_x_given_n, pf[<font size=\"4\"><b>j</b></font>]) where <font size=\"4\"><b>j</b></font> non-firing')\n",
    "\n",
    "# win.setTitle(generate_html_string(f'JSD(p_x_given_n, pf[{i_str}]) - JSD(p_x_given_n, pf[{j_str}]) where {j_str} non-firing', font_size=8))\n",
    "\n",
    "# r'$\\fn{JSD}{\\matr{pf}_{i}, \\Pr{\\vec{x}_{t}|\\vec{n}_{t}}} - \\fn{JSD}{\\matr{pf}_{j}, \\Pr{\\vec{x}_{t}|\\vec{n}_{t}}}$'\n",
    "# title_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b315f1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyqtgraph.GraphicsScene import exportDialog\n",
    "\n",
    "# active_item = active_fig_obj.win\n",
    "active_item = active_fig_obj.plot_dict['curr_cell_pf_curve']['plot_item']\n",
    "exportDialog = exportDialog.ExportDialog(active_item.scene())\n",
    "exportDialog.show(active_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea2e239",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_fig_obj.plot_dict['curr_cell_pf_curve']['plot_item']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e586e32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.filtered_epochs[short_epoch_name].t_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7c5219",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.filtered_epochs[long_epoch_name].start_end_times"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f996fd9",
   "metadata": {},
   "source": [
    "## Pre 2023-04-13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b6ac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import plot_kourosh_activity_style_figure\n",
    "\n",
    "from neuropy.core.neurons import NeuronType\n",
    "# # Include only pyramidal aclus:\n",
    "# print(f'all shared_aclus: {len(shared_aclus)}\\nshared_aclus: {shared_aclus}')\n",
    "# shared_aclu_neuron_type = long_session.neurons.neuron_type[np.isin(long_session.neurons.neuron_ids, shared_aclus)]\n",
    "# assert len(shared_aclu_neuron_type) == len(shared_aclus)\n",
    "# # Find only the aclus that are pyramidal:\n",
    "# is_shared_aclu_pyramidal = (shared_aclu_neuron_type == NeuronType.PYRAMIDAL)\n",
    "# pyramidal_only_shared_aclus = shared_aclus[is_shared_aclu_pyramidal]\n",
    "# print(f'num pyramidal_only_shared_aclus: {len(pyramidal_only_shared_aclus)}\\npyramidal_only_shared_aclus: {pyramidal_only_shared_aclus}')\n",
    "\n",
    "\n",
    "## Drop Pyramidal but don't use only shared aclus:\n",
    "all_aclus = deepcopy(long_session.neurons.neuron_ids)\n",
    "neuron_type = long_session.neurons.neuron_type\n",
    "assert len(neuron_type) == len(all_aclus)\n",
    "# Find only the aclus that are pyramidal:\n",
    "is_aclu_pyramidal = (neuron_type == NeuronType.PYRAMIDAL)\n",
    "pyramidal_only_all_aclus = all_aclus[is_aclu_pyramidal]\n",
    "print(f'num pyramidal_only_all_aclus: {len(pyramidal_only_all_aclus)}\\npyramidal_only_all_aclus: {pyramidal_only_all_aclus}')\n",
    "\n",
    "is_aclu_interneuron = (neuron_type == NeuronType.INTERNEURONS)\n",
    "interneuron_only_all_aclus = all_aclus[is_aclu_interneuron]\n",
    "print(f'num interneuron_only_all_aclus: {len(interneuron_only_all_aclus)}\\ninterneurons: {interneuron_only_all_aclus}')\n",
    "\n",
    "# app, win, plots, plots_data = plot_kourosh_activity_style_figure(long_results_obj, long_session, shared_aclus, epoch_idx=5, callout_epoch_IDXs=[0,1,2,3], skip_rendering_callouts=True)\n",
    "# app, win, plots, plots_data = plot_kourosh_activity_style_figure(long_results_obj, long_session, pyramidal_only_shared_aclus, epoch_idx=2, callout_epoch_IDXs=[0,4], skip_rendering_callouts=False)\n",
    "app, win, self.plots, self.plots_data = plot_kourosh_activity_style_figure(long_results_obj, long_session, pyramidal_only_all_aclus, epoch_idx=6, callout_epoch_IDXs=[2,4,6], skip_rendering_callouts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985977d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use the Jupyter Index Thing\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import DiagnosticDistanceMetricFigure\n",
    "\n",
    "## Render the internactive slider that allows selecting the timebin index to debug\n",
    "n_timebins = np.sum(long_results_obj.all_epochs_num_epoch_time_bins)\n",
    "timebinned_neuron_info = long_results_obj.timebinned_neuron_info\n",
    "result = long_results_obj.new_result\n",
    "active_fig_obj, update_function = DiagnosticDistanceMetricFigure.build_interactive_diagnostic_distance_metric_figure(long_results_obj, timebinned_neuron_info, result)\n",
    "active_fig_obj.integer_slider(n_timebins=n_timebins, update_func=update_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1aa692",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_fig_obj.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea983fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "app, win, self.plots, self.plots_data = plot_kourosh_activity_style_figure(long_results_obj, long_session, pyramidal_only_all_aclus, epoch_idx=11, callout_epoch_IDXs=[0,1,2, 3, 4, 5], skip_rendering_callouts=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f519e392",
   "metadata": {},
   "source": [
    "# 2023-04-13 Show Surprise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b417bb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.MultiContextComparingDisplayFunctions import plot_long_short, plot_long_short_any_values, plot_long_short_expected_vs_observed_firing_rates, _helper_add_long_short_session_indicator_regions\n",
    "# plot_long_short(long_results_obj, short_results_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbd6593",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_long_short_any_values(long_results_obj=long_results_obj, short_results_obj=short_results_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b8a7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_long_short_expected_vs_observed_firing_rates(long_results_obj=long_results_obj, short_results_obj=short_results_obj, limit_aclus=[89]) # 4, 89, 28, 97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdf68bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fn = lambda a_results_obj: a_results_obj.all_epochs_decoded_epoch_time_bins_mean[:,0]\n",
    "# y_fn = lambda a_results_obj: a_results_obj.all_epochs_all_cells_one_left_out_posterior_to_scrambled_pf_surprises_mean\n",
    "y_fn = lambda a_results_obj: a_results_obj.all_epochs_all_cells_one_left_out_posterior_to_pf_surprises_mean\n",
    "# y_fn = lambda a_results_obj: a_results_obj.all_epochs_computed_one_left_out_posterior_to_pf_surprises\n",
    "\n",
    "# (time_bins, neurons), (epochs, neurons), (epochs)\n",
    "# all_epochs_computed_one_left_out_posterior_to_pf_surprises, all_epochs_computed_cell_one_left_out_posterior_to_pf_surprises_mean, all_epochs_all_cells_one_left_out_posterior_to_pf_surprises_mean\n",
    "win, plots_tuple, legend = plot_long_short_any_values(long_results_obj, short_results_obj, x=x_fn, y=y_fn, limit_aclus=[20])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2fe80559",
   "metadata": {},
   "source": [
    "# 2023-04-13 - Find Good looking epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbb6dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "from pyphocorehelpers.plotting.figure_management import PhoActiveFigureManager2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd46c859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PendingNotebookCode import DecodedEpochSlicesPaginatedFigureController\n",
    "\n",
    "_out_pagination_controller = DecodedEpochSlicesPaginatedFigureController.init_from_decoder_data(long_results_obj.active_filter_epochs, long_results_obj.all_included_filter_epochs_decoder_result, xbin=long_results_obj.original_1D_decoder.xbin, global_pos_df=global_session.position.df, a_name='TestDecodedEpochSlicesPaginationController', max_subplots_per_page=20)\n",
    "_out_pagination_controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d526f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .\n",
    "\n",
    "current_page_idx = _out_pagination_controller.ui.mw.ui.paginator_controller_widget.current_page_idx\n",
    "curr_page_data_indicies, curr_page_data_items =  _out_pagination_controller.plots_data.paginator.get_page_data(page_idx=current_page_idx)\n",
    "curr_page_data_indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1ace00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.indexing_helpers import safe_find_index_in_list\n",
    "\n",
    "def _get_current_page_data_indicies():\n",
    "\t\"\"\" captures `ui.mw.ui.paginator_controller_widget.current_page_idx`, `plots_data.paginator` \"\"\"\n",
    "\tcurrent_page_idx = _out_pagination_controller.ui.mw.ui.paginator_controller_widget.current_page_idx\n",
    "\tcurr_page_data_indicies, curr_page_data_items =  _out_pagination_controller.plots_data.paginator.get_page_data(page_idx=current_page_idx)\n",
    "\treturn current_page_idx, curr_page_data_indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5a6446",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PendingNotebookCode import PaginatedSelectionManager\n",
    "\n",
    "\n",
    "sel_man = PaginatedSelectionManager(axes=_out_pagination_controller.plots.axs, fig=_out_pagination_controller.plots.fig)\n",
    "\n",
    "def on_page_change(updated_page_idx):\n",
    "    # print(f'on_page_change(updated_page_idx: {updated_page_idx})')\n",
    "    # Update on page change:\n",
    "    sel_man.perform_update()\n",
    "\n",
    "ui.mw.ui.paginator_controller_widget.jump_to_page.connect(on_page_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b69d31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_man.is_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693f6443",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PendingNotebookCode import SelectionManager\n",
    "\n",
    "# Create a SelectionManager instance\n",
    "sm = SelectionManager(self.plots.axs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb271d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.is_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e810bced",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_containers = filter_epochs_decoder_result.marginal_x_list.copy()\n",
    "\n",
    "[a_marginal_x_list.p_x_given_n for a_marginal_x_list in filter_epochs_decoder_result.marginal_x_list]\n",
    "[a_marginal_x_list.most_likely_positions_1D for a_marginal_x_list in filter_epochs_decoder_result.marginal_x_list]\n",
    "\n",
    "posterior_containers\n",
    "# posterior_containers = np.array(filter_epochs_decoder_result.marginal_x_list.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079f7a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "included_page_data_indicies, (curr_page_active_filter_epochs, curr_page_epoch_labels, curr_page_time_bin_containers, curr_page_posterior_containers) = epoch_slices_paginator.get_page_data(page_idx=1)\n",
    "# included_page_data_indicies, (curr_page_active_filter_epochs, curr_page_epoch_labels, curr_page_time_bin_containers) = epoch_slices_paginator.get_page_data(page_idx=1)\n",
    "included_page_data_indicies\n",
    "curr_page_posterior_containers[0].p_x_given_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559ffa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from pyphocorehelpers.indexing_helpers import safe_len\n",
    "\n",
    "# {k:safe_len(v) for k,v in filter_epochs_decoder_result.__dict__.items() if (safe_len(v) or 0) > 0}\n",
    "\n",
    "## Only get the items that are num_filter_epochs long:\n",
    "epoch_splittable_items = {k:v for k,v in filter_epochs_decoder_result.__dict__.items() if (safe_len(v) or 0) == filter_epochs_decoder_result.num_filter_epochs}\n",
    "# epoch_splittable_items\n",
    "epoch_splittable_item_names = list(epoch_splittable_items.keys())\n",
    "# print(epoch_splittable_item_names)\n",
    "# ('most_likely_positions_list', 'p_x_given_n_list', 'marginal_x_list', 'marginal_y_list', 'most_likely_position_indicies_list', 'spkcount', 'nbins', 'time_bin_containers', 'time_bin_edges')\n",
    "# epoch_splittable_item_values = [epoch_splittable_items[k] for k in ('most_likely_positions_list', 'p_x_given_n_list', 'marginal_x_list', 'marginal_y_list', 'most_likely_position_indicies_list', 'nbins', 'time_bin_containers', 'time_bin_edges')]\n",
    "epoch_splittable_item_values = [epoch_splittable_items[k] for k in ('epoch_description_list','time_bin_containers','marginal_x_list')]\n",
    "# epoch_splittable_item_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed0656a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [23, 27, 29, ]\n",
    "[16, 17, 18, 20, 21, 22, 23, 25, 26, 29]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e6526e9",
   "metadata": {},
   "source": [
    "# 2023-03-28 - Playing around with older computations/visualizations from the `_display_short_long_firing_rate_index_comparison` era:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d2e9eb6",
   "metadata": {},
   "source": [
    "\n",
    "2023-04-20 - Encountered issue with the replays in session '2006-6-08_14-26-15' where they are duplicated exactly twice, like the first half of the rows are legitimate entries and the second half are directly repeated versions of the first with the only difference appearing to be the 'epoch_id' column changes from 1 to 2. 'rel_id' column seems incorrect but different for some reason. It must be how the MATLAB script exports the values.\n",
    "\n",
    "Also when I'm looking at only the `short_session.replay` there are many non-2 'epoch_id' values, which is strange. \n",
    "\n",
    "TODO: It could have something to do with Jonathan's code maybe? Because the 'replay_r' and 'replay_p' columns he added are different. SEEMS FALSE. It's this way even without running Jonathan's code, although the values might have been saved later?\n",
    "\tAlso flat_replay_idx jumps from 689 to 1087 at the transition from epoch_id 1 to 2\n",
    "\n",
    "UPDATE: the 'replay_r' and 'replay_p' columns aren't from Joanthan, they're in the original .replay_info.mat that's imported!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a13cccd",
   "metadata": {},
   "source": [
    "# Plot long|short firing rate index using 'long_short_fr_indicies_analyses':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caab469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_save_parent_path = Path(r'E:\\Dropbox (Personal)\\Active\\Kamran Diba Lab\\Results from 2023-01-20 - LongShort Firing Rate Indicies')\n",
    "## Get the output path (active_session_figures_out_path) for this session (and all of its filtered_contexts as well):\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "figures_parent_out_path = create_daily_programmatic_display_function_testing_folder_if_needed()\n",
    "active_session_figures_out_path = session_context_to_relative_path(figures_parent_out_path, active_identifying_session_ctx)\n",
    "print(f'curr_session_parent_out_path: {active_session_figures_out_path}')\n",
    "active_session_figures_out_path.mkdir(parents=True, exist_ok=True) # make folder if needed\n",
    "curr_active_pipeline.display('_display_short_long_firing_rate_index_comparison', curr_active_pipeline.sess.get_context(), fig_save_parent_path=active_session_figures_out_path)\n",
    "# plt.close() # closes the current figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0165676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_short_long_firing_rate_analyses'], fail_on_exception=True, debug_print=False) # fail_on_exception MUST be True or error handling is all messed up \n",
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "x_frs_index, y_frs_index = long_short_fr_indicies_analysis_results['x_frs_index'], long_short_fr_indicies_analysis_results['y_frs_index'] # use the all_results_dict as the computed data value\n",
    "active_context = long_short_fr_indicies_analysis_results['active_context']\n",
    "long_short_fr_indicies_analysis_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0409e08",
   "metadata": {},
   "source": [
    "# Other Programmatic Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecc42a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_extended_programmatic_figures(curr_active_pipeline=curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4289a4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_programmatic_figures(curr_active_pipeline=curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5977e9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the 2D placefields for my presentation\n",
    "from neuropy.core.neuron_identities import PlotStringBrevityModeEnum\n",
    "from neuropy.plotting.ratemaps import BackgroundRenderingOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cbba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# '_display_2d_placefield_result_plot_ratemaps_2D'\n",
    "# %matplotlib inline\n",
    "%matplotlib qt\n",
    "# curr_active_pipeline.display('_display_2d_placefield_result_plot_ratemaps_2D', long_epoch_context) # MatplotlibRenderPlots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48029c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# long_pf2D.plot_occupancy()\n",
    "_out = short_one_step_decoder_2D.pf.plot_ratemaps_2D(included_unit_neuron_IDs=[2,4,5], bg_rendering_mode=BackgroundRenderingOptions.EMPTY, use_special_overlayed_title=False, missing_aclu_string_formatter=None, debug_print=False, brev_mode=PlotStringBrevityModeEnum.NONE)\n",
    "\n",
    "## Single column output: subplots=(None, 9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14977e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "active_display_to_pdf_fn(curr_active_pipeline, curr_display_function_name='_display_1d_placefields', debug_print=False) # ðŸŸ¢âœ… Now seems to be working and saving to PDF!! Still using matplotlib.use('Qt5Agg') mode and plots still appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2686e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_shared_aclus_only_decoder.pf.plot_occupancy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ae6c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "long_one_step_decoder_2D.pf.plot_occupancy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8006610",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_one_step_decoder_2D.pf.plot_ratemaps_2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49dcc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.display('_display_short_long_pf1D_comparison', active_session_configuration_context=global_epoch_context, single_figure=False)\n",
    "\n",
    "short_one_step_decoder_1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402834bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "\n",
    "long_single_cell_pfmap_processing_fn = None\n",
    "short_single_cell_pfmap_processing_fn = None\n",
    "\n",
    "# long_single_cell_pfmap_processing_fn = lambda i, aclu, pfmap: 0.5 * pfmap # flip over the y-axis\n",
    "# short_single_cell_pfmap_processing_fn = lambda i, aclu, pfmap: -0.5 * pfmap # flip over the y-axis\n",
    "\n",
    "# pad = 1\n",
    "# long_single_cell_pfmap_processing_fn = lambda i, aclu, pfmap: (0.5 * pfmap) + (0.5*pad) # shift the baseline up by half\n",
    "# short_single_cell_pfmap_processing_fn = lambda i, aclu, pfmap: (-0.5 * pfmap * pad) + (0.5*pad) # flip over the y-axis, shift the baseline down by half\n",
    "\n",
    "# pad = 1\n",
    "# long_single_cell_pfmap_processing_fn = lambda i, aclu, pfmap: (0.5 * pfmap * pad) + (0.5*pad) # shift the baseline up by half\n",
    "# short_single_cell_pfmap_processing_fn = lambda i, aclu, pfmap: (0.5 * pfmap * pad) + (0.5*pad) # flip over the y-axis, shift the baseline down by half\n",
    "# long_single_cell_pfmap_processing_fn = lambda i, aclu, pfmap: (0.5 * pfmap * pad) # shift the baseline up by half\n",
    "# short_single_cell_pfmap_processing_fn = lambda i, aclu, pfmap: (0.5 * pfmap * pad) # flip over the y-axis, shift the baseline down by half\n",
    "\n",
    "\n",
    "# long_single_cell_pfmap_processing_fn = lambda i, aclu, pfmap: (1.0 * pfmap * pad) # shift the baseline up by half\n",
    "# short_single_cell_pfmap_processing_fn = lambda i, aclu, pfmap: (-1.0 * pfmap * pad) + (1.0*pad) # this does not work and results in short being fully filled. I think this is because the fill_between gets reversed since everything is below baseline\n",
    "\n",
    "sort_idx = None\n",
    "\n",
    "out = curr_active_pipeline.display('_display_short_long_pf1D_comparison', active_identifying_session_ctx, single_figure=False, debug_print=False, fignum='Short v Long pf1D Comparison',\n",
    "                                   long_kwargs={'sortby': sort_idx, 'single_cell_pfmap_processing_fn': long_single_cell_pfmap_processing_fn},\n",
    "                                   short_kwargs={'sortby': sort_idx, 'single_cell_pfmap_processing_fn': short_single_cell_pfmap_processing_fn, 'curve_hatch_style': {'hatch':'///', 'edgecolor':'k'}},\n",
    "                                  )\n",
    "\n",
    "# ax = out.axes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cfbb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_idx = np.argsort(product_overlap_scalars_df.prod_overlap.to_numpy())[::-1] # the `[::-1]` term reverses the array, which by defaul is returned in ascending order and we want descending\n",
    "sort_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe831b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "curr_ratemap = long_one_step_decoder_1D.pf.ratemap\n",
    "curr_ratemap.get_sort_indicies()\n",
    "# .pf1D.ratemap"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1e8629a",
   "metadata": {},
   "source": [
    "# 2023-04-27 - Idea: Candidate Replay \"Quality\" Metric\n",
    "Observed that I visually distinguish \"good\" replays from bad ones based on their mostly-monotonically increasing nature.\n",
    "\n",
    "#### They don't have to:\n",
    "\tSpan the whole track\n",
    "\tStart or end at an end-cap\n",
    "\tIncrease linearly\n",
    "\n",
    "#### The algorithm must:\n",
    "\ttolerate ocasional jumps in an otherwise linear sequence\n",
    "\tallow sequences to \"start\" only halfway through. They should extract out the coherent sequence\n",
    "\n",
    "#### Ideas:\n",
    "\t- just a linear fit\n",
    "\t- a monotonicity check using some sort of cumulative sum over the differences in position.\n",
    "\t- \"radon transform\"?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de511aa5",
   "metadata": {},
   "source": [
    "# 2023-05-02 - Session Validation Check Info\n",
    "Generate info about the number of laps detected, the duration, the number of cells, the number of replays, etc for the active session so that it can be ensured that there wasn't an error that is messing up the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15697281",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.active_sess_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5045805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.debug_helpers import debug_print_placefield, debug_print_spike_counts, debug_print_subsession_neuron_differences\n",
    "from neuropy.utils.misc import print_seconds_human_readable\n",
    "\n",
    "debug_print_spike_counts(global_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8693c951",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from neuropy.analyses.laps import estimate_session_laps\n",
    "\n",
    "curr_laps = global_session.laps\n",
    "curr_laps.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5570d369",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build the new laps first:\n",
    "# global_session = estimate_session_laps(global_session)\n",
    "\n",
    "global_session.replace_session_laps_with_estimates()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7125b9f7",
   "metadata": {},
   "source": [
    "### Plotting Validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b942014",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "short_one_step_decoder_1D.pf.plot_ratemaps_1D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfe7eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_results.pf1D_Decoder.pf.plot_ratemaps_1D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bed5960",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_results.pf2D_Decoder.pf.plot_ratemaps_2D()\n",
    "short_one_step_decoder_2D.pf.plot_ratemaps_2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ea99e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "long_session.plot_laps_2d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d18bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.laps import plot_laps_2d\n",
    "\n",
    "%matplotlib qt\n",
    "fig, out_axes_list = plot_laps_2d(global_session, legacy_plotting_mode=False)\n",
    "out_axes_list[0].set_title('New Pho Position Thresholding Estimated Laps')\n",
    "fig.canvas.manager.set_window_title('New Pho Position Thresholding Estimated Laps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae2e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Laps \n",
    "from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.Mixins.LapsVisualizationMixin import LapsVisualizationMixin\n",
    "\n",
    "curr_position_df, lap_specific_position_dfs = LapsVisualizationMixin._compute_laps_specific_position_dfs(curr_active_pipeline.sess)\n",
    "lap_specific_position_dfs = [curr_position_df.groupby('lap').get_group(i)[['t','x','y','lin_pos']] for i in curr_active_pipeline.sess.laps.lap_id] # dataframes split for each ID:\n",
    "laps_position_times_list = [np.squeeze(lap_pos_df[['t']].to_numpy()) for lap_pos_df in lap_specific_position_dfs]\n",
    "laps_position_traces_list = [lap_pos_df[['x','y']].to_numpy().T for lap_pos_df in lap_specific_position_dfs]\n",
    "## Build Epochs:\n",
    "epochs = curr_active_pipeline.sess.laps.to_dataframe()\n",
    "epoch_slices = epochs[['start', 'stop']].to_numpy()\n",
    "epoch_description_list = [f'lap {epoch_tuple.lap_id} (maze: {epoch_tuple.maze_id}, direction: {epoch_tuple.lap_dir})' for epoch_tuple in epochs[['lap_id','maze_id','lap_dir']].itertuples()]\n",
    "# print(f'epoch_description_list: {epoch_description_list}') # epoch_descriptions: ['lap 41 (maze: 2, direction: 1)', 'lap 42 (maze: 2, direction: 0)', 'lap 43 (maze: 2, direction: 1)', 'lap 44 (maze: 2, direction: 0)', 'lap 45 (maze: 2, direction: 1)', 'lap 46 (maze: 2, direction: 0)', 'lap 47 (maze: 2, direction: 1)', 'lap 48 (maze: 2, direction: 0)', 'lap 49 (maze: 2, direction: 1)', 'lap 50 (maze: 2, direction: 0)', 'lap 51 (maze: 2, direction: 1)', 'lap 52 (maze: 2, direction: 0)', 'lap 53 (maze: 2, direction: 1)', 'lap 54 (maze: 2, direction: 0)', 'lap 55 (maze: 2, direction: 1)', 'lap 56 (maze: 2, direction: 0)', 'lap 57 (maze: 2, direction: 1)', 'lap 58 (maze: 2, direction: 0)', 'lap 59 (maze: 2, direction: 1)', 'lap 60 (maze: 2, direction: 0)', 'lap 61 (maze: 2, direction: 1)', 'lap 62 (maze: 2, direction: 0)', 'lap 63 (maze: 2, direction: 1)', 'lap 64 (maze: 2, direction: 0)', 'lap 65 (maze: 2, direction: 1)', 'lap 66 (maze: 2, direction: 0)', 'lap 67 (maze: 2, direction: 1)', 'lap 68 (maze: 2, direction: 0)', 'lap 69 (maze: 2, direction: 1)', 'lap 70 (maze: 2, direction: 0)', 'lap 71 (maze: 2, direction: 1)', 'lap 72 (maze: 2, direction: 0)', 'lap 73 (maze: 2, direction: 1)', 'lap 74 (maze: 2, direction: 0)', 'lap 75 (maze: 2, direction: 1)', 'lap 76 (maze: 2, direction: 0)', 'lap 77 (maze: 2, direction: 1)', 'lap 78 (maze: 2, direction: 0)', 'lap 79 (maze: 2, direction: 1)']\n",
    "# -"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spike3d-poetry",
   "language": "python",
   "name": "spike3d-poetry"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
