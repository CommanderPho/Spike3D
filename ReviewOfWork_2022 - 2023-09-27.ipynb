{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96ce022a",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "build_module_logger(module_name=\"Spike3D.pipeline\"):\n",
      "\t Module logger com.PhoHale.Spike3D.pipeline has file logging enabled and will log to EXTERNAL\\TESTING\\Logging\\debug_com.PhoHale.Spike3D.pipeline.log\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "# %load_ext viztracer\n",
    "# from viztracer import VizTracer\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "import sys\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from pathlib import Path\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "from copy import deepcopy\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "# pd.options.mode.dtype_backend = 'pyarrow' # use new pyarrow backend instead of numpy\n",
    "from attrs import define, field, fields, Factory\n",
    "import tables as tb\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Pho's Formatting Preferences\n",
    "from pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\n",
    "set_pho_preferences_concise()\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "# from neuropy import core\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.core.epoch import NamedTimerange, Epoch\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.utils.matplotlib_helpers import matplotlib_file_only, matplotlib_configuration, matplotlib_configuration_update\n",
    "from neuropy.core.neuron_identities import NeuronIdentityTable, neuronTypesList, neuronTypesEnum\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "from neuropy.core.neurons import NeuronType\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from neuropy.core.position import Position\n",
    "from neuropy.core.session.dataSession import DataSession\n",
    "from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent, PlacefieldSnapshot\n",
    "\n",
    "from pyphocorehelpers.print_helpers import print_object_memory_usage, print_dataframe_memory_usage, print_value_overview_only, DocumentationFilePrinter, print_keys_if_possible, generate_html_string, CapturedException\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_load_session, batch_extended_computations, batch_extended_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import _find_any_context_neurons\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchSessionCompletionHandler # for `post_compute_validate(...)`\n",
    "from neuropy.utils.mixins.AttrsClassHelpers import AttrsBasedClassHelperMixin, serialized_field, serialized_attribute_field, non_serialized_field\n",
    "from neuropy.utils.mixins.HDF5_representable import HDF_DeserializationMixin, post_deserialize, HDF_SerializationMixin, HDFMixin\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BasePositionDecoder\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsResults\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends # for `_perform_long_short_instantaneous_spike_rate_groups_analysis`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import SingleBarResult, InstantaneousSpikeRateGroupsComputation, TruncationCheckingResults # for `BatchSessionCompletionHandler`, `AcrossSessionsAggregator`\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import SplitPartitionMembership\n",
    "\n",
    "# Plotting\n",
    "# import pylustrator # customization of figures\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "# import pylustrator # call `pylustrator.start()` before creating your first figure in code.\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot, plot_raster_plot\n",
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import DataSeriesColorHelpers\n",
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import UnitColoringMode, DataSeriesColorHelpers\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import _build_default_tick, build_scatter_plot_kwargs\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.Render2DScrollWindowPlot import Render2DScrollWindowPlotMixin, ScatterItemData\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_extended_programmatic_figures, batch_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PAPER_FIGURE_figure_1_add_replay_epoch_rasters, PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_3, main_complete_figure_generations\n",
    "\n",
    "from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import *\n",
    "\n",
    "# Jupyter Widget Interactive\n",
    "from IPython.display import display\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import interactive_pipeline_widget, fullwidth_path_widget, interactive_pipeline_files\n",
    "\n",
    "global_data_root_parent_path = find_first_extant_path([Path(r'W:\\Data'), Path(r'/home/halechr/FastData'), Path(r'/media/MAX/Data'), Path(r'/Volumes/MoverNew/data'), Path(r'/home/halechr/turbo/Data')])\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1538e2a-4e39-4d11-90b5-a9fef9258058",
   "metadata": {
    "tags": [
     "REQUIRED",
     "ACTIVE"
    ]
   },
   "source": [
    "# Load Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f917bad9-8fe7-4882-b83b-71cf878fffd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-29T16:05:43.785201Z",
     "start_time": "2023-07-29T16:05:34.880381100Z"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "load",
     "REQUIRED"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "basedir: W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\n",
      "Loading loaded session pickle file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\loadedSessPickle.pkl... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:NeuropyPipeline.__setstate__(state=\"{'pipeline_name': 'kdiba_pipeline', 'session_data_type': 'kdiba', '_stage': DisplayPipelineStage(stage_name='kdiba_pipeline_input', identity=<PipelineStage.Displayed: 4>)}\")\n",
      "INFO:com.PhoHale.Spike3D.pipeline:select_filters(...) with: []\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze1\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze2\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing perform_action_for_all_contexts with action EvaluationActions.EVALUATE_COMPUTATIONS on filtered_session with filter named \"maze\"...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "INFO:com.PhoHale.Spike3D.pipeline:Performing global computations...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:NeuropyPipeline.on_stage_changed(new_stage=\"PipelineStage.Displayed\")\n",
      "WARNING:com.PhoHale.Spike3D.pipeline:WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Loading pickled pipeline success: W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\loadedSessPickle.pkl.\n",
      "properties already present in pickled version. No need to save.\n",
      "pipeline load success!\n",
      "using provided computation_functions_name_includelist: ['_perform_baseline_placefield_computation', '_perform_time_dependent_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_time_dependent_pf_sequential_surprise_computation_perform_two_step_position_decoding_computation']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the excludelist/includelist or computation function definitions change. Rework so that this is smarter.\n",
      "WARNING: saving_mode is SKIP_SAVING so pipeline will not be saved despite calling .save_pipeline(...).\n",
      "saving_mode.shouldSave == False, so not saving at the end of batch_load_session\n",
      "Loading loaded session pickle file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\output\\global_computation_results.pkl... done.\n"
     ]
    }
   ],
   "source": [
    "%pdb off\n",
    "# ==================================================================================================================== #\n",
    "# Load Data                                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "active_data_mode_name = 'kdiba'\n",
    "local_session_root_parent_context = IdentifyingContext(format_name=active_data_mode_name) # , animal_name='', configuration_name='one', session_name=a_sess.session_name\n",
    "local_session_root_parent_path = global_data_root_parent_path.joinpath('KDIBA')\n",
    "\n",
    "# [*] - indicates bad or session with a problem\n",
    "# 0, 1, 2, 3, 4, 5, 6, 7, [8], [9], 10, 11, [12], 13, 14, [15], [16], 17, \n",
    "# curr_context: IdentifyingContext = good_contexts_list[1] # select the session from all of the good sessions here.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15') # DONE. Very good. Many good Pfs, many good replays.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43') # DONE, might be the BEST SESSION, good example session with lots of place cells, clean replays, and clear bar graphs.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31') # DONE, Good Pfs but no good replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-13_14-42-6') # BAD, 2023-07-14, unsure why still.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19') # DONE, GREAT, both good Pfs and replays!\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25') # DONE, Added replay selections. Very \"jumpy\" between the starts and ends of the track.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-09_22-24-40') # DONE, Added replay selections. A TON of putative replays in general, most bad, but some good.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46') # DONE, added replay selections. Very few (like 12) replays each.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-13_15-22-3') # DONE, Good Pfs, no good epochs.\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30') # DONE, okay replays (selected)\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50') # DONE, very few replays (selected)\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-19_13-34-40') # BAD\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54') # DONE, one replay each (selected)\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3') # BAD, Good Pfs strangely despite horrible map, no good epochs\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-12_15-25-59') # BAD, No Epochs\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-16_18-47-52')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-17_12-52-15')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-25_13-20-55')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-28_12-38-13')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_17-46-44') # DONE, good. Many good pfs, many good replays. Noticed very strange jumping off the track in the 3D behavior/spikes viewer. Is there something wrong with this session?\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-02_19-28-0') # DONE, good?, replays selected, few\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25') # DONE, very few replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_12-15-3')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-09_22-4-5')\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54') # DONE, replays selected, quite a few replays but few are very good.\n",
    "\n",
    "\n",
    "curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-08_21-16-25')\n",
    "\n",
    "local_session_parent_path: Path = local_session_root_parent_path.joinpath(curr_context.animal, curr_context.exper_name) # 'gor01', 'one' - probably not needed anymore\n",
    "basedir: Path = local_session_parent_path.joinpath(curr_context.session_name).resolve()\n",
    "print(f'basedir: {str(basedir)}')\n",
    "\n",
    "# Read if possible:\n",
    "saving_mode = PipelineSavingScheme.SKIP_SAVING\n",
    "force_reload = False\n",
    "\n",
    "# # # # # Force write:\n",
    "# saving_mode = PipelineSavingScheme.TEMP_THEN_OVERWRITE\n",
    "# saving_mode = PipelineSavingScheme.OVERWRITE_IN_PLACE\n",
    "# force_reload = True\n",
    "\n",
    "## TODO: if loading is not possible, we need to change the `saving_mode` so that the new results are properly saved.\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-full_session_LOO_decoding_analysis.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "# epoch_name_includelist = ['maze']\n",
    "epoch_name_includelist = None\n",
    "active_computation_functions_name_includelist=[#'_perform_estimated_epochs_computation',  # AL:WAYS OFF\n",
    "                                            '_perform_baseline_placefield_computation',\n",
    "                                        '_perform_time_dependent_placefield_computation', # AL:WAYS OFF\n",
    "                                        '_perform_extended_statistics_computation',\n",
    "                                        '_perform_position_decoding_computation', \n",
    "                                        '_perform_firing_rate_trends_computation',\n",
    "                                        '_perform_pf_find_ratemap_peaks_computation',\n",
    "                                        '_perform_time_dependent_pf_sequential_surprise_computation' # AL:WAYS OFF\n",
    "                                        '_perform_two_step_position_decoding_computation',\n",
    "                                        # '_perform_recursive_latent_placefield_decoding' # AL:WAYS OFF\n",
    "                                    ]\n",
    "# active_computation_functions_name_includelist=['_perform_baseline_placefield_computation']\n",
    "\n",
    "curr_active_pipeline: NeuropyPipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_includelist=epoch_name_includelist,\n",
    "                                        computation_functions_name_includelist=active_computation_functions_name_includelist,\n",
    "                                        saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                        skip_extended_batch_computations=True, debug_print=False, fail_on_exception=False) # , active_pickle_filename = 'loadedSessPickle_withParameters.pkl'\n",
    "\n",
    "if not force_reload: # not just force_reload, needs to recompute whenever the computation fails.\n",
    "    try:\n",
    "        curr_active_pipeline.load_pickled_global_computation_results()\n",
    "    except Exception as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'cannot load global results: {e}')\n",
    "        raise\n",
    "\n",
    "\n",
    "# 6m 1.1s\n",
    "# 12m 15.6s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2206378",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "included includelist is specified: ['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'ratemap_peaks_prominence2d', 'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping', 'pf_dt_sequential_surprise', 'long_short_endcap_analysis'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze\"\n",
      "pf_computation, maze already computed.\n",
      "pfdt_computation missing.\n",
      "\t Recomputing pfdt_computation...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Recomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (24.71824744583462, 248.6393456241123)\n",
      "\t done.\n",
      "Recomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((24.71824744583462, 248.6393456241123), (136.77104473778593, 152.85274652666337))\n",
      "\t done.\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Recomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (24.71824744583462, 248.6393456241123)\n",
      "\t done.\n",
      "Recomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((24.71824744583462, 248.6393456241123), (136.77104473778593, 152.85274652666337))\n",
      "\t done.\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n",
      "Recomputing active_epoch_time_dependent_placefields... using self.config.grid_bin_bounds_1D: (24.71824744583462, 248.6393456241123)\n",
      "\t done.\n",
      "Recomputing active_epoch_time_dependent_placefields2D... using self.config.grid_bin_bounds: ((24.71824744583462, 248.6393456241123), (136.77104473778593, 152.85274652666337))\n",
      "\t done.\n",
      "\t done.\n",
      "ratemap_peaks_prominence2d missing.\n",
      "\t Recomputing ratemap_peaks_prominence2d...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n",
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n",
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n",
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n",
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n",
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n",
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n",
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n",
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n",
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n",
      "WARNING: a_slice is None. 2023-09-25 - Unsure if this is okay, used to be a fatal error.\n",
      "\t done.\n",
      "pf_dt_sequential_surprise missing.\n",
      "\t Recomputing pf_dt_sequential_surprise...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze1\"...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze2\"...\n",
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n",
      "\t done.\n",
      "firing_rate_trends, maze already computed.\n",
      "long_short_endcap_analysis missing.\n",
      "\t Recomputing long_short_endcap_analysis...\n",
      "num_disappearing_endcap_cells/num_total_endcap_cells: 8/43\n",
      "num_non_disappearing_endcap_cells/num_total_endcap_cells: 35/43\n",
      "num_significant_position_remappping_endcap_cells/num_non_disappearing_endcap_cells: 8/35\n",
      "\t done.\n",
      "long_short_decoding_analyses, maze already computed.\n",
      "short_long_pf_overlap_analyses missing.\n",
      "\t Recomputing short_long_pf_overlap_analyses...\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "\t done.\n",
      "long_short_fr_indicies_analyses missing.\n",
      "\t Recomputing long_short_fr_indicies_analyses...\n",
      "have an existing `global_computation_results.computation_config`: DynamicContainer({'instantaneous_time_bin_size_seconds': 0.01})\n",
      "_generalized_compute_long_short_firing_rate_indicies(...): processing key: \"laps\"\n",
      "_generalized_compute_long_short_firing_rate_indicies(...): processing key: \"replays\"\n",
      "_generalized_compute_long_short_firing_rate_indicies(...): processing key: \"non_replays\"\n",
      "\t done.\n",
      "jonathan_firing_rate_analysis, maze already computed.\n",
      "long_short_post_decoding, maze already computed.\n",
      "WARNING: after execution of all _comp_specifiers found the functions: {'long_short_rate_remapping': False} still remain! Are they correct and do they have proper validator decorators?\n",
      "done with all batch_extended_computations(...).\n",
      "newly_computed_values: [('pfdt_computation', 'maze'), ('ratemap_peaks_prominence2d', 'maze'), ('pf_dt_sequential_surprise', 'maze'), ('long_short_endcap_analysis', 'maze'), ('short_long_pf_overlap_analyses', 'maze'), ('long_short_fr_indicies_analyses', 'maze')].\n",
      "\n",
      "\n",
      "!!WARNING!!: changes to global results have been made but they will not be saved since saving_mode.value == \"skip_saving\"\n",
      "\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca3453d7de60468993fd6d49c26e106b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Box(children=(Label(value='session path:', layout=Layout(width='auto')), Label(value='W:\\\\Data\\â€¦"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# try:\n",
    "## Post Compute Validate 2023-05-16:\n",
    "was_updated = BatchSessionCompletionHandler.post_compute_validate(curr_active_pipeline) ## TODO: need to potentially re-save if was_updated\n",
    "if was_updated:\n",
    "    try:\n",
    "        curr_active_pipeline.save_pipeline(saving_mode=saving_mode)\n",
    "    except Exception as e:\n",
    "        ## TODO: catch/log saving error and indicate that it isn't saved.\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'ERROR RE-SAVING PIPELINE after update. error: {e}')\n",
    "\n",
    "\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "extended_computations_include_includelist=['pf_computation', 'pfdt_computation', 'firing_rate_trends', 'pf_dt_sequential_surprise', 'ratemap_peaks_prominence2d',\n",
    "    'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping',\n",
    "    #  'long_short_inst_spike_rate_groups',\n",
    "     'pf_dt_sequential_surprise', 'long_short_endcap_analysis'\n",
    "] # do only specified\n",
    "force_recompute_global = force_reload\n",
    "# force_recompute_global = True\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True, force_recompute=force_recompute_global, debug_print=False)\n",
    "if (len(newly_computed_values) > 0):\n",
    "    print(f'newly_computed_values: {newly_computed_values}.')\n",
    "    if (saving_mode.value != 'skip_saving'):\n",
    "        print(f'Saving global results...')\n",
    "        try:\n",
    "            # curr_active_pipeline.global_computation_results.persist_time = datetime.now()\n",
    "            # Try to write out the global computation function results:\n",
    "            curr_active_pipeline.save_global_computation_results()\n",
    "        except Exception as e:\n",
    "            exception_info = sys.exc_info()\n",
    "            e = CapturedException(e, exception_info)\n",
    "            print(f'\\n\\n!!WARNING!!: saving the global results threw the exception: {e}')\n",
    "            print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "    else:\n",
    "        print(f'\\n\\n!!WARNING!!: changes to global results have been made but they will not be saved since saving_mode.value == \"skip_saving\"')\n",
    "        print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "else:\n",
    "    print(f'no changes in global results.')\n",
    "\n",
    "# except Exception as e:\n",
    "#     exception_info = sys.exc_info()\n",
    "#     e = CapturedException(e, exception_info)\n",
    "#     print(f'second half threw: {e}')\n",
    "\n",
    "\n",
    "# 4m 5.2s for inst fr computations\n",
    "# Jupyter Widget Interactive\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import interactive_pipeline_widget, fullwidth_path_widget, interactive_pipeline_files\n",
    "\n",
    "_pipeline_jupyter_widget = interactive_pipeline_widget(curr_active_pipeline=curr_active_pipeline)\n",
    "# display(_pipeline_jupyter_widget)\n",
    "_pipeline_jupyter_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ce8eb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:save_pipeline(): Attempting to save pipeline to disk...\n",
      "INFO:com.PhoHale.Spike3D.pipeline:\tfinalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\loadedSessPickle.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\loadedSessPickle.pkl\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\20230927165133-loadedSessPickle.pkl... pipeline does not have \"display_output\"\n",
      "pipeline does not have \"render_actions\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:moving new output at 'W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\20230927165133-loadedSessPickle.pkl' -> to desired location: 'W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\loadedSessPickle.pkl'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "moving new output at 'W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\20230927165133-loadedSessPickle.pkl' -> to desired location: 'W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\loadedSessPickle.pkl'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:com.PhoHale.Spike3D.pipeline:\t save complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_computation_results_pickle_path: W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\output\\global_computation_results.pkl\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\gor01\\two\\2006-6-08_21-16-25\\output\\global_computation_results.pkl... done.\n"
     ]
    }
   ],
   "source": [
    "if curr_active_pipeline.updated_since_last_pickle:\n",
    "\t_bak_saving_mode = saving_mode\n",
    "\n",
    "saving_mode = PipelineSavingScheme.TEMP_THEN_OVERWRITE\n",
    "try:\n",
    "\tcurr_active_pipeline.save_pipeline(saving_mode=saving_mode)\n",
    "\tcurr_active_pipeline.save_global_computation_results()\n",
    "\n",
    "except Exception as e:\n",
    "\t## TODO: catch/log saving error and indicate that it isn't saved.\n",
    "\texception_info = sys.exc_info()\n",
    "\te = CapturedException(e, exception_info)\n",
    "\tprint(f'ERROR RE-SAVING PIPELINE after update. error: {e}')\n",
    "finally:\n",
    "\tsaving_mode = _bak_saving_mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3515eaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.Filesystem.metadata_helpers import FilesystemMetadata\n",
    "\n",
    "hdf5_output_path: Path = curr_active_pipeline.get_output_path().joinpath('pipeline_results.h5').resolve()\n",
    "print(f'pipeline hdf5_output_path: {hdf5_output_path}')\n",
    "\n",
    "\n",
    "# Only get files newer than date\n",
    "newest_file_to_overwrite_date = datetime.now() - timedelta(days=1) # don't overwrite any files more recent than 1 day ago\n",
    "if hdf5_output_path.exists() and (FilesystemMetadata.get_last_modified_time(hdf5_output_path)<=newest_file_to_overwrite_date):\n",
    "\t# file is folder than the date to overwrite, so overwrite it\n",
    "\tprint(f'OVERWRITING (or writing) the file {hdf5_output_path}!')\n",
    "else:\n",
    "\tprint(f'file {hdf5_output_path} is newer than the allowed overwrite date, so it will be skipped.')\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c850782f",
   "metadata": {},
   "source": [
    "# End Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87dc7ae9",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computation_config\n"
     ]
    }
   ],
   "source": [
    "## long_short_decoding_analyses:\n",
    "curr_long_short_decoding_analyses = curr_active_pipeline.global_computation_results.computed_data['long_short_leave_one_out_decoding_analysis']\n",
    "long_one_step_decoder_1D, short_one_step_decoder_1D, long_replays, short_replays, global_replays, long_shared_aclus_only_decoder, short_shared_aclus_only_decoder, shared_aclus, long_short_pf_neurons_diff, n_neurons, long_results_obj, short_results_obj, is_global = curr_long_short_decoding_analyses.long_decoder, curr_long_short_decoding_analyses.short_decoder, curr_long_short_decoding_analyses.long_replays, curr_long_short_decoding_analyses.short_replays, curr_long_short_decoding_analyses.global_replays, curr_long_short_decoding_analyses.long_shared_aclus_only_decoder, curr_long_short_decoding_analyses.short_shared_aclus_only_decoder, curr_long_short_decoding_analyses.shared_aclus, curr_long_short_decoding_analyses.long_short_pf_neurons_diff, curr_long_short_decoding_analyses.n_neurons, curr_long_short_decoding_analyses.long_results_obj, curr_long_short_decoding_analyses.short_results_obj, curr_long_short_decoding_analyses.is_global \n",
    "\n",
    "# (long_one_step_decoder_1D, short_one_step_decoder_1D), (long_one_step_decoder_2D, short_one_step_decoder_2D) = compute_short_long_constrained_decoders(curr_active_pipeline, recalculate_anyway=True)\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_epoch_context, short_epoch_context, global_epoch_context = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_epoch_name, short_epoch_name, global_epoch_name)]\n",
    "long_epoch_obj, short_epoch_obj = [Epoch(curr_active_pipeline.sess.epochs.to_dataframe().epochs.label_slice(an_epoch_name)) for an_epoch_name in [long_epoch_name, short_epoch_name]]\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name]['computed_data'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_computation_config, short_computation_config, global_computation_config = [curr_active_pipeline.computation_results[an_epoch_name]['computation_config'] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "long_pf2D, short_pf2D, global_pf2D = long_results.pf2D, short_results.pf2D, global_results.pf2D\n",
    "decoding_time_bin_size = long_one_step_decoder_1D.time_bin_size # 1.0/30.0 # 0.03333333333333333\n",
    "\n",
    "\n",
    "## Get global 'long_short_post_decoding' results:\n",
    "curr_long_short_post_decoding = curr_active_pipeline.global_computation_results.computed_data['long_short_post_decoding']\n",
    "expected_v_observed_result, curr_long_short_rr = curr_long_short_post_decoding.expected_v_observed_result, curr_long_short_post_decoding.rate_remapping\n",
    "rate_remapping_df, high_remapping_cells_only = curr_long_short_rr.rr_df, curr_long_short_rr.high_only_rr_df\n",
    "Flat_epoch_time_bins_mean, Flat_decoder_time_bin_centers, num_neurons, num_timebins_in_epoch, num_total_flat_timebins, is_short_track_epoch, is_long_track_epoch, short_short_diff, long_long_diff = expected_v_observed_result.Flat_epoch_time_bins_mean, expected_v_observed_result.Flat_decoder_time_bin_centers, expected_v_observed_result.num_neurons, expected_v_observed_result.num_timebins_in_epoch, expected_v_observed_result.num_total_flat_timebins, expected_v_observed_result.is_short_track_epoch, expected_v_observed_result.is_long_track_epoch, expected_v_observed_result.short_short_diff, expected_v_observed_result.long_long_diff\n",
    "\n",
    "jonathan_firing_rate_analysis_result: JonathanFiringRateAnalysisResult = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis\n",
    "(epochs_df_L, epochs_df_S), (filter_epoch_spikes_df_L, filter_epoch_spikes_df_S), (good_example_epoch_indicies_L, good_example_epoch_indicies_S), (short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset), new_all_aclus_sort_indicies, assigning_epochs_obj = PAPER_FIGURE_figure_1_add_replay_epoch_rasters(curr_active_pipeline)\n",
    "\n",
    "# inst_spike_rate_groups_result: InstantaneousSpikeRateGroupsComputation = curr_active_pipeline.global_computation_results.computed_data.long_short_inst_spike_rate_groups\n",
    "# custom_InstSpikeRateTrends_df = inst_spike_rate_groups_result.all_incl_endPlatforms_InstSpikeRateTrends_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "485fa087",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Relative Entropy/Surprise Results:\n",
    "active_extended_stats = global_results['extended_stats']\n",
    "active_relative_entropy_results = active_extended_stats['pf_dt_sequential_surprise'] # DynamicParameters\n",
    "post_update_times: np.ndarray = active_relative_entropy_results['post_update_times'] # (4152,) = (n_post_update_times,)\n",
    "snapshot_differences_result_dict = active_relative_entropy_results['snapshot_differences_result_dict']\n",
    "time_intervals: np.ndarray = active_relative_entropy_results['time_intervals']\n",
    "long_short_rel_entr_curves_frames: np.ndarray = active_relative_entropy_results['long_short_rel_entr_curves_frames'] # (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "short_long_rel_entr_curves_frames: np.ndarray = active_relative_entropy_results['short_long_rel_entr_curves_frames'] # (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "flat_relative_entropy_results: np.ndarray = active_relative_entropy_results['flat_relative_entropy_results'] # (149, 63) - (nSnapshots, nXbins)\n",
    "flat_jensen_shannon_distance_results: np.ndarray = active_relative_entropy_results['flat_jensen_shannon_distance_results'] # (149, 63) - (nSnapshots, nXbins)\n",
    "flat_jensen_shannon_distance_across_all_positions: np.ndarray = np.sum(np.abs(flat_jensen_shannon_distance_results), axis=1) # sum across all position bins # (4152,) - (nSnapshots)\n",
    "flat_surprise_across_all_positions: np.ndarray = np.sum(np.abs(flat_relative_entropy_results), axis=1) # sum across all position bins # (4152,) - (nSnapshots)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e4d1632",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# Time-dependent\n",
    "long_pf1D_dt, short_pf1D_dt, global_pf1D_dt = long_results.pf1D_dt, short_results.pf1D_dt, global_results.pf1D_dt\n",
    "long_pf2D_dt, short_pf2D_dt, global_pf2D_dt = long_results.pf2D_dt, short_results.pf2D_dt, global_results.pf2D_dt\n",
    "global_pf1D_dt: PfND_TimeDependent = global_results.pf1D_dt\n",
    "global_pf2D_dt: PfND_TimeDependent = global_results.pf2D_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66fe35dc",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([4, 8, 16, 82], dtype='int64')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## long_short_endcap_analysis:\n",
    "truncation_checking_result: TruncationCheckingResults = curr_active_pipeline.global_computation_results.computed_data.long_short_endcap\n",
    "\n",
    "disappearing_endcap_aclus = truncation_checking_result.disappearing_endcap_aclus\n",
    "disappearing_endcap_aclus\n",
    "\n",
    "trivially_remapping_endcap_aclus = truncation_checking_result.minor_remapping_endcap_aclus\n",
    "trivially_remapping_endcap_aclus\n",
    "\n",
    "significant_distant_remapping_endcap_aclus = truncation_checking_result.significant_distant_remapping_endcap_aclus\n",
    "significant_distant_remapping_endcap_aclus\n",
    "\n",
    "\n",
    "appearing_aclus = jonathan_firing_rate_analysis_result.neuron_replay_stats_df[jonathan_firing_rate_analysis_result.neuron_replay_stats_df['track_membership'] == SplitPartitionMembership.RIGHT_ONLY].index\n",
    "appearing_aclus\n",
    "# appearing_endcap_aclus = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "524a2a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surprise_time_bin_duration: 0.5\n"
     ]
    }
   ],
   "source": [
    "## This method tries to convert the active_relative_entropy_results:\n",
    "active_relative_entropy_results = deepcopy(active_extended_stats['pf_dt_sequential_surprise'].to_dict()) # DynamicParameters\n",
    "\n",
    "# snapshot_differences_result_dict = active_relative_entropy_results['snapshot_differences_result_dict']\n",
    "\n",
    "# n_post_update_times == 'nSnapshots'\n",
    "post_update_times: np.ndarray = active_relative_entropy_results['post_update_times'] # (4152,) = (n_post_update_times,)\n",
    "time_intervals: np.ndarray = active_relative_entropy_results['time_intervals']\n",
    "surprise_time_bin_duration = (post_update_times[2]-post_update_times[1])\n",
    "print(f'surprise_time_bin_duration: {surprise_time_bin_duration}')\n",
    "\n",
    "long_short_rel_entr_curves_frames: np.ndarray = active_relative_entropy_results['long_short_rel_entr_curves_frames'] # (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "short_long_rel_entr_curves_frames: np.ndarray = active_relative_entropy_results['short_long_rel_entr_curves_frames'] # (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "flat_relative_entropy_results: np.ndarray = active_relative_entropy_results['flat_relative_entropy_results'] # (149, 63) - (n_post_update_times, nXbins)\n",
    "flat_jensen_shannon_distance_results: np.ndarray = active_relative_entropy_results['flat_jensen_shannon_distance_results'] # (149, 63) - (n_post_update_times, nXbins)\n",
    "\n",
    "flat_jensen_shannon_distance_across_all_positions: np.ndarray = np.sum(np.abs(flat_jensen_shannon_distance_results), axis=1) # sum across all position bins # (4152,) - (nSnapshots)\n",
    "flat_surprise_across_all_positions: np.ndarray = np.sum(np.abs(flat_relative_entropy_results), axis=1) # sum across all position bins # (4152,) - (nSnapshots)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a087168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "post_update_times.shape: (2288,)\n",
      "time_intervals.shape: (2289, 2)\n",
      "flat_jensen_shannon_distance_across_all_positions.shape: (2288,)\n"
     ]
    }
   ],
   "source": [
    "print(f'post_update_times.shape: {post_update_times.shape}')\n",
    "print(f'time_intervals.shape: {time_intervals.shape}')\n",
    "flat_relative_entropy_results.shape # (3308, 107)\n",
    "# 4152\n",
    "print(f'flat_jensen_shannon_distance_across_all_positions.shape: {np.shape(flat_jensen_shannon_distance_across_all_positions)}') # .shape: (3308,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a248611",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_update_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9188faee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06b58ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: 'â–º';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: 'â–¼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.Dataset&gt;\n",
       "Dimensions:                                            (post_update_t: 2288,\n",
       "                                                        neuron_idx: 82,\n",
       "                                                        xbin: 112)\n",
       "Coordinates:\n",
       "  * post_update_t                                      (post_update_t) float64 ...\n",
       "Dimensions without coordinates: neuron_idx, xbin\n",
       "Data variables:\n",
       "    long_short_rel_entr_curves_frames                  (post_update_t, neuron_idx, xbin) float64 ...\n",
       "    short_long_rel_entr_curves_frames                  (post_update_t, neuron_idx, xbin) float64 ...\n",
       "    flat_relative_entropy_results                      (post_update_t, xbin) float64 ...\n",
       "    flat_jensen_shannon_distance_results               (post_update_t, xbin) float64 ...\n",
       "    flat_surprise_across_all_positions                 (post_update_t) float64 ...\n",
       "    flat_jensen_shannon_distance_across_all_positions  (post_update_t) float64 ...</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.Dataset</div></div><ul class='xr-sections'><li class='xr-section-item'><input id='section-61fd2c04-4475-4dc6-b3b3-322772a47784' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-61fd2c04-4475-4dc6-b3b3-322772a47784' class='xr-section-summary'  title='Expand/collapse section'>Dimensions:</label><div class='xr-section-inline-details'><ul class='xr-dim-list'><li><span class='xr-has-index'>post_update_t</span>: 2288</li><li><span>neuron_idx</span>: 82</li><li><span>xbin</span>: 112</li></ul></div><div class='xr-section-details'></div></li><li class='xr-section-item'><input id='section-b8a23bba-ee99-4690-9f9a-3cb51dee5dd2' class='xr-section-summary-in' type='checkbox'  checked><label for='section-b8a23bba-ee99-4690-9f9a-3cb51dee5dd2' class='xr-section-summary' >Coordinates: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>post_update_t</span></div><div class='xr-var-dims'>(post_update_t)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>42.85 43.35 ... 1.186e+03 1.186e+03</div><input id='attrs-245ec221-263d-4199-b1e3-52eddd76635d' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-245ec221-263d-4199-b1e3-52eddd76635d' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-9c2bb2f3-3a82-4aa7-b1f9-4a6c3efef3e7' class='xr-var-data-in' type='checkbox'><label for='data-9c2bb2f3-3a82-4aa7-b1f9-4a6c3efef3e7' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([  42.852108,   43.352108,   43.852108, ..., 1185.352108, 1185.852108,\n",
       "       1186.352108])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-00b9b9d4-49da-45c8-aa5a-ed4cc10e5384' class='xr-section-summary-in' type='checkbox'  checked><label for='section-00b9b9d4-49da-45c8-aa5a-ed4cc10e5384' class='xr-section-summary' >Data variables: <span>(6)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span>long_short_rel_entr_curves_frames</span></div><div class='xr-var-dims'>(post_update_t, neuron_idx, xbin)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>0.0 -0.0006439 ... 0.0 0.0</div><input id='attrs-cd23357d-82e4-4d84-9195-294d95346ad1' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-cd23357d-82e4-4d84-9195-294d95346ad1' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-5f5d080d-7d1e-4606-a505-34f705bbec33' class='xr-var-data-in' type='checkbox'><label for='data-5f5d080d-7d1e-4606-a505-34f705bbec33' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[[0, -0.000643949, -0.00410326, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, -0.0010987, -0.00647803, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "...\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 1.06931e-06, 6.97283e-06, ..., 0, 0, 0],\n",
       "        [0, 1.72475e-08, 1.1247e-07, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 1.20728e-07, 7.87245e-07, ..., 0, 0, 0],\n",
       "        [0, 9.65825e-07, 6.298e-06, ..., 0, 0, 0],\n",
       "        [0, 1.72469e-08, 1.12464e-07, ..., 0, 0, 0]]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>short_long_rel_entr_curves_frames</span></div><div class='xr-var-dims'>(post_update_t, neuron_idx, xbin)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>0.0 0.0006936 0.004625 ... 0.0 0.0</div><input id='attrs-44ddcfe7-1218-4eea-8d4d-68d9dedf89f7' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-44ddcfe7-1218-4eea-8d4d-68d9dedf89f7' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-a0192bc8-1680-40f4-9806-485ac300a8b4' class='xr-var-data-in' type='checkbox'><label for='data-a0192bc8-1680-40f4-9806-485ac300a8b4' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[[0, 0.000693643, 0.00462534, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0.00160743, 0.0114234, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "...\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, -1.0693e-06, -6.97266e-06, ..., 0, 0, 0],\n",
       "        [0, -1.72462e-08, -1.12458e-07, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, -1.20728e-07, -7.87245e-07, ..., 0, 0, 0],\n",
       "        [0, -9.65823e-07, -6.29793e-06, ..., 0, 0, 0],\n",
       "        [0, -1.72469e-08, -1.12464e-07, ..., 0, 0, 0]]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>flat_relative_entropy_results</span></div><div class='xr-var-dims'>(post_update_t, xbin)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>0.0 0.003628 0.02502 ... 0.0 0.0</div><input id='attrs-329b31ae-822e-4463-9438-43956f89e3a8' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-329b31ae-822e-4463-9438-43956f89e3a8' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-75edd95c-dfca-49a3-b4c0-7c8bb0c2eb86' class='xr-var-data-in' type='checkbox'><label for='data-75edd95c-dfca-49a3-b4c0-7c8bb0c2eb86' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[0, 0.00362844, 0.0250167, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 2.42837e-05, 0.000158353, ..., 0, 0, 0]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>flat_jensen_shannon_distance_results</span></div><div class='xr-var-dims'>(post_update_t, xbin)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>0.0 0.0001525 0.001304 ... 0.0 0.0</div><input id='attrs-f71e650b-676f-499f-98ff-18a43b75745f' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-f71e650b-676f-499f-98ff-18a43b75745f' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-9ad56f07-5060-450f-9bf0-50f9ed080093' class='xr-var-data-in' type='checkbox'><label for='data-9ad56f07-5060-450f-9bf0-50f9ed080093' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([[0, 0.000152471, 0.00130376, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 2.74475e-11, 1.04398e-09, ..., 0, 0, 0]])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>flat_surprise_across_all_positions</span></div><div class='xr-var-dims'>(post_update_t)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>inf inf inf ... 3.572 2.514 1.079</div><input id='attrs-f835d20f-0077-414f-a791-5c42f6cb6763' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-f835d20f-0077-414f-a791-5c42f6cb6763' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-bd458c03-53c9-4198-beee-b6478730501f' class='xr-var-data-in' type='checkbox'><label for='data-bd458c03-53c9-4198-beee-b6478730501f' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([inf, inf, inf, ..., 3.57216, 2.51449, 1.07941])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span>flat_jensen_shannon_distance_across_all_positions</span></div><div class='xr-var-dims'>(post_update_t)</div><div class='xr-var-dtype'>float64</div><div class='xr-var-preview xr-preview'>inf inf inf ... 0.02405 0.01174</div><input id='attrs-715e5d43-6fc1-4c72-a4c6-129681125235' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-715e5d43-6fc1-4c72-a4c6-129681125235' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-13677abe-fb01-45f4-a121-7dc48c1e3c97' class='xr-var-data-in' type='checkbox'><label for='data-13677abe-fb01-45f4-a121-7dc48c1e3c97' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([inf, inf, inf, ..., 0.013688, 0.0240541, 0.0117406])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-3fbf2f9f-786b-469c-9a18-b204972ac58d' class='xr-section-summary-in' type='checkbox'  ><label for='section-3fbf2f9f-786b-469c-9a18-b204972ac58d' class='xr-section-summary' >Indexes: <span>(1)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>post_update_t</div></div><div class='xr-index-preview'>PandasIndex</div><div></div><input id='index-faf1a93c-8e2f-46ea-a6ef-0df049a09ba3' class='xr-index-data-in' type='checkbox'/><label for='index-faf1a93c-8e2f-46ea-a6ef-0df049a09ba3' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Float64Index([42.852107851649635, 43.352107851649635, 43.852107851649635, 44.352107851649635, 44.852107851649635, 45.352107851649635, 45.852107851649635, 46.352107851649635, 46.852107851649635, 47.352107851649635,\n",
       "              ...\n",
       "              1181.8521078516496, 1182.3521078516496, 1182.8521078516496, 1183.3521078516496, 1183.8521078516496, 1184.3521078516496, 1184.8521078516496, 1185.3521078516496, 1185.8521078516496, 1186.3521078516496], dtype=&#x27;float64&#x27;, name=&#x27;post_update_t&#x27;, length=2288))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-6b194204-0296-4694-a8ea-19d12a7ddaa2' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-6b194204-0296-4694-a8ea-19d12a7ddaa2' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:                                            (post_update_t: 2288,\n",
       "                                                        neuron_idx: 82,\n",
       "                                                        xbin: 112)\n",
       "Coordinates:\n",
       "  * post_update_t                                      (post_update_t) float64 ...\n",
       "Dimensions without coordinates: neuron_idx, xbin\n",
       "Data variables:\n",
       "    long_short_rel_entr_curves_frames                  (post_update_t, neuron_idx, xbin) float64 ...\n",
       "    short_long_rel_entr_curves_frames                  (post_update_t, neuron_idx, xbin) float64 ...\n",
       "    flat_relative_entropy_results                      (post_update_t, xbin) float64 ...\n",
       "    flat_jensen_shannon_distance_results               (post_update_t, xbin) float64 ...\n",
       "    flat_surprise_across_all_positions                 (post_update_t) float64 ...\n",
       "    flat_jensen_shannon_distance_across_all_positions  (post_update_t) float64 ..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xarray as xr\n",
    "\n",
    "\n",
    "active_relative_entropy_results_xr_dict = {}\n",
    "\n",
    "ndim:int = 1\n",
    "\n",
    "if ndim < 2:\n",
    "\tpos_dim_labels = (\"xbin\", )\n",
    "else:\n",
    "\tpos_dim_labels = (\"xbin\", \"ybin\")\n",
    "\n",
    "extra_coords = {'post_update_t': post_update_times}\n",
    "active_relative_entropy_results_xr_dict['long_short_rel_entr_curves_frames'] = xr.DataArray(active_relative_entropy_results['long_short_rel_entr_curves_frames'], dims=(\"post_update_t\", \"neuron_idx\", *pos_dim_labels), coords={'post_update_t': post_update_times}) # \n",
    "active_relative_entropy_results_xr_dict['short_long_rel_entr_curves_frames'] = xr.DataArray(active_relative_entropy_results['short_long_rel_entr_curves_frames'], dims=(\"post_update_t\", \"neuron_idx\", *pos_dim_labels), coords={'post_update_t': post_update_times})\n",
    "\n",
    "active_relative_entropy_results_xr_dict['flat_relative_entropy_results'] = xr.DataArray(active_relative_entropy_results['flat_relative_entropy_results'], dims=(\"post_update_t\", *pos_dim_labels), coords={'post_update_t': post_update_times})\n",
    "active_relative_entropy_results_xr_dict['flat_jensen_shannon_distance_results'] = xr.DataArray(active_relative_entropy_results['flat_jensen_shannon_distance_results'], dims=(\"post_update_t\", *pos_dim_labels), coords={'post_update_t': post_update_times})\n",
    "\n",
    "active_relative_entropy_results_xr_dict['flat_surprise_across_all_positions'] = xr.DataArray(flat_surprise_across_all_positions, dims=(\"post_update_t\",), coords={'post_update_t': post_update_times})\n",
    "active_relative_entropy_results_xr_dict['flat_jensen_shannon_distance_across_all_positions'] = xr.DataArray(flat_jensen_shannon_distance_across_all_positions, dims=(\"post_update_t\",), coords={'post_update_t': post_update_times})\n",
    "combined_dataset = xr.Dataset(active_relative_entropy_results_xr_dict)\n",
    "combined_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04944753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5f14da",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_matrix = active_relative_entropy_results_xr_dict['flat_jensen_shannon_distance_results'].to_numpy().astype(float)\n",
    "out_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdc5ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_matrix = active_relative_entropy_results_xr_dict['long_short_rel_entr_curves_frames'].to_numpy().astype(float)\n",
    "out_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83483c60",
   "metadata": {},
   "source": [
    "# 2023-09-26 - Interactive `napari` testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bae54740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.shape(animal_pos_track_data): (2289, 4)\n"
     ]
    }
   ],
   "source": [
    "import napari\n",
    "from pyphoplacecellanalysis.GUI.Napari.napari_helpers import napari_add_surprise_data_layers, napari_add_animal_position\n",
    "\n",
    "# create the viewer and window\n",
    "viewer = napari.Viewer()\n",
    "\n",
    "# image_layer = viewer.add_image(out_matrix.astype(float))\n",
    "# viewer = napari.view_image(out_matrix.astype(float))\n",
    "# # Send local variables to the console\n",
    "# viewer.update_console(locals())\n",
    "# print(f'{locals()}')\n",
    "\n",
    "napari_add_surprise_data_layers(viewer, active_relative_entropy_results)\n",
    "napari_add_animal_position(viewer=viewer, position_df=global_pf1D_dt.all_time_filtered_pos_df[['t','x','binned_x']], time_intervals=time_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9be7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Add grid_bin_bounds\n",
    "global_pf1D_dt.config.grid_bin_bounds\n",
    "rect = np.array([[0, 0], [3, 1]])\n",
    "viewer.add_shapes(rect, shape_type='rectangle', edge_width=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014b071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Layers are accessible via:\n",
    "# viewer.layers[a_name].contrast_limits=(100, 175)\n",
    "\n",
    "\n",
    "# image_layer['long_short_rel_entr_curves_frames'] = viewer.add_image(active_relative_entropy_results_xr_dict['long_short_rel_entr_curves_frames'].to_numpy().astype(float), name='long_short_rel_entr_curves_frames')\n",
    "# image_layer = viewer.add_image(active_relative_entropy_results_xr_dict['short_long_rel_entr_curves_frames'].to_numpy().astype(float), name='short_long_rel_entr_curves_frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fd833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_layer = image_layer_dict['long_short_rel_entr_curves_frames']\n",
    "image_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995bcea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_layer.contrast_limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924e6a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_layer.colormap = 'bop blue'\n",
    "image_layer.blending\n",
    "\n",
    "\n",
    "dict(blending='additive', colormap='red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f1645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "viewer.dims.set_point(axis, position)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aabac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imsave\n",
    "# from napari_animation import Animation\n",
    "\n",
    "def _set_timepoint(viewer, current_timepoint):\n",
    "    variable_timepoint = list(viewer.dims.current_step)\n",
    "    variable_timepoint[0] = current_timepoint\n",
    "    viewer.dims.current_step = variable_timepoint\n",
    "\n",
    "# animation = Animation(viewer)\n",
    "# viewer.update_console({'animation': animation})\n",
    "# animation.capture_keyframe()\n",
    "viewer.reset_view()\n",
    "\n",
    "n_time_windows = np.shape(time_intervals)[0]\n",
    "\n",
    "for window_idx in np.arange(n_time_windows):\n",
    "\t_set_timepoint(viewer, window_idx+1)\n",
    "\t# take screenshot\n",
    "\tscreenshot = viewer.screenshot()\n",
    "\t# from skimage.io import imsave\n",
    "\timsave(f'output/videos/screenshot_{window_idx}.png', screenshot)\n",
    "\t# animation.capture_keyframe()\n",
    "\n",
    "# animation.animate('demo2D.mov', canvas_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a091ce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(screenshot)\n",
    "screenshot.shape # (1165, 1488, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daed0ef",
   "metadata": {},
   "source": [
    "# 2023-09-27 - Exporting suprise ndarray to a video file for visualization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075bff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add the animal's closest current position (binned) as a single colored pixel along the top of the array:\n",
    "len(global_pf1D_dt.historical_snapshots)\n",
    "\n",
    "global_pf1D_dt.historical_snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe72914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# array = active_relative_entropy_results_xr_dict['long_short_rel_entr_curves_frames'].to_numpy()\n",
    "array = active_relative_entropy_results_xr_dict['long_short_rel_entr_curves_frames'].to_numpy()\n",
    "gray_frames = cv2.normalize(array, None, 255, 0, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U) # same size as array\n",
    "# gray_3c = cv2.merge([gray, gray, gray])\n",
    "\n",
    "print(f'array.shape: {array.shape}')\n",
    "print(f'gray_frames.shape: {gray_frames.shape}')\n",
    "assert array.shape == gray_frames.shape, f\"gray_frames should be the same size as the input array, just scaled to greyscale int8!\"\n",
    "# print(f'gray_3c.shape: {gray_3c.shape}')\n",
    "\n",
    "# Extract width and height from the array:\n",
    "n_frames = np.shape(array)[0]\n",
    "height = np.shape(array)[1]\n",
    "width = np.shape(array)[2]\n",
    "\n",
    "# initialize video writer\n",
    "fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
    "fps = 30\n",
    "video_filename = 'output/videos/output.avi'\n",
    "# video_filename='output/videos/long_short_rel_entr_curves_frames.mp4'\n",
    "\n",
    "# # initialize water image\n",
    "# height = 500\n",
    "# width = 700\n",
    "# water_depth = np.zeros((height, width), dtype=float)\n",
    "\n",
    "out = cv2.VideoWriter(video_filename, fourcc, fps, (width, height))\n",
    "\n",
    "# new frame after each addition of water\n",
    "for i in np.arange(n_frames):\n",
    "    gray = np.squeeze(gray_frames[i,:,:]) # single frame\n",
    "    gray_3c = cv2.merge([gray, gray, gray])\n",
    "    out.write(gray_3c)\n",
    "\n",
    "# close out the video writer\n",
    "out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb792a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def save_array_as_video(array, output_filename='output/videos/long_short_rel_entr_curves_frames.mp4', fps=30.0, isColor=False):\n",
    "    \"\"\"\n",
    "    Save a 3D numpy array as a grayscale video.\n",
    "\n",
    "    Parameters:\n",
    "    - array: numpy array of shape (timesteps, height, width)\n",
    "    - output_filename: name of the output video file\n",
    "    - fps: frames per second for the output video\n",
    "    \"\"\"\n",
    "    if array.dtype != np.uint8:\n",
    "        array = array.astype(np.uint8)\n",
    "    # Initialize the video writer\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_filename, fourcc, fps, (array.shape[2], array.shape[1]), isColor=isColor)\n",
    "    for i in range(array.shape[0]):\n",
    "        frame = array[i]\n",
    "        if not isColor:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)\n",
    "        out.write(frame)\n",
    "    out.release()\n",
    "    return Path(output_filename).resolve()\n",
    "\n",
    "\n",
    "def normalize_and_save_as_video(array, output_filename='output.mp4', fps=30.0):\n",
    "    array = ((array - array.min()) / (array.max() - array.min()) * 255).astype(np.uint8)\n",
    "    return save_array_as_video(array, output_filename, fps)\n",
    "\n",
    "\n",
    "def colormap_and_save_as_video(array, output_filename='output.mp4', fps=30.0, colormap=cv2.COLORMAP_JET):\n",
    "    array = ((array - array.min()) / (array.max() - array.min()) * 255).astype(np.uint8)\n",
    "    color_array = cv2.applyColorMap(array, colormap)\n",
    "    return save_array_as_video(color_array, output_filename, fps, isColor=True)\n",
    "    \n",
    "\n",
    "# Example usage\n",
    "# array = np.random.randint(0, 256, (4123, 90, 117), dtype=np.uint8)\n",
    "\n",
    "# Save the `long_short_rel_entr_curves_frames` array out to the file:\n",
    "# video_out_path = save_array_as_video(active_relative_entropy_results_xr_dict['long_short_rel_entr_curves_frames'].to_numpy(), output_filename='output/videos/long_short_rel_entr_curves_frames.mp4')\n",
    "\n",
    "# array = active_relative_entropy_results_xr_dict['long_short_rel_entr_curves_frames'].to_numpy()\n",
    "array = gray.copy()\n",
    "# video_out_path = normalize_and_save_as_video(array=array, output_filename='output/videos/long_short_rel_entr_curves_frames.mp4')\n",
    "video_out_path = save_array_as_video(array=array, output_filename='output/videos/long_short_rel_entr_curves_frames.mp4', isColor=False)\n",
    "print(f'video_out_path: {video_out_path}')\n",
    "reveal_in_system_file_manager(video_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d831bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataset.dump_to_store()\n",
    "\n",
    "xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8515c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataset.to_netcdf('output/test_relative_entropy_results_xrDataSet.h5', engine='h5netcdf')\n",
    "\n",
    "# combined_dataset.dump_to_store("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf460221",
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.Dataset(data_vars=dict(\n",
    "         temperature=([\"x\", \"y\", \"time\"], temperature),\n",
    "         precipitation=([\"x\", \"y\", \"time\"], precipitation),\n",
    "     ),\n",
    "     coords=dict(\n",
    "         lon=([\"x\", \"y\"], lon),\n",
    "         lat=([\"x\", \"y\"], lat),\n",
    "         time=time,\n",
    "         reference_time=reference_time,\n",
    "     ),\n",
    "     attrs=dict(description=\"Weather related data.\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df53ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_update_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3ea9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# xr.DataArray(long_short_rel_entr_curves_frames, dims=(\"post_update_t\", \"neuron_idx\", *pos_dim_labels), name=\"long_short_rel_entr_curves_frames\", coords={'post_update_t': post_update_times})\n",
    "# post_update_times.shape # (3308,)\n",
    "# time_intervals.shape # (3309, 2)\n",
    "\n",
    "# xr.DataArray(long_short_rel_entr_curves_frames, dims=(\"post_update_t\", \"neuron_idx\", *pos_dim_labels), name=\"long_short_rel_entr_curves_frames\", coords={'post_update_t': post_update_times})\n",
    "\n",
    "\n",
    "# def prepare_surprise_result_for_export_as_xarray(post_update_times: np.ndarray, a_result, ndim:int=1) -> xr.DataArray:\n",
    "# \t\"\"\" exports all snapshots as an xarray \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# \t# post_update_times = active_extended_stats.pf_dt_sequential_surprise.post_update_times\n",
    "# \ta_result\n",
    "# \t# post_update_times = np.array(list(self.historical_snapshots.keys()), dtype=np.float64)\n",
    "# \tif ndim < 2:\n",
    "# \t\tpos_dim_labels = (\"xbin\", )\n",
    "# \telse:\n",
    "# \t\tpos_dim_labels = (\"xbin\", \"ybin\")\n",
    "\n",
    "# \t# occupancy_weighted_tuning_maps_over_time_arr = np.stack([placefield_snapshot.occupancy_weighted_tuning_maps_matrix for timestamp_t, placefield_snapshot in self.historical_snapshots.items()]) # Concatenates so that the time is the first dimension\n",
    "# \toccupancy_weighted_tuning_maps_over_time_xr = xr.DataArray(a_result, dims=(\"snapshot_t\", \"neuron_idx\", *pos_dim_labels), name=\"tuning_maps\", coords={'snapshot_t': post_update_times}) # , coords={\"x\": [10, 20]}\n",
    "# \toccupancy_weighted_tuning_maps_over_time_xr.attrs[\"long_name\"] = \"occupancy_weighted_tuning_maps\"\n",
    "# \toccupancy_weighted_tuning_maps_over_time_xr.attrs[\"units\"] = \"spikes/sec\"\n",
    "# \toccupancy_weighted_tuning_maps_over_time_xr.attrs[\"description\"] = \"The tuning maps for each cell normalized for their occupancy.\"\n",
    "# \toccupancy_weighted_tuning_maps_over_time_xr.attrs[\"random_attribute\"] = 123\n",
    "# \treturn occupancy_weighted_tuning_maps_over_time_xr\n",
    "\n",
    "## Body:\n",
    "\n",
    "# prepare_surprise_result_for_export_as_xarray(long_short_rel_entr_curves_frames, dims=(\"post_update_t\", \"neuron_idx\", *pos_dim_labels), name=\"long_short_rel_entr_curves_frames\", coords={'post_update_t': post_update_times})\n",
    "\n",
    "xr.DataArray(long_short_rel_entr_curves_frames, dims=(\"post_update_t\", \"neuron_idx\", *pos_dim_labels), name=\"long_short_rel_entr_curves_frames\", coords={'post_update_t': post_update_times})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9183612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(active_relative_entropy_results)\n",
    "type(long_results_obj) # pyphoplacecellanalysis.Analysis.Decoder.decoder_result.LeaveOneOutDecodingAnalysisResult\n",
    "short_results_obj\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1129c3d",
   "metadata": {},
   "source": [
    "# 2023-09-26 - Interactive `Spike3DRasterWindowWidget` exploration`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651664bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Gets the existing SpikeRasterWindow or creates a new one if one doesn't already exist:\n",
    "from pyphocorehelpers.gui.Qt.TopLevelWindowHelper import TopLevelWindowHelper\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg # Used to get the app for TopLevelWindowHelper.top_level_windows\n",
    "## For searching with `TopLevelWindowHelper.all_widgets(...)`:\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import Spike2DRaster\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike3DRaster import Spike3DRaster\n",
    "from pyphoplacecellanalysis.GUI.Qt.SpikeRasterWindows.Spike3DRasterWindowWidget import Spike3DRasterWindowWidget\n",
    "\n",
    "found_spike_raster_windows = TopLevelWindowHelper.all_widgets(pg.mkQApp(), searchType=Spike3DRasterWindowWidget)\n",
    "\n",
    "if len(found_spike_raster_windows) < 1:\n",
    "\t# no existing spike_raster_windows. Make a new one\n",
    "\tprint(f'no existing SpikeRasterWindow. Creating a new one.')\n",
    "\t# Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\n",
    "\tactive_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.plot._display_spike_rasters_pyqtplot_2D().values()\n",
    "\n",
    "else:\n",
    "\tprint(f'found {len(found_spike_raster_windows)} existing Spike3DRasterWindowWidget windows using TopLevelWindowHelper.all_widgets(...). Will use the most recent.')\n",
    "\t# assert len(found_spike_raster_windows) == 1, f\"found {len(found_spike_raster_windows)} Spike3DRasterWindowWidget windows using TopLevelWindowHelper.all_widgets(...) but require exactly one.\"\n",
    "\t# Get the most recent existing one and reuse that:\n",
    "\tspike_raster_window = found_spike_raster_windows[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bd5e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Spike3DRasterWindowWidget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0460c6e5",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "outputs": [],
   "source": [
    "# uses global's 'extended_stats' results for relative entropy (surprise) analyses:\n",
    "\n",
    "import tables as tb\n",
    "\n",
    "\n",
    "# {\n",
    "# 't': Tuple[float, float],\n",
    "# 'snapshots': Tuple[PlacefieldSnapshot, PlacefieldSnapshot],\n",
    "# 'relative_entropy_result_dict': {\n",
    "# \t\t'long_short_rel_entr_curve': np.array,\n",
    "# \t\t...\n",
    "# \t\t'jensen_shannon_distance': np.array,\n",
    "# \t} # 5 items\n",
    "# } # 3 items\n",
    "# Dict[float, PlacefieldSnapshot]\n",
    "\n",
    "def relative_entropy_to_h5(global_results, file_path='output/test_relative_entropy_numpy_arrays.h5'):\n",
    "\tprint(f'relative_entropy_to_h5(...)')\n",
    "\n",
    "\tactive_extended_stats = global_results['extended_stats']\n",
    "\tactive_relative_entropy_results = active_extended_stats['pf_dt_sequential_surprise'] # DynamicParameters\n",
    "\tpost_update_times: np.ndarray = active_relative_entropy_results['post_update_times'] # (4152,) = (n_post_update_times,)\n",
    "\tsnapshot_differences_result_dict = active_relative_entropy_results['snapshot_differences_result_dict']\n",
    "\ttime_intervals: np.ndarray = active_relative_entropy_results['time_intervals']\n",
    "\tlong_short_rel_entr_curves_frames: np.ndarray = active_relative_entropy_results['long_short_rel_entr_curves_frames'] # (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "\tshort_long_rel_entr_curves_frames: np.ndarray = active_relative_entropy_results['short_long_rel_entr_curves_frames'] # (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "\tflat_relative_entropy_results: np.ndarray = active_relative_entropy_results['flat_relative_entropy_results'] # (149, 63) - (nSnapshots, nXbins)\n",
    "\tflat_jensen_shannon_distance_results: np.ndarray = active_relative_entropy_results['flat_jensen_shannon_distance_results'] # (149, 63) - (nSnapshots, nXbins)\n",
    "\tflat_jensen_shannon_distance_across_all_positions: np.ndarray = np.sum(np.abs(flat_jensen_shannon_distance_results), axis=1) # sum across all position bins # (4152,) - (nSnapshots)\n",
    "\tflat_surprise_across_all_positions: np.ndarray = np.sum(np.abs(flat_relative_entropy_results), axis=1) # sum across all position bins # (4152,) - (nSnapshots)\n",
    "\t\n",
    "\t# Create an HDF5 file\n",
    "\twith tb.open_file(file_path, mode=\"w\") as hdf5_file:\n",
    "\t\tprint(f'trying to write to \"{file_path}\"...')\n",
    "\t\t# Create groups for organization\n",
    "\t\troot = hdf5_file.root\n",
    "\t\tgroup = hdf5_file.create_group(root, 'relative_entropy_results')\n",
    "\t\t\n",
    "\t\t# Store np.ndarrays in the HDF5 file\n",
    "\t\thdf5_file.create_array(group, 'post_update_times', post_update_times)\n",
    "\t\thdf5_file.create_array(group, 'time_intervals', time_intervals)\n",
    "\t\thdf5_file.create_array(group, 'long_short_rel_entr_curves_frames', long_short_rel_entr_curves_frames)\n",
    "\t\thdf5_file.create_array(group, 'short_long_rel_entr_curves_frames', short_long_rel_entr_curves_frames)\n",
    "\t\thdf5_file.create_array(group, 'flat_relative_entropy_results', flat_relative_entropy_results)\n",
    "\t\thdf5_file.create_array(group, 'flat_jensen_shannon_distance_results', flat_jensen_shannon_distance_results)\n",
    "\t\thdf5_file.create_array(group, 'flat_jensen_shannon_distance_across_all_positions', flat_jensen_shannon_distance_across_all_positions)\n",
    "\t\thdf5_file.create_array(group, 'flat_surprise_across_all_positions', flat_surprise_across_all_positions)\n",
    "\t\n",
    "\tprint(f'\\t done!')\n",
    "\t\n",
    "\n",
    "relative_entropy_to_h5(global_results, file_path='output/test_relative_entropy_numpy_arrays.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c6b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.export_pipeline_to_h5()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbf2641",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_differences_result_dict\n",
    "\n",
    "flat_jensen_shannon_distance_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06537c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_relative_entropy_results\n",
    "# type(active_relative_entropy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd2f58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_replay_stats_df: pd.DataFrame = jonathan_firing_rate_analysis_result.neuron_replay_stats_df\n",
    "neuron_replay_stats_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d613474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test classifying various x-positions as belonging to outside the outside_maze, the track_endcaps, or the track_body\n",
    "from enum import Enum\n",
    "\n",
    "class TrackPositionClassification(Enum):\n",
    "    OUTSIDE_MAZE = \"outside_maze\"\n",
    "    TRACK_ENDCAPS = \"track_endcaps\"\n",
    "    TRACK_BODY = \"track_body\"\n",
    "\n",
    "\n",
    "neuron_replay_stats_df: pd.DataFrame = jonathan_firing_rate_analysis_result.neuron_replay_stats_df\n",
    "short_pf_peak_x = neuron_replay_stats_df.short_pf_peak_x\n",
    "long_pf_peak_x = neuron_replay_stats_df.long_pf_peak_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8b2a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_remapping_df[np.isin(rate_remapping_df.index, significant_distant_remapping_endcap_aclus)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51571ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_spike_rate_groups_result: InstantaneousSpikeRateGroupsComputation = curr_active_pipeline.global_computation_results.computed_data.long_short_inst_spike_rate_groups\n",
    "# custom_InstSpikeRateTrends_df = inst_spike_rate_groups_result.all_incl_endPlatforms_InstSpikeRateTrends_df\n",
    "# if not hasattr(inst_spike_rate_groups_result, 'all_incl_endPlatforms_InstSpikeRateTrends_df'):\n",
    "# \tinst_spike_rate_groups_result.all_incl_endPlatforms_InstSpikeRateTrends_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628c789f",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# 2023-09-14 - Find cells outside the bounds of the short track\n",
    "# Modifies the `jonathan_firing_rate_analysis_result.neuron_replay_stats_df` in-place instead of creating a copy:\n",
    "# neuron_replay_stats_df = deepcopy(jonathan_firing_rate_analysis_result.neuron_replay_stats_df)\n",
    "neuron_replay_stats_df: pd.DataFrame = jonathan_firing_rate_analysis_result.neuron_replay_stats_df\n",
    "# Extract the peaks of the long placefields to find ones that have peaks outside the boundaries\n",
    "# long_pf_peaks = neuron_replay_stats_df[neuron_replay_stats_df['has_long_pf']]['long_pf_peak_x'] - 150.0 # this shift of 150.0 is to center the midpoint of the track at 0. \n",
    "# # display(long_pf_peaks)\n",
    "# is_left_cap = (long_pf_peaks < -72.0)\n",
    "# is_right_cap = (long_pf_peaks > 72.0)\n",
    "# is_either_cap =  np.logical_or(is_left_cap, is_right_cap)\n",
    "\n",
    "# # Adds ['is_long_peak_left_cap', 'is_long_peak_right_cap', 'is_long_peak_either_cap'] columns: \n",
    "# neuron_replay_stats_df['is_long_peak_left_cap'] = False\n",
    "# neuron_replay_stats_df['is_long_peak_right_cap'] = False\n",
    "# neuron_replay_stats_df.loc[is_left_cap.index, 'is_long_peak_left_cap'] = is_left_cap # True\n",
    "# neuron_replay_stats_df.loc[is_right_cap.index, 'is_long_peak_right_cap'] = is_right_cap # True\n",
    "# neuron_replay_stats_df['is_long_peak_either_cap'] = np.logical_or(neuron_replay_stats_df['is_long_peak_left_cap'], neuron_replay_stats_df['is_long_peak_right_cap'])\n",
    "# adds ['LS_pf_peak_x_diff'] column\n",
    "# neuron_replay_stats_df['LS_pf_peak_x_diff'] = neuron_replay_stats_df['long_pf_peak_x'] - neuron_replay_stats_df['short_pf_peak_x']\n",
    "neuron_replay_stats_df.is_long_peak_either_cap\n",
    "\n",
    "## Extract just the endcap cells:\n",
    "cap_cells_df = neuron_replay_stats_df[np.logical_and(neuron_replay_stats_df['has_long_pf'], neuron_replay_stats_df['is_long_peak_either_cap'])]\n",
    "cap_aclus = cap_cells_df.index\n",
    "num_total_endcap_cells = len(cap_aclus)\n",
    "display(num_total_endcap_cells)\n",
    "\n",
    "# \"Disppearing\" cells fall below the 1Hz firing criteria on the short track:\n",
    "disappearing_endcap_cells_df = cap_cells_df[np.logical_not(cap_cells_df['has_short_pf'])]\n",
    "disappearing_endcap_aclus = disappearing_endcap_cells_df.index\n",
    "num_disappearing_endcap_cells = len(disappearing_endcap_aclus)\n",
    "print(f'num_disappearing_endcap_cells/num_total_endcap_cells: {num_disappearing_endcap_cells}/{num_total_endcap_cells}')\n",
    "\n",
    "non_disappearing_endcap_cells_df = cap_cells_df[cap_cells_df['has_short_pf']] # \"non_disappearing\" cells are those with a placefield on the short track as well\n",
    "num_non_disappearing_endcap_cells = len(non_disappearing_endcap_cells_df)\n",
    "print(f'num_non_disappearing_endcap_cells/num_total_endcap_cells: {num_non_disappearing_endcap_cells}/{num_total_endcap_cells}')\n",
    "\n",
    "# display(non_disappearing_endcap_cells_df)\n",
    "# non_disappearing_endcap_cells_df['LS_pf_peak_x_diff'] = non_disappearing_endcap_cells_df['long_pf_peak_x'] - non_disappearing_endcap_cells_df['short_pf_peak_x']\n",
    "# display(non_disappearing_endcap_cells_df)\n",
    "\n",
    "# Classify the non_disappearing cells into two groups:\n",
    "# 1. Those that exhibit significant remapping onto somewhere else on the track\n",
    "non_disappearing_endcap_cells_df['has_significant_distance_remapping'] = (np.abs(non_disappearing_endcap_cells_df['LS_pf_peak_x_diff']) >= 40.0) # The most a placefield could translate intwards would be (35 + (pf_width/2.0)) I think.\n",
    "num_significant_position_remappping_endcap_cells = len(non_disappearing_endcap_cells_df[non_disappearing_endcap_cells_df['has_significant_distance_remapping'] == True])\n",
    "print(f'num_significant_position_remappping_endcap_cells/num_non_disappearing_endcap_cells: {num_significant_position_remappping_endcap_cells}/{num_non_disappearing_endcap_cells}')\n",
    "\n",
    "# 2. Those that seem to remain where they were on the long track, perhaps being \"sampling-clipped\" or translated adjacent to the platform. These two subcases can be distinguished by a change in the placefield's length (truncated cells would be a fraction of the length, although might need to account for scaling with new track length)\n",
    "minorly_changed_endcap_cells_df = non_disappearing_endcap_cells_df[non_disappearing_endcap_cells_df['has_significant_distance_remapping'] == False]\n",
    "\n",
    "non_disappearing_endcap_cells_df\n",
    "# endcaps:\n",
    "significant_distant_remapping_endcap_aclus = non_disappearing_endcap_cells_df[non_disappearing_endcap_cells_df['has_significant_distance_remapping']].index.to_numpy() # Int64Index([3, 5, 7, 11, 14, 38, 41, 53, 57, 61, 62, 75, 78, 79, 82, 83, 85, 95, 98, 100, 102], dtype='int64')\n",
    "significant_distant_remapping_endcap_aclus\n",
    "minor_remapping_endcap_aclus = minorly_changed_endcap_cells_df.index.to_numpy()\n",
    "minor_remapping_endcap_aclus\n",
    "jonathan_firing_rate_analysis_result.neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568e1351",
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_distant_remapping_endcap_df = jonathan_firing_rate_analysis_result.neuron_replay_stats_df[np.isin(jonathan_firing_rate_analysis_result.neuron_replay_stats_df.index, significant_distant_remapping_endcap_aclus)]\n",
    "significant_distant_remapping_endcap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8f1fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will these remapped cells be included in replays after the delta?\n",
    "num_short_replays = non_disappearing_endcap_cells_df['short_num_replays']\n",
    "short_replay_mean_fr_Hz = non_disappearing_endcap_cells_df['replay_diff']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcb50e6",
   "metadata": {},
   "source": [
    "## 2023-09-20 - Plot the significantly remapping cells using the lower-level `plot_short_v_long_pf1D_comparison` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebc2de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import plot_short_v_long_pf1D_comparison\n",
    "from neuropy.utils.matplotlib_helpers import perform_update_title_subtitle\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import add_vertical_track_bounds_lines, add_track_shapes\n",
    "from neuropy.plotting.ratemaps import plot_ratemap_1D\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import LongShortDisplayConfigManager\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "graphics_output_dict = {}\n",
    "active_context: IdentifyingContext = curr_active_pipeline.get_session_context()\n",
    "\n",
    "long_short_display_config_manager = LongShortDisplayConfigManager()\n",
    "long_epoch_config = long_short_display_config_manager.long_epoch_config.as_pyqtgraph_kwargs()\n",
    "short_epoch_config = long_short_display_config_manager.short_epoch_config.as_pyqtgraph_kwargs()\n",
    "\n",
    "long_epoch_matplotlib_config = long_short_display_config_manager.long_epoch_config.as_matplotlib_kwargs()\n",
    "short_epoch_matplotlib_config = long_short_display_config_manager.short_epoch_config.as_matplotlib_kwargs()\n",
    "\n",
    "shared_kwargs = dict(pad=1, cmap='hsv', active_context=curr_active_pipeline.get_session_context(), plot_zero_baselines=True, skip_figure_titles=True, use_flexitext_titles=True, flat_stack_mode=False)\n",
    "top_level_shared_kwargs = dict(should_plot_vertical_track_bounds_lines=True, sortby='peak_long')\n",
    "# top_level_shared_kwargs = dict(should_plot_vertical_track_bounds_lines=False, should_plot_linear_track_shapes=True) # Renders the linear track shape on the maze. Assumes `flat_stack_mode=True`\n",
    "\n",
    "\n",
    "# # flat_stack_mode: all placefields are stacked up (z-wise) on top of each other on a single axis with no offsets:\n",
    "# shared_kwargs = dict(pad=1, active_context=curr_active_pipeline.get_session_context(), plot_zero_baselines=True, skip_figure_titles=True, use_flexitext_titles=True, flat_stack_mode=True)\n",
    "# top_level_shared_kwargs = dict(should_plot_vertical_track_bounds_lines=False, should_plot_linear_track_shapes=True) # Renders the linear track shape on the maze. Assumes `flat_stack_mode=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec159e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2023-09-21 - Plot All\n",
    "graphics_output_dict = graphics_output_dict | fig_remapping_cells(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfab342",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.suptitle('Translation Remapping Cells')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d9a3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_surprise_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d02c8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long_results = curr_active_pipeline.computation_results['maze1_PYR'].computed_data\n",
    "# short_results = curr_active_pipeline.computation_results['maze2_PYR'].computed_data\n",
    "# curr_any_context_neurons = _find_any_context_neurons(*[curr_active_pipeline.computation_results[k].computed_data.pf1D.ratemap.neuron_ids for k in ['maze1_PYR', 'maze2_PYR']])\n",
    "# (fig_long_pf_1D, ax_long_pf_1D, long_sort_ind, long_neurons_colors_array), (fig_short_pf_1D, ax_short_pf_1D, short_sort_ind, short_neurons_colors_array) = plot_short_v_long_pf1D_comparison(long_results, short_results, disappearing_endcap_aclus, reuse_axs_tuple=None, single_figure=True, shared_kwargs=shared_kwargs, title_string=\"Disappearing Cells\", subtitle_string=None, **top_level_shared_kwargs)\n",
    "graphics_output_dict['disappearing_endcap_aclus'] = curr_active_pipeline.display('_display_short_long_pf1D_comparison', curr_active_pipeline.get_session_context(), included_any_context_neuron_ids=disappearing_endcap_aclus, reuse_axs_tuple=None, single_figure=True, shared_kwargs=shared_kwargs, title_string=\"Disappearing Cells\", subtitle_string=None, **top_level_shared_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3500f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (fig_long_pf_1D, ax_long_pf_1D, long_sort_ind, long_neurons_colors_array), (fig_short_pf_1D, ax_short_pf_1D, short_sort_ind, short_neurons_colors_array) = plot_short_v_long_pf1D_comparison(long_results, short_results, significant_distant_remapping_endcap_aclus, reuse_axs_tuple=None, single_figure=True, shared_kwargs=shared_kwargs, title_string=\"Significant Distance Remapping Cells\", subtitle_string=\"1D Placefields\", **top_level_shared_kwargs)\n",
    "graphics_output_dict['significant_distant_remapping_endcap_aclus'] = curr_active_pipeline.display('_display_short_long_pf1D_comparison', curr_active_pipeline.get_session_context(), included_any_context_neuron_ids=significant_distant_remapping_endcap_aclus, reuse_axs_tuple=None, single_figure=True, shared_kwargs=shared_kwargs, title_string=\"Significant Distance Remapping Cells\", subtitle_string=\"1D Placefields\", **top_level_shared_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c7f4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (fig_long_pf_1D, ax_long_pf_1D, long_sort_ind, long_neurons_colors_array), (fig_short_pf_1D, ax_short_pf_1D, short_sort_ind, short_neurons_colors_array) = plot_short_v_long_pf1D_comparison(long_results, short_results, trivially_remapping_endcap_aclus, reuse_axs_tuple=None, single_figure=True, shared_kwargs=shared_kwargs, title_string=\"Trivially Remapping Cells\", subtitle_string=\"1D Placefields\", **top_level_shared_kwargs)\n",
    "graphics_output_dict['trivially_remapping_endcap_aclus'] = curr_active_pipeline.display('_display_short_long_pf1D_comparison', curr_active_pipeline.get_session_context(), included_any_context_neuron_ids=trivially_remapping_endcap_aclus, reuse_axs_tuple=None, single_figure=True, shared_kwargs=shared_kwargs, title_string=\"Trivially Remapping Cells\", subtitle_string=\"1D Placefields\", **top_level_shared_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744564fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2023-09-18 - Shows the cells that exhibit simple remapping after delta\n",
    "graphics_output_dict = curr_active_pipeline.display('_display_short_long_pf1D_comparison', curr_active_pipeline.get_session_context(), included_any_context_neuron_ids=None, reuse_axs_tuple=None, single_figure=True, shared_kwargs=shared_kwargs, **top_level_shared_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e11c5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import fig_example_nontopo_remap\n",
    "\n",
    "graphics_output_dict = fig_example_nontopo_remap(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be59d32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771e3b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.export_pipeline_to_h5('output/2023_09_26_new_pipeline_test.h5')\n",
    "# ERROR: encountered exception !! 'InstantaneousSpikeRateGroupsComputation' object has no attribute 'all_incl_endPlatforms_InstSpikeRateTrends_df' ::::: (<class 'AttributeError'>, AttributeError(\"'InstantaneousSpikeRateGroupsComputation' object has no attribute 'all_incl_endPlatforms_InstSpikeRateTrends_df'\"), <traceback object at 0x000001E5A3D3D040>) while trying to build the session HDF output.\n",
    "# AttributeError: 'SpikeRateTrends' object has no attribute 'included_neuron_ids'\n",
    "# _neuron_replay_stats_df - TypeError: Cannot serialize the column [track_membership] because its data contents are not [string] but [mixed] object dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aa0ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255ef3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "\n",
    "graphics_output_dict = curr_active_pipeline.display('_display_short_long_pf1D_scalar_overlap_comparison', active_identifying_session_ctx, save_figure=False)\n",
    "# fig, axs, plot_data = graphics_output_dict['fig'], graphics_output_dict['axs'], graphics_output_dict['plot_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e146d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ca625b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _display_long_short_expected_v_observed_firing_rate\n",
    "graphics_output_dict = curr_active_pipeline.display('_display_long_short_expected_v_observed_firing_rate', curr_active_pipeline.sess.get_context(), included_neuron_IDs=significant_distant_remapping_endcap_aclus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6bc6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_temp_force_recompute=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33d838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recompute 'long_short_fr_indicies_analyses'\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_extended_computations\n",
    "\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "\n",
    "# _temp_force_recompute=True\n",
    "_temp_force_recompute=False\n",
    "# extended_computations_include_includelist = ['_perform_time_dependent_placefield_computation', 'long_short_fr_indicies_analyses', 'pf_dt_sequential_surprise', 'short_long_pf_overlap_analyses'] # do only specifiedl\n",
    "extended_computations_include_includelist = ['jonathan_firing_rate_analysis', 'short_long_pf_overlap_analyses']\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True, force_recompute=_temp_force_recompute, debug_print=False)\n",
    "newly_computed_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed12881",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.rdf.rdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab18fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.irdf.irdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a269239",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ad2b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2ce6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_long_short_fr_indicies_analysis_bak = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "\n",
    "curr_long_short_fr_indicies_analysis = curr_active_pipeline.global_computation_results.computed_data.pop('long_short_fr_indicies_analysis')\n",
    "\n",
    "print(list(curr_long_short_fr_indicies_analysis.keys())) # ['long_laps', 'long_replays', 'short_laps', 'short_replays', 'global_laps', 'global_replays', 'long_non_replays', 'short_non_replays', 'global_non_replays', 'long_mean_non_replays_frs', 'short_mean_non_replays_frs', 'long_mean_non_replays_all_frs', 'short_mean_non_replays_all_frs', 'non_replays_frs_index', 'long_mean_non_replays_all_inst_frs', 'short_mean_non_replays_all_inst_frs', 'non_replays_inst_frs_index', 'active_context']\n",
    "\n",
    "print_keys_if_possible('curr_long_short_fr_indicies_analysis', curr_long_short_fr_indicies_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6411650",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a621ba9",
   "metadata": {},
   "source": [
    "# 2023-09-12 - Assemble all neuron-level properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6554ac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import build_merged_neuron_firing_rate_indicies\n",
    "\n",
    "joined_neruon_fri_df = build_merged_neuron_firing_rate_indicies(curr_active_pipeline, enable_display_intermediate_results=False)\n",
    "joined_neruon_fri_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963c78c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(joined_neruon_fri_df.columns)) # ['aclu', 'lsfria_laps_frs_index', 'lsfria_laps_inst_frs_index', 'lsfria_replays_frs_index', 'lsfria_replays_inst_frs_index', 'lsfria_non_replays_frs_index', 'lsfria_non_replays_inst_frs_index', 'jfra_long_pf_peak_x', 'jfra_has_long_pf', 'jfra_short_pf_peak_x', 'jfra_has_short_pf', 'jfra_has_na', 'jfra_track_membership', 'jfra_long_non_replay_mean', 'jfra_short_non_replay_mean', 'jfra_non_replay_diff', 'jfra_long_replay_mean', 'jfra_short_replay_mean', 'jfra_replay_diff', 'jfra_long_mean', 'jfra_short_mean', 'jfra_mean_diff', 'jfra_neuron_IDX', 'jfra_num_replays', 'jfra_long_num_replays', 'jfra_short_num_replays', 'jfra_neuron_type', 'lspd_laps', 'lspd_replays', 'lspd_skew', 'lspd_max_axis_distance_from_center', 'lspd_distance_from_center', 'lspd_has_considerable_remapping']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bd0afa",
   "metadata": {},
   "source": [
    "# Computing cosolidated `long_short_fr_indicies_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be486bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'long_short_fr_indicies_analysis'\n",
    "curr_long_short_fr_indicies_analysis = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "_curr_aclus = list(curr_long_short_fr_indicies_analysis['laps_frs_index'].keys()) # extract one set of keys for the aclus\n",
    "_curr_frs_indicies_dict = {k:v.values() for k,v in curr_long_short_fr_indicies_analysis.items() if k in ['laps_frs_index', 'laps_inst_frs_index', 'replays_frs_index', 'replays_inst_frs_index', 'non_replays_frs_index', 'non_replays_inst_frs_index']} # extract the values\n",
    "long_short_fr_indicies_df = pd.DataFrame(_curr_frs_indicies_dict, index=_curr_aclus)\n",
    "long_short_fr_indicies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62734a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ax = long_short_fr_indicies_df.plot.scatter(x='non_replays_inst_frs_index' , y='replays_inst_frs_index', title='Replays v. Non-replay Firing Rate Index Comparison')\n",
    "# long_short_fr_indicies_df.plot.scatter(x='laps_inst_frs_index' , y='replays_inst_frs_index', title='Replays v. Laps Firing Rate Index Comparison', ax=ax)\n",
    "\n",
    "ax = long_short_fr_indicies_df.plot.scatter(x='non_replays_frs_index' , y='replays_frs_index', title='Replays v. Non-replay Firing Rate Index Comparison')\n",
    "long_short_fr_indicies_df.plot.scatter(x='laps_frs_index' , y='replays_frs_index', title='Replays v. Laps Firing Rate Index Comparison', ax=ax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8f1e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "# scatter_matrix(long_short_fr_indicies_df, figsize=(10, 10))\n",
    "scatter_matrix(joined_neruon_fri_df, figsize=(10, 10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07a9146",
   "metadata": {},
   "source": [
    "## Plots the RateRemappingFiringRateIndex Number Line Figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8a42fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Extract rr_* variables from rate_remapping_df\n",
    "# rr_aclus = rate_remapping_df.index.values\n",
    "# rr_laps, rr_replays, rr_skew, rr_neuron_type = [rate_remapping_df[n].values for n in ['laps', 'replays', 'skew', 'neuron_type']]\n",
    "\n",
    "\n",
    "## Extract rr_* variables from joined_neruon_fri_df\n",
    "rr_aclus = joined_neruon_fri_df.index.values\n",
    "rr_laps, rr_replays, rr_skew, rr_neuron_type = [joined_neruon_fri_df[n].values for n in ['lspd_laps', 'lspd_replays', 'lspd_skew', 'jfra_neuron_type']]\n",
    "\n",
    "## Display:\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import plot_rr_aclu\n",
    "n_debug_limit = 10\n",
    "fig, axs, sort_indicies = plot_rr_aclu([str(aclu) for aclu in rr_aclus[:n_debug_limit]], rr_laps=rr_laps[:n_debug_limit], rr_replays=rr_replays[:n_debug_limit], rr_neuron_types=rr_neuron_type[:n_debug_limit])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad336e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fri_index_dicts_list = [dict(x=rr_laps, marker=r'$\\theta$', markersize=10, color='black', label='rr_laps'),\n",
    "\tdict(x=rr_replays, marker='o', markersize=10, fillstyle='none', color='black', label='rr_replays'),\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc67e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Display Paginated multi-plot\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import plot_rr_aclu\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import RateRemappingPaginatedFigureController\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context()\n",
    "_out_rr_pagination_controller = RateRemappingPaginatedFigureController.init_from_rr_data(rr_aclus, rr_laps, rr_replays, rr_neuron_type, max_subplots_per_page=30, a_name='TestRateRemappingPaginatedFigureController', active_context=active_identifying_session_ctx)\n",
    "a_paginator = _out_rr_pagination_controller.plots_data.paginator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3cdf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Determine the included percentiles for `joined_neruon_fri_df`\n",
    "\n",
    "\n",
    "# Calculate 10th and 90th percentiles\n",
    "lower_bound = custom_InstSpikeRateTrends_df['custom_frs_index'].quantile(0.10)\n",
    "upper_bound = custom_InstSpikeRateTrends_df['custom_frs_index'].quantile(0.90)\n",
    "\n",
    "# Filter rows\n",
    "bottom_10_percent = custom_InstSpikeRateTrends_df[custom_InstSpikeRateTrends_df['custom_frs_index'] <= lower_bound]\n",
    "top_10_percent = custom_InstSpikeRateTrends_df[custom_InstSpikeRateTrends_df['custom_frs_index'] >= upper_bound]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f368c7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_InstSpikeRateTrends_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ea9e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f5724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_10_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb42f660",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_frs_index = {aclu:_fr_index(long_mean_laps_frs[aclu], short_mean_laps_frs[aclu]) for aclu in long_mean_laps_frs.keys()}\n",
    "x_frs_index = {aclu:_fr_index(long_mean_replays_frs[aclu], short_mean_replays_frs[aclu]) for aclu in long_mean_replays_frs.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149efb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.export_pipeline_to_h5()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51090828",
   "metadata": {},
   "source": [
    "# 2023-09-18 - Computation Validators and Computations as Needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f456395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.gui.Qt.TopLevelWindowHelper import TopLevelWindowHelper, print_widget_hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cbe228",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = pg.mkQApp()\n",
    "app\n",
    "app.topLevelWindows()\n",
    "\n",
    "top_level_windows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79502585",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_level_windows = TopLevelWindowHelper.top_level_windows(app, only_visible=True)\n",
    "top_level_windows # IndexedOrderedDict([('DockClassWindow', <PyQt5.QtGui.QWindow object at 0x000001F7383E9670>), ('qt_splithandle_Window', <PyQt5.QtGui.QWindow object at 0x000001F7383E9280>), ('PhoDockAreaContainingWindowClassWindow', <PyQt5.QtGui.QWindow object at 0x000001F7383E9550>), ('DockAreaClassWindow', <PyQt5.QtGui.QWindow object at 0x000001F7383E98B0>), ('VContainerClassWindow', <PyQt5.QtGui.QWindow object at 0x000001F7383E9430>), ('DockLabelClassWindow', <PyQt5.QtGui.QWindow object at 0x000001F7383D8AF0>), ('QWidgetClassWindow', <PyQt5.QtGui.QWindow object at 0x000001F7370CD280>), ('MainWindowClassWindow', <PyQt5.QtGui.QWindow object at 0x000001F7370CD160>), ('QFrameClassWindow', <PyQt5.QtGui.QWindow object at 0x000001F7370CD1F0>)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68e8968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Phodockareacontainingwindowclasswindow'\n",
    "\n",
    "for a_win_key, a_win in top_level_windows.items():\n",
    "\tprint(f'{a_win}')\n",
    "\t# print(f'\\t{a_win.title()}')\n",
    "\t# print(f'\\t{type(a_win)}')\n",
    "\tprint_widget_hierarchy(a_win, indent='\\t\\t')\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c90a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "searchType = 'PhoDockAreaContainingWindowClassWindow'\n",
    "top_level_windows_with_superclass_list = [a_widget for a_widget in top_level_windows if isinstance(a_widget, (searchType))]\n",
    "top_level_windows_with_superclass_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa48905",
   "metadata": {},
   "outputs": [],
   "source": [
    "'PhoDockAreaContainingWindowClassWindow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d4904a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e518d238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_extended_computations\n",
    "\n",
    "curr_active_pipeline.reload_default_computation_functions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438fc995",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "extended_computations_include_includelist = ['pf_computation', 'pfdt_computation', 'long_short_fr_indicies_analyses', 'jonathan_firing_rate_analysis', 'long_short_decoding_analyses', 'long_short_post_decoding', \n",
    "    '_perform_time_dependent_pf_sequential_surprise_computation',\n",
    "     'long_short_rate_remapping',\n",
    "     'long_short_inst_spike_rate_groups'\n",
    "    ] # do only specifiedl , 'long_short_rate_remapping'\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True, force_recompute=False, debug_print=False)\n",
    "newly_computed_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bdf999",
   "metadata": {},
   "outputs": [],
   "source": [
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=['_perform_pf_find_ratemap_peaks_peak_prominence2d_computation'], included_computation_filter_names=['maze1', 'maze2', 'maze'], include_global_functions=True, fail_on_exception=True, progress_print=True, force_recompute=False, debug_print=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5f0719",
   "metadata": {},
   "outputs": [],
   "source": [
    "'_perform_long_short_endcap_analysis'\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=['_perform_long_short_endcap_analysis'], include_global_functions=True, fail_on_exception=True, progress_print=True, force_recompute=False, debug_print=False)\n",
    "newly_computed_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf82a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.updated_since_last_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecb5d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0850fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "newly_computed_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68abe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "newly_computed_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec21cd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_remapping_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c131a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_remapping_df[['laps',\t'replays',\t'skew',\t'max_axis_distance_from_center', 'distance_from_center', 'has_considerable_remapping']] # drops ['neuron_type', 'render_color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce01cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.HDF5_representable import HDF_Converter\n",
    "\n",
    "file_path = 'output/test_rate_remapping_new.h5'\n",
    "\n",
    "session_context = curr_active_pipeline.get_session_context() \n",
    "session_group_key: str = \"/\" + session_context.get_description(separator=\"/\", include_property_names=False) # 'kdiba/gor01/one/2006-6-08_14-26-15'\n",
    "session_uid: str = session_context.get_description(separator=\"|\", include_property_names=False)\n",
    "## Global Computations\n",
    "a_global_computations_group_key: str = f\"{session_group_key}/global_computations\"\n",
    "with tb.open_file(file_path, mode='w') as f:\n",
    "    a_global_computations_group = f.create_group(session_group_key, 'global_computations', title='the result of computations that operate over many or all of the filters in the session.', createparents=True)\n",
    "\n",
    "\n",
    "# rate_remapping_df\n",
    "# rate_remapping_df = rate_remapping_df[['laps',\t'replays',\t'skew',\t'max_axis_distance_from_center',\t'distance_from_center', \t'has_considerable_remapping']]\n",
    "# # active_context = kwargs.pop('active_context', None) # TODO: requiring that the caller pass active_context isn't optimal\n",
    "# active_context = session_context\n",
    "# rate_remapping_df = HDF_Converter.prepare_neuron_indexed_dataframe_for_hdf(rate_remapping_df, active_context=active_context, aclu_column_name=None)\n",
    "# # rate_remapping_df.to_hdf(file_path, key=f'{key}/rate_remapping_df', format='table', data_columns=True)\n",
    "curr_long_short_rr.to_hdf(file_path, key=f'{a_global_computations_group_key}/rate_remapping', active_context=curr_active_pipeline.get_session_context())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e0b2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.global_computation_results_pickle_path\n",
    "# curr_active_pipeline.pickle_path\n",
    "curr_active_pipeline.get_output_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468420ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "outman = curr_active_pipeline.get_output_manager()\n",
    "figure_output_path = outman.get_figure_save_file_path(curr_active_pipeline.get_session_context(), make_folder_if_needed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9642b886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.placefield import plot_1d_placecell_validations\n",
    "\n",
    "# curr_active_pipeline.plotting_config\n",
    "active_session_configuration_name = global_epoch_name\n",
    "active_config = curr_active_pipeline.active_configs[active_session_configuration_name]\n",
    "\n",
    "_out = plot_1d_placecell_validations(global_pf1D, active_config.plotting_config, modifier_string='lap_only', should_save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3086b2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.to_hdf('output/test_pipeline_fixed.h5', key='/')\n",
    "# TypeError: objects of type ``list`` are not supported in this context, sorry; supported objects are: NumPy array, record or scalar\n",
    "# for flattened_spike\n",
    "# .infer_objects()\n",
    "\n",
    "# curr_active_pipeline.export_pipeline_to_h5()\n",
    "# self.to_hdf(file_path=hdf5_output_path, key=\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f55395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.session.dataSession import DataSession\n",
    "\n",
    "## Test saaving sessions\n",
    "sess: DataSession = deepcopy(curr_active_pipeline.sess)\n",
    "sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fa4d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.to_hdf('output/test_sess.h5', key='/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64c4d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.laps\n",
    "# sess.ripples\n",
    "sess.pbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a777624",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb693c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent, PlacefieldSnapshot\n",
    "\n",
    "global_pf1D_dt: PfND_TimeDependent = global_results.pf1D_dt\n",
    "global_pf2D_dt: PfND_TimeDependent = global_results.pf2D_dt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c7b9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.TimeSynchronizedOccupancyPlotter import TimeSynchronizedOccupancyPlotter\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.TimeSynchronizedPlacefieldsPlotter import TimeSynchronizedPlacefieldsPlotter\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.Mixins.helpers import build_combined_time_synchronized_plotters_window\n",
    "\n",
    "active_pf_2D_dt = global_pf2D_dt\n",
    "active_pf_2D_dt.reset()\n",
    "active_pf_2D_dt.update(t=500.0, start_relative_t=True)\n",
    "all_plotters, root_dockAreaWindow, app = build_combined_time_synchronized_plotters_window(active_pf_2D_dt, fixed_window_duration = 15.0)\n",
    "controlling_widget, curr_sync_occupancy_plotter, curr_placefields_plotter = all_plotters # end up in some sort of `linkedViewChanged` loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca360a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "controlling_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab329525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\n",
    "_out = curr_active_pipeline.plot._display_spike_rasters_pyqtplot_2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a39b41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.gui.Qt.TopLevelWindowHelper import TopLevelWindowHelper\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg # Used to get the app for TopLevelWindowHelper.top_level_windows\n",
    "## For searching with `TopLevelWindowHelper.all_widgets(...)`:\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import Spike2DRaster\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike3DRaster import Spike3DRaster\n",
    "from pyphoplacecellanalysis.GUI.Qt.SpikeRasterWindows.Spike3DRasterWindowWidget import Spike3DRasterWindowWidget\n",
    "\n",
    "found_spike_raster_windows = TopLevelWindowHelper.all_widgets(pg.mkQApp(), searchType=Spike3DRasterWindowWidget)\n",
    "# assert len(found_spike_raster_windows) == 1, f\"found {len(found_spike_raster_windows)} Spike3DRasterWindowWidget windows using TopLevelWindowHelper.all_widgets(...) but require exactly one.\"\n",
    "if len(found_spike_raster_windows) > 1:\n",
    "\tprint(f'found {len(found_spike_raster_windows)} widgets with the searchType provided:')\n",
    "\tprint(f'{found_spike_raster_windows}')\n",
    "\tprint(f'defaulting to using the most recent [-1]...')\n",
    "spike_raster_window = found_spike_raster_windows[-1]\n",
    "\n",
    "# Extras:\n",
    "active_2d_plot = spike_raster_window.spike_raster_plt_2d # <pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster.Spike2DRaster at 0x196c7244280>\n",
    "active_3d_plot = spike_raster_window.spike_raster_plt_3d # <pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster.Spike2DRaster at 0x196c7244280>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aec9ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.SpikesRenderingBaseMixin import SpikeEmphasisState\n",
    "\n",
    "active_pf_2D = global_pf2D\n",
    "## Example 1: De-emphasize spikes excluded from the placefield calculations:\n",
    "is_spike_included_in_pf = np.isin(spike_raster_window.spike_raster_plt_2d.spikes_df.index, active_pf_2D.filtered_spikes_df.index)\n",
    "spike_raster_window.spike_raster_plt_2d.update_spike_emphasis(np.logical_not(is_spike_included_in_pf), SpikeEmphasisState.Deemphasized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63d9412",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_spike_included_in_pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c8a447",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_pf_2D_dt.update(t=1000.0, start_relative_t=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2cdc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "curr_sync_occupancy_plotter = TimeSynchronizedOccupancyPlotter(global_pf2D_dt)\n",
    "curr_sync_occupancy_plotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45af89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_pf2D_dt.historical_snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ddb46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_pf2D_dt.batch_snapshotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01b157c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_sync_placefield_plotter = TimeSynchronizedPlacefieldsPlotter(active_time_dependent_placefields2D)\n",
    "curr_sync_placefield_plotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e90ffe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure pickling is okay with pf1D_dt\n",
    "global_pf1D_dt.to_hdf('output/test_global_pf1D_dt.h5', key='global_pf1D_dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4d25bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "override_pickle_path: Path = Path('output/test_pipeline.pkl').resolve()\n",
    "override_pickle_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21766da",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_extended_stats = curr_active_pipeline.computation_results['maze'].computed_data['extended_stats']\n",
    "active_extended_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fce55d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_relative_entropy_results = active_extended_stats['relative_entropy_analyses']\n",
    "post_update_times = active_relative_entropy_results['post_update_times']\n",
    "snapshot_differences_result_dict = active_relative_entropy_results['snapshot_differences_result_dict']\n",
    "time_intervals = active_relative_entropy_results['time_intervals']\n",
    "long_short_rel_entr_curves_frames = active_relative_entropy_results['long_short_rel_entr_curves_frames']\n",
    "short_long_rel_entr_curves_frames = active_relative_entropy_results['short_long_rel_entr_curves_frames']\n",
    "flat_relative_entropy_results = active_relative_entropy_results['flat_relative_entropy_results']\n",
    "flat_jensen_shannon_distance_results = active_relative_entropy_results['flat_jensen_shannon_distance_results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcce2c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(active_relative_entropy_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e84671f",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_pf1D_dt.plot_ratemaps_1D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0811563b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute with the new computation config:\n",
    "computation_functions_name_includelist=['_perform_baseline_placefield_computation', '_perform_time_dependent_placefield_computation', '_perform_extended_statistics_computation',\n",
    "\t\t\t\t\t\t\t\t\t'_perform_position_decoding_computation', \n",
    "\t\t\t\t\t\t\t\t\t'_perform_firing_rate_trends_computation',\n",
    "\t\t\t\t\t\t\t\t\t'_perform_pf_find_ratemap_peaks_computation',\n",
    "\t\t\t\t\t\t\t\t\t'_perform_time_dependent_pf_sequential_surprise_computation'\n",
    "\t\t\t\t\t\t\t\t\t'_perform_two_step_position_decoding_computation',\n",
    "\t\t\t\t\t\t\t\t\t# '_perform_recursive_latent_placefield_decoding'\n",
    "\t\t\t\t\t\t\t\t]  # '_perform_pf_find_ratemap_peaks_peak_prominence2d_computation'\n",
    "\n",
    "# computation_functions_name_includelist=['_perform_baseline_placefield_computation']\n",
    "curr_active_pipeline.perform_computations(computation_functions_name_includelist=computation_functions_name_includelist, computation_functions_name_excludelist=None, fail_on_exception=True, debug_print=False, overwrite_extant_results=True) #, overwrite_extant_results=False  ], fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bb2250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global_pf1D.included_neuron_IDs\n",
    "included_neuron_IDs = list(long_pf1D.included_neuron_IDs[0])\n",
    "print(included_neuron_IDs)\n",
    "included_neuron_IDs.index(4)\n",
    "long_pf1D.long\n",
    "# long_pf1D.included_neuron_IDs[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9cf70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_pf1D.neuron_extended_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fd7967",
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuronExtendedIdentityTuple(shank=10, cluster=10, id=87),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d527d34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(long_pf1D.included_neuron_IDs).index(87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c794035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_pf1D.plot_all(87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2842b293",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_pf1D.plotRaw_v_time(87)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc03468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display('_display_batch_pho_jonathan_replay_firing_rate_comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a98c74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "PAPER_FIGURE_figure_3(curr_active_pipeline, defer_render=False, save_figure=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaef94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import SplitPartitionMembership\n",
    "from neuropy.core.neurons import NeuronType\n",
    "from neuropy.utils.mixins.HDF5_representable import HDF_Converter\n",
    "\n",
    "# Generate the unique aclus\n",
    "_neuron_replay_stats_df = deepcopy(jonathan_firing_rate_analysis_result.neuron_replay_stats_df)\n",
    "_neuron_replay_stats_df\n",
    "\n",
    "# _neuron_replay_stats_df = prepare_neuron_indexed_dataframe_for_hdf(_neuron_replay_stats_df, active_context=curr_active_pipeline.get_session_context(), aclu_column_name=None)\n",
    "\n",
    "\n",
    "_neuron_replay_stats_df = HDF_Converter.prepare_neuron_indexed_dataframe_for_hdf(_neuron_replay_stats_df, active_context=curr_active_pipeline.get_session_context(), aclu_column_name=None)\n",
    "\n",
    "\n",
    "\n",
    "# active_context = curr_active_pipeline.get_session_context()\n",
    "# sess_specific_aclus = list(_neuron_replay_stats_df.index.to_numpy())\n",
    "# session_ctxt_key:str = active_context.get_description(separator='|', subset_includelist=IdentifyingContext._get_session_context_keys())\n",
    "\n",
    "# # Adds column columns=['neuron_uid', 'session_uid', 'aclu']\n",
    "# _neuron_replay_stats_df['aclu'] = sess_specific_aclus # _neuron_replay_stats_df.index.to_numpy() # add explicit 'aclu' column from index\n",
    "# _neuron_replay_stats_df['session_uid'] = session_ctxt_key # add fixed 'session_uid' column \n",
    "# _neuron_replay_stats_df['neuron_uid'] = [f\"{session_ctxt_key}|{aclu}\" for aclu in sess_specific_aclus]\n",
    "_neuron_replay_stats_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a96980c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3725c6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# _out = curr_active_pipeline.last_added_display_output\n",
    "# Showing\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "_out = curr_active_pipeline.display('_display_long_short_expected_v_observed_firing_rate', max_num_rows=10)\n",
    "# a_fig = _out.figures[0]\n",
    "# a_fig.show()\n",
    "# .show()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bee8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_v_observed_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff1bc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_remapping_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfc81e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use the `long_short_decoding_analyses` global result to access `long_results_obj.active_filter_epochs`:\n",
    "curr_long_short_decoding_analyses = curr_active_pipeline.global_computation_results.computed_data['long_short_leave_one_out_decoding_analysis']\n",
    "long_one_step_decoder_1D, short_one_step_decoder_1D, long_replays, short_replays, global_replays, long_shared_aclus_only_decoder, short_shared_aclus_only_decoder, shared_aclus, long_short_pf_neurons_diff, n_neurons, long_results_obj, short_results_obj, is_global = curr_long_short_decoding_analyses.long_decoder, curr_long_short_decoding_analyses.short_decoder, curr_long_short_decoding_analyses.long_replays, curr_long_short_decoding_analyses.short_replays, curr_long_short_decoding_analyses.global_replays, curr_long_short_decoding_analyses.long_shared_aclus_only_decoder, curr_long_short_decoding_analyses.short_shared_aclus_only_decoder, curr_long_short_decoding_analyses.shared_aclus, curr_long_short_decoding_analyses.long_short_pf_neurons_diff, curr_long_short_decoding_analyses.n_neurons, curr_long_short_decoding_analyses.long_results_obj, curr_long_short_decoding_analyses.short_results_obj, curr_long_short_decoding_analyses.is_global\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e29b1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratemap\n",
    "# ratemap = deepcopy(long_pf1D.ratemap)\n",
    "\n",
    "ratemap: Ratemap = deepcopy(long_pf2D.ratemap)\n",
    "ratemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3eb175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot long|short firing rate index:\n",
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "x_frs_index, y_frs_index = long_short_fr_indicies_analysis_results['x_frs_index'], long_short_fr_indicies_analysis_results['y_frs_index'] # use the all_results_dict as the computed data value\n",
    "active_context = long_short_fr_indicies_analysis_results['active_context']\n",
    "\n",
    "# final_context = active_context.adding_context('display_fn', display_fn_name='display_long_short_laps')\n",
    "# fig = _plot_long_short_firing_rate_indicies(x_frs_index, y_frs_index, final_context, debug_print=debug_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf62bcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_short_fr_indicies_analysis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fe874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_test_file_path = Path(f'output/test_long_short_fr_indicies_analysis_results.h5').resolve()\n",
    "h5_test_file_path\n",
    "long_short_fr_indicies_analysis_results.to_hdf(h5_test_file_path, key='long_short_fr_indicies_analysis_results')\n",
    "\n",
    "# jonathan_firing_rate_analysis_result.is_hdf_serializable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887a4964",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "h5_test_file_path = Path(f'output/test_long_short_decoding_analyses.h5').resolve()\n",
    "h5_test_file_path\n",
    "curr_long_short_decoding_analyses.to_hdf(h5_test_file_path, key='long_short_decoding_analyses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5d993a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import LeaveOneOutDecodingResult, LeaveOneOutDecodingAnalysisResult, TimebinnedNeuronActivity, _convert_dict_to_hdf_attrs_fn\n",
    "\n",
    "# curr_long_short_decoding_analyses.long_results_obj.new_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a593865",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f'type(curr_long_short_decoding_analyses.long_results_obj): {type(curr_long_short_decoding_analyses.long_results_obj)}')\n",
    "h5_test_file_path = Path(f'output/test_LeaveOneOutDecodingAnalysisResult.h5').resolve()\n",
    "curr_long_short_decoding_analyses.long_results_obj.to_hdf(h5_test_file_path, key='long_results_obj')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefe4a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_long_short_decoding_analyses.short_results_obj.to_hdf(h5_test_file_path, key='short_results_obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4985e323",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "_obj = deepcopy(curr_long_short_decoding_analyses.long_results_obj.timebinned_neuron_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10c1cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.hstack((_obj.active_IDXs, _obj.inactive_IDXs))\n",
    "\n",
    "[np.hstack((a_v, i_v)) for a_v, i_v in zip(_obj.active_IDXs, _obj.inactive_IDXs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90541e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TimebinnedNeuronActivity\n",
    "h5_test_file_path = Path(f'output/test_TimebinnedNeuronActivity.h5').resolve()\n",
    "curr_long_short_decoding_analyses.long_results_obj.timebinned_neuron_info.to_hdf(h5_test_file_path, key='timebinned_neuron_info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57c067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'type(curr_long_short_decoding_analyses.long_results_obj.new_result): {type(curr_long_short_decoding_analyses.long_results_obj.new_result)}')\n",
    "h5_test_file_path = Path(f'output/test_LeaveOneOutDecodingResult.h5').resolve()\n",
    "curr_long_short_decoding_analyses.long_results_obj.new_result.to_hdf(h5_test_file_path, key='new_result', file_mode='r+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564e4bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_long_short_decoding_analyses.short_results_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e98dfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.rdf.rdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a028cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import SplitPartitionMembership\n",
    "from neuropy.core.neurons import NeuronType\n",
    "\n",
    "jonathan_firing_rate_analysis_result.neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccf5fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "\n",
    "h5_test_file_path = Path(f'output/test_jonathan_firing_rate_analysis_result.h5').resolve()\n",
    "h5_test_file_path\n",
    "jonathan_firing_rate_analysis_result.to_hdf(h5_test_file_path, key='jonathan_firing_rate_analysis_result')\n",
    "\n",
    "# jonathan_firing_rate_analysis_result.is_hdf_serializable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4506ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "aclu_to_idx = jonathan_firing_rate_analysis_result.rdf.aclu_to_idx\n",
    "aclu_to_idx_df: pd.DataFrame = pd.DataFrame({'aclu': list(aclu_to_idx.keys()), 'fragile_linear_idx': list(aclu_to_idx.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a867b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I wanna look at the suprise metrics again please.\n",
    "\n",
    "# can align each of the sessions (across days) to the track transition point (the \"Delta\") as the zero.\n",
    "\n",
    "# print_keys_if_possible(\"global_computation_results\", curr_active_pipeline.global_computation_results, max_depth=2)\n",
    "\n",
    "# computed_data: pyphocorehelpers.DataStructure.dynamic_parameters.DynamicParameters\n",
    "# \t\tâ”‚   â”œâ”€â”€ jonathan_firing_rate_analysis: pyphocorehelpers.DataStructure.dynamic_parameters.DynamicParameters\n",
    "# \t\tâ”‚   â”œâ”€â”€ long_short_fr_indicies_analysis: pyphocorehelpers.DataStructure.dynamic_parameters.DynamicParameters\n",
    "# \t\tâ”‚   â”œâ”€â”€ long_short_leave_one_out_decoding_analysis: pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations.LeaveOneOutDecodingAnalysis\n",
    "# \t\tâ”‚   â”œâ”€â”€ long_short_post_decoding: pyphocorehelpers.DataStructure.dynamic_parameters.DynamicParameters\n",
    "\n",
    "\n",
    "print_keys_if_possible(\"global_computation_results\", curr_active_pipeline.global_computation_results.computed_data, max_depth=3)\n",
    "\n",
    "# jonathan_firing_rate_analysis_result.rdf\n",
    "\n",
    "# long_short_leave_one_out_decoding_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d775a6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computed_data.long_short_fr_indicies_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e6c297",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computed_data.long_short_post_decoding.expected_v_observed_result\n",
    "# curr_active_pipeline.global_computation_results.computed_data.long_short_post_decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab6f97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed529276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterative partition\n",
    "curr_active_pipeline.global_computation_results.computed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1267131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computed_data.long_short_post_decoding.expected_v_observed_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511f54b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computed_data.long_short_post_decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f26386",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computed_data.long_short_post_decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccdbb13",
   "metadata": {
    "tags": [
     "NOW",
     "across_sessions",
     "table"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsResults, InstantaneousFiringRatesDataframeAccessor, InstantaneousSpikeRateGroupsComputation, trackMembershipTypesEnum, trackExclusiveToMembershipTypeDict, trackExclusiveToMembershipTypeReverseDict\n",
    "\n",
    "# ## Specify the output file:\n",
    "# common_file_path = Path('output/test_across_session_scatter_plot_new.h5')\n",
    "# print(f'common_file_path: {common_file_path}')\n",
    "# InstantaneousFiringRatesDataframeAccessor.add_results_to_inst_fr_results_table(curr_active_pipeline, common_file_path, file_mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d33a7c",
   "metadata": {
    "tags": [
     "NOW",
     "load",
     "plot"
    ]
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from pyphocorehelpers.indexing_helpers import partition, safe_pandas_get_group\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import InstantaneousFiringRatesDataframeAccessor, AcrossSessionsVisualizations\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import SingleBarResult\n",
    "\n",
    "common_file_path = Path('output/active_across_session_scatter_plot_results.h5')\n",
    "print(f'common_file_path: {common_file_path}')\n",
    "\n",
    "# InstantaneousSpikeRateGroupsComputation, : pd.DataFrame\n",
    "_shell_obj, loaded_result_df = InstantaneousFiringRatesDataframeAccessor.load_and_prepare_for_plot(common_file_path)\n",
    "# Perform the actual plotting:\n",
    "AcrossSessionsVisualizations.across_sessions_bar_graphs(_shell_obj, num_sessions=13, save_figure=False, enable_tiny_point_labels=False, enable_hover_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb580a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "maximum_timedelta: timedelta = timedelta(1, 0, 0) # 1 Day maximum time\n",
    "delta_since_last_compute: timedelta = curr_active_pipeline.get_time_since_last_computation()\n",
    "print(f'delta_since_last_compute: {delta_since_last_compute}')\n",
    "needs_recompute: bool = delta_since_last_compute > maximum_timedelta\n",
    "print(f'\\tneeds_recompute: {needs_recompute}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624326b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Serialization of preprocessing parameters test\n",
    "file_path = 'output/preprocessing_parameters.h5'\n",
    "\n",
    "with h5py.File(file_path, \"w\") as f:\n",
    "\tpreprocessing_group = f.create_group(\"preprocessing_parameters\")\n",
    "\n",
    "\t# Serialize epoch_estimation_parameters\n",
    "\tepoch_estimation_group = preprocessing_group.create_group(\"epoch_estimation_parameters\")\n",
    "\n",
    "\tlaps_group = epoch_estimation_group.create_group(\"laps\")\n",
    "\tlaps_group.attrs[\"N\"] = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"laps\"][\"N\"]\n",
    "\tlaps_group.attrs[\"should_backup_extant_laps_obj\"] = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"laps\"][\"should_backup_extant_laps_obj\"]\n",
    "\n",
    "\tPBEs_group = epoch_estimation_group.create_group(\"PBEs\")\n",
    "\tPBEs_group.attrs[\"thresh\"] = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"PBEs\"][\"thresh\"]\n",
    "\tPBEs_group.attrs[\"min_dur\"] = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"PBEs\"][\"min_dur\"]\n",
    "\tPBEs_group.attrs[\"merge_dur\"] = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"PBEs\"][\"merge_dur\"]\n",
    "\tPBEs_group.attrs[\"max_dur\"] = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"PBEs\"][\"max_dur\"]\n",
    "\n",
    "\treplays_group = epoch_estimation_group.create_group(\"replays\")\n",
    "\treplay_data = preprocessing_parameters_dict[\"epoch_estimation_parameters\"][\"replays\"]\n",
    "\t# replay_dataframe = pd.DataFrame(replay_data)\n",
    "\t# replay_data.to_hdf(f, \"/preprocessing_parameters/epoch_estimation_parameters/replays\")\n",
    "\t## TODO: add the data here using Epoch's .to_hdf\n",
    "\t\n",
    "\t# Check for \"None\" values before setting attributes\n",
    "\tdef check_and_set(key, value):\n",
    "\t\tif value is not None:\n",
    "\t\t\treplays_group.attrs[key] = value\n",
    "\n",
    "\t# Set attributes if not \"None\", otherwise skip writing\n",
    "\tcheck_and_set(\"min_epoch_included_duration\", preprocessing_parameters_dict[\"epoch_estimation_parameters\"].get('replays', {}).get(\"min_epoch_included_duration\"))\n",
    "\tcheck_and_set(\"max_epoch_included_duration\", preprocessing_parameters_dict[\"epoch_estimation_parameters\"].get('replays', {}).get(\"max_epoch_included_duration\"))\n",
    "\tcheck_and_set(\"maximum_speed_thresh\", preprocessing_parameters_dict[\"epoch_estimation_parameters\"].get('replays', {}).get(\"maximum_speed_thresh\"))\n",
    "\tcheck_and_set(\"min_inclusion_fr_active_thresh\", preprocessing_parameters_dict[\"epoch_estimation_parameters\"].get('replays', {}).get(\"min_inclusion_fr_active_thresh\"))\n",
    "\tcheck_and_set(\"min_num_unique_aclu_inclusions\", preprocessing_parameters_dict[\"epoch_estimation_parameters\"].get('replays', {}).get(\"min_num_unique_aclu_inclusions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc30a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_default_neptune_plots = False\n",
    "# enable_default_neptune_plots = True\n",
    "\n",
    "## To file only:\n",
    "with matplotlib_file_only():\n",
    "\t# Perform non-interactive Matplotlib operations with 'AGG' backend\n",
    "\tmain_complete_figure_generations(curr_active_pipeline, enable_default_neptune_plots=enable_default_neptune_plots, save_figures_only=True, save_figure=True)\n",
    "\n",
    "## Clear the Programmatically open figures:\n",
    "plt.close('all') # this takes care of the matplotlib-backed figures.\n",
    "curr_active_pipeline.clear_display_outputs()\n",
    "curr_active_pipeline.clear_registered_output_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44783dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "# Perform interactive Matplotlib operations with 'Qt5Agg' backend\n",
    "_out_figures = main_complete_figure_generations(curr_active_pipeline, enable_default_neptune_plots=False, save_figures_only=False, save_figure=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943b8f18",
   "metadata": {},
   "source": [
    "# Common Display Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef70fb2",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": [
     "plot_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# configure backend here\n",
    "matplotlib.use('Qt5Agg')\n",
    "# backend_qt5agg\n",
    "# %matplotlib qt5\n",
    "# %matplotlib qt\n",
    "# matplotlib.use('AGG') # non-interactive backend ## 2022-08-16 - Surprisingly this works to make the matplotlib figures render only to .png file, not appear on the screen!\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "# mpl.rcParams['toolbar'] = 'None' # disable toolbars\n",
    "\n",
    "# Showing\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fbf214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pylustrator # customization of figures\n",
    "import matplotlib\n",
    "# configure backend here\n",
    "matplotlib.use('Qt5Agg')\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "import pylustrator # call `pylustrator.start()` before creating your first figure in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530208a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pylustrator.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8eddbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b490781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot The laps:\n",
    "from neuropy.utils.matplotlib_helpers import plot_position_curves_figure\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.laps import plot_laps_2d\n",
    "pylustrator.start()\n",
    "fig, out_axes_list = plot_laps_2d(global_session, legacy_plotting_mode=False, include_velocity=False, include_accel=False, figsize=(24, 10))\n",
    "out_axes_list[0].set_title('Estimated Laps')\n",
    "fig.canvas.manager.set_window_title('Estimated Laps')\n",
    "ax = out_axes_list[0]\n",
    "ax.set_xlim((1036.242685185441, 1441.769668184419))\n",
    "\n",
    "# Hide y-axis ticklabels\n",
    "plt.tick_params(axis='y', which='both', labelleft=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb32cee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "ax = fig.axes[0]\n",
    "ax\n",
    "ax.get_xlim()\n",
    "\n",
    "\n",
    "laps_example_region_xlims = (1036.242685185441, 1441.769668184419)\n",
    "\n",
    "fig, out_axes_list = plot_position_curves_figure(global_session.position, include_velocity=False, include_accel=False, figsize=(24, 10))\n",
    "\n",
    "_out1 = curr_active_pipeline.display('_display_long_short_laps', include_velocity=False, include_accel=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475b2e4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c59882",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.plot._display_decoder_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9737539d",
   "metadata": {},
   "source": [
    "# 2023-09-07 - Track Graphics Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a866b1b",
   "metadata": {
    "tags": [
     "ACTIVE",
     "track_graphics"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphocorehelpers.geometry_helpers import BoundsRect, point_tuple_mid_point\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import LinearTrackDimensions\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import add_vertical_track_bounds_lines, add_track_shapes, test_LinearTrackDimensions_2D_pyqtgraph\n",
    "from neuropy.utils.mathutil import contiguous_regions, threshPeriods, compute_grid_bin_bounds, map_value\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import test_LinearTrackDimensions_2D_Matplotlib\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import LinearTrackInstance\n",
    "\n",
    "\n",
    "grid_bin_bounds = BoundsRect.init_from_grid_bin_bounds(global_pf2D.config.grid_bin_bounds)\n",
    "display(grid_bin_bounds)\n",
    "\n",
    "# long_track_dims = LinearTrackDimensions.init_from_grid_bin_bounds(grid_bin_bounds)\n",
    "# short_track_dims = LinearTrackDimensions.init_from_grid_bin_bounds(grid_bin_bounds)\n",
    "\n",
    "long_track_dims = LinearTrackDimensions(track_length=170.0)\n",
    "short_track_dims = LinearTrackDimensions(track_length=100.0)\n",
    "\n",
    "common_1D_platform_height = 0.25\n",
    "common_1D_track_height = 0.1\n",
    "long_track_dims.minor_axis_platform_side_width = common_1D_platform_height\n",
    "long_track_dims.track_width = common_1D_track_height # (short_track_dims.minor_axis_platform_side_width\n",
    "\n",
    "short_track_dims.minor_axis_platform_side_width = common_1D_platform_height\n",
    "short_track_dims.track_width = common_1D_track_height # (short_track_dims.minor_axis_platform_side_width\n",
    "\n",
    "# instances:\n",
    "long_track = LinearTrackInstance(long_track_dims, grid_bin_bounds=grid_bin_bounds)\n",
    "short_track = LinearTrackInstance(short_track_dims, grid_bin_bounds=grid_bin_bounds)\n",
    "\n",
    "print(long_track_dims)\n",
    "print(short_track_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c8f5ab",
   "metadata": {},
   "source": [
    "# 2023-09-21 - Continuous Surprise Figure - How do I display it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dbe065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '_perform_time_dependent_pf_sequential_surprise_computation'\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import plot_long_short_surprise_difference_plot, plot_long_short, plot_long_short_any_values\n",
    "from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import fig_surprise_results\n",
    "\n",
    "from neuropy.utils.matplotlib_helpers import draw_epoch_regions\n",
    "from pyphocorehelpers.DataStructure.RenderPlots.MatplotLibRenderPlots import MatplotlibRenderPlots\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import LongShortDisplayConfigManager\n",
    "long_short_display_config_manager = LongShortDisplayConfigManager()\n",
    "long_epoch_config = long_short_display_config_manager.long_epoch_config.as_matplotlib_kwargs()\n",
    "short_epoch_config = long_short_display_config_manager.short_epoch_config.as_matplotlib_kwargs()\n",
    "\n",
    "graphics_outputs_list = fig_surprise_results(curr_active_pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fe45c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00d58220",
   "metadata": {},
   "source": [
    "### FOUND! 2023-09-21 - Found code that generated surprise plots, strangely not stored anywhere!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe7b982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: nSnapshots == n_post_update_times\n",
    "active_relative_entropy_results = active_extended_stats['pf_dt_sequential_surprise']\n",
    "post_update_times = active_relative_entropy_results['post_update_times'] # (4123,) = (nSnapshots,)\n",
    "snapshot_differences_result_dict = active_relative_entropy_results['snapshot_differences_result_dict']\n",
    "time_intervals = active_relative_entropy_results['time_intervals']\n",
    "long_short_rel_entr_curves_frames = active_relative_entropy_results['long_short_rel_entr_curves_frames'] # (4123, 108, 63) = (nSnapshots, n_neurons, n_xbins)\n",
    "short_long_rel_entr_curves_frames = active_relative_entropy_results['short_long_rel_entr_curves_frames'] # (4123, 108, 63) = (nSnapshots, n_neurons, n_xbins)\n",
    "flat_relative_entropy_results = active_relative_entropy_results['flat_relative_entropy_results'] # (4123, 63) - (nSnapshots, nXbins)\n",
    "flat_jensen_shannon_distance_results = active_relative_entropy_results['flat_jensen_shannon_distance_results'] # (4123, 63) - (nSnapshots, nXbins)\n",
    "flat_jensen_shannon_distance_across_all_positions = np.sum(np.abs(flat_jensen_shannon_distance_results), axis=1) # sum across all position bins # (4123,) - (nSnapshots)\n",
    "flat_surprise_across_all_positions = np.sum(np.abs(flat_relative_entropy_results), axis=1) # sum across all position bins # (4123,) - (nSnapshots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61282cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(flat_jensen_shannon_distance_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2d8d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(flat_relative_entropy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922a7718",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(flat_jensen_shannon_distance_across_all_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a303ca32",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(long_short_rel_entr_curves_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7205c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_image(flat_jensen_shannon_distance_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb518301",
   "metadata": {},
   "outputs": [],
   "source": [
    "from silx.gui.plot import Plot2D\n",
    "\n",
    "plot = Plot2D()  # Create the plot widget\n",
    "plot.addImage(flat_jensen_shannon_distance_results, legend='image')  # Plot the 2D data set with default colormap\n",
    "plot.setGraphTitle('flat_jensen_shannon_distance_results')\n",
    "plot.getXAxis().setLabel('Position Bin')\n",
    "plot.getYAxis().setLabel('Snapshot Timebin')\n",
    "plot.show()  # Make the plot widget visible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589c3d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot = Plot2D()  # Create the plot widget\n",
    "plot.addImage(long_short_rel_entr_curves_frames, legend='image')  # Plot the 2D data set with default colormap\n",
    "plot.setGraphTitle('long_short_rel_entr_curves_frames')\n",
    "# plot.getXAxis().setLabel('Position Bin')\n",
    "# plot.getYAxis().setLabel('Snapshot Timebin')\n",
    "plot.show()  # Make the plot widget visible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f8f97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from silx.gui.plot.StackView import StackViewMainWindow\n",
    "\n",
    "# synthetic data, stack of 100 images of size 200x300\n",
    "# mystack = np.fromfunction(\n",
    "#     lambda i, j, k: np.sin(i/15.) + np.cos(j/4.) + 2 * np.sin(k/6.),\n",
    "#     (100, 200, 300)\n",
    "# )\n",
    "\n",
    "sv = StackViewMainWindow()\n",
    "sv.setColormap(\"jet\", autoscale=True)\n",
    "sv.setStack(long_short_rel_entr_curves_frames)\n",
    "# (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "sv.setLabels([\"post_update_time\", \"aclu\", \"Position (xbin)\"])\n",
    "sv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa37de28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "heatmap_pf1D_win, heatmap_pf1D_img = visualize_heatmap_pyqtgraph(flat_jensen_shannon_distance_results, show_yticks=False, title=f\"flat_jensen_shannon_distance_results\", defer_show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa164de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_pf1D_win, heatmap_pf1D_img = visualize_heatmap_pyqtgraph(flat_jensen_shannon_distance_across_all_positions, show_yticks=False, title=f\"flat_jensen_shannon_distance_across_all_positions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2295dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.matplotlib_helpers import draw_epoch_regions\n",
    "from neuropy.core.epoch import Epoch\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(post_update_times, flat_surprise_across_all_positions)\n",
    "ax.set_ylabel('Relative Entropy across all positions')\n",
    "ax.set_xlabel('t (seconds)')\n",
    "epochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, facecolor=('r','cyan'), alpha=0.1, edgecolors=None, labels_kwargs={'y_offset': -0.05, 'size': 14}, defer_render=True, debug_print=False)\n",
    "laps_epochs_collection, laps_epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.laps.as_epoch_obj(), ax, facecolor='r', edgecolors='black', labels_kwargs={'y_offset': -16.0, 'size':8}, defer_render=True, debug_print=False)\n",
    "# replays_epochs_collection, replays_epoch_labels = draw_epoch_regions(active_filter_epoch_obj, ax, facecolor='orange', edgecolors=None, labels_kwargs=None, defer_render=False, debug_print=False)\n",
    "fig.suptitle('flat_surprise_across_all_positions')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f00561d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(post_update_times, flat_jensen_shannon_distance_across_all_positions, label='JS_Distance')\n",
    "ax.set_ylabel('J-S Distance across all positions')\n",
    "ax.set_xlabel('t (seconds)')\n",
    "epochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, facecolor=('red','cyan'), alpha=0.1, edgecolors=None, labels_kwargs={'y_offset': -0.05, 'size': 14}, defer_render=True, debug_print=False)\n",
    "laps_epochs_collection, laps_epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.laps.as_epoch_obj(), ax, facecolor='red', edgecolors='black', labels_kwargs={'y_offset': -16.0, 'size':8}, defer_render=True, debug_print=False)\n",
    "# replays_epochs_collection, replays_epoch_labels = draw_epoch_regions(active_filter_epoch_obj, ax, facecolor='orange', edgecolors=None, labels_kwargs=None, defer_render=False, debug_print=False)\n",
    "fig.suptitle('flat_jensen_shannon_distance_across_all_positions')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df587d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show basic relative entropy vs. time plot:\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(post_update_times, flat_relative_entropy_results)\n",
    "ax.set_ylabel('Relative Entropy')\n",
    "ax.set_xlabel('t (seconds)')\n",
    "epochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, facecolor=('red','cyan'), alpha=0.1, edgecolors=None, labels_kwargs={'y_offset': -0.05, 'size': 14}, defer_render=False, debug_print=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316ffda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "win, plots = plot_long_short_surprise_difference_plot(curr_active_pipeline, long_results_obj, short_results_obj, long_epoch_name, short_epoch_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dc968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "win, (ax_long, ax_short), legend = plot_long_short(long_results_obj, short_results_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6066cafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_fn = lambda a_results_obj: a_results_obj.all_epochs_decoded_epoch_time_bins_mean[:,0]\n",
    "# y_fn = lambda a_results_obj: a_results_obj.all_epochs_all_cells_one_left_out_posterior_to_scrambled_pf_surprises_mean\n",
    "# y_fn = lambda a_results_obj: a_results_obj.all_epochs_all_cells_one_left_out_posterior_to_pf_surprises_mean\n",
    "y_fn = lambda a_results_obj: a_results_obj.all_epochs_computed_one_left_out_posterior_to_pf_surprises\n",
    "\n",
    "# (time_bins, neurons), (epochs, neurons), (epochs)\n",
    "# all_epochs_computed_one_left_out_posterior_to_pf_surprises, all_epochs_computed_cell_one_left_out_posterior_to_pf_surprises_mean, all_epochs_all_cells_one_left_out_posterior_to_pf_surprises_mean\n",
    "win, plots_tuple, legend = plot_long_short_any_values(long_results_obj, short_results_obj, x=x_fn, y=y_fn) #  limit_aclus=[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5d42b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO 2023-09-21 16:19: - [ ] Does not work due to QCode issue\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.MultiContextComparingDisplayFunctions import _context_nested_docks\n",
    "\n",
    "\n",
    "# active_display_output = {}\n",
    "# active_identifying_filtered_session_ctx = global_epoch_context\n",
    "# display_output = active_display_output | curr_active_pipeline.display('_display_context_nested_docks', active_identifying_filtered_session_ctx, enable_gui=False, debug_print=False) # returns {'master_dock_win': master_dock_win, 'app': app, 'out_items': out_items}\n",
    "# master_dock_win = display_output['master_dock_win']\n",
    "# app = display_output['app']\n",
    "# out_items = display_output['out_items']\n",
    "\n",
    "include_includelist = curr_active_pipeline.active_completed_computation_result_names # ['maze', 'sprinkle']\n",
    "\n",
    "out_items = {}\n",
    "master_dock_win, app, out_items = _context_nested_docks(curr_active_pipeline, active_config_names=include_includelist, **{'enable_gui': True, 'debug_print': False})\n",
    "master_dock_win"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094f8467",
   "metadata": {},
   "source": [
    "# Test classifying various x-positions as belonging to outside the outside_maze, the track_endcaps, or the track_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7326d309",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_replay_stats_df: pd.DataFrame = jonathan_firing_rate_analysis_result.neuron_replay_stats_df\n",
    "short_pf_peak_x = neuron_replay_stats_df.short_pf_peak_x.values\n",
    "long_pf_peak_x = neuron_replay_stats_df.long_pf_peak_x.values\n",
    "\n",
    "# long_pf_peak_x_maze_classification = [classify_x_position(test_x, long_rects) for test_x in long_pf_peak_x.values]\n",
    "# short_pf_peak_x_maze_classification = [classify_x_position(test_x, short_rects) for test_x in short_pf_peak_x.values]\n",
    "# [classify_x_position(test_x, short_rects) for test_x in long_pf_peak_x.values]\n",
    "\n",
    "long_track.is_on_maze(long_pf_peak_x)\n",
    "# long_track.is_on_endcap(long_pf_peak_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4bc1b6",
   "metadata": {},
   "source": [
    "## NOW TODO 2023-09-20 22:33: - [ ] Need to fix tests and determing why some peaks are falling outside the bounds (as assessed by the is_on_maze function to see if implementation is valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e13f006",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# assert short_track.is_on_maze(short_pf_peak_x)[np.logical_not(np.isnan(short_pf_peak_x))].all(), f\"all valid short peaks should be located on the short track\" # should all be true yeah?\n",
    "assert long_track.is_on_maze(short_pf_peak_x)[np.logical_not(np.isnan(short_pf_peak_x))].all(), f\"all valid short peaks should be located on the long track\"\n",
    "assert long_track.is_on_maze(long_pf_peak_x)[np.logical_not(np.isnan(long_pf_peak_x))].all(), f\"all valid long peaks should be located on the long track. {long_track.is_on_maze(long_pf_peak_x)[np.logical_not(np.isnan(long_pf_peak_x))]}\" # not working\n",
    "assert short_track.is_on_maze(short_pf_peak_x)[np.logical_not(np.isnan(short_pf_peak_x))].all(), f\"all valid short peaks should be located on the short track. {short_track.is_on_maze(short_pf_peak_x)[np.logical_not(np.isnan(short_pf_peak_x))]}\" # not working\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ec27b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_track.is_on_endcap(long_pf_peak_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1bc2ae",
   "metadata": {},
   "source": [
    "## Debug Plots for `LinearTrackDimensions` and `LinearTrackInstance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0ece7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "app, w, cw, (long_track_dims, long_rect_items, long_rects), (short_track_dims, short_rect_items, short_rects) = test_LinearTrackDimensions_2D_pyqtgraph(long_track_dims, short_track_dims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cdcb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "axs = fig.get_axes()\n",
    "ax = axs[0]\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4510a162",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_rects_outputs, short_rects_outputs = add_track_shapes(grid_bin_bounds, ax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277a73e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long_offset=(150.0, 0.5)\n",
    "# short_offset=(150.0, -0.5)\n",
    "\n",
    "long_offset=(grid_bin_bounds.center_point[0], 0.5)\n",
    "short_offset=(grid_bin_bounds.center_point[0], -0.5)\n",
    "\n",
    "# # Create a second y-axis sharing the same x-axis as ax\n",
    "# ax2 = ax.twinx()\n",
    "# # ax2.plot(x, y2, 'b-')\n",
    "# ax2.set_ylabel('Track data', color='b')\n",
    "# # Set the adjustable attribute to 'datalim'\n",
    "# ax.set_adjustable('datalim')\n",
    "# ax2.set_adjustable('datalim')\n",
    "# long_track_dims.plot_rects(ax2, offset=long_offset)\n",
    "# short_track_dims.plot_rects(ax2, offset=short_offset)\n",
    "\n",
    "combined_item, rect_items, rects = long_track_dims.plot_rects(ax, offset=long_offset)\n",
    "short_track_dims.plot_rects(ax, offset=short_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b04046",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1, ax2 = test_LinearTrackDimensions_2D_Matplotlib(long_track_dims, short_track_dims, long_offset=(150.0, 0.5), short_offset=(150.0, -0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2210369b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Find center from `grid_bin_bounds`\n",
    "# long_pf2D.bin_info\n",
    "grid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\n",
    "\n",
    "x_diff = (grid_bin_bounds[0][1] - grid_bin_bounds[0][0])\n",
    "y_diff = (grid_bin_bounds[1][1] - grid_bin_bounds[1][0])\n",
    "print(f'x_diff: {x_diff}, y_diff: {y_diff}')\n",
    "\n",
    "# Find the x, y midpoints:\n",
    "x_midpoint = grid_bin_bounds[0][0] + (x_diff/2.0)\n",
    "y_midpoint = grid_bin_bounds[1][0] + (y_diff/2.0)\n",
    "print(f'x_midpoint: {x_midpoint}, y_midpoint: {y_midpoint}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcb6c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_bin_bounds_center_point = (point_tuple_mid_point(grid_bin_bounds[0]), point_tuple_mid_point(grid_bin_bounds[1])) # (145.43, 140.61)\n",
    "x_midpoint, y_midpoint = grid_bin_bounds_center_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfcd3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# long_track_dims.total_length # 214.0\n",
    "# short_track_dims.total_length # 144.0\n",
    "# zero_alignment_point = self.total_length/2.0\n",
    "long_notable_x_positions, _long_notable_y_positions = long_track_dims._build_component_notable_positions(offset_point=(x_midpoint, y_midpoint))\n",
    "short_notable_x_positions, _short_notable_y_positions = short_track_dims._build_component_notable_positions(offset_point=(x_midpoint, y_midpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7c4759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _add_vertical_track_bounds_lines(grid_bin_bounds, ax=None):\n",
    "# \t\"\"\" \n",
    "# \tCaptures: long_notable_x_positions, short_notable_x_positions\n",
    "\t\n",
    "# \tUsage:\n",
    "# \t\tgrid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\n",
    "# \t\tlong_track_line_collection, short_track_line_collection = _add_vertical_track_bounds_lines(grid_bin_bounds=grid_bin_bounds, ax=ax)\n",
    "\n",
    "# \t\"\"\"\n",
    "# \tlong_track_dims = LinearTrackDimensions(track_length=170.0)\n",
    "# \tshort_track_dims = LinearTrackDimensions(track_length=100.0)\n",
    "\n",
    "# \t# Find center from `grid_bin_bounds` using `point_tuple_mid_point`\n",
    "# \tx_midpoint, y_midpoint = (point_tuple_mid_point(grid_bin_bounds[0]), point_tuple_mid_point(grid_bin_bounds[1])) # grid_bin_bounds_center_point: (145.43, 140.61)\n",
    "\n",
    "# \tlong_notable_x_positions, _long_notable_y_positions = long_track_dims._build_component_notable_positions(offset_point=(x_midpoint, y_midpoint))\n",
    "# \tshort_notable_x_positions, _short_notable_y_positions = short_track_dims._build_component_notable_positions(offset_point=(x_midpoint, y_midpoint))\n",
    "\n",
    "# \t# Omit the midpoint\n",
    "# \tlong_notable_x_platform_positions = long_notable_x_positions[[0,1,3,4]]\n",
    "# \tshort_notable_x_platform_positions = short_notable_x_positions[[0,1,3,4]]\n",
    "\n",
    "# \t## Adds to current axes:\n",
    "# \tif ax is None:\n",
    "# \t\tfig = plt.gcf()\n",
    "# \t\taxs = fig.get_axes()\n",
    "# \t\tax = axs[0]\n",
    "# \tlong_track_line_collection: matplotlib.collections.LineCollection = plt.vlines(long_notable_x_platform_positions, label='long_track_x_pos_lines', ymin=ax.get_ybound()[0], ymax=ax.get_ybound()[1], colors='#0000FFAA', linestyles='dashed') # matplotlib.collections.LineCollection\n",
    "# \tshort_track_line_collection: matplotlib.collections.LineCollection = plt.vlines(short_notable_x_platform_positions, label='short_track_x_pos_lines', ymin=ax.get_ybound()[0], ymax=ax.get_ybound()[1], colors='#FF0000AA', linestyles='dashed') # matplotlib.collections.LineCollection\n",
    "# \treturn long_track_line_collection, short_track_line_collection\n",
    "\n",
    "grid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\n",
    "long_track_line_collection, short_track_line_collection = add_vertical_track_bounds_lines(grid_bin_bounds=grid_bin_bounds, ax=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec63da15",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect_items, rects = long_track_dims.plot_rects(axs[0]) # , offset=(x, y) # , offset=(0.1, 100.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267c7cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_track_line_collection.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840d8eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_track_line_collection.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bdce2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_track_dims.plot_rects(ax, offset=)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691fef31",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "axs = fig.get_axes()\n",
    "ax = axs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5766851",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_track_line_collection.remove()\n",
    "short_track_line_collection.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fc84bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.placefield import plot_1D_placecell_validation\n",
    "\n",
    "_out = plot_1D_placecell_validation(long_pf1D, 0)\n",
    "\n",
    "axes = _out[1]\n",
    "ax = axes[0]\n",
    "# ax = axes[1]\n",
    "ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cae003",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_track_dims = LinearTrackDimensions.init_from_grid_bin_bounds(grid_bin_bounds=grid_bin_bounds, debug_print=True)\n",
    "\n",
    "fig, axs = plt.subplots(2, 1)\n",
    "\n",
    "rect_items, rects = long_track_dims.plot_rects(axs[0]) # , offset=(x, y) # , offset=(0.1, 100.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1b251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# long_track_dims.plot_rects(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb503975",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_grid_bin_bounds_validation', curr_active_pipeline.get_session_context(), defer_render=False, save_figure=True)\n",
    "fig = _out.figures[0]\n",
    "ax = _out.axes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eea2ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the bounding box coordinates and dimensions\n",
    "bbox = ax.bbox\n",
    "x, y, width, height = bbox.x0, bbox.y0, bbox.width, bbox.height\n",
    "x, y, width, height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf2cb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_empty = ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dab829d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect_items, rects = long_track_dims.plot_rects(ax_empty) # , offset=(x, y) # , offset=(0.1, 100.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251dd801",
   "metadata": {},
   "outputs": [],
   "source": [
    "(320.0, 983.7668560462606, 901.8181818181818, 91.99628790747863)\n",
    "active_track_dims = LinearTrackDimensions(width=901.8181818181818)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeba0c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.transforms import Bbox\n",
    "\n",
    "# Step 2: Define a simple vector graphic (an arrow in this case)\n",
    "def draw_arrow(ax, x, y, width, height):\n",
    "    arrow = patches.FancyArrow(x, y, width, height, width=0.2*height, color=\"red\")\n",
    "    ax.add_patch(arrow)\n",
    "\n",
    "# Step 3: Scale and draw the arrow within a bounding box\n",
    "def draw_scaled_arrow_in_bbox(ax, bbox):\n",
    "    # Extract the bounding box coordinates and dimensions\n",
    "    x, y, width, height = bbox.x0, bbox.y0, bbox.width, bbox.height\n",
    "\n",
    "    # Draw the bounding box (for visualization)\n",
    "    rect = patches.Rectangle((x, y), width, height, linewidth=1, edgecolor='black', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "    # Draw the scaled arrow within the bounding box\n",
    "    draw_arrow(ax, x, y, width, height)\n",
    "\n",
    "# Main code\n",
    "fig, ax = plt.subplots()\n",
    "bbox = Bbox.from_bounds(0.2, 0.2, 0.6, 0.6)  # Define bounding box with [x, y, width, height]\n",
    "\n",
    "draw_scaled_arrow_in_bbox(ax, bbox)\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_aspect('equal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ba7368",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0680b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rect_items[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3adfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d49be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "## Adds a new subplot to an existing (fig, ax) without requiring modifications in the original code!\n",
    "\n",
    "# Get the current gridspec from ax\n",
    "gs = ax.get_subplotspec().get_gridspec()\n",
    "\n",
    "# Create a new gridspec with an additional column\n",
    "gs_new = gridspec.GridSpec(1, 2, width_ratios=[1, 0.5]) # new column is half the width of the current one\n",
    "\n",
    "# Reposition the existing ax using the new gridspec\n",
    "ax.set_position(gs_new[0, 0].get_position(fig))\n",
    "\n",
    "# Add a new subplot in the new column\n",
    "ax2 = fig.add_subplot(gs_new[0, 1])\n",
    "\n",
    "\n",
    "ax2.plot(np.cos(np.linspace(0, 10, 100)))\n",
    "# ax2.cla()\n",
    "# long_track_dims.plot_rects(ax2)\n",
    "\n",
    "# long_track_dims.plot_rects(ax2, offset=(0.1, 0.0))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffd94f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out2 = curr_active_pipeline.display('_display_batch_pho_jonathan_replay_firing_rate_comparison', included_unit_neuron_IDs=[2], n_max_plot_rows=2, save_figure=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a1d5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import fig_example_handpicked_pho_jonathan_active_set_cells\n",
    "\n",
    "_LxC_out, _SxC_out = fig_example_handpicked_pho_jonathan_active_set_cells(curr_active_pipeline, save_figure=True, included_LxC_example_neuron_IDs=[4, 58], included_SxC_example_neuron_IDs=[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6907963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neuropy.analyses.placefields import PfnDMixin, plotRaw_v_time\n",
    "from neuropy.analyses.placefields import PfnDMixin\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "_out3 = long_pf1D.plotRaw_v_time(0, should_include_trajectory=True, should_include_spikes=False, should_include_labels=True, use_filtered_positions=True, use_pandas_plotting=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a88a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out4 = long_pf1D.plotRaw_v_time(0, should_include_trajectory=True, should_include_spikes=False, should_include_labels=True, use_filtered_positions=False, use_pandas_plotting=False)\n",
    "# _out4 = long_pf1D.plotRaw_v_time(0, should_include_trajectory=True, should_include_spikes=False, should_include_labels=True, use_filtered_positions=False, use_pandas_plotting=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e59bdb",
   "metadata": {},
   "source": [
    "# Figure 1) pf1D Ratemaps, Active set, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77377ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot, plot_raster_plot\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap_pyqtgraph # used in `plot_kourosh_activity_style_figure`\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_1_add_replay_epoch_rasters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5035f2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pf1d_compare_graphics, (example_epoch_rasters_L, example_epoch_rasters_S), example_stacked_epoch_graphics = PAPER_FIGURE_figure_1_full(curr_active_pipeline) # did not display the pf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05664e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = jonathan_firing_rate_analysis_result.rdf.rdf\n",
    "rdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a2984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "['start']\n",
    "\n",
    "\n",
    "# Any change in duration over the recording session duration?\n",
    "rdf['duration']\n",
    "\n",
    "# rdf.plot.scatter('start', 'duration')\n",
    "\n",
    "# rdf.plot.scatter('duration', 'num_neuron_participating') # strong positive trend\n",
    "\n",
    "# rdf.plot.scatter('start', 'num_neuron_participating') # num neurons participating seems to increase over time, especially after the short track is introduced. Contrary to my hypothesis.\n",
    "\n",
    "rdf.plot.scatter('start', 'num_short_only_neuron_participating')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ['num_neuron_participating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dc28f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "a_plot_obj = curr_active_pipeline.plot\n",
    "a_plot_obj._display_spike_rasters_pyqtplot_2D()\n",
    "# '_display_spike_rasters_pyqtplot_2D': ' Plots a standalone 2D raster plot\\n        ',\n",
    "# '_display_spike_rasters_pyqtplot_3D': ' Plots a standalone 3D raster plot with independent/standalone controls built-in\\n        ',\n",
    "# '_display_spike_rasters_pyqtplot_3D_with_2D_controls': ' Plots a standalone 3D raster plot (via pyqtgraph) with a separate 2D raster plot as the window with which you can adjust the viewed window. \\n        ',\n",
    "# '_display_spike_rasters_vedo_3D': ' Plots a standalone 3D raster plot with independent/standalone controls built-in\\n        ',\n",
    "# '_display_spike_rasters_vedo_3D_with_2D_controls': ' Plots a standalone 3D raster plot (via Vedo) with a separate 2D raster plot as the window with which you can adjust the viewed window. \\n        ',\n",
    "# '_display_spike_rasters_window': ' Displays a Spike3DRasterWindowWidget with a configurable set of raster widgets and controls in it.\\n        ',type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e247349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(a_plot_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0c9b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_display_function_docs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3877d9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf1d_compare_fig_L, pf1d_compare_fig_S = pf1d_compare_graphics.figures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46626313",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf1d_compare_fig_L.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999442a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44ffa57",
   "metadata": {
    "tags": [
     "active"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import build_shared_sorted_neuronIDs\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap_pyqtgraph\n",
    "\n",
    "ratemap = long_pf1D.ratemap\n",
    "included_unit_neuron_IDs = EITHER_subset.track_exclusive_aclus\n",
    "rediculous_final_sorted_all_included_neuron_ID, rediculous_final_sorted_all_included_pfmap = build_shared_sorted_neuronIDs(ratemap, included_unit_neuron_IDs, sort_ind=new_all_aclus_sort_indicies.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c7755b",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_pf1D_win, heatmap_pf1D_img = visualize_heatmap_pyqtgraph(rediculous_final_sorted_all_included_pfmap, show_yticks=False, title=f\"pf1D Sorted Visualization\", defer_show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66369f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_curves_sorted = long_pf1D.ratemap.normalized_tuning_curves[is_included][included_new_all_aclus_sort_indicies]\n",
    "heatmap_pf1D_win, heatmap_pf1D_img = visualize_heatmap_pyqtgraph(active_curves_sorted, show_yticks=False, title=f\"pf1D Sorted Visualization\", defer_show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5f0066",
   "metadata": {
    "tags": [
     "unwrap_figure_output",
     "interactive"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import DecodedEpochSlicesPaginatedFigureController\n",
    "\n",
    "## Stacked Epoch Plot\n",
    "example_stacked_epoch_graphics = curr_active_pipeline.display('_display_long_and_short_stacked_epoch_slices', defer_render=False, save_figure=True)\n",
    "pagination_controller_L, pagination_controller_S = example_stacked_epoch_graphics.plot_data['controllers']\n",
    "ax_L, ax_S = example_stacked_epoch_graphics.axes\n",
    "final_figure_context_L, final_context_S = example_stacked_epoch_graphics.context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cbb0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## After launching the interactive Stacked Epoch Plots for user epoch selection, try to update the selection with previously added annotations:\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from pyphoplacecellanalysis.GUI.Qt.Mixins.PaginationMixins import SelectionsObject\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import DecodedEpochSlicesPaginatedFigureController\n",
    "\n",
    "user_annotation_man = UserAnnotationsManager()\n",
    "user_annotations = user_annotation_man.get_user_annotations()\n",
    "\n",
    "final_context_L = curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='replays', decoder='long_results_obj')\n",
    "final_context_S = curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='replays', decoder='short_results_obj')\n",
    "# _out_pagination_controller.params.active_identifying_figure_ctx.adding_context(None,  user_annotation=\"selections\")\n",
    "selections_context_L = final_context_L.adding_context(None,  user_annotation=\"selections\")\n",
    "selections_context_S = final_context_S.adding_context(None,  user_annotation=\"selections\")\n",
    "\n",
    "saved_selection_L: SelectionsObject = pagination_controller_L.save_selection()\n",
    "saved_selection_S: SelectionsObject = pagination_controller_S.save_selection()\n",
    "# saved_selection_L = user_annotation_man.update_selections_from_annotations(saved_selection_L, user_annotations)\n",
    "# saved_selection_S = user_annotation_man.update_selections_from_annotations(saved_selection_S, user_annotations)\n",
    "\n",
    "saved_selection_L = saved_selection_L.update_selections_from_annotations(user_annotations, debug_print=False)\n",
    "saved_selection_S = saved_selection_S.update_selections_from_annotations(user_annotations, debug_print=False)\n",
    "\n",
    "## re-apply the selections:\n",
    "pagination_controller_L.restore_selections(saved_selection_L, defer_render=True)\n",
    "pagination_controller_S.restore_selections(saved_selection_S, defer_render=True)\n",
    "\n",
    "ax_L[0].figure.canvas.draw()  # .figures.canvas.draw()\n",
    "ax_S[0].figure.canvas.draw()  # .figures.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b2f39d",
   "metadata": {
    "tags": [
     "TODO"
    ]
   },
   "source": [
    "## 2023-09-06 - Plot the decoded positions for each replay on the track:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a592c55f",
   "metadata": {
    "tags": [
     "TODO"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import LinearTrackDimensions\n",
    "\n",
    "\n",
    "long_track_dims = LinearTrackDimensions(track_length=100.0)\n",
    "short_track_dims = LinearTrackDimensions(track_length=70.0)\n",
    "\n",
    "\n",
    "# long_track_dims.plot_rects(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fe2d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import _test_LinearTrackDimensions_2D\n",
    "\n",
    "app, w, cw, (long_track_dims, long_rect_items, long_rects), (short_track_dims, short_rect_items, short_rects) = _test_LinearTrackDimensions_2D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48faca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_fig_3_a, _out_fig_3_b = PAPER_FIGURE_figure_3(curr_active_pipeline, defer_render=False, save_figure=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d481370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = _out_fig_3_a.axes[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c872e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_track_dims.plot_rects(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ff0f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "pagination_controller_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26f364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the symbol properties\n",
    "# symbol = pg.mkPen('w', width=1)  # Pen for the lines\n",
    "size = 1.0  # Fixed x-width\n",
    "symbol_brush = None  # No brush for the symbol (transparent fill)\n",
    "\n",
    "# override_scatter_plot_kwargs = dict(pxMode=False, symbol='|', size=size, pen={'color': 'w', 'width': 1.0}) # , brush=symbol_brush\n",
    "\n",
    "override_scatter_plot_kwargs = dict(pxMode=False, symbol='arrow_up', size=1.0, pen={'color': 'w', 'width': 1.0}, hoverable=True) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226bb530",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_epoch_spikes_df_L.spikes.rebuild_fragile_linear_neuron_IDXs();\n",
    "filter_epoch_spikes_df_S.spikes.rebuild_fragile_linear_neuron_IDXs();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b889b886",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_L, win_L, plots_L, plots_data_L = plot_multiple_raster_plot(epochs_df_L, filter_epoch_spikes_df_L, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs,\n",
    "\t\t\t\t\t\t\t\t\t\tepoch_id_key_name='replay_epoch_id', scatter_app_name=\"Long Decoded Example Replays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee132b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_S, win_S, plots_S, plots_data_S = plot_multiple_raster_plot(epochs_df_S, filter_epoch_spikes_df_S, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs,\n",
    "                                                                 epoch_id_key_name='replay_epoch_id', scatter_app_name=\"Short Decoded Example Replays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26dd0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test single `plot_raster_plot` calls\n",
    "an_epoch = list(epochs_df_L.itertuples())[0]\n",
    "an_epoch_spikes_df = filter_epoch_spikes_df_L[filter_epoch_spikes_df_L['replay_epoch_id'] == an_epoch.Index]\n",
    "\n",
    "_out_single_raster_plot = plot_raster_plot(an_epoch_spikes_df, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=None, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs, scatter_app_name=\"test1\")\n",
    "_out_single_raster_plot2 = plot_raster_plot(an_epoch_spikes_df, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs, scatter_app_name=\"test2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6071c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "app_alt, win_alt, plots_alt, plots_data_alt = plot_multiple_raster_plot(epochs_df_L, filter_epoch_spikes_df_L, included_neuron_ids=EITHER_subset.track_exclusive_aclus, unit_sort_order=None, unit_colors_list=unit_colors_list, scatter_plot_kwargs=override_scatter_plot_kwargs,\n",
    "                                                                         epoch_id_key_name='replay_epoch_id', scatter_app_name=\"ALT Long Decoded Example Replays\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d20407c",
   "metadata": {},
   "source": [
    "### Testing `plot_kourosh_activity_style_figure` for debugging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69512447",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.decoder_result import plot_kourosh_activity_style_figure\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.helpers import _helper_make_scatterplot_clickable\n",
    "\n",
    "plot_aclus = EITHER_subset.track_exclusive_aclus.copy()\n",
    "# plot_aclus = EITHER_subset.track_exclusive_aclus[new_all_aclus_sort_indicies].copy()\n",
    "_out_A = plot_kourosh_activity_style_figure(long_results_obj, long_session, plot_aclus, unit_sort_order=new_all_aclus_sort_indicies, epoch_idx=13, callout_epoch_IDXs=None, skip_rendering_callouts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326f29f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "app, win, plots, plots_data = _out_A\n",
    "# plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338d4092",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO 2023-06-27 10:42: - [ ] Desperitely need a class that \"explodes\" the important variables and their types out of a DynamicParameters (dict-like) or other object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517cdee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_n = plot_kourosh_activity_style_figure(long_results_obj, long_session, EITHER_subset.track_exclusive_aclus, unit_sort_order=new_all_aclus_sort_indicies, epoch_idx=49, callout_epoch_IDXs=np.arange(6), skip_rendering_callouts=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af748f5c",
   "metadata": {},
   "source": [
    "# 2023-07-14 - LxC and SxC PhoJonathanSession plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9415e3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import BatchPhoJonathanFiguresHelper\n",
    "\n",
    "## Get global 'jonathan_firing_rate_analysis' results:\n",
    "curr_jonathan_firing_rate_analysis = curr_active_pipeline.global_computation_results.computed_data['jonathan_firing_rate_analysis']\n",
    "neuron_replay_stats_df, rdf, aclu_to_idx, irdf = curr_jonathan_firing_rate_analysis.neuron_replay_stats_df, curr_jonathan_firing_rate_analysis.rdf.rdf, curr_jonathan_firing_rate_analysis.rdf.aclu_to_idx, curr_jonathan_firing_rate_analysis.irdf.irdf\n",
    "\n",
    "# with VizTracer(output_file=f\"viztracer_display_BatchPhoJonathanFiguresHelper_PlusPDF_20.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "active_out_figures_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, included_unit_neuron_IDs=XOR_subset.track_exclusive_aclus, n_max_page_rows=20, write_vector_format=False, write_png=True) # active_out_figures_dict: {IdentifyingContext<('kdiba', 'gor01', 'two', '2006-6-07_16-40-19', 'BatchPhoJonathanReplayFRC', 'long_only', '(12,21,48)')>: <Figure size 1920x660 with 12 Axes>, IdentifyingContext<('kdiba', 'gor01', 'two', '2006-6-07_16-40-19', 'BatchPhoJonathanReplayFRC', 'short_only', '(18,19,65)')>: <Figure size 1920x660 with 12 Axes>}\n",
    "print(f'active_out_figures_dict: {active_out_figures_dict}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec1c4bb",
   "metadata": {
    "tags": [
     "ACTIVE_2023-09-07"
    ]
   },
   "outputs": [],
   "source": [
    "# 2023-09-07 - Build Example LxC/SxC cells from handpicked examples: aclus = [4, 58]\n",
    "# from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import build_extra_cell_info_label_string\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out2 = curr_active_pipeline.display('_display_batch_pho_jonathan_replay_firing_rate_comparison', n_max_plot_rows=2, save_figure=False, included_unit_neuron_IDs=[4, 58]) # , included_unit_neuron_IDs=[4, 58]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052f7ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.display(display_function='_display_2d_placefield_result_plot_ratemaps_2D', active_session_configuration_context=long_epoch_context)\n",
    "\n",
    "\n",
    "# curr_active_pipeline.display(display_function='_display_placemaps_pyqtplot_2D', active_session_configuration_context=long_epoch_context)\n",
    "curr_active_pipeline.display(display_function='_display_1d_placefields', active_session_configuration_context=long_epoch_context)\n",
    "# curr_active_pipeline.display(display_function='_display_2d_placefield_occupancy', active_session_configuration_context=long_epoch_context)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae8158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display(display_function='_display_2d_placefield_occupancy', active_session_configuration_context=long_epoch_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be309d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display(display_function='_display_2d_placefield_occupancy', active_session_configuration_context=short_epoch_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bb48de",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display(display_function='_display_2d_placefield_result_plot_ratemaps_2D', active_session_configuration_context=short_epoch_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5115fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display(display_function='_display_2d_placefield_result_plot_ratemaps_2D', active_session_configuration_context=long_epoch_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d12ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure() # new figure to hold the result\n",
    "# can show the figures by looping through and calling\n",
    "for a_ctxt, a_fig in active_out_figures_dict.items():\n",
    "    print(f'showing: {a_ctxt}')\n",
    "    a_fig.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edea79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]] # only uses global_session\n",
    "(epochs_df_L, epochs_df_S), (filter_epoch_spikes_df_L, filter_epoch_spikes_df_S), (good_example_epoch_indicies_L, good_example_epoch_indicies_S), (short_exclusive, long_exclusive, BOTH_subset, EITHER_subset, XOR_subset, NEITHER_subset), new_all_aclus_sort_indicies, assigning_epochs_obj = PAPER_FIGURE_figure_1_add_replay_epoch_rasters(curr_active_pipeline)\n",
    "\n",
    "long_short_fr_indicies_analysis_results = curr_active_pipeline.global_computation_results.computed_data['long_short_fr_indicies_analysis']\n",
    "long_laps, long_replays, short_laps, short_replays, global_laps, global_replays = [long_short_fr_indicies_analysis_results[k] for k in ['long_laps', 'long_replays', 'short_laps', 'short_replays', 'global_laps', 'global_replays']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d085cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "jonathan_firing_rate_analysis_result.neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813ab296",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_exclusive.track_exclusive_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05be832a",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_exclusive.track_exclusive_df['lap_delta_minus_inst_fr'] = LxC_ThetaDeltaMinus.cell_agg_inst_fr_list # (n_cells, )\n",
    "long_exclusive.track_exclusive_df['lap_delta_plus_inst_fr'] = LxC_ThetaDeltaPlus.cell_agg_inst_fr_list # (n_cells, )\n",
    "long_exclusive.track_exclusive_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3077438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = LxC_ThetaDeltaMinus.epoch_agg_inst_fr_list # (n_epochs, n_cells)\n",
    "# d = d[:,1]\n",
    "d = LxC_ThetaDeltaMinus.cell_agg_inst_fr_list # (n_cells, )\n",
    "d\n",
    "long_exclusive.track_exclusive_df['lap_delta_minus_inst_fr'] = LxC_ThetaDeltaMinus.cell_agg_inst_fr_list # (n_cells, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6984de2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop out the very low (inactive) Epochs... I guess? But we want it to be influenced by the inactive epochs.\n",
    "curr_active_pipeline.\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d3f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(LxC_ThetaDeltaMinus.inst_fr_signals_list) # n_epochs\n",
    "d = LxC_ThetaDeltaMinus.inst_fr_df_list\n",
    "d[0]\n",
    "# (n_epochs, n_cells)\n",
    "# print(f'{d.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2b2901",
   "metadata": {},
   "source": [
    "## NOW: 2023-07-11 - Testing Batch-computed inst_firing_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c034766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchSessionCompletionHandler\n",
    "from pyphoplacecellanalysis.General.Batch.PhoDiba2023Paper import PaperFigureTwo, InstantaneousSpikeRateGroupsComputation\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "from pyphoplacecellanalysis.General.Batch.AcrossSessionResults import AcrossSessionsResults, AcrossSessionsVisualizations\n",
    "\n",
    "\n",
    "## Load the saved across-session results:\n",
    "inst_fr_output_filename = 'long_short_inst_firing_rate_result_handlers_2023-07-12.pkl'\n",
    "across_session_inst_fr_computation, across_sessions_instantaneous_fr_dict, across_sessions_instantaneous_frs_list = AcrossSessionsResults.load_across_sessions_data(global_data_root_parent_path=global_data_root_parent_path, inst_fr_output_filename=inst_fr_output_filename)\n",
    "# across_sessions_instantaneous_fr_dict = loadData(global_batch_result_inst_fr_file_path)\n",
    "num_sessions = len(across_sessions_instantaneous_fr_dict)\n",
    "print(f'num_sessions: {num_sessions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2549c92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Aggregate across all of the sessions to build a new combined `InstantaneousSpikeRateGroupsComputation`, which can be used to plot the \"PaperFigureTwo\", bar plots for many sessions.\n",
    "global_multi_session_context = IdentifyingContext(format_name='kdiba', num_sessions=num_sessions) # some global context across all of the sessions, not sure what to put here.\n",
    "\n",
    "# To correctly aggregate results across sessions, it only makes sense to combine entries at the `.cell_agg_inst_fr_list` variable and lower (as the number of cells can be added across sessions, treated as unique for each session).\n",
    "\n",
    "## Display the aggregate across sessions:\n",
    "_out_fig_2 = PaperFigureTwo(instantaneous_time_bin_size_seconds=0.01) # WARNING: we didn't save this info\n",
    "_out_fig_2.computation_result = across_session_inst_fr_computation\n",
    "_out_fig_2.active_identifying_session_ctx = across_session_inst_fr_computation.active_identifying_session_ctx\n",
    "# Set callback, the only self-specific property\n",
    "_out_fig_2._pipeline_file_callback_fn = curr_active_pipeline.output_figure # lambda args, kwargs: self.write_to_file(args, kwargs, curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f71cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing\n",
    "restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "# Perform interactive Matplotlib operations with 'Qt5Agg' backend\n",
    "_fig_2_theta_out, _fig_2_replay_out = _out_fig_2.display(active_context=global_multi_session_context, title_modifier_fn=lambda original_title: f\"{original_title} ({num_sessions} sessions)\", save_figure=True)\n",
    "\t\n",
    "_out_fig_2.perform_save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7b230c",
   "metadata": {},
   "source": [
    "# Figure 3) `PAPER_FIGURE_figure_3`: Firing Rate Index and Long/Short Firing Rate Replays v. Laps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6008da8",
   "metadata": {
    "tags": [
     "figure_3",
     "active"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.utils.matplotlib_helpers import FormattedFigureText\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import _plot_long_short_firing_rate_indicies\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "_out, _out2 = PAPER_FIGURE_figure_3(curr_active_pipeline, defer_render=False, save_figure=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd3546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out2.figures\n",
    "_out.axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c49f148",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.0-0.090"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd17dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = _out.figures\n",
    "fig\n",
    "# Computed long ($L$)|short($S$) firing rate indicies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed322ee",
   "metadata": {},
   "source": [
    "# `active_pf_nD`, `active_pf_nD_dt` visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8606b372",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.TimeSynchronizedOccupancyPlotter import TimeSynchronizedOccupancyPlotter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d478ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "curr_sync_occupancy_plotter = TimeSynchronizedOccupancyPlotter(global_pf2D_dt)\n",
    "curr_sync_occupancy_plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14388eec",
   "metadata": {},
   "source": [
    "# 2023-07-07 - `batch_extended_programmatic_figures` Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e3c3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "neptuner = batch_perform_all_plots(curr_active_pipeline, enable_neptune=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126028b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb off\n",
    "%load_ext viztracer\n",
    "from viztracer import VizTracer\n",
    "from pyphocorehelpers.print_helpers import get_now_day_str, get_now_time_str, get_now_time_precise_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a065e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-batch_extended_programmatic_figures.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "    batch_extended_programmatic_figures(curr_active_pipeline, write_vector_format=False, write_png=False, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef9f9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_extended_programmatic_figures(curr_active_pipeline, write_vector_format=False, write_png=False, debug_print=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7a0f86",
   "metadata": {},
   "source": [
    "# 2023-07-19 - Validation with 3D tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecde32c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "\n",
    "display_output = {}\n",
    "# active_config_name = long_epoch_name\n",
    "active_config_name = global_epoch_name\n",
    "active_config = curr_active_pipeline.active_configs[active_config_name]\n",
    "active_config.plotting_config.should_use_linear_track_geometry = True # indicate that it's a linear track so the better geometry can be used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80672dec",
   "metadata": {},
   "source": [
    "# 3D Plotters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0f0e7a",
   "metadata": {},
   "source": [
    "## ðŸ“£ Programmatically adding several epoch rectangles by calling the addRenderable context menu functions all at once for SpikeRaster2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb05977",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_renderables_menu = active_2d_plot.ui.menus.custom_context_menus.add_renderables[0].programmatic_actions_dict\n",
    "menu_commands = ['AddTimeIntervals.PBEs', 'AddTimeIntervals.Ripples', 'AddTimeIntervals.Replays', 'AddTimeIntervals.Laps', 'AddTimeIntervals.Session.Epochs']\n",
    "for a_command in menu_commands:\n",
    "    add_renderables_menu[a_command].trigger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb2d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.Specific2DRenderTimeEpochs import General2DRenderTimeEpochs, Ripples_2DRenderTimeEpochs, inline_mkColor\n",
    "## Inline Concise: Position Replays, PBEs, and Ripples all below the scatter:\n",
    "# active_2d_plot.interval_datasources.Replays.update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, y_location=-10.0, height=7.5, pen_color=inline_mkColor('orange', 0.8), brush_color=inline_mkColor('orange', 0.5), **kwargs)) ## Fully inline\n",
    "# active_2d_plot.interval_datasources.PBEs.update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, y_location=-2.0, height=1.5, pen_color=inline_mkColor('pink', 0.8), brush_color=inline_mkColor('pink', 0.5), **kwargs)) ## Fully inline\n",
    "# active_2d_plot.interval_datasources.Ripples.update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, y_location=-12.0, height=1.5, pen_color=inline_mkColor('cyan', 0.8), brush_color=inline_mkColor('cyan', 0.5), **kwargs)) ## Fully inline\n",
    "# active_2d_plot.interval_datasources.SessionEpochs .update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, y_location=-12.0, height=1.5, pen_color=inline_mkColor('cyan', 0.8), brush_color=inline_mkColor('cyan', 0.5), **kwargs)) ## Fully inline\n",
    "epochs_update_dict = {\n",
    "    'Replays':dict(y_location=-10.0, height=7.5, pen_color=inline_mkColor('orange', 0.8), brush_color=inline_mkColor('orange', 0.5)),\n",
    "    'PBEs':dict(y_location=-2.0, height=1.5, pen_color=inline_mkColor('pink', 0.8), brush_color=inline_mkColor('pink', 0.5)),\n",
    "    'Ripples':dict(y_location=-12.0, height=1.5, pen_color=inline_mkColor('cyan', 0.8), brush_color=inline_mkColor('cyan', 0.5)),\n",
    "    'SessionEpochs ':dict(y_location=-12.0, height=1.5, pen_color=inline_mkColor('cyan', 0.8), brush_color=inline_mkColor('cyan', 0.5)),\n",
    "}\n",
    "active_2d_plot.update_rendered_intervals_visualization_properties(epochs_update_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8e16b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rendered_interval_keys = list(interval_info.keys())\n",
    "desired_interval_height_ratios = [2.0, 2.0, 1.0, 0.1, 1.0, 1.0, 1.0] # ratio of heights to each interval\n",
    "required_vertical_offsets, required_interval_heights = EpochRenderingMixin.build_stacked_epoch_layout(desired_interval_height_ratios, epoch_render_stack_height=20.0, interval_stack_location='below')\n",
    "stacked_epoch_layout_dict = {interval_key:dict(y_location=y_location, height=height) for interval_key, y_location, height in zip(rendered_interval_keys, required_vertical_offsets, required_interval_heights)} # Build a stacked_epoch_layout_dict to update the display\n",
    "active_2d_plot.update_rendered_intervals_visualization_properties(stacked_epoch_layout_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd240080",
   "metadata": {},
   "source": [
    "## ðŸªŸ ipcDataExplorer - 3D Interactive Tuning Curves Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5568d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_display_function_docs_dict\n",
    "\n",
    "'_display_3d_image_plotter'\n",
    "'_display_long_short_laps'\n",
    "'_display_3d_interactive_custom_data_explorer'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c55128f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.InteractiveDataExplorerBase import InteractiveDataExplorerBase\n",
    "# from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.InteractiveCustomDataExplorer import InteractiveCustomDataExplorer # TypeError: super(type, obj): obj must be an instance or subtype of type\n",
    "\n",
    "active_config_name = global_epoch_context\n",
    "# curr_active_pipeline.reload_default_display_functions()\n",
    "# _out = curr_active_pipeline.display('_display_3d_interactive_custom_data_explorer', long_epoch_name) # long_epoch_context\n",
    "display_dict = curr_active_pipeline.display('_display_3d_interactive_custom_data_explorer', active_config_name) # does not work, missing color info?\n",
    "iplapsDataExplorer = display_dict['iplapsDataExplorer']\n",
    "# plotter is available at\n",
    "p = display_dict['plotter']\n",
    "iplapsDataExplorer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5ac39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "# df = pd.DataFrame([curr_active_pipeline.registered_display_function_docs_dict])\n",
    "# df = curr_active_pipeline.registered_display_function_docs_dict\n",
    "df = pd.DataFrame.from_dict(curr_active_pipeline.registered_display_function_docs_dict, orient='index', columns=['Value'])\n",
    "display_widget = widgets.Output()\n",
    "with display_widget:\n",
    "\tdisplay(df)\n",
    "display_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8949a4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.matplotlib_helpers import plot_position_curves_figure\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1df3828",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "graphics_output_dict = curr_active_pipeline.display('_display_long_short_laps', active_identifying_session_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5c4871",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out3 = curr_active_pipeline.display('_display_long_and_short_stacked_epoch_slices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c64ae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.laps import plot_lap_trajectories_3d\n",
    "# ## single_combined_plot == True mode (mode 1.):\n",
    "# p, laps_pages = plot_lap_trajectories_3d(curr_active_pipeline.sess, single_combined_plot=True)\n",
    "# p.show()\n",
    "\n",
    "## single_combined_plot == False mode (mode 2.):        \n",
    "p, laps_pages = plot_lap_trajectories_3d(curr_active_pipeline.sess, single_combined_plot=False, curr_num_subplots=len(curr_active_pipeline.sess.laps.lap_id), active_page_index=0)\n",
    "p.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5ec90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.laps import plot_lap_trajectories_2d\n",
    "\n",
    "p_laps_2D, axs_laps_2D, laps_2D_pages = plot_lap_trajectories_2d(curr_active_pipeline.sess, curr_num_subplots=5, active_page_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428ddaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_laps_2D.suptitle('plot_lap_trajectories_2d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21c4da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = axs_laps_2D[0,0]\n",
    "ax_empty = axs_laps_2D[-1,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8b777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_track_position_offset = 1.0 * long_track_dims.compute_position_offset(grid_bin_bounds=grid_bin_bounds) # array([49.43, 140.61])\n",
    "long_track_position_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651f665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_bin_bounds_center_point = (point_tuple_mid_point(grid_bin_bounds[0]), point_tuple_mid_point(grid_bin_bounds[1])) # (145.43, 140.61)\n",
    "print(f'grid_bin_bounds_center_point: {grid_bin_bounds_center_point}')\n",
    "x_midpoint, y_midpoint = grid_bin_bounds_center_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77188bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_annotation_man = UserAnnotationsManager()\n",
    "user_annotations = user_annotation_man.get_user_annotations()\n",
    "\n",
    "final_context_L = curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='replays', decoder='long_results_obj')\n",
    "final_context_S = curr_active_pipeline.build_display_context_for_session(display_fn_name='DecodedEpochSlices', epochs='replays', decoder='short_results_obj')\n",
    "# _out_pagination_controller.params.active_identifying_figure_ctx.adding_context(None,  user_annotation=\"selections\")\n",
    "selections_context_L = final_context_L.adding_context(None,  user_annotation=\"selections\")\n",
    "selections_context_S = final_context_S.adding_context(None,  user_annotation=\"selections\")\n",
    "\n",
    "## try to get the user annotations for this session:\n",
    "try:\n",
    "\tselection_idxs_L = user_annotations[selections_context_L]\n",
    "\tselection_idxs_S = user_annotations[selections_context_S]\n",
    "except KeyError as e:\n",
    "\tif allow_interactive_selection:\n",
    "\t\tprint(f'user annotations <good replay selections> are not found. Creating them interactively...')\n",
    "\t\tuser_annotations = interactive_good_epoch_selections(annotations_man=user_annotation_man, curr_active_pipeline=curr_active_pipeline)  # perform interactive selection. Should block here.\n",
    "\t\tselection_idxs_L = user_annotations[selections_context_L]\n",
    "\t\tselection_idxs_S = user_annotations[selections_context_S]\n",
    "\telse:\n",
    "\t\tprint(f'interactive annotation is not permitted. Failing.')\n",
    "\t\traise e\n",
    "except Exception as e:\n",
    "\tprint('Unhandled exception: {e}')\n",
    "\traise\n",
    "\n",
    "# for updating the filter_epochs_df (`filter_epochs_df`) from the selections:\n",
    "self.filter_epochs_df['long_is_user_included'] = np.isin(self.filter_epochs_df.index, selection_idxs_L)\n",
    "self.filter_epochs_df['short_is_user_included'] = np.isin(self.filter_epochs_df.index, selection_idxs_S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bcd4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdf off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a222ab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from neuropy.utils.mixins.binning_helpers import transition_matrix\n",
    "\n",
    "### 1D Transition Matrix:\n",
    "\n",
    "def _compute_position_transition_matrix(xbin_labels, binned_x: np.ndarray, n_powers:int=3):\n",
    "\t\"\"\"  1D Transition Matrix from binned positions (e.g. 'binned_x')\n",
    "\n",
    "\t\tpf1D.xbin_labels # array([  1,   2,   3,   4,  ...)\n",
    "\t\tpf1D.filtered_pos_df['binned_x'].to_numpy() # array([116, 115, 115, ...,  93,  93,  93], dtype=int64)\n",
    "\t\"\"\"\n",
    "\tnum_position_states = len(xbin_labels)\n",
    "\t# binned_x = pos_1D.to_numpy()\n",
    "\tbinned_x_indicies = binned_x - 1\n",
    "\tbinned_x_transition_matrix = transition_matrix(deepcopy(binned_x_indicies), markov_order=1, max_state_index=num_position_states)\n",
    "\t# binned_x_transition_matrix_higher_order_list = [binned_x_transition_matrix, transition_matrix(deepcopy(binned_x_indicies), markov_order=2, max_state_index=num_position_states), transition_matrix(deepcopy(binned_x_indicies), markov_order=3, max_state_index=num_position_states)]\n",
    "\n",
    "\tbinned_x_transition_matrix[np.isnan(binned_x_transition_matrix)] = 0.0\n",
    "\tbinned_x_transition_matrix_higher_order_list = [binned_x_transition_matrix] + [np.linalg.matrix_power(binned_x_transition_matrix, n) for n in np.arange(2, n_powers+1)]\n",
    "\t# , np.linalg.matrix_power(binned_x_transition_matrix, 2), np.linalg.matrix_power(binned_x_transition_matrix, 3)\n",
    "\t# binned_x_transition_matrix.shape # (64, 64)\n",
    "\treturn binned_x_transition_matrix_higher_order_list\n",
    "\n",
    "def _build_decoded_positions_transition_matrix(active_one_step_decoder):\n",
    "\t\"\"\" Compute the transition_matrix from the decoded positions \n",
    "\n",
    "\tTODO: make sure that separate events (e.g. separate replays) are not truncated creating erronious transitions\n",
    "\n",
    "\t\"\"\"\n",
    "\t# active_time_window_variable = active_one_step_decoder.time_window_centers # get time window centers (n_time_window_centers,) # (4060,)\n",
    "\t# active_most_likely_positions = active_one_step_decoder.most_likely_positions.T # (4060, 2) NOTE: the most_likely_positions for the active_one_step_decoder are tranposed compared to the active_two_step_decoder\n",
    "\t# active_most_likely_positions = active_two_step_decoder.most_likely_positions # (2, 4060)\n",
    "\tactive_one_step_decoder.most_likely_position_flat_indicies\n",
    "\t# active_most_likely_positions = active_one_step_decoder.revised_most_likely_positions.T\n",
    "\t# active_most_likely_positions #.shape # (36246,)\n",
    "\n",
    "\tmost_likely_position_indicies = np.squeeze(np.array(np.unravel_index(active_one_step_decoder.most_likely_position_flat_indicies, active_one_step_decoder.original_position_data_shape))) # convert back to an array\n",
    "\tmost_likely_position_xbins = most_likely_position_indicies + 1 # add 1 to convert back to a bin label from an index\n",
    "\t# most_likely_position_indicies # (1, 36246)\n",
    "\n",
    "\txbin_labels = np.arange(active_one_step_decoder.original_position_data_shape[0]) + 1\n",
    "\n",
    "\tdecoded_binned_x_transition_matrix_higher_order_list = _compute_position_transition_matrix(xbin_labels, most_likely_position_indicies)\n",
    "\treturn decoded_binned_x_transition_matrix_higher_order_list, xbin_labels\n",
    "\n",
    "\n",
    "# pf1D = deepcopy(curr_active_pipeline.computation_results['maze1'].computed_data['pf1D'])\n",
    "pf1D = deepcopy(global_pf1D)\n",
    "# pf1D = deepcopy(short_pf1D)\n",
    "# pf1D = deepcopy(long_pf1D)\n",
    "binned_x_transition_matrix_higher_order_list = _compute_position_transition_matrix(pf1D.xbin_labels, pf1D.filtered_pos_df['binned_x'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dec59e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf1D.filtered_pos_df.plot(x='t',y='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb355dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization ______________________________________________________________________________________________________ #\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow, LayoutScrollability\n",
    "out = BasicBinnedImageRenderingWindow(binned_x_transition_matrix_higher_order_list[0], pf1D.xbin_labels, pf1D.xbin_labels, name='binned_x_transition_matrix', title=\"Transition Matrix for binned x (from, to)\", variable_label='Transition Matrix', scrollability_mode=LayoutScrollability.NON_SCROLLABLE)\n",
    "# out.add_data(row=1, col=0, matrix=active_eloy_analysis.pf_overlapDensity_2D, xbins=active_pf_2D_dt.xbin_labels, ybins=active_pf_2D_dt.ybin_labels, name='pf_overlapDensity', title='pf overlapDensity metric', variable_label='pf overlapDensity')\n",
    "\n",
    "# out.add_data(row=1, col=0, matrix=binned_x_transition_matrix_higher_order_list[1], xbins=pf1D.xbin_labels, ybins=pf1D.ybin_labels, name='binned_x_transition_matrix^2', title='2nd Order Transition Matrix for binned x (from, to)', variable_label='2nd Order Transition Matrix') # , scrollability_mode=LayoutScrollability.NON_SCROLLABLE\n",
    "# out.add_data(row=2, col=0, matrix=binned_x_transition_matrix_higher_order_list[2], xbins=pf1D.xbin_labels, ybins=pf1D.ybin_labels, name='binned_x_transition_matrix^3', title='3rd Order Transition Matrix for binned x (from, to)', variable_label='3rd Order Transition Matrix') # , scrollability_mode=LayoutScrollability.NON_SCROLLABLE\n",
    "\n",
    "# Separate Windows for each:\n",
    "# out2 = BasicBinnedImageRenderingWindow(binned_x_transition_matrix_higher_order_list[1], pf1D.xbin_labels, pf1D.xbin_labels, name='binned_x_transition_matrix^2', title=\"2nd Order Transition Matrix for binned x (from, to)\", variable_label='2nd Order Transition Matrix', scrollability_mode=LayoutScrollability.NON_SCROLLABLE)\n",
    "# out3 = BasicBinnedImageRenderingWindow(binned_x_transition_matrix_higher_order_list[2], pf1D.xbin_labels, pf1D.xbin_labels, name='binned_x_transition_matrix^3', title=\"3rd Order Transition Matrix for binned x (from, to)\", variable_label='3rd Order Transition Matrix', scrollability_mode=LayoutScrollability.NON_SCROLLABLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990e5f54",
   "metadata": {},
   "source": [
    "## 1. Compute the transition_matrix from the decoded positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e5db7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BayesianPlacemapPositionDecoder\n",
    "# active_one_step_decoder = deepcopy(long_one_step_decoder_1D) # long_results_obj.original_1D_decoder\n",
    "long_decoded_binned_x_transition_matrix_higher_order_list, long_xbin_labels = _build_decoded_positions_transition_matrix(active_one_step_decoder=deepcopy(long_one_step_decoder_1D))\n",
    "short_decoded_binned_x_transition_matrix_higher_order_list, short_xbin_labels = _build_decoded_positions_transition_matrix(active_one_step_decoder=deepcopy(short_one_step_decoder_1D))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcddd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_decoded = BasicBinnedImageRenderingWindow(decoded_binned_x_transition_matrix_higher_order_list[0], active_one_step_decoder.xbin_centers, active_one_step_decoder.xbin_centers, name='decoded_binned_x_transition_matrix', title=\"DECODED Transition Matrix for binned x (from, to)\", variable_label='Transition Matrix', scrollability_mode=LayoutScrollability.NON_SCROLLABLE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea34522",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "out = BasicBinnedImageRenderingWindow(binned_x_transition_matrix_higher_order_list[i], pf1D.xbin_labels, pf1D.xbin_labels, name='binned_x_transition_matrix', title=\"Transition Matrix for binned x (from, to)\", variable_label='Transition Matrix', scrollability_mode=LayoutScrollability.NON_SCROLLABLE)\n",
    "out.add_data(row=1, col=0, matrix=long_decoded_binned_x_transition_matrix_higher_order_list[i], xbins=long_xbin_labels, ybins=long_xbin_labels, name='long_decoded_binned_x_transition_matrix', title='Long DECODED Transition Matrix', variable_label='long decoded')\n",
    "out.add_data(row=2, col=0, matrix=short_decoded_binned_x_transition_matrix_higher_order_list[i], xbins=short_xbin_labels, ybins=short_xbin_labels, name='short_decoded_binned_x_transition_matrix', title='Short DECODED Transition Matrix', variable_label='short decoded')\n",
    "# out.add_data(row=1, col=0, matrix=binned_x_transition_matrix_higher_order_list[1], xbins=pf1D.xbin_labels, ybins=pf1D.ybin_labels, name='binned_x_transition_matrix^2', title='2nd Order Transition Matrix for binned x (from, to)', variable_label='2nd Order Transition Matrix') # , scrollability_mode=LayoutScrollability.NON_SCROLLABLE\n",
    "# out.add_data(row=2, col=0, matrix=binned_x_transition_matrix_higher_order_list[2], xbins=pf1D.xbin_labels, ybins=pf1D.ybin_labels, name='binned_x_transition_matrix^3', title='3rd Order Transition Matrix for binned x (from, to)', variable_label='3rd Order Transition Matrix') # , scrollability_mode=LayoutScrollability.NON_SCROLLABLE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fb7eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_one_step_decoder.most_likely_position_indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a8f4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## 2. Use the position transition matrix to determine how likely each decoded position's transition is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87cd169",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_binned_instantaneous_unit_specific_spike_rate = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.time_binned_instantaneous_unit_specific_spike_rate\n",
    "timestamps = time_binned_instantaneous_unit_specific_spike_rate.time_bins\n",
    "\n",
    "value_df = time_binned_instantaneous_unit_specific_spike_rate.instantaneous_unit_specific_spike_rate_values\n",
    "value_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0807be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of spikes version:\n",
    "time_binned_unit_specific_spike_rate = curr_active_pipeline.global_computation_results.computed_data.jonathan_firing_rate_analysis.time_binned_unit_specific_spike_rate\n",
    "timestamps = time_binned_unit_specific_spike_rate.time_bins\n",
    "value_df = time_binned_unit_specific_spike_rate.time_binned_unit_specific_binned_spike_rate\n",
    "value_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
