{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b767063d-daa6-4057-b615-2e58b9587551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/miniconda3/envs/PhoLabViz/lib/python3.9/site-packages/outdated/utils.py:14: OutdatedPackageWarning: The package outdated is out of date. Your version is 0.2.1, the latest is 0.2.2.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n",
      "/home/halechr/miniconda3/envs/PhoLabViz/lib/python3.9/site-packages/outdated/utils.py:14: OutdatedPackageWarning: The package pingouin is out of date. Your version is 0.5.1, the latest is 0.5.2.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build_module_logger(module_name=\"Spike3D.pipeline\"):\n",
      "\t Module logger com.PhoHale.Spike3D.pipeline has file logging enabled and will log to EXTERNAL/TESTING/Logging/debug_com.PhoHale.Spike3D.pipeline.log\n"
     ]
    }
   ],
   "source": [
    "%pdb off\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "# %gui qt\n",
    "# $env:QT_API=\"pyqt6\"\n",
    "# %gui qt5\n",
    "# %gui qt6\n",
    "# from PyQt5.Qt import QApplication\n",
    "# # start qt event loop\n",
    "# _instance = QApplication.instance()\n",
    "# if not _instance:\n",
    "#     _instance = QApplication([])\n",
    "# app = _instance\n",
    "\n",
    "from copy import deepcopy\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Pho's Formatting Preferences\n",
    "# from pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\n",
    "# set_pho_preferences_concise()\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "# from neuropy import core\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.core.epoch import NamedTimerange\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.BapunDataSessionFormat import BapunDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.RachelDataSessionFormat import RachelDataSessionFormat\n",
    "from neuropy.core.session.Formats.Specific.HiroDataSessionFormat import HiroDataSessionFormatRegisteredClass\n",
    "\n",
    "known_data_session_type_properties_dict = DataSessionFormatRegistryHolder.get_registry_known_data_session_type_dict()\n",
    "active_data_session_types_registered_classes_dict = DataSessionFormatRegistryHolder.get_registry_data_session_type_class_name_dict()\n",
    "enable_saving_to_disk = False\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "\n",
    "from PendingNotebookCode import _perform_batch_plot, _build_batch_plot_kwargs, find_local_session_paths\n",
    "\n",
    "def build_eloy_computation_configs(sess, **kwargs):\n",
    "    \"\"\" OPTIONALLY can be overriden by implementors to provide specific filter functions \"\"\"\n",
    "    # (4.0, 4.0)cm bins, (6.0, 6.0)cm gaussian smoothing\n",
    "    # peak frate > 2Hz \n",
    "    # return [DynamicContainer(pf_params=PlacefieldComputationParameters(speed_thresh=10.0, grid_bin=(4.0, 4.0), smooth=(6.0, 6.0), frate_thresh=0.2, time_bin_size=1.0, computation_epochs = None), spike_analysis=None)]\n",
    "    # return [DynamicContainer(pf_params=PlacefieldComputationParameters(speed_thresh=10.0, grid_bin=(4.0, 4.0), smooth=(2.5, 2.5), frate_thresh=0.2, time_bin_size=1.0, computation_epochs = None), spike_analysis=None)]\n",
    "    # return [DynamicContainer(pf_params=PlacefieldComputationParameters(speed_thresh=10.0, grid_bin=(4.0, 4.0), smooth=(0.2, 0.2), frate_thresh=0.2, time_bin_size=1.0, computation_epochs = None), spike_analysis=None)]\n",
    "    return [DynamicContainer(pf_params=PlacefieldComputationParameters(speed_thresh=10.0, grid_bin=(4.0, 4.0), smooth=(0.2, 0.2), frate_thresh=0.2, time_bin_size=0.025, computation_epochs = None), spike_analysis=None)]\n",
    "\n",
    "\n",
    "\n",
    "# global_data_root_parent_path = Path(r'W:\\Data') # Windows Apogee\n",
    "global_data_root_parent_path = Path(r'/media/MAX/Data') # Diba Lab Workstation Linux\n",
    "# global_data_root_parent_path = Path(r'/Volumes/MoverNew/data') # rMBP\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bd1e96-4dae-4944-998d-c6964b3f8699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_session_names_list: ['2006-6-13_14-42-6', '2006-6-07_11-26-53', '2006-6-08_14-26-15', '2006-6-09_3-23-37', '2021-12-06 Code Backup', '2006-6-09_1-22-43', 'DibaCode', 'KamranMatlabCode', '2006-6-12_15-55-31']\n",
      "basedir: /media/MAX/Data/KDIBA/gor01/one/2006-6-07_11-26-53\n",
      "Skipping loading from pickled file because force_reload == True.\n",
      "Must reload/rebuild.\n",
      "NeuropyPipeline.on_stage_changed(new_stage=\"PipelineStage.Input\")\n",
      "Loading matlab import file results to /media/MAX/Data/KDIBA/gor01/one/2006-6-07_11-26-53/2006-6-07_11-26-53.epochs_info.mat... done.\n",
      "Loading matlab import file results to /media/MAX/Data/KDIBA/gor01/one/2006-6-07_11-26-53/2006-6-07_11-26-53.position_info.mat... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/halechr/repos/NeuroPy/neuropy/core/session/Formats/SessionSpecifications.py:139: UserWarning: WARNING: Optional File: /media/MAX/Data/KDIBA/gor01/one/2006-6-07_11-26-53/2006-6-07_11-26-53.dat does not exist. Continuing without it.\n",
      "  warnings.warn(f'WARNING: Optional File: {an_optional_filepath} does not exist. Continuing without it.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Loading matlab import file results to /media/MAX/Data/KDIBA/gor01/one/2006-6-07_11-26-53/2006-6-07_11-26-53.spikes.mat... done.\n",
      "Failure loading .position.npy. Must recompute.\n",
      "\n",
      "Computing linear positions for all active epochs for session... Saving updated position results results to /media/MAX/Data/KDIBA/gor01/one/2006-6-07_11-26-53/2006-6-07_11-26-53.position.npy... 2006-6-07_11-26-53.position.npy saved\n",
      "done.\n",
      "\t force_recompute is True! Forcing recomputation of .interpolated_spike_positions.npy\n",
      "\n",
      "Computing interpolate_spike_positions columns results to spikes_df... done.\n",
      "\t Saving updated interpolated spike position results results to /media/MAX/Data/KDIBA/gor01/one/2006-6-07_11-26-53/2006-6-07_11-26-53.interpolated_spike_positions.npy... 2006-6-07_11-26-53.interpolated_spike_positions.npy saved\n",
      "done.\n",
      "Loading matlab import file results to /media/MAX/Data/KDIBA/gor01/one/2006-6-07_11-26-53/2006-6-07_11-26-53.laps_info.mat... done.\n",
      "setting laps object.\n",
      "session.laps loaded successfully!\n",
      "Loading matlab import file results to /media/MAX/Data/KDIBA/gor01/one/2006-6-07_11-26-53/2006-6-07_11-26-53.replay_info.mat... done.\n",
      "session.replays loaded successfully!\n",
      "Loading success: /media/MAX/Data/KDIBA/gor01/one/2006-6-07_11-26-53/ripple_df.pkl.\n",
      "Loading success: .mua.npy.\n",
      "Loading success: .pbe.npy.\n",
      "Computing spikes_df PBEs column results to spikes_df... done.\n",
      "Computing added spike scISI column results to spikes_df... done.\n",
      "NeuropyPipeline.on_stage_changed(new_stage=\"PipelineStage.Loaded\")\n",
      "skip_save is True so resultant pipeline will not be saved to the pickle file.\n",
      "global_named_timerange: <NamedTimerange: {'name': 'maze', 'start_end_times': [0.0, 1932.4200048116618]};>, first_included_epoch_name: maze1, last_included_epoch_name: maze2\n",
      "active_session_filter_configurations: {'maze1': <function DataSessionFormatBaseRegisteredClass.build_default_filter_functions.<locals>.<dictcomp>.<lambda> at 0x7fb3bb7e0670>, 'maze2': <function DataSessionFormatBaseRegisteredClass.build_default_filter_functions.<locals>.<dictcomp>.<lambda> at 0x7fb3bb7e05e0>, 'maze': <function DataSessionFormatBaseRegisteredClass.build_global_epoch_filter_config_dict.<locals>.<lambda> at 0x7fb3bbb98040>}\n",
      "NeuropyPipeline.on_stage_changed(new_stage=\"PipelineStage.Computed\")\n",
      "Applying session filter named \"maze1\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1739.1533641185379)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze2\"...\n",
      "Constraining to epoch with times (start: 1739.1533641185379, end: 1932.4200048116618)\n",
      "computing neurons mua for session...\n",
      "\n",
      "Applying session filter named \"maze\"...\n",
      "Constraining to epoch with times (start: 0.0, end: 1932.4200048116618)\n",
      "computing neurons mua for session...\n",
      "\n",
      "due to whitelist, including only 6 out of 14 registered computation functions.\n",
      "Recomputing active_epoch_placefields... \t done.\n",
      "Recomputing active_epoch_placefields2D... \t done.\n",
      "Recomputing active_epoch_time_dependent_placefields... \t done.\n",
      "Recomputing active_epoch_time_dependent_placefields2D... \t done.\n",
      "WARNING: _setup_time_bin_spike_counts_N_i(): updating self.time_window_edges and self.time_window_edges_binning_info ...\n",
      "from ._setup_time_bin_spike_counts_N_i():\n",
      "\ttime_window_edges.shape: (52180,)\n",
      "unit_specific_time_binned_spike_counts.shape: (64, 52179)\n"
     ]
    }
   ],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Load Data                                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "# %%viztracer\n",
    "active_data_mode_name = 'kdiba'\n",
    "active_data_mode_registered_class = active_data_session_types_registered_classes_dict[active_data_mode_name]\n",
    "active_data_mode_type_properties = known_data_session_type_properties_dict[active_data_mode_name]\n",
    "\n",
    "## Data must be pre-processed using the MATLAB script located here: \n",
    "#     neuropy/data_session_pre_processing_scripts/KDIBA/IIDataMat_Export_ToPython_2022_08_01.m\n",
    "# From pre-computed .mat files:\n",
    "\n",
    "local_session_root_parent_path = global_data_root_parent_path.joinpath('KDIBA')\n",
    "\n",
    "## Animal `gor01`:\n",
    "local_session_parent_path = local_session_root_parent_path.joinpath('gor01', 'one')\n",
    "local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=['PhoHelpers', 'Spike3D-Minimal-Test', 'Unused'])\n",
    "\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath('gor01', 'two')\n",
    "# local_session_paths_list, local_session_names_list =  _find_local_session_paths(local_session_parent_path, blacklist=[])\n",
    "    \n",
    "# ### Animal `vvp01`:\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath('vvp01', 'one')\n",
    "# local_session_paths_list, local_session_names_list =  _find_local_session_paths(local_session_parent_path, blacklist=[])\n",
    "\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath('vvp01', 'two')\n",
    "# local_session_paths_list, local_session_names_list =  _find_local_session_paths(local_session_parent_path, blacklist=[])\n",
    "\n",
    "# local_session_paths_list = [local_session_parent_path.joinpath(a_name).resolve() for a_name in local_session_names_list]\n",
    "basedir = local_session_paths_list[1] # NOT 3\n",
    "print(f'basedir: {str(basedir)}')\n",
    "\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "curr_active_pipeline = NeuropyPipeline.try_init_from_saved_pickle_or_reload_if_needed(active_data_mode_name, active_data_mode_type_properties, override_basepath=Path(basedir), override_post_load_functions=[], force_reload=False, active_pickle_filename='loadedSessPickle.pkl', skip_save=True)\n",
    "active_session_filter_configurations = active_data_mode_registered_class.build_default_filter_functions(sess=curr_active_pipeline.sess, epoch_name_whitelist=['maze1','maze2','maze']) # build_filters_pyramidal_epochs(sess=curr_kdiba_pipeline.sess)\n",
    "# active_session_filter_configurations = active_data_mode_registered_class.build_filters_pyramidal_epochs(sess=curr_active_pipeline.sess, epoch_name_whitelist=['maze','maze1','maze2'])\n",
    "# active_session_filter_configurations = active_data_mode_registered_class.build_filters_pyramidal_epochs(sess=curr_active_pipeline.sess, epoch_name_whitelist=['maze1','maze2'])\n",
    "# active_session_filter_configurations = active_data_mode_registered_class.build_filters_pyramidal_epochs(sess=curr_active_pipeline.sess, epoch_name_whitelist=['maze1'])\n",
    "# active_session_filter_configurations = active_data_mode_registered_class.build_filters_pyramidal_epochs(sess=curr_active_pipeline.sess, epoch_name_whitelist=['maze2'])\n",
    "print(f'active_session_filter_configurations: {active_session_filter_configurations}')\n",
    "\n",
    "# sess.epochs.t_start = 22.26 # exclude the first short period where the animal isn't on the maze yet\n",
    "# active_session_filter_configurations = {'maze1': lambda x: (x.filtered_by_epoch(x.epochs.get_named_timerange('maze1')), x.epochs.get_named_timerange('maze1')),\n",
    "#     'maze2': lambda x: (x.filtered_by_epoch(x.epochs.get_named_timerange('maze2')), x.epochs.get_named_timerange('maze2')),\n",
    "#     'maze': lambda x: (x.filtered_by_epoch(NamedTimerange(name='maze', start_end_times=[x.epochs['maze1'][0], x.epochs['maze2'][1]])), NamedTimerange(name='maze', start_end_times=[x.epochs['maze1'][0], x.epochs['maze2'][1]]))\n",
    "# }\n",
    "\n",
    "active_session_computation_configs = active_data_mode_registered_class.build_default_computation_configs(sess=curr_active_pipeline.sess, time_bin_size=0.03333) #1.0/30.0 # decode at 30fps to match the position sampling frequency\n",
    "# active_session_computation_configs[0].pf_params.smooth = (0.0, 0.0)\n",
    "# active_session_computation_configs = build_eloy_computation_configs(sess=curr_active_pipeline.sess)\n",
    "curr_active_pipeline.filter_sessions(active_session_filter_configurations) ## NOTE: BUG: TODO: this fails when the pipeline is loaded if the active_session_filter_configurations were initially defined in the notebook itself (because it can't get the source code).\n",
    "\n",
    "# Whitelist Mode:\n",
    "computation_functions_name_whitelist=['_perform_baseline_placefield_computation', '_perform_time_dependent_placefield_computation', '_perform_extended_statistics_computation',\n",
    "                                        '_perform_position_decoding_computation', \n",
    "                                        '_perform_firing_rate_trends_computation',\n",
    "                                        '_perform_pf_find_ratemap_peaks_computation',\n",
    "                                        # '_perform_two_step_position_decoding_computation',\n",
    "                                        # '_perform_recursive_latent_placefield_decoding'\n",
    "                                     ]  # '_perform_pf_find_ratemap_peaks_peak_prominence2d_computation'\n",
    "computation_functions_name_blacklist=None\n",
    "\n",
    "# # Blacklist Mode:\n",
    "# computation_functions_name_whitelist=None\n",
    "# computation_functions_name_blacklist=['_perform_spike_burst_detection_computation','_perform_recursive_latent_placefield_decoding']\n",
    "\n",
    "curr_active_pipeline.perform_computations(active_session_computation_configs[0], computation_functions_name_whitelist=computation_functions_name_whitelist, computation_functions_name_blacklist=computation_functions_name_blacklist, fail_on_exception=True, debug_print=False) #, overwrite_extant_results=False  ], fail_on_exception=True, debug_print=False)\n",
    "\n",
    "# curr_active_pipeline.perform_computations(active_session_computation_configs[0], computation_functions_name_blacklist=['_perform_spike_burst_detection_computation'], debug_print=False, fail_on_exception=False) # whitelist: ['_perform_baseline_placefield_computation']\n",
    "\n",
    "curr_active_pipeline.prepare_for_display(root_output_dir=global_data_root_parent_path.joinpath('Output'), should_smooth_maze=True) # TODO: pass a display config\n",
    "\n",
    "curr_active_pipeline.save_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452f7f79-d631-4f8a-82e4-0ba1b17d8391",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb on\n",
    "## üó®Ô∏èüü¢ 2022-10-26 - Jonathan Firing Rate Analyses\n",
    "# ==================================================================================================================== #\n",
    "# Perform missing global computations                                                                                  #\n",
    "# ==================================================================================================================== #\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_jonathan_replay_firing_rate_analyses', '_perform_short_long_pf_overlap_analyses'], fail_on_exception=True, debug_print=True)\n",
    "\n",
    "## Get global 'jonathan_firing_rate_analysis' results:\n",
    "curr_jonathan_firing_rate_analysis = curr_active_pipeline.global_computation_results.computed_data['jonathan_firing_rate_analysis']\n",
    "neuron_replay_stats_df, rdf, aclu_to_idx, irdf = curr_jonathan_firing_rate_analysis['neuron_replay_stats_df'], curr_jonathan_firing_rate_analysis['rdf']['rdf'], curr_jonathan_firing_rate_analysis['rdf']['aclu_to_idx'], curr_jonathan_firing_rate_analysis['irdf']['irdf']\n",
    "neuron_replay_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9345b2c5-8a0c-4c09-8880-5b16283bf20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = curr_active_pipeline.sess\n",
    "# replays_df = sess.replay\n",
    "# replays_df = sess.pbe.to_dataframe()\n",
    "replays_df = sess.ripple.to_dataframe()\n",
    "replays_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f86c01e-ca65-4886-a0e8-aa9ec2848b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.paradigm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5e4e21-3704-4ef3-a72e-49cad69a6f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.active_configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1ee5ec-36fe-4d56-826f-accf054376ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "d4 = dict(d1, **d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb5cd1d-9cb9-49cb-ba9e-360b51f42547",
   "metadata": {},
   "outputs": [],
   "source": [
    "{k: v for k, v in sorted(curr_active_pipeline.active_configs.items(), key=lambda item: item[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfd5666-42e8-48b7-b4fe-c25c54408d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bedbcd-39cb-4714-8ebe-aa1844c95d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.paradigm[1][0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e3259f-3cfa-4ec4-b709-af8b9d1272c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Batch Output of Figures                                                                                              #\n",
    "# ==================================================================================================================== #\n",
    "## üó®Ô∏èüü¢ 2022-11-05 - Pho-Jonathan Batch Outputs of Firing Rate Figures\n",
    "# %matplotlib qt\n",
    "\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import SplitPartitionMembership\n",
    "short_only_df = neuron_replay_stats_df[neuron_replay_stats_df.track_membership == SplitPartitionMembership.RIGHT_ONLY]\n",
    "short_only_aclus = short_only_df.index.values.tolist()\n",
    "long_only_df = neuron_replay_stats_df[neuron_replay_stats_df.track_membership == SplitPartitionMembership.LEFT_ONLY]\n",
    "long_only_aclus = long_only_df.index.values.tolist()\n",
    "shared_df = neuron_replay_stats_df[neuron_replay_stats_df.track_membership == SplitPartitionMembership.SHARED]\n",
    "shared_aclus = shared_df.index.values.tolist()\n",
    "print(f'shared_aclus: {shared_aclus}')\n",
    "print(f'long_only_aclus: {long_only_aclus}')\n",
    "print(f'short_only_aclus: {short_only_aclus}')\n",
    "\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Output Figures to File                                                                                               #\n",
    "# ==================================================================================================================== #\n",
    "## PDF Output\n",
    "# %matplotlib qtagg\n",
    "import matplotlib\n",
    "# configure backend here\n",
    "# matplotlib.use('Qt5Agg')\n",
    "# backend_qt5agg\n",
    "matplotlib.use('AGG') # non-interactive backend ## 2022-08-16 - Surprisingly this works to make the matplotlib figures render only to .png file, not appear on the screen!\n",
    "\n",
    "n_max_page_rows = 10\n",
    "_batch_plot_kwargs_list = _build_batch_plot_kwargs(long_only_aclus, short_only_aclus, shared_aclus, active_identifying_session_ctx, n_max_page_rows=n_max_page_rows)\n",
    "active_out_figures_list = _perform_batch_plot(curr_active_pipeline, _batch_plot_kwargs_list, figures_parent_out_path=None, write_pdf=False, write_png=True, progress_print=True, debug_print=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PhoLabViz]",
   "language": "python",
   "name": "conda-env-PhoLabViz-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
