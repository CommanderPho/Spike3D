{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dd392e0-1cc6-407a-8c0c-18f66153a51b",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8063c28-10a2-4e3d-a524-a09b38b4db06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "build_module_logger(module_name=\"Spike3D.pipeline\"):\n",
      "\t Module logger com.PhoHale.Spike3D.pipeline has file logging enabled and will log to EXTERNAL\\TESTING\\Logging\\debug_com.PhoHale.Spike3D.pipeline.log\n"
     ]
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "%pdb off\n",
    "# %load_ext viztracer\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "from benedict import benedict\n",
    "import numpy as np\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "# %gui qt\n",
    "# !env QT_API=\"pyqt5\"\n",
    "%gui qt5\n",
    "# %gui qt6\n",
    "# from PyQt5.Qt import QApplication\n",
    "# # start qt event loop\n",
    "# _instance = QApplication.instance()\n",
    "# if not _instance:\n",
    "#     _instance = QApplication([])\n",
    "# app = _instance\n",
    "\n",
    "from copy import deepcopy\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from benedict import benedict # https://github.com/fabiocaccamo/python-benedict#usage\n",
    "\n",
    "# Pho's Formatting Preferences\n",
    "# from pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\n",
    "# set_pho_preferences_concise()\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.general_helpers import CodeConversion\n",
    "from pyphocorehelpers.print_helpers import print_keys_if_possible, print_value_overview_only, document_active_variables\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "# from neuropy import core\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.core.epoch import NamedTimerange\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder\n",
    "from neuropy.core.session.Formats.Specific.BapunDataSessionFormat import BapunDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.core.session.Formats.Specific.RachelDataSessionFormat import RachelDataSessionFormat\n",
    "from neuropy.core.session.Formats.Specific.HiroDataSessionFormat import HiroDataSessionFormatRegisteredClass\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import find_local_session_paths\n",
    "\n",
    "# from PendingNotebookCode import _perform_batch_plot, _build_batch_plot_kwargs\n",
    "from pyphoplacecellanalysis.General.NonInteractiveWrapper import batch_load_session, SessionBatchProgress, batch_programmatic_figures, batch_extended_programmatic_figures\n",
    "\n",
    "session_batch_status = {}\n",
    "enable_saving_to_disk = False\n",
    "\n",
    "global_data_root_parent_path = Path(r'W:\\Data') # Windows Apogee\n",
    "# global_data_root_parent_path = Path(r'/media/MAX/Data') # Diba Lab Workstation Linux\n",
    "# global_data_root_parent_path = Path(r'/Volumes/MoverNew/data') # rMBP\n",
    "assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fde1ef-b6bc-4500-866e-00a69be7f8de",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9983bae-c681-4fed-a552-e59630485b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local_session_names_list: ['2006-6-07_11-26-53', '2006-6-08_14-26-15', '2006-6-09_1-22-43', '2006-6-09_3-23-37', '2006-6-12_15-55-31', '2006-6-13_14-42-6']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-07_11-26-53'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-08_14-26-15'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-09_3-23-37'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-12_15-55-31'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>,\n",
       " WindowsPath('W:/Data/KDIBA/gor01/one/2006-6-13_14-42-6'): <SessionBatchProgress.NOT_STARTED: 'NOT_STARTED'>}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Load Data                                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "active_data_mode_name = 'kdiba'\n",
    "\n",
    "## Data must be pre-processed using the MATLAB script located here: \n",
    "#     neuropy/data_session_pre_processing_scripts/KDIBA/IIDataMat_Export_ToPython_2022_08_01.m\n",
    "# From pre-computed .mat files:\n",
    "\n",
    "local_session_root_parent_context = IdentifyingContext(format_name=active_data_mode_name) # , animal_name='', configuration_name='one', session_name=self.session_name\n",
    "local_session_root_parent_path = global_data_root_parent_path.joinpath('KDIBA')\n",
    "\n",
    "## Animal `gor01`:\n",
    "local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='gor01', exper_name='one') # IdentifyingContext<('kdiba', 'gor01', 'one')>\n",
    "local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name) # 'gor01', 'one'\n",
    "local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=['PhoHelpers', 'Spike3D-Minimal-Test', 'Unused'])\n",
    "\n",
    "# local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='gor01', exper_name='two')\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name)\n",
    "# local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=[])\n",
    "\n",
    "### Animal `vvp01`:\n",
    "# local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='vvp01', exper_name='one')\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name)\n",
    "# local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=[])\n",
    "\n",
    "# local_session_parent_context = local_session_root_parent_context.adding_context(collision_prefix='animal', animal='vvp01', exper_name='two')\n",
    "# local_session_parent_path = local_session_root_parent_path.joinpath(local_session_parent_context.animal, local_session_parent_context.exper_name)\n",
    "# local_session_paths_list, local_session_names_list =  find_local_session_paths(local_session_parent_path, blacklist=[])\n",
    "\n",
    "## Build session contexts list:\n",
    "local_session_contexts_list = [local_session_parent_context.adding_context(collision_prefix='sess', session_name=a_name) for a_name in local_session_names_list] # [IdentifyingContext<('kdiba', 'gor01', 'one', '2006-6-07_11-26-53')>, ..., IdentifyingContext<('kdiba', 'gor01', 'one', '2006-6-13_14-42-6')>]\n",
    "\n",
    "## Initialize `session_batch_status` with the NOT_STARTED status if it doesn't already have a different status\n",
    "for curr_session_basedir in local_session_paths_list:\n",
    "    curr_session_status = session_batch_status.get(curr_session_basedir, None)\n",
    "    if curr_session_status is None:\n",
    "        session_batch_status[curr_session_basedir] = SessionBatchProgress.NOT_STARTED # set to not started if not present\n",
    "        # session_batch_status[curr_session_basedir] = SessionBatchProgress.COMPLETED # set to not started if not present\n",
    "        \n",
    "\n",
    "session_batch_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd04382a-07bb-4270-a3c5-7ca0c0a71518",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Run batch queue\n",
    "for curr_sess_ctx, curr_session_basedir, curr_session_name in zip(local_session_contexts_list, local_session_paths_list, local_session_names_list):\n",
    "    print(f'curr_session_basedir: {str(curr_session_basedir)}')\n",
    "    curr_session_status = session_batch_status.get(curr_session_basedir, None)\n",
    "    if curr_session_status.name != SessionBatchProgress.COMPLETED.name:\n",
    "        session_batch_status[curr_session_basedir] = SessionBatchProgress.NOT_STARTED\n",
    "        try:\n",
    "            session_batch_status[curr_session_basedir] = SessionBatchProgress.RUNNING\n",
    "            curr_active_pipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, curr_session_basedir, force_reload=False)\n",
    "            active_identifying_session_ctx, active_session_figures_out_path, active_out_figures_list = batch_programmatic_figures(curr_active_pipeline)\n",
    "            batch_extended_programmatic_figures(curr_active_pipeline)\n",
    "            session_batch_status[curr_session_basedir] = SessionBatchProgress.COMPLETED\n",
    "            print(f'completed processing for {curr_session_basedir}: {active_identifying_session_ctx}')\n",
    "        except Exception as e:\n",
    "            print(f'ERROR processing {curr_session_basedir} with error {e}')\n",
    "            session_batch_status[curr_session_basedir] = SessionBatchProgress.ABORTED\n",
    "            # raise e\n",
    "    else:\n",
    "        print(f'\\t already completed')\n",
    "\n",
    "print(f'session_batch_status: {session_batch_status}')\n",
    "print('!!! done running batch !!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ab8feb-f917-4ac4-be40-20083a25f005",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ðŸŸ¢ Single basedir (non-batch) testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cba147e2-ff54-49c8-8229-8fe69391fad7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basedir: W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\n",
      "Loading loaded session pickle file results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\loadedSessPickle.pkl... WARNING: failed to unpickle PfND_TimeDependent - just resetting. Snapshots will not be loaded.\n",
      "WARNING: failed to unpickle PfND_TimeDependent - just resetting. Snapshots will not be loaded.\n",
      "WARNING: failed to unpickle PfND_TimeDependent - just resetting. Snapshots will not be loaded.\n",
      "WARNING: failed to unpickle PfND_TimeDependent - just resetting. Snapshots will not be loaded.\n",
      "WARNING: failed to unpickle PfND_TimeDependent - just resetting. Snapshots will not be loaded.\n",
      "WARNING: failed to unpickle PfND_TimeDependent - just resetting. Snapshots will not be loaded.\n",
      "done.\n",
      "Loading pickled pipeline success: W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\loadedSessPickle.pkl.\n",
      "property already present in pickled version. No need to save.\n",
      "is_common_filter_name: [ True  True  True]\n",
      "is_novel_filter_name: [False False False]\n",
      "common_filter_names: ['maze1' 'maze2' 'maze']\n",
      "prev_filter_src != active_filter_src\n",
      "prev_filter_src:\n",
      "    def build_global_epoch_filter_config_dict(cls, sess, global_epoch_name='maze', first_included_epoch_name=None, last_included_epoch_name=None, debug_print=False):\n",
      "        \"\"\" builds the 'global' filter for the entire session that includes by default the times from all other epochs in sess. \n",
      "        e.g. builds the 'maze' epoch from ['maze1', 'maze2'] epochs\n",
      "\n",
      "        Usage:\n",
      "            global_epoch_filter_fn_dict, global_named_timerange = build_global_epoch_filter_config_dict(sess, global_epoch_name='maze', first_included_epoch_name=None, last_included_epoch_name=None, debug_print=True)\n",
      "            global_epoch_filter_fn_dict\n",
      "\n",
      "        \"\"\"\n",
      "        all_epoch_names = list(sess.epochs.get_unique_labels()) # all_epoch_names # ['maze1', 'maze2']\n",
      "        if global_epoch_name in all_epoch_names:\n",
      "            global_epoch_name = f\"{global_epoch_name}_GLOBAL\"\n",
      "            print('WARNING: name collision \"{global_epoch_name}\" already exists in all_epoch_names: {all_epoch_names}! Using {global_epoch_name} instead.')\n",
      "        \n",
      "        if first_included_epoch_name is not None:\n",
      "            # global_start_end_times[0] = sess.epochs[first_included_epoch_name][0] # 'maze1'\n",
      "            pass\n",
      "        else:\n",
      "            first_included_epoch_name = sess.epochs.get_unique_labels()[0]\n",
      "            \n",
      "        if last_included_epoch_name is not None:\n",
      "            # global_start_end_times[1] = sess.epochs[last_included_epoch_name][1] # 'maze2'\n",
      "            pass\n",
      "        else:\n",
      "            last_included_epoch_name = sess.epochs.get_unique_labels()[-1]\n",
      "    \n",
      "        # global_start_end_times = [epochs.t_start, epochs.t_stop]\n",
      "        global_start_end_times = [sess.epochs[first_included_epoch_name][0], sess.epochs[last_included_epoch_name][1]]\n",
      "        # global_start_end_times_fn = lambda x: [sess.epochs[first_included_epoch_name][0], sess.epochs[last_included_epoch_name][1]]\n",
      "        \n",
      "        global_named_timerange = NamedTimerange(name=global_epoch_name, start_end_times=global_start_end_times)\n",
      "        # global_epoch_filter_fn = (lambda x: (x.filtered_by_epoch(NamedTimerange(name=global_epoch_name, start_end_times=[x.epochs['maze1'][0], x.epochs['maze2'][1]])), NamedTimerange(name=global_epoch_name, start_end_times=[x.epochs['maze1'][0], x.epochs['maze2'][1]])))\n",
      "        if debug_print:\n",
      "            print(f'global_named_timerange: {global_named_timerange}, first_included_epoch_name: {first_included_epoch_name}, last_included_epoch_name: {last_included_epoch_name}')\n",
      "        global_epoch_filter_fn = (lambda x: (x.filtered_by_epoch(NamedTimerange(name=global_epoch_name, start_end_times=[x.epochs[(first_included_epoch_name or x.epochs.get_unique_labels()[0])][0], x.epochs[(last_included_epoch_name or x.epochs.get_unique_labels()[-1])][1]])), NamedTimerange(name=global_epoch_name, start_end_times=[x.epochs[(first_included_epoch_name or x.epochs.get_unique_labels()[0])][0], x.epochs[(last_included_epoch_name or x.epochs.get_unique_labels()[-1])][1]])))\n",
      "        return {global_epoch_name: global_epoch_filter_fn}, global_named_timerange\n",
      "\n",
      "active_filter_src:\n",
      "        epoch_filter_configs_dict = {f'{an_epoch_name}{filter_name_suffix}':lambda a_sess, epoch_name=an_epoch_name: (a_sess.filtered_by_epoch(a_sess.epochs.get_named_timerange(epoch_name)), a_sess.epochs.get_named_timerange(epoch_name)) for an_epoch_name in epoch_name_whitelist}\n",
      "\n",
      "prev_filter_src != active_filter_src\n",
      "prev_filter_src:\n",
      "    def build_global_epoch_filter_config_dict(cls, sess, global_epoch_name='maze', first_included_epoch_name=None, last_included_epoch_name=None, debug_print=False):\n",
      "        \"\"\" builds the 'global' filter for the entire session that includes by default the times from all other epochs in sess. \n",
      "        e.g. builds the 'maze' epoch from ['maze1', 'maze2'] epochs\n",
      "\n",
      "        Usage:\n",
      "            global_epoch_filter_fn_dict, global_named_timerange = build_global_epoch_filter_config_dict(sess, global_epoch_name='maze', first_included_epoch_name=None, last_included_epoch_name=None, debug_print=True)\n",
      "            global_epoch_filter_fn_dict\n",
      "\n",
      "        \"\"\"\n",
      "        all_epoch_names = list(sess.epochs.get_unique_labels()) # all_epoch_names # ['maze1', 'maze2']\n",
      "        if global_epoch_name in all_epoch_names:\n",
      "            global_epoch_name = f\"{global_epoch_name}_GLOBAL\"\n",
      "            print('WARNING: name collision \"{global_epoch_name}\" already exists in all_epoch_names: {all_epoch_names}! Using {global_epoch_name} instead.')\n",
      "        \n",
      "        if first_included_epoch_name is not None:\n",
      "            # global_start_end_times[0] = sess.epochs[first_included_epoch_name][0] # 'maze1'\n",
      "            pass\n",
      "        else:\n",
      "            first_included_epoch_name = sess.epochs.get_unique_labels()[0]\n",
      "            \n",
      "        if last_included_epoch_name is not None:\n",
      "            # global_start_end_times[1] = sess.epochs[last_included_epoch_name][1] # 'maze2'\n",
      "            pass\n",
      "        else:\n",
      "            last_included_epoch_name = sess.epochs.get_unique_labels()[-1]\n",
      "    \n",
      "        # global_start_end_times = [epochs.t_start, epochs.t_stop]\n",
      "        global_start_end_times = [sess.epochs[first_included_epoch_name][0], sess.epochs[last_included_epoch_name][1]]\n",
      "        # global_start_end_times_fn = lambda x: [sess.epochs[first_included_epoch_name][0], sess.epochs[last_included_epoch_name][1]]\n",
      "        \n",
      "        global_named_timerange = NamedTimerange(name=global_epoch_name, start_end_times=global_start_end_times)\n",
      "        # global_epoch_filter_fn = (lambda x: (x.filtered_by_epoch(NamedTimerange(name=global_epoch_name, start_end_times=[x.epochs['maze1'][0], x.epochs['maze2'][1]])), NamedTimerange(name=global_epoch_name, start_end_times=[x.epochs['maze1'][0], x.epochs['maze2'][1]])))\n",
      "        if debug_print:\n",
      "            print(f'global_named_timerange: {global_named_timerange}, first_included_epoch_name: {first_included_epoch_name}, last_included_epoch_name: {last_included_epoch_name}')\n",
      "        global_epoch_filter_fn = (lambda x: (x.filtered_by_epoch(NamedTimerange(name=global_epoch_name, start_end_times=[x.epochs[(first_included_epoch_name or x.epochs.get_unique_labels()[0])][0], x.epochs[(last_included_epoch_name or x.epochs.get_unique_labels()[-1])][1]])), NamedTimerange(name=global_epoch_name, start_end_times=[x.epochs[(first_included_epoch_name or x.epochs.get_unique_labels()[0])][0], x.epochs[(last_included_epoch_name or x.epochs.get_unique_labels()[-1])][1]])))\n",
      "        return {global_epoch_name: global_epoch_filter_fn}, global_named_timerange\n",
      "\n",
      "active_filter_src:\n",
      "        epoch_filter_configs_dict = {f'{an_epoch_name}{filter_name_suffix}':lambda a_sess, epoch_name=an_epoch_name: (a_sess.filtered_by_epoch(a_sess.epochs.get_named_timerange(epoch_name)), a_sess.epochs.get_named_timerange(epoch_name)) for an_epoch_name in epoch_name_whitelist}\n",
      "\n",
      "prev_filter_src != active_filter_src\n",
      "prev_filter_src:\n",
      "    def get_registry_known_data_session_type_dict(cls, override_data_basepath=None):\n",
      "        \"\"\" returns a dict<str, KnownDataSessionTypeProperties> with keys corresponding to the registered short-names of the data_session_type (like 'kdiba', or 'bapun') and values of KnownDataSessionTypeProperties. \"\"\"\n",
      "        return {a_class._session_class_name:a_class.get_known_data_session_type_properties(override_basepath=override_data_basepath) for a_class_name, a_class in cls.get_registry().items() if a_class_name != 'DataSessionFormatBaseRegisteredClass'}\n",
      "\n",
      "active_filter_src:\n",
      "        global_epoch_filter_fn = (lambda x: (x.filtered_by_epoch(NamedTimerange(name=global_epoch_name, start_end_times=[x.epochs[(first_included_epoch_name or x.epochs.get_unique_labels()[0])][0], x.epochs[(last_included_epoch_name or x.epochs.get_unique_labels()[-1])][1]])), NamedTimerange(name=global_epoch_name, start_end_times=[x.epochs[(first_included_epoch_name or x.epochs.get_unique_labels()[0])][0], x.epochs[(last_included_epoch_name or x.epochs.get_unique_labels()[-1])][1]])))\n",
      "\n",
      "changed_filters_names_list: ['maze1', 'maze2', 'maze']\n",
      "WARNING: changed_filters_names_list > 0!: ['maze1', 'maze2', 'maze'] but these filters are in the changed_filters_ignore_list: ['maze1', 'maze2', 'maze']\n",
      "ignored_changed_filters_list: ['maze1', 'maze2', 'maze']\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze1] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the blacklist/whitelist or computation function definitions change. Rework so that this is smarter.\n",
      "updating computation_results...\n",
      "done.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze2] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the blacklist/whitelist or computation function definitions change. Rework so that this is smarter.\n",
      "updating computation_results...\n",
      "done.\n",
      "WARNING: skipping computation because overwrite_extant_results=False and active_computation_results[maze] already exists and is non-None\n",
      "\t TODO: this will prevent recomputation even when the blacklist/whitelist or computation function definitions change. Rework so that this is smarter.\n",
      "updating computation_results...\n",
      "done.\n",
      "finalized_loaded_sess_pickle_path: W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\loadedSessPickle.pkl\n",
      "Saving (file mode 'w+b') saved session pickle file results : W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\20221214165739-loadedSessPickle.pkl... done.\n",
      "moving new output at 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\20221214165739-loadedSessPickle.pkl' -> to desired location: 'W:\\Data\\KDIBA\\gor01\\one\\2006-6-08_14-26-15\\loadedSessPickle.pkl'\n"
     ]
    }
   ],
   "source": [
    "# %pdb on\n",
    "basedir = local_session_paths_list[1] # NOT 3\n",
    "print(f'basedir: {str(basedir)}')\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "curr_active_pipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, skip_save=False, force_reload=False)\n",
    "## SAVE AFTERWARDS!\n",
    "# curr_active_pipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, skip_save=False, force_reload=False, active_pickle_filename='loadedSessPickle - full-good.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0500d00a-ae74-4ce0-897d-72d30007f92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_identifying_session_ctx, curr_session_figures_out_path, active_out_figures_list = batch_programmatic_figures(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af76646b-2701-442e-84b3-14ffcf3c0c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_extended_programmatic_figures(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec4e913-d02a-40bd-9a9d-d109af03c087",
   "metadata": {
    "tags": []
   },
   "source": [
    "###  Compute Required Global Computations Manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "608c93b2-9869-48cb-8980-c3dbebad9814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_computation_results is None. Building initial global_computation_results...\n",
      "Performing _execute_computation_functions(...) with 2 registered_computation_functions...\n",
      "include_whitelist: ['maze1', 'maze2', 'maze']\n",
      "long_epoch_name: maze1, short_epoch_name: maze2, global_epoch_name: maze\n",
      "Time window 375 has no spikes.\n",
      "Time window 690 has no spikes.\n",
      "include_whitelist: ['maze1', 'maze2', 'maze']\n",
      "long_epoch_name: maze1, short_epoch_name: maze2, global_epoch_name: maze\n",
      "_execute_computation_functions(...): \n",
      "\taccumulated_errors: None\n",
      "shared_aclus: [3, 5, 6, 7, 9, 10, 11, 12, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108]\n",
      "long_only_aclus: [2, 8, 16, 97, 105, 109]\n",
      "short_only_aclus: [4, 13, 58]\n"
     ]
    }
   ],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Perform missing global computations                                                                                  #\n",
    "# ==================================================================================================================== #\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_jonathan_replay_firing_rate_analyses', '_perform_short_long_pf_overlap_analyses'], fail_on_exception=True, debug_print=True) # \n",
    "\n",
    "## Get global 'jonathan_firing_rate_analysis' results:\n",
    "curr_jonathan_firing_rate_analysis = curr_active_pipeline.global_computation_results.computed_data['jonathan_firing_rate_analysis']\n",
    "neuron_replay_stats_df, rdf, aclu_to_idx, irdf = curr_jonathan_firing_rate_analysis['neuron_replay_stats_df'], curr_jonathan_firing_rate_analysis['rdf']['rdf'], curr_jonathan_firing_rate_analysis['rdf']['aclu_to_idx'], curr_jonathan_firing_rate_analysis['irdf']['irdf']\n",
    "\n",
    "## Get global `short_long_pf_overlap_analyses` results:\n",
    "short_long_pf_overlap_analyses = curr_active_pipeline.global_computation_results.computed_data.short_long_pf_overlap_analyses\n",
    "conv_overlap_dict = short_long_pf_overlap_analyses['conv_overlap_dict']\n",
    "conv_overlap_scalars_df = short_long_pf_overlap_analyses['conv_overlap_scalars_df']\n",
    "prod_overlap_dict = short_long_pf_overlap_analyses['product_overlap_dict']\n",
    "relative_entropy_overlap_dict = short_long_pf_overlap_analyses['relative_entropy_overlap_dict']\n",
    "relative_entropy_overlap_scalars_df = short_long_pf_overlap_analyses['relative_entropy_overlap_scalars_df']\n",
    "\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import SplitPartitionMembership\n",
    "short_only_df = neuron_replay_stats_df[neuron_replay_stats_df.track_membership == SplitPartitionMembership.RIGHT_ONLY]\n",
    "short_only_aclus = short_only_df.index.values.tolist()\n",
    "long_only_df = neuron_replay_stats_df[neuron_replay_stats_df.track_membership == SplitPartitionMembership.LEFT_ONLY]\n",
    "long_only_aclus = long_only_df.index.values.tolist()\n",
    "shared_df = neuron_replay_stats_df[neuron_replay_stats_df.track_membership == SplitPartitionMembership.SHARED]\n",
    "shared_aclus = shared_df.index.values.tolist()\n",
    "print(f'shared_aclus: {shared_aclus}')\n",
    "print(f'long_only_aclus: {long_only_aclus}')\n",
    "print(f'short_only_aclus: {short_only_aclus}')\n",
    "\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04fad059-542b-4653-ac50-6b851827ed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_time_dependent_pf_sequential_surprise_computation', '_perform_firing_rate_trends_computation'], enabled_filter_names=['maze'], fail_on_exception=True, debug_print=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2ed9458-2eb3-49da-81ea-75efe95dae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%viztracer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9d165f3-a996-4140-835d-bf263df664e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n"
     ]
    }
   ],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_firing_rate_trends_computation'], enabled_filter_names=['maze'], fail_on_exception=True, debug_print=False) \n",
    "\n",
    "active_extended_stats = curr_active_pipeline.computation_results['maze'].computed_data['extended_stats']\n",
    "time_binned_pos_df = active_extended_stats['time_binned_position_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0dd042cd-b30d-42fc-aab4-34cf8bb69ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing run_specific_computations_single_context on filtered_session with filter named \"maze\"...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'time_binned_unit_specific_binned_spike_counts'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# %%viztracer\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mcurr_active_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_specific_computation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomputation_functions_name_whitelist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_perform_time_dependent_pf_sequential_surprise_computation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_perform_firing_rate_trends_computation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menabled_filter_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaze\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfail_on_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug_print\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \n\u001b[0;32m      4\u001b[0m active_extended_stats \u001b[38;5;241m=\u001b[39m curr_active_pipeline\u001b[38;5;241m.\u001b[39mcomputation_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaze\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcomputed_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mextended_stats\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m time_binned_pos_df \u001b[38;5;241m=\u001b[39m active_extended_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_binned_position_df\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\users\\pho\\repos\\pyphoplacecellanalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:715\u001b[0m, in \u001b[0;36mPipelineWithComputedPipelineStageMixin.perform_specific_computation\u001b[1;34m(self, active_computation_params, enabled_filter_names, computation_functions_name_whitelist, fail_on_exception, debug_print)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;124;03m\"\"\" perform a specific computation (specified in computation_functions_name_whitelist) in a minimally destructive manner using the previously recomputed results:\u001b[39;00m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;124;03mPassthrough wrapper to self.stage.perform_specific_computation(...) with the same arguments.\u001b[39;00m\n\u001b[0;32m    710\u001b[0m \n\u001b[0;32m    711\u001b[0m \u001b[38;5;124;03mUpdates:\u001b[39;00m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;124;03m    curr_active_pipeline.computation_results\u001b[39;00m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# self.stage is of type ComputedPipelineStage\u001b[39;00m\n\u001b[1;32m--> 715\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_specific_computation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactive_computation_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactive_computation_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menabled_filter_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menabled_filter_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomputation_functions_name_whitelist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomputation_functions_name_whitelist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfail_on_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfail_on_exception\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug_print\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug_print\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\pho\\repos\\pyphoplacecellanalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:430\u001b[0m, in \u001b[0;36mComputedPipelineStage.perform_specific_computation\u001b[1;34m(self, active_computation_params, enabled_filter_names, computation_functions_name_whitelist, fail_on_exception, debug_print)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;66;03m## Here is an issue, we need to get the appropriate computation result depending on whether it's global or not \u001b[39;00m\n\u001b[0;32m    429\u001b[0m previous_computation_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomputation_results[a_select_config_name]\n\u001b[1;32m--> 430\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomputation_results[a_select_config_name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_specific_computations_single_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprevious_computation_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomputation_functions_name_whitelist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomputation_functions_name_whitelist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mare_global\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfail_on_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfail_on_exception\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug_print\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug_print\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\pho\\repos\\pyphoplacecellanalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:232\u001b[0m, in \u001b[0;36mComputedPipelineStage.run_specific_computations_single_context\u001b[1;34m(self, previous_computation_result, computation_functions_name_whitelist, fail_on_exception, progress_logger_callback, are_global, debug_print)\u001b[0m\n\u001b[0;32m    230\u001b[0m     progress_logger_callback(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrun_specific_computations_single_context(including only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(active_computation_functions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m out of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mregistered_computation_function_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m registered computation functions): active_computation_functions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactive_computation_functions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    231\u001b[0m \u001b[38;5;66;03m# Perform the computations:\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mComputedPipelineStage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_computation_functions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactive_computation_functions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprevious_computation_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprevious_computation_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfail_on_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfail_on_exception\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_logger_callback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_logger_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mare_global\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mare_global\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug_print\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug_print\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\pho\\repos\\pyphoplacecellanalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:475\u001b[0m, in \u001b[0;36mComputedPipelineStage._execute_computation_functions\u001b[1;34m(active_computation_functions, previous_computation_result, fail_on_exception, progress_logger_callback, are_global, debug_print)\u001b[0m\n\u001b[0;32m    472\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fail_on_exception:\n\u001b[0;32m    473\u001b[0m     \u001b[38;5;66;03m## normal version that fails on any exception:\u001b[39;00m\n\u001b[0;32m    474\u001b[0m     composed_registered_computations_function \u001b[38;5;241m=\u001b[39m compose_functions(\u001b[38;5;241m*\u001b[39mactive_computation_functions, progress_logger\u001b[38;5;241m=\u001b[39mprogress_logger_callback, error_logger\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;66;03m# functions are composed left-to-right\u001b[39;00m\n\u001b[1;32m--> 475\u001b[0m     previous_computation_result \u001b[38;5;241m=\u001b[39m \u001b[43mcomposed_registered_computations_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprevious_computation_result\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m     accumulated_errors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;66;03m## Use exception-tolerant version of function composition (functions are composed left-to-right):\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\pho\\repos\\pyphocorehelpers\\src\\pyphocorehelpers\\function_helpers.py:30\u001b[0m, in \u001b[0;36mcompose_functions.<locals>._\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m progress_logger \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     29\u001b[0m         progress_logger(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExecuting [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_num_funcs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\users\\pho\\repos\\pyphoplacecellanalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\ExtendedStats.py:132\u001b[0m, in \u001b[0;36mExtendedStatsComputations._perform_time_dependent_pf_sequential_surprise_computation\u001b[1;34m(computation_result, debug_print)\u001b[0m\n\u001b[0;32m    129\u001b[0m active_firing_rate_trends \u001b[38;5;241m=\u001b[39m computation_result\u001b[38;5;241m.\u001b[39mcomputed_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiring_rate_trends\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    130\u001b[0m time_bin_size_seconds, pf_included_spikes_only \u001b[38;5;241m=\u001b[39m active_firing_rate_trends[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_bin_size_seconds\u001b[39m\u001b[38;5;124m'\u001b[39m], active_firing_rate_trends[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpf_included_spikes_only\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 132\u001b[0m active_time_binning_container, active_time_binned_unit_specific_binned_spike_counts \u001b[38;5;241m=\u001b[39m pf_included_spikes_only[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_binning_container\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[43mpf_included_spikes_only\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime_binned_unit_specific_binned_spike_counts\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# ZhangReconstructionImplementation._validate_time_binned_spike_rate_df(active_time_binning_container.centers, active_time_binned_unit_specific_binned_spike_counts)\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m## Use appropriate pf_1D_dt:\u001b[39;00m\n\u001b[0;32m    136\u001b[0m active_session, pf_computation_config \u001b[38;5;241m=\u001b[39m computation_result\u001b[38;5;241m.\u001b[39msess, computation_result\u001b[38;5;241m.\u001b[39mcomputation_config\u001b[38;5;241m.\u001b[39mpf_params\n",
      "File \u001b[1;32mc:\\users\\pho\\repos\\pyphocorehelpers\\src\\pyphocorehelpers\\DataStructure\\dynamic_parameters.py:34\u001b[0m, in \u001b[0;36mDynamicParameters.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DynamicParameters\u001b[38;5;241m.\u001b[39mdebug_enabled:\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDynamicParameters.__getitem__(self, key): key \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'time_binned_unit_specific_binned_spike_counts'"
     ]
    }
   ],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_whitelist=['_perform_time_dependent_pf_sequential_surprise_computation'], enabled_filter_names=['maze'], fail_on_exception=True, debug_print=False) \n",
    "active_relative_entropy_results = active_extended_stats['relative_entropy_analyses']\n",
    "post_update_times = active_relative_entropy_results['post_update_times']\n",
    "snapshot_differences_result_dict = active_relative_entropy_results['snapshot_differences_result_dict']\n",
    "time_intervals = active_relative_entropy_results['time_intervals']\n",
    "long_short_rel_entr_curves_frames = active_relative_entropy_results['long_short_rel_entr_curves_frames']\n",
    "short_long_rel_entr_curves_frames = active_relative_entropy_results['short_long_rel_entr_curves_frames']\n",
    "flat_relative_entropy_results = active_relative_entropy_results['flat_relative_entropy_results']\n",
    "flat_jensen_shannon_distance_results = active_relative_entropy_results['flat_jensen_shannon_distance_results']\n",
    "\n",
    "# sequential_surprise:\n",
    "# sequential_surprise = active_extended_stats['sequential_surprise']\n",
    "# post_update_times = sequential_surprise['post_update_times']\n",
    "# pf_overlap_results = sequential_surprise['pf_overlap_results']\n",
    "# flat_relative_entropy_results = sequential_surprise['flat_relative_entropy_results']\n",
    "# flat_jensen_shannon_distance_results = sequential_surprise['flat_jensen_shannon_distance_results'] # flat_jensen_shannon_distance_results\n",
    "# difference_snapshots = sequential_surprise['difference_snapshots']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eef41244-d61b-4fd5-8f73-b95d21407dc7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'active_extended_stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m active_relative_entropy_results \u001b[38;5;241m=\u001b[39m \u001b[43mactive_extended_stats\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelative_entropy_analyses\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      2\u001b[0m post_update_times \u001b[38;5;241m=\u001b[39m active_relative_entropy_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost_update_times\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m snapshot_differences_result_dict \u001b[38;5;241m=\u001b[39m active_relative_entropy_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msnapshot_differences_result_dict\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'active_extended_stats' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d49b39-3a9e-4220-87d8-19a0402e1fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "_perform_relative_entropy_analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ff3858-33f0-466f-83c6-9c43f5d8d8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_time_binned_spiking_activity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562fe302-864e-4ecd-aa0b-ec182d1055e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adda15c4-a7ef-4695-b545-900734ee2db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.computation_results.\n",
    "\n",
    "self.unit_specific_time_binned_spike_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c486c42-15d2-44a8-9d9a-c9dc788fc706",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_binned_pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406a4fc3-42be-4d78-b164-5fef12c3d77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_computations_results = curr_active_pipeline.computation_results['maze']\n",
    "\n",
    "# Index Mapping:\n",
    "curr_neuron_IDs = np.array(curr_computations_results.computed_data['pf2D_Decoder'].neuron_IDs)\n",
    "# curr_neuron_IDXs = curr_computations_results.computed_data['pf2D_Decoder'].neuron_IDXs\n",
    "\n",
    "# # need to filter spike_raster_plt_3d_vedo.cell_ids to only include the ones present in curr_neuron_IDs\n",
    "# is_included_in_computation_result_neuron_IDs = np.isin(active_curve_plotter_3d.cell_ids, curr_neuron_IDs)\n",
    "# included_neuron_ids = active_curve_plotter_3d.cell_ids[is_included_in_computation_result_neuron_IDs]\n",
    "# # excluded_neuron_ids = active_curve_plotter_3d.cell_ids[~is_included_in_computation_result_neuron_IDs]\n",
    "\n",
    "included_neuron_ids = curr_neuron_IDs\n",
    "# Data Mapping:\n",
    "data_values_column_names = [str(an_id) for an_id in included_neuron_ids]\n",
    "\n",
    "proper_time_windows = np.atleast_2d(curr_computations_results.computed_data['pf2D_Decoder'].time_window_centers) \n",
    "proper_time_windows.shape # (1, 62911)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3373a32-72cc-4f88-8bc0-346dad4e2b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: HACK: This is wrong, it should be the time_window_centers, but for some reason there are too few of them now!\n",
    "proper_time_windows = np.atleast_2d(curr_computations_results.computed_data['pf2D_Decoder'].time_window_edges) \n",
    "\n",
    "proper_time_windows.shape # (1, 62912)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff6f02f-dbdc-4aa2-8e1f-5be49c868c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_plot_df = curr_computations_results.computed_data['pf2D_Decoder'].unit_specific_time_binned_spike_counts\n",
    "active_plot_df.shape # (107, 62289)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c2fc66-60d4-4438-b24b-8d97b9b2f4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_plot_df = pd.DataFrame(np.concatenate((proper_time_windows, curr_computations_results.computed_data['pf2D_Decoder'].unit_specific_time_binned_spike_counts)).T, columns=(['t'] + data_values_column_names))\n",
    "active_plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a320d69e-23cc-4c14-b36c-d547757a3c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_relative_entropy_results.shape # (149, 63) - (nSnapshots, nXbins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a986997f-2862-46f9-881d-c4092433fb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_jensen_shannon_distance_results.shape # (149, 63) - (nSnapshots, nXbins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc28ea8-9552-48a4-a976-62c1dd3bdb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_jensen_shannon_distance_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1996503-2b3b-4623-a603-8918e37cb4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "surprise_across_all_positions = np.sum(flat_relative_entropy_results, axis=1) # sum across all position bins\n",
    "# surprise_across_all_positions.shape # (149,) - (nSnapshots)\n",
    "surprise_across_all_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195f181a-9ca6-459f-973b-cfbfbfcb0b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_jensen_shannon_distance_across_all_positions = np.sum(flat_jensen_shannon_distance_results, axis=1) # sum across all position bins\n",
    "flat_jensen_shannon_distance_across_all_positions.shape # (149,) - (nSnapshots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cab241e-2656-46a0-9e14-03ae4701893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_update_times.shape # (149,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf8673a-bac6-404b-a4d7-7242eef630e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_relative_entropy_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cdbdd9-8b43-4497-a351-d3e604ba8a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_overlap_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9a2c34-5cc2-4c42-ab6d-3beb2afd2a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b22f972-13b0-4c72-9d32-8238502d36d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3753fe07-c952-4e9e-b98f-9a757342bfd3",
   "metadata": {},
   "source": [
    "Let $x$ be the position\n",
    "\n",
    "https://notesonai.com/KL+Divergence\n",
    "https://observablehq.com/@stwind/forward-and-reverse-kl-divergences\n",
    "https://notesonai.com/Maximum+Likelihood+Estimation\n",
    "\n",
    "Alternative Measures:\n",
    "    https://notesonai.com/Jensen%E2%80%93Shannon+Divergence - overcomes becoming infinity when the distributions don't overlap\n",
    "\n",
    "https://stats.stackexchange.com/questions/188903/intuition-on-the-kullback-leibler-kl-divergence\n",
    "https://blogs.rstudio.com/ai/posts/2020-02-19-kl-divergence/\n",
    "https://www.linkedin.com/pulse/kl-divergence-some-interesting-facts-niraj-kumar\n",
    "\n",
    "- [ ] Try Wasserstein distance: https://stats.stackexchange.com/questions/351947/whats-the-maximum-value-of-kullback-leibler-kl-divergence/352008#352008\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc27d20-67b4-42ff-80d2-4c9bf7122908",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "def _simple_surprise_plot():\n",
    "    plt.plot(post_update_times, flat_relative_entropy_results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ffdd5a-6108-4cc3-9f32-001d123fa356",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(post_update_times, flat_relative_entropy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329dfa38-76ee-4448-b6bb-13ad76c5dc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(post_update_times.T, surprise_across_all_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455c53f5-26cf-4935-be1e-30ff7d0de486",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(post_update_times.T, flat_jensen_shannon_distance_across_all_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2699a721-61dd-4006-9a9f-cceffa41bf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flat_relative_entropy_results.shape # (1, 63)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c429125-a200-4d1a-937f-6a4c064cfef2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## ðŸŸ¢ 2022-11-21 - 1D Ratemaps Before and After Track change (Long vs. Short track)\n",
    "Working metrics for comparing overlaps of 1D placefields before and after track change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c477bb6d-6d82-40ce-8406-2c95ff878e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb off\n",
    "%matplotlib qt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from pyphocorehelpers.plotting.figure_management import PhoActiveFigureManager2D\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import _find_any_context_neurons, _compare_computation_results\n",
    "from neuropy.utils.colors_util import get_neuron_colors\n",
    "from neuropy.core.neuron_identities import PlotStringBrevityModeEnum\n",
    "\n",
    "from neuropy.analyses.placefields import PfND # for re-binning pf1D\n",
    "\n",
    "from neuropy.plotting.figure import Fig\n",
    "from neuropy.plotting.ratemaps import plot_ratemap_1D\n",
    "\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import build_neurons_color_map\n",
    "\n",
    "\n",
    "\n",
    "def find_epoch_names(curr_active_pipeline):\n",
    "    include_whitelist = curr_active_pipeline.active_completed_computation_result_names # ['maze', 'sprinkle']\n",
    "    long_epoch_name = include_whitelist[0] # 'maze1_PYR'\n",
    "    short_epoch_name = include_whitelist[1] # 'maze2_PYR'\n",
    "    global_epoch_name = include_whitelist[-1] # 'maze_PYR'\n",
    "    return long_epoch_name, short_epoch_name, global_epoch_name\n",
    "    \n",
    "\n",
    "curr_active_pipeline.active_completed_computation_result_names\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = find_epoch_names(curr_active_pipeline)\n",
    "long_results = curr_active_pipeline.computation_results[long_epoch_name]['computed_data']\n",
    "short_results = curr_active_pipeline.computation_results[short_epoch_name]['computed_data']\n",
    "global_results = curr_active_pipeline.computation_results[global_epoch_name]['computed_data']\n",
    "\n",
    "long_pf1D = long_results.pf1D\n",
    "short_pf1D = short_results.pf1D\n",
    "global_pf1D = global_results.pf1D\n",
    "\n",
    "\n",
    "curr_active_pipeline.active_completed_computation_result_names\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = find_epoch_names(curr_active_pipeline)\n",
    "long_results = curr_active_pipeline.computation_results[long_epoch_name]['computed_data']\n",
    "short_results = curr_active_pipeline.computation_results[short_epoch_name]['computed_data']\n",
    "global_results = curr_active_pipeline.computation_results[global_epoch_name]['computed_data']\n",
    "\n",
    "long_pf1D = long_results.pf1D\n",
    "short_pf1D = short_results.pf1D\n",
    "global_pf1D = global_results.pf1D\n",
    "\n",
    "## Allow overriding PfND's bins:\n",
    "# TODO: 2022-12-09 - We want to be able to have both long/short track placefields have the same bins. \n",
    "if (len(short_pf1D.xbin) < len(long_pf1D.xbin)):\n",
    "    print(f'short_pf1D will be re-binned to match long_pf1D...')\n",
    "    bak_short_pf1D = deepcopy(short_pf1D) # Backup the original first\n",
    "    xbin, ybin, bin_info, grid_bin = long_pf1D.xbin, long_pf1D.ybin, long_pf1D.bin_info, long_pf1D.config.grid_bin\n",
    "    ## Apply to the short dataframe:\n",
    "    short_pf1D.xbin, short_pf1D.ybin, short_pf1D.bin_info, short_pf1D.config.grid_bin = xbin, ybin, bin_info, grid_bin\n",
    "    ## Updates (replacing) the 'binned_x' (and if 2D 'binned_y') columns to the position dataframe:\n",
    "    short_pf1D._filtered_pos_df, _, _, _ = PfND.build_position_df_discretized_binned_positions(short_pf1D._filtered_pos_df, short_pf1D.config, xbin_values=short_pf1D.xbin, ybin_values=short_pf1D.ybin, debug_print=False) # Finishes setup\n",
    "    short_pf1D.compute() # does compute\n",
    "    print(f'done.') ## Successfully re-bins pf1D:\n",
    "\n",
    "    \n",
    "## get shared neuron info:\n",
    "# this must be done after we rebuild the short_pf1D bins (if we need to) so they continue to match:\n",
    "pf_neurons_diff = _compare_computation_results(long_results.pf1D.ratemap.neuron_ids, short_results.pf1D.ratemap.neuron_ids)\n",
    "\n",
    "shared_aclus = pf_neurons_diff.intersection #.shape (56,)\n",
    "print(f'shared_aclus: {shared_aclus}.\\t np.shape: {np.shape(shared_aclus)}')\n",
    "# curr_any_context_neurons = pf_neurons_diff.either\n",
    "long_only_aclus = pf_neurons_diff.lhs_only\n",
    "short_only_aclus = pf_neurons_diff.rhs_only\n",
    "print(f'long_only_aclus: {long_only_aclus}.\\t np.shape: {np.shape(long_only_aclus)}')\n",
    "print(f'short_only_aclus: {short_only_aclus}.\\t np.shape: {np.shape(short_only_aclus)}')\n",
    "\n",
    "## Get the normalized_tuning_curves only for the shared aclus (that are common across (long/short/global):\n",
    "long_is_included = np.isin(long_pf1D.ratemap.neuron_ids, shared_aclus)  #.shape # (104, 63)\n",
    "long_incl_aclus = np.array(long_pf1D.ratemap.neuron_ids)[long_is_included] #.shape # (98,)\n",
    "long_incl_curves = long_pf1D.ratemap.normalized_tuning_curves[long_is_included]  #.shape # (98, 63)\n",
    "assert long_incl_aclus.shape[0] == long_incl_curves.shape[0] # (98,) == (98, 63)\n",
    "\n",
    "short_is_included = np.isin(short_pf1D.ratemap.neuron_ids, shared_aclus)\n",
    "short_incl_aclus = np.array(short_pf1D.ratemap.neuron_ids)[short_is_included] #.shape (98,)\n",
    "short_incl_curves = short_pf1D.ratemap.normalized_tuning_curves[short_is_included]  #.shape # (98, 40)\n",
    "assert short_incl_aclus.shape[0] == short_incl_curves.shape[0] # (98,) == (98, 63)\n",
    "# assert short_incl_curves.shape[1] == long_incl_curves.shape[1] # short and long should have the same bins\n",
    "\n",
    "global_is_included = np.isin(global_pf1D.ratemap.neuron_ids, shared_aclus)\n",
    "global_incl_aclus = np.array(global_pf1D.ratemap.neuron_ids)[global_is_included] #.shape (98,)\n",
    "global_incl_curves = global_pf1D.ratemap.normalized_tuning_curves[global_is_included]  #.shape # (98, 63)\n",
    "assert global_incl_aclus.shape[0] == global_incl_curves.shape[0] # (98,) == (98, 63)\n",
    "assert global_incl_curves.shape[1] == long_incl_curves.shape[1] # global and long should have the same bins\n",
    "\n",
    "assert np.alltrue(np.isin(long_incl_aclus, short_incl_aclus))\n",
    "assert np.alltrue(np.isin(long_incl_aclus, global_incl_aclus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093c42e4-b5a9-4e8d-bc76-ac4c41bbaa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_results.pf2D_Decoder.time_window_edges.shape # (62912,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ec533c-311e-482a-beb6-2a4d751f7a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac5f589-e2f2-4349-bf29-7495eb0bed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_results.pf2D_Decoder.spikes_df.binned_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6635bef7-3f7b-4d9a-b2d1-f28d48f5b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.MultiContextComputationFunctions import compute_relative_entropy_divergence_overlap\n",
    "\n",
    "relative_entropy_overlap_dict, relative_entropy_overlap_scalars_df = compute_relative_entropy_divergence_overlap(long_results, short_results, debug_print=False)\n",
    "relative_entropy_overlap_scalars_df\n",
    "\n",
    "aclu_keys = [k for k,v in relative_entropy_overlap_dict.items() if v is not None]\n",
    "# len(aclu_keys) # 101\n",
    "short_long_rel_entr_curves = np.vstack([v['short_long_rel_entr_curve'] for k,v in relative_entropy_overlap_dict.items() if v is not None])\n",
    "short_long_rel_entr_curves # .shape # (101, 63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba2cfd7-e192-44ee-8976-44ee4994ff64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PendingNotebookCode import Plot\n",
    "plot = Plot(curr_active_pipeline)\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f131e643-be52-43a3-a79b-6df6529c1ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot._display_1d_placefields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb69475-7add-4c96-afd2-37bb93b27b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot._display_3d_image_plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f721be2-3aa0-4914-8e03-96ae8291ffdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display('_display_1d_placefield_validations', active_session_configuration_context=curr_active_pipeline.filtered_contexts.maze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd809f42-1ab1-4656-b5e5-5fea032347e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(curr_active_pipeline.filtered_contexts.values())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec64c65a-30f6-4007-ba88-c73f565df1de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4213a9ce-5f73-475a-be83-22fea1a4eebc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ðŸš€ðŸ“Œâœ³ï¸â›³ 2022-12-09 Almost got relative entropy working for iterative `pf_1D_dt` (to see how much surprise a given lap, or intra-lap period, generates):\n",
    "\n",
    "ACTIVE FOR MONDAY: \n",
    "Only running into a small issue where I'm not sure what the correct neuron_IDs for the snapshotted-values are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fb3320-21b3-41c4-a1e8-22e68273a3a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Newest way of dropping bad laps:\n",
    "from neuropy.utils.efficient_interval_search import get_non_overlapping_epochs, drop_overlapping\n",
    "from neuropy.core.epoch import Epoch\n",
    "from pyphocorehelpers.print_helpers import print_object_memory_usage  # used in batch_snapshotting(...) to show object memory usage\n",
    "\n",
    "from neuropy.analyses.laps import _build_new_lap_and_intra_lap_intervals # for _perform_time_dependent_pf_sequential_surprise_computation\n",
    "\n",
    "sess = curr_active_pipeline.sess\n",
    "sess, combined_records_list = _build_new_lap_and_intra_lap_intervals(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ceb180-6970-4417-8766-a6f0d517edb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_perform_relative_entropy_analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c5d1ac-1ccd-453f-89b6-00adba4a3784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent\n",
    "\n",
    "global_epoch_name = curr_active_pipeline.active_completed_computation_result_names[-1] # 'maze'\n",
    "global_results = curr_active_pipeline.computation_results[global_epoch_name]['computed_data']\n",
    "\n",
    "## Get existing `pf1D_dt`:\n",
    "active_pf_1D_dt = global_results.pf1D_dt\n",
    "\n",
    "# ## Make new pf_1D_dt:\n",
    "computation_result = curr_active_pipeline.computation_results[global_epoch_name]\n",
    "active_session, pf_computation_config = computation_result.sess, computation_result.computation_config.pf_params\n",
    "active_session_spikes_df, active_pos, computation_config, active_epoch_placefields1D, active_epoch_placefields2D, included_epochs, should_force_recompute_placefields = active_session.spikes_df, active_session.position, pf_computation_config, None, None, pf_computation_config.computation_epochs, True\n",
    "active_pf_1D_dt = PfND_TimeDependent(deepcopy(active_session_spikes_df), deepcopy(active_pos.linear_pos_obj), epochs=included_epochs,\n",
    "                                    speed_thresh=computation_config.speed_thresh, frate_thresh=computation_config.frate_thresh,\n",
    "                                    grid_bin=computation_config.grid_bin, grid_bin_bounds=computation_config.grid_bin_bounds, smooth=computation_config.smooth)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb66068-b670-4eb1-80f4-32dd9d117895",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_out_snapshots = active_pf_1D_dt.batch_snapshotting(combined_records_list, reset_at_start=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7e6104-bbf6-43c6-8609-8eb8d36e282b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_out_snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fdd6a9-63d5-47e6-a8e9-cfd2218b9f53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_object_memory_usage(_out_snapshots) # object size: 11.900370 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dff342-6c92-4827-84da-9f281cf95f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'flat_relative_entropy_results'\n",
    "# pf_overlap_results, flat_relative_entropy_results = compute_snapshot_differences(active_pf_1D_dt)\n",
    "# post_update_times, pf_overlap_results, flat_relative_entropy_results, flat_jensen_shannon_distance_results = compute_snapshot_differences(_out_snapshots)\n",
    "post_update_times, pf_overlap_results, flat_relative_entropy_results, flat_jensen_shannon_distance_results = compute_snapshot_differences(active_pf_1D_dt.historical_snapshots)\n",
    "# relative_entropy_result_dicts_list = [a_val_dict['relative_entropy_result_dict'] for a_val_dict in pf_overlap_results]\n",
    "# long_short_rel_entr_curves_list = [a_val_dict['long_short_rel_entr_curve'] for a_val_dict in relative_entropy_result_dicts_list] # [0].shape # (108, 63) = (n_neurons, n_xbins)\n",
    "# short_long_rel_entr_curves_list = [a_val_dict['short_long_rel_entr_curve'] for a_val_dict in relative_entropy_result_dicts_list]\n",
    "# long_short_rel_entr_curves_frames = np.stack([a_val_dict['long_short_rel_entr_curve'] for a_val_dict in relative_entropy_result_dicts_list]) # build a 3D array (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "# short_long_rel_entr_curves_frames = np.stack([a_val_dict['short_long_rel_entr_curve'] for a_val_dict in relative_entropy_result_dicts_list]) # build a 3D array (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e571080-2b8e-4924-98cc-dc7fdb608be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_relative_entropy_results = np.vstack(flat_relative_entropy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006a3757-a39e-44b3-813b-446b77d41990",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db12532-ba56-4e8f-b64f-bfac5a73afdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eefaffa-d9a6-4499-86a9-03414ae1abad",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_update_times.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a2dd6f-0dfd-42f2-b0e2-7b58268ff22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_relative_entropy_results.shape # (149, 63) (n_windows, n_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2875e1-175a-4b55-b091-83954fee18b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_jensen_shannon_distance_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2082c157-b481-4691-93b7-275fa7f29b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(snapshot_times) # we'll call the time being analyzed between snapshots: t, t+1 the snapshot t+1 since it incldues the contribution of these timepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b14a1f-a885-44e5-8267-78fa04444623",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(post_update_times, flat_relative_entropy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41556e2a-b3c4-4a48-b34c-b26c22daeaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(flat_relative_entropy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eb57ff-f8c6-4bd1-9175-c77e0c52aa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(flat_jensen_shannon_distance_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77243e72-28e4-418d-a797-db3871057c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axvline(1211.55808, color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c95b1d-2a47-4e3c-b8ee-d439198e9a7d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## `active_pf_nD`, `active_pf_nD_dt` visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64faa259-d3fa-4df0-8f65-d3fc20132314",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.TimeSynchronizedOccupancyPlotter import TimeSynchronizedOccupancyPlotter\n",
    "\n",
    "curr_sync_occupancy_plotter = TimeSynchronizedOccupancyPlotter(active_pf_2D_dt)\n",
    "curr_sync_occupancy_plotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab755fe-3b7a-4797-bafd-d33d666c84b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_pf_1D_dt.plot_ratemaps_1D(**({'subplots': (None, 9), 'resolution_multiplier': 1.0, 'enable_spike_overlay': False}));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27682783-c1f0-487b-abda-231d0faf7de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_pf_1D.plot_ratemaps_1D(**({'subplots': (None, 9), 'resolution_multiplier': 1.0, 'enable_spike_overlay': False}));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf582372-8835-4cad-ba36-6478441d195d",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_pf_2D_dt.update(t=3000000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8273f9b8-5e95-4713-97ca-02cc5843644d",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_pf_2D_dt.plot_ratemaps_2D(**({'subplots': (None, 9), 'resolution_multiplier': 1.0, 'enable_spike_overlay': False}));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ef9219-087b-43df-a56f-d640385b9374",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_pf_2D.plot_ratemaps_2D(**({'subplots': (None, 9), 'resolution_multiplier': 1.0, 'enable_spike_overlay': False}));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0e0852-84c1-4e02-bae8-6e59d079c122",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_pf_2D_dt.plot_ratemaps_2D(**({'subplots': (None, 9), 'resolution_multiplier': 1.0, 'enable_spike_overlay': False}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ba5ca1-5263-4ed6-b7fa-ea1cba869715",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_pf_2D.plot_ratemaps_2D(**({'subplots': (None, 9), 'resolution_multiplier': 1.0, 'enable_spike_overlay': False}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d633f44-df72-4e3c-a1c2-4272558f508d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Laps and `stacked_epoch_slices_view`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a571409-905a-4107-8978-fe77e5c1632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.Mixins.LapsVisualizationMixin import LapsVisualizationMixin\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import stacked_epoch_slices_view, stacked_epoch_slices_view_viewbox\n",
    "\n",
    "sess = curr_active_pipeline.sess\n",
    "curr_position_df, lap_specific_position_dfs = LapsVisualizationMixin._compute_laps_specific_position_dfs(sess)\n",
    "lap_specific_position_dfs = [curr_position_df.groupby('lap').get_group(i)[['t','x','y','lin_pos']] for i in sess.laps.lap_id] # dataframes split for each ID:\n",
    "laps_position_times_list = [np.squeeze(lap_pos_df[['t']].to_numpy()) for lap_pos_df in lap_specific_position_dfs]\n",
    "laps_position_traces_list = [lap_pos_df[['x','y']].to_numpy().T for lap_pos_df in lap_specific_position_dfs]\n",
    "\n",
    "## Build Epochs:\n",
    "epochs = sess.laps.to_dataframe()\n",
    "epoch_slices = epochs[['start', 'stop']].to_numpy()\n",
    "epoch_description_list = [f'lap {epoch_tuple.lap_id} (maze: {epoch_tuple.maze_id}, direction: {epoch_tuple.lap_dir})' for epoch_tuple in epochs[['lap_id','maze_id','lap_dir']].itertuples()]\n",
    "# print(f'epoch_description_list: {epoch_description_list}') # epoch_descriptions: ['lap 41 (maze: 2, direction: 1)', 'lap 42 (maze: 2, direction: 0)', ..., 'lap 79 (maze: 2, direction: 1)']\n",
    "\n",
    "stacked_epoch_slices_view_laps_containers = stacked_epoch_slices_view(epoch_slices, laps_position_times_list, laps_position_traces_list, epoch_description_list, name='stacked_epoch_slices_view_laps')\n",
    "# params, plots_data, plots, ui = stacked_epoch_slices_view_laps_containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f06dc93-3900-4531-a484-f57fc0528df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearRegionItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076f63af-e630-4c20-9b14-2ef673dd0dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "VTickGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbfc4c6-8b45-4f07-ab1b-c433de832c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdb off\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "from pyphoplacecellanalysis.External.pyqtgraph.Qt import QtCore, QtGui, QtWidgets\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsObjects.CustomLinearRegionItem import CustomLinearRegionItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd940eb-5dae-49fe-9ec5-5584b5228b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PendingNotebookCode import plot_simple_graph\n",
    "\n",
    "plts, win, app = plot_simple_graph()\n",
    "pg._exec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61151f9a-5561-42b8-8957-97c8ea804b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, out_axes_list = _plot_position_curves_figure(position_obj, include_velocity=True, include_accel=True, figsize=(24, 10))\n",
    "\n",
    "# def _plot_position_curves_figure_pyqtgraph(position_obj, include_velocity=True, include_accel=False, figsize=(24, 10)):\n",
    "#     \"\"\" Renders a figure with a position curve and optionally its higher-order derivatives \"\"\"\n",
    "#     num_subplots = 1\n",
    "#     out_axes_list = []\n",
    "#     if include_velocity:\n",
    "#         num_subplots = num_subplots + 1\n",
    "#     if include_accel:\n",
    "#         num_subplots = num_subplots + 1\n",
    "#     subplots=(num_subplots, 1)\n",
    "#     fig = plt.figure(figsize=figsize, clear=True)\n",
    "#     gs = plt.GridSpec(subplots[0], subplots[1], figure=fig, hspace=0.02)\n",
    "    \n",
    "#     ax0 = fig.add_subplot(gs[0])\n",
    "#     ax0.plot(position_obj.time, position_obj.x, 'k')\n",
    "#     ax0.set_ylabel('pos_x')\n",
    "#     out_axes_list.append(ax0)\n",
    "    \n",
    "#     if include_velocity:\n",
    "#         ax1 = fig.add_subplot(gs[1])\n",
    "#         # ax1.plot(position_obj.time, pos_df['velocity_x'], 'grey')\n",
    "#         # ax1.plot(position_obj.time, pos_df['velocity_x_smooth'], 'r')\n",
    "#         ax1.plot(position_obj.time, position_obj._data['velocity_x_smooth'], 'k')\n",
    "#         ax1.set_ylabel('Velocity_x')\n",
    "#         ax0.set_xticklabels([]) # this is intensionally ax[i-1], as we want to disable the tick labels on above plots        \n",
    "#         out_axes_list.append(ax1)\n",
    "\n",
    "#     if include_accel:  \n",
    "#         ax2 = fig.add_subplot(gs[2])\n",
    "#         # ax2.plot(position_obj.time, position_obj.velocity)\n",
    "#         # ax2.plot(position_obj.time, pos_df['velocity_x'])\n",
    "#         ax2.plot(position_obj.time, position_obj._data['acceleration_x'], 'k')\n",
    "#         # ax2.plot(position_obj.time, pos_df['velocity_y'])\n",
    "#         ax2.set_ylabel('Higher Order Terms')\n",
    "#         ax1.set_xticklabels([]) # this is intensionally ax[i-1], as we want to disable the tick labels on above plots\n",
    "#         out_axes_list.append(ax2)\n",
    "    \n",
    "#     # Shared:\n",
    "#     # ax0.get_shared_x_axes().join(ax0, ax1)\n",
    "#     ax0.get_shared_x_axes().join(*out_axes_list)\n",
    "#     ax0.set_xticklabels([])\n",
    "#     ax0.set_xlim([position_obj.time[0], position_obj.time[-1]])\n",
    "\n",
    "#     return fig, out_axes_list\n",
    "\n",
    "position_obj = curr_active_pipeline.sess.position\n",
    "include_velocity=True\n",
    "include_accel=False\n",
    "\n",
    "num_subplots = 1\n",
    "# out_axes_list = []\n",
    "out_canvas_list = []\n",
    "out_curve_list = []\n",
    "\n",
    "if include_velocity:\n",
    "    num_subplots = num_subplots + 1\n",
    "if include_accel:\n",
    "    num_subplots = num_subplots + 1\n",
    "\n",
    "# app = pg.mkQApp()\n",
    "mw = QtWidgets.QMainWindow()\n",
    "mw.setWindowTitle('Position Curves With Laps')\n",
    "mw.resize(1200, 800)\n",
    "\n",
    "view = pg.GraphicsLayoutWidget()  ## GraphicsView with GraphicsLayout inserted by default\n",
    "mw.setCentralWidget(view)\n",
    "# cw = QtWidgets.QWidget()\n",
    "# mw.setCentralWidget(cw)\n",
    "# l = QtWidgets.QVBoxLayout()\n",
    "# cw.setLayout(l)\n",
    "mw.show()\n",
    "mw.setWindowTitle('Position Plot with Laps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6120bd95-31a4-4591-a62a-13ee21f4c4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_canvas = view.addPlot(title=\"Position\")\n",
    "new_canvas.showGrid(x = True, y = True)\n",
    "new_canvas.setLabel('left', \"Position\")\n",
    "new_canvas.setLabel('bottom', \"Time\")\n",
    "new_curve = new_canvas.plot(pen=pen, symbolBrush=symbolBrush, symbolSize=symbolSize)\n",
    "new_curve.setData(x=xData, y=yData)\n",
    "\n",
    "# s1 = pg.ScatterPlotItem(size=10, pen='k', symbolBrush=(255,0,0), symbolPen='w', brush=pg.mkBrush(255, 255, 255, 120))\n",
    "# l1 = pg.PlotDataItem(antialias=True, pen=pen_aps_model)\n",
    "# pg.LineSegmentROI(size\n",
    "# .plot(np.random.normal(size=100), pen=(200,200,200), symbolBrush=(255,0,0), symbolPen='w')\n",
    "\n",
    "def build_spot_data(pos):\n",
    "    spots = [{'pos': pos[:,i], 'data': 1} for i in range(np.shape(pos)[1])] # + [{'pos': [0,0], 'data': 1}]\n",
    "    return spots\n",
    "    \n",
    "spots = build_spot_data(test_points)\n",
    "s1.addPoints(spots)\n",
    "w1.addItem(s1)\n",
    "# s1.sigClicked.connect(clicked)\n",
    "\n",
    "# mw.show()\n",
    "\n",
    "app.exec()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c294da92-f837-48b0-b021-f10ea9888fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_canvas = view.addPlot(title=\"Position\")\n",
    "new_canvas.showGrid(x = True, y = True)\n",
    "new_canvas.setLabel('left', \"Position\")\n",
    "new_canvas.setLabel('bottom', \"Time\")\n",
    "out_canvas_list.append(new_canvas)\n",
    "new_curve = new_canvas.plot(pen=pen, symbolBrush=symbolBrush, symbolSize=symbolSize)\n",
    "new_curve.setData(x=position_obj.time, y=position_obj._data['velocity_x_smooth'])\n",
    "out_curve_list.append(new_curve)\n",
    "app.exec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c705870b-aed2-4f8f-b3a9-febb292b82de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pw = pg.PlotWidget()  ## giving the plots names allows us to link their axes together\n",
    "l.addWidget(pw)\n",
    "# pw.setLabel('left', 'Position')\n",
    "# pw.setLabel('bottom', 'Time', units='s')\n",
    "# out_axes_list.append(pw)\n",
    "\n",
    "\n",
    "\n",
    "# # p1 = pw1.plot()\n",
    "# # p1.setPen((200,200,100))    \n",
    "# # pw.plot(position_obj.time, position_obj._data['velocity_x_smooth'], 'k')\n",
    "\n",
    "# if include_velocity:\n",
    "#     pw2 = pg.PlotWidget(name='Velocity')\n",
    "#     l.addWidget(pw2)\n",
    "#     pw2.setLabel('left', 'Velocity')\n",
    "#     pw2.setLabel('bottom', 'Time', units='s')\n",
    "#     out_axes_list.append(pw2)\n",
    "#     # p2 = pw2.plot()\n",
    "#     # p2.setPen((200,200,100))\n",
    "\n",
    "# if include_accel:\n",
    "#     pw3 = pg.PlotWidget()\n",
    "#     l.addWidget(pw3)\n",
    "#     pw3.setLabel('left', 'Accel.')\n",
    "#     pw3.setLabel('bottom', 'Time', units='s')\n",
    "#     out_axes_list.append(p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdad90b-6dcc-440b-8f49-b9497a6e08e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7b8ed1-d93a-44b5-9648-8861988d04a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mw.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3b171c-8244-4f8f-816b-b9ffa60d4b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "mw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066ef567-c86d-4c6e-a84d-689a7f5175a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create an empty plot curve to be filled later, set its pen\n",
    "p1 = pw.plot()\n",
    "p1.setPen((200,200,100))\n",
    "\n",
    "## Add in some extra graphics\n",
    "rect = QtWidgets.QGraphicsRectItem(QtCore.QRectF(0, 0, 1, 5e-11))\n",
    "rect.setPen(pg.mkPen(100, 200, 100))\n",
    "pw.addItem(rect)\n",
    "\n",
    "pw.setLabel('left', 'Position', units='V')\n",
    "pw.setLabel('bottom', 'Time', units='s')\n",
    "pw.setXRange(0, 2)\n",
    "pw.setYRange(0, 1e-10)\n",
    "\n",
    "\n",
    "new_curves_separate_plot = target_graphics_layout_widget.addPlot(row=row, col=col, rowspan=rowspan, colspan=colspan) # PlotItem\n",
    "new_curves_separate_plot.setObjectName(name)\n",
    "\n",
    "# Setup axes bounds for the bottom windowed plot:\n",
    "# new_curves_separate_plot.hideAxis('left')\n",
    "new_curves_separate_plot.showAxis('left')\n",
    "new_curves_separate_plot.hideAxis('bottom') # hide the shared time axis since it's synced with the other plot\n",
    "# new_curves_separate_plot.showAxis('bottom')\n",
    "\n",
    "new_curves_separate_plot.setMouseEnabled(x=False, y=True)\n",
    "\n",
    "# # setup the new_curves_separate_plot to have a linked X-axis to the other scroll plot:\n",
    "main_plot_widget = self.plots.main_plot_widget # PlotItem\n",
    "new_curves_separate_plot.setXLink(main_plot_widget) # works to synchronize the main zoomed plot (current window) with the epoch_rect_separate_plot (rectangles plotter)\n",
    "\n",
    "\n",
    "main_time_curves_view_widget = \n",
    "# def ScrollRasterPreviewWindow_on_BuildUI(self, background_static_scroll_window_plot):\n",
    "\n",
    "#         # Common Tick Label\n",
    "#         vtick = QtGui.QPainterPath()\n",
    "#         vtick.moveTo(0, -0.5)\n",
    "#         vtick.lineTo(0, 0.5)\n",
    "        \n",
    "#         #############################\n",
    "#         ## Bottom Windowed Scroll Plot/Widget:\n",
    "\n",
    "#         # ALL Spikes in the preview window:\n",
    "#         curr_spike_x, curr_spike_y, curr_spike_pens, self.plots_data.all_spots, curr_n = self._build_all_spikes_data_values()\n",
    "        \n",
    "#         self.plots.preview_overview_scatter_plot = pg.ScatterPlotItem(name='spikeRasterOverviewWindowScatterPlotItem', pxMode=True, symbol=vtick, size=5, pen={'color': 'w', 'width': 1})\n",
    "#         self.plots.preview_overview_scatter_plot.setObjectName('preview_overview_scatter_plot') # this seems necissary, the 'name' parameter in addPlot(...) seems to only change some internal property related to the legend AND drastically slows down the plotting\n",
    "#         self.plots.preview_overview_scatter_plot.opts['useCache'] = True\n",
    "#         self.plots.preview_overview_scatter_plot.addPoints(self.plots_data.all_spots) # , hoverable=True\n",
    "#         background_static_scroll_window_plot.addItem(self.plots.preview_overview_scatter_plot)\n",
    "        \n",
    "#         # Add the linear region overlay:\n",
    "#         # self.ui.scroll_window_region = pg.LinearRegionItem(pen=pg.mkPen('#fff'), brush=pg.mkBrush('#f004'), hoverBrush=pg.mkBrush('#fff4'), hoverPen=pg.mkPen('#f00'), clipItem=self.plots.preview_overview_scatter_plot) # bound the LinearRegionItem to the plotted data\n",
    "        \n",
    "#         self.ui.scroll_window_region = CustomLinearRegionItem(pen=pg.mkPen('#fff'), brush=pg.mkBrush('#f004'), hoverBrush=pg.mkBrush('#fff4'), hoverPen=pg.mkPen('#f00'), clipItem=self.plots.preview_overview_scatter_plot) # bound the LinearRegionItem to the plotted data\n",
    "#         self.ui.scroll_window_region.setObjectName('scroll_window_region')\n",
    "#         self.ui.scroll_window_region.setZValue(10)\n",
    "#         # Add the LinearRegionItem to the ViewBox, but tell the ViewBox to exclude this item when doing auto-range calculations.\n",
    "#         background_static_scroll_window_plot.addItem(self.ui.scroll_window_region, ignoreBounds=True)\n",
    "#         self.ui.scroll_window_region.sigRegionChanged.connect(self._Render2DScrollWindowPlot_on_linear_region_item_update)\n",
    "\n",
    "        \n",
    "#         # Setup axes bounds for the bottom windowed plot:\n",
    "#         background_static_scroll_window_plot.hideAxis('left')\n",
    "#         background_static_scroll_window_plot.hideAxis('bottom')\n",
    "#         # background_static_scroll_window_plot.setLabel('bottom', 'Time', units='s')\n",
    "#         background_static_scroll_window_plot.setMouseEnabled(x=False, y=False)\n",
    "#         background_static_scroll_window_plot.disableAutoRange('xy')\n",
    "#         # background_static_scroll_window_plot.enableAutoRange(x=False, y=False)\n",
    "#         background_static_scroll_window_plot.setAutoVisible(x=False, y=False)\n",
    "#         background_static_scroll_window_plot.setAutoPan(x=False, y=False)\n",
    "        \n",
    "#         # Setup range for plot:\n",
    "#         earliest_t, latest_t = self.spikes_window.total_df_start_end_times\n",
    "#         background_static_scroll_window_plot.setXRange(earliest_t, latest_t, padding=0)\n",
    "#         background_static_scroll_window_plot.setYRange(np.nanmin(curr_spike_y), np.nanmax(curr_spike_y), padding=0)\n",
    "        \n",
    "#         return background_static_scroll_window_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fbea81-1532-4c88-b0b8-84382d79e5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses.laps import estimation_session_laps # for estimation_session_laps\n",
    "\n",
    "%pdb on\n",
    "curr_active_pipeline.sess = estimation_session_laps(curr_active_pipeline.sess, should_plot_laps_2d=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24558cc4-f2eb-4549-b64d-8a42dc6d2216",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.laps import plot_laps_2d\n",
    "\n",
    "fig, out_axes_list = plot_laps_2d(curr_active_pipeline.sess, legacy_plotting_mode=True)\n",
    "out_axes_list[0].set_title('New Pho Position Thresholding Estimated Laps')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f9df68-e032-4176-9381-5deb899b87f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from neuropy.utils.misc import is_iterable\n",
    "from neuropy.plotting.figure import pretty_plot\n",
    "from scipy.ndimage import gaussian_filter, gaussian_filter1d, interpolation\n",
    "\n",
    "from neuropy.analyses.laps import estimation_session_laps # Newest pho laps estimation\n",
    "from pyphoplacecellanalysis.Analysis.reliability import compute_lap_to_lap_reliability\n",
    "\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.laps import _plot_position_curves_figure\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.laps import plot_laps_2d\n",
    "\n",
    "curr_result_label = 'maze1'\n",
    "sess = curr_active_pipeline.filtered_sessions[curr_result_label]\n",
    "sess = curr_active_pipeline.sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad99826-10ab-4979-ab0e-f186016b3b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Approach: try to compute brand-new laps using estimation_session_laps(sess):\n",
    "# sess = estimation_session_laps(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d608ab32-6ddc-4cd3-92eb-02fd41333906",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_pf_1D_dt.snapshot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73669756-4a9d-4bc7-8d41-72d4d807104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "even_lap_specific_epochs.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c67af28-8cd8-46e8-a683-7e2f4ccd8a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.laps.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab47e75-79d4-419e-b181-8ca27e277d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = sess.position.to_dataframe()\n",
    "hardcoded_track_midpoint_x = 150.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f881cd5d-2dcd-42bc-ae8f-3bb67daf3c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df.x.aggregate(['nanmin','mean', 'median','nanmax'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62324d83-c5da-40cc-ae99-37771b916c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pdb off\n",
    "fig, out_axes_list = _plot_position_curves_figure(sess.position, include_velocity=True, include_accel=True, figsize=(24, 10))\n",
    "ax0 = out_axes_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1644c1d-8704-4c98-b272-e5901b9b0e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(['x','velocity_x_smooth']).issubset(pos_df.columns), 'pos_df requires the columns \"x\", and \"velocity_x_smooth\" at a minimum'\n",
    "zero_centered_x = pos_df['x'] - hardcoded_track_midpoint_x\n",
    "zero_crossings_x = np.diff(np.sign(zero_centered_x))\n",
    "# Find ascending crossings:\n",
    "asc_crossing_midpoints = np.where(zero_crossings_x > 0)[0] # (24,), corresponding to increasing positions\n",
    "# find descending crossings:\n",
    "desc_crossing_midpoints = np.where(zero_crossings_x < 0)[0] # (24,)\n",
    "print(f'desc_crossings_x: {np.shape(desc_crossing_midpoints)}, asc_crossings_x: {np.shape(asc_crossing_midpoints)}') # desc_crossings_x: (24,), asc_crossings_x: (24,)\n",
    "# desc_crossings_x: (43,), asc_crossings_x: (42,)\n",
    "\n",
    "desc_crossing_beginings = np.zeros_like(desc_crossing_midpoints)\n",
    "desc_crossing_endings = np.zeros_like(desc_crossing_midpoints)\n",
    "\n",
    "asc_crossing_beginings = np.zeros_like(asc_crossing_midpoints)\n",
    "asc_crossing_endings = np.zeros_like(asc_crossing_midpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c284cc55-aaa2-44e1-b630-65d0f4e5b0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# desc_crossings_x: (43,), asc_crossings_x: (42,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4354dc6-3d81-4e53-a116-353a0a2372ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_crossings_x.nonzero()[0].shape # (85,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0f63d1-aa70-4514-92eb-dd5bc174aacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(desc_crossing_midpoints) > len(asc_crossing_midpoints):\n",
    "    print(f'WARNING: must drop last desc_crossing_midpoint.')\n",
    "    assert len(desc_crossing_midpoints) > 1\n",
    "    desc_crossing_midpoints = desc_crossing_midpoints[:-1] # all but the very last which is dropped\n",
    "    \n",
    "elif len(asc_crossing_midpoints) > len(desc_crossing_midpoints):\n",
    "    print(f'WARNING: must drop last asc_crossing_midpoints.')\n",
    "    assert len(asc_crossing_midpoints) > 1\n",
    "    asc_crossing_midpoints = asc_crossing_midpoints[:-1] # all but the very last which is dropped\n",
    "    \n",
    "assert len(asc_crossing_midpoints) == len(desc_crossing_midpoints), f\"desc_crossings_x: {np.shape(desc_crossing_midpoints)}, asc_crossings_x: {np.shape(asc_crossing_midpoints)}\"\n",
    "desc_crossing_midpoints, asc_crossing_midpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e34273-05a7-4e86-9b03-f0e059aad7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_starting_with_ascend = (asc_crossing_midpoints[0] < desc_crossing_midpoints[0]) # True if the animal is starting at the lower half (bottom) of the track, meaning the first motion is an ascending one\n",
    "is_starting_with_ascend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ca1a8d-d5c4-4056-bd2c-2e8918dce99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "desc_crossing_midpoints, asc_crossing_midpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f3b8f1-0c0a-4890-bea4-744373dacb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_draw = False\n",
    "\n",
    "# testing-only, work on a single crossing:\n",
    "for a_desc_crossing_i in np.arange(len(desc_crossing_midpoints)):\n",
    "    a_desc_crossing = desc_crossing_midpoints[a_desc_crossing_i]\n",
    "    # print(f'a_desc_crossing: {a_desc_crossing}')\n",
    "    # pos_df.loc[a_desc_crossing:, :]\n",
    "    curr_remainder_pos_df = pos_df.loc[a_desc_crossing:, :]\n",
    "    # pos_df.loc[a_desc_crossing:, ['velocity_x_smooth']]\n",
    "    curr_next_transition_points = curr_remainder_pos_df[curr_remainder_pos_df['velocity_x_smooth'] > 0.0].index # the first increasing\n",
    "    curr_next_transition_point = curr_next_transition_points[0] # desc endings\n",
    "    desc_crossing_endings[a_desc_crossing_i] = curr_next_transition_point\n",
    "\n",
    "    # Preceeding points:\n",
    "    curr_preceeding_pos_df = pos_df.loc[0:a_desc_crossing, :]\n",
    "    curr_prev_transition_points = curr_preceeding_pos_df[curr_preceeding_pos_df['velocity_x_smooth'] > 0.0].index # the last increasing # TODO: this is not quite right.\n",
    "    curr_prev_transition_point = curr_prev_transition_points[-1] # Get last (nearest to curr_preceeding_pos_df's end) point. desc beginings\n",
    "    desc_crossing_beginings[a_desc_crossing_i] = curr_prev_transition_point\n",
    "    if debug_draw:\n",
    "        ax0.scatter(curr_points[curr_next_transition_point,0], curr_points[curr_next_transition_point,1], s=15, c='orange')\n",
    "        ax0.vlines(curr_points[curr_next_transition_point,0], 0, 1, transform=ax0.get_xaxis_transform(), colors='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cddb042-579a-4fe7-bb5d-6e1f55f023a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_asc_crossing_i in np.arange(len(asc_crossing_midpoints)):\n",
    "    an_asc_crossing = asc_crossing_midpoints[a_asc_crossing_i]\n",
    "    # print(f'a_desc_crossing: {a_desc_crossing}')\n",
    "    # pos_df.loc[a_desc_crossing:, :]\n",
    "    curr_remainder_pos_df = pos_df.loc[an_asc_crossing:, :]\n",
    "    # pos_df.loc[a_desc_crossing:, ['velocity_x_smooth']]\n",
    "    curr_next_transition_points = curr_remainder_pos_df[curr_remainder_pos_df['velocity_x_smooth'] < 0.0].index # the first decreasing\n",
    "    curr_next_transition_point = curr_next_transition_points[0] # asc endings\n",
    "    asc_crossing_endings[a_asc_crossing_i] = curr_next_transition_point\n",
    "    if debug_draw:\n",
    "        ax0.scatter(curr_points[curr_next_transition_point,0], curr_points[curr_next_transition_point,1], s=15, c='orange')\n",
    "        ax0.vlines(curr_points[curr_next_transition_point,0], 0, 1, transform=ax0.get_xaxis_transform(), colors='g')\n",
    "\n",
    "    # Preceeding points:\n",
    "    curr_preceeding_pos_df = pos_df.loc[0:an_asc_crossing, :]\n",
    "    curr_prev_transition_points = curr_preceeding_pos_df[curr_preceeding_pos_df['velocity_x_smooth'] < 0.0].index #\n",
    "    curr_prev_transition_point = curr_prev_transition_points[-1] # Get last (nearest to curr_preceeding_pos_df's end) point. desc beginings\n",
    "    asc_crossing_beginings[a_asc_crossing_i] = curr_prev_transition_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49375f96-3fc4-4165-8b31-802c8b193ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Outputs\n",
    "desc_crossing_beginings, desc_crossing_midpoints, desc_crossing_endings, asc_crossing_beginings, asc_crossing_midpoints, asc_crossing_endings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556f657e-3b3e-4257-92c9-59d1cde7e56c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9ee62a-91c9-4ac9-b1fc-92586c8d82ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_laps = sess.laps\n",
    "curr_laps.from_estimated_laps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273e02a3-057c-44cb-bc6f-44e7baadc567",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_laps_df = sess.laps.to_dataframe()\n",
    "curr_laps_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab44ff03-dd61-4e18-b75f-2739bb562918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec15352-ca62-4be7-952e-128f8b7dde45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = sess.compute_position_laps() # ensures the laps are computed if they need to be:\n",
    "position_obj = sess.position\n",
    "position_obj.compute_higher_order_derivatives()\n",
    "pos_df = position_obj.compute_smoothed_position_info(N=20) ## Smooth the velocity curve to apply meaningful logic to it\n",
    "pos_df = position_obj.to_dataframe()\n",
    "pos_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7d35f7-e385-4a17-a91c-abc8b67e4dbb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Missing 'start_position_index' and 'end_position_index' for laps:\n",
    "\n",
    "Seems to be added by `NeuroPy.neuropy.core.laps.Laps.from_estimated_laps` \n",
    "    `NeuroPy.neuropy.analyses.laps.estimation_session_laps`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b9e07d-bdeb-4494-979b-3b0b3cec0f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, out_axes_list = plot_laps_2d(sess, legacy_plotting_mode=True)\n",
    "fig, out_axes_list = plot_laps_2d(sess, legacy_plotting_mode=False)\n",
    "out_axes_list[0].set_title('New Pho Position Thresholding Estimated Laps')\n",
    "\n",
    "curr_cell_idx = 2 \n",
    "# curr_cell_idx = 3 # good for end platform analysis\n",
    "curr_cell_ID = sess.spikes_df.spikes.neuron_ids[curr_cell_idx]\n",
    "print(f'curr_cell_idx: {curr_cell_idx}, curr_cell_ID: {curr_cell_ID}')\n",
    "\n",
    "# pre-filter by spikes that occur in one of the included laps for the filtered_spikes_df\n",
    "filtered_spikes_df = sess.spikes_df.copy()\n",
    "time_variable_name = filtered_spikes_df.spikes.time_variable_name # 't_rel_seconds'\n",
    "\n",
    "lap_ids = sess.laps.lap_id\n",
    "# lap_flat_idxs = sess.laps.get_lap_flat_indicies(lap_ids)\n",
    "\n",
    "out_indicies, out_digitized_position_bins, out_within_lap_spikes_overlap = compute_lap_to_lap_reliability(curr_active_pipeline.computation_results[curr_result_label].computed_data['pf2D'], filtered_spikes_df, lap_ids, curr_cell_idx, debug_print=False, plot_results=True);\n",
    "\n",
    "# compute_reliability_metrics(out_indicies, out_digitized_position_bins, out_within_lap_spikes_overlap, debug_print=False, plot_results=False)\n",
    "\n",
    "# # curr_kdiba_pipeline.computation_results['maze1'].computed_data['pf2D'].plotRaw_v_time(curr_cell_idx)\n",
    "# _test_plotRaw_v_time(curr_kdiba_pipeline.computation_results[curr_result_label].computed_data['pf2D'], curr_cell_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db190a7-2b3d-4f63-be72-a5204a43dad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05348578-ac0c-4da1-a9c9-36794e5997c8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# `_display_short_long_pf1D_comparison` and `_display_short_long_pf1D_scalar_overlap_comparison`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28739947-375a-4c68-95fa-ccc54eb9824a",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "\n",
    "long_single_cell_pfmap_processing_fn = None\n",
    "short_single_cell_pfmap_processing_fn = None\n",
    "\n",
    "# long_single_cell_pfmap_processing_fn = lambda i, aclu, pfmap: 0.5 * pfmap # flip over the y-axis\n",
    "# short_single_cell_pfmap_processing_fn = lambda i, aclu, pfmap: -0.5 * pfmap # flip over the y-axis\n",
    "\n",
    "# pad = 1\n",
    "# long_single_cell_pfmap_processing_fn = lambda i, aclu, pfmap: (0.5 * pfmap) + (0.5*pad) # shift the baseline up by half\n",
    "# short_single_cell_pfmap_processing_fn = lambda i, aclu, pfmap: (-0.5 * pfmap * pad) + (0.5*pad) # flip over the y-axis, shift the baseline down by half\n",
    "\n",
    "# pad = 1\n",
    "# long_single_cell_pfmap_processing_fn = lambda i, aclu, pfmap: (0.5 * pfmap * pad) + (0.5*pad) # shift the baseline up by half\n",
    "# short_single_cell_pfmap_processing_fn = lambda i, aclu, pfmap: (0.5 * pfmap * pad) + (0.5*pad) # flip over the y-axis, shift the baseline down by half\n",
    "# long_single_cell_pfmap_processing_fn = lambda i, aclu, pfmap: (0.5 * pfmap * pad) # shift the baseline up by half\n",
    "# short_single_cell_pfmap_processing_fn = lambda i, aclu, pfmap: (0.5 * pfmap * pad) # flip over the y-axis, shift the baseline down by half\n",
    "\n",
    "\n",
    "# long_single_cell_pfmap_processing_fn = lambda i, aclu, pfmap: (1.0 * pfmap * pad) # shift the baseline up by half\n",
    "# short_single_cell_pfmap_processing_fn = lambda i, aclu, pfmap: (-1.0 * pfmap * pad) + (1.0*pad) # this does not work and results in short being fully filled. I think this is because the fill_between gets reversed since everything is below baseline\n",
    "\n",
    "\n",
    "out = curr_active_pipeline.display('_display_short_long_pf1D_comparison', active_identifying_session_ctx, single_figure=True, debug_print=False, fignum='Short v Long pf1D Comparison',\n",
    "                                   long_kwargs={'sortby': sort_idx, 'single_cell_pfmap_processing_fn': long_single_cell_pfmap_processing_fn},\n",
    "                                   short_kwargs={'sortby': sort_idx, 'single_cell_pfmap_processing_fn': short_single_cell_pfmap_processing_fn, 'curve_hatch_style': {'hatch':'///', 'edgecolor':'k'}},\n",
    "                                  )\n",
    "ax = out.axes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e882c022-7426-4143-bade-93ee7802d1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Overlap Scalar Comparisons: plots a comparison of a specific type of scalar values for all cells\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.MultiContextComparingDisplayFunctions import PlacefieldOverlapMetricMode\n",
    "\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'\n",
    "\n",
    "# overlap_metric_mode = PlacefieldOverlapMetricMode.POLY\n",
    "# overlap_metric_mode = PlacefieldOverlapMetricMode.PRODUCT\n",
    "# overlap_metric_mode = PlacefieldOverlapMetricMode.CONVOLUTION\n",
    "overlap_metric_mode = PlacefieldOverlapMetricMode.REL_ENTROPY\n",
    "\n",
    "out = curr_active_pipeline.display('_display_short_long_pf1D_scalar_overlap_comparison', active_identifying_session_ctx, overlap_metric_mode=overlap_metric_mode, variant_name='_area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff7d434-25c8-425e-8578-00ba8f333588",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.TimeSynchronizedOccupancyPlotter import TimeSynchronizedOccupancyPlotter\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.TimeSynchronizedPlacefieldsPlotter import TimeSynchronizedPlacefieldsPlotter\n",
    "\n",
    "curr_placefields_plotter = TimeSynchronizedPlacefieldsPlotter(active_pf_2D_dt)\n",
    "curr_placefields_plotter.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100b3e55-3243-4346-aa00-9b6fd705e7ff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2022-12-09 - Pho Surprise/KL-Divergence Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cd05b7-ade9-420e-8b14-3e71474431f5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "source": [
    "## âŒðŸ†– BROKEN Individual Plotting Outputs:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9655181f-dc58-470a-b496-0fc9cd3c0883",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Common Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad892ba6-4657-4370-957c-d2926c32826c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## MATPLOTLIB Imports:\n",
    "import matplotlib\n",
    "# configure backend here\n",
    "matplotlib.use('Qt5Agg')\n",
    "# backend_qt5agg\n",
    "# matplotlib.use('AGG') # non-interactive backend\n",
    "## 2022-08-16 - Surprisingly this works to make the matplotlib figures render only to .png file, not appear on the screen!\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.backends import backend_pdf\n",
    "\n",
    "from neuropy.utils.matplotlib_helpers import enumTuningMap2DPlotVariables # for getting the variant name from the dict\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "mpl.rcParams['toolbar'] = 'None' # disable toolbars\n",
    "\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import create_daily_programmatic_display_function_testing_folder_if_needed, build_pdf_metadata_from_display_context, programmatic_display_to_PDF\n",
    "\n",
    "# from pyphocorehelpers.plotting.figure_management import PhoActiveFigureManager2D, capture_new_figures_decorator\n",
    "# fig_man = PhoActiveFigureManager2D(name=f'fig_man') # Initialize a new figure manager\n",
    "\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0e2d2e-b547-4fc9-a610-9cb834776a16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44dd1ae1-a5cd-4a03-bc11-dbb77dc161b8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Single (Session, Filter) Context Plotting:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774fe569-bbb0-4112-816d-bdbcba78dab5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Utility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc39ef8c-731a-47e5-9471-8f64d9e5511d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reload display functions:\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "curr_active_pipeline.registered_display_function_names # ['_display_1d_placefield_validations', '_display_2d_placefield_result_plot_ratemaps_2D', '_display_2d_placefield_result_plot_raw', '_display_normal', '_display_placemaps_pyqtplot_2D', '_display_decoder_result', '_display_plot_most_likely_position_comparisons', '_display_two_step_decoder_prediction_error_2D', '_display_two_step_decoder_prediction_error_animated_2D', '_display_spike_rasters_pyqtplot_2D', '_display_spike_rasters_pyqtplot_3D', '_display_spike_rasters_pyqtplot_3D_with_2D_controls', '_display_spike_rasters_vedo_3D', '_display_spike_rasters_vedo_3D_with_2D_controls', '_display_spike_rasters_window', '_display_speed_vs_PFoverlapDensity_plots', '_display_3d_image_plotter', '_display_3d_interactive_custom_data_explorer', '_display_3d_interactive_spike_and_behavior_browser', '_display_3d_interactive_tuning_curves_plotter']\n",
    "print(curr_active_pipeline.registered_display_function_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f563259-19f3-4d85-bb53-ae88e389cde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib --list \n",
    "# Available matplotlib backends: ['tk', 'gtk', 'gtk3', 'gtk4', 'wx', 'qt4', 'qt5', 'qt6', 'qt', 'osx', 'nbagg', 'notebook', 'agg', 'svg', 'pdf', 'ps', 'inline', 'ipympl', 'widget']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ed2748-0817-42dc-93b8-6648d3c16caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "## NOTE THAT ONCE THIS IS SET TO qt, it cannot be undone!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a062f0e-dfdf-4f95-a412-7cb8bbafb7c0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Systematic Display Function Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7811d710-3ada-437f-827d-0eeacbcbe16b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Matplotlib-based plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4d9f10-e1ca-485d-af0f-4cd9a40562ae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# matplotlib.use('AGG') # non-interactive backend\n",
    "# %matplotlib -l\n",
    "\n",
    "matplotlib.use('Qt5Agg') # non-interactive backend\n",
    "## 2022-08-16 - Surprisingly this works to make the matplotlib figures render only to .png file, not appear on the screen!\n",
    "\n",
    "curr_active_pipeline.filtered_session_names # ['maze', 'sprinkle']\n",
    "active_config_name = 'maze'\n",
    "\n",
    "active_display_to_pdf_fn = programmatic_display_to_PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0217fa1d-86bd-4a3f-9413-3ae52901aef9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "active_display_to_pdf_fn(curr_active_pipeline, curr_display_function_name='_display_1d_placefield_validations') # ðŸŸ¢âœ… Now seems to be working and saving to PDF!! Still using matplotlib.use('Qt5Agg') mode and plots still appear. Moderate visual improvements can still be made (titles overlap and stuff). Works with %%capture\n",
    "\n",
    "# active_display_to_pdf_fn(curr_active_pipeline, curr_display_function_name='_display_1d_placefield_validations', filter_name=active_config_name) # ðŸŸ¢âœ… Now seems to be working and saving to PDF!! Still using matplotlib.use('Qt5Agg') mode and plots still appear. Moderate visual improvements can still be made (titles overlap and stuff). Works with %%capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d9db48-c37b-4e67-8486-ddc1b0c7fba0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "active_display_to_pdf_fn(curr_active_pipeline, curr_display_function_name='_display_2d_placefield_result_plot_raw', debug_print=False) # ðŸ”‡ðŸ†–âŒ IndexError: index 80 is out of bounds for GridSpec with size 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c52598-3352-4b11-bb72-9dea8e55e527",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "active_display_to_pdf_fn(curr_active_pipeline, curr_display_function_name='_display_1d_placefields', debug_print=False) # ðŸŸ¢âœ… Now seems to be working and saving to PDF!! Still using matplotlib.use('Qt5Agg') mode and plots still appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282bf408-5a13-47a3-a3c9-5c3d55454b4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "active_display_to_pdf_fn(curr_active_pipeline, curr_display_function_name='_display_1d_placefields', debug_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca4c701-a343-44c4-a2d7-68d6b975b6a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "active_display_to_pdf_fn(curr_active_pipeline, curr_display_function_name='_display_normal', debug_print=True) # ðŸžâŒ TypeError: unhashable type: 'list'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7038ae4-17ce-491c-a1d3-e934537ed550",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "active_display_to_pdf_fn(curr_active_pipeline, curr_display_function_name='_display_2d_placefield_result_plot_ratemaps_2D') #  ðŸŸ¢âœ… Now seems to be working and saving to PDF!! Still using matplotlib.use('Qt5Agg') mode and plots still appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f8696f-45c6-4870-93f6-713246d455fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "active_display_to_pdf_fn(curr_active_pipeline, curr_display_function_name='_display_normal', filter_name=active_config_name) # ðŸžâŒ TypeError: unhashable type: 'list'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b16c86e-5dc1-4918-a115-7ae99eae1084",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### ðŸžðŸ‘ï¸â€ðŸ—¨ï¸ðŸ”œ TODO: FINISH THIS UP AND FIGURE OUT WHATEVER THE HELL I'M DOING HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b62efd2-f8f3-4dc7-baa9-67fcbdf3f983",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "curr_display_function_name = '_display_2d_placefield_result_plot_ratemaps_2D'\n",
    "built_pdf_metadata, curr_pdf_save_path = _build_pdf_pages_output_info(curr_display_function_name)\n",
    "out_fig_list = []\n",
    "active_identifying_display_ctx = active_identifying_filtered_session_ctx.adding_context('display_fn', display_fn_name=curr_display_function_name)\n",
    "figure_format_config = _get_curr_figure_format_config() # Fetch the context from the GUI\n",
    "figure_format_config['enable_saving_to_disk'] = False # don't use the in-built figure export/saving to disk functionality as we want to wrap the output figure with the Pdf saving, not write to a .png\n",
    "with backend_pdf.PdfPages(curr_pdf_save_path, keep_empty=False, metadata=built_pdf_metadata) as pdf:\n",
    "    ## TypeError: neuropy.utils.debug_helpers.safely_accepts_kwargs.<locals>._safe_kwargs_fn() got multiple values for keyword argument 'computation_config'\n",
    "    for filter_name in curr_active_pipeline.filtered_session_names:\n",
    "        print(f'filter_name: {filter_name}')\n",
    "        active_identifying_ctx = active_identifying_display_ctx.adding_context('plot_variable', variable_name=enumTuningMap2DPlotVariables.SPIKES_MAPS)\n",
    "        active_identifying_ctx_string = active_identifying_ctx.get_description(separator='|') # Get final discription string\n",
    "        out_fig_list.extend(curr_active_pipeline.display(curr_display_function_name, filter_name, plot_variable=enumTuningMap2DPlotVariables.SPIKES_MAPS, fignum=active_identifying_ctx_string, **figure_format_config)) # works!\n",
    "        active_identifying_ctx = active_identifying_display_ctx.adding_context('plot_variable', variable_name=enumTuningMap2DPlotVariables.TUNING_MAPS)\n",
    "        active_identifying_ctx_string = active_identifying_ctx.get_description(separator='|') # Get final discription string\n",
    "        out_fig_list.extend(curr_active_pipeline.display(curr_display_function_name, filter_name, plot_variable=enumTuningMap2DPlotVariables.TUNING_MAPS, fignum=active_identifying_ctx_string, **figure_format_config))\n",
    "        for a_fig in out_fig_list:\n",
    "            pdf.savefig(a_fig, transparent=True)\n",
    "            \n",
    "# ðŸžðŸ”‡ðŸ†–âŒ NameError: name '_build_pdf_pages_output_info' is not defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9fad5b-4871-46a6-b4a4-b50480bca489",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "curr_display_function_name = '_display_decoder_result'\n",
    "built_pdf_metadata, curr_pdf_save_path = _build_pdf_pages_output_info(curr_display_function_name)\n",
    "with backend_pdf.PdfPages(curr_pdf_save_path, keep_empty=False, metadata=built_pdf_metadata) as pdf:\n",
    "    plots = curr_active_pipeline.display(curr_display_function_name, filter_name)\n",
    "    print(plots)\n",
    "    # pdf.savefig(a_fig)\n",
    "    \n",
    "    \n",
    "# ðŸžðŸ”‡ðŸ†–âŒ NameError: name '_build_pdf_pages_output_info' is not defined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11a9839-3fd4-4fd8-988c-61144c84051a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### PyQtGraph-based Pf2D Viewers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fa3058-24c9-49e1-af41-cad50df2d829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŸ¢âœ… Nearly Completely Working - Needs subplot labels changed to match standardized matplotlib version, needs color scheme set consistently to matplotlib version, needs colorbars removed\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow, add_bin_ticks, build_binned_imageItem\n",
    "from neuropy.utils.matplotlib_helpers import _build_variable_max_value_label, enumTuningMap2DPlotMode, enumTuningMap2DPlotVariables, _determine_best_placefield_2D_layout, _scale_current_placefield_to_acceptable_range\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.plot_placefields import display_all_pf_2D_pyqtgraph_binned_image_rendering\n",
    "\n",
    "# NOTE FILTER SPECIFIC: active_config_name and active_pf_2D depend on active_config_name\n",
    "\n",
    "## Get the figure_format_config from the figure_format_config widget:\n",
    "active_identifying_display_ctx = active_identifying_filtered_session_ctx.adding_context('display_fn', display_fn_name='display_all_pf_2D_pyqtgraph_binned_image_rendering')\n",
    "figure_format_config = _get_curr_figure_format_config() # Fetch the context from the GUI\n",
    "out_all_pf_2D_pyqtgraph_binned_image_fig = display_all_pf_2D_pyqtgraph_binned_image_rendering(active_pf_2D, figure_format_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd7686d-b854-44bf-a6e3-fb7c338380b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_all_pf_2D_pyqtgraph_binned_image_fig.setWindowTitle(f'{active_identifying_display_ctx.get_description()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158ffab7-de5e-43af-8162-bff293df838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = active_one_step_decoder.ratemap.normalized_tuning_curves\n",
    "images.shape # (66, 41, 63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1048f102-f9d2-4c2e-96d7-4d8eb820a7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŸ¢ðŸš§ðŸŸ¨ Almost Working - Needs subplot labels changed from Cell[i] to the appropriate standardized titles. Needs other minor refinements.\n",
    "# ðŸš§ pyqtplot_plot_image_array needs major improvements to achieve feature pairity with display_all_pf_2D_pyqtgraph_binned_image_rendering, so probably just use display_all_pf_2D_pyqtgraph_binned_image_rendering.  \n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.plot_placefields import pyqtplot_plot_image_array\n",
    "\n",
    "# Get the decoders from the computation result:       \n",
    "# Get flat list of images:\n",
    "images = active_one_step_decoder.ratemap.normalized_tuning_curves # (43, 63, 63)\n",
    "occupancy = active_one_step_decoder.ratemap.occupancy\n",
    "\n",
    "active_identifying_display_ctx = active_identifying_filtered_session_ctx.adding_context('display_fn', display_fn_name='pyqtplot_plot_image_array')\n",
    "figure_format_config = _get_curr_figure_format_config() # Fetch the context from the GUI\n",
    "## Get final discription string:\n",
    "active_identifying_ctx_string = active_identifying_display_ctx.get_description(separator='|')\n",
    "print(f'active_identifying_ctx_string: {active_identifying_ctx_string}')\n",
    "\n",
    "## Build the widget:\n",
    "app, parent_root_widget, root_render_widget, plot_array, img_item_array, other_components_array = pyqtplot_plot_image_array(active_one_step_decoder.xbin, active_one_step_decoder.ybin, images, occupancy, \n",
    "                                                                        app=None, parent_root_widget=None, root_render_widget=None, max_num_columns=8)\n",
    "parent_root_widget.show()\n",
    "if master_dock_win is not None:\n",
    "    # if there's an open master_dock_win, add this widget as a child dock\n",
    "    master_dock_win.add_display_dock(identifier=active_identifying_ctx_string, widget=parent_root_widget, dockIsClosable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4fc1d3-0100-4bf1-8a9e-1ea7203d2b9c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Decoder Plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a1e343-5737-4435-be8b-369483624fa4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Must switch back to the interactive backend here for the interactive/animated decoder plots:\n",
    "matplotlib.use('Qt5Agg')\n",
    "# backend_qt5agg\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.switch_backend('Qt5Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8180d131-f7a6-44f4-b63d-b1d3ef9bb409",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.display('_display_two_step_decoder_prediction_error_animated_2D', active_config_name, variable_name='p_x_given_n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840af86d-030a-4ba5-973d-316e94c16a61",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ## MATPLOTLIB Imports:\n",
    "# import matplotlib\n",
    "# # configure backend here\n",
    "# matplotlib.use('Qt5Agg')\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib as mpl\n",
    "## This plot looks phenominal, and the slider works!\n",
    "curr_active_pipeline.display('_display_two_step_decoder_prediction_error_2D', active_config_name, variable_name='p_x_given_n') # NOW: TypeError: _temp_debug_two_step_plots_animated_imshow() missing 1 required positional argument: 'time_binned_position_df'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd163714-1838-4c8d-9796-dc3823b11f0f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.display('_display_two_step_decoder_prediction_error_2D', active_config_name, variable_name='p_x_given_n_and_x_prev')  # this one doesn't work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78308cc1-7dea-49aa-814a-d2784de14981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the decoders from the computation result:\n",
    "# active_one_step_decoder = computation_result.computed_data['pf2D_Decoder']\n",
    "# active_two_step_decoder = computation_result.computed_data.get('pf2D_TwoStepDecoder', None)\n",
    "# active_measured_positions = computation_result.sess.position.to_dataframe()\n",
    "\n",
    "active_one_step_decoder # BayesianPlacemapPositionDecoder\n",
    "active_two_step_decoder\n",
    "\n",
    "## SAVE OUT THE RESULTS of the decoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea8058a-d9a2-4a75-9de8-a6a3af0e690a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4cd691-4c3f-48d2-b5d3-150231fdba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PDF Output, NOTE this is single plot stuff: uses active_config_name\n",
    "from matplotlib.backends import backend_pdf\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import create_daily_programmatic_display_function_testing_folder_if_needed, build_pdf_metadata_from_display_context, programmatic_display_to_PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2967bd-dcf4-495c-8341-ae00e2230590",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2022-10-04 Modern Programmatic PDF outputs:\n",
    "# programmatic_display_to_PDF(curr_active_pipeline, curr_display_function_name='_display_plot_decoded_epoch_slices',  debug_print=False)\n",
    "programmatic_display_to_PDF(curr_active_pipeline, curr_display_function_name='_display_plot_decoded_epoch_slices', filter_epochs='ripple', decoding_time_bin_size=0.02, debug_test_max_num_slices=128, debug_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf583b3-0a6b-44be-90ac-ed8803bdd100",
   "metadata": {},
   "outputs": [],
   "source": [
    "programmatic_display_to_PDF(curr_active_pipeline, curr_display_function_name='_display_plot_decoded_epoch_slices', filter_epochs='laps', debug_test_max_num_slices=128, debug_print=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aef1b4c-44bf-44ed-b0c3-9ecaa20ddb6a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "source": [
    "### ðŸ”œ 2022-08-10 ðŸ‘ï¸â€ðŸ—¨ï¸ NOW: Plot animal positions on the computed posteriors:\n",
    "The process of plotting the animal position on the decoder plot needs to be refined. Currently it works by re-implementing \n",
    "\n",
    "ðŸ”œ NEXT STEP: TODO: Make a \"Datasource\" like approach perhaps to provide the actual animal position at each point in time?\n",
    "ðŸžðŸ”œ BUG TODO: Noticed that for Bapun Day5 data, it looks like the current position point is being plotted incorrectly (it doesn't even move across the space much)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e206f5-e582-4b4b-ae56-d235ef79c0b5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import ZhangReconstructionImplementation\n",
    "from neuropy.utils.mixins.binning_helpers import BinningContainer\n",
    "from pyphocorehelpers.indexing_helpers import build_pairwise_indicies\n",
    "\n",
    "global_epoch_name = curr_active_pipeline.active_completed_computation_result_names[-1] # 'maze'\n",
    "global_results = curr_active_pipeline.computation_results[global_epoch_name]['computed_data']\n",
    "sess =  curr_active_pipeline.computation_results[global_epoch_name].sess\n",
    "active_one_step_decoder = curr_active_pipeline.computation_results[global_epoch_name].computed_data.get('pf2D_Decoder', None)\n",
    "active_two_step_decoder = curr_active_pipeline.computation_results[global_epoch_name].computed_data.get('pf2D_TwoStepDecoder', None)\n",
    "active_extended_stats = curr_active_pipeline.computation_results[global_epoch_name].computed_data.get('extended_stats', None)\n",
    "active_firing_rate_trends = curr_active_pipeline.computation_results[global_epoch_name].computed_data.get('firing_rate_trends', None)\n",
    "time_bin_size_seconds, all_session_spikes, pf_included_spikes_only = active_firing_rate_trends['time_bin_size_seconds'], active_firing_rate_trends['all_session_spikes'], active_firing_rate_trends['pf_included_spikes_only']\n",
    "\n",
    "active_time_binning_container, active_time_window_edges, active_time_window_edges_binning_info, active_time_binned_unit_specific_binned_spike_rate, active_time_binned_unit_specific_binned_spike_counts = pf_included_spikes_only['time_binning_container'], pf_included_spikes_only['time_window_edges'], pf_included_spikes_only['time_window_edges_binning_info'], pf_included_spikes_only['time_binned_unit_specific_binned_spike_rate'], pf_included_spikes_only['time_binned_unit_specific_binned_spike_counts']\n",
    "\n",
    "ZhangReconstructionImplementation._validate_time_binned_spike_rate_df(active_time_binning_container.centers, active_time_binned_unit_specific_binned_spike_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e970db-653e-48d6-b484-eb2a41df2af7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## time_binned_unit_specific_binned_spike_rate mode:\n",
    "try:  \n",
    "    time_bins = active_firing_rate_trends.all_session_spikes.time_binning_container.centers # .shape # (4188,)\n",
    "    time_binned_unit_specific_binned_spike_rate_df = active_firing_rate_trends.all_session_spikes.time_binned_unit_specific_binned_spike_rate\n",
    "except KeyError:\n",
    "    time_bins, time_binned_unit_specific_binned_spike_rate_df = {}, {}\n",
    "\n",
    "ZhangReconstructionImplementation._validate_time_binned_spike_rate_df(time_bins, time_binned_unit_specific_binned_spike_rate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21afb753-1577-47b4-b0e7-75ed40136238",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cum_time = active_time_binning_container.centers.cumsum()\n",
    "cum_spike_counts = time_binned_unit_specific_binned_spike_counts.cumsum(axis=0)\n",
    "cum_spike_counts\n",
    "\n",
    "cum_spike_rates = cum_spike_counts.astype('float').copy()\n",
    "cum_spike_rates = cum_spike_rates / cum_time[:,None] # not sure this is right: no this is wrong, as not all time (cummulative time) is spent in this bine\n",
    "cum_spike_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d27da6-72ef-4a5e-bea9-9cba6908b83c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2519c589-4158-45dc-980e-6649d5944ad1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cum_spike_rates.plot(x='index', y='2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff70fc8b-1214-4902-bbb9-873e82b072b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "source": [
    "### Testing `ZhangReconstructionImplementation.time_bin_spike_counts_N_i(...)` and `ZhangReconstructionImplementation.compute_time_binned_spiking_activity(...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b2709a-d331-4b78-946a-30a08e07b071",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "time_bin_size_seconds = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d016bbf-f949-418c-adb0-6ae7ed08ccc9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from `_setup_time_bin_spike_counts_N_i`: using `ZhangReconstructionImplementation.time_bin_spike_counts_N_i(...)` this one now works too, but its output is transposed compared to the `_perform_firing_rate_trends_computation` version:\n",
    "active_session_spikes_df = sess.spikes_df.copy()\n",
    "unit_specific_binned_spike_counts, time_window_edges, time_window_edges_binning_info = ZhangReconstructionImplementation.time_bin_spike_counts_N_i(active_session_spikes_df.copy(), time_bin_size=time_bin_size_seconds, debug_print=False)  # np.shape(unit_specific_spike_counts): (4188, 108)\n",
    "time_binning_container = BinningContainer(edges=time_window_edges, edge_info=time_window_edges_binning_info)\n",
    "ZhangReconstructionImplementation._validate_time_binned_spike_counts(time_binning_container, unit_specific_binned_spike_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37434deb-7978-4857-afa0-058969f6f743",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Test `ZhangReconstructionImplementation.time_bin_spike_counts_N_i(...)` with manual bins -- `_setup_time_bin_spike_counts_N_i`: using `ZhangReconstructionImplementation.time_bin_spike_counts_N_i(...)` this one now works too, but its output is transposed compared to the `_perform_firing_rate_trends_computation` version:\n",
    "extant_time_window_edges = deepcopy(time_binning_container.edges)\n",
    "extant_time_window_edges_binning_info = deepcopy(time_binning_container.edge_info)\n",
    "active_session_spikes_df = sess.spikes_df.copy()\n",
    "unit_specific_binned_spike_counts, time_window_edges, time_window_edges_binning_info = ZhangReconstructionImplementation.time_bin_spike_counts_N_i(active_session_spikes_df.copy(), time_bin_size=time_bin_size_seconds,\n",
    "                                                                                                                                                   time_window_edges=extant_time_window_edges, time_window_edges_binning_info=extant_time_window_edges_binning_info, debug_print=False)  # np.shape(unit_specific_spike_counts): (4188, 108)\n",
    "time_binning_container = BinningContainer(edges=time_window_edges, edge_info=time_window_edges_binning_info)\n",
    "ZhangReconstructionImplementation._validate_time_binned_spike_counts(time_binning_container, unit_specific_binned_spike_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374ead33-f492-41f3-ba32-c9484b31f9cb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from `_perform_firing_rate_trends_computation`: using `ZhangReconstructionImplementation.compute_time_binned_spiking_activity(...)` this one now all makes sense:\n",
    "active_session_spikes_df = sess.spikes_df.copy()\n",
    "unit_specific_binned_spike_count_df, sess_time_window_edges, sess_time_window_edges_binning_info = ZhangReconstructionImplementation.compute_time_binned_spiking_activity(active_session_spikes_df.copy(), max_time_bin_size=time_bin_size_seconds, debug_print=False) # np.shape(unit_specific_spike_counts): (4188, 108)\n",
    "sess_time_binning_container = BinningContainer(edges=sess_time_window_edges, edge_info=sess_time_window_edges_binning_info)\n",
    "ZhangReconstructionImplementation._validate_time_binned_spike_rate_df(sess_time_binning_container.centers, unit_specific_binned_spike_count_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda254c5-9983-4877-bef6-ab35a567156a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "847e4180-3a58-4fcf-91fe-cc42335798e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "source": [
    "# Finally 2022-12-13 - Efficient PfND_TimeDependent batch snapshots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba34f36c-22d9-422c-81b2-b31f9bc732ba",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.ExtendedStats import compute_snapshot_differences\n",
    "\n",
    "global_epoch_name = curr_active_pipeline.active_completed_computation_result_names[-1] # 'maze'\n",
    "global_results = curr_active_pipeline.computation_results[global_epoch_name]['computed_data']\n",
    "\n",
    "# ## Make new pf_1D_dt:\n",
    "computation_result = curr_active_pipeline.computation_results[global_epoch_name]\n",
    "active_session, pf_computation_config = computation_result.sess, computation_result.computation_config.pf_params\n",
    "active_session_spikes_df, active_pos, computation_config, active_epoch_placefields1D, active_epoch_placefields2D, included_epochs, should_force_recompute_placefields = active_session.spikes_df, active_session.position, pf_computation_config, None, None, pf_computation_config.computation_epochs, True\n",
    "active_pf_1D_dt = PfND_TimeDependent(deepcopy(active_session_spikes_df), deepcopy(active_pos.linear_pos_obj), epochs=included_epochs,\n",
    "                                    speed_thresh=computation_config.speed_thresh, frate_thresh=computation_config.frate_thresh,\n",
    "                                    grid_bin=computation_config.grid_bin, grid_bin_bounds=computation_config.grid_bin_bounds, smooth=computation_config.smooth)\n",
    "\n",
    "out_pair_indicies = build_pairwise_indicies(np.arange(active_time_binning_container.edge_info.num_bins))\n",
    "time_intervals = active_time_binning_container.edges[out_pair_indicies] # .shape # (4153, 2)\n",
    "# time_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dbd063-4037-41f6-a709-6853f94e4c28",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Entirely independent computations for binned_times:\n",
    "# active_pf_1D_dt.reset()\n",
    "\n",
    "out_list_t = []\n",
    "out_list = []\n",
    "for start_t, end_t in time_intervals:\n",
    "    out_list_t.append(end_t)\n",
    "    \n",
    "    ## Inline version that reuses active_pf_1D_dt directly:\n",
    "    # out_list.append(active_pf_1D_dt.complete_time_range_computation(start_t, end_t, assign_results_to_member_variables=False))\n",
    "    # Static version uses the static variables of `active_pf_1D_dt`:\n",
    "    computed_out_results = PfND_TimeDependent.perform_time_range_computation(active_pf_1D_dt.all_time_filtered_spikes_df, active_pf_1D_dt.all_time_filtered_pos_df, position_srate=active_pf_1D_dt.position_srate,\n",
    "                                                                 xbin=active_pf_1D_dt.xbin, ybin=active_pf_1D_dt.ybin,\n",
    "                                                                 start_time=start_t, end_time=end_t,\n",
    "                                                                 included_neuron_IDs=active_pf_1D_dt.included_neuron_IDs, active_computation_config=active_pf_1D_dt.config, override_smooth=active_pf_1D_dt.smooth) # previously active_computation_config=None\n",
    "    out_list.append(computed_out_results)\n",
    "    \n",
    "\n",
    "out_list # len(out_list) # 4153\n",
    "out_list_t = np.array(out_list_t)\n",
    "historical_snapshots = {float(t):v for t, v in zip(out_list_t, out_list)} # build a dict<float:PlacefieldSnapshot>\n",
    " # {1.9991045125061646: <neuropy.analyses.time_dependent_placefields.PlacefieldSnapshot at 0x16c2b74fb20>, 2.4991045125061646: <neuropy.analyses.time_dependent_placefields.PlacefieldSnapshot at 0x168acfb3bb0>, ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca25202-7e8f-4758-8c17-dba3162a5bd7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "active_pf_1D_dt.historical_snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a953959-5d94-4c0e-b7ad-cacc8f81a524",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "active_pf_1D_dt.included_neuron_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc63d35a-ff86-4570-9a64-b80b4f3ed04c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "historical_snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752a95d6-ea6e-4425-acb0-da220e2d23b3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "post_update_times, pf_overlap_results, flat_relative_entropy_results, flat_jensen_shannon_distance_results = compute_snapshot_differences(historical_snapshots)\n",
    "relative_entropy_result_dicts_list = [a_val_dict['relative_entropy_result_dict'] for a_val_dict in pf_overlap_results]\n",
    "long_short_rel_entr_curves_list = [a_val_dict['long_short_rel_entr_curve'] for a_val_dict in relative_entropy_result_dicts_list] # [0].shape # (108, 63) = (n_neurons, n_xbins)\n",
    "short_long_rel_entr_curves_list = [a_val_dict['short_long_rel_entr_curve'] for a_val_dict in relative_entropy_result_dicts_list]\n",
    "long_short_rel_entr_curves_frames = np.stack([a_val_dict['long_short_rel_entr_curve'] for a_val_dict in relative_entropy_result_dicts_list]) # build a 3D array (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "short_long_rel_entr_curves_frames = np.stack([a_val_dict['short_long_rel_entr_curve'] for a_val_dict in relative_entropy_result_dicts_list]) # build a 3D array (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4396a90f-c52d-4860-901a-3fe8fb87c838",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# NEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cbb997-b00d-4d44-bfb1-fee9321a5df5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import ZhangReconstructionImplementation\n",
    "from neuropy.utils.mixins.binning_helpers import BinningContainer\n",
    "from pyphocorehelpers.indexing_helpers import build_pairwise_indicies\n",
    "from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.ExtendedStats import compute_snapshot_differences\n",
    "\n",
    "global_epoch_name = curr_active_pipeline.active_completed_computation_result_names[-1] # 'maze'\n",
    "global_results = curr_active_pipeline.computation_results[global_epoch_name]['computed_data']\n",
    "sess =  curr_active_pipeline.computation_results[global_epoch_name].sess\n",
    "active_one_step_decoder = curr_active_pipeline.computation_results[global_epoch_name].computed_data.get('pf2D_Decoder', None)\n",
    "active_two_step_decoder = curr_active_pipeline.computation_results[global_epoch_name].computed_data.get('pf2D_TwoStepDecoder', None)\n",
    "active_extended_stats = curr_active_pipeline.computation_results[global_epoch_name].computed_data.get('extended_stats', None)\n",
    "active_firing_rate_trends = curr_active_pipeline.computation_results[global_epoch_name].computed_data.get('firing_rate_trends', None)\n",
    "time_bin_size_seconds, all_session_spikes, pf_included_spikes_only = active_firing_rate_trends['time_bin_size_seconds'], active_firing_rate_trends['all_session_spikes'], active_firing_rate_trends['pf_included_spikes_only']\n",
    "\n",
    "active_time_binning_container, active_time_window_edges, active_time_window_edges_binning_info, active_time_binned_unit_specific_binned_spike_rate, active_time_binned_unit_specific_binned_spike_counts = pf_included_spikes_only['time_binning_container'], pf_included_spikes_only['time_window_edges'], pf_included_spikes_only['time_window_edges_binning_info'], pf_included_spikes_only['time_binned_unit_specific_binned_spike_rate'], pf_included_spikes_only['time_binned_unit_specific_binned_spike_counts']\n",
    "\n",
    "ZhangReconstructionImplementation._validate_time_binned_spike_rate_df(active_time_binning_container.centers, active_time_binned_unit_specific_binned_spike_counts)\n",
    "\n",
    "\n",
    "# ## Make new pf_1D_dt:\n",
    "computation_result = curr_active_pipeline.computation_results[global_epoch_name]\n",
    "active_session, pf_computation_config = computation_result.sess, computation_result.computation_config.pf_params\n",
    "active_session_spikes_df, active_pos, computation_config, active_epoch_placefields1D, active_epoch_placefields2D, included_epochs, should_force_recompute_placefields = active_session.spikes_df, active_session.position, pf_computation_config, None, None, pf_computation_config.computation_epochs, True\n",
    "active_pf_1D_dt = PfND_TimeDependent(deepcopy(active_session_spikes_df), deepcopy(active_pos.linear_pos_obj), epochs=included_epochs,\n",
    "                                    speed_thresh=computation_config.speed_thresh, frate_thresh=computation_config.frate_thresh,\n",
    "                                    grid_bin=computation_config.grid_bin, grid_bin_bounds=computation_config.grid_bin_bounds, smooth=computation_config.smooth)\n",
    "\n",
    "out_pair_indicies = build_pairwise_indicies(np.arange(active_time_binning_container.edge_info.num_bins))\n",
    "time_intervals = active_time_binning_container.edges[out_pair_indicies] # .shape # (4153, 2)\n",
    "# time_intervals\n",
    "\n",
    "## Entirely independent computations for binned_times:\n",
    "# active_pf_1D_dt.reset()\n",
    "\n",
    "out_list_t = []\n",
    "out_list = []\n",
    "for start_t, end_t in time_intervals:\n",
    "    out_list_t.append(end_t)\n",
    "    \n",
    "    ## Inline version that reuses active_pf_1D_dt directly:\n",
    "    # out_list.append(active_pf_1D_dt.complete_time_range_computation(start_t, end_t, assign_results_to_member_variables=False))\n",
    "    # Static version uses the static variables of `active_pf_1D_dt`:\n",
    "    computed_out_results = PfND_TimeDependent.perform_time_range_computation(active_pf_1D_dt.all_time_filtered_spikes_df, active_pf_1D_dt.all_time_filtered_pos_df, position_srate=active_pf_1D_dt.position_srate,\n",
    "                                                                 xbin=active_pf_1D_dt.xbin, ybin=active_pf_1D_dt.ybin,\n",
    "                                                                 start_time=start_t, end_time=end_t,\n",
    "                                                                 included_neuron_IDs=active_pf_1D_dt.included_neuron_IDs, active_computation_config=active_pf_1D_dt.config, override_smooth=active_pf_1D_dt.smooth) # previously active_computation_config=None\n",
    "    out_list.append(computed_out_results)\n",
    "    \n",
    "\n",
    "out_list # len(out_list) # 4153\n",
    "out_list_t = np.array(out_list_t)\n",
    "historical_snapshots = {float(t):v for t, v in zip(out_list_t, out_list)} # build a dict<float:PlacefieldSnapshot>\n",
    " # {1.9991045125061646: <neuropy.analyses.time_dependent_placefields.PlacefieldSnapshot at 0x16c2b74fb20>, 2.4991045125061646: <neuropy.analyses.time_dependent_placefields.PlacefieldSnapshot at 0x168acfb3bb0>, ...}\n",
    "\n",
    "post_update_times, pf_overlap_results, flat_relative_entropy_results, flat_jensen_shannon_distance_results = compute_snapshot_differences(historical_snapshots)\n",
    "relative_entropy_result_dicts_list = [a_val_dict['relative_entropy_result_dict'] for a_val_dict in pf_overlap_results]\n",
    "long_short_rel_entr_curves_list = [a_val_dict['long_short_rel_entr_curve'] for a_val_dict in relative_entropy_result_dicts_list] # [0].shape # (108, 63) = (n_neurons, n_xbins)\n",
    "short_long_rel_entr_curves_list = [a_val_dict['short_long_rel_entr_curve'] for a_val_dict in relative_entropy_result_dicts_list]\n",
    "long_short_rel_entr_curves_frames = np.stack([a_val_dict['long_short_rel_entr_curve'] for a_val_dict in relative_entropy_result_dicts_list]) # build a 3D array (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)\n",
    "short_long_rel_entr_curves_frames = np.stack([a_val_dict['short_long_rel_entr_curve'] for a_val_dict in relative_entropy_result_dicts_list]) # build a 3D array (4152, 108, 63) = (n_post_update_times, n_neurons, n_xbins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14e43d4-4f55-4c8d-bc49-c0fd75c49822",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Show basic relative entropy vs. time plot:\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(post_update_times, flat_relative_entropy_results)\n",
    "ax.set_ylabel('Relative Entropy')\n",
    "ax.set_xlabel('t (seconds)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0633eefe-7860-492e-80a2-d180f53efa07",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# heatmap\n",
    "fig, ax = plt.subplots()\n",
    "# ax.plot(post_update_times, flat_relative_entropy_results)\n",
    "ax.imshow(flat_relative_entropy_results.T)\n",
    "ax.set_ylabel('Relative Entropy')\n",
    "ax.set_xlabel('t (seconds)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644e5547-8869-42f8-beae-9dddae6f4bcc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# \"Surpise\": unit of a [Wow]\n",
    "# \"Startle\": the first derivative of \"Surpise\" with a unit of a [Gasp]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac5f7c4-6c31-49a8-882b-2d15621c5708",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from numpy import inf\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "# Replace np.inf with a maximally high value.\n",
    "inf_value_mask = np.isinf(flat_relative_entropy_results) # all the infinte values\n",
    "\n",
    "normalized_flat_relative_entropy_results = flat_relative_entropy_results.copy()\n",
    "normalized_flat_relative_entropy_results[normalized_flat_relative_entropy_results == inf] = 0  # zero out the infinite values for normalization to the feature range (-1, 1)\n",
    "normalized_flat_relative_entropy_results = minmax_scale(normalized_flat_relative_entropy_results, feature_range=(-1, 1)) # normalize to the feature_range (-1, 1)\n",
    "\n",
    "# Restore the infinite values at the specified value:\n",
    "# normalized_flat_relative_entropy_results[inf_value_mask] = 0.0\n",
    "normalized_flat_relative_entropy_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304dc728-b4cf-44f9-ab5e-38ada98d79e9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(post_update_times, normalized_flat_relative_entropy_results)\n",
    "ax.set_ylabel('Normalized Relative Entropy')\n",
    "ax.set_xlabel('t (seconds)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7348b8f-7836-4a26-935f-e71d399b7b6c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "source": [
    "## Plotting Crap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d125005b-9c58-4747-b877-01e680c112fb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Python\n",
    "import pandas as pd\n",
    "# from prophet import Prophet\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6237067-21a1-4e52-a84b-d34bff1e39ac",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "ax.stackplot(post_update_times, flat_relative_entropy_results.T, baseline=\"sym\")\n",
    "ax.axhline(0, color=\"black\", ls=\"--\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3ac66a-c9b7-4dc9-a1c4-1100c2d0a15b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47dd52c-e03e-428e-99c5-bf3d213c72f1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow\n",
    "\n",
    "out = BasicBinnedImageRenderingWindow(flat_relative_entropy_results, post_update_times, active_pf_1D_dt.xbin_labels, name='relative_entropy', title=\"Relative Entropy per Pos (X) @ time (t)\", variable_label='Rel Entropy')\n",
    "out\n",
    "# out.add_data(row=1, col=0, matrix=active_eloy_analysis.pf_overlapDensity_2D, xbins=active_pf_2D_dt.xbin_labels, ybins=active_pf_2D_dt.ybin_labels, name='pf_overlapDensity', title='pf overlapDensity metric', variable_label='pf overlapDensity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e26fcf-a3d3-4753-9b13-d72781d871f6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Examples.pyqtplot_Matrix import MatrixRenderingWindow\n",
    "from pyphoplacecellanalysis.External.pyqtgraph.Qt import QtCore, QtGui, QtWidgets\n",
    "\n",
    "# QtWidgets\n",
    "# out_old = MatrixRenderingWindow("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7be914-2eea-4ccb-9d04-dec7ebea2e42",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "out.ui.graphics_layout.setMinimumHeight(out.params.all_plots_height)\n",
    "# out.ui.graphics_layout.setSizeAdjustPolicy()\n",
    "out.ui.graphics_layout.setSizePolicy(QtWidgets.QSizePolicy.Expanding, QtWidgets.QSizePolicy.MinimumExpanding)\n",
    "# out.ui.graphics_layout.setSizeAdjustPolicy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2292f2-46ef-4c73-b512-af61382bcf59",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# sizePolicy = QtWidgets.QSizePolicy(QtWidgets.QSizePolicy.Expanding, QtWidgets.QSizePolicy.MinimumExpanding)\n",
    "# sizePolicy.setHorizontalStretch(0)\n",
    "# sizePolicy.setVerticalStretch(0)\n",
    "# sizePolicy.setHeightForWidth(self.scroll_area.sizePolicy().hasHeightForWidth())\n",
    "# self.scroll_area.setSizePolicy(sizePolicy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79868d6d-a926-47de-98a9-673aed56890d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ax.pcolormesh(xgrid, ygrid, temp, cmap=\"magma\", vmin=MIN_TEMP, vmax=MAX_TEMP)\n",
    "# Invert the vertical axis\n",
    "ax.set_ylim(24, 0)\n",
    "# Set tick positions for both axes\n",
    "ax.yaxis.set_ticks([i for i in range(24)])\n",
    "ax.xaxis.set_ticks([10, 20, 30])\n",
    "# Remove ticks by setting their length to 0\n",
    "ax.yaxis.set_tick_params(length=0)\n",
    "ax.xaxis.set_tick_params(length=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4205079-dbba-40b9-b2a7-e5e9379e55a6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "post_update_times.shape # (4152,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3930c21-fd29-40c4-9c13-bc53fdb2272c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(flat_relative_entropy_results) # len(flat_relative_entropy_results) # 4152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429b9a3e-c041-4d7a-80bf-47d8524f69be",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "flat_relative_entropy_results.shape # (4152, 63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668b2908-3a94-46eb-ae4e-a5be44d293c3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "flat_jensen_shannon_distance_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79d7998-fcdc-49be-b163-e1d47544abc0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.unique(flat_relative_entropy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f82cd21-7590-4518-b005-cd53ecb313e2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.unique(flat_jensen_shannon_distance_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd173afc-d14f-4a22-9a81-f6a045e1b647",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ax.plot(flat_jensen_shannon_distance_results[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d92665-a1a6-48d7-b158-430b1ace7123",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(post_update_times, flat_relative_entropy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c914e532-93c4-42d9-969a-fd7128b0b1f2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(post_update_times, flat_relative_entropy_results)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d43581-e9c6-43cb-81c6-e3d597cd0456",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "long_short_rel_entr_curves_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25837e0-7f86-4c47-bc9b-3d41dde32378",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "flat_relative_entropy_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1549106-bdf5-48c4-8e9c-70a9b72c9708",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b184be5-5afa-4b9c-8b1f-249282304da2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "flat_jensen_shannon_distance_results.shape # (4152, 63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cad45c-2745-4bf1-8a8c-bac85b2dff7b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyphocorehelpers.print_helpers import print_object_memory_usage, print_dataframe_memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e8f8c9-1a10-4f1c-b0e0-ea327d358a1b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print_object_memory_usage(long_short_rel_entr_curves_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d0fcc7-e87f-47b0-b86b-b6a606621fe6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print_object_memory_usage(out_list) # object size: 331.506809 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01dedd6-ebf3-4532-a06b-350eee24c032",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print_object_memory_usage(out_list_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0e72f3-3325-4cd5-8b21-a0e9cf1be205",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print_object_memory_usage(out_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e421a11-caee-4e62-b186-ffca03c0cbc3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a_snapshot = out_list[0]\n",
    "a_snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e951c955-2bc6-40b4-b7f5-51920be2dd78",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "a_snapshot.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0027d9bf-1a19-41a9-b4e8-ae136c0b2c6e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(out_list) # 4153"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3025f6b5-b492-42c0-84cd-85abce1c1e8c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "out_list_t = np.array(out_list_t)\n",
    "out_list_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1564fee-1741-4342-9862-02f40256b379",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print_object_memory_usage(active_pf_1D_dt) # object size: 200.256337 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85965e1-ca95-4a9b-b029-8693e7ae099d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf28ec1-2fff-4214-944d-5b51b785a186",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# active_one_step_decoder.time_binning_container\n",
    "n_neurons = np.shape(self.unit_specific_time_binned_spike_counts)[0] > len(self.neuron_IDXs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58abd918-6a97-4189-b23c-be5be28750aa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Get the current positions at each of the time_window_centers:\n",
    "# active_resampled_measured_positions\n",
    "# active_extended_stats = active_computed_data.extended_stats\n",
    "time_binned_pos_df = active_extended_stats.time_binned_position_df\n",
    "active_resampled_pos_df = time_binned_pos_df  # 1717 rows Ã— 16 columns\n",
    "active_resampled_pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c0a808-f99d-43ce-b8e1-0fc5bf21e552",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "active_extended_stats.time_binned_position_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c89f30-1512-4b6b-9683-a6dfccd49f38",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "active_resampled_measured_positions = active_resampled_pos_df[['x','y']].to_numpy() # The measured positions resampled (interpolated) at the window centers. \n",
    "# np.shape(active_resampled_measured_positions) # (1911, 2)\n",
    "active_one_step_decoder.active_time_window_centers.shape # (1911,)\n",
    "print(f'active_one_step_decoder.active_time_window_centers.shape: {active_one_step_decoder.active_time_window_centers.shape}')\n",
    "# Note this has 2900 rows Ã— 24 columns and active_one_step_decoder.active_time_window_centers.shape is (2892,) for some reason. Shouldn't they be the same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4960d6eb-3b33-440f-b326-35f5449c5f32",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "active_resampled_pos_df # (62911,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d081d0e-5077-4961-823f-45e29047c3d8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "active_resampled_measured_positions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9393f2-0d56-46b5-ab94-eea2718d7e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider\n",
    "\n",
    "from PendingNotebookCode import _temp_debug_two_step_plots_animated_imshow\n",
    "\n",
    "# Get the decoders from the computation result:\n",
    "# active_one_step_decoder = computation_result.computed_data['pf2D_Decoder']\n",
    "# active_two_step_decoder = computation_result.computed_data.get('pf2D_TwoStepDecoder', None)\n",
    "# active_measured_positions = computation_result.sess.position.to_dataframe()\n",
    "\n",
    "def _debug_on_frame_update(new_frame_idx, ax):\n",
    "    print(f'_debug_on_frame_update(new_frame_idx: {new_frame_idx}, ax: {ax})')\n",
    "    pass\n",
    "\n",
    "# active_resampled_pos_df = active_computed_data.extended_stats.time_binned_position_df  # 1717 rows Ã— 16 columns\n",
    "\n",
    "# Simple plot type 1:\n",
    "# plotted_variable_name = kwargs.get('variable_name', 'p_x_given_n') # Tries to get the user-provided variable name, otherwise defaults to 'p_x_given_n'\n",
    "plotted_variable_name = 'p_x_given_n' # Tries to get the user-provided variable name, otherwise defaults to 'p_x_given_n'\n",
    "_temp_debug_two_step_plots_animated_imshow(active_one_step_decoder, active_two_step_decoder, active_computed_data.extended_stats.time_binned_position_df, variable_name=plotted_variable_name, update_callback_function=_debug_on_frame_update) # Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef20765-0f3e-4348-a12f-fceccf0ccb85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "curr_display_function_name = '_display_spike_rasters_pyqtplot_2D'\n",
    "curr_active_pipeline.display(curr_display_function_name, global_epoch_name, debug_print=False, enable_saving_to_disk=enable_saving_to_disk) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6322ea-88f5-475a-808d-340cd86ebff5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Works, displays my velocity/density result for both 2D and 1D:\n",
    "# out_plot_1D, out_plot_2D = curr_active_pipeline.display('_display_speed_vs_PFoverlapDensity_plots', active_config_name)\n",
    "curr_display_function_name = '_display_speed_vs_PFoverlapDensity_plots'\n",
    "plots = curr_active_pipeline.display(curr_display_function_name, global_epoch_name)\n",
    "plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01598d95-1b12-4d7f-9231-5c5384e68d77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "curr_display_function_name = '_display_placemaps_pyqtplot_2D'\n",
    "out_plots = curr_active_pipeline.display(curr_display_function_name, global_epoch_name, max_num_columns=8)    \n",
    "out_plots[1].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b64e53-1d01-43b7-818e-3f0c32b20e9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a_plot = plots[0] # PlotWidget \n",
    "# a_plot_item = a_plot.plotItem # PlotItem\n",
    "# a_plot.scene() # GraphicsScene\n",
    "export_pyqtgraph_plot(plots[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80051ed-8a89-4c83-a6e7-1095793d270f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# GUI/Widget Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2cf485-35f5-4966-9372-53e031714bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.gui.Qt.TopLevelWindowHelper import TopLevelWindowHelper\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg # Used to get the app for TopLevelWindowHelper.top_level_windows\n",
    "## For searching with `TopLevelWindowHelper.all_widgets(...)`:\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import Spike2DRaster\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike3DRaster import Spike3DRaster\n",
    "from pyphoplacecellanalysis.GUI.Qt.SpikeRasterWindows.Spike3DRasterWindowWidget import Spike3DRasterWindowWidget\n",
    "\n",
    "found_spike_raster_windows = TopLevelWindowHelper.all_widgets(pg.mkQApp(), searchType=Spike3DRasterWindowWidget)\n",
    "assert len(found_spike_raster_windows) == 1, f\"found {len(found_spike_raster_windows)} Spike3DRasterWindowWidget windows using TopLevelWindowHelper.all_widgets(...) but require exactly one.\"\n",
    "spike_raster_window = found_spike_raster_windows[0]\n",
    "# Extras:\n",
    "active_2d_plot = spike_raster_window.spike_raster_plt_2d # <pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster.Spike2DRaster at 0x196c7244280>\n",
    "active_3d_plot = spike_raster_window.spike_raster_plt_3d # <pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster.Spike2DRaster at 0x196c7244280>\n",
    "main_graphics_layout_widget = active_2d_plot.ui.main_graphics_layout_widget # GraphicsLayoutWidget\n",
    "main_plot_widget = active_2d_plot.plots.main_plot_widget # PlotItem\n",
    "background_static_scroll_plot_widget = active_2d_plot.plots.background_static_scroll_window_plot # PlotItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f712f990-3ac6-450c-8e01-f8a51c9dc64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "widget, fig, ax = active_2d_plot.add_new_matplotlib_render_plot_widget(name='RelativeEntropy')\n",
    "\n",
    "## plot the `post_update_times`, and `flat_relative_entropy_results`\n",
    "_temp_out = ax.plot(post_update_times, flat_relative_entropy_results)\n",
    "\n",
    "# Perform Initial (one-time) update from source -> controlled:\n",
    "# This syncs the new widget up to the full data window (the entire session), not the active window:\n",
    "widget.on_window_changed(active_2d_plot.spikes_window.total_data_start_time, active_2d_plot.spikes_window.total_data_end_time)\n",
    "widget.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a66aec8-8869-4b3d-ba5d-2045c7b79dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "widget.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21f3eb0-236b-4291-bc05-25ce5e4f8b41",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### `matplotlib_view_widget` examples from 241 notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8acbb10-6078-4d96-afcb-95854a06a17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.sync_matplotlib_render_plot_widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a2a54d-a442-4cf3-9a64-f642de3f7967",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.sync_matplotlib_render_plot_widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346f5f94-80d0-418c-85f0-316bb506e4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52827ed6-4873-4cf3-ae70-0e29ed0b2308",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.ui.matplotlib_view_widget # MatplotlibTimeSynchronizedWidget "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e68889-3a48-4bce-98ad-f0e6e042a315",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.ui.matplotlib_view_widget.ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d90c8ec-572a-44ef-97a4-b442e40f9060",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.ui.dynamic_docked_widget_container.dynamic_display_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555f78e1-af9c-41fc-938d-f86c5b936611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dDisplayItem = active_2d_plot.ui.dynamic_docked_widget_container.find_display_dock(identifier=\"matplotlib_view_widget\") # Dock\n",
    "dDisplayItem = active_2d_plot.ui.dynamic_docked_widget_container.find_display_dock(identifier=\"RelativeEntropy\") # Dock\n",
    "dDisplayItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99be5320-b281-461e-b3ed-2b7504f24e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_most_likely_position_comparsions, plot_1D_most_likely_position_comparsions\n",
    "\n",
    "active_decoder = active_one_step_decoder\n",
    "# marginals_x, marginals_y = active_decoder.perform_build_marginals(p_x_given_n=active_decoder.p_x_given_n, most_likely_positions=active_decoder.most_likely_positions)\n",
    "marginals_x = active_decoder.marginal.x\n",
    "\n",
    "## Get the previously created matplotlib_view_widget figure/ax:\n",
    "# active_positions = marginals_x.most_likely_positions_1D\n",
    "active_positions = marginals_x.revised_most_likely_positions_1D\n",
    "fig, curr_ax = plot_1D_most_likely_position_comparsions(sess.position.to_dataframe(), ax=active_2d_plot.ui.matplotlib_view_widget.ax, time_window_centers=active_decoder.time_window_centers, xbin=active_decoder.xbin,\n",
    "                                                   posterior=marginals_x.p_x_given_n,\n",
    "                                                   active_most_likely_positions_1D=active_positions,\n",
    "                                                   enable_flat_line_drawing=False, debug_print=False)\n",
    "active_2d_plot.ui.matplotlib_view_widget.draw()\n",
    "active_2d_plot.sync_matplotlib_render_plot_widget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e00d39-760b-4c3e-bd50-e8aa55df38da",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.ui.matplotlib_view_widget.fig.clear()\n",
    "active_2d_plot.ui.matplotlib_view_widget.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9147bf42-6493-4fa3-87f1-2f20559741df",
   "metadata": {},
   "outputs": [],
   "source": [
    "currFig, currAx = curr_active_pipeline.display('_display_plot_marginal_1D_most_likely_position_comparisons', active_config_name, variable_name='x', posterior_name='p_x_given_n_and_x_prev', ax=active_2d_plot.ui.matplotlib_view_widget.ax) ## Current plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159be975-e999-4cb3-baa9-215e169552e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dDisplayItem = active_2d_plot.ui.dynamic_docked_widget_container.find_display_dock(identifier=\"matplotlib_view_widget\") # Dock\n",
    "# dDisplayItem.setOrientation('vertical', force=True)\n",
    "# dDisplayItem.setOrientation('horizontal', force=True)\n",
    "# dDisplayItem.updateStyle()\n",
    "# dDisplayItem.update()\n",
    "dDisplayItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ccb75a-a08a-4efe-9557-ca2ef9abe100",
   "metadata": {},
   "outputs": [],
   "source": [
    "## THE CORE WORKING VERSION - 2022-09-27 @ 4pm\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_most_likely_position_comparsions, plot_1D_most_likely_position_comparsions\n",
    "\n",
    "## Test Plotting just a single dimension of the 2D posterior:\n",
    "pho_custom_decoder = active_one_step_decoder # active_pf_2D\n",
    "# pho_custom_decoder = new_2D_decoder\n",
    "active_posterior = pho_custom_decoder.p_x_given_n\n",
    "# Collapse the 2D position posterior into two separate 1D (X & Y) marginal posteriors. Be sure to re-normalize each marginal after summing\n",
    "marginal_posterior_x = np.squeeze(np.sum(active_posterior, 1)) # sum over all y. Result should be [x_bins x time_bins]\n",
    "marginal_posterior_x = marginal_posterior_x / np.sum(marginal_posterior_x, axis=0) # sum over all positions for each time_bin (so there's a normalized distribution at each timestep)\n",
    "# np.shape(marginal_posterior_x) # (41, 3464)\n",
    "custom_2D_decoder_container = PhoUIContainer('active_pf_2D_decoder', figure_id=f'active_pf_2D_decoder_most_likely')\n",
    "# custom_2D_decoder_container.fig, custom_2D_decoder_container.ax = plt.subplots(num=custom_2D_decoder_container.figure_id, ncols=1, nrows=1, figsize=(15,15), clear=True, sharex=True, sharey=False, constrained_layout=True)\n",
    "\n",
    "custom_2D_decoder_container.fig = active_2d_plot.ui.matplotlib_view_widget.getFigure()\n",
    "custom_2D_decoder_container.ax = active_2d_plot.ui.matplotlib_view_widget.ax #getFigure().add_subplot(111)\n",
    "custom_2D_decoder_container.fig.suptitle(custom_2D_decoder_container.name)\n",
    "custom_2D_decoder_container.fig, custom_2D_decoder_container.ax = plot_1D_most_likely_position_comparsions(sess.position.to_dataframe(), ax=custom_2D_decoder_container.ax, time_window_centers=pho_custom_decoder.active_time_window_centers, xbin=pho_custom_decoder.xbin,\n",
    "                                                   posterior=marginal_posterior_x,\n",
    "                                                   active_most_likely_positions_1D=pho_custom_decoder.most_likely_positions[:,0].T,\n",
    "                                                   enable_flat_line_drawing=False, debug_print=False)\n",
    "\n",
    "active_2d_plot.ui.matplotlib_view_widget.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d565f473-58b0-45cd-a453-9966c2893b67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phoviz_ultimate]",
   "language": "python",
   "name": "conda-env-phoviz_ultimate-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
