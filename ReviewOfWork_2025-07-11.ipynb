{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33f7f339",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[0️⃣ ReviewOfWork (Main Notebook) - Imports](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77d98a7b",
   "metadata": {
    "tags": [
     "run-group-0-interactive",
     "run-group-0",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n",
      "PyQt5 formatters registered successfully\n",
      "MAX_LINE_LENGTH: 240\n",
      "doc_output_parent_folder: C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\EXTERNAL\\DEVELOPER_NOTES\\DataStructureDocumentation\n",
      "field.name: \"merged_directional_placefields\", variable_name: \"merged_directional_placefields\"\n",
      "field.name: \"rank_order_shuffle_analysis\", variable_name: \"rank_order_shuffle_analysis\"\n",
      "field.name: \"directional_decoders_decode_continuous\", variable_name: \"directional_decoders_decode_continuous\"\n",
      "field.name: \"directional_decoders_evaluate_epochs\", variable_name: \"directional_decoders_evaluate_epochs\"\n",
      "field.name: \"directional_decoders_epoch_heuristic_scoring\", variable_name: \"directional_decoders_epoch_heuristic_scoring\"\n",
      "field.name: \"directional_train_test_split\", variable_name: \"directional_train_test_split\"\n",
      "field.name: \"long_short_decoding_analyses\", variable_name: \"long_short_decoding_analyses\"\n",
      "field.name: \"long_short_rate_remapping\", variable_name: \"long_short_rate_remapping\"\n",
      "field.name: \"long_short_inst_spike_rate_groups\", variable_name: \"long_short_inst_spike_rate_groups\"\n",
      "field.name: \"wcorr_shuffle_analysis\", variable_name: \"wcorr_shuffle_analysis\"\n",
      "field.name: \"non_pbe_epochs_results\", variable_name: \"non_pbe_epochs_results\"\n",
      "field.name: \"position_decoding\", variable_name: \"position_decoding\"\n",
      "field.name: \"perform_specific_epochs_decoding\", variable_name: \"perform_specific_epochs_decoding\"\n",
      "field.name: \"DEP_ratemap_peaks\", variable_name: \"DEP_ratemap_peaks\"\n",
      "field.name: \"ratemap_peaks_prominence2d\", variable_name: \"ratemap_peaks_prominence2d\"\n",
      "DAY_DATE_STR: 2025-07-11, DAY_DATE_TO_USE: 2025-07-11\n",
      "NOW_DATETIME: 2025-07-11_0730AM, NOW_DATETIME_TO_USE: 2025-07-11_0730AM\n",
      "global_data_root_parent_path changed to W:\\Data\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3898864efc445bbc57f74a1cbfd903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='Data Root:', layout=Layout(width='auto'), options=(WindowsPath('W:/Data'),), style=ToggleButtonsStyle(button_width='max-content'), tooltip='global_data_root_parent_path', value=WindowsPath('W:/Data'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%config IPCompleter.use_jedi = False\n",
    "# %xmode Verbose\n",
    "# %xmode context\n",
    "%pdb off\n",
    "%load_ext autoreload\n",
    "%autoreload 3\n",
    "# # Add exclusions for metaclass-using modules\n",
    "# %aimport -neuropy.core.session.dataSession\n",
    "# %aimport -neuropy.core.session.Formats.BaseDataSessionFormats\n",
    "# %aimport -neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat\n",
    "# %aimport -neuropy.core.session.Formats.Specific.BapunDataSessionFormat \n",
    "# %aimport -neuropy.core.session.Formats.Specific.RachelDataSessionFormat\n",
    "# %aimport -neuropy.core.session.Formats.Specific.HiroDataSessionFormt\n",
    "\n",
    "# !pip install viztracer\n",
    "%load_ext viztracer\n",
    "from viztracer import VizTracer\n",
    "\n",
    "# %load_ext memory_profiler\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "os.environ['QT_API'] = 'pyqt5'\n",
    "os.environ['PYQTGRAPH_QT_LIB'] = 'PyQt5'\n",
    "\n",
    "# from PyQt5.QtWebEngineWidgets import QWebEngineView ## this must come first, before any QtApplication is made: 'ImportError: QtWebEngineWidgets must be imported or Qt.AA_ShareOpenGLContexts must be set before a QCoreApplication instance is created'\n",
    "\n",
    "# required to enable non-blocking interaction:\n",
    "%gui qt5\n",
    "\n",
    "import importlib\n",
    "from copy import deepcopy\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "# pd.options.mode.dtype_backend = 'pyarrow' # use new pyarrow backend instead of numpy\n",
    "\n",
    "from attrs import define, field, fields, Factory, make_class\n",
    "import tables as tb\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Pho's Formatting Preferences\n",
    "import builtins\n",
    "\n",
    "import IPython\n",
    "from IPython.core.formatters import PlainTextFormatter\n",
    "from IPython import get_ipython\n",
    "\n",
    "from pyphocorehelpers.preferences_helpers import set_pho_preferences, set_pho_preferences_concise, set_pho_preferences_verbose\n",
    "set_pho_preferences_concise()\n",
    "# Jupyter-lab enable printing for any line on its own (instead of just the last one in the cell)\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# BEGIN PPRINT CUSTOMIZATION ___________________________________________________________________________________________ #\n",
    "\n",
    "## IPython pprint\n",
    "from pyphocorehelpers.pprint import wide_pprint, wide_pprint_ipython, wide_pprint_jupyter, MAX_LINE_LENGTH\n",
    "# Override default pprint\n",
    "builtins.pprint = wide_pprint\n",
    "\n",
    "ip = get_ipython()\n",
    "\n",
    "from pyphocorehelpers.ipython_helpers import CustomFormatterMagics\n",
    "\n",
    "# Register the magic\n",
    "get_ipython().register_magics(CustomFormatterMagics)\n",
    "\n",
    "\n",
    "\n",
    "from pyphocorehelpers.pyqt_ipython_rendering_helpers import PyQtFormatters\n",
    "from pyphoplacecellanalysis.General.Mixins.DisplayHelpers import debug_widget_geometry\n",
    "\n",
    "# Register formatters for specific PyQt5 types\n",
    "# Create an instance and register formatters\n",
    "qt_formatters = PyQtFormatters()\n",
    "qt_formatters.register()\n",
    "\n",
    "\n",
    "from pyphocorehelpers.print_helpers import render_scrollable_colored_table_from_dataframe, render_scrollable_colored_table\n",
    "\n",
    "# # import pho_jupyter_preview_widget\n",
    "# from pyphocorehelpers.pho_jupyter_preview_widget.ipython_helpers import PreviewWidgetMagics\n",
    "# from pyphocorehelpers.pho_jupyter_preview_widget.display_helpers import array_repr_with_graphical_preview\n",
    "\n",
    "# # # # Register the magic\n",
    "# ip.register_magics(PreviewWidgetMagics)\n",
    "\n",
    "# %config_ndarray_preview width=500\n",
    "\n",
    "# Register the custom display function for NumPy arrays\n",
    "# ip.display_formatter.formatters['text/html'].for_type(np.ndarray, lambda arr: array_preview_with_graphical_shape_repr_html(arr))\n",
    "# ip = array_repr_with_graphical_shape(ip=ip)\n",
    "# ip = array_repr_with_graphical_preview(ip=ip)\n",
    "# ip = dataframe_show_more_button(ip=ip)\n",
    "\n",
    "print(f'MAX_LINE_LENGTH: {MAX_LINE_LENGTH}')\n",
    "text_formatter: PlainTextFormatter = ip.display_formatter.formatters['text/plain']\n",
    "text_formatter.max_width = MAX_LINE_LENGTH\n",
    "text_formatter.for_type(object, wide_pprint_jupyter)\n",
    "\n",
    "\n",
    "# END PPRINT CUSTOMIZATION ___________________________________________________________________________________________ #\n",
    "\n",
    "from pyphocorehelpers.print_helpers import get_now_time_str, get_now_day_str\n",
    "from pyphocorehelpers.indexing_helpers import get_dict_subset\n",
    "\n",
    "## Pho's Custom Libraries:\n",
    "from pyphocorehelpers.Filesystem.path_helpers import find_first_extant_path, file_uri_from_path\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "import pyphocorehelpers.programming_helpers as programming_helpers\n",
    "\n",
    "# NeuroPy (Diba Lab Python Repo) Loading\n",
    "# from neuropy import core\n",
    "from typing import Dict, List, Tuple, Optional, Callable, Union, Any\n",
    "from typing_extensions import TypeAlias\n",
    "import nptyping as ND\n",
    "from nptyping import NDArray\n",
    "import neuropy.utils.type_aliases as types\n",
    "\n",
    "from neuropy.core.session.Formats.BaseDataSessionFormats import DataSessionFormatRegistryHolder, find_local_session_paths\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.core.epoch import NamedTimerange, Epoch\n",
    "from neuropy.core.ratemap import Ratemap\n",
    "from neuropy.core.session.Formats.Specific.KDibaOldDataSessionFormat import KDibaOldDataSessionFormatRegisteredClass\n",
    "from neuropy.utils.matplotlib_helpers import matplotlib_file_only, matplotlib_configuration, matplotlib_configuration_update\n",
    "from neuropy.core.neuron_identities import NeuronIdentityTable, neuronTypesList, neuronTypesEnum\n",
    "from neuropy.utils.mixins.AttrsClassHelpers import AttrsBasedClassHelperMixin, serialized_field, serialized_attribute_field, non_serialized_field, custom_define\n",
    "from neuropy.utils.mixins.HDF5_representable import HDF_DeserializationMixin, post_deserialize, HDF_SerializationMixin, HDFMixin, HDF_Converter\n",
    "\n",
    "## For computation parameters:\n",
    "from neuropy.analyses.placefields import PlacefieldComputationParameters\n",
    "from neuropy.utils.dynamic_container import DynamicContainer\n",
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from neuropy.core.neurons import NeuronType\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from neuropy.core.position import Position\n",
    "from neuropy.core.session.dataSession import DataSession\n",
    "from neuropy.analyses.time_dependent_placefields import PfND_TimeDependent, PlacefieldSnapshot\n",
    "from neuropy.utils.debug_helpers import debug_print_placefield, debug_print_subsession_neuron_differences, debug_print_ratemap, debug_print_spike_counts, debug_plot_2d_binning, print_aligned_columns, parameter_sweeps, _plot_parameter_sweep, compare_placefields_info\n",
    "from neuropy.utils.indexing_helpers import NumpyHelpers, union_of_arrays, intersection_of_arrays, find_desired_sort_indicies, paired_incremental_sorting\n",
    "from pyphocorehelpers.print_helpers import print_object_memory_usage, print_dataframe_memory_usage, print_value_overview_only, DocumentationFilePrinter, print_keys_if_possible, generate_html_string, document_active_variables\n",
    "from pyphocorehelpers.programming_helpers import metadata_attributes\n",
    "from pyphocorehelpers.function_helpers import function_attributes\n",
    "## Pho Programming Helpers:\n",
    "import inspect\n",
    "from pyphocorehelpers.print_helpers import DocumentationFilePrinter, TypePrintMode, print_keys_if_possible, debug_dump_object_member_shapes, print_value_overview_only, document_active_variables\n",
    "from pyphocorehelpers.programming_helpers import IPythonHelpers, PythonDictionaryDefinitionFormat, MemoryManagement, inspect_callable_arguments, get_arguments_as_optional_dict, GeneratedClassDefinitionType, CodeConversion\n",
    "from pyphocorehelpers.notebook_helpers import NotebookCellExecutionLogger\n",
    "from pyphocorehelpers.gui.Qt.TopLevelWindowHelper import TopLevelWindowHelper, print_widget_hierarchy\n",
    "from pyphocorehelpers.indexing_helpers import reorder_columns, reorder_columns_relative, dict_to_full_array\n",
    "from pyphocorehelpers.DataStructure.RenderPlots.MatplotLibRenderPlots import MatplotlibRenderPlots\n",
    "\n",
    "doc_output_parent_folder: Path = Path('EXTERNAL/DEVELOPER_NOTES/DataStructureDocumentation').resolve() # ../.\n",
    "print(f\"doc_output_parent_folder: {doc_output_parent_folder}\")\n",
    "assert doc_output_parent_folder.exists()\n",
    "\n",
    "_notebook_path:Path = Path(IPythonHelpers.try_find_notebook_filepath(IPython.extract_module_locals())).resolve() # Finds the path of THIS notebook\n",
    "# _notebook_execution_logger: NotebookCellExecutionLogger = NotebookCellExecutionLogger(notebook_path=_notebook_path, enable_logging_to_file=False) # Builds a logger that records info about this notebook\n",
    "\n",
    "# pyPhoPlaceCellAnalysis:\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import NeuropyPipeline # get_neuron_identities\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import export_pyqtgraph_plot\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_load_session, batch_extended_computations, batch_evaluate_required_computations, BatchPlotting # BatchPlotting.batch_extended_programmatic_figures\n",
    "\n",
    "\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.NeuropyPipeline import PipelineSavingScheme # used in perform_pipeline_save\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import PipelineJupyterHelpers, CustomProcessingPhases\n",
    "\n",
    "\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "pg.setConfigOptions(useOpenGL=True)    # Use OpenGL for rendering which handles larger coordinates\n",
    "\n",
    "from pyphocorehelpers.exception_helpers import ExceptionPrintingContext, CapturedException\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import JonathanFiringRateAnalysisResult\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import _find_any_context_neurons\n",
    "from pyphoplacecellanalysis.General.Batch.runBatch import BatchSessionCompletionHandler # for `post_compute_validate(...)`\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BasePositionDecoder\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsResults\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends # for `_perform_long_short_instantaneous_spike_rate_groups_analysis`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.LongShortTrackComputations import SingleBarResult, InstantaneousSpikeRateGroupsComputation, TruncationCheckingResults # for `BatchSessionCompletionHandler`, `AcrossSessionsAggregator`\n",
    "from pyphoplacecellanalysis.General.Mixins.CrossComputationComparisonHelpers import SplitPartitionMembership\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalComputationFunctions, DirectionalLapsResult, TrackTemplates, DecoderDecodedEpochsResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderGlobalComputationFunctions,  RankOrderComputationsContainer, RankOrderResult, RankOrderAnalyses\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import EpochComputationFunctions, EpochComputationsComputationsContainer, DecodingResultND, Compute_NonPBE_Epochs, KnownFilterEpochs\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.SequenceBasedComputations import WCorrShuffle, SequenceBasedComputationsContainer\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.ComputationFunctionRegistryHolder import ComputationFunctionRegistryHolder, computation_precidence_specifying_function, global_function\n",
    "\n",
    "from neuropy.utils.mixins.binning_helpers import transition_matrix\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import TransitionMatrixComputations\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates, get_proper_global_spikes_df\n",
    "\n",
    "from pyphocorehelpers.Filesystem.path_helpers import set_posix_windows\n",
    "\n",
    "from pyphocorehelpers.assertion_helpers import Assert\n",
    "\n",
    "# Plotting\n",
    "# import pylustrator # customization of figures\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "_bak_rcParams = mpl.rcParams.copy()\n",
    "\n",
    "matplotlib.use('Qt5Agg')\n",
    "# %matplotlib inline\n",
    "# %matplotlib auto\n",
    "\n",
    "# _restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# import pylustrator # call `pylustrator.start()` before creating your first figure in code.\n",
    "from pyphoplacecellanalysis.Pho2D.matplotlib.visualize_heatmap import visualize_heatmap, visualize_heatmap_pyqtgraph # used in `plot_kourosh_activity_style_figure`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multiple_raster_plot, plot_raster_plot\n",
    "from pyphoplacecellanalysis.General.Mixins.DataSeriesColorHelpers import UnitColoringMode, DataSeriesColorHelpers\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import _build_default_tick, build_scatter_plot_kwargs\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.Render2DScrollWindowPlot import Render2DScrollWindowPlotMixin, ScatterItemData\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import BatchPlotting # BatchPlotting.batch_extended_programmatic_figures, BatchPlotting.batch_programmatic_figures\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.SpikeAnalysis import SpikeRateTrends\n",
    "from pyphoplacecellanalysis.General.Mixins.SpikesRenderingBaseMixin import SpikeEmphasisState\n",
    "from pyphoplacecellanalysis.General.Model.SpecificComputationParameterTypes import ComputationKWargParameters\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PAPER_FIGURE_figure_1_add_replay_epoch_rasters, PAPER_FIGURE_figure_1_full, PAPER_FIGURE_figure_3, main_complete_figure_generations\n",
    "# from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import *\n",
    "\n",
    "# Jupyter Widget Interactive\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import interactive_pipeline_widget, interactive_pipeline_files\n",
    "from pyphocorehelpers.gui.Jupyter.simple_widgets import fullwidth_path_widget, render_colors\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import PipelineJupyterHelpers, CustomProcessingPhases, PipelinePickleFileSelectorWidget\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.PhoContainerTool import GenericMatplotlibContainer, GenericPyQtGraphContainer, PhoBaseContainerTool\n",
    "\n",
    "from datetime import datetime, date, timedelta\n",
    "from pyphocorehelpers.print_helpers import get_now_day_str, get_now_rounded_time_str\n",
    "\n",
    "DAY_DATE_STR: str = date.today().strftime(\"%Y-%m-%d\")\n",
    "DAY_DATE_TO_USE = f'{DAY_DATE_STR}' # used for filenames throught the notebook\n",
    "print(f'DAY_DATE_STR: {DAY_DATE_STR}, DAY_DATE_TO_USE: {DAY_DATE_TO_USE}')\n",
    "\n",
    "NOW_DATETIME: str = get_now_rounded_time_str()\n",
    "NOW_DATETIME_TO_USE = f'{NOW_DATETIME}' # used for filenames throught the notebook\n",
    "print(f'NOW_DATETIME: {NOW_DATETIME}, NOW_DATETIME_TO_USE: {NOW_DATETIME_TO_USE}')\n",
    "\n",
    "def get_global_variable(var_name):\n",
    "    \"\"\" used by `PipelineJupyterHelpers._build_pipeline_custom_processing_mode_selector_widget(...)` to update the notebook's variables \"\"\"\n",
    "    return globals()[var_name]\n",
    "    \n",
    "def update_global_variable(var_name, value):\n",
    "    \"\"\" used by `PipelineJupyterHelpers._build_pipeline_custom_processing_mode_selector_widget(...)` to update the notebook's variables \"\"\"\n",
    "    globals()[var_name] = value\n",
    "\n",
    "from pyphocorehelpers.gui.Jupyter.simple_widgets import build_global_data_root_parent_path_selection_widget\n",
    "all_paths = [Path(r'/home/halechr/FastData'), Path('/Volumes/SwapSSD/Data'), Path('/Users/pho/data'), Path(r'/media/halechr/MAX/Data'), Path(r'W:\\Data'), Path(r'/home/halechr/cloud/turbo/Data'), Path(r'/Volumes/MoverNew/data'), Path(r'/home/halechr/turbo/Data'), Path(r'/Users/pho/cloud/turbo/Data')] # Path('/Volumes/FedoraSSD/FastData'), \n",
    "global_data_root_parent_path = None\n",
    "def on_user_update_path_selection(new_path: Path):\n",
    "    global global_data_root_parent_path\n",
    "    new_global_data_root_parent_path = new_path.resolve()\n",
    "    global_data_root_parent_path = new_global_data_root_parent_path\n",
    "    print(f'global_data_root_parent_path changed to {global_data_root_parent_path}')\n",
    "    assert global_data_root_parent_path.exists(), f\"global_data_root_parent_path: {global_data_root_parent_path} does not exist! Is the right computer's config commented out above?\"\n",
    "            \n",
    "global_data_root_parent_path_widget = build_global_data_root_parent_path_selection_widget(all_paths, on_user_update_path_selection)\n",
    "global_data_root_parent_path_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e81646",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[0️⃣ Load Pipeline](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f07773d",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-0",
     "all",
     "run-group-0-interactive",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basedir: W:\\Data\\KDIBA\\gor01\\one\\2006-6-12_15-55-31\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bed69e8385e409f96f3500cfe7fad02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(ToggleButtons(description='CustomProcessingPhases:', options=('clean_run', 'continued_run', 'final_run'), style=ToggleButtonsStyle(description_width='initial'), tooltips=('Select clean_run', 'Select continued_run', 'Select final_run'), value='clean_run'), Label(value='Empty')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving_mode: PipelineSavingScheme.SKIP_SAVING, force_reload: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['lap_direction_determination',\n",
       " 'pf_computation',\n",
       " 'pfdt_computation',\n",
       " 'position_decoding',\n",
       " 'firing_rate_trends',\n",
       " 'extended_stats',\n",
       " 'long_short_decoding_analyses',\n",
       " 'jonathan_firing_rate_analysis',\n",
       " 'long_short_fr_indicies_analyses',\n",
       " 'long_short_post_decoding',\n",
       " 'long_short_inst_spike_rate_groups',\n",
       " 'long_short_endcap_analysis',\n",
       " 'split_to_directional_laps',\n",
       " 'merged_directional_placefields',\n",
       " 'directional_decoders_decode_continuous',\n",
       " 'directional_decoders_evaluate_epochs',\n",
       " 'directional_decoders_epoch_heuristic_scoring',\n",
       " 'non_PBE_epochs_results',\n",
       " 'generalized_specific_epochs_decoding']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.2.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 9;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.2.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.2.2.min.js\", \"https://cdn.holoviz.org/panel/1.2.3/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      Bokeh = root.Bokeh;\n      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      if (!reloading && (!bokeh_loaded || is_dev)) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='6c47b4ed-6a24-451c-a162-ac354063c9a9'>\n",
       "  <div id=\"ce40cb53-c049-4e1b-b643-aa2f79e00428\" data-root-id=\"6c47b4ed-6a24-451c-a162-ac354063c9a9\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"5efdf969-1709-4ba9-be7d-cc568c614156\":{\"version\":\"3.2.2\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"6c47b4ed-6a24-451c-a162-ac354063c9a9\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"2db642a1-7c56-484c-9508-916f2bb6edcb\",\"attributes\":{\"plot_id\":\"6c47b4ed-6a24-451c-a162-ac354063c9a9\",\"comm_id\":\"f3d65d848314422c9ae6e23b48fd9414\",\"client_comm_id\":\"b81b0057ed444094b9ad5220d93e9443\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"5efdf969-1709-4ba9-be7d-cc568c614156\",\"roots\":{\"6c47b4ed-6a24-451c-a162-ac354063c9a9\":\"ce40cb53-c049-4e1b-b643-aa2f79e00428\"},\"root_ids\":[\"6c47b4ed-6a24-451c-a162-ac354063c9a9\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  const is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1\n",
       "  function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version && !is_dev) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "6c47b4ed-6a24-451c-a162-ac354063c9a9"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.2.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n  var reloading = true;\n  var Bokeh = root.Bokeh;\n  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'tabulator': 'https://cdn.jsdelivr.net/npm/tabulator-tables@5.5.0/dist/js/tabulator', 'moment': 'https://cdn.jsdelivr.net/npm/luxon/build/global/luxon.min', 'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"tabulator\"], function(Tabulator) {\n\twindow.Tabulator = Tabulator\n\ton_load()\n      })\n      require([\"moment\"], function(moment) {\n\twindow.moment = moment\n\ton_load()\n      })\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 11;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['Tabulator'] !== undefined) && (!(window['Tabulator'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/js/tabulator.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['moment'] !== undefined) && (!(window['moment'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/luxon/build/global/luxon.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/js/tabulator.js\", \"https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/luxon/build/global/luxon.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [\"https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/css/tabulator_simple.min.css\"];\n  var inline_js = [    function(Bokeh) {\n      inject_raw_css(\".tabulator{position:relative;border:1px solid #999;font-size:14px;text-align:left;overflow:hidden;-webkit-transform:translateZ(0);-moz-transform:translateZ(0);-ms-transform:translateZ(0);-o-transform:translateZ(0);transform:translateZ(0)}.tabulator[tabulator-layout=fitDataFill] .tabulator-tableholder .tabulator-table{min-width:100%}.tabulator[tabulator-layout=fitDataTable]{display:inline-block}.tabulator.tabulator-block-select{user-select:none}.tabulator .tabulator-header{position:relative;box-sizing:border-box;width:100%;border-bottom:1px solid #999;background-color:#fff;color:#555;font-weight:700;white-space:nowrap;overflow:hidden;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none}.tabulator .tabulator-header.tabulator-header-hidden{display:none}.tabulator .tabulator-header .tabulator-header-contents{position:relative;overflow:hidden}.tabulator .tabulator-header .tabulator-header-contents .tabulator-headers{display:inline-block}.tabulator .tabulator-header .tabulator-col{display:inline-flex;position:relative;box-sizing:border-box;flex-direction:column;justify-content:flex-start;border-right:1px solid #ddd;background:#fff;text-align:left;vertical-align:bottom;overflow:hidden}.tabulator .tabulator-header .tabulator-col.tabulator-moving{position:absolute;border:1px solid #999;background:#e6e6e6;pointer-events:none}.tabulator .tabulator-header .tabulator-col .tabulator-col-content{box-sizing:border-box;position:relative;padding:4px}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-header-popup-button{padding:0 8px}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-header-popup-button:hover{cursor:pointer;opacity:.6}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title-holder{position:relative}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title{box-sizing:border-box;width:100%;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;vertical-align:bottom}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title.tabulator-col-title-wrap{white-space:normal;text-overflow:clip}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title .tabulator-title-editor{box-sizing:border-box;width:100%;border:1px solid #999;padding:1px;background:#fff}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title .tabulator-header-popup-button+.tabulator-title-editor{width:calc(100% - 22px)}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-sorter{display:flex;align-items:center;position:absolute;top:0;bottom:0;right:4px}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{width:0;height:0;border-left:6px solid transparent;border-right:6px solid transparent;border-bottom:6px solid #bbb}.tabulator .tabulator-header .tabulator-col.tabulator-col-group .tabulator-col-group-cols{position:relative;display:flex;border-top:1px solid #ddd;overflow:hidden;margin-right:-1px}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter{position:relative;box-sizing:border-box;margin-top:2px;width:100%;text-align:center}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter textarea{height:auto!important}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter svg{margin-top:3px}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter input::-ms-clear{width:0;height:0}.tabulator .tabulator-header .tabulator-col.tabulator-sortable .tabulator-col-title{padding-right:25px}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable.tabulator-col-sorter-element:hover{cursor:pointer;background-color:#e6e6e6}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=none] .tabulator-col-content .tabulator-col-sorter{color:#bbb}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=none] .tabulator-col-content .tabulator-col-sorter.tabulator-col-sorter-element .tabulator-arrow:hover{cursor:pointer;border-bottom:6px solid #555}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=none] .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{border-top:none;border-bottom:6px solid #bbb}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=ascending] .tabulator-col-content .tabulator-col-sorter{color:#666}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=ascending] .tabulator-col-content .tabulator-col-sorter.tabulator-col-sorter-element .tabulator-arrow:hover{cursor:pointer;border-bottom:6px solid #555}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=ascending] .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{border-top:none;border-bottom:6px solid #666}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=descending] .tabulator-col-content .tabulator-col-sorter{color:#666}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=descending] .tabulator-col-content .tabulator-col-sorter.tabulator-col-sorter-element .tabulator-arrow:hover{cursor:pointer;border-top:6px solid #555}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=descending] .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{border-bottom:none;border-top:6px solid #666;color:#666}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical .tabulator-col-content .tabulator-col-title{writing-mode:vertical-rl;text-orientation:mixed;display:flex;align-items:center;justify-content:center}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-col-vertical-flip .tabulator-col-title{transform:rotate(180deg)}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-sortable .tabulator-col-title{padding-right:0;padding-top:20px}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-sortable.tabulator-col-vertical-flip .tabulator-col-title{padding-right:0;padding-bottom:20px}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-sortable .tabulator-col-sorter{justify-content:center;left:0;right:0;top:4px;bottom:auto}.tabulator .tabulator-header .tabulator-frozen{position:sticky;left:0;z-index:10}.tabulator .tabulator-header .tabulator-frozen.tabulator-frozen-left{border-right:2px solid #ddd}.tabulator .tabulator-header .tabulator-frozen.tabulator-frozen-right{border-left:2px solid #ddd}.tabulator .tabulator-header .tabulator-calcs-holder{box-sizing:border-box;background:#fff!important;border-top:1px solid #ddd;border-bottom:1px solid #ddd}.tabulator .tabulator-header .tabulator-calcs-holder .tabulator-row{background:#fff!important}.tabulator .tabulator-header .tabulator-calcs-holder .tabulator-row .tabulator-col-resize-handle,.tabulator .tabulator-header .tabulator-frozen-rows-holder:empty{display:none}.tabulator .tabulator-tableholder{position:relative;width:100%;white-space:nowrap;overflow:auto;-webkit-overflow-scrolling:touch}.tabulator .tabulator-tableholder:focus{outline:none}.tabulator .tabulator-tableholder .tabulator-placeholder{box-sizing:border-box;display:flex;align-items:center;justify-content:center;width:100%}.tabulator .tabulator-tableholder .tabulator-placeholder[tabulator-render-mode=virtual]{min-height:100%;min-width:100%}.tabulator .tabulator-tableholder .tabulator-placeholder .tabulator-placeholder-contents{display:inline-block;text-align:center;padding:10px;color:#ccc;font-weight:700;font-size:20px;white-space:normal}.tabulator .tabulator-tableholder .tabulator-table{position:relative;display:inline-block;background-color:#fff;white-space:nowrap;overflow:visible;color:#333}.tabulator .tabulator-tableholder .tabulator-table .tabulator-row.tabulator-calcs{font-weight:700;background:#f2f2f2!important}.tabulator .tabulator-tableholder .tabulator-table .tabulator-row.tabulator-calcs.tabulator-calcs-top{border-bottom:2px solid #ddd}.tabulator .tabulator-tableholder .tabulator-table .tabulator-row.tabulator-calcs.tabulator-calcs-bottom{border-top:2px solid #ddd}.tabulator .tabulator-footer{border-top:1px solid #999;background-color:#fff;color:#555;font-weight:700;white-space:nowrap;user-select:none;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none}.tabulator .tabulator-footer .tabulator-footer-contents{display:flex;flex-direction:row;align-items:center;justify-content:space-between;padding:5px 10px}.tabulator .tabulator-footer .tabulator-footer-contents:empty{display:none}.tabulator .tabulator-footer .tabulator-calcs-holder{box-sizing:border-box;width:100%;text-align:left;background:#fff!important;border-bottom:1px solid #ddd;border-top:1px solid #ddd;overflow:hidden}.tabulator .tabulator-footer .tabulator-calcs-holder .tabulator-row{display:inline-block;background:#fff!important}.tabulator .tabulator-footer .tabulator-calcs-holder .tabulator-row .tabulator-col-resize-handle{display:none}.tabulator .tabulator-footer .tabulator-calcs-holder:only-child{margin-bottom:-5px;border-bottom:none}.tabulator .tabulator-footer>*+.tabulator-page-counter{margin-left:10px}.tabulator .tabulator-footer .tabulator-page-counter{font-weight:400}.tabulator .tabulator-footer .tabulator-paginator{flex:1;text-align:right;color:#555;font-family:inherit;font-weight:inherit;font-size:inherit}.tabulator .tabulator-footer .tabulator-page-size{display:inline-block;margin:0 5px;padding:2px 5px;border:1px solid #aaa;border-radius:3px}.tabulator .tabulator-footer .tabulator-pages{margin:0 7px}.tabulator .tabulator-footer .tabulator-page{display:inline-block;margin:0 2px;padding:2px 5px;border:1px solid #aaa;border-radius:3px;background:hsla(0,0%,100%,.2)}.tabulator .tabulator-footer .tabulator-page.active{color:#d00}.tabulator .tabulator-footer .tabulator-page:disabled{opacity:.5}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-footer .tabulator-page:not(.disabled):hover{cursor:pointer;background:rgba(0,0,0,.2);color:#fff}}.tabulator .tabulator-col-resize-handle{position:relative;display:inline-block;width:6px;margin-left:-3px;margin-right:-3px;z-index:10;vertical-align:middle}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-col-resize-handle:hover{cursor:ew-resize}}.tabulator .tabulator-col-resize-handle:last-of-type{width:3px;margin-right:0}.tabulator .tabulator-alert{position:absolute;display:flex;align-items:center;top:0;left:0;z-index:100;height:100%;width:100%;background:rgba(0,0,0,.4);text-align:center}.tabulator .tabulator-alert .tabulator-alert-msg{display:inline-block;margin:0 auto;padding:10px 20px;border-radius:10px;background:#fff;font-weight:700;font-size:16px}.tabulator .tabulator-alert .tabulator-alert-msg.tabulator-alert-state-msg{border:4px solid #333;color:#000}.tabulator .tabulator-alert .tabulator-alert-msg.tabulator-alert-state-error{border:4px solid #d00;color:#590000}.tabulator-row{position:relative;box-sizing:border-box;min-height:22px}.tabulator-row,.tabulator-row.tabulator-row-even{background-color:#fff}@media (hover:hover) and (pointer:fine){.tabulator-row.tabulator-selectable:hover{background-color:#bbb;cursor:pointer}}.tabulator-row.tabulator-selected{background-color:#9abcea}@media (hover:hover) and (pointer:fine){.tabulator-row.tabulator-selected:hover{background-color:#769bcc;cursor:pointer}}.tabulator-row.tabulator-row-moving{border:1px solid #000;background:#fff}.tabulator-row.tabulator-moving{position:absolute;border-top:1px solid #ddd;border-bottom:1px solid #ddd;pointer-events:none;z-index:15}.tabulator-row .tabulator-row-resize-handle{position:absolute;right:0;bottom:0;left:0;height:5px}.tabulator-row .tabulator-row-resize-handle.prev{top:0;bottom:auto}@media (hover:hover) and (pointer:fine){.tabulator-row .tabulator-row-resize-handle:hover{cursor:ns-resize}}.tabulator-row .tabulator-responsive-collapse{box-sizing:border-box;padding:5px;border-top:1px solid #ddd;border-bottom:1px solid #ddd}.tabulator-row .tabulator-responsive-collapse:empty{display:none}.tabulator-row .tabulator-responsive-collapse table{font-size:14px}.tabulator-row .tabulator-responsive-collapse table tr td{position:relative}.tabulator-row .tabulator-responsive-collapse table tr td:first-of-type{padding-right:10px}.tabulator-row .tabulator-cell{display:inline-block;position:relative;box-sizing:border-box;padding:4px;border-right:1px solid #ddd;vertical-align:middle;white-space:nowrap;overflow:hidden;text-overflow:ellipsis}.tabulator-row .tabulator-cell.tabulator-frozen{display:inline-block;position:sticky;left:0;background-color:inherit;z-index:10}.tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-left{border-right:2px solid #ddd}.tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-right{border-left:2px solid #ddd}.tabulator-row .tabulator-cell.tabulator-editing{border:1px solid #1d68cd;outline:none;padding:0}.tabulator-row .tabulator-cell.tabulator-editing input,.tabulator-row .tabulator-cell.tabulator-editing select{border:1px;background:transparent;outline:none}.tabulator-row .tabulator-cell.tabulator-validation-fail{border:1px solid #d00}.tabulator-row .tabulator-cell.tabulator-validation-fail input,.tabulator-row .tabulator-cell.tabulator-validation-fail select{border:1px;background:transparent;color:#d00}.tabulator-row .tabulator-cell.tabulator-row-handle{display:inline-flex;align-items:center;justify-content:center;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none}.tabulator-row .tabulator-cell.tabulator-row-handle .tabulator-row-handle-box{width:80%}.tabulator-row .tabulator-cell.tabulator-row-handle .tabulator-row-handle-box .tabulator-row-handle-bar{width:100%;height:3px;margin-top:2px;background:#666}.tabulator-row .tabulator-cell .tabulator-data-tree-branch{display:inline-block;vertical-align:middle;height:9px;width:7px;margin-top:-9px;margin-right:5px;border-bottom-left-radius:1px;border-left:2px solid #ddd;border-bottom:2px solid #ddd}.tabulator-row .tabulator-cell .tabulator-data-tree-control{display:inline-flex;justify-content:center;align-items:center;vertical-align:middle;height:11px;width:11px;margin-right:5px;border:1px solid #333;border-radius:2px;background:rgba(0,0,0,.1);overflow:hidden}@media (hover:hover) and (pointer:fine){.tabulator-row .tabulator-cell .tabulator-data-tree-control:hover{cursor:pointer;background:rgba(0,0,0,.2)}}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-collapse{display:inline-block;position:relative;height:7px;width:1px;background:transparent}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-collapse:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-expand{display:inline-block;position:relative;height:7px;width:1px;background:#333}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-expand:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle{display:inline-flex;align-items:center;justify-content:center;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none;height:15px;width:15px;border-radius:20px;background:#666;color:#fff;font-weight:700;font-size:1.1em}@media (hover:hover) and (pointer:fine){.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle:hover{opacity:.7;cursor:pointer}}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle.open .tabulator-responsive-collapse-toggle-close{display:initial}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle.open .tabulator-responsive-collapse-toggle-open{display:none}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle svg{stroke:#fff}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle .tabulator-responsive-collapse-toggle-close{display:none}.tabulator-row .tabulator-cell .tabulator-traffic-light{display:inline-block;height:14px;width:14px;border-radius:14px}.tabulator-row.tabulator-group{box-sizing:border-box;border-bottom:1px solid #999;border-right:1px solid #ddd;border-top:1px solid #999;padding:5px 5px 5px 10px;background:#ccc;font-weight:700;min-width:100%}@media (hover:hover) and (pointer:fine){.tabulator-row.tabulator-group:hover{cursor:pointer;background-color:rgba(0,0,0,.1)}}.tabulator-row.tabulator-group.tabulator-group-visible .tabulator-arrow{margin-right:10px;border-left:6px solid transparent;border-right:6px solid transparent;border-top:6px solid #666;border-bottom:0}.tabulator-row.tabulator-group.tabulator-group-level-1{padding-left:30px}.tabulator-row.tabulator-group.tabulator-group-level-2{padding-left:50px}.tabulator-row.tabulator-group.tabulator-group-level-3{padding-left:70px}.tabulator-row.tabulator-group.tabulator-group-level-4{padding-left:90px}.tabulator-row.tabulator-group.tabulator-group-level-5{padding-left:110px}.tabulator-row.tabulator-group .tabulator-group-toggle{display:inline-block}.tabulator-row.tabulator-group .tabulator-arrow{display:inline-block;width:0;height:0;margin-right:16px;border-top:6px solid transparent;border-bottom:6px solid transparent;border-right:0;border-left:6px solid #666;vertical-align:middle}.tabulator-row.tabulator-group span{margin-left:10px;color:#d00}.tabulator-popup-container{position:absolute;display:inline-block;box-sizing:border-box;background:#fff;border:1px solid #ddd;box-shadow:0 0 5px 0 rgba(0,0,0,.2);font-size:14px;overflow-y:auto;-webkit-overflow-scrolling:touch;z-index:10000}.tabulator-popup{padding:5px;border-radius:3px}.tabulator-tooltip{max-width:Min(500px,100%);padding:3px 5px;border-radius:2px;box-shadow:none;font-size:12px;pointer-events:none}.tabulator-menu .tabulator-menu-item{position:relative;box-sizing:border-box;padding:5px 10px;user-select:none}.tabulator-menu .tabulator-menu-item.tabulator-menu-item-disabled{opacity:.5}@media (hover:hover) and (pointer:fine){.tabulator-menu .tabulator-menu-item:not(.tabulator-menu-item-disabled):hover{cursor:pointer;background:#fff}}.tabulator-menu .tabulator-menu-item.tabulator-menu-item-submenu{padding-right:25px}.tabulator-menu .tabulator-menu-item.tabulator-menu-item-submenu:after{display:inline-block;position:absolute;top:calc(5px + .4em);right:10px;height:7px;width:7px;content:\\\"\\\";border-color:#ddd;border-style:solid;border-width:1px 1px 0 0;vertical-align:top;transform:rotate(45deg)}.tabulator-menu .tabulator-menu-separator{border-top:1px solid #ddd}.tabulator-edit-list{max-height:200px;font-size:14px;overflow-y:auto;-webkit-overflow-scrolling:touch}.tabulator-edit-list .tabulator-edit-list-item{padding:4px;color:#333;outline:none}.tabulator-edit-list .tabulator-edit-list-item.active{color:#fff;background:#1d68cd}.tabulator-edit-list .tabulator-edit-list-item.active.focused{outline:1px solid hsla(0,0%,100%,.5)}.tabulator-edit-list .tabulator-edit-list-item.focused{outline:1px solid #1d68cd}@media (hover:hover) and (pointer:fine){.tabulator-edit-list .tabulator-edit-list-item:hover{cursor:pointer;color:#fff;background:#1d68cd}}.tabulator-edit-list .tabulator-edit-list-placeholder{padding:4px;color:#333;text-align:center}.tabulator-edit-list .tabulator-edit-list-group{border-bottom:1px solid #ddd;padding:6px 4px 4px;color:#333;font-weight:700}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-2,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-2{padding-left:12px}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-3,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-3{padding-left:20px}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-4,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-4{padding-left:28px}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-5,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-5{padding-left:36px}.tabulator.tabulator-ltr{direction:ltr}.tabulator.tabulator-rtl{text-align:initial;direction:rtl}.tabulator.tabulator-rtl .tabulator-header .tabulator-col{text-align:initial;border-left:1px solid #ddd;border-right:initial}.tabulator.tabulator-rtl .tabulator-header .tabulator-col.tabulator-col-group .tabulator-col-group-cols{margin-right:0;margin-left:-1px}.tabulator.tabulator-rtl .tabulator-header .tabulator-col.tabulator-sortable .tabulator-col-title{padding-right:0;padding-left:25px}.tabulator.tabulator-rtl .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-sorter{left:8px;right:auto}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell{border-right:initial;border-left:1px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell .tabulator-data-tree-branch{margin-right:0;margin-left:5px;border-bottom-left-radius:0;border-bottom-right-radius:1px;border-left:initial;border-right:2px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell .tabulator-data-tree-control{margin-right:0;margin-left:5px}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-left{border-left:2px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-right{border-right:2px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-col-resize-handle:last-of-type{width:3px;margin-left:0;margin-right:-3px}.tabulator.tabulator-rtl .tabulator-footer .tabulator-calcs-holder{text-align:initial}.tabulator-print-fullscreen{position:absolute;top:0;bottom:0;left:0;right:0;z-index:10000}body.tabulator-print-fullscreen-hide>:not(.tabulator-print-fullscreen){display:none!important}.tabulator-print-table{border-collapse:collapse}.tabulator-print-table .tabulator-data-tree-branch{display:inline-block;vertical-align:middle;height:9px;width:7px;margin-top:-9px;margin-right:5px;border-bottom-left-radius:1px;border-left:2px solid #ddd;border-bottom:2px solid #ddd}.tabulator-print-table .tabulator-print-table-group{box-sizing:border-box;border-bottom:1px solid #999;border-right:1px solid #ddd;border-top:1px solid #999;padding:5px 5px 5px 10px;background:#ccc;font-weight:700;min-width:100%}@media (hover:hover) and (pointer:fine){.tabulator-print-table .tabulator-print-table-group:hover{cursor:pointer;background-color:rgba(0,0,0,.1)}}.tabulator-print-table .tabulator-print-table-group.tabulator-group-visible .tabulator-arrow{margin-right:10px;border-left:6px solid transparent;border-right:6px solid transparent;border-top:6px solid #666;border-bottom:0}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-1 td{padding-left:30px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-2 td{padding-left:50px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-3 td{padding-left:70px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-4 td{padding-left:90px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-5 td{padding-left:110px!important}.tabulator-print-table .tabulator-print-table-group .tabulator-group-toggle{display:inline-block}.tabulator-print-table .tabulator-print-table-group .tabulator-arrow{display:inline-block;width:0;height:0;margin-right:16px;border-top:6px solid transparent;border-bottom:6px solid transparent;border-right:0;border-left:6px solid #666;vertical-align:middle}.tabulator-print-table .tabulator-print-table-group span{color:#d00}.tabulator-print-table .tabulator-data-tree-control{display:inline-flex;justify-content:center;align-items:center;vertical-align:middle;height:11px;width:11px;margin-right:5px;border:1px solid #333;border-radius:2px;background:rgba(0,0,0,.1);overflow:hidden}@media (hover:hover) and (pointer:fine){.tabulator-print-table .tabulator-data-tree-control:hover{cursor:pointer;background:rgba(0,0,0,.2)}}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-collapse{display:inline-block;position:relative;height:7px;width:1px;background:transparent}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-collapse:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-expand{display:inline-block;position:relative;height:7px;width:1px;background:#333}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-expand:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator{border:none;background-color:#fff}.tabulator .tabulator-header .tabulator-calcs-holder{background:#f2f2f2!important;border-bottom:1px solid #999}.tabulator .tabulator-header .tabulator-calcs-holder .tabulator-row{background:#f2f2f2!important}.tabulator .tabulator-tableholder .tabulator-placeholder span{color:#000}.tabulator .tabulator-footer .tabulator-calcs-holder{background:#f2f2f2!important;border-bottom:1px solid #fff}.tabulator .tabulator-footer .tabulator-calcs-holder .tabulator-row{background:#f2f2f2!important}.tabulator-row{border-bottom:1px solid #ddd}.tabulator-row .tabulator-cell:last-of-type{border-right:none}.tabulator-row.tabulator-group span{color:#666}.tabulator-print-table .tabulator-print-table-group span{margin-left:10px;color:#666}\\n/*# sourceMappingURL=tabulator_simple.min.css.map */\");\n    },    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      Bokeh = root.Bokeh;\n      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      if (!reloading && (!bokeh_loaded || is_dev)) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.2.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n  var reloading = true;\n  var Bokeh = root.Bokeh;\n  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'tabulator': 'https://cdn.jsdelivr.net/npm/tabulator-tables@5.5.0/dist/js/tabulator', 'moment': 'https://cdn.jsdelivr.net/npm/luxon/build/global/luxon.min', 'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"tabulator\"], function(Tabulator) {\n\twindow.Tabulator = Tabulator\n\ton_load()\n      })\n      require([\"moment\"], function(moment) {\n\twindow.moment = moment\n\ton_load()\n      })\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 11;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['Tabulator'] !== undefined) && (!(window['Tabulator'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/js/tabulator.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['moment'] !== undefined) && (!(window['moment'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/luxon/build/global/luxon.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/js/tabulator.js\", \"https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/luxon/build/global/luxon.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [\"https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/css/tabulator_simple.min.css\"];\n  var inline_js = [    function(Bokeh) {\n      inject_raw_css(\".tabulator{position:relative;border:1px solid #999;font-size:14px;text-align:left;overflow:hidden;-webkit-transform:translateZ(0);-moz-transform:translateZ(0);-ms-transform:translateZ(0);-o-transform:translateZ(0);transform:translateZ(0)}.tabulator[tabulator-layout=fitDataFill] .tabulator-tableholder .tabulator-table{min-width:100%}.tabulator[tabulator-layout=fitDataTable]{display:inline-block}.tabulator.tabulator-block-select{user-select:none}.tabulator .tabulator-header{position:relative;box-sizing:border-box;width:100%;border-bottom:1px solid #999;background-color:#fff;color:#555;font-weight:700;white-space:nowrap;overflow:hidden;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none}.tabulator .tabulator-header.tabulator-header-hidden{display:none}.tabulator .tabulator-header .tabulator-header-contents{position:relative;overflow:hidden}.tabulator .tabulator-header .tabulator-header-contents .tabulator-headers{display:inline-block}.tabulator .tabulator-header .tabulator-col{display:inline-flex;position:relative;box-sizing:border-box;flex-direction:column;justify-content:flex-start;border-right:1px solid #ddd;background:#fff;text-align:left;vertical-align:bottom;overflow:hidden}.tabulator .tabulator-header .tabulator-col.tabulator-moving{position:absolute;border:1px solid #999;background:#e6e6e6;pointer-events:none}.tabulator .tabulator-header .tabulator-col .tabulator-col-content{box-sizing:border-box;position:relative;padding:4px}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-header-popup-button{padding:0 8px}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-header-popup-button:hover{cursor:pointer;opacity:.6}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title-holder{position:relative}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title{box-sizing:border-box;width:100%;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;vertical-align:bottom}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title.tabulator-col-title-wrap{white-space:normal;text-overflow:clip}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title .tabulator-title-editor{box-sizing:border-box;width:100%;border:1px solid #999;padding:1px;background:#fff}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title .tabulator-header-popup-button+.tabulator-title-editor{width:calc(100% - 22px)}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-sorter{display:flex;align-items:center;position:absolute;top:0;bottom:0;right:4px}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{width:0;height:0;border-left:6px solid transparent;border-right:6px solid transparent;border-bottom:6px solid #bbb}.tabulator .tabulator-header .tabulator-col.tabulator-col-group .tabulator-col-group-cols{position:relative;display:flex;border-top:1px solid #ddd;overflow:hidden;margin-right:-1px}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter{position:relative;box-sizing:border-box;margin-top:2px;width:100%;text-align:center}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter textarea{height:auto!important}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter svg{margin-top:3px}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter input::-ms-clear{width:0;height:0}.tabulator .tabulator-header .tabulator-col.tabulator-sortable .tabulator-col-title{padding-right:25px}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable.tabulator-col-sorter-element:hover{cursor:pointer;background-color:#e6e6e6}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=none] .tabulator-col-content .tabulator-col-sorter{color:#bbb}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=none] .tabulator-col-content .tabulator-col-sorter.tabulator-col-sorter-element .tabulator-arrow:hover{cursor:pointer;border-bottom:6px solid #555}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=none] .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{border-top:none;border-bottom:6px solid #bbb}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=ascending] .tabulator-col-content .tabulator-col-sorter{color:#666}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=ascending] .tabulator-col-content .tabulator-col-sorter.tabulator-col-sorter-element .tabulator-arrow:hover{cursor:pointer;border-bottom:6px solid #555}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=ascending] .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{border-top:none;border-bottom:6px solid #666}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=descending] .tabulator-col-content .tabulator-col-sorter{color:#666}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=descending] .tabulator-col-content .tabulator-col-sorter.tabulator-col-sorter-element .tabulator-arrow:hover{cursor:pointer;border-top:6px solid #555}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=descending] .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{border-bottom:none;border-top:6px solid #666;color:#666}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical .tabulator-col-content .tabulator-col-title{writing-mode:vertical-rl;text-orientation:mixed;display:flex;align-items:center;justify-content:center}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-col-vertical-flip .tabulator-col-title{transform:rotate(180deg)}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-sortable .tabulator-col-title{padding-right:0;padding-top:20px}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-sortable.tabulator-col-vertical-flip .tabulator-col-title{padding-right:0;padding-bottom:20px}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-sortable .tabulator-col-sorter{justify-content:center;left:0;right:0;top:4px;bottom:auto}.tabulator .tabulator-header .tabulator-frozen{position:sticky;left:0;z-index:10}.tabulator .tabulator-header .tabulator-frozen.tabulator-frozen-left{border-right:2px solid #ddd}.tabulator .tabulator-header .tabulator-frozen.tabulator-frozen-right{border-left:2px solid #ddd}.tabulator .tabulator-header .tabulator-calcs-holder{box-sizing:border-box;background:#fff!important;border-top:1px solid #ddd;border-bottom:1px solid #ddd}.tabulator .tabulator-header .tabulator-calcs-holder .tabulator-row{background:#fff!important}.tabulator .tabulator-header .tabulator-calcs-holder .tabulator-row .tabulator-col-resize-handle,.tabulator .tabulator-header .tabulator-frozen-rows-holder:empty{display:none}.tabulator .tabulator-tableholder{position:relative;width:100%;white-space:nowrap;overflow:auto;-webkit-overflow-scrolling:touch}.tabulator .tabulator-tableholder:focus{outline:none}.tabulator .tabulator-tableholder .tabulator-placeholder{box-sizing:border-box;display:flex;align-items:center;justify-content:center;width:100%}.tabulator .tabulator-tableholder .tabulator-placeholder[tabulator-render-mode=virtual]{min-height:100%;min-width:100%}.tabulator .tabulator-tableholder .tabulator-placeholder .tabulator-placeholder-contents{display:inline-block;text-align:center;padding:10px;color:#ccc;font-weight:700;font-size:20px;white-space:normal}.tabulator .tabulator-tableholder .tabulator-table{position:relative;display:inline-block;background-color:#fff;white-space:nowrap;overflow:visible;color:#333}.tabulator .tabulator-tableholder .tabulator-table .tabulator-row.tabulator-calcs{font-weight:700;background:#f2f2f2!important}.tabulator .tabulator-tableholder .tabulator-table .tabulator-row.tabulator-calcs.tabulator-calcs-top{border-bottom:2px solid #ddd}.tabulator .tabulator-tableholder .tabulator-table .tabulator-row.tabulator-calcs.tabulator-calcs-bottom{border-top:2px solid #ddd}.tabulator .tabulator-footer{border-top:1px solid #999;background-color:#fff;color:#555;font-weight:700;white-space:nowrap;user-select:none;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none}.tabulator .tabulator-footer .tabulator-footer-contents{display:flex;flex-direction:row;align-items:center;justify-content:space-between;padding:5px 10px}.tabulator .tabulator-footer .tabulator-footer-contents:empty{display:none}.tabulator .tabulator-footer .tabulator-calcs-holder{box-sizing:border-box;width:100%;text-align:left;background:#fff!important;border-bottom:1px solid #ddd;border-top:1px solid #ddd;overflow:hidden}.tabulator .tabulator-footer .tabulator-calcs-holder .tabulator-row{display:inline-block;background:#fff!important}.tabulator .tabulator-footer .tabulator-calcs-holder .tabulator-row .tabulator-col-resize-handle{display:none}.tabulator .tabulator-footer .tabulator-calcs-holder:only-child{margin-bottom:-5px;border-bottom:none}.tabulator .tabulator-footer>*+.tabulator-page-counter{margin-left:10px}.tabulator .tabulator-footer .tabulator-page-counter{font-weight:400}.tabulator .tabulator-footer .tabulator-paginator{flex:1;text-align:right;color:#555;font-family:inherit;font-weight:inherit;font-size:inherit}.tabulator .tabulator-footer .tabulator-page-size{display:inline-block;margin:0 5px;padding:2px 5px;border:1px solid #aaa;border-radius:3px}.tabulator .tabulator-footer .tabulator-pages{margin:0 7px}.tabulator .tabulator-footer .tabulator-page{display:inline-block;margin:0 2px;padding:2px 5px;border:1px solid #aaa;border-radius:3px;background:hsla(0,0%,100%,.2)}.tabulator .tabulator-footer .tabulator-page.active{color:#d00}.tabulator .tabulator-footer .tabulator-page:disabled{opacity:.5}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-footer .tabulator-page:not(.disabled):hover{cursor:pointer;background:rgba(0,0,0,.2);color:#fff}}.tabulator .tabulator-col-resize-handle{position:relative;display:inline-block;width:6px;margin-left:-3px;margin-right:-3px;z-index:10;vertical-align:middle}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-col-resize-handle:hover{cursor:ew-resize}}.tabulator .tabulator-col-resize-handle:last-of-type{width:3px;margin-right:0}.tabulator .tabulator-alert{position:absolute;display:flex;align-items:center;top:0;left:0;z-index:100;height:100%;width:100%;background:rgba(0,0,0,.4);text-align:center}.tabulator .tabulator-alert .tabulator-alert-msg{display:inline-block;margin:0 auto;padding:10px 20px;border-radius:10px;background:#fff;font-weight:700;font-size:16px}.tabulator .tabulator-alert .tabulator-alert-msg.tabulator-alert-state-msg{border:4px solid #333;color:#000}.tabulator .tabulator-alert .tabulator-alert-msg.tabulator-alert-state-error{border:4px solid #d00;color:#590000}.tabulator-row{position:relative;box-sizing:border-box;min-height:22px}.tabulator-row,.tabulator-row.tabulator-row-even{background-color:#fff}@media (hover:hover) and (pointer:fine){.tabulator-row.tabulator-selectable:hover{background-color:#bbb;cursor:pointer}}.tabulator-row.tabulator-selected{background-color:#9abcea}@media (hover:hover) and (pointer:fine){.tabulator-row.tabulator-selected:hover{background-color:#769bcc;cursor:pointer}}.tabulator-row.tabulator-row-moving{border:1px solid #000;background:#fff}.tabulator-row.tabulator-moving{position:absolute;border-top:1px solid #ddd;border-bottom:1px solid #ddd;pointer-events:none;z-index:15}.tabulator-row .tabulator-row-resize-handle{position:absolute;right:0;bottom:0;left:0;height:5px}.tabulator-row .tabulator-row-resize-handle.prev{top:0;bottom:auto}@media (hover:hover) and (pointer:fine){.tabulator-row .tabulator-row-resize-handle:hover{cursor:ns-resize}}.tabulator-row .tabulator-responsive-collapse{box-sizing:border-box;padding:5px;border-top:1px solid #ddd;border-bottom:1px solid #ddd}.tabulator-row .tabulator-responsive-collapse:empty{display:none}.tabulator-row .tabulator-responsive-collapse table{font-size:14px}.tabulator-row .tabulator-responsive-collapse table tr td{position:relative}.tabulator-row .tabulator-responsive-collapse table tr td:first-of-type{padding-right:10px}.tabulator-row .tabulator-cell{display:inline-block;position:relative;box-sizing:border-box;padding:4px;border-right:1px solid #ddd;vertical-align:middle;white-space:nowrap;overflow:hidden;text-overflow:ellipsis}.tabulator-row .tabulator-cell.tabulator-frozen{display:inline-block;position:sticky;left:0;background-color:inherit;z-index:10}.tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-left{border-right:2px solid #ddd}.tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-right{border-left:2px solid #ddd}.tabulator-row .tabulator-cell.tabulator-editing{border:1px solid #1d68cd;outline:none;padding:0}.tabulator-row .tabulator-cell.tabulator-editing input,.tabulator-row .tabulator-cell.tabulator-editing select{border:1px;background:transparent;outline:none}.tabulator-row .tabulator-cell.tabulator-validation-fail{border:1px solid #d00}.tabulator-row .tabulator-cell.tabulator-validation-fail input,.tabulator-row .tabulator-cell.tabulator-validation-fail select{border:1px;background:transparent;color:#d00}.tabulator-row .tabulator-cell.tabulator-row-handle{display:inline-flex;align-items:center;justify-content:center;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none}.tabulator-row .tabulator-cell.tabulator-row-handle .tabulator-row-handle-box{width:80%}.tabulator-row .tabulator-cell.tabulator-row-handle .tabulator-row-handle-box .tabulator-row-handle-bar{width:100%;height:3px;margin-top:2px;background:#666}.tabulator-row .tabulator-cell .tabulator-data-tree-branch{display:inline-block;vertical-align:middle;height:9px;width:7px;margin-top:-9px;margin-right:5px;border-bottom-left-radius:1px;border-left:2px solid #ddd;border-bottom:2px solid #ddd}.tabulator-row .tabulator-cell .tabulator-data-tree-control{display:inline-flex;justify-content:center;align-items:center;vertical-align:middle;height:11px;width:11px;margin-right:5px;border:1px solid #333;border-radius:2px;background:rgba(0,0,0,.1);overflow:hidden}@media (hover:hover) and (pointer:fine){.tabulator-row .tabulator-cell .tabulator-data-tree-control:hover{cursor:pointer;background:rgba(0,0,0,.2)}}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-collapse{display:inline-block;position:relative;height:7px;width:1px;background:transparent}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-collapse:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-expand{display:inline-block;position:relative;height:7px;width:1px;background:#333}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-expand:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle{display:inline-flex;align-items:center;justify-content:center;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none;height:15px;width:15px;border-radius:20px;background:#666;color:#fff;font-weight:700;font-size:1.1em}@media (hover:hover) and (pointer:fine){.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle:hover{opacity:.7;cursor:pointer}}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle.open .tabulator-responsive-collapse-toggle-close{display:initial}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle.open .tabulator-responsive-collapse-toggle-open{display:none}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle svg{stroke:#fff}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle .tabulator-responsive-collapse-toggle-close{display:none}.tabulator-row .tabulator-cell .tabulator-traffic-light{display:inline-block;height:14px;width:14px;border-radius:14px}.tabulator-row.tabulator-group{box-sizing:border-box;border-bottom:1px solid #999;border-right:1px solid #ddd;border-top:1px solid #999;padding:5px 5px 5px 10px;background:#ccc;font-weight:700;min-width:100%}@media (hover:hover) and (pointer:fine){.tabulator-row.tabulator-group:hover{cursor:pointer;background-color:rgba(0,0,0,.1)}}.tabulator-row.tabulator-group.tabulator-group-visible .tabulator-arrow{margin-right:10px;border-left:6px solid transparent;border-right:6px solid transparent;border-top:6px solid #666;border-bottom:0}.tabulator-row.tabulator-group.tabulator-group-level-1{padding-left:30px}.tabulator-row.tabulator-group.tabulator-group-level-2{padding-left:50px}.tabulator-row.tabulator-group.tabulator-group-level-3{padding-left:70px}.tabulator-row.tabulator-group.tabulator-group-level-4{padding-left:90px}.tabulator-row.tabulator-group.tabulator-group-level-5{padding-left:110px}.tabulator-row.tabulator-group .tabulator-group-toggle{display:inline-block}.tabulator-row.tabulator-group .tabulator-arrow{display:inline-block;width:0;height:0;margin-right:16px;border-top:6px solid transparent;border-bottom:6px solid transparent;border-right:0;border-left:6px solid #666;vertical-align:middle}.tabulator-row.tabulator-group span{margin-left:10px;color:#d00}.tabulator-popup-container{position:absolute;display:inline-block;box-sizing:border-box;background:#fff;border:1px solid #ddd;box-shadow:0 0 5px 0 rgba(0,0,0,.2);font-size:14px;overflow-y:auto;-webkit-overflow-scrolling:touch;z-index:10000}.tabulator-popup{padding:5px;border-radius:3px}.tabulator-tooltip{max-width:Min(500px,100%);padding:3px 5px;border-radius:2px;box-shadow:none;font-size:12px;pointer-events:none}.tabulator-menu .tabulator-menu-item{position:relative;box-sizing:border-box;padding:5px 10px;user-select:none}.tabulator-menu .tabulator-menu-item.tabulator-menu-item-disabled{opacity:.5}@media (hover:hover) and (pointer:fine){.tabulator-menu .tabulator-menu-item:not(.tabulator-menu-item-disabled):hover{cursor:pointer;background:#fff}}.tabulator-menu .tabulator-menu-item.tabulator-menu-item-submenu{padding-right:25px}.tabulator-menu .tabulator-menu-item.tabulator-menu-item-submenu:after{display:inline-block;position:absolute;top:calc(5px + .4em);right:10px;height:7px;width:7px;content:\\\"\\\";border-color:#ddd;border-style:solid;border-width:1px 1px 0 0;vertical-align:top;transform:rotate(45deg)}.tabulator-menu .tabulator-menu-separator{border-top:1px solid #ddd}.tabulator-edit-list{max-height:200px;font-size:14px;overflow-y:auto;-webkit-overflow-scrolling:touch}.tabulator-edit-list .tabulator-edit-list-item{padding:4px;color:#333;outline:none}.tabulator-edit-list .tabulator-edit-list-item.active{color:#fff;background:#1d68cd}.tabulator-edit-list .tabulator-edit-list-item.active.focused{outline:1px solid hsla(0,0%,100%,.5)}.tabulator-edit-list .tabulator-edit-list-item.focused{outline:1px solid #1d68cd}@media (hover:hover) and (pointer:fine){.tabulator-edit-list .tabulator-edit-list-item:hover{cursor:pointer;color:#fff;background:#1d68cd}}.tabulator-edit-list .tabulator-edit-list-placeholder{padding:4px;color:#333;text-align:center}.tabulator-edit-list .tabulator-edit-list-group{border-bottom:1px solid #ddd;padding:6px 4px 4px;color:#333;font-weight:700}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-2,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-2{padding-left:12px}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-3,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-3{padding-left:20px}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-4,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-4{padding-left:28px}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-5,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-5{padding-left:36px}.tabulator.tabulator-ltr{direction:ltr}.tabulator.tabulator-rtl{text-align:initial;direction:rtl}.tabulator.tabulator-rtl .tabulator-header .tabulator-col{text-align:initial;border-left:1px solid #ddd;border-right:initial}.tabulator.tabulator-rtl .tabulator-header .tabulator-col.tabulator-col-group .tabulator-col-group-cols{margin-right:0;margin-left:-1px}.tabulator.tabulator-rtl .tabulator-header .tabulator-col.tabulator-sortable .tabulator-col-title{padding-right:0;padding-left:25px}.tabulator.tabulator-rtl .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-sorter{left:8px;right:auto}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell{border-right:initial;border-left:1px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell .tabulator-data-tree-branch{margin-right:0;margin-left:5px;border-bottom-left-radius:0;border-bottom-right-radius:1px;border-left:initial;border-right:2px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell .tabulator-data-tree-control{margin-right:0;margin-left:5px}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-left{border-left:2px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-right{border-right:2px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-col-resize-handle:last-of-type{width:3px;margin-left:0;margin-right:-3px}.tabulator.tabulator-rtl .tabulator-footer .tabulator-calcs-holder{text-align:initial}.tabulator-print-fullscreen{position:absolute;top:0;bottom:0;left:0;right:0;z-index:10000}body.tabulator-print-fullscreen-hide>:not(.tabulator-print-fullscreen){display:none!important}.tabulator-print-table{border-collapse:collapse}.tabulator-print-table .tabulator-data-tree-branch{display:inline-block;vertical-align:middle;height:9px;width:7px;margin-top:-9px;margin-right:5px;border-bottom-left-radius:1px;border-left:2px solid #ddd;border-bottom:2px solid #ddd}.tabulator-print-table .tabulator-print-table-group{box-sizing:border-box;border-bottom:1px solid #999;border-right:1px solid #ddd;border-top:1px solid #999;padding:5px 5px 5px 10px;background:#ccc;font-weight:700;min-width:100%}@media (hover:hover) and (pointer:fine){.tabulator-print-table .tabulator-print-table-group:hover{cursor:pointer;background-color:rgba(0,0,0,.1)}}.tabulator-print-table .tabulator-print-table-group.tabulator-group-visible .tabulator-arrow{margin-right:10px;border-left:6px solid transparent;border-right:6px solid transparent;border-top:6px solid #666;border-bottom:0}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-1 td{padding-left:30px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-2 td{padding-left:50px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-3 td{padding-left:70px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-4 td{padding-left:90px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-5 td{padding-left:110px!important}.tabulator-print-table .tabulator-print-table-group .tabulator-group-toggle{display:inline-block}.tabulator-print-table .tabulator-print-table-group .tabulator-arrow{display:inline-block;width:0;height:0;margin-right:16px;border-top:6px solid transparent;border-bottom:6px solid transparent;border-right:0;border-left:6px solid #666;vertical-align:middle}.tabulator-print-table .tabulator-print-table-group span{color:#d00}.tabulator-print-table .tabulator-data-tree-control{display:inline-flex;justify-content:center;align-items:center;vertical-align:middle;height:11px;width:11px;margin-right:5px;border:1px solid #333;border-radius:2px;background:rgba(0,0,0,.1);overflow:hidden}@media (hover:hover) and (pointer:fine){.tabulator-print-table .tabulator-data-tree-control:hover{cursor:pointer;background:rgba(0,0,0,.2)}}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-collapse{display:inline-block;position:relative;height:7px;width:1px;background:transparent}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-collapse:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-expand{display:inline-block;position:relative;height:7px;width:1px;background:#333}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-expand:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator{border:none;background-color:#fff}.tabulator .tabulator-header .tabulator-calcs-holder{background:#f2f2f2!important;border-bottom:1px solid #999}.tabulator .tabulator-header .tabulator-calcs-holder .tabulator-row{background:#f2f2f2!important}.tabulator .tabulator-tableholder .tabulator-placeholder span{color:#000}.tabulator .tabulator-footer .tabulator-calcs-holder{background:#f2f2f2!important;border-bottom:1px solid #fff}.tabulator .tabulator-footer .tabulator-calcs-holder .tabulator-row{background:#f2f2f2!important}.tabulator-row{border-bottom:1px solid #ddd}.tabulator-row .tabulator-cell:last-of-type{border-right:none}.tabulator-row.tabulator-group span{color:#666}.tabulator-print-table .tabulator-print-table-group span{margin-left:10px;color:#666}\\n/*# sourceMappingURL=tabulator_simple.min.css.map */\");\n    },    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      Bokeh = root.Bokeh;\n      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      if (!reloading && (!bokeh_loaded || is_dev)) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.2.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var is_dev = py_version.indexOf(\"+\") !== -1 || py_version.indexOf(\"-\") !== -1;\n  var reloading = true;\n  var Bokeh = root.Bokeh;\n  var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'tabulator': 'https://cdn.jsdelivr.net/npm/tabulator-tables@5.5.0/dist/js/tabulator', 'moment': 'https://cdn.jsdelivr.net/npm/luxon/build/global/luxon.min', 'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"tabulator\"], function(Tabulator) {\n\twindow.Tabulator = Tabulator\n\ton_load()\n      })\n      require([\"moment\"], function(moment) {\n\twindow.moment = moment\n\ton_load()\n      })\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 11;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['Tabulator'] !== undefined) && (!(window['Tabulator'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/js/tabulator.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['moment'] !== undefined) && (!(window['moment'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/luxon/build/global/luxon.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.2.3/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.2.3/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/js/tabulator.js\", \"https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/luxon/build/global/luxon.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [\"https://cdn.holoviz.org/panel/1.2.3/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/css/tabulator_simple.min.css\"];\n  var inline_js = [    function(Bokeh) {\n      inject_raw_css(\".tabulator{position:relative;border:1px solid #999;font-size:14px;text-align:left;overflow:hidden;-webkit-transform:translateZ(0);-moz-transform:translateZ(0);-ms-transform:translateZ(0);-o-transform:translateZ(0);transform:translateZ(0)}.tabulator[tabulator-layout=fitDataFill] .tabulator-tableholder .tabulator-table{min-width:100%}.tabulator[tabulator-layout=fitDataTable]{display:inline-block}.tabulator.tabulator-block-select{user-select:none}.tabulator .tabulator-header{position:relative;box-sizing:border-box;width:100%;border-bottom:1px solid #999;background-color:#fff;color:#555;font-weight:700;white-space:nowrap;overflow:hidden;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none}.tabulator .tabulator-header.tabulator-header-hidden{display:none}.tabulator .tabulator-header .tabulator-header-contents{position:relative;overflow:hidden}.tabulator .tabulator-header .tabulator-header-contents .tabulator-headers{display:inline-block}.tabulator .tabulator-header .tabulator-col{display:inline-flex;position:relative;box-sizing:border-box;flex-direction:column;justify-content:flex-start;border-right:1px solid #ddd;background:#fff;text-align:left;vertical-align:bottom;overflow:hidden}.tabulator .tabulator-header .tabulator-col.tabulator-moving{position:absolute;border:1px solid #999;background:#e6e6e6;pointer-events:none}.tabulator .tabulator-header .tabulator-col .tabulator-col-content{box-sizing:border-box;position:relative;padding:4px}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-header-popup-button{padding:0 8px}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-header-popup-button:hover{cursor:pointer;opacity:.6}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title-holder{position:relative}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title{box-sizing:border-box;width:100%;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;vertical-align:bottom}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title.tabulator-col-title-wrap{white-space:normal;text-overflow:clip}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title .tabulator-title-editor{box-sizing:border-box;width:100%;border:1px solid #999;padding:1px;background:#fff}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-title .tabulator-header-popup-button+.tabulator-title-editor{width:calc(100% - 22px)}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-sorter{display:flex;align-items:center;position:absolute;top:0;bottom:0;right:4px}.tabulator .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{width:0;height:0;border-left:6px solid transparent;border-right:6px solid transparent;border-bottom:6px solid #bbb}.tabulator .tabulator-header .tabulator-col.tabulator-col-group .tabulator-col-group-cols{position:relative;display:flex;border-top:1px solid #ddd;overflow:hidden;margin-right:-1px}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter{position:relative;box-sizing:border-box;margin-top:2px;width:100%;text-align:center}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter textarea{height:auto!important}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter svg{margin-top:3px}.tabulator .tabulator-header .tabulator-col .tabulator-header-filter input::-ms-clear{width:0;height:0}.tabulator .tabulator-header .tabulator-col.tabulator-sortable .tabulator-col-title{padding-right:25px}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable.tabulator-col-sorter-element:hover{cursor:pointer;background-color:#e6e6e6}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=none] .tabulator-col-content .tabulator-col-sorter{color:#bbb}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=none] .tabulator-col-content .tabulator-col-sorter.tabulator-col-sorter-element .tabulator-arrow:hover{cursor:pointer;border-bottom:6px solid #555}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=none] .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{border-top:none;border-bottom:6px solid #bbb}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=ascending] .tabulator-col-content .tabulator-col-sorter{color:#666}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=ascending] .tabulator-col-content .tabulator-col-sorter.tabulator-col-sorter-element .tabulator-arrow:hover{cursor:pointer;border-bottom:6px solid #555}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=ascending] .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{border-top:none;border-bottom:6px solid #666}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=descending] .tabulator-col-content .tabulator-col-sorter{color:#666}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=descending] .tabulator-col-content .tabulator-col-sorter.tabulator-col-sorter-element .tabulator-arrow:hover{cursor:pointer;border-top:6px solid #555}}.tabulator .tabulator-header .tabulator-col.tabulator-sortable[aria-sort=descending] .tabulator-col-content .tabulator-col-sorter .tabulator-arrow{border-bottom:none;border-top:6px solid #666;color:#666}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical .tabulator-col-content .tabulator-col-title{writing-mode:vertical-rl;text-orientation:mixed;display:flex;align-items:center;justify-content:center}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-col-vertical-flip .tabulator-col-title{transform:rotate(180deg)}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-sortable .tabulator-col-title{padding-right:0;padding-top:20px}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-sortable.tabulator-col-vertical-flip .tabulator-col-title{padding-right:0;padding-bottom:20px}.tabulator .tabulator-header .tabulator-col.tabulator-col-vertical.tabulator-sortable .tabulator-col-sorter{justify-content:center;left:0;right:0;top:4px;bottom:auto}.tabulator .tabulator-header .tabulator-frozen{position:sticky;left:0;z-index:10}.tabulator .tabulator-header .tabulator-frozen.tabulator-frozen-left{border-right:2px solid #ddd}.tabulator .tabulator-header .tabulator-frozen.tabulator-frozen-right{border-left:2px solid #ddd}.tabulator .tabulator-header .tabulator-calcs-holder{box-sizing:border-box;background:#fff!important;border-top:1px solid #ddd;border-bottom:1px solid #ddd}.tabulator .tabulator-header .tabulator-calcs-holder .tabulator-row{background:#fff!important}.tabulator .tabulator-header .tabulator-calcs-holder .tabulator-row .tabulator-col-resize-handle,.tabulator .tabulator-header .tabulator-frozen-rows-holder:empty{display:none}.tabulator .tabulator-tableholder{position:relative;width:100%;white-space:nowrap;overflow:auto;-webkit-overflow-scrolling:touch}.tabulator .tabulator-tableholder:focus{outline:none}.tabulator .tabulator-tableholder .tabulator-placeholder{box-sizing:border-box;display:flex;align-items:center;justify-content:center;width:100%}.tabulator .tabulator-tableholder .tabulator-placeholder[tabulator-render-mode=virtual]{min-height:100%;min-width:100%}.tabulator .tabulator-tableholder .tabulator-placeholder .tabulator-placeholder-contents{display:inline-block;text-align:center;padding:10px;color:#ccc;font-weight:700;font-size:20px;white-space:normal}.tabulator .tabulator-tableholder .tabulator-table{position:relative;display:inline-block;background-color:#fff;white-space:nowrap;overflow:visible;color:#333}.tabulator .tabulator-tableholder .tabulator-table .tabulator-row.tabulator-calcs{font-weight:700;background:#f2f2f2!important}.tabulator .tabulator-tableholder .tabulator-table .tabulator-row.tabulator-calcs.tabulator-calcs-top{border-bottom:2px solid #ddd}.tabulator .tabulator-tableholder .tabulator-table .tabulator-row.tabulator-calcs.tabulator-calcs-bottom{border-top:2px solid #ddd}.tabulator .tabulator-footer{border-top:1px solid #999;background-color:#fff;color:#555;font-weight:700;white-space:nowrap;user-select:none;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none}.tabulator .tabulator-footer .tabulator-footer-contents{display:flex;flex-direction:row;align-items:center;justify-content:space-between;padding:5px 10px}.tabulator .tabulator-footer .tabulator-footer-contents:empty{display:none}.tabulator .tabulator-footer .tabulator-calcs-holder{box-sizing:border-box;width:100%;text-align:left;background:#fff!important;border-bottom:1px solid #ddd;border-top:1px solid #ddd;overflow:hidden}.tabulator .tabulator-footer .tabulator-calcs-holder .tabulator-row{display:inline-block;background:#fff!important}.tabulator .tabulator-footer .tabulator-calcs-holder .tabulator-row .tabulator-col-resize-handle{display:none}.tabulator .tabulator-footer .tabulator-calcs-holder:only-child{margin-bottom:-5px;border-bottom:none}.tabulator .tabulator-footer>*+.tabulator-page-counter{margin-left:10px}.tabulator .tabulator-footer .tabulator-page-counter{font-weight:400}.tabulator .tabulator-footer .tabulator-paginator{flex:1;text-align:right;color:#555;font-family:inherit;font-weight:inherit;font-size:inherit}.tabulator .tabulator-footer .tabulator-page-size{display:inline-block;margin:0 5px;padding:2px 5px;border:1px solid #aaa;border-radius:3px}.tabulator .tabulator-footer .tabulator-pages{margin:0 7px}.tabulator .tabulator-footer .tabulator-page{display:inline-block;margin:0 2px;padding:2px 5px;border:1px solid #aaa;border-radius:3px;background:hsla(0,0%,100%,.2)}.tabulator .tabulator-footer .tabulator-page.active{color:#d00}.tabulator .tabulator-footer .tabulator-page:disabled{opacity:.5}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-footer .tabulator-page:not(.disabled):hover{cursor:pointer;background:rgba(0,0,0,.2);color:#fff}}.tabulator .tabulator-col-resize-handle{position:relative;display:inline-block;width:6px;margin-left:-3px;margin-right:-3px;z-index:10;vertical-align:middle}@media (hover:hover) and (pointer:fine){.tabulator .tabulator-col-resize-handle:hover{cursor:ew-resize}}.tabulator .tabulator-col-resize-handle:last-of-type{width:3px;margin-right:0}.tabulator .tabulator-alert{position:absolute;display:flex;align-items:center;top:0;left:0;z-index:100;height:100%;width:100%;background:rgba(0,0,0,.4);text-align:center}.tabulator .tabulator-alert .tabulator-alert-msg{display:inline-block;margin:0 auto;padding:10px 20px;border-radius:10px;background:#fff;font-weight:700;font-size:16px}.tabulator .tabulator-alert .tabulator-alert-msg.tabulator-alert-state-msg{border:4px solid #333;color:#000}.tabulator .tabulator-alert .tabulator-alert-msg.tabulator-alert-state-error{border:4px solid #d00;color:#590000}.tabulator-row{position:relative;box-sizing:border-box;min-height:22px}.tabulator-row,.tabulator-row.tabulator-row-even{background-color:#fff}@media (hover:hover) and (pointer:fine){.tabulator-row.tabulator-selectable:hover{background-color:#bbb;cursor:pointer}}.tabulator-row.tabulator-selected{background-color:#9abcea}@media (hover:hover) and (pointer:fine){.tabulator-row.tabulator-selected:hover{background-color:#769bcc;cursor:pointer}}.tabulator-row.tabulator-row-moving{border:1px solid #000;background:#fff}.tabulator-row.tabulator-moving{position:absolute;border-top:1px solid #ddd;border-bottom:1px solid #ddd;pointer-events:none;z-index:15}.tabulator-row .tabulator-row-resize-handle{position:absolute;right:0;bottom:0;left:0;height:5px}.tabulator-row .tabulator-row-resize-handle.prev{top:0;bottom:auto}@media (hover:hover) and (pointer:fine){.tabulator-row .tabulator-row-resize-handle:hover{cursor:ns-resize}}.tabulator-row .tabulator-responsive-collapse{box-sizing:border-box;padding:5px;border-top:1px solid #ddd;border-bottom:1px solid #ddd}.tabulator-row .tabulator-responsive-collapse:empty{display:none}.tabulator-row .tabulator-responsive-collapse table{font-size:14px}.tabulator-row .tabulator-responsive-collapse table tr td{position:relative}.tabulator-row .tabulator-responsive-collapse table tr td:first-of-type{padding-right:10px}.tabulator-row .tabulator-cell{display:inline-block;position:relative;box-sizing:border-box;padding:4px;border-right:1px solid #ddd;vertical-align:middle;white-space:nowrap;overflow:hidden;text-overflow:ellipsis}.tabulator-row .tabulator-cell.tabulator-frozen{display:inline-block;position:sticky;left:0;background-color:inherit;z-index:10}.tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-left{border-right:2px solid #ddd}.tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-right{border-left:2px solid #ddd}.tabulator-row .tabulator-cell.tabulator-editing{border:1px solid #1d68cd;outline:none;padding:0}.tabulator-row .tabulator-cell.tabulator-editing input,.tabulator-row .tabulator-cell.tabulator-editing select{border:1px;background:transparent;outline:none}.tabulator-row .tabulator-cell.tabulator-validation-fail{border:1px solid #d00}.tabulator-row .tabulator-cell.tabulator-validation-fail input,.tabulator-row .tabulator-cell.tabulator-validation-fail select{border:1px;background:transparent;color:#d00}.tabulator-row .tabulator-cell.tabulator-row-handle{display:inline-flex;align-items:center;justify-content:center;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none}.tabulator-row .tabulator-cell.tabulator-row-handle .tabulator-row-handle-box{width:80%}.tabulator-row .tabulator-cell.tabulator-row-handle .tabulator-row-handle-box .tabulator-row-handle-bar{width:100%;height:3px;margin-top:2px;background:#666}.tabulator-row .tabulator-cell .tabulator-data-tree-branch{display:inline-block;vertical-align:middle;height:9px;width:7px;margin-top:-9px;margin-right:5px;border-bottom-left-radius:1px;border-left:2px solid #ddd;border-bottom:2px solid #ddd}.tabulator-row .tabulator-cell .tabulator-data-tree-control{display:inline-flex;justify-content:center;align-items:center;vertical-align:middle;height:11px;width:11px;margin-right:5px;border:1px solid #333;border-radius:2px;background:rgba(0,0,0,.1);overflow:hidden}@media (hover:hover) and (pointer:fine){.tabulator-row .tabulator-cell .tabulator-data-tree-control:hover{cursor:pointer;background:rgba(0,0,0,.2)}}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-collapse{display:inline-block;position:relative;height:7px;width:1px;background:transparent}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-collapse:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-expand{display:inline-block;position:relative;height:7px;width:1px;background:#333}.tabulator-row .tabulator-cell .tabulator-data-tree-control .tabulator-data-tree-control-expand:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle{display:inline-flex;align-items:center;justify-content:center;-moz-user-select:none;-khtml-user-select:none;-webkit-user-select:none;-o-user-select:none;height:15px;width:15px;border-radius:20px;background:#666;color:#fff;font-weight:700;font-size:1.1em}@media (hover:hover) and (pointer:fine){.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle:hover{opacity:.7;cursor:pointer}}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle.open .tabulator-responsive-collapse-toggle-close{display:initial}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle.open .tabulator-responsive-collapse-toggle-open{display:none}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle svg{stroke:#fff}.tabulator-row .tabulator-cell .tabulator-responsive-collapse-toggle .tabulator-responsive-collapse-toggle-close{display:none}.tabulator-row .tabulator-cell .tabulator-traffic-light{display:inline-block;height:14px;width:14px;border-radius:14px}.tabulator-row.tabulator-group{box-sizing:border-box;border-bottom:1px solid #999;border-right:1px solid #ddd;border-top:1px solid #999;padding:5px 5px 5px 10px;background:#ccc;font-weight:700;min-width:100%}@media (hover:hover) and (pointer:fine){.tabulator-row.tabulator-group:hover{cursor:pointer;background-color:rgba(0,0,0,.1)}}.tabulator-row.tabulator-group.tabulator-group-visible .tabulator-arrow{margin-right:10px;border-left:6px solid transparent;border-right:6px solid transparent;border-top:6px solid #666;border-bottom:0}.tabulator-row.tabulator-group.tabulator-group-level-1{padding-left:30px}.tabulator-row.tabulator-group.tabulator-group-level-2{padding-left:50px}.tabulator-row.tabulator-group.tabulator-group-level-3{padding-left:70px}.tabulator-row.tabulator-group.tabulator-group-level-4{padding-left:90px}.tabulator-row.tabulator-group.tabulator-group-level-5{padding-left:110px}.tabulator-row.tabulator-group .tabulator-group-toggle{display:inline-block}.tabulator-row.tabulator-group .tabulator-arrow{display:inline-block;width:0;height:0;margin-right:16px;border-top:6px solid transparent;border-bottom:6px solid transparent;border-right:0;border-left:6px solid #666;vertical-align:middle}.tabulator-row.tabulator-group span{margin-left:10px;color:#d00}.tabulator-popup-container{position:absolute;display:inline-block;box-sizing:border-box;background:#fff;border:1px solid #ddd;box-shadow:0 0 5px 0 rgba(0,0,0,.2);font-size:14px;overflow-y:auto;-webkit-overflow-scrolling:touch;z-index:10000}.tabulator-popup{padding:5px;border-radius:3px}.tabulator-tooltip{max-width:Min(500px,100%);padding:3px 5px;border-radius:2px;box-shadow:none;font-size:12px;pointer-events:none}.tabulator-menu .tabulator-menu-item{position:relative;box-sizing:border-box;padding:5px 10px;user-select:none}.tabulator-menu .tabulator-menu-item.tabulator-menu-item-disabled{opacity:.5}@media (hover:hover) and (pointer:fine){.tabulator-menu .tabulator-menu-item:not(.tabulator-menu-item-disabled):hover{cursor:pointer;background:#fff}}.tabulator-menu .tabulator-menu-item.tabulator-menu-item-submenu{padding-right:25px}.tabulator-menu .tabulator-menu-item.tabulator-menu-item-submenu:after{display:inline-block;position:absolute;top:calc(5px + .4em);right:10px;height:7px;width:7px;content:\\\"\\\";border-color:#ddd;border-style:solid;border-width:1px 1px 0 0;vertical-align:top;transform:rotate(45deg)}.tabulator-menu .tabulator-menu-separator{border-top:1px solid #ddd}.tabulator-edit-list{max-height:200px;font-size:14px;overflow-y:auto;-webkit-overflow-scrolling:touch}.tabulator-edit-list .tabulator-edit-list-item{padding:4px;color:#333;outline:none}.tabulator-edit-list .tabulator-edit-list-item.active{color:#fff;background:#1d68cd}.tabulator-edit-list .tabulator-edit-list-item.active.focused{outline:1px solid hsla(0,0%,100%,.5)}.tabulator-edit-list .tabulator-edit-list-item.focused{outline:1px solid #1d68cd}@media (hover:hover) and (pointer:fine){.tabulator-edit-list .tabulator-edit-list-item:hover{cursor:pointer;color:#fff;background:#1d68cd}}.tabulator-edit-list .tabulator-edit-list-placeholder{padding:4px;color:#333;text-align:center}.tabulator-edit-list .tabulator-edit-list-group{border-bottom:1px solid #ddd;padding:6px 4px 4px;color:#333;font-weight:700}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-2,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-2{padding-left:12px}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-3,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-3{padding-left:20px}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-4,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-4{padding-left:28px}.tabulator-edit-list .tabulator-edit-list-group.tabulator-edit-list-group-level-5,.tabulator-edit-list .tabulator-edit-list-item.tabulator-edit-list-group-level-5{padding-left:36px}.tabulator.tabulator-ltr{direction:ltr}.tabulator.tabulator-rtl{text-align:initial;direction:rtl}.tabulator.tabulator-rtl .tabulator-header .tabulator-col{text-align:initial;border-left:1px solid #ddd;border-right:initial}.tabulator.tabulator-rtl .tabulator-header .tabulator-col.tabulator-col-group .tabulator-col-group-cols{margin-right:0;margin-left:-1px}.tabulator.tabulator-rtl .tabulator-header .tabulator-col.tabulator-sortable .tabulator-col-title{padding-right:0;padding-left:25px}.tabulator.tabulator-rtl .tabulator-header .tabulator-col .tabulator-col-content .tabulator-col-sorter{left:8px;right:auto}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell{border-right:initial;border-left:1px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell .tabulator-data-tree-branch{margin-right:0;margin-left:5px;border-bottom-left-radius:0;border-bottom-right-radius:1px;border-left:initial;border-right:2px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell .tabulator-data-tree-control{margin-right:0;margin-left:5px}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-left{border-left:2px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-cell.tabulator-frozen.tabulator-frozen-right{border-right:2px solid #ddd}.tabulator.tabulator-rtl .tabulator-row .tabulator-col-resize-handle:last-of-type{width:3px;margin-left:0;margin-right:-3px}.tabulator.tabulator-rtl .tabulator-footer .tabulator-calcs-holder{text-align:initial}.tabulator-print-fullscreen{position:absolute;top:0;bottom:0;left:0;right:0;z-index:10000}body.tabulator-print-fullscreen-hide>:not(.tabulator-print-fullscreen){display:none!important}.tabulator-print-table{border-collapse:collapse}.tabulator-print-table .tabulator-data-tree-branch{display:inline-block;vertical-align:middle;height:9px;width:7px;margin-top:-9px;margin-right:5px;border-bottom-left-radius:1px;border-left:2px solid #ddd;border-bottom:2px solid #ddd}.tabulator-print-table .tabulator-print-table-group{box-sizing:border-box;border-bottom:1px solid #999;border-right:1px solid #ddd;border-top:1px solid #999;padding:5px 5px 5px 10px;background:#ccc;font-weight:700;min-width:100%}@media (hover:hover) and (pointer:fine){.tabulator-print-table .tabulator-print-table-group:hover{cursor:pointer;background-color:rgba(0,0,0,.1)}}.tabulator-print-table .tabulator-print-table-group.tabulator-group-visible .tabulator-arrow{margin-right:10px;border-left:6px solid transparent;border-right:6px solid transparent;border-top:6px solid #666;border-bottom:0}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-1 td{padding-left:30px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-2 td{padding-left:50px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-3 td{padding-left:70px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-4 td{padding-left:90px!important}.tabulator-print-table .tabulator-print-table-group.tabulator-group-level-5 td{padding-left:110px!important}.tabulator-print-table .tabulator-print-table-group .tabulator-group-toggle{display:inline-block}.tabulator-print-table .tabulator-print-table-group .tabulator-arrow{display:inline-block;width:0;height:0;margin-right:16px;border-top:6px solid transparent;border-bottom:6px solid transparent;border-right:0;border-left:6px solid #666;vertical-align:middle}.tabulator-print-table .tabulator-print-table-group span{color:#d00}.tabulator-print-table .tabulator-data-tree-control{display:inline-flex;justify-content:center;align-items:center;vertical-align:middle;height:11px;width:11px;margin-right:5px;border:1px solid #333;border-radius:2px;background:rgba(0,0,0,.1);overflow:hidden}@media (hover:hover) and (pointer:fine){.tabulator-print-table .tabulator-data-tree-control:hover{cursor:pointer;background:rgba(0,0,0,.2)}}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-collapse{display:inline-block;position:relative;height:7px;width:1px;background:transparent}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-collapse:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-expand{display:inline-block;position:relative;height:7px;width:1px;background:#333}.tabulator-print-table .tabulator-data-tree-control .tabulator-data-tree-control-expand:after{position:absolute;content:\\\"\\\";left:-3px;top:3px;height:1px;width:7px;background:#333}.tabulator{border:none;background-color:#fff}.tabulator .tabulator-header .tabulator-calcs-holder{background:#f2f2f2!important;border-bottom:1px solid #999}.tabulator .tabulator-header .tabulator-calcs-holder .tabulator-row{background:#f2f2f2!important}.tabulator .tabulator-tableholder .tabulator-placeholder span{color:#000}.tabulator .tabulator-footer .tabulator-calcs-holder{background:#f2f2f2!important;border-bottom:1px solid #fff}.tabulator .tabulator-footer .tabulator-calcs-holder .tabulator-row{background:#f2f2f2!important}.tabulator-row{border-bottom:1px solid #ddd}.tabulator-row .tabulator-cell:last-of-type{border-right:none}.tabulator-row.tabulator-group span{color:#666}.tabulator-print-table .tabulator-print-table-group span{margin-left:10px;color:#666}\\n/*# sourceMappingURL=tabulator_simple.min.css.map */\");\n    },    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      Bokeh = root.Bokeh;\n      bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      if (!reloading && (!bokeh_loaded || is_dev)) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2997c6e74743be84212a5d2f89f123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Column\n",
       "    [0] Tabulator(disabled=True, height=400, page_size=10, pagination='local', selection=[0], show_index=False, sorters=[{'field': 'Modification D...], value=              ...)\n",
       "    [1] Tabulator(disabled=True, height=400, page_size=10, pagination='local', show_index=False, sorters=[{'field': 'Modification D...], value=              ...)\n",
       "    [2] Column(margin=(10, 0))\n",
       "        [0] HTML(str)\n",
       "        [1] Row\n",
       "            [0] IntInput(end=100, name='Min FR (Hz)', start=0, value=2, width=150)\n",
       "            [1] TextInput(name='QClu Values', placeholder='Enter as list: [1, ..., value='[1, 2, 4, 6, 7, 8, 9]')\n",
       "    [3] Row\n",
       "        [0] Button(button_type='success', name='Save')\n",
       "        [1] Button(button_type='primary', name='Load')\n",
       "        [2] Button(button_type='warning', name='Compute')\n",
       "        [3] Button(button_type='primary', name='Compute New')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Load Data                                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "active_data_mode_name = 'kdiba'\n",
    "local_session_root_parent_context = IdentifyingContext(format_name=active_data_mode_name) # , animal_name='', configuration_name='one', session_name=a_sess.session_name\n",
    "local_session_root_parent_path = global_data_root_parent_path.joinpath('KDIBA')\n",
    "\n",
    "# [*] - indicates bad or session with a problem\n",
    "# 0, 1, 2, 3, 4, 5, 6, 7, [8], [9], 10, 11, [12], 13, 14, [15], [16], 17, \n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-08_14-26-15') # Recomputed 2025-06-10 00:56\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43') # Recomputed 2025-06-10 01:18\n",
    "curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-12_15-55-31') # Recomputed 2025-06-10 01:16 \n",
    "\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19') # Recomputed 2025-06-10 01:56  -- notedy ylims shifted up by about half the track width\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-12_16-53-46') # Recomputed 2025-06-10 02:27 \n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-09_17-29-30') ## BLOCKING ERROR with pf2D computation (empty) for 5Hz 2024-12-02 15:24 \n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='one',session_name='2006-4-10_12-25-50') # Recomputed 2025-06-10 02:40 \n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-09_16-40-54') # 2025-06-10 02:52 -- about 3 good replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='vvp01',exper_name='two',session_name='2006-4-10_12-58-3') # Recomputed 2025-06-10 03:23\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='11-03_12-3-25') # Recomputed 2024-12-16 19:33 -- about 5 good replays\n",
    "# curr_context = IdentifyingContext(format_name='kdiba',animal='pin01',exper_name='one',session_name='fet11-01_12-58-54') # Recomputed 2024-12-16 19:36 -- TONS of good replays, 10+ pages of them \n",
    "\n",
    "local_session_parent_path: Path = local_session_root_parent_path.joinpath(curr_context.animal, curr_context.exper_name) # 'gor01', 'one' - probably not needed anymore\n",
    "basedir: Path = local_session_parent_path.joinpath(curr_context.session_name).resolve()\n",
    "print(f'basedir: {str(basedir)}')\n",
    "\n",
    "epoch_name_includelist = None\n",
    "active_computation_functions_name_includelist=['lap_direction_determination',\n",
    "                                                'pf_computation',\n",
    "                                                'pfdt_computation',\n",
    "                                                # 'firing_rate_trends',\n",
    "                                                # 'pf_dt_sequential_surprise', \n",
    "                                            #    'ratemap_peaks_prominence2d',\n",
    "                                                'position_decoding', \n",
    "                                                # 'position_decoding_two_step', #'directional_decoders_epoch_heuristic_scoring',\n",
    "                                            #    'long_short_decoding_analyses', 'jonathan_firing_rate_analysis', 'long_short_fr_indicies_analyses', 'short_long_pf_overlap_analyses', 'long_short_post_decoding', 'long_short_rate_remapping',\n",
    "                                            #     'long_short_inst_spike_rate_groups',\n",
    "                                            #     'long_short_endcap_analysis',\n",
    "                                            \n",
    "]\n",
    "\n",
    "## 'split_to_directional_laps' -- is global\n",
    "\n",
    "\n",
    "\n",
    "# Read if possible:\n",
    "saving_mode = PipelineSavingScheme.SKIP_SAVING\n",
    "force_reload = False\n",
    "\n",
    "# # Force write:\n",
    "# saving_mode = PipelineSavingScheme.TEMP_THEN_OVERWRITE\n",
    "# # saving_mode = PipelineSavingScheme.OVERWRITE_IN_PLACE\n",
    "# force_reload = True\n",
    "\n",
    "selector, on_value_change = PipelineJupyterHelpers._build_pipeline_custom_processing_mode_selector_widget(update_global_variable_fn=update_global_variable, debug_print=False, enable_full_view=True)\n",
    "# selector.value = 'clean_run'\n",
    "selector.value = 'continued_run'\n",
    "# selector.value = 'final_run'\n",
    "on_value_change(dict(new=selector.value)) ## do update manually so the workspace variables reflect the set values\n",
    "## TODO: if loading is not possible, we need to change the `saving_mode` so that the new results are properly saved.\n",
    "print(f\"saving_mode: {saving_mode}, force_reload: {force_reload}\")\n",
    "\n",
    "extended_computations_include_includelist_phase_dict: Dict[str, CustomProcessingPhases] = CustomProcessingPhases.get_extended_computations_include_includelist_phase_dict()\n",
    "\n",
    "current_phase: CustomProcessingPhases = CustomProcessingPhases[selector.value]  # Assuming selector.value is an instance of CustomProcessingPhases\n",
    "extended_computations_include_includelist: List[str] = [key for key, value in extended_computations_include_includelist_phase_dict.items() if value <= current_phase]\n",
    "display(extended_computations_include_includelist)\n",
    "force_recompute_override_computations_includelist = None\n",
    "# force_recompute_override_computations_includelist = ['split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous'] # \n",
    "\n",
    "# ## INPUTS: basedir\n",
    "active_session_pickle_file_widget = PipelinePickleFileSelectorWidget(directory=basedir, on_update_global_variable_callback=update_global_variable, on_get_global_variable_callback=get_global_variable)\n",
    "\n",
    "_subfn_load, _subfn_save, _subfn_compute, _subfn_compute_new = active_session_pickle_file_widget._build_load_save_callbacks(global_data_root_parent_path=global_data_root_parent_path, active_data_mode_name=active_data_mode_name, basedir=basedir, saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                                             extended_computations_include_includelist=extended_computations_include_includelist, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist)\n",
    "\n",
    "## try selecting the first\n",
    "did_find_valid_selection: bool = active_session_pickle_file_widget.try_select_first_valid_files()\n",
    "\n",
    "# Display the widget\n",
    "active_session_pickle_file_widget.servable()\n",
    "# active_session_pickle_file_widget.try_select_first_valid_files()\n",
    "\n",
    "# OUTPUTS: active_session_pickle_file_widget, widget.active_local_pkl, widget.active_global_pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc6e0657",
   "metadata": {
    "tags": [
     "run-group-0-interactive",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "if did_find_valid_selection:\n",
    "\t_subfn_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3776d302",
   "metadata": {},
   "outputs": [],
   "source": [
    "_subfn_compute_new()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabb8569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom_suffix: str = '_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0'\n",
    "\n",
    "minimum_inclusion_fr_Hz = active_session_pickle_file_widget.current_parameter_values['minimum_inclusion_fr_Hz']\n",
    "included_qclu_values = active_session_pickle_file_widget.current_parameter_values['included_qclu_values']\n",
    "\n",
    "included_qclu_values\n",
    "\n",
    "custom_suffix: str = f'_withNewComputedReplays-qclu_{included_qclu_values}-frateThresh_{minimum_inclusion_fr_Hz:02d}'\n",
    "custom_suffix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac6b6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set default local comp pkl:\n",
    "default_selected_local_file_name: str = 'loadedSessPickle.pkl'\n",
    "default_local_section_indicies = [active_session_pickle_file_widget.local_file_browser_widget._data['File Name'].tolist().index(default_selected_local_file_name)]\n",
    "active_session_pickle_file_widget.local_file_browser_widget.selection = default_local_section_indicies\n",
    "\n",
    "## Set default global computation pkl:\n",
    "default_selected_global_file_name: str = 'global_computation_results.pkl'\n",
    "default_global_section_indicies = [active_session_pickle_file_widget.global_file_browser_widget._data['File Name'].tolist().index(default_selected_global_file_name)]\n",
    "active_session_pickle_file_widget.global_file_browser_widget.selection = default_global_section_indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaac9d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.pickle_path\n",
    "# curr_active_pipeline.has_associated_pickle\n",
    "curr_active_pipeline.save_pipeline("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c072a49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.IPyWidgets.SaveAsWidget import PipelineBackupWidget\n",
    "\n",
    "backup_widget = PipelineBackupWidget(curr_active_pipeline)\n",
    "backup_widget.servable()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb1135e",
   "metadata": {},
   "source": [
    "## <a id='toc2_1_'></a>[2024-06-25 - Load from saved custom](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5515d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline, custom_suffix, proposed_load_pkl_path = active_session_pickle_file_widget.on_load_local(global_data_root_parent_path=global_data_root_parent_path, active_data_mode_name=active_data_mode_name, basedir=basedir, saving_mode=saving_mode, force_reload=force_reload)\n",
    "curr_active_pipeline = active_session_pickle_file_widget.on_load_global(curr_active_pipeline=curr_active_pipeline, basedir=basedir, extended_computations_include_includelist=extended_computations_include_includelist, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist,\n",
    "                                       skip_global_load=False, force_reload=False, override_global_computation_results_pickle_path=active_session_pickle_file_widget.active_global_pkl)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9337ddc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads custom pipeline pickles that were saved out via `custom_save_filepaths['pipeline_pkl'] = curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE, active_pickle_filename=custom_save_filenames['pipeline_pkl'])`\n",
    "\n",
    "## INPUTS: global_data_root_parent_path, active_data_mode_name, basedir, saving_mode, force_reload, custom_save_filenames\n",
    "# custom_suffix: str = '_withNewKamranExportedReplays'\n",
    "\n",
    "# custom_suffix: str = '_withNewComputedReplays'\n",
    "# custom_suffix: str = '_withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0'\n",
    "\n",
    "# custom_save_filenames = {\n",
    "#     'pipeline_pkl':f'loadedSessPickle{custom_suffix}.pkl',\n",
    "#     'global_computation_pkl':f\"global_computation_results{custom_suffix}.pkl\",\n",
    "#     'pipeline_h5':f'pipeline{custom_suffix}.h5',\n",
    "# }\n",
    "# print(f'custom_save_filenames: {custom_save_filenames}')\n",
    "# custom_save_filepaths = {k:v for k, v in custom_save_filenames.items()}\n",
    "\n",
    "# # ==================================================================================================================== #\n",
    "# # PIPELINE LOADING                                                                                                     #\n",
    "# # ==================================================================================================================== #\n",
    "# # load the custom saved outputs\n",
    "# active_pickle_filename = custom_save_filenames['pipeline_pkl'] # 'loadedSessPickle_withParameters.pkl'\n",
    "# print(f'active_pickle_filename: \"{active_pickle_filename}\"')\n",
    "# # assert active_pickle_filename.exists()\n",
    "# active_session_h5_filename = custom_save_filenames['pipeline_h5'] # 'pipeline_withParameters.h5'\n",
    "# print(f'active_session_h5_filename: \"{active_session_h5_filename}\"')\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "## DO NOT allow recompute if the file doesn't exist!!\n",
    "# Computing loaded session pickle file results : \"W:/Data/KDIBA/gor01/two/2006-6-07_16-40-19/loadedSessPickle_withNewComputedReplays.pkl\"... done.\n",
    "# Failure loading W:\\Data\\KDIBA\\gor01\\two\\2006-6-07_16-40-19\\loadedSessPickle_withNewComputedReplays.pkl.\n",
    "# proposed_load_pkl_path = basedir.joinpath(active_pickle_filename).resolve()\n",
    "\n",
    "## INPUTS: widget.active_global_pkl, widget.active_global_pkl\n",
    "\n",
    "if active_session_pickle_file_widget.active_global_pkl is None:\n",
    "    skip_global_load: bool = True\n",
    "    override_global_computation_results_pickle_path = None\n",
    "else:\n",
    "    skip_global_load: bool = False\n",
    "    override_global_computation_results_pickle_path = active_session_pickle_file_widget.active_global_pkl.resolve()\n",
    "    Assert.path_exists(override_global_computation_results_pickle_path)\n",
    "    override_global_computation_results_pickle_path\n",
    "\n",
    "\n",
    "proposed_load_pkl_path = active_session_pickle_file_widget.active_local_pkl.resolve()\n",
    "Assert.path_exists(proposed_load_pkl_path)\n",
    "proposed_load_pkl_path\n",
    "\n",
    "custom_suffix: str = active_session_pickle_file_widget.try_extract_custom_suffix()\n",
    "print(f'custom_suffix: \"{custom_suffix}\"')\n",
    "\n",
    "## OUTPUTS: custom_suffix, proposed_load_pkl_path, (override_global_computation_results_pickle_path, skip_global_load)\n",
    "from pyphocorehelpers.Filesystem.path_helpers import set_posix_windows\n",
    "## INPUTS: proposed_load_pkl_path\n",
    "assert proposed_load_pkl_path.exists(), f\"for a saved custom the file must exist!\"\n",
    "\n",
    "epoch_name_includelist=None\n",
    "active_computation_functions_name_includelist=['lap_direction_determination', 'pf_computation','firing_rate_trends', 'position_decoding']\n",
    "\n",
    "with set_posix_windows():\n",
    "    curr_active_pipeline: NeuropyPipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_includelist=epoch_name_includelist,\n",
    "                                            computation_functions_name_includelist=active_computation_functions_name_includelist,\n",
    "                                            saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                            skip_extended_batch_computations=True, debug_print=False, fail_on_exception=True, active_pickle_filename=proposed_load_pkl_path) # , active_pickle_filename = 'loadedSessPickle_withParameters.pkl'\n",
    "\n",
    "## Post Compute Validate 2023-05-16:\n",
    "was_updated = BatchSessionCompletionHandler.post_compute_validate(curr_active_pipeline) ## TODO: need to potentially re-save if was_updated. This will fail because constained versions not ran yet.\n",
    "if was_updated:\n",
    "    print(f'was_updated: {was_updated}')\n",
    "    try:\n",
    "        if saving_mode == PipelineSavingScheme.SKIP_SAVING:\n",
    "            print(f'WARNING: PipelineSavingScheme.SKIP_SAVING but need to save post_compute_validate changes!!')\n",
    "        else:\n",
    "            curr_active_pipeline.save_pipeline(saving_mode=saving_mode)\n",
    "    except Exception as e:\n",
    "        ## TODO: catch/log saving error and indicate that it isn't saved.\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'ERROR RE-SAVING PIPELINE after update. error: {e}')\n",
    "\n",
    "print(f'Pipeline loaded from custom pickle!!')\n",
    "## OUTPUT: curr_active_pipeline\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Global computations loading:                                                                                            #\n",
    "# ==================================================================================================================== #\n",
    "# Loads saved global computations that were saved out via: `custom_save_filepaths['global_computation_pkl'] = curr_active_pipeline.save_global_computation_results(override_global_pickle_filename=custom_save_filenames['global_computation_pkl'])`\n",
    "## INPUTS: custom_save_filenames\n",
    "## INPUTS: curr_active_pipeline, override_global_computation_results_pickle_path, extended_computations_include_includelist\n",
    "\n",
    "override_global_computation_results_pickle_path = None\n",
    "# override_global_computation_results_pickle_path = custom_save_filenames['global_computation_pkl']\n",
    "print(f'override_global_computation_results_pickle_path: \"{override_global_computation_results_pickle_path}\"')\n",
    "\n",
    "# Pre-load ___________________________________________________________________________________________________________ #\n",
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Pre-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "# valid_computed_results_output_list\n",
    "\n",
    "# Try Unpickling Global Computations to update pipeline ______________________________________________________________ #\n",
    "if (not force_reload) and (not skip_global_load): # not just force_reload, needs to recompute whenever the computation fails.\n",
    "    try:\n",
    "        # INPUTS: override_global_computation_results_pickle_path\n",
    "        with set_posix_windows():\n",
    "            sucessfully_updated_keys, successfully_loaded_keys = curr_active_pipeline.load_pickled_global_computation_results(override_global_computation_results_pickle_path=override_global_computation_results_pickle_path,\n",
    "                                                                                            allow_overwrite_existing=True, allow_overwrite_existing_allow_keys=extended_computations_include_includelist, ) # is new\n",
    "            print(f'sucessfully_updated_keys: {sucessfully_updated_keys}\\nsuccessfully_loaded_keys: {successfully_loaded_keys}')\n",
    "            did_any_paths_change: bool = curr_active_pipeline.post_load_fixup_sess_basedirs(updated_session_basepath=deepcopy(basedir)) ## use INPUT: basedir\n",
    "            \n",
    "    except FileNotFoundError as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'cannot load global results because pickle file does not exist! Maybe it has never been created? {e}')\n",
    "    except Exception as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'Unhandled exception: cannot load global results: {e}')\n",
    "        raise\n",
    "\n",
    "# Post-Load __________________________________________________________________________________________________________ #\n",
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "\n",
    "\n",
    "\n",
    "## fixup missing paths\n",
    "# self.basepath: WindowsPath('/nfs/turbo/umms-kdiba/KDIBA/gor01/one/2006-6-09_1-22-43')\n",
    "\n",
    "## INPUTS: basedir\n",
    "did_any_paths_change: bool = curr_active_pipeline.post_load_fixup_sess_basedirs(updated_session_basepath=deepcopy(basedir)) ## use INPUT: basedir\n",
    "\n",
    "# Compute ____________________________________________________________________________________________________________ #\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "force_recompute_global = force_reload\n",
    "# force_recompute_global = True\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "if (len(newly_computed_values) > 0):\n",
    "    print(f'newly_computed_values: {newly_computed_values}.')\n",
    "    if (saving_mode.value != 'skip_saving'):\n",
    "        print(f'Saving global results...')\n",
    "        try:\n",
    "            # curr_active_pipeline.global_computation_results.persist_time = datetime.now()\n",
    "            # Try to write out the global computation function results:\n",
    "            curr_active_pipeline.save_global_computation_results()\n",
    "        except Exception as e:\n",
    "            exception_info = sys.exc_info()\n",
    "            e = CapturedException(e, exception_info)\n",
    "            print(f'\\n\\n!!WARNING!!: saving the global results threw the exception: {e}')\n",
    "            print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "    else:\n",
    "        print(f'\\n\\n!!WARNING!!: changes to global results have been made but they will not be saved since saving_mode.value == \"skip_saving\"')\n",
    "        print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "else:\n",
    "    print(f'no changes in global results.')\n",
    "\n",
    "# Post-compute _______________________________________________________________________________________________________ #\n",
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=False, force_recompute_override_computations_includelist=[], debug_print=True)\n",
    "print(f'Post-compute validation: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "\n",
    "# Post-Load __________________________________________________________________________________________________________ #\n",
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "\n",
    "print(f'force_reload: {force_reload}, saving_mode: {saving_mode}')\n",
    "force_reload\n",
    "saving_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f813f01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## indicate that it was loaded with a custom suffix\n",
    "curr_active_pipeline.pickle_path ## correct\n",
    "curr_active_pipeline.global_computation_results_pickle_path ## correct\n",
    "\n",
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE, override_pickle_path=curr_active_pipeline.pickle_path, active_pickle_filename=curr_active_pipeline.pickle_path.name) #active_pickle_filename=\n",
    "curr_active_pipeline.save_global_computation_results(override_global_pickle_path=curr_active_pipeline.global_computation_results_pickle_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49de9fb9",
   "metadata": {},
   "source": [
    "## 0️⃣💾 Save Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba28da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_selected_local_file_name: str = 'loadedSessPickle.pkl'\n",
    "if curr_active_pipeline.pickle_path is None:\n",
    "    curr_active_pipeline.pickle_path = Path('W:/Data/KDIBA/vvp01/one/2006-4-09_17-29-30/loadedSessPickle.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89fe1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## indicate that it was loaded with a custom suffix\n",
    "curr_active_pipeline.pickle_path ## correct\n",
    "curr_active_pipeline.global_computation_results_pickle_path ## correct\n",
    "\n",
    "if curr_active_pipeline.pickle_path is None:\n",
    "    active_pickle_filename = 'loadedSessPickle.pkl'\n",
    "else:\n",
    "    active_pickle_filename = curr_active_pipeline.pickle_path.name\n",
    "    \n",
    "print(f'active_pickle_filename: {active_pickle_filename}')\n",
    "curr_active_pipeline.save_pipeline(saving_mode=PipelineSavingScheme.TEMP_THEN_OVERWRITE, override_pickle_path=curr_active_pipeline.pickle_path, active_pickle_filename=active_pickle_filename) #active_pickle_filename=\n",
    "curr_active_pipeline.save_global_computation_results(override_global_pickle_path=curr_active_pipeline.global_computation_results_pickle_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9ba82e",
   "metadata": {},
   "source": [
    "## <a id='toc2_3_'></a>[0️⃣ Normal Pipeline Load](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8167df1c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-0",
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# ==================================================================================================================== #\n",
    "# Load Pipeline                                                                                                        #\n",
    "# ==================================================================================================================== #\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-full_session_LOO_decoding_analysis.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "# epoch_name_includelist = ['maze']\n",
    "\n",
    "curr_active_pipeline: NeuropyPipeline = batch_load_session(global_data_root_parent_path, active_data_mode_name, basedir, epoch_name_includelist=epoch_name_includelist,\n",
    "                                        computation_functions_name_includelist=active_computation_functions_name_includelist,\n",
    "                                        saving_mode=saving_mode, force_reload=force_reload,\n",
    "                                        skip_extended_batch_computations=True, debug_print=True, fail_on_exception=False) #, time_bin_size = 0.025 time_bin_size = 0.058, override_parameters_flat_keypaths_dict = dict(), \n",
    "# , active_pickle_filename = 'loadedSessPickle_withParameters.pkl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b125667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.get_failed_computations()\n",
    "curr_active_pipeline.clear_all_failed_computations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76c7dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# {'maze1_odd': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze2_odd': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze_odd': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze1_even': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze2_even': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze_even': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze1_any': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze2_any': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')},\n",
    "#  'maze_any': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:1065<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')}}\n",
    "\n",
    "_out = curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_split_to_directional_laps'], fail_on_exception=True, debug_print=True)\n",
    "\n",
    "\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_split_to_directional_laps'], computation_kwargs_list=[{}], \n",
    "#                                                   enabled_filter_names=None, fail_on_exception=True, debug_print=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8edcd94",
   "metadata": {
    "tags": [
     "run-group-0"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "## Post Compute Validate 2023-05-16:\n",
    "# was_updated = BatchSessionCompletionHandler.post_compute_validate(curr_active_pipeline) ## TODO: need to potentially re-save if was_updated. This will fail because constained versions not ran yet.\n",
    "was_updated = False\n",
    "if was_updated:\n",
    "    print(f'was_updated: {was_updated}')\n",
    "    try:\n",
    "        curr_active_pipeline.save_pipeline(saving_mode=saving_mode)\n",
    "    except Exception as e:\n",
    "        ## TODO: catch/log saving error and indicate that it isn't saved.\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'ERROR RE-SAVING PIPELINE after update. error: {e}')\n",
    "\n",
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Pre-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "# valid_computed_results_output_list\n",
    "if not force_reload: # not just force_reload, needs to recompute whenever the computation fails.\n",
    "    try:\n",
    "        # curr_active_pipeline.load_pickled_global_computation_results()\n",
    "        with set_posix_windows():\n",
    "            sucessfully_updated_keys, successfully_loaded_keys = curr_active_pipeline.load_pickled_global_computation_results(allow_overwrite_existing=True, allow_overwrite_existing_allow_keys=extended_computations_include_includelist) # is new\n",
    "            \n",
    "        print(f'sucessfully_updated_keys: {sucessfully_updated_keys}\\nsuccessfully_loaded_keys: {successfully_loaded_keys}')\n",
    "    except FileNotFoundError as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'cannot load global results because pickle file does not exist! Maybe it has never been created? {e}')\n",
    "    except Exception as e:\n",
    "        exception_info = sys.exc_info()\n",
    "        e = CapturedException(e, exception_info)\n",
    "        print(f'Unhandled exception: cannot load global results: {e}')\n",
    "        raise\n",
    "\n",
    "# Recomputing active_epoch_placefields... \t done.\n",
    "# Recomputing active_epoch_placefields2D... \t done.\n",
    "# WARN: f\"len(self.is_non_firing_time_bin): 30459, self.num_time_windows: 30762\", trying to recompute them....\n",
    "# UNHANDLED EXCEPTION: Unable to allocate 3.46 GiB for an array with shape (15124, 30724) and data type float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9809aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.accumulated_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcac55a8",
   "metadata": {
    "tags": [
     "run-group-0",
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "force_recompute_global = force_reload\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "force_recompute_global = force_reload # Post-load global computations: needs_computation_output_dict: ['rank_order_shuffle_analysis', 'directional_train_test_split', 'short_long_pf_overlap_analyses', 'wcorr_shuffle_analysis', 'extended_pf_peak_information', 'position_decoding_two_step']\n",
    "# force_recompute_global = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4321d2fc",
   "metadata": {
    "tags": [
     "run-group-0"
    ]
   },
   "outputs": [],
   "source": [
    "fail_on_exception = False\n",
    "\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=fail_on_exception, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "if (len(newly_computed_values) > 0):\n",
    "    print(f'newly_computed_values: {newly_computed_values}.')\n",
    "    if (saving_mode.value != 'skip_saving'):\n",
    "        print(f'Saving global results...')\n",
    "        try:\n",
    "            # curr_active_pipeline.global_computation_results.persist_time = datetime.now()\n",
    "            # Try to write out the global computation function results:\n",
    "            curr_active_pipeline.save_global_computation_results()\n",
    "        except Exception as e:\n",
    "            exception_info = sys.exc_info()\n",
    "            e = CapturedException(e, exception_info)\n",
    "            print(f'\\n\\n!!WARNING!!: saving the global results threw the exception: {e}')\n",
    "            print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "    else:\n",
    "        print(f'\\n\\n!!WARNING!!: changes to global results have been made but they will not be saved since saving_mode.value == \"skip_saving\"')\n",
    "        print(f'\\tthe global results are currently unsaved! proceed with caution and save as soon as you can!\\n\\n\\n')\n",
    "else:\n",
    "    print(f'no changes in global results.')\n",
    "\n",
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=fail_on_exception, progress_print=True,\n",
    "                                                    force_recompute=False, force_recompute_override_computations_includelist=[], debug_print=True)\n",
    "print(f'Post-compute validation: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615018da",
   "metadata": {},
   "source": [
    "## <a id='toc2_4_'></a>[0️⃣ Shared Post-Pipeline load stuff](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c842f5e4",
   "metadata": {
    "tags": [
     "run-group-0-interactive",
     "run-2025-04-11_full-session_marginals",
     "run-group-0"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO CUSTOM SUFFIX.\n",
      "collected_outputs_path: C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\output\\collected_outputs\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'curr_active_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 28\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcollected_outputs_path: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcollected_outputs_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# collected_outputs_path.mkdir(exist_ok=True)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# assert collected_outputs_path.exists()\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m## Build the output prefix from the session context:\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m active_context \u001b[38;5;241m=\u001b[39m \u001b[43mcurr_active_pipeline\u001b[49m\u001b[38;5;241m.\u001b[39mget_session_context()\n\u001b[0;32m     29\u001b[0m curr_session_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m curr_active_pipeline\u001b[38;5;241m.\u001b[39msession_name \u001b[38;5;66;03m# '2006-6-08_14-26-15'\u001b[39;00m\n\u001b[0;32m     30\u001b[0m CURR_BATCH_OUTPUT_PREFIX: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBATCH_DATE_TO_USE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurr_session_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'curr_active_pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "# BATCH_DATE_TO_USE: str = f'{DAY_DATE_TO_USE}_GL'\n",
    "# BATCH_DATE_TO_USE: str = f'{DAY_DATE_TO_USE}_rMBP' # TODO: Change this as needed, templating isn't actually doing anything rn.\n",
    "BATCH_DATE_TO_USE: str = f'{DAY_DATE_TO_USE}_Apogee'\n",
    "# BATCH_DATE_TO_USE: str = f'{DAY_DATE_TO_USE}_Lab'\n",
    " \n",
    "try:\n",
    "    if custom_suffix is not None:\n",
    "        BATCH_DATE_TO_USE = f'{BATCH_DATE_TO_USE}{custom_suffix}'\n",
    "        print(f'Adding custom suffix: \"{custom_suffix}\" - BATCH_DATE_TO_USE: \"{BATCH_DATE_TO_USE}\"')\n",
    "except NameError as err:\n",
    "    custom_suffix = None\n",
    "    print(f'NO CUSTOM SUFFIX.')\n",
    "\n",
    "known_collected_output_paths = [Path(v).resolve() for v in ['/nfs/turbo/umms-kdiba/Data/Output/collected_outputs', '/home/halechr/FastData/collected_outputs/',\n",
    "                                                           '/home/halechr/cloud/turbo/Data/Output/collected_outputs',\n",
    "                                                           r'C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\output\\collected_outputs',\n",
    "                                                           r\"K:\\scratch\\collected_outputs\",\n",
    "                                                           '/Users/pho/data/collected_outputs',\n",
    "                                                          'output/gen_scripts/']]\n",
    "collected_outputs_path = find_first_extant_path(known_collected_output_paths)\n",
    "assert collected_outputs_path.exists(), f\"collected_outputs_path: {collected_outputs_path} does not exist! Is the right computer's config commented out above?\"\n",
    "# fullwidth_path_widget(scripts_output_path, file_name_label='Scripts Output Path:')\n",
    "print(f'collected_outputs_path: {collected_outputs_path}')\n",
    "# collected_outputs_path.mkdir(exist_ok=True)\n",
    "# assert collected_outputs_path.exists()\n",
    "\n",
    "## Build the output prefix from the session context:\n",
    "active_context = curr_active_pipeline.get_session_context()\n",
    "curr_session_name: str = curr_active_pipeline.session_name # '2006-6-08_14-26-15'\n",
    "CURR_BATCH_OUTPUT_PREFIX: str = f\"{BATCH_DATE_TO_USE}-{curr_session_name}\"\n",
    "print(f'CURR_BATCH_OUTPUT_PREFIX: \"{CURR_BATCH_OUTPUT_PREFIX}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606e8116",
   "metadata": {},
   "source": [
    "## <a id='toc2_5_'></a>[Specific Recomputations](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f010d1a9",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "any_most_recent_computation_time, each_epoch_latest_computation_time, each_epoch_each_result_computation_completion_times, (global_computations_latest_computation_time, global_computation_completion_times) = curr_active_pipeline.get_computation_times(debug_print=False)\n",
    "# each_epoch_latest_computation_time\n",
    "each_epoch_each_result_computation_completion_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3d4f61",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd11d0f",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.clear_all_failed_computations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ff30b7",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_results.computation_config.instantaneous_time_bin_size_seconds = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58db94e",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "force_recompute_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f285cd23",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "force_recompute_global = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47820977",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "extended_computations_include_includelist=['lap_direction_determination', 'pf_computation', 'firing_rate_trends', 'pfdt_computation',\n",
    "    # 'pf_dt_sequential_surprise',\n",
    "    #  'ratemap_peaks_prominence2d',\n",
    "    'extended_stats',\n",
    "    'long_short_decoding_analyses',\n",
    "    'jonathan_firing_rate_analysis',\n",
    "    'long_short_fr_indicies_analyses',\n",
    "    'short_long_pf_overlap_analyses',\n",
    "    'long_short_post_decoding',\n",
    "    # 'long_short_rate_remapping',\n",
    "    'long_short_inst_spike_rate_groups',\n",
    "    'long_short_endcap_analysis',\n",
    "    # 'spike_burst_detection',\n",
    "    'split_to_directional_laps',\n",
    "    'merged_directional_placefields',\n",
    "    'rank_order_shuffle_analysis',\n",
    "    'directional_decoders_decode_continuous',\n",
    "    'directional_decoders_evaluate_epochs',\n",
    "    'directional_decoders_epoch_heuristic_scoring',\n",
    "] # do only specified\n",
    "\n",
    "# ['split_to_directional_laps', 'merged_directional_placefields', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous']\n",
    "\n",
    "# force_recompute_override_computations_includelist = [\n",
    "#     'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring',\n",
    "#     'split_to_directional_laps', 'lap_direction_determination', 'DirectionalLaps',\n",
    "#     'merged_directional_placefields',\n",
    "#     'directional_decoders_decode_continuous',\n",
    "# ]\n",
    "force_recompute_override_computations_includelist = None\n",
    "\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "newly_computed_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc0a702",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "# extended_computations_include_includelist=['ratemap_peaks_prominence2d', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring',] # do only specified\n",
    "extended_computations_include_includelist=['rank_order_shuffle_analysis', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs' ] # do only specified\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db62d145",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "newly_computed_values = curr_active_pipeline.batch_extended_computations(include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = curr_active_pipeline.batch_evaluate_required_computations(include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02779f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27120a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "newly_computed_values = curr_active_pipeline.batch_extended_computations(include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3927a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = curr_active_pipeline.batch_evaluate_required_computations(include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8b307a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.global_computation_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d357f9",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# mmm ## lots of m's to break computations\n",
    "\n",
    "## Next wave of computations\n",
    "extended_computations_include_includelist=['directional_decoders_epoch_heuristic_scoring',] # do only specified\n",
    "force_recompute_override_computations_includelist = deepcopy(extended_computations_include_includelist)\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617dbaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mmm ## lots of m's to break computations\n",
    "\n",
    "## Next wave of computations\n",
    "extended_computations_include_includelist=['rank_order_shuffle_analysis',] # do only specified\n",
    "force_recompute_override_computations_includelist = deepcopy(extended_computations_include_includelist)\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "# Post-hoc verification that the computations worked and that the validators reflect that. The list should be empty now.\n",
    "newly_computed_values = batch_extended_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3efc4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'lap_direction_determination'\n",
    "extended_computations_include_includelist=['_split_to_directional_laps'] # do only specified\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=extended_computations_include_includelist, include_global_functions=True, fail_on_exception=True, progress_print=True,\n",
    "                                                    force_recompute=force_recompute_global, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=True)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_split_to_directional_laps'], computation_kwargs_list=None, enabled_filter_names=None, fail_on_exception=True, debug_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d834f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "curr_active_pipeline.get_failed_computations() # 'maze1_odd': {'_split_to_directional_laps': CapturedException(_split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs', traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\Computation.py:973<fn: _execute_computation_functions>: TypeError: _split_to_directional_laps() missing 3 required positional arguments: 'global_computation_results', 'computation_results', and 'active_configs')}\n",
    "\n",
    "# curr_active_pipeline.rerun_failed_computations()\n",
    "# curr_active_pipeline.stage.rerun_failed_computations()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e982eb",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[0️⃣ Pho Interactive Pipeline Jupyter Widget](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce08192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from pyphocorehelpers.Filesystem.open_in_system_file_manager import reveal_in_system_file_manager\n",
    "from pyphoplacecellanalysis.GUI.IPyWidgets.pipeline_ipywidgets import interactive_pipeline_widget, interactive_pipeline_files\n",
    "\n",
    "_pipeline_jupyter_widget = interactive_pipeline_widget(curr_active_pipeline=curr_active_pipeline)\n",
    "# display(_pipeline_jupyter_widget)\n",
    "_pipeline_jupyter_widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474f4c95",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[1️⃣ End Run](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a533ba8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T23:21:40.700275900Z",
     "start_time": "2023-11-16T23:21:40.584273Z"
    },
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 656.0648088779999, 1122.1864874939201)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (long_one_step_decoder_1D, short_one_step_decoder_1D), (long_one_step_decoder_2D, short_one_step_decoder_2D) = compute_short_long_constrained_decoders(curr_active_pipeline, recalculate_anyway=True)\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_epoch_context, short_epoch_context, global_epoch_context = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_epoch_name, short_epoch_name, global_epoch_name)]\n",
    "long_epoch_obj, short_epoch_obj = [Epoch(curr_active_pipeline.sess.epochs.to_dataframe().epochs.label_slice(an_epoch_name.removesuffix('_any'))) for an_epoch_name in [long_epoch_name, short_epoch_name]] #TODO 2023-11-10 20:41: - [ ] Issue with getting actual Epochs from sess.epochs for directional laps: emerges because long_epoch_name: 'maze1_any' and the actual epoch label in curr_active_pipeline.sess.epochs is 'maze1' without the '_any' part.\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_results, short_results, global_results = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_computation_config, short_computation_config, global_computation_config = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "long_pf1D, short_pf1D, global_pf1D = long_results.pf1D, short_results.pf1D, global_results.pf1D\n",
    "long_pf2D, short_pf2D, global_pf2D = long_results.pf2D, short_results.pf2D, global_results.pf2D\n",
    "\n",
    "assert short_epoch_obj.n_epochs > 0, f'long_epoch_obj: {long_epoch_obj}, short_epoch_obj: {short_epoch_obj}'\n",
    "assert long_epoch_obj.n_epochs > 0, f'long_epoch_obj: {long_epoch_obj}, short_epoch_obj: {short_epoch_obj}'\n",
    "\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "t_start, t_delta, t_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b841b01c",
   "metadata": {
    "tags": [
     "created-2025-07-07"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e348e0c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>t_seconds</th>\n",
       "      <th>t_rel_seconds</th>\n",
       "      <th>shank</th>\n",
       "      <th>cluster</th>\n",
       "      <th>aclu</th>\n",
       "      <th>qclu</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>speed</th>\n",
       "      <th>traj</th>\n",
       "      <th>lap</th>\n",
       "      <th>maze_relative_lap</th>\n",
       "      <th>maze_id</th>\n",
       "      <th>is_theta</th>\n",
       "      <th>is_ripple</th>\n",
       "      <th>theta_phase_radians</th>\n",
       "      <th>neuron_type</th>\n",
       "      <th>flat_spike_idx</th>\n",
       "      <th>x_loaded</th>\n",
       "      <th>y_loaded</th>\n",
       "      <th>lin_pos</th>\n",
       "      <th>fragile_linear_neuron_IDX</th>\n",
       "      <th>PBE_id</th>\n",
       "      <th>scISI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>278.0</td>\n",
       "      <td>954487.442005</td>\n",
       "      <td>0.008540</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>150.977740</td>\n",
       "      <td>89.232496</td>\n",
       "      <td>1.623794</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.768066</td>\n",
       "      <td>NeuronType.INTERNEURONS</td>\n",
       "      <td>0</td>\n",
       "      <td>0.532477</td>\n",
       "      <td>0.317501</td>\n",
       "      <td>197.393093</td>\n",
       "      <td>34</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>301.0</td>\n",
       "      <td>954487.442712</td>\n",
       "      <td>0.009247</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>150.978050</td>\n",
       "      <td>89.233567</td>\n",
       "      <td>1.623932</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.858485</td>\n",
       "      <td>NeuronType.INTERNEURONS</td>\n",
       "      <td>1</td>\n",
       "      <td>0.532475</td>\n",
       "      <td>0.317523</td>\n",
       "      <td>197.392671</td>\n",
       "      <td>20</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>318.0</td>\n",
       "      <td>954487.443234</td>\n",
       "      <td>0.009769</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>150.978279</td>\n",
       "      <td>89.234359</td>\n",
       "      <td>1.624034</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3.858485</td>\n",
       "      <td>NeuronType.INTERNEURONS</td>\n",
       "      <td>2</td>\n",
       "      <td>0.532473</td>\n",
       "      <td>0.317539</td>\n",
       "      <td>197.392358</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>434.0</td>\n",
       "      <td>954487.446797</td>\n",
       "      <td>0.013332</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>150.979841</td>\n",
       "      <td>89.239762</td>\n",
       "      <td>1.624731</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.136575</td>\n",
       "      <td>NeuronType.INTERNEURONS</td>\n",
       "      <td>3</td>\n",
       "      <td>0.532462</td>\n",
       "      <td>0.317649</td>\n",
       "      <td>197.390227</td>\n",
       "      <td>40</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>537.0</td>\n",
       "      <td>954487.449962</td>\n",
       "      <td>0.016497</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>51</td>\n",
       "      <td>5</td>\n",
       "      <td>150.981227</td>\n",
       "      <td>89.244559</td>\n",
       "      <td>1.625350</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.342388</td>\n",
       "      <td>NeuronType.INTERNEURONS</td>\n",
       "      <td>4</td>\n",
       "      <td>0.532452</td>\n",
       "      <td>0.317747</td>\n",
       "      <td>197.388334</td>\n",
       "      <td>49</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>546.0</td>\n",
       "      <td>954487.450238</td>\n",
       "      <td>0.016773</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>150.981349</td>\n",
       "      <td>89.244978</td>\n",
       "      <td>1.625404</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4.342388</td>\n",
       "      <td>NeuronType.INTERNEURONS</td>\n",
       "      <td>5</td>\n",
       "      <td>0.532451</td>\n",
       "      <td>0.317755</td>\n",
       "      <td>197.388169</td>\n",
       "      <td>36</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350625</th>\n",
       "      <td>36912788.0</td>\n",
       "      <td>955621.393732</td>\n",
       "      <td>1133.960267</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>148.463986</td>\n",
       "      <td>112.483349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.528125</td>\n",
       "      <td>NeuronType.INTERNEURONS</td>\n",
       "      <td>350625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.964345</td>\n",
       "      <td>20</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.017572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350626</th>\n",
       "      <td>36912895.0</td>\n",
       "      <td>955621.397019</td>\n",
       "      <td>1133.963554</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>148.463986</td>\n",
       "      <td>112.483349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.580159</td>\n",
       "      <td>NeuronType.INTERNEURONS</td>\n",
       "      <td>350626</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.964345</td>\n",
       "      <td>6</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.025405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350627</th>\n",
       "      <td>36912899.0</td>\n",
       "      <td>955621.397142</td>\n",
       "      <td>1133.963677</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>148.463986</td>\n",
       "      <td>112.483349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.580159</td>\n",
       "      <td>NeuronType.INTERNEURONS</td>\n",
       "      <td>350627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.964345</td>\n",
       "      <td>34</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.005284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350628</th>\n",
       "      <td>36912903.0</td>\n",
       "      <td>955621.397265</td>\n",
       "      <td>1133.963800</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>148.463986</td>\n",
       "      <td>112.483349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.580159</td>\n",
       "      <td>NeuronType.INTERNEURONS</td>\n",
       "      <td>350628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.964345</td>\n",
       "      <td>20</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.003533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350629</th>\n",
       "      <td>36912972.0</td>\n",
       "      <td>955621.399384</td>\n",
       "      <td>1133.965919</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>148.463986</td>\n",
       "      <td>112.483349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.584353</td>\n",
       "      <td>NeuronType.INTERNEURONS</td>\n",
       "      <td>350629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.964345</td>\n",
       "      <td>46</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.008878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350630</th>\n",
       "      <td>36912975.0</td>\n",
       "      <td>955621.399476</td>\n",
       "      <td>1133.966011</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>148.463986</td>\n",
       "      <td>112.483349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1.584353</td>\n",
       "      <td>NeuronType.INTERNEURONS</td>\n",
       "      <td>350630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.964345</td>\n",
       "      <td>36</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.008694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350631 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 t      t_seconds  t_rel_seconds  shank  cluster  aclu  qclu           x           y     speed  traj  lap  maze_relative_lap  maze_id  is_theta  is_ripple  theta_phase_radians              neuron_type  flat_spike_idx  x_loaded  y_loaded     lin_pos  fragile_linear_neuron_IDX  PBE_id     scISI\n",
       "0            278.0  954487.442005       0.008540      8       28    36     5  150.977740   89.232496  1.623794     0   -1                 -1        1     False      False             3.768066  NeuronType.INTERNEURONS               0  0.532477  0.317501  197.393093                         34      -1       NaN\n",
       "1            301.0  954487.442712       0.009247      7        5    22     5  150.978050   89.233567  1.623932     0   -1                 -1        1     False      False             3.858485  NeuronType.INTERNEURONS               1  0.532475  0.317523  197.392671                         20      -1       NaN\n",
       "2            318.0  954487.443234       0.009769      2        2     6     5  150.978279   89.234359  1.624034     0   -1                 -1        1     False      False             3.858485  NeuronType.INTERNEURONS               2  0.532473  0.317539  197.392358                          4      -1       NaN\n",
       "3            434.0  954487.446797       0.013332     10        6    42     5  150.979841   89.239762  1.624731     0   -1                 -1        1     False      False             4.136575  NeuronType.INTERNEURONS               3  0.532462  0.317649  197.390227                         40      -1       NaN\n",
       "4            537.0  954487.449962       0.016497     12        5    51     5  150.981227   89.244559  1.625350     0   -1                 -1        1     False      False             4.342388  NeuronType.INTERNEURONS               4  0.532452  0.317747  197.388334                         49      -1       NaN\n",
       "5            546.0  954487.450238       0.016773      9        4    38     5  150.981349   89.244978  1.625404     0   -1                 -1        1     False      False             4.342388  NeuronType.INTERNEURONS               5  0.532451  0.317755  197.388169                         36      -1       NaN\n",
       "...            ...            ...            ...    ...      ...   ...   ...         ...         ...       ...   ...  ...                ...      ...       ...        ...                  ...                      ...             ...       ...       ...         ...                        ...     ...       ...\n",
       "350625  36912788.0  955621.393732    1133.960267      7        5    22     5  148.463986  112.483349  0.000000     0   -1                 -1        2     False      False             1.528125  NeuronType.INTERNEURONS          350625       NaN       NaN  195.964345                         20      -1  0.017572\n",
       "350626  36912895.0  955621.397019    1133.963554      2        4     8     5  148.463986  112.483349  0.000000     0   -1                 -1        2     False      False             1.580159  NeuronType.INTERNEURONS          350626       NaN       NaN  195.964345                          6      -1  0.025405\n",
       "350627  36912899.0  955621.397142    1133.963677      8       28    36     5  148.463986  112.483349  0.000000     0   -1                 -1        2     False      False             1.580159  NeuronType.INTERNEURONS          350627       NaN       NaN  195.964345                         34      -1  0.005284\n",
       "350628  36912903.0  955621.397265    1133.963800      7        5    22     5  148.463986  112.483349  0.000000     0   -1                 -1        2     False      False             1.580159  NeuronType.INTERNEURONS          350628       NaN       NaN  195.964345                         20      -1  0.003533\n",
       "350629  36912972.0  955621.399384    1133.965919     11        2    48     5  148.463986  112.483349  0.000000     0   -1                 -1        2     False      False             1.584353  NeuronType.INTERNEURONS          350629       NaN       NaN  195.964345                         46      -1  0.008878\n",
       "350630  36912975.0  955621.399476    1133.966011      9        4    38     5  148.463986  112.483349  0.000000     0   -1                 -1        2     False      False             1.584353  NeuronType.INTERNEURONS          350630       NaN       NaN  195.964345                         36      -1  0.008694\n",
       "\n",
       "[350631 rows x 25 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# directional_merged_decoders_result = deepcopy(directional_decoders_epochs_decode_result)\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "\n",
    "spikes_df = deepcopy(curr_active_pipeline.sess.spikes_df)\n",
    "spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "528460fb",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "global_computation_results = curr_active_pipeline.global_computation_results\n",
    "\n",
    "rank_order_results = curr_active_pipeline.global_computation_results.computed_data.get('RankOrder', None) # : \"RankOrderComputationsContainer\"\n",
    "if rank_order_results is not None:\n",
    "    minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "else:        \n",
    "    ## get from parameters:\n",
    "    minimum_inclusion_fr_Hz: float = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.included_qclu_values\n",
    "\n",
    "\n",
    "directional_laps_results: DirectionalLapsResult = global_computation_results.computed_data['DirectionalLaps']\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\n",
    "# print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "# print(f'included_qclu_values: {included_qclu_values}')\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "ripple_decoding_time_bin_size: float = directional_merged_decoders_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_merged_decoders_result.laps_decoding_time_bin_size\n",
    "# pos_bin_size = _recover_position_bin_size(track_templates.get_decoders()[0]) # 3.793023081021702\n",
    "# print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}, ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}, pos_bin_size: {pos_bin_size}')\n",
    "# pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "\n",
    "## Simple Pearson Correlation\n",
    "assert spikes_df is not None\n",
    "(laps_simple_pf_pearson_merged_df, ripple_simple_pf_pearson_merged_df), corr_column_names = directional_merged_decoders_result.compute_simple_spike_time_v_pf_peak_x_by_epoch(track_templates=track_templates, spikes_df=deepcopy(spikes_df))\n",
    "## OUTPUTS: (laps_simple_pf_pearson_merged_df, ripple_simple_pf_pearson_merged_df), corr_column_names\n",
    "## Computes the highest-valued decoder for this score:\n",
    "try:\n",
    "    best_decoder_index_col_name: str = 'best_decoder_index'\n",
    "    laps_simple_pf_pearson_merged_df[best_decoder_index_col_name] = laps_simple_pf_pearson_merged_df[corr_column_names].abs().apply(lambda row: np.argmax(row.values), axis=1)\n",
    "    ripple_simple_pf_pearson_merged_df[best_decoder_index_col_name] = ripple_simple_pf_pearson_merged_df[corr_column_names].abs().apply(lambda row: np.argmax(row.values), axis=1)\n",
    "except KeyError as e:\n",
    "    pass # KeyError: \"None of [Index(['long_LR_pf_peak_x_pearsonr', 'long_RL_pf_peak_x_pearsonr', 'short_LR_pf_peak_x_pearsonr', 'short_RL_pf_peak_x_pearsonr'], dtype='object')] are in the [columns]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed4d1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_directional_pf1D_Decoder = directional_merged_decoders_result.all_directional_pf1D_Decoder\n",
    "pf1D = all_directional_pf1D_Decoder.pf\n",
    "# all_directional_pf1D_Decoder\n",
    "pf1D\n",
    "# all_directional_pf1D_Decoder.pf.plot_occupancy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1dc2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sort from left to right by peak location, and bottom-to-top by context\n",
    "# pf1D.peak_indicies\n",
    "# pf1D.peak_tuning_curve_center_of_mass_bin_coordinates\n",
    "\n",
    "# pf1D.get_tuning_curve_peak_df\n",
    "# pf1D.tuning_curves_dict\n",
    "# pf1D.tuning_curves\n",
    "\n",
    "# pf1D\n",
    "directional_laps_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0eed3e0c",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(active_epochs_df): 133\n",
      "min_num_unique_aclu_inclusions: 8\n",
      "pos_bin_size: 4.877453969028168\n",
      "ripple_decoding_time_bin_size: 0.042\n",
      "laps_decoding_time_bin_size: 0.05\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult, SingleEpochDecodedResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)\n",
    "\n",
    "pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict\n",
    "decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict\n",
    "\n",
    "print(f'pos_bin_size: {pos_bin_size}')\n",
    "print(f'ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}')\n",
    "print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}')\n",
    "\n",
    "# Radon Transforms:\n",
    "decoder_laps_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_df_dict\n",
    "decoder_ripple_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_df_dict\n",
    "decoder_laps_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_extras_dict\n",
    "decoder_ripple_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_extras_dict\n",
    "\n",
    "# Weighted correlations:\n",
    "laps_weighted_corr_merged_df: pd.DataFrame = directional_decoders_epochs_decode_result.laps_weighted_corr_merged_df\n",
    "ripple_weighted_corr_merged_df: pd.DataFrame = directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "decoder_laps_weighted_corr_df_dict: Dict[str, pd.DataFrame] = directional_decoders_epochs_decode_result.decoder_laps_weighted_corr_df_dict\n",
    "decoder_ripple_weighted_corr_df_dict: Dict[str, pd.DataFrame] = directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict\n",
    "\n",
    "# Pearson's correlations:\n",
    "laps_simple_pf_pearson_merged_df: pd.DataFrame = directional_decoders_epochs_decode_result.laps_simple_pf_pearson_merged_df\n",
    "ripple_simple_pf_pearson_merged_df: pd.DataFrame = directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df\n",
    "\n",
    "# laps_simple_pf_pearson_merged_df\n",
    "# ripple_simple_pf_pearson_merged_df\n",
    "\n",
    "# ## Drop rows where all are missing\n",
    "# corr_column_names = ['long_LR_pf_peak_x_pearsonr', 'long_RL_pf_peak_x_pearsonr', 'short_LR_pf_peak_x_pearsonr', 'short_RL_pf_peak_x_pearsonr']\n",
    "# # ripple_simple_pf_pearson_merged_df.dropna(subset=corr_column_names, axis='index', how='all') # 350/412 rows\n",
    "# filtered_laps_simple_pf_pearson_merged_df: pd.DataFrame = laps_simple_pf_pearson_merged_df.dropna(subset=corr_column_names, axis='index', how='any') # 320/412 rows\n",
    "# filtered_ripple_simple_pf_pearson_merged_df: pd.DataFrame = ripple_simple_pf_pearson_merged_df.dropna(subset=corr_column_names, axis='index', how='any') # 320/412 rows\n",
    "\n",
    "## Update the `decoder_ripple_filter_epochs_decoder_result_dict` with the included epochs:\n",
    "# decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_ripple_filter_epochs_decoder_result_dict[a_name].filtered_by_epochs(filtered_ripple_simple_pf_pearson_merged_df.index) for a_name, a_df in decoder_ripple_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_laps_filter_epochs_decoder_result_dict[a_name].filtered_by_epochs(filtered_laps_simple_pf_pearson_merged_df.index) for a_name, a_df in decoder_laps_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_ripple_filter_epochs_decoder_result_dict[a_name].filtered_by_epoch_times(filtered_ripple_simple_pf_pearson_merged_df[['start', 'stop']].to_numpy()) for a_name, a_df in decoder_ripple_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_laps_filter_epochs_decoder_result_dict[a_name].filtered_by_epoch_times(filtered_laps_simple_pf_pearson_merged_df[['start', 'stop']].to_numpy()) for a_name, a_df in decoder_laps_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_ripple_filter_epochs_decoder_result_dict[a_name].filtered_by_epoch_times(filtered_ripple_simple_pf_pearson_merged_df['start'].to_numpy()) for a_name, a_df in decoder_ripple_filter_epochs_decoder_result_dict.items()}\n",
    "# decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:decoder_laps_filter_epochs_decoder_result_dict[a_name].filtered_by_epoch_times(filtered_laps_simple_pf_pearson_merged_df['start'].to_numpy()) for a_name, a_df in decoder_laps_filter_epochs_decoder_result_dict.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987755c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92b35196",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Context(format_name= 'kdiba', animal= 'gor01', exper_name= 'one', session_name= '2006-6-12_15-55-31')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006-6-12_15-55-31:\tt_start: 0.0, t_delta: 656.0648088779999, t_end: 1122.1864874939201\n"
     ]
    }
   ],
   "source": [
    "# I have several python variables I want to print: t_start, t_delta, t_end\n",
    "# I want to generate a print statement that explicitly lists the variable name prior to its value like `print(f't_start: {t_start}, t_delta: {t_delta}, t_end: {t_end}')`\n",
    "# Currently I have to t_start, t_delta, t_end\n",
    "curr_active_pipeline.get_session_context()\n",
    "\n",
    "print(f'{curr_active_pipeline.session_name}:\\tt_start: {t_start}, t_delta: {t_delta}, t_end: {t_end}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c49f5d4f",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "# Unpack all directional variables:\n",
    "## {\"even\": \"RL\", \"odd\": \"LR\"}\n",
    "long_LR_name, short_LR_name, global_LR_name, long_RL_name, short_RL_name, global_RL_name, long_any_name, short_any_name, global_any_name = ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "\n",
    "# Most popular\n",
    "# long_LR_name, short_LR_name, long_RL_name, short_RL_name, global_any_name\n",
    "\n",
    "# Unpacking for `(long_LR_name, long_RL_name, short_LR_name, short_RL_name)`\n",
    "(long_LR_context, long_RL_context, short_LR_context, short_RL_context) = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj, global_any_laps_epochs_obj = [curr_active_pipeline.computation_results[an_epoch_name].computation_config.pf_params.computation_epochs for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name, global_any_name)] # note has global also\n",
    "(long_LR_session, long_RL_session, short_LR_session, short_RL_session) = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)] # sessions are correct at least, seems like just the computation parameters are messed up\n",
    "(long_LR_results, long_RL_results, short_LR_results, short_RL_results) = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_computation_config, long_RL_computation_config, short_LR_computation_config, short_RL_computation_config) = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_pf1D, long_RL_pf1D, short_LR_pf1D, short_RL_pf1D) = (long_LR_results.pf1D, long_RL_results.pf1D, short_LR_results.pf1D, short_RL_results.pf1D)\n",
    "(long_LR_pf2D, long_RL_pf2D, short_LR_pf2D, short_RL_pf2D) = (long_LR_results.pf2D, long_RL_results.pf2D, short_LR_results.pf2D, short_RL_results.pf2D)\n",
    "(long_LR_pf1D_Decoder, long_RL_pf1D_Decoder, short_LR_pf1D_Decoder, short_RL_pf1D_Decoder) = (long_LR_results.pf1D_Decoder, long_RL_results.pf1D_Decoder, short_LR_results.pf1D_Decoder, short_RL_results.pf1D_Decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7104fc37",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum_inclusion_fr_Hz: 5.0\n",
      "included_qclu_values: [1, 2, 4, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult, DirectionalLapsResult, DirectionalDecodersContinuouslyDecodedResult\n",
    "\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']   \n",
    "rank_order_results: RankOrderComputationsContainer = curr_active_pipeline.global_computation_results.computed_data.get('RankOrder', None)\n",
    "if rank_order_results is not None:\n",
    "    minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "else:        \n",
    "    ## get from parameters:\n",
    "    minimum_inclusion_fr_Hz: float = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.included_qclu_values\n",
    "\n",
    "print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "print(f'included_qclu_values: {included_qclu_values}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a4a6873",
   "metadata": {
    "tags": [
     "run-group-end-run"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeuristicsResult(is_global: bool,\n",
       "\tresult_version: str,\n",
       "\t_VersionedResultMixin_version: str,\n",
       "\theuristic_scores_df_dict: dict,\n",
       "\tpartition_result_dict: dict\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring, HeuristicsResult\n",
    "\n",
    "a_heuristics_result: HeuristicsResult = curr_active_pipeline.global_computation_results.computed_data['Heuristics']\n",
    "a_heuristics_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a6eab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_merged_decoders_result.laps_time_bin_marginals_df\n",
    "directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00672033",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_laps_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bb2118",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result ## here is a single result, but not a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f90757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_build_individual_time_bin_decoded_posteriors_df\n",
    "\n",
    "## From `directional_merged_decoders_result`\n",
    "# transfer_column_names_list: List[str] = ['maze_id', 'lap_dir', 'lap_id']\n",
    "transfer_column_names_list: List[str] = []\n",
    "filtered_laps_time_bin_marginals_df = _perform_build_individual_time_bin_decoded_posteriors_df(curr_active_pipeline, track_templates=track_templates, all_directional_laps_filter_epochs_decoder_result=directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result, transfer_column_names_list=transfer_column_names_list)\n",
    "filtered_laps_time_bin_marginals_df['lap_id'] = filtered_laps_time_bin_marginals_df['parent_epoch_label'].astype(int) + 1\n",
    "filtered_laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4c2073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result\n",
    "\n",
    "# directional_merged_decoders_result.all_directional_decoder_dict\n",
    "directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df77e66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import PhoPaginatedMultiDecoderDecodedEpochsWindow, DecodedEpochSlicesPaginatedFigureController, EpochSelectionsObject, ClickActionCallbacks\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.ThinButtonBar.ThinButtonBarWidget import ThinButtonBarWidget\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.PaginationCtrl.PaginationControlWidget import PaginationControlWidget, PaginationControlWidgetState\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from pyphoplacecellanalysis.Resources import GuiResources, ActionIcons, silx_resources_rc\n",
    "## INPUTS filtered_decoder_filter_epochs_decoder_result_dict\n",
    "# decoder_decoded_epochs_result_dict: generic\n",
    "\n",
    "app, paginated_multi_decoder_decoded_epochs_window, pagination_controller_dict = PhoPaginatedMultiDecoderDecodedEpochsWindow.init_from_track_templates(curr_active_pipeline, track_templates,\n",
    "                                                                                                # decoder_decoded_epochs_result_dict=decoder_ripple_filter_epochs_decoder_result_dict, epochs_name='ripple',\n",
    "                                                                                                decoder_decoded_epochs_result_dict=filtered_decoder_filter_epochs_decoder_result_dict, epochs_name='ripple',\n",
    "                                                                                                # decoder_decoded_epochs_result_dict=filtered_ripple_simple_pf_pearson_merged_df, epochs_name='ripple',\n",
    "                                                                                                # decoder_decoded_epochs_result_dict=long_like_during_post_delta_only_filtered_decoder_filter_epochs_decoder_result_dict, epochs_name='ripple', title='Long-like post-Delta Ripples Only', ## RIPPLE\n",
    "                                                                                                # decoder_decoded_epochs_result_dict=decoder_laps_filter_epochs_decoder_result_dict, epochs_name='laps', ## LAPS\n",
    "                                                                                                included_epoch_indicies=None, debug_print=False,\n",
    "                                                                                                params_kwargs={'enable_per_epoch_action_buttons': False,\n",
    "                                                                                                    'skip_plotting_most_likely_positions': True, 'skip_plotting_measured_positions': True, \n",
    "                                                                                                    'enable_decoded_most_likely_position_curve': False, 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': True,\n",
    "                                                                                                    # 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': False,\n",
    "                                                                                                    # 'disable_y_label': True,\n",
    "                                                                                                    'isPaginatorControlWidgetBackedMode': True,\n",
    "                                                                                                    'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True,\n",
    "                                                                                                    # 'debug_print': True,\n",
    "                                                                                                    'max_subplots_per_page': 10,\n",
    "                                                                                                    'scrollable_figure': False,\n",
    "                                                                                                    # 'scrollable_figure': True,\n",
    "                                                                                                    # 'posterior_heatmap_imshow_kwargs': dict(vmin=0.0075),\n",
    "                                                                                                    'use_AnchoredCustomText': False,\n",
    "                                                                                                    'should_suppress_callback_exceptions': False,\n",
    "                                                                                                    # 'build_fn': 'insets_view',\n",
    "                                                                                                })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ce9677",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### attached raster viewer widget:\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.RankOrderRastersDebugger import RankOrderRastersDebugger\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import get_proper_global_spikes_df\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "\n",
    "## INPUTS: active_spikes_df\n",
    "# active_spikes_df = get_proper_global_spikes_df(curr_active_pipeline, minimum_inclusion_fr_Hz=5)\n",
    "\n",
    "active_spikes_df = get_proper_global_spikes_df(curr_active_pipeline)\n",
    "\n",
    "# PosteriorExporting._perform_export_current_epoch_marginal_and_raster_images\n",
    "\n",
    "\n",
    "\n",
    "# _out_ripple_rasters, update_attached_raster_viewer_epoch_callback = paginated_multi_decoder_decoded_epochs_window.build_attached_raster_viewer_widget(track_templates=track_templates, active_spikes_df=active_spikes_df, filtered_epochs_df=filtered_epochs_df) ## BEST\n",
    "# _out_ripple_rasters, update_attached_raster_viewer_epoch_callback = paginated_multi_decoder_decoded_epochs_window.build_attached_raster_viewer_widget(track_templates=track_templates, active_spikes_df=active_spikes_df, filtered_epochs_df=filtered_ripple_simple_pf_pearson_merged_df) # original\n",
    "_out_ripple_rasters, update_attached_raster_viewer_epoch_callback = paginated_multi_decoder_decoded_epochs_window.build_attached_raster_viewer_widget(track_templates=track_templates, active_spikes_df=active_spikes_df, filtered_epochs_df=extracted_merged_scores_df)\n",
    "# _out_ripple_rasters, update_attached_raster_viewer_epoch_callback = paginated_multi_decoder_decoded_epochs_window.build_attached_raster_viewer_widget(track_templates=track_templates, active_spikes_df=active_spikes_df, filtered_epochs_df=long_like_during_post_delta_only_filter_epochs_df) # Long-like-during-post-delta\n",
    "\n",
    "\n",
    "# all_directional_laps_filter_epochs_decoder_result_value\n",
    "# laps_filter_epochs = ensure_dataframe(deepcopy(decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)) \n",
    "# _out_ripple_rasters, update_attached_raster_viewer_epoch_callback = paginated_multi_decoder_decoded_epochs_window.build_attached_raster_viewer_widget(track_templates=track_templates, active_spikes_df=laps_spikes_df, filtered_epochs_df=filtered_laps_simple_pf_pearson_merged_df) ## LAPS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d2fead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66d41af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out_ripple_rasters: RankOrderRastersDebugger\n",
    "### Add yellow-blue marginals to `paginated_multi_decoder_decoded_epochs_window`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_decoded_epoch_slices\n",
    "from pyphocorehelpers.gui.Qt.widget_positioning_helpers import WidgetPositioningHelpers, DesiredWidgetLocation, WidgetGeometryInfo\n",
    "\n",
    "yellow_blue_trackID_marginals_plot_tuple = paginated_multi_decoder_decoded_epochs_window.build_attached_yellow_blue_track_identity_marginal_window(directional_merged_decoders_result, global_session, ripple_decoding_time_bin_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fee2d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean and max number of active aclus per time bin for each epoch (lap)\n",
    "filtered_laps_time_bin_marginals_df.groupby(['lap_id']).agg(n_unique_aclus_mean=('n_unique_aclus', 'mean'), n_unique_aclus_max=('n_unique_aclus', 'max')).reset_index()\n",
    "filtered_laps_time_bin_marginals_df.groupby(['maze_id']).agg(n_unique_aclus_mean=('n_unique_aclus', 'mean'), n_unique_aclus_max=('n_unique_aclus', 'max')).reset_index() ## per maze\n",
    "filtered_laps_time_bin_marginals_df.groupby(['maze_id', 'lap_dir']).agg(n_unique_aclus_mean=('n_unique_aclus', 'mean'), n_unique_aclus_max=('n_unique_aclus', 'max')).reset_index() # per maze x lap_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93346114",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "DEPRICATION WARNING: workaround to allow subscripting ComputationResult objects. Will be depricated. key: computed_data\n",
      "were pipeline preprocessing parameters missing and updated?: False\n",
      "\t !!!||||||||||||||||||> RUNNING `PostHocPipelineFixup.FINAL_UPDATE_ALL(...)`:\n",
      "starting `PostHocPipelineFixup.FINAL_UPDATE_ALL(...)`...\n",
      "\t !!!||||||||||||||||||> RUNNING `PostHocPipelineFixup.FINAL_FIX_GRID_BIN_BOUNDS(...)`:\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-12_15-55-31/2006-6-12_15-55-31.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-12_15-55-31/2006-6-12_15-55-31.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-12_15-55-31/2006-6-12_15-55-31.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-12_15-55-31/2006-6-12_15-55-31.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-12_15-55-31/2006-6-12_15-55-31.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-12_15-55-31/2006-6-12_15-55-31.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-12_15-55-31/2006-6-12_15-55-31.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-12_15-55-31/2006-6-12_15-55-31.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-12_15-55-31/2006-6-12_15-55-31.position_info.mat\"... done.\n",
      "Loading matlab import file results : \"W:/Data/KDIBA/gor01/one/2006-6-12_15-55-31/2006-6-12_15-55-31.position_info.mat\"... done.\n",
      "No grid bin bounds were changed. Everything should be up-to-date!\n",
      "\t =================> RUNNING `PostHocPipelineFixup.FINAL_UPDATE_FILEPATHS(...)`:\n",
      "\t =================> RUNNING `PostHocPipelineFixup.FINAL_UPDATE_NON_PBE_EPOCHS(...)`:\n",
      "computing non_PBE epochs for session...\n",
      "\n",
      "Saving non_pbe results results : \"W:/Data/KDIBA/gor01/one/2006-6-12_15-55-31/2006-6-12_15-55-31.non_pbe.npy\"... 2006-6-12_15-55-31.non_pbe.npy saved\n",
      "done.\n",
      "computing non_PBE_EndcapsOnly epochs for session...\n",
      "\n",
      "Saving non_pbe_endcaps results results : \"W:/Data/KDIBA/gor01/one/2006-6-12_15-55-31/2006-6-12_15-55-31.non_pbe_endcaps.npy\"... 2006-6-12_15-55-31.non_pbe_endcaps.npy saved\n",
      "done.\n",
      "\tDirectionalLapsResult.init_from_pipeline_natural_epochs(...): was_modified: False\n",
      "\tPostHocPipelineFixup.FINAL_UPDATE_ALL(...): did_any_change: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.BatchCompletionHandler import BatchSessionCompletionHandler\n",
    "\n",
    "BatchSessionCompletionHandler.post_compute_validate(curr_active_pipeline=curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0617e7a3",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['maze1_odd', 'maze1_even', 'maze2_odd', 'maze2_even']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(directional_laps_results.directional_lap_specific_configs.keys()) # ['maze1_odd', 'maze1_even', 'maze2_odd', 'maze2_even']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "912656a7",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(active_epochs_df): 133\n",
      "min_num_unique_aclu_inclusions: 8\n",
      "pos_bin_size = 4.877453969028168, ripple_decoding_time_bin_size = 0.042, laps_decoding_time_bin_size = 0.05\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "from neuropy.utils.indexing_helpers import NumpyHelpers\n",
    "\n",
    "if ('DirectionalDecodersEpochsEvaluations' in curr_active_pipeline.global_computation_results.computed_data) and (curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations'] is not None):\n",
    "    directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "    directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)\n",
    "\n",
    "    ## UNPACK HERE via direct property access:\n",
    "    pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "    ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "    laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "    print(f'{pos_bin_size = }, {ripple_decoding_time_bin_size = }, {laps_decoding_time_bin_size = }') # pos_bin_size = 3.8054171165052444, ripple_decoding_time_bin_size = 0.025, laps_decoding_time_bin_size = 0.2\n",
    "    decoder_laps_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict\n",
    "    decoder_ripple_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict\n",
    "    decoder_laps_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_df_dict\n",
    "    decoder_ripple_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_df_dict\n",
    "\n",
    "    # New items:\n",
    "    decoder_laps_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_extras_dict\n",
    "    decoder_ripple_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_extras_dict\n",
    "\n",
    "    # Weighted correlations:\n",
    "    laps_weighted_corr_merged_df = directional_decoders_epochs_decode_result.laps_weighted_corr_merged_df\n",
    "    ripple_weighted_corr_merged_df = directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "    decoder_laps_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_laps_weighted_corr_df_dict\n",
    "    decoder_ripple_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict\n",
    "\n",
    "    # Pearson's correlations:\n",
    "    laps_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.laps_simple_pf_pearson_merged_df\n",
    "    ripple_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df\n",
    "    \n",
    "    # for k, v in directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict.items():\n",
    "    #     print(f'{k}: v.decoding_time_bin_size: {v.decoding_time_bin_size}')\n",
    "    \n",
    "    individual_result_ripple_time_bin_sizes = [v.decoding_time_bin_size for k, v in directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict.items()]\n",
    "    if not np.allclose(ripple_decoding_time_bin_size, individual_result_ripple_time_bin_sizes):\n",
    "        individual_result_ripple_time_bin_size = individual_result_ripple_time_bin_sizes[0] # get the first\n",
    "        assert np.allclose(individual_result_ripple_time_bin_size, individual_result_ripple_time_bin_sizes), f\"`individual_result_ripple_time_bin_size ({individual_result_ripple_time_bin_size}) does not equal the individual result time bin sizes: {individual_result_ripple_time_bin_sizes}`. This can occur when there are epochs smaller than the desired size ({ripple_decoding_time_bin_size}) for the result and epochs_filtering_mode=EpochFilteringMode.ConstrainDecodingTimeBinSizeToMinimum\"\n",
    "        print(f'WARN: overriding directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size (original value: {directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size}) with individual_result_ripple_time_bin_size: {individual_result_ripple_time_bin_size}')\n",
    "        directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size = individual_result_ripple_time_bin_size # override the time_bin_size with the actually used one\n",
    "        ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "        print(f'{pos_bin_size = }, {ripple_decoding_time_bin_size = }, {laps_decoding_time_bin_size = }') # pos_bin_size = 3.8054171165052444, ripple_decoding_time_bin_size = 0.025, laps_decoding_time_bin_size = 0.2\n",
    "    else:\n",
    "        # all are close, it's good\n",
    "        pass\n",
    "\n",
    "    # assert np.allclose(ripple_decoding_time_bin_size, individual_result_ripple_time_bin_sizes), f\"`directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size ({ripple_decoding_time_bin_size}) does not equal the individual result time bin sizes: {individual_result_ripple_time_bin_sizes}`. This can occur when there are epochs smaller than the desired size ({ripple_decoding_time_bin_size}) for the result and epochs_filtering_mode=EpochFilteringMode.ConstrainDecodingTimeBinSizeToMinimum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06f1c291",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    start_position_index  end_position_index  lap_dir  start_t_rel_seconds  end_t_rel_seconds        start         stop  lap_id label  duration  start_spike_index  end_spike_index  num_spikes     wcorr  P_decoder  pearsonr  mseq_len  mseq_len_ignoring_intrusions  mseq_len_ignoring_intrusions_and_repeats  mseq_len_ratio_ignoring_intrusions_and_repeats  mseq_tcov  mseq_dtrav  avg_jump_cm    travel  coverage  total_distance_traveled  track_coverage_score  longest_sequence_length  longest_sequence_length_ratio  direction_change_bin_ratio  congruent_dir_bins_ratio  total_congruent_direction_change  total_variation  integral_second_derivative  stddev_of_diff\n",
       "0                   1097                1275        1            36.307721          42.245845    36.307721    42.245845       1     1  5.938124              10539            13270        2731 -0.614169        NaN       NaN         6                             6                                         2                                        0.054054   0.084746   43.897086    59.554123  0.280649  0.305085                 0.915254              0.915254                        6                       0.111111                    0.542373                  0.483051                       3648.335569      7086.940617                3.360513e+06       93.874835\n",
       "1                   1898                1942        0            63.035515          64.503950    63.035515    64.503950       2     2  1.468435              19799            20451         652  0.122183        NaN -0.732962         4                             4                                         3                                        0.272727   0.237288   73.161810    65.683047  0.317514  0.457627                 0.898305              0.898305                        4                       0.307692                    0.551724                  0.448276                       1082.794781      1970.491403                5.542015e+05       88.745944\n",
       "2                   2167                2281        1            72.009997          75.816214    72.009997    75.816214       3     3  3.806217              23513            25261        1748 -0.542060        NaN  0.297872        13                            13                                         3                                        0.187500   0.135593  107.303987    46.937577  0.222220  0.508475                 0.915254              0.915254                       13                       0.276596                    0.394737                  0.421053                       1833.922692      3614.193391                1.696029e+06       85.744037\n",
       "3                   2705                2885        0            89.962477          95.968505    89.962477    95.968505       4     4  6.006028              29415            32021        2606  0.397755        NaN -0.762219        10                            10                                         2                                        0.054054   0.135593   48.774540    57.965114  0.273122  0.338983                 0.813559              0.813559                       10                       0.140845                    0.441667                  0.400000                       3506.889404      7013.778807                2.727758e+06       87.255093\n",
       "4                   3487                3598        1           116.054576         119.758834   116.054576   119.758834       5     5  3.704258              38595            40181        1586 -0.581298   0.622022  0.714060         9                             8                                         5                                        0.172414   0.186441  136.568711    49.945129  0.236542  0.355932                 0.915254              0.915254                        8                       0.170213                    0.405405                  0.418919                       1887.574686      3745.884648                9.416620e+05       79.317193\n",
       "5                   4351                4457        0           144.884115         148.420034   144.884115   148.420034       6     6  3.535919              46168            47732        1564  0.366222        NaN -0.754093        17                            17                                         1                                        0.111111   0.050847   68.284356    58.529448  0.277409  0.322034                 0.762712              0.762712                       17                       0.586207                    0.528571                  0.442857                       2116.815023      4155.590782                1.530715e+06       79.758662\n",
       "..                   ...                 ...      ...                  ...                ...          ...          ...     ...   ...       ...                ...              ...         ...       ...        ...       ...       ...                           ...                                       ...                                             ...        ...         ...          ...       ...       ...                      ...                   ...                      ...                            ...                         ...                       ...                               ...              ...                         ...             ...\n",
       "68                 31060               31194        1          1036.082438        1040.552516  1036.082438  1040.552516      69    69  4.470078             316733           318509        1776 -0.373464        NaN  0.530539         4                             4                                         3                                        0.166667   0.101695   58.529448    63.406902  0.299623  0.440678                 0.915254              0.915254                        4                       0.125000                    0.573034                  0.471910                       2906.962566      5706.621144                2.231841e+06       94.042463\n",
       "69                 31482               31624        0          1050.162130        1054.902187  1050.162130  1054.902187      70    70  4.740057             320915           322792        1877  0.396403        NaN -0.680590        12                            11                                         1                                        0.032258   0.118644   68.284356    45.231968  0.213613  0.440678                 0.898305              0.898305                       11                       0.180328                    0.404255                  0.393617                       2268.016096      4297.036947                1.411292e+06       71.488238\n",
       "70                 31996               32110        1          1067.313526        1071.118508  1067.313526  1071.118508      71    71  3.804982             327030           328324        1294 -0.308008        NaN  0.716296         4                             4                                         2                                        0.142857   0.050847   14.632362    98.182515  0.464834  0.457627                 0.915254              0.915254                        4                       0.210526                    0.618421                  0.460526                       3780.026826      7560.053652                3.685930e+06      127.657639\n",
       "71                 32169               32335        0          1073.085383        1078.623888  1073.085383  1078.623888      72    72  5.538505             328762           330703        1941  0.390896        NaN -0.752823        11                            10                                         1                                        0.038462   0.135593   78.039264    63.011432  0.297123  0.542373                 0.915254              0.915254                       10                       0.181818                    0.509091                  0.409091                       3497.134496      6994.268992                2.888362e+06       94.325471\n",
       "72                 32583               32766        1          1086.898689        1093.004903  1086.898689  1093.004903      73    73  6.106214             333679           335728        2049 -0.369657        NaN  0.793035         8                             8                                         3                                        0.081081   0.169492   97.549079    68.641242  0.323383  0.406780                 0.915254              0.915254                        8                       0.123077                    0.467213                  0.459016                       4336.056578      8442.872820                4.012513e+06      104.660883\n",
       "73                 32922               33063        0          1098.211036        1102.915145  1098.211036  1102.915145      74    74  4.704109             336967           338893        1926  0.226520        NaN -0.653314         4                             4                                         2                                        0.074074   0.203390   63.406902    44.667210  0.210946  0.457627                 0.915254              0.915254                        4                       0.083333                    0.531915                  0.404255                       2253.383734      4243.384953                1.055305e+06       62.350321\n",
       "\n",
       "[74 rows x 35 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dce38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directional_decoders_epochs_decode_result # DecoderDecodedEpochsResult\n",
    "# laps_weighted_corr_merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "881402df",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'maze_any'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# active_config_name: str = 'maze_any'\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "active_config_name: str = global_epoch_name # 'maze_any'\n",
    "active_config_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b80230",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "## INPUTS: curr_active_pipeline, active_config_name\n",
    "active_peak_prominence_2d_results = curr_active_pipeline.computation_results[active_config_name].computed_data.get('RatemapPeaksAnalysis', {}).get('PeakProminence2D', None)\n",
    "if active_peak_prominence_2d_results is None:\n",
    "    curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['ratemap_peaks_prominence2d'], enabled_filter_names=None, fail_on_exception=False, debug_print=False)\n",
    "    # curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['ratemap_peaks_prominence2d'], enabled_filter_names=[short_LR_name, short_RL_name, long_any_name, short_any_name], fail_on_exception=False, debug_print=False) # or at least\n",
    "    active_peak_prominence_2d_results = curr_active_pipeline.computation_results[active_config_name].computed_data.get('RatemapPeaksAnalysis', {}).get('PeakProminence2D', None)\n",
    "    assert active_peak_prominence_2d_results is not None, f\"bad even after computation\"\n",
    "\n",
    "# active_peak_prominence_2d_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7706d485",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(active_peak_prominence_2d_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "238f67cb",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all",
     "run-continuous-decoding",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "previously_decoded time_bin_sizes: [0.025, 0.05]\n",
      "time_bin_size: 0.05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'long_LR': DecodedFilterEpochsResult(decoding_time_bin_size: float,\n",
       " \tfilter_epochs: neuropy.core.epoch.Epoch,\n",
       " \tnum_filter_epochs: int,\n",
       " \tmost_likely_positions_list: list | shape (n_epochs),\n",
       " \tp_x_given_n_list: list | shape (n_epochs),\n",
       " \tmarginal_x_list: list | shape (n_epochs),\n",
       " \tmarginal_y_list: list | shape (n_epochs),\n",
       " \tmost_likely_position_indicies_list: list | shape (n_epochs),\n",
       " \tspkcount: list | shape (n_epochs),\n",
       " \tnbins: numpy.ndarray | shape (n_epochs),\n",
       " \ttime_bin_containers: list | shape (n_epochs),\n",
       " \ttime_bin_edges: list | shape (n_epochs),\n",
       " \tepoch_description_list: list | shape (n_epochs),\n",
       " \tpos_bin_edges: numpy.ndarray | shape (n_pos_bins+1)\n",
       " ),\n",
       " 'long_RL': DecodedFilterEpochsResult(decoding_time_bin_size: float,\n",
       " \tfilter_epochs: neuropy.core.epoch.Epoch,\n",
       " \tnum_filter_epochs: int,\n",
       " \tmost_likely_positions_list: list | shape (n_epochs),\n",
       " \tp_x_given_n_list: list | shape (n_epochs),\n",
       " \tmarginal_x_list: list | shape (n_epochs),\n",
       " \tmarginal_y_list: list | shape (n_epochs),\n",
       " \tmost_likely_position_indicies_list: list | shape (n_epochs),\n",
       " \tspkcount: list | shape (n_epochs),\n",
       " \tnbins: numpy.ndarray | shape (n_epochs),\n",
       " \ttime_bin_containers: list | shape (n_epochs),\n",
       " \ttime_bin_edges: list | shape (n_epochs),\n",
       " \tepoch_description_list: list | shape (n_epochs),\n",
       " \tpos_bin_edges: numpy.ndarray | shape (n_pos_bins+1)\n",
       " ),\n",
       " 'short_LR': DecodedFilterEpochsResult(decoding_time_bin_size: float,\n",
       " \tfilter_epochs: neuropy.core.epoch.Epoch,\n",
       " \tnum_filter_epochs: int,\n",
       " \tmost_likely_positions_list: list | shape (n_epochs),\n",
       " \tp_x_given_n_list: list | shape (n_epochs),\n",
       " \tmarginal_x_list: list | shape (n_epochs),\n",
       " \tmarginal_y_list: list | shape (n_epochs),\n",
       " \tmost_likely_position_indicies_list: list | shape (n_epochs),\n",
       " \tspkcount: list | shape (n_epochs),\n",
       " \tnbins: numpy.ndarray | shape (n_epochs),\n",
       " \ttime_bin_containers: list | shape (n_epochs),\n",
       " \ttime_bin_edges: list | shape (n_epochs),\n",
       " \tepoch_description_list: list | shape (n_epochs),\n",
       " \tpos_bin_edges: numpy.ndarray | shape (n_pos_bins+1)\n",
       " ),\n",
       " 'short_RL': DecodedFilterEpochsResult(decoding_time_bin_size: float,\n",
       " \tfilter_epochs: neuropy.core.epoch.Epoch,\n",
       " \tnum_filter_epochs: int,\n",
       " \tmost_likely_positions_list: list | shape (n_epochs),\n",
       " \tp_x_given_n_list: list | shape (n_epochs),\n",
       " \tmarginal_x_list: list | shape (n_epochs),\n",
       " \tmarginal_y_list: list | shape (n_epochs),\n",
       " \tmost_likely_position_indicies_list: list | shape (n_epochs),\n",
       " \tspkcount: list | shape (n_epochs),\n",
       " \tnbins: numpy.ndarray | shape (n_epochs),\n",
       " \ttime_bin_containers: list | shape (n_epochs),\n",
       " \ttime_bin_edges: list | shape (n_epochs),\n",
       " \tepoch_description_list: list | shape (n_epochs),\n",
       " \tpos_bin_edges: numpy.ndarray | shape (n_pos_bins+1)\n",
       " ),\n",
       " 'pseudo2D': DecodedFilterEpochsResult(decoding_time_bin_size: float,\n",
       " \tfilter_epochs: neuropy.core.epoch.Epoch,\n",
       " \tnum_filter_epochs: int,\n",
       " \tmost_likely_positions_list: list | shape (n_epochs),\n",
       " \tp_x_given_n_list: list | shape (n_epochs),\n",
       " \tmarginal_x_list: list | shape (n_epochs),\n",
       " \tmarginal_y_list: list | shape (n_epochs),\n",
       " \tmost_likely_position_indicies_list: list | shape (n_epochs),\n",
       " \tspkcount: list | shape (n_epochs),\n",
       " \tnbins: numpy.ndarray | shape (n_epochs),\n",
       " \ttime_bin_containers: list | shape (n_epochs),\n",
       " \ttime_bin_edges: list | shape (n_epochs),\n",
       " \tepoch_description_list: list | shape (n_epochs),\n",
       " \tpos_bin_edges: numpy.ndarray | shape (n_pos_bins+1)\n",
       " )}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'long_LR': array([[1.12864e-05, 0.0122032, 1.12864e-05, ..., 2.16839e-06, 3.39987e-09, 1.38309e-12],\n",
       "        [5.09012e-05, 0.011878, 5.09012e-05, ..., 2.64237e-05, 4.92466e-08, 1.00129e-10],\n",
       "        [0.000192038, 0.0108585, 0.000192038, ..., 0.000259099, 5.54565e-07, 5.11459e-09],\n",
       "        ...,\n",
       "        [6.13313e-06, 0.0118433, 6.13313e-06, ..., 9.6698e-05, 5.65617e-09, 0],\n",
       "        [7.92632e-07, 0.0121884, 7.92632e-07, ..., 6.59427e-06, 1.27358e-10, 0],\n",
       "        [0, 0.0122907, 0, ..., 3.60075e-07, 0, 0]]),\n",
       " 'long_RL': array([[2.49294e-05, 0.0121457, 2.49294e-05, ..., 5.26774e-08, 0, 0],\n",
       "        [0.0001384, 0.0118379, 0.0001384, ..., 8.59939e-07, 0, 0],\n",
       "        [0.000613178, 0.0110681, 0.000613178, ..., 1.14085e-05, 0, 0],\n",
       "        ...,\n",
       "        [9.48593e-05, 0.0119155, 9.48593e-05, ..., 3.47742e-05, 0, 0],\n",
       "        [1.70537e-05, 0.01223, 1.70537e-05, ..., 2.00381e-06, 0, 0],\n",
       "        [1.99143e-06, 0.0123073, 1.99143e-06, ..., 8.78256e-08, 0, 0]]),\n",
       " 'short_LR': array([[0, 0.0123274, 0, ..., 0, 0, 0],\n",
       "        [0, 0.0123274, 0, ..., 0, 0, 0],\n",
       "        [0, 0.0123274, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0.0123274, 0, ..., 0, 0, 0],\n",
       "        [0, 0.0123274, 0, ..., 0, 0, 0],\n",
       "        [0, 0.0123274, 0, ..., 0, 0, 0]]),\n",
       " 'short_RL': array([[0, 0.0123274, 0, ..., 0, 0, 0],\n",
       "        [0, 0.0123274, 0, ..., 0, 0, 0],\n",
       "        [0, 0.0123274, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0.0123274, 0, ..., 0, 0, 0],\n",
       "        [0, 0.0123274, 0, ..., 0, 0, 0],\n",
       "        [0, 0.0123274, 0, ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalDecodersContinuouslyDecodedResult\n",
    "\n",
    "if 'DirectionalDecodersDecoded' in curr_active_pipeline.global_computation_results.computed_data:\n",
    "    directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "    all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "    pseudo2D_decoder: BasePositionDecoder = directional_decoders_decode_result.pseudo2D_decoder\n",
    "    spikes_df = directional_decoders_decode_result.spikes_df\n",
    "    continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "    previously_decoded_keys: List[float] = list(continuously_decoded_result_cache_dict.keys()) # [0.03333]\n",
    "    print(F'previously_decoded time_bin_sizes: {previously_decoded_keys}')\n",
    "    \n",
    "    time_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\n",
    "    print(f'time_bin_size: {time_bin_size}')\n",
    "    continuously_decoded_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_decode_result.most_recent_continuously_decoded_dict\n",
    "    all_directional_continuously_decoded_dict = continuously_decoded_dict or {} ## what is plotted in the `f'{a_decoder_name}_ContinuousDecode'` rows by `AddNewDirectionalDecodedEpochs_MatplotlibPlotCommand`\n",
    "    all_directional_continuously_decoded_dict\n",
    "\n",
    "    pseudo2D_decoder_continuously_decoded_result: DecodedFilterEpochsResult = continuously_decoded_dict.get('pseudo2D', None)\n",
    "    assert len(pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list) == 1\n",
    "    p_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0]\n",
    "    # p_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0]['p_x_given_n']\n",
    "    time_bin_containers = pseudo2D_decoder_continuously_decoded_result.time_bin_containers[0]\n",
    "    time_window_centers = time_bin_containers.centers\n",
    "    # p_x_given_n.shape # (62, 4, 209389)\n",
    "\n",
    "    ## Split across the 2nd axis to make 1D posteriors that can be displayed in separate dock rows:\n",
    "    assert p_x_given_n.shape[1] == 4, f\"expected the 4 pseudo-y bins for the decoder in p_x_given_n.shape[1]. but found p_x_given_n.shape: {p_x_given_n.shape}\"\n",
    "    split_pseudo2D_posteriors_dict = {k:np.squeeze(p_x_given_n[:, i, :]) for i, k in enumerate(('long_LR', 'long_RL', 'short_LR', 'short_RL'))}\n",
    "    split_pseudo2D_posteriors_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d92b4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_decoders_decode_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e1ee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_directional_pf1D_Decoder_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7b4e959",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceBased is not computed.\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.SequenceBasedComputations import WCorrShuffle, SequenceBasedComputationsContainer\n",
    "\n",
    "wcorr_shuffle_results: SequenceBasedComputationsContainer = curr_active_pipeline.global_computation_results.computed_data.get('SequenceBased', None)\n",
    "if wcorr_shuffle_results is not None:    \n",
    "    wcorr_ripple_shuffle: WCorrShuffle = wcorr_shuffle_results.wcorr_ripple_shuffle\n",
    "    if wcorr_ripple_shuffle is not None:\n",
    "        print(f'wcorr_ripple_shuffle.n_completed_shuffles: {wcorr_ripple_shuffle.n_completed_shuffles}')\n",
    "    else:\n",
    "        print(f'SequenceBased is computed but `wcorr_shuffle_results.wcorr_ripple_shuffle` is None.')        \n",
    "else:\n",
    "    print(f'SequenceBased is not computed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e9cc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['trial_by_trial_metrics'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "directional_trial_by_trial_activity_result = curr_active_pipeline.global_computation_results.computed_data.get('TrialByTrialActivity', None) ## try again to get the result\n",
    "assert directional_trial_by_trial_activity_result is not None, f\"directional_trial_by_trial_activity_result is None even after forcing recomputation!!\"\n",
    "print(f'\\t done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10d7394a",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.reliability import TrialByTrialActivity\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrialByTrialActivityResult\n",
    "\n",
    "directional_trial_by_trial_activity_result: TrialByTrialActivityResult = curr_active_pipeline.global_computation_results.computed_data.get('TrialByTrialActivity', None)\n",
    "if directional_trial_by_trial_activity_result is None:\n",
    "    # if `KeyError: 'TrialByTrialActivity'` recompute\n",
    "    print(f'TrialByTrialActivity is not computed, computing it...')\n",
    "    curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['trial_by_trial_metrics'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "    directional_trial_by_trial_activity_result = curr_active_pipeline.global_computation_results.computed_data.get('TrialByTrialActivity', None) ## try again to get the result\n",
    "    assert directional_trial_by_trial_activity_result is not None, f\"directional_trial_by_trial_activity_result is None even after forcing recomputation!!\"\n",
    "    print(f'\\t done.')\n",
    "\n",
    "## unpack either way:\n",
    "any_decoder_neuron_IDs = directional_trial_by_trial_activity_result.any_decoder_neuron_IDs\n",
    "active_pf_dt: PfND_TimeDependent = directional_trial_by_trial_activity_result.active_pf_dt\n",
    "directional_lap_epochs_dict: Dict[str, Epoch] = directional_trial_by_trial_activity_result.directional_lap_epochs_dict\n",
    "directional_active_lap_pf_results_dicts: Dict[str, TrialByTrialActivity] = directional_trial_by_trial_activity_result.directional_active_lap_pf_results_dicts\n",
    "stability_dict = {k:list(v.aclu_to_stability_score_dict.values()) for k,v in directional_active_lap_pf_results_dicts.items()}\n",
    "stability_df: pd.DataFrame = pd.DataFrame({'aclu': any_decoder_neuron_IDs, **stability_dict})\n",
    "## OUTPUTS: stability_df, stability_dict\n",
    "\n",
    "## OUTPUTS: directional_trial_by_trial_activity_result, directional_active_lap_pf_results_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94fad74c",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceBased is not computed.\n"
     ]
    }
   ],
   "source": [
    "wcorr_shuffle_results: SequenceBasedComputationsContainer = curr_active_pipeline.global_computation_results.computed_data.get('SequenceBased', None)\n",
    "if wcorr_shuffle_results is not None:    \n",
    "    wcorr_ripple_shuffle: WCorrShuffle = wcorr_shuffle_results.wcorr_ripple_shuffle\n",
    "    if wcorr_ripple_shuffle is not None:  \n",
    "        print(f'wcorr_ripple_shuffle.n_completed_shuffles: {wcorr_ripple_shuffle.n_completed_shuffles}')\n",
    "    else:\n",
    "        print(f'SequenceBased is computed but wcorr_ripple_shuffle is None.')\n",
    "else:\n",
    "    print(f'SequenceBased is not computed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3ed0870",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "run-continuous-decoding",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_bin_size: 0.05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SingleEpochDecodedResult(p_x_given_n: numpy.ndarray,\n",
       "\tepoch_info_tuple: pandas.core.frame.EpochTuple,\n",
       "\tmost_likely_positions: numpy.ndarray,\n",
       "\tmost_likely_position_indicies: numpy.ndarray,\n",
       "\tnbins: numpy.int32,\n",
       "\ttime_bin_container: neuropy.utils.mixins.binning_helpers.BinningContainer,\n",
       "\ttime_bin_edges: numpy.ndarray,\n",
       "\tmarginal_x: neuropy.utils.dynamic_container.DynamicContainer,\n",
       "\tmarginal_y: neuropy.utils.dynamic_container.DynamicContainer,\n",
       "\tepoch_data_index: int\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult, SingleEpochDecodedResult\n",
    "\n",
    "most_recent_time_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\n",
    "# most_recent_time_bin_size\n",
    "most_recent_continuously_decoded_dict = deepcopy(directional_decoders_decode_result.most_recent_continuously_decoded_dict)\n",
    "# most_recent_continuously_decoded_dict\n",
    "\n",
    "## Adds in the 'pseudo2D' decoder in:\n",
    "time_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\n",
    "# time_bin_size: float = 0.01\n",
    "print(f'time_bin_size: {time_bin_size}')\n",
    "continuously_decoded_dict = continuously_decoded_result_cache_dict[time_bin_size]\n",
    "pseudo2D_decoder_continuously_decoded_result = continuously_decoded_dict.get('pseudo2D', None)\n",
    "if pseudo2D_decoder_continuously_decoded_result is None:\n",
    "    # compute here...\n",
    "    ## Currently used for both cases to decode:\n",
    "    t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "    single_global_epoch_df: pd.DataFrame = pd.DataFrame({'start': [t_start], 'stop': [t_end], 'label': [0]}) # Build an Epoch object containing a single epoch, corresponding to the global epoch for the entire session:\n",
    "    single_global_epoch: Epoch = Epoch(single_global_epoch_df)\n",
    "    spikes_df = directional_decoders_decode_result.spikes_df\n",
    "    pseudo2D_decoder_continuously_decoded_result: DecodedFilterEpochsResult = pseudo2D_decoder.decode_specific_epochs(spikes_df=deepcopy(spikes_df), filter_epochs=single_global_epoch, decoding_time_bin_size=time_bin_size, debug_print=False)\n",
    "    continuously_decoded_dict['pseudo2D'] = pseudo2D_decoder_continuously_decoded_result\n",
    "    continuously_decoded_dict\n",
    "    \n",
    "pseudo2D_decoder_continuously_decoded_single_result: SingleEpochDecodedResult = pseudo2D_decoder_continuously_decoded_result.get_result_for_epoch(0)\n",
    "pseudo2D_decoder_continuously_decoded_single_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eab4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudo2D_decoder_continuously_decoded_single_result.epoch_info_tuple\n",
    "pseudo2D_decoder_continuously_decoded_single_result.nbins\n",
    "pseudo2D_decoder_continuously_decoded_single_result.p_x_given_n\n",
    "pseudo2D_decoder_continuously_decoded_single_result.p_x_given_n.shape # (57, 4, 29951)\n",
    "\n",
    "\n",
    "short_RL_only = pseudo2D_decoder_continuously_decoded_single_result.p_x_given_n[:, 3, :]\n",
    "np.shape(short_RL_only)\n",
    "\n",
    "debug_portion_short_RL_only = short_RL_only[:, :1000]\n",
    "\n",
    "\n",
    "plt.figure(clear=True)\n",
    "plt.imshow(debug_portion_short_RL_only)\n",
    "# plt.plot(np.sum(short_RL_only, axis=0))\n",
    "# plt.plot(np.cumsum(np.sum(short_RL_only, axis=0)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f48287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88344ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import SingleEpochDecodedResult\n",
    "\n",
    "\n",
    "only_result.p_x_given_n\n",
    "only_result.time_bin_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ee77bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo2D_decoder_continuously_decoded_result.filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa2dc5fe",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "# NEW 2023-11-22 method: Get the templates (which can be filtered by frate first) and the from those get the decoders):        \n",
    "# track_templates: TrackTemplates = directional_laps_results.get_shared_aclus_only_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz) # shared-only\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, included_qclu_values=included_qclu_values) # non-shared-only\n",
    "long_LR_decoder, long_RL_decoder, short_LR_decoder, short_RL_decoder = track_templates.get_decoders()\n",
    "\n",
    "# Unpack all directional variables:\n",
    "## {\"even\": \"RL\", \"odd\": \"LR\"}\n",
    "long_LR_name, short_LR_name, global_LR_name, long_RL_name, short_RL_name, global_RL_name, long_any_name, short_any_name, global_any_name = ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "# Unpacking for `(long_LR_name, long_RL_name, short_LR_name, short_RL_name)`\n",
    "(long_LR_context, long_RL_context, short_LR_context, short_RL_context) = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj, global_any_laps_epochs_obj = [curr_active_pipeline.computation_results[an_epoch_name].computation_config.pf_params.computation_epochs for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name, global_any_name)] # note has global also\n",
    "(long_LR_session, long_RL_session, short_LR_session, short_RL_session) = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)] # sessions are correct at least, seems like just the computation parameters are messed up\n",
    "(long_LR_results, long_RL_results, short_LR_results, short_RL_results) = [curr_active_pipeline.computation_results[an_epoch_name].computed_data for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_computation_config, long_RL_computation_config, short_LR_computation_config, short_RL_computation_config) = [curr_active_pipeline.computation_results[an_epoch_name].computation_config for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)]\n",
    "(long_LR_pf1D, long_RL_pf1D, short_LR_pf1D, short_RL_pf1D) = (long_LR_results.pf1D, long_RL_results.pf1D, short_LR_results.pf1D, short_RL_results.pf1D)\n",
    "(long_LR_pf2D, long_RL_pf2D, short_LR_pf2D, short_RL_pf2D) = (long_LR_results.pf2D, long_RL_results.pf2D, short_LR_results.pf2D, short_RL_results.pf2D)\n",
    "(long_LR_pf1D_Decoder, long_RL_pf1D_Decoder, short_LR_pf1D_Decoder, short_RL_pf1D_Decoder) = (long_LR_results.pf1D_Decoder, long_RL_results.pf1D_Decoder, short_LR_results.pf1D_Decoder, short_RL_results.pf1D_Decoder)\n",
    "\n",
    "if rank_order_results is not None:\n",
    "    # `LongShortStatsItem` form (2024-01-02):\n",
    "    # LR_results_real_values = np.array([(a_result_item.long_stats_z_scorer.real_value, a_result_item.short_stats_z_scorer.real_value) for epoch_id, a_result_item in rank_order_results.LR_ripple.ranked_aclus_stats_dict.items()])\n",
    "    # RL_results_real_values = np.array([(a_result_item.long_stats_z_scorer.real_value, a_result_item.short_stats_z_scorer.real_value) for epoch_id, a_result_item in rank_order_results.RL_ripple.ranked_aclus_stats_dict.items()])\n",
    "    LR_results_long_short_z_diffs = np.array([a_result_item.long_short_z_diff for epoch_id, a_result_item in rank_order_results.LR_ripple.ranked_aclus_stats_dict.items()])\n",
    "    RL_results_long_short_z_diff = np.array([a_result_item.long_short_z_diff for epoch_id, a_result_item in rank_order_results.RL_ripple.ranked_aclus_stats_dict.items()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c260739a4f36c662",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrainTestSplitResult\n",
    "\n",
    "if 'TrainTestSplit' in curr_active_pipeline.global_computation_results.computed_data:\n",
    "    directional_train_test_split_result: TrainTestSplitResult = curr_active_pipeline.global_computation_results.computed_data.get('TrainTestSplit', None)\n",
    "    training_data_portion: float = directional_train_test_split_result.training_data_portion\n",
    "    test_data_portion: float = directional_train_test_split_result.test_data_portion\n",
    "    test_epochs_dict: Dict[str, pd.DataFrame] = directional_train_test_split_result.test_epochs_dict\n",
    "    train_epochs_dict: Dict[str, pd.DataFrame] = directional_train_test_split_result.train_epochs_dict\n",
    "    train_lap_specific_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_train_test_split_result.train_lap_specific_pf1D_Decoder_dict\n",
    "    \n",
    "long_LR_name, short_LR_name, global_LR_name, long_RL_name, short_RL_name, global_RL_name, long_any_name, short_any_name, global_any_name = ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any']\n",
    "long_LR_epochs_obj, long_RL_epochs_obj, short_LR_epochs_obj, short_RL_epochs_obj = [curr_active_pipeline.computation_results[an_epoch_name].computation_config.pf_params.computation_epochs for an_epoch_name in (long_LR_name, long_RL_name, short_LR_name, short_RL_name)] # note has global also\n",
    "long_LR_name, long_RL_name, short_LR_name, short_RL_name = track_templates.get_decoder_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec18cf18",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "if 'burst_detection' in curr_active_pipeline.computation_results[global_epoch_name].computed_data:\n",
    "    active_burst_intervals = curr_active_pipeline.computation_results[global_epoch_name].computed_data['burst_detection']['burst_intervals']\n",
    "# active_burst_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d31f37d",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "active_extended_stats = global_results.get('extended_stats', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9554d3bf5955d9d3",
   "metadata": {
    "tags": [
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "# Time-dependent\n",
    "long_pf1D_dt, short_pf1D_dt, global_pf1D_dt = long_results.pf1D_dt, short_results.pf1D_dt, global_results.pf1D_dt\n",
    "long_pf2D_dt, short_pf2D_dt, global_pf2D_dt = long_results.pf2D_dt, short_results.pf2D_dt, global_results.pf2D_dt\n",
    "global_pf1D_dt: PfND_TimeDependent = global_results.pf1D_dt\n",
    "global_pf2D_dt: PfND_TimeDependent = global_results.pf2D_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7a8050",
   "metadata": {},
   "outputs": [],
   "source": [
    "## long_short_endcap_analysis: checks for cells localized to the endcaps that have their placefields truncated after shortening the track\n",
    "truncation_checking_result: TruncationCheckingResults = curr_active_pipeline.global_computation_results.computed_data.long_short_endcap\n",
    "disappearing_endcap_aclus = truncation_checking_result.disappearing_endcap_aclus\n",
    "# disappearing_endcap_aclus\n",
    "trivially_remapping_endcap_aclus = truncation_checking_result.minor_remapping_endcap_aclus\n",
    "# trivially_remapping_endcap_aclus\n",
    "significant_distant_remapping_endcap_aclus = truncation_checking_result.significant_distant_remapping_endcap_aclus\n",
    "# significant_distant_remapping_endcap_aclus\n",
    "# appearing_aclus = jonathan_firing_rate_analysis_result.neuron_replay_stats_df[jonathan_firing_rate_analysis_result.neuron_replay_stats_df['track_membership'] == SplitPartitionMembership.RIGHT_ONLY].index\n",
    "# appearing_aclus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8ff5d1",
   "metadata": {},
   "source": [
    "# <a id='toc5_'></a>[1️⃣ POST-Compute:](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "728c46e6",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "21"
    },
    "tags": [
     "unwrap",
     "initial",
     "run-group-end-run",
     "all",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum_inclusion_fr_Hz: 5.0\n",
      "included_qclu_values: [1, 2, 4, 6, 7, 8, 9]\n",
      "laps_decoding_time_bin_size: 0.05, ripple_decoding_time_bin_size: 0.05\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalDisplayFunctions\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import plot_multi_sort_raster_browser\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.RankOrderRastersDebugger import RankOrderRastersDebugger\n",
    "\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import paired_separately_sort_neurons, paired_incremental_sort_neurons # _display_directional_template_debugger\n",
    "from neuropy.utils.indexing_helpers import paired_incremental_sorting, union_of_arrays, intersection_of_arrays, find_desired_sort_indicies\n",
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.ScrollBarWithSpinBox.ScrollBarWithSpinBox import ScrollBarWithSpinBox\n",
    "\n",
    "from neuropy.utils.mixins.HDF5_representable import HDF_SerializationMixin\n",
    "from pyphoplacecellanalysis.General.Model.ComputationResults import ComputedResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderAnalyses, RankOrderResult, ShuffleHelper, Zscorer, LongShortStatsTuple, DirectionalRankOrderLikelihoods, DirectionalRankOrderResult, RankOrderComputationsContainer\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import TimeColumnAliasesProtocol\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import RankOrderComputationsContainer\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import DirectionalRankOrderResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "\n",
    "## Display Testing\n",
    "# from pyphoplacecellanalysis.External.pyqtgraph import QtGui\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.Extensions.pyqtgraph_helpers import pyqtplot_build_image_bounds_extent, pyqtplot_plot_image\n",
    "\n",
    "spikes_df = curr_active_pipeline.sess.spikes_df\n",
    "rank_order_results: RankOrderComputationsContainer = curr_active_pipeline.global_computation_results.computed_data.get('RankOrder', None)\n",
    "if rank_order_results is not None:\n",
    "    minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "    ripple_result_tuple, laps_result_tuple = rank_order_results.ripple_most_likely_result_tuple, rank_order_results.laps_most_likely_result_tuple\n",
    "\n",
    "else:        \n",
    "    ## get from parameters:\n",
    "    minimum_inclusion_fr_Hz: float = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.included_qclu_values\n",
    "\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, included_qclu_values=included_qclu_values) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\n",
    "print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "print(f'included_qclu_values: {included_qclu_values}')\n",
    "# ripple_result_tuple\n",
    "\n",
    "\n",
    "# directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "# directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)\n",
    "\n",
    "# pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "# ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "# laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "# decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict\n",
    "# decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict\n",
    "\n",
    "\n",
    "## Unpacks `rank_order_results`: \n",
    "# global_replays = Epoch(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].replay))\n",
    "# global_replays = TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].replay))\n",
    "# active_replay_epochs, active_epochs_df, active_selected_spikes_df = combine_rank_order_results(rank_order_results, global_replays, track_templates=track_templates)\n",
    "# active_epochs_df\n",
    "\n",
    "# ripple_result_tuple.directional_likelihoods_tuple.long_best_direction_indices\n",
    "dir_index_to_direction_name_map: Dict[int, str] = {0:'LR', 1:\"RL\"}\n",
    "\n",
    "if rank_order_results is not None:\n",
    "    ## All three DataFrames are the same number of rows, each with one row corresponding to an Epoch:\n",
    "    active_replay_epochs_df = deepcopy(rank_order_results.LR_ripple.epochs_df)\n",
    "    # active_replay_epochs_df\n",
    "\n",
    "    # Change column type to int8 for columns: 'long_best_direction_indices', 'short_best_direction_indices'\n",
    "    # directional_likelihoods_df = pd.DataFrame.from_dict(ripple_result_tuple.directional_likelihoods_tuple._asdict()).astype({'long_best_direction_indices': 'int8', 'short_best_direction_indices': 'int8'})\n",
    "    directional_likelihoods_df = ripple_result_tuple.directional_likelihoods_df\n",
    "    # directional_likelihoods_df\n",
    "\n",
    "    # 2023-12-15 - Newest method:\n",
    "    laps_merged_complete_epoch_stats_df: pd.DataFrame = rank_order_results.laps_merged_complete_epoch_stats_df ## New method\n",
    "    ripple_merged_complete_epoch_stats_df: pd.DataFrame = rank_order_results.ripple_merged_complete_epoch_stats_df ## New method\n",
    "\n",
    "\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "\n",
    "all_directional_decoder_dict_value = directional_merged_decoders_result.all_directional_decoder_dict\n",
    "all_directional_pf1D_Decoder_value = directional_merged_decoders_result.all_directional_pf1D_Decoder\n",
    "# long_directional_pf1D_Decoder_value = directional_merged_decoders_result.long_directional_pf1D_Decoder\n",
    "# long_directional_decoder_dict_value = directional_merged_decoders_result.long_directional_decoder_dict\n",
    "# short_directional_pf1D_Decoder_value = directional_merged_decoders_result.short_directional_pf1D_Decoder\n",
    "# short_directional_decoder_dict_value = directional_merged_decoders_result.short_directional_decoder_dict\n",
    "\n",
    "all_directional_laps_filter_epochs_decoder_result_value = directional_merged_decoders_result.all_directional_laps_filter_epochs_decoder_result\n",
    "all_directional_ripple_filter_epochs_decoder_result_value = directional_merged_decoders_result.all_directional_ripple_filter_epochs_decoder_result\n",
    "\n",
    "laps_directional_marginals, laps_directional_all_epoch_bins_marginal, laps_most_likely_direction_from_decoder, laps_is_most_likely_direction_LR_dir  = directional_merged_decoders_result.laps_directional_marginals_tuple\n",
    "laps_track_identity_marginals, laps_track_identity_all_epoch_bins_marginal, laps_most_likely_track_identity_from_decoder, laps_is_most_likely_track_identity_Long = directional_merged_decoders_result.laps_track_identity_marginals_tuple\n",
    "ripple_directional_marginals, ripple_directional_all_epoch_bins_marginal, ripple_most_likely_direction_from_decoder, ripple_is_most_likely_direction_LR_dir  = directional_merged_decoders_result.ripple_directional_marginals_tuple\n",
    "ripple_track_identity_marginals, ripple_track_identity_all_epoch_bins_marginal, ripple_most_likely_track_identity_from_decoder, ripple_is_most_likely_track_identity_Long = directional_merged_decoders_result.ripple_track_identity_marginals_tuple\n",
    "\n",
    "ripple_decoding_time_bin_size: float = directional_merged_decoders_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_merged_decoders_result.laps_decoding_time_bin_size\n",
    "\n",
    "print(f'laps_decoding_time_bin_size: {laps_decoding_time_bin_size}, ripple_decoding_time_bin_size: {ripple_decoding_time_bin_size}')\n",
    "\n",
    "laps_all_epoch_bins_marginals_df = directional_merged_decoders_result.laps_all_epoch_bins_marginals_df\n",
    "ripple_all_epoch_bins_marginals_df = directional_merged_decoders_result.ripple_all_epoch_bins_marginals_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d2f342",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_merged_complete_epoch_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdb4ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_directional_marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753ca336",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "# from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import HeuristicReplayScoring\n",
    "from neuropy.core.epoch import find_data_indicies_from_epoch_times\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_filter_replay_epochs\n",
    "\n",
    "# filtered_epochs_df, filtered_decoder_filter_epochs_decoder_result_dict, filtered_ripple_all_epoch_bins_marginals_df = None, None, None\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-_perform_filter_replay_epochs.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "filtered_epochs_df, filtered_decoder_filter_epochs_decoder_result_dict, filtered_ripple_all_epoch_bins_marginals_df = _perform_filter_replay_epochs(curr_active_pipeline, global_epoch_name, track_templates, decoder_ripple_filter_epochs_decoder_result_dict, ripple_all_epoch_bins_marginals_df, ripple_decoding_time_bin_size=ripple_decoding_time_bin_size, should_only_include_user_selected_epochs=False)\n",
    "filtered_epochs_df\n",
    "# filtered_ripple_all_epoch_bins_marginals_df\n",
    "\n",
    "## 1m 38s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a32882",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_ripple_all_epoch_bins_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92aad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_sess: DataSession = curr_active_pipeline.sess\n",
    "global_session.compute_pbe_epochs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca48dd6",
   "metadata": {},
   "source": [
    "### <a id='toc5_1_1_'></a>[2024-06-25 - Advanced Time-dependent decoding:](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c76fbb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 21\u001b[0m\n\u001b[0;32m     17\u001b[0m subdiv_df: pd\u001b[38;5;241m.\u001b[39mDataFrame \u001b[38;5;241m=\u001b[39m subdivide_epochs(df, subdivide_bin_size)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# print(subdivided_df)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m## Evolve the ratemaps:\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m _a_pf1D_dt_snapshots \u001b[38;5;241m=\u001b[39m \u001b[43ma_pf1D_dt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_snapshotting\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubdiv_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_at_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m _a_pf2D_dt_snapshots \u001b[38;5;241m=\u001b[39m a_pf2D_dt\u001b[38;5;241m.\u001b[39mbatch_snapshotting(subdiv_df, reset_at_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# a_pf2D_dt.plot_ratemaps_2D()\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m## takes about 2 mins\u001b[39;00m\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\time_dependent_placefields.py:405\u001b[0m, in \u001b[0;36mPfND_TimeDependent.batch_snapshotting\u001b[1;34m(self, combined_records_list, reset_at_start, debug_print)\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m debug_print:\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, start_t: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_t\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, stop_t: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstop_t\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, item_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 405\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstop_t\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_relative_t\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshould_snapshot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# advance the self to the current start time\u001b[39;00m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m debug_print:\n\u001b[0;32m    407\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdone.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\time_dependent_placefields.py:365\u001b[0m, in \u001b[0;36mPfND_TimeDependent.update\u001b[1;34m(self, t, start_relative_t, should_snapshot)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_display_additive_update(t)\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;66;03m# non-additive mode, recompute:\u001b[39;00m\n\u001b[1;32m--> 365\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomplete_time_range_computation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshould_snapshot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# should_snapshot=False during this call because we snapshot ourselves in the next step if should_snapshot==True\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_snapshot:\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msnapshot()\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\time_dependent_placefields.py:735\u001b[0m, in \u001b[0;36mPfND_TimeDependent.complete_time_range_computation\u001b[1;34m(self, start_time, end_time, assign_results_to_member_variables, should_snapshot)\u001b[0m\n\u001b[0;32m    733\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcomplete_time_range_computation\u001b[39m(\u001b[38;5;28mself\u001b[39m, start_time, end_time, assign_results_to_member_variables\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, should_snapshot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    734\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" recomputes the entire time period from start_time to end_time with few other assumptions \"\"\"\u001b[39;00m\n\u001b[1;32m--> 735\u001b[0m     computed_out_results \u001b[38;5;241m=\u001b[39m \u001b[43mPfND_TimeDependent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_time_range_computation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_time_filtered_spikes_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_time_filtered_pos_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_srate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposition_srate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    736\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43mxbin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxbin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mybin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mybin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    737\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_time\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    738\u001b[0m \u001b[43m                                                         \u001b[49m\u001b[43mincluded_neuron_IDs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincluded_neuron_IDs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactive_computation_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverride_smooth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmooth\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# previously active_computation_config=None\u001b[39;00m\n\u001b[0;32m    740\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m assign_results_to_member_variables:\n\u001b[0;32m    741\u001b[0m         \u001b[38;5;66;03m# Should replace current time variables with those from this most recently added snapshot:\u001b[39;00m\n\u001b[0;32m    742\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_snapshot_data(end_time, computed_out_results)\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\time_dependent_placefields.py:894\u001b[0m, in \u001b[0;36mPfND_TimeDependent.perform_time_range_computation\u001b[1;34m(cls, spikes_df, pos_df, position_srate, xbin, ybin, start_time, end_time, included_neuron_IDs, active_computation_config, override_smooth)\u001b[0m\n\u001b[0;32m    890\u001b[0m active_pf_spikes_df, active_aclu_to_fragile_linear_neuron_IDX_dict \u001b[38;5;241m=\u001b[39m active_pf_spikes_df\u001b[38;5;241m.\u001b[39mspikes\u001b[38;5;241m.\u001b[39mrebuild_fragile_linear_neuron_IDXs()\n\u001b[0;32m    893\u001b[0m counts_df, num_position_samples_occupancy \u001b[38;5;241m=\u001b[39m _build_bin_pos_counts(active_pf_pos_df, xbin_values\u001b[38;5;241m=\u001b[39mxbin, ybin_values\u001b[38;5;241m=\u001b[39mybin, active_computation_config\u001b[38;5;241m=\u001b[39mactive_computation_config)\n\u001b[1;32m--> 894\u001b[0m spikes_counts_df, spikes_map_dict \u001b[38;5;241m=\u001b[39m \u001b[43m_build_bin_spike_counts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactive_pf_spikes_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneuron_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mincluded_neuron_IDs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxbin_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxbin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mybin_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mybin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactive_computation_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mactive_computation_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[38;5;66;03m# Convert curr_spikes_map_dict from a dict into the expected 3-dim matrix:\u001b[39;00m\n\u001b[0;32m    896\u001b[0m spikes_maps_matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([spikes_matrix \u001b[38;5;28;01mfor\u001b[39;00m an_aclu, spikes_matrix \u001b[38;5;129;01min\u001b[39;00m spikes_map_dict\u001b[38;5;241m.\u001b[39mitems()])  \u001b[38;5;66;03m# spikes_maps_matrix.shape # (40, 64, 29) (len(curr_spikes_map_dict), n_xbins, n_ybins)\u001b[39;00m\n",
      "File \u001b[1;32m~\\repos\\Spike3DWorkEnv\\NeuroPy\\neuropy\\analyses\\time_dependent_placefields.py:852\u001b[0m, in \u001b[0;36mPfND_TimeDependent.perform_time_range_computation.<locals>._build_bin_spike_counts\u001b[1;34m(active_pf_spikes_df, neuron_ids, xbin_values, ybin_values, active_computation_config)\u001b[0m\n\u001b[0;32m    850\u001b[0m curr_counts_df \u001b[38;5;241m=\u001b[39m active_pf_spikes_df\u001b[38;5;241m.\u001b[39mvalue_counts(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maclu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinned_x\u001b[39m\u001b[38;5;124m'\u001b[39m], sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto_frame(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcounts\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, group \u001b[38;5;129;01min\u001b[39;00m curr_counts_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maclu\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 852\u001b[0m     xbin_indicies \u001b[38;5;241m=\u001b[39m \u001b[43mgroup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinned_x\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mint\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# curr_spikes_map_dict[name][xbin_indicies, ybin_indicies] += group.counts.values # Additive\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     curr_spikes_map_dict[name][xbin_indicies] \u001b[38;5;241m=\u001b[39m group\u001b[38;5;241m.\u001b[39mcounts\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;66;03m# Assignment\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv_UV\\lib\\site-packages\\pandas\\core\\arrays\\categorical.py:565\u001b[0m, in \u001b[0;36mCategorical.astype\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m    561\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot cast \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dtype to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    562\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    564\u001b[0m     result \u001b[38;5;241m=\u001b[39m take_nd(\n\u001b[1;32m--> 565\u001b[0m         new_cats, \u001b[43mensure_platform_int\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_codes\u001b[49m\u001b[43m)\u001b[49m, fill_value\u001b[38;5;241m=\u001b[39mfill_value\n\u001b[0;32m    566\u001b[0m     )\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Directional Versions: 'long_LR':\n",
    "from neuropy.core.epoch import subdivide_epochs, ensure_dataframe\n",
    "\n",
    "\n",
    "## INPUTS: long_LR_epochs_obj, long_LR_results\n",
    "\n",
    "a_pf1D_dt: PfND_TimeDependent = deepcopy(long_LR_results.pf1D_dt)\n",
    "a_pf2D_dt: PfND_TimeDependent = deepcopy(long_LR_results.pf2D_dt)\n",
    "\n",
    "# Example usage\n",
    "df: pd.DataFrame = ensure_dataframe(deepcopy(long_LR_epochs_obj)) \n",
    "df['epoch_type'] = 'lap'\n",
    "df['interval_type_id'] = 666\n",
    "\n",
    "# subdivide_bin_size = 0.200  # Specify the size of each sub-epoch in seconds\n",
    "subdivide_bin_size = 0.050\n",
    "subdiv_df: pd.DataFrame = subdivide_epochs(df, subdivide_bin_size)\n",
    "# print(subdivided_df)\n",
    "\n",
    "## Evolve the ratemaps:\n",
    "_a_pf1D_dt_snapshots = a_pf1D_dt.batch_snapshotting(subdiv_df, reset_at_start=True)\n",
    "_a_pf2D_dt_snapshots = a_pf2D_dt.batch_snapshotting(subdiv_df, reset_at_start=True)\n",
    "# a_pf2D_dt.plot_ratemaps_2D()\n",
    "\n",
    "## takes about 2 mins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788d8b7e",
   "metadata": {},
   "source": [
    "# <a id='toc6_'></a>[/ 🛑 End Run Section 🛑](#toc0_)\n",
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7433b81f",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "## Find the time series of Long-likely events\n",
    "# type(long_RL_results) # DynamicParameters\n",
    "long_LR_pf1D_Decoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d2363d",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "type(all_directional_decoder_dict_value)\n",
    "list(all_directional_decoder_dict_value.keys()) # ['long_LR', 'long_RL', 'short_LR', 'short_RL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634e6027",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "laps_all_epoch_bins_marginals_df\n",
    "laps_most_likely_direction_from_decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdabd71",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "type(ripple_result_tuple) # pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations.DirectionalRankOrderResult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fca534c",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "assert isinstance(ripple_result_tuple, DirectionalRankOrderResult) \n",
    "\n",
    "ripple_result_tuple.plot_histograms(num='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15629dae",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.RankOrderComputations import DirectionalRankOrderResult\n",
    "from pyphocorehelpers.DataStructure.RenderPlots.MatplotLibRenderPlots import MatplotlibRenderPlots \n",
    "\n",
    "# @register_type_display(DirectionalRankOrderResult)\n",
    "def plot_histograms(self: DirectionalRankOrderResult, **kwargs) -> \"MatplotlibRenderPlots\":\n",
    "    \"\"\" \n",
    "    num='RipplesRankOrderZscore'\n",
    "    \"\"\"\n",
    "    print(f'.plot_histograms(..., kwargs: {kwargs})')\n",
    "    fig = plt.figure(layout=\"constrained\", **kwargs)\n",
    "    ax_dict = fig.subplot_mosaic(\n",
    "        [\n",
    "            [\"long_short_best_z_score_diff\", \"long_short_best_z_score_diff\"],\n",
    "            [\"long_best_z_scores\", \"short_best_z_scores\"],\n",
    "        ],\n",
    "    )\n",
    "    plots = (pd.DataFrame({'long_best_z_scores': self.long_best_dir_z_score_values}).hist(ax=ax_dict['long_best_z_scores'], bins=21, alpha=0.8),\n",
    "        pd.DataFrame({'short_best_z_scores': self.short_best_dir_z_score_values}).hist(ax=ax_dict['short_best_z_scores'], bins=21, alpha=0.8),\n",
    "        pd.DataFrame({'long_short_best_z_score_diff': self.long_short_best_dir_z_score_diff_values}).hist(ax=ax_dict['long_short_best_z_score_diff'], bins=21, alpha=0.8),\n",
    "    )\n",
    "    return MatplotlibRenderPlots(name='plot_histogram_figure', figures=[fig], axes=ax_dict)\n",
    "\n",
    "\n",
    "# register_type_display(plot_histograms, DirectionalRankOrderResult)\n",
    "## Call the newly added `plot_histograms` function on the `ripple_result_tuple` object which is of type `DirectionalRankOrderResult`:\n",
    "assert isinstance(ripple_result_tuple, DirectionalRankOrderResult) \n",
    "ripple_result_tuple.plot_histograms(num='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c291690",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "ripple_result_tuple.plot_histograms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b30bcb",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# 💾 CSVs \n",
    "print(f'\\t try saving to CSV...')\n",
    "merged_complete_epoch_stats_df = rank_order_results.ripple_merged_complete_epoch_stats_df ## New method\n",
    "merged_complete_epoch_stats_df\n",
    "merged_complete_ripple_epoch_stats_df_output_path = curr_active_pipeline.get_output_path().joinpath(f'{DAY_DATE_TO_USE}_merged_complete_epoch_stats_df.csv').resolve()\n",
    "merged_complete_epoch_stats_df.to_csv(merged_complete_ripple_epoch_stats_df_output_path)\n",
    "print(f'\\t saving to CSV: {merged_complete_ripple_epoch_stats_df_output_path} done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60749347",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    },
    "tags": [
     "all",
     "active-2025-01-20"
    ]
   },
   "outputs": [],
   "source": [
    "print(f'\\tdone. building global result.')\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "selected_spikes_df = deepcopy(curr_active_pipeline.global_computation_results.computed_data['RankOrder'].LR_ripple.selected_spikes_df)\n",
    "# active_epochs = global_computation_results.computed_data['RankOrder'].ripple_most_likely_result_tuple.active_epochs\n",
    "active_epochs = deepcopy(curr_active_pipeline.global_computation_results.computed_data['RankOrder'].LR_ripple.epochs_df)\n",
    "track_templates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz)\n",
    "\n",
    "ripple_combined_epoch_stats_df, ripple_new_output_tuple = RankOrderAnalyses.pandas_df_based_correlation_computations(selected_spikes_df=selected_spikes_df, active_epochs_df=active_epochs, track_templates=track_templates, num_shuffles=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313886d9",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# new_output_tuple (output_active_epoch_computed_values, valid_stacked_arrays, real_stacked_arrays, n_valid_shuffles) = ripple_new_output_tuple\n",
    "curr_active_pipeline.global_computation_results.computed_data['RankOrder'].ripple_combined_epoch_stats_df, curr_active_pipeline.global_computation_results.computed_data['RankOrder'].ripple_new_output_tuple = ripple_combined_epoch_stats_df, ripple_new_output_tuple\n",
    "print(f'done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6f086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Display the `TrainTestSplitResult` in a `PhoPaginatedMultiDecoderDecodedEpochsWindow`\n",
    "from neuropy.core.epoch import Epoch, ensure_dataframe\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import add_laps_groundtruth_information_to_dataframe\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import PhoPaginatedMultiDecoderDecodedEpochsWindow\n",
    "\n",
    "## INPUTS: train_decoded_results_dict\n",
    "# decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs # looks like 'lap_dir' column is wrong\n",
    "\n",
    "# active_results: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(decoder_laps_filter_epochs_decoder_result_dict)\n",
    "active_results: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy({k:v.decoder_result for k, v in _out_separate_decoder_results[0].items()})\n",
    "\n",
    "laps_app, laps_paginated_multi_decoder_decoded_epochs_window, laps_pagination_controller_dict = PhoPaginatedMultiDecoderDecodedEpochsWindow.init_from_track_templates(curr_active_pipeline, track_templates,\n",
    "                            decoder_decoded_epochs_result_dict=active_results, epochs_name='laps', included_epoch_indicies=None, \n",
    "    params_kwargs={'enable_per_epoch_action_buttons': False,\n",
    "    'skip_plotting_most_likely_positions': False, 'skip_plotting_measured_positions': False, \n",
    "    # 'enable_decoded_most_likely_position_curve': False, 'enable_radon_transform_info': True, 'enable_weighted_correlation_info': False,\n",
    "    'enable_decoded_most_likely_position_curve': True, 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': False,\n",
    "    # 'disable_y_label': True,\n",
    "    # 'isPaginatorControlWidgetBackedMode': True,\n",
    "    # 'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True,\n",
    "    # 'debug_print': True,\n",
    "    'max_subplots_per_page': 10,\n",
    "    'scrollable_figure': True,\n",
    "    # 'posterior_heatmap_imshow_kwargs': dict(vmin=0.0075),\n",
    "    'use_AnchoredCustomText': False,\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3d15bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_build_individual_time_bin_decoded_posteriors_df\n",
    "\n",
    "transfer_column_names_list: List[str] = ['maze_id', 'lap_dir', 'lap_id']\n",
    "filtered_laps_time_bin_marginals_df = _perform_build_individual_time_bin_decoded_posteriors_df(curr_active_pipeline, track_templates=track_templates, all_directional_laps_filter_epochs_decoder_result=all_directional_laps_filter_epochs_decoder_result, transfer_column_names_list=transfer_column_names_list)\n",
    "filtered_laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e0053b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import co_filter_epochs_and_spikes\n",
    "\n",
    "## INPUTS: all_directional_laps_filter_epochs_decoder_result\n",
    "transfer_column_names_list: List[str] = ['maze_id', 'lap_dir', 'lap_id']\n",
    "TIME_OVERLAP_PREVENTION_EPSILON: float = 1e-12\n",
    "(laps_directional_marginals_tuple, laps_track_identity_marginals_tuple, laps_non_marginalized_decoder_marginals_tuple), laps_marginals_df = all_directional_laps_filter_epochs_decoder_result.compute_marginals(epoch_idx_col_name='lap_idx', epoch_start_t_col_name='lap_start_t',\n",
    "                                                                                                                                                    additional_transfer_column_names=['start','stop','label','duration','lap_id','lap_dir','maze_id','is_LR_dir'])\n",
    "laps_directional_marginals, laps_directional_all_epoch_bins_marginal, laps_most_likely_direction_from_decoder, laps_is_most_likely_direction_LR_dir  = laps_directional_marginals_tuple\n",
    "laps_track_identity_marginals, laps_track_identity_all_epoch_bins_marginal, laps_most_likely_track_identity_from_decoder, laps_is_most_likely_track_identity_Long = laps_track_identity_marginals_tuple\n",
    "non_marginalized_decoder_marginals, non_marginalized_decoder_all_epoch_bins_marginal, most_likely_decoder_idxs, non_marginalized_decoder_all_epoch_bins_decoder_probs_df = laps_non_marginalized_decoder_marginals_tuple\n",
    "laps_time_bin_marginals_df: pd.DataFrame = all_directional_laps_filter_epochs_decoder_result.build_per_time_bin_marginals_df(active_marginals_tuple=(laps_directional_marginals, laps_track_identity_marginals, non_marginalized_decoder_marginals),\n",
    "                                                                                                                              columns_tuple=(['P_LR', 'P_RL'], ['P_Long', 'P_Short'], ['long_LR', 'long_RL', 'short_LR', 'short_RL']), transfer_column_names_list=transfer_column_names_list)\n",
    "laps_time_bin_marginals_df['start'] = laps_time_bin_marginals_df['start'] + TIME_OVERLAP_PREVENTION_EPSILON ## ENSURE NON-OVERLAPPING\n",
    "\n",
    "## INPUTS: laps_time_bin_marginals_df\n",
    "# active_min_num_unique_aclu_inclusions_requirement: int = track_templates.min_num_unique_aclu_inclusions_requirement(curr_active_pipeline, required_min_percentage_of_active_cells=0.33333333333333)\n",
    "active_min_num_unique_aclu_inclusions_requirement = None # must be none for individual `time_bin` periods\n",
    "filtered_laps_time_bin_marginals_df, active_spikes_df = co_filter_epochs_and_spikes(active_spikes_df=get_proper_global_spikes_df(curr_active_pipeline, minimum_inclusion_fr_Hz=curr_active_pipeline.global_computation_config.rank_order_shuffle_analysis.minimum_inclusion_fr_Hz),\n",
    "                                                                  active_epochs_df=laps_time_bin_marginals_df, included_aclus=track_templates.any_decoder_neuron_IDs, min_num_unique_aclu_inclusions=active_min_num_unique_aclu_inclusions_requirement,\n",
    "                                                                epoch_id_key_name='lap_individual_time_bin_id', no_interval_fill_value=-1, add_unique_aclus_list_column=True, drop_non_epoch_spikes=True)\n",
    "filtered_laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff8fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean and max number of active aclus per time bin for each epoch (lap)\n",
    "filtered_laps_time_bin_marginals_df.groupby(['lap_id']).agg(n_unique_aclus_mean=('n_unique_aclus', 'mean'), n_unique_aclus_max=('n_unique_aclus', 'max')).reset_index()\n",
    "filtered_laps_time_bin_marginals_df.groupby(['maze_id']).agg(n_unique_aclus_mean=('n_unique_aclus', 'mean'), n_unique_aclus_max=('n_unique_aclus', 'max')).reset_index() ## per maze\n",
    "filtered_laps_time_bin_marginals_df.groupby(['maze_id', 'lap_dir']).agg(n_unique_aclus_mean=('n_unique_aclus', 'mean'), n_unique_aclus_max=('n_unique_aclus', 'max')).reset_index() # per maze x lap_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e6cdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cb39d3",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# {frozenset({('desired_shared_decoding_time_bin_size', 0.025), ('minimum_event_duration', 0.05), ('use_single_time_bin_per_epoch', False)}): 0.025,\n",
    "#  frozenset({('desired_shared_decoding_time_bin_size', 0.03), ('minimum_event_duration', 0.05), ('use_single_time_bin_per_epoch', False)}): 0.03,\n",
    "#  frozenset({('desired_shared_decoding_time_bin_size', 0.044), ('minimum_event_duration', 0.05), ('use_single_time_bin_per_epoch', False)}): 0.044,\n",
    "#  frozenset({('desired_shared_decoding_time_bin_size', 0.05), ('minimum_event_duration', 0.05), ('use_single_time_bin_per_epoch', False)}): 0.05}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d4ce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_trial_by_trial_result.directional_active_lap_pf_results_dicts\n",
    "a_trial_by_trial_result.directional_lap_epochs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944c59a0",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "several_time_bin_sizes_ripple_df\n",
    "\n",
    "ripple_out_path # 'K:/scratch/collected_outputs/2024-07-05-kdiba_gor01_two_2006-6-07_16-40-19__withNewKamranExportedReplays-(ripple_marginals_df).csv'\n",
    "# 'K:/scratch/collected_outputs/2024-07-05-kdiba_gor01_two_2006-6-07_16-40-19__withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-(ripple_marginals_df).csv'\n",
    "several_time_bin_sizes_time_bin_ripple_df\n",
    "\n",
    "ripple_time_bin_marginals_out_path # 'K:/scratch/collected_outputs/2024-07-05-kdiba_gor01_two_2006-6-07_16-40-19__withNewKamranExportedReplays-(ripple_time_bin_marginals_df).csv'\n",
    "# 'K:/scratch/collected_outputs/2024-07-05-kdiba_gor01_two_2006-6-07_16-40-19__withNewComputedReplays-qclu_[1, 2]-frateThresh_5.0-(ripple_time_bin_marginals_df).csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2dfa3e",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "v: DecoderDecodedEpochsResult = list(output_directional_decoders_epochs_decode_results_dict.values())[0]\n",
    "v.add_all_extra_epoch_columns(curr_active_pipeline=curr_active_pipeline, track_templates=track_templates)\n",
    "# _out = v.export_csvs(parent_output_path=collected_outputs_path, active_context=curr_active_pipeline.get_session_context(), session_name=curr_active_pipeline.session_name, curr_session_t_delta=t_delta)\n",
    "\n",
    "# assert self.collected_outputs_path.exists()\n",
    "# curr_session_name: str = curr_active_pipeline.session_name # '2006-6-08_14-26-15'\n",
    "# CURR_BATCH_OUTPUT_PREFIX: str = f\"{self.BATCH_DATE_TO_USE}-{curr_session_name}\"\n",
    "# print(f'CURR_BATCH_OUTPUT_PREFIX: {CURR_BATCH_OUTPUT_PREFIX}')\n",
    "\n",
    "# from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_extended_computations\n",
    "# curr_active_pipeline.reload_default_computation_functions()\n",
    "# batch_extended_computations(curr_active_pipeline, include_includelist=['merged_directional_placefields'], include_global_functions=True, fail_on_exception=True, force_recompute=False)\n",
    "# directional_merged_decoders_result = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "\n",
    "# active_context = curr_active_pipeline.get_session_context()\n",
    "# _out = directional_merged_decoders_result.compute_and_export_marginals_df_csvs(parent_output_path=self.collected_outputs_path, active_context=active_context)\n",
    "# print(f'successfully exported marginals_df_csvs to {self.collected_outputs_path}!')\n",
    "# (laps_marginals_df, laps_out_path), (ripple_marginals_df, ripple_out_path) = _out\n",
    "# (laps_marginals_df, laps_out_path, laps_time_bin_marginals_df, laps_time_bin_marginals_out_path), (ripple_marginals_df, ripple_out_path, ripple_time_bin_marginals_df, ripple_time_bin_marginals_out_path) = _out\n",
    "# print(f'\\tlaps_out_path: {laps_out_path}\\n\\tripple_out_path: {ripple_out_path}\\n\\tdone.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58b6311",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa94d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "_across_session_results_extended_dict['perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260a8b74",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "## Take extra computations from `_decode_and_evaluate_epochs_using_directional_decoders` and integrate into the multi-time-bin results from `perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function`\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _compute_all_df_score_metrics\n",
    "\n",
    "should_skip_radon_transform = True\n",
    "## Recompute the epoch scores/metrics such as radon transform and wcorr:\n",
    "\n",
    "a_sweep_tuple, a_pseudo_2D_result = list(output_full_directional_merged_decoders_result.items())[0]\n",
    "a_decoder_laps_filter_epochs_decoder_result_dict = deepcopy(a_pseudo_2D_result.all_directional_laps_filter_epochs_decoder_result)\n",
    "a_decoder_ripple_filter_epochs_decoder_result_dict = deepcopy(a_pseudo_2D_result.all_directional_ripple_filter_epochs_decoder_result)\n",
    "\n",
    "(decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict), merged_df_outputs_tuple, raw_dict_outputs_tuple = _compute_all_df_score_metrics(directional_merged_decoders_result, track_templates,\n",
    "                                                                                                                                                                                    decoder_laps_filter_epochs_decoder_result_dict=a_decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict=a_decoder_ripple_filter_epochs_decoder_result_dict,\n",
    "                                                                                                                                                                                    spikes_df=deepcopy(curr_active_pipeline.sess.spikes_df),\n",
    "                                                                                                                                                                                    should_skip_radon_transform=should_skip_radon_transform)\n",
    "laps_radon_transform_merged_df, ripple_radon_transform_merged_df, laps_weighted_corr_merged_df, ripple_weighted_corr_merged_df, laps_simple_pf_pearson_merged_df, ripple_simple_pf_pearson_merged_df = merged_df_outputs_tuple\n",
    "decoder_laps_radon_transform_df_dict, decoder_ripple_radon_transform_df_dict, decoder_laps_radon_transform_extras_dict, decoder_ripple_radon_transform_extras_dict, decoder_laps_weighted_corr_df_dict, decoder_ripple_weighted_corr_df_dict = raw_dict_outputs_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfda868",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# `_perform_compute_custom_epoch_decoding`\n",
    "\n",
    "a_sweep_tuple\n",
    "# a_pseudo_2D_result.all_directional_laps_filter_epochs_decoder_result\n",
    "# a_pseudo_2D_result\n",
    "# a_pseudo_2D_result.short_directional_decoder_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9603a0",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# print_keys_if_possible('several_time_bin_sizes_laps_df', several_time_bin_sizes_laps_df)\n",
    "print_keys_if_possible('output_full_directional_merged_decoders_result', output_full_directional_merged_decoders_result, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a71abd",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# get_file_pat\n",
    "collected_outputs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c0f606",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "output_laps_decoding_accuracy_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dd6f87",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# from neuropy.utils.matplotlib_helpers import pho_jointplot\n",
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import pho_jointplot, plot_histograms\n",
    "sns.set_theme(style=\"ticks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4b238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# from neuropy.utils.matplotlib_helpers import pho_jointplot\n",
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import pho_jointplot, plot_histograms\n",
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "# def pho_jointplot(*args, **kwargs):\n",
    "# \t\"\"\" wraps sns.jointplot to allow adding titles/axis labels/etc.\"\"\"\n",
    "# \ttitle = kwargs.pop('title', None)\n",
    "# \t_out = sns.jointplot(*args, **kwargs)\n",
    "# \tif title is not None:\n",
    "# \t\tplt.suptitle(title)\n",
    "# \treturn _out\n",
    "\n",
    "common_kwargs = dict(ylim=(0,1), hue='time_bin_size') # , marginal_kws=dict(bins=25, fill=True)\n",
    "# sns.jointplot(data=a_laps_all_epoch_bins_marginals_df, x='lap_start_t', y='P_Long', kind=\"scatter\", color=\"#4CB391\")\n",
    "pho_jointplot(data=several_time_bin_sizes_laps_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Laps: per epoch') #color=\"#4CB391\")\n",
    "pho_jointplot(data=several_time_bin_sizes_ripple_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Ripple: per epoch')\n",
    "pho_jointplot(data=several_time_bin_sizes_time_bin_ripple_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Ripple: per time bin')\n",
    "pho_jointplot(data=several_time_bin_sizes_time_bin_laps_df, x='delta_aligned_start_t', y='P_Long', kind=\"scatter\", **common_kwargs, title='Laps: per time bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43311ee",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import plot_histograms\n",
    "\n",
    "# You can use it like this:\n",
    "plot_histograms('Laps', 'One Session', several_time_bin_sizes_time_bin_laps_df, \"several\")\n",
    "plot_histograms('Ripples', 'One Session', several_time_bin_sizes_time_bin_ripple_df, \"several\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a33b924",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "several_time_bin_sizes_ripple_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2a9d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.displot(\n",
    "#     several_time_bin_sizes_laps_df, x=\"P_Long\", col=\"species\", row=\"time_bin_size\",\n",
    "#     binwidth=3, height=3, facet_kws=dict(margin_titles=True),\n",
    "# )\n",
    "\n",
    "sns.displot(\n",
    "    several_time_bin_sizes_laps_df, x='delta_aligned_start_t', y='P_Long', row=\"time_bin_size\",\n",
    "    binwidth=3, height=3, facet_kws=dict(margin_titles=True),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495ef2bb",
   "metadata": {},
   "source": [
    "# <a id='toc7_'></a>[🎨 2024-02-06 - Other Plotting](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d5623a2",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    },
    "tags": [
     "all",
     "run-group-display",
     "run-spike_raster_window_test",
     "run-2025-04-11_full-session_marginals",
     "run-display-launcher-widget",
     "run-group-mergedcolorplot"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.TimeSynchronizedPlacefieldsPlotter import TimeSynchronizedPlacefieldsPlotter\n",
    "\n",
    "# For PlotWidget\n",
    "pg.setConfigOptions(useOpenGL=True)\n",
    "\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "\n",
    "#  Create a new `SpikeRaster2D` instance using `_display_spike_raster_pyqtplot_2D` and capture its outputs:\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "curr_active_pipeline.prepare_for_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83293544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import batch_perform_all_plots\n",
    "\n",
    "_out = batch_perform_all_plots(curr_active_pipeline, debug_print=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86d59de",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968df7ce",
   "metadata": {
    "tags": [
     "all",
     "run-display-launcher-widget"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Display import DisplayFunctionItem\n",
    "from pyphocorehelpers.gui.Qt.tree_helpers import find_tree_item_by_text\n",
    "from pyphoplacecellanalysis.GUI.Qt.MainApplicationWindows.LauncherWidget.LauncherWidget import LauncherWidget\n",
    "\n",
    "widget = LauncherWidget()\n",
    "# widget.debug_print = True\n",
    "treeWidget = widget.mainTreeWidget # QTreeWidget\n",
    "widget.build_for_pipeline(curr_active_pipeline=curr_active_pipeline)\n",
    "widget.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab95f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.gui.Qt.color_helpers import ColormapHelpers\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "cmap = ColormapHelpers.create_transparent_colormap(cmap_name='Reds', lower_bound_alpha=0.01, should_return_LinearSegmentedColormap=False)\n",
    "cmap\n",
    "\n",
    "_out = dict()\n",
    "_out['_display_trial_to_trial_reliability'] = curr_active_pipeline.display(display_function='_display_trial_to_trial_reliability', active_session_configuration_context=None, cmap=cmap) # _display_trial_to_trial_reliability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a879f8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out['_display_trial_to_trial_reliability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e56dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = dict()\n",
    "_out['_display_pf_peak_prominence2d_plots'] = curr_active_pipeline.display(display_function='_display_pf_peak_prominence2d_plots', active_session_configuration_context=IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43',filter_name='maze2_odd',lap_dir='odd'),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   neuron_id=8) # _display_pf_peak_prominence2d_plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990d7f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b653dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out['_display_directional_laps_overview'] = curr_active_pipeline.display(display_function='_display_directional_laps_overview', active_session_configuration_context=None) # _display_directional_laps_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df692641",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams\n",
    "# set_yticklabels\n",
    "\n",
    "# Set major tick label size for both x and y axes\n",
    "# ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "matplotlib.rc('xtick', labelsize=5)\n",
    "matplotlib.rc('ytick', labelsize=5)\n",
    "mpl.rcParams['font.family'] = 'Arial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8a5ca1",
   "metadata": {
    "tags": [
     "run-group-publication"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.plotting.ratemaps import plot_ratemap_1D\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out = dict()\n",
    "\n",
    "fig1_common_kwargs = dict(save_figure=True, write_vector_format=True, write_png=False, prepare_for_publication=True, bbox_inches='tight', pad_inches=0, aclu_labels_strokewidth=1)\n",
    "_out['_display_directional_track_template_pf1Ds'] = curr_active_pipeline.display(display_function='_display_directional_track_template_pf1Ds', active_session_configuration_context=None, **fig1_common_kwargs) # _display_directional_track_template_pf1Ds\n",
    "_out['_display_directional_track_template_pf1Ds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9705d6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for decoder_name, an_ax in _out['_display_directional_track_template_pf1Ds'].axes_dict.items():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce79ac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import perform_add_1D_track_bounds_lines\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "_out = dict()\n",
    "_out['_display_grid_bin_bounds_validation_x'] = curr_active_pipeline.display(display_function='_display_grid_bin_bounds_validation', active_session_configuration_context=None, is_x_axis=True) # _display_grid_bin_bounds_validation\n",
    "_out['_display_grid_bin_bounds_validation_y'] = curr_active_pipeline.display(display_function='_display_grid_bin_bounds_validation', active_session_configuration_context=None, is_x_axis=False) # _display_grid_bin_bounds_validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465a1575",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfd3606",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out = dict()\n",
    "_out['_display_directional_track_remapping_diagram'] = curr_active_pipeline.display(display_function='_display_directional_track_remapping_diagram', active_session_configuration_context=None, draw_point_aclu_labels=True, use_unique_aclu_colors=False, write_vector_format=True,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t) # _display_grid_bin_bounds_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad8ae03",
   "metadata": {},
   "source": [
    "### Plots the tracks with the vertical long/short platform lines overlayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048f6f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import test_LinearTrackDimensions_2D_Matplotlib, add_vertical_track_bounds_lines\n",
    "\n",
    "session_cm_grid_bin_bounds = UserAnnotationsManager.get_hardcoded_specific_session_override_dict()[curr_active_pipeline.get_session_context()]['cm_grid_bin_bounds']\n",
    "session_cm_grid_bin_bounds = BoundsRect.init_from_grid_bin_bounds(session_cm_grid_bin_bounds)\n",
    "session_cm_grid_bin_bounds\n",
    "\n",
    "x_mid, y_mid = session_cm_grid_bin_bounds.center_point\n",
    "\n",
    "long_offset = (x_mid, y_mid)\n",
    "short_offset = (x_mid, y_mid)\n",
    "fig, ax1, ax2 = test_LinearTrackDimensions_2D_Matplotlib(long_offset=long_offset, short_offset=short_offset)\n",
    "\n",
    "grid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\n",
    "long_track_line_collection, short_track_line_collection = add_vertical_track_bounds_lines(grid_bin_bounds=deepcopy(long_pf2D.config.grid_bin_bounds), ax=ax1)\n",
    "long_track_line_collection, short_track_line_collection = add_vertical_track_bounds_lines(grid_bin_bounds=deepcopy(short_pf2D.config.grid_bin_bounds), ax=ax2)\n",
    "\n",
    "# long_notable_x_platform_positions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d59b8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722390a6",
   "metadata": {
    "tags": [
     "run-group-publication"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import CellFieldRemappingModels\n",
    "\n",
    "# LS_pf_peak_x_diff = ['LS_pf_peak_x_diff']\n",
    "# active_scatter_all_neuron_stats_table[['long_LR_pf1D_peak', 'long_RL_pf1D_peak']]\n",
    "# active_scatter_all_neuron_stats_table[['short_LR_pf1D_peak', 'short_RL_pf1D_peak', 'peak_diff_LR_pf1D_peak', 'peak_diff_RL_pf1D_peak']]\n",
    "\n",
    "\n",
    "all_neuron_stats_table: pd.DataFrame = AcrossSessionsResults.build_neuron_identities_df_for_CSV(curr_active_pipeline=curr_active_pipeline)\n",
    "active_scatter_all_neuron_stats_table = CellFieldRemappingModels.fix_has_considerable_remapping_column(all_neuron_stats_table=all_neuron_stats_table)\n",
    "active_scatter_all_neuron_stats_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4dcfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_errors, best_model_name = CellFieldRemappingModels.main_evaluate_remapping_models(active_scatter_all_neuron_stats_table=active_scatter_all_neuron_stats_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1a371c",
   "metadata": {
    "tags": [
     "run-group-publication"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsResults # for .build_neuron_identities_df_for_CSV\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PhoPublicationFigureHelper\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import TrackRemappingDiagramFigure\n",
    "\n",
    "# 2025-06-09 18:22 - Added combined output helper:        \n",
    "# all_neuron_stats_table: pd.DataFrame = AcrossSessionsResults.build_neuron_identities_df_for_CSV(curr_active_pipeline=curr_active_pipeline)\n",
    "# active_scatter_all_neuron_stats_table: pd.DataFrame = deepcopy(all_neuron_stats_table).fillna(value=np.nan, inplace=False) ## fill all Pandas.NA values with np.nan so they can be correctly cast to floats\n",
    "# active_scatter_all_neuron_stats_table\n",
    "\n",
    "## INPUTS: active_scatter_all_neuron_stats_table\n",
    "use_pf2D_peaks: bool = False\n",
    "                    \n",
    "_fig_container = TrackRemappingDiagramFigure.plot_publication_bidirectional_track_remapping_diagram(all_neuron_stats_table=active_scatter_all_neuron_stats_table,\n",
    "    use_pf2D_peaks=use_pf2D_peaks, use_considerable_remapping_cells_only=False,\n",
    "    # common_circle_points_kwargs = dict(alpha=0.9, picker=False, plotnonfinite=False),\n",
    "    # common_BOTH_only_circle_points_kwargs = dict(alpha=0.6, picker=False, plotnonfinite=False, marker='o', zorder=9),\t\n",
    "    common_circle_points_kwargs = dict(alpha=0.9, picker=False, plotnonfinite=False, linewidths=0),\n",
    "    common_BOTH_only_circle_points_kwargs = dict(alpha=0.9, picker=False, plotnonfinite=False, marker='d', zorder=9),\t\t\n",
    "\n",
    "    # arrowprops_kwargs = dict(arrowstyle=\"fancy, head_length=0.25, head_width=0.25, tail_width=0.05\", alpha=0.6, zorder=1),\n",
    "    # arrowprops_kwargs = dict(arrowstyle=\"fancy, head_length=0.9, head_width=0.25, tail_width=0.01\", alpha=0.6, zorder=1),\n",
    "    # arrowprops_kwargs = dict(arrowstyle=\"fancy, head_length=0.25, head_width=0.25, tail_width=0.05\", mutation_scale=1, alpha=0.6, zorder=1),\n",
    "    arrowprops_kwargs = dict(arrowstyle=\"simple\", lw=0.01, alpha=0.6, zorder=1), # , mutation_scale=10\n",
    "\t\n",
    "    # base_1D_height = 1.0, top_bottom_padding = 0.025,  intra_track_y_spacing = 0.05, scatter_point_size = 15.0, # Defaults\n",
    "    base_1D_height = 1.0, top_bottom_padding = 0.2125,  intra_track_y_spacing = 0.25, scatter_point_size = 7.0, # Smaller\n",
    "    base_platform_additive_height = 0.1, long_height_multiplier = 1.0, common_1D_platform_height = 0.25, common_1D_track_height = 0.1, track_to_baseline_padding = 0.05,\n",
    "\tedgecolors = \"#00000000\", # should be provided here and not within `common_circle_points_kwargs` or `common_BOTH_only_circle_points_kwargs` because the real edgecolors need to have one value for each point \n",
    "\t\n",
    "    considerable_remapping_emphasis_color='red',\n",
    "    # considerable_remapping_emphasis_color=None,\n",
    "    write_vector_format=True,\n",
    "\tskip_RL_direction_tracks=True,\n",
    ")\n",
    "_fig_container\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043e463b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_fig_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b8f357",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89837555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPlacefieldGlobalDisplayFunctions\n",
    "\n",
    "collector = DirectionalPlacefieldGlobalDisplayFunctions._display_directional_track_remapping_diagram(owning_pipeline_reference=curr_active_pipeline, global_computation_results=curr_active_pipeline.global_computation_results, computation_results=None, active_configs=None, save_figure=False, is_dark_mode=False)\n",
    "collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20264629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PAPER_FIGURE_figure_1_full\n",
    "\n",
    "pf1d_compare_graphics, (example_epoch_rasters_L, example_epoch_rasters_S), example_stacked_epoch_graphics, fig_1c_figures_out_dict = PAPER_FIGURE_figure_1_full(curr_active_pipeline, prepare_for_publication=True, write_vector_format=True) # did not display the pf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5507c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out = dict()\n",
    "_out['_display_pf_peak_prominence2d_plots'] = curr_active_pipeline.display(display_function='_display_pf_peak_prominence2d_plots', active_session_configuration_context=IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43',filter_name='maze1_odd',lap_dir='odd')) # _display_pf_peak_prominence2d_plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cb9f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out['3d_interactive_spike_and_behavior_browser'] = curr_active_pipeline.display(display_function='_display_3d_interactive_spike_and_behavior_browser', active_session_configuration_context=None) # _display_grid_bin_bounds_validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9039fb3",
   "metadata": {},
   "source": [
    "#### 2025-06-26 - InteractivePlaceCellDataExplorer with Long & Short Placefields - Not Finished\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f90de3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.InteractivePlaceCellDataExplorer import InteractivePlaceCellDataExplorer\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out = {}\n",
    "global_any_context = curr_active_pipeline.filtered_contexts[global_any_name]\n",
    "_out['_display_3d_interactive_tuning_curves_plotter'] = curr_active_pipeline.display(display_function='_display_3d_interactive_tuning_curves_plotter', active_session_configuration_context=global_any_context,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t separate_window = False,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t params_kwargs={'show_legend': False, 'should_display_placefield_points': False, 'should_nan_non_visited_elements': False, 'zScalingFactor': 500.0, 'debug_print': False},\n",
    "                                                                                    #  panel_controls_mode = 'Panel',\n",
    "                                                                                    # panel_controls_mode = 'Qt',\n",
    "                                                                                    panel_controls_mode = None,\n",
    "                                                                                    # debug_print=False,\n",
    "                                                                                    ) # _display_grid_bin_bounds_validation\n",
    "\n",
    "\n",
    "## Move the long-maze to -`maze_y_offset` units and the short-maze to +`maze_y_offset` units along the y-axis \n",
    "ipcDataExplorer: InteractivePlaceCellDataExplorer = _out['_display_3d_interactive_tuning_curves_plotter']['ipcDataExplorer']\n",
    "pActiveTuningCurvesPlotter = _out['_display_3d_interactive_tuning_curves_plotter']['plotter']\n",
    "pane = _out['_display_3d_interactive_tuning_curves_plotter']['pane']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbaf985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import LongShort3DPlacefieldsHelpers\n",
    "\n",
    "pane = LongShort3DPlacefieldsHelpers._plot_long_short_placefields(ipcDataExplorer=ipcDataExplorer, long_pf2D=long_pf2D, short_pf2D=short_pf2D, maze_y_offset=20.0)\n",
    "# ipcDataExplorer.p.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace9a90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in ipcDataExplorer.plots.tuningCurvePlotActors.items():\n",
    "    v.SetVisibility(0)\n",
    "    peaks = v.get('peaks', None)\n",
    "    if peaks:\n",
    "        peaks.SetVisibility(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ipcDataExplorer.plots_data['tuningCurvePlotData']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c056786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipcDataExplorer.plots.tuningCurvePlotActors[3]['long']['peaks']\n",
    "# ipcDataExplorer.plots.tuningCurvePlotActors[3]['peaks'].SetVisibility(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2eb151",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import LongShort3DPlacefieldsHelpers\n",
    "\n",
    "# active_config_name: str = short_epoch_name # 'maze_any'\n",
    "# print(f'active_config_name: {active_config_name}')\n",
    "# active_peak_prominence_2d_results = curr_active_pipeline.computation_results[active_config_name].computed_data.get('RatemapPeaksAnalysis', {}).get('PeakProminence2D', None)\n",
    "\n",
    "# # pActiveTuningCurvesPlotter = None\n",
    "# # display_output = display_output | curr_active_pipeline.display('_display_3d_interactive_tuning_curves_plotter', active_config_name, extant_plotter=display_output.get('pActiveTuningCurvesPlotter', None), panel_controls_mode='Qt', should_nan_non_visited_elements=False, zScalingFactor=2000.0) # Works now!\n",
    "# # ipcDataExplorer = display_output['ipcDataExplorer']\n",
    "# # display_output['pActiveTuningCurvesPlotter'] = display_output.pop('plotter') # rename the key from the generic \"plotter\" to \"pActiveSpikesBehaviorPlotter\" to avoid collisions with others\n",
    "# # pActiveTuningCurvesPlotter = display_output['pActiveTuningCurvesPlotter']\n",
    "# # root_dockAreaWindow, placefieldControlsContainerWidget, pf_widgets = display_output['pane'] # for Qt mode\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "# render_all_neuron_peak_prominence_2d_results_on_pyvista_plotter(ipcDataExplorer, active_peak_prominence_2d_results)\n",
    "LongShort3DPlacefieldsHelpers.render_long_short_all_neuron_peak_prominence_2d_results_on_pyvista_plotter(ipcDataExplorer,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t long_peak_prominence_2d_results=curr_active_pipeline.computation_results[long_epoch_name].computed_data.get('RatemapPeaksAnalysis', {}).get('PeakProminence2D', None),\n",
    "                                                                                                         short_peak_prominence_2d_results=curr_active_pipeline.computation_results[short_epoch_name].computed_data.get('RatemapPeaksAnalysis', {}).get('PeakProminence2D', None),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51d1e83",
   "metadata": {},
   "source": [
    "### PhoJonathan Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c430bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acd174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import PhoJonathanPlotHelpers\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import BatchPhoJonathanFiguresHelper\n",
    "from pyphocorehelpers.DataStructure.RenderPlots.MatplotLibRenderPlots import FigureCollector\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import PhoPublicationFigureHelper\n",
    "\n",
    "## Get global 'jonathan_firing_rate_analysis' results:\n",
    "curr_jonathan_firing_rate_analysis = curr_active_pipeline.global_computation_results.computed_data['jonathan_firing_rate_analysis']\n",
    "neuron_replay_stats_df, rdf, aclu_to_idx, irdf = curr_jonathan_firing_rate_analysis.neuron_replay_stats_df, curr_jonathan_firing_rate_analysis.rdf.rdf, curr_jonathan_firing_rate_analysis.rdf.aclu_to_idx, curr_jonathan_firing_rate_analysis.irdf.irdf\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Batch Output of Figures                                                                                              #\n",
    "# ==================================================================================================================== #\n",
    "## 🗨️🟢 2022-11-05 - Pho-Jonathan Batch Outputs of Firing Rate Figures\n",
    "short_only_df = neuron_replay_stats_df[neuron_replay_stats_df.track_membership == SplitPartitionMembership.RIGHT_ONLY]\n",
    "short_only_aclus = short_only_df.index.values.tolist()\n",
    "long_only_df = neuron_replay_stats_df[neuron_replay_stats_df.track_membership == SplitPartitionMembership.LEFT_ONLY]\n",
    "long_only_aclus = long_only_df.index.values.tolist()\n",
    "shared_df = neuron_replay_stats_df[neuron_replay_stats_df.track_membership == SplitPartitionMembership.SHARED]\n",
    "shared_aclus = shared_df.index.values.tolist()\n",
    "print(f'shared_aclus: {shared_aclus}')\n",
    "print(f'long_only_aclus: {long_only_aclus}')\n",
    "print(f'short_only_aclus: {short_only_aclus}')\n",
    "\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'    \n",
    "## MODE: this mode creates a special folder to contain the outputs for this session.\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Output Figures to File                                                                                               #\n",
    "# ==================================================================================================================== #\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-BatchPhoJonathanFiguresHelper.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "prepare_for_publication: bool = True\n",
    "# prepare_for_publication: bool = False\n",
    "display_context = curr_active_pipeline.get_session_context()\n",
    "\n",
    "figsize = (6.5, 4)\n",
    "if prepare_for_publication:\n",
    "    from neuropy.utils.matplotlib_helpers import find_first_available_matplotlib_font_name\n",
    "\n",
    "    found_matplotlib_font_name: str = find_first_available_matplotlib_font_name(desired_fonts_list=['Arial'])\n",
    "    assert found_matplotlib_font_name, f\"found_matplotlib_font_name: {found_matplotlib_font_name} Arial was not found!\"\n",
    "else:\n",
    "    found_matplotlib_font_name = None\n",
    "\n",
    "_rc_context_kwargs = {'savefig.transparent': True, 'ps.fonttype': 42, 'pdf.fonttype': 42, }\n",
    "if prepare_for_publication:\n",
    "    assert found_matplotlib_font_name is not None\n",
    "    _rc_context_kwargs.update(PhoPublicationFigureHelper.rc_context_kwargs(prepare_for_publication=prepare_for_publication, **{'figure.dpi': '100', 'figure.frameon': False, 'figure.figsize': figsize, 'font.family': found_matplotlib_font_name})) # , 'figure.constrained_layout.use': (constrained_layout or False)\n",
    "\n",
    "\n",
    "with mpl.rc_context(_rc_context_kwargs): # 'figure.dpi': '220', 'figure.figsize': (10, 4), \n",
    "    # Create a FigureCollector instance\n",
    "    with FigureCollector(name='BatchPhoJonathanFiguresHelper', base_context=display_context) as collector:\n",
    "            \n",
    "        active_out_figures_dict = BatchPhoJonathanFiguresHelper.run(curr_active_pipeline, neuron_replay_stats_df, n_max_page_rows=1, write_vector_format=True, write_png=True, show_only_refined_cells=False)\n",
    "                \n",
    "        # for a_ctxt, a_matlab_render_plots_obj in active_out_figures_dict.items():\n",
    "        #     collector.post_hoc_append(figures=a_matlab_render_plots_obj.figures, axes=a_matlab_render_plots_obj.axes, contexts=[a_ctxt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26df7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3c878f",
   "metadata": {},
   "source": [
    "#### Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6595b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps).trimmed_to_non_overlapping() \n",
    "global_laps_epochs_df = global_laps.to_dataframe()\n",
    "_out_ripple_rasters: RankOrderRastersDebugger = RankOrderRastersDebugger.init_rank_order_debugger(global_spikes_df, deepcopy(global_laps_epochs_df),\n",
    "                                                                                                track_templates, None,\n",
    "                                                                                                None, None,\n",
    "                                                                                                dock_add_locations = dict(zip(('long_LR', 'long_RL', 'short_LR', 'short_RL'), (['right'], ['right'], ['right'], ['right']))),\n",
    "                                                                                                )\n",
    "_out_ripple_rasters.set_top_info_bar_visibility(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87275307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.fourthYearPresentation import fig_remapping_cells\n",
    "\n",
    "a_fig_collector = fig_remapping_cells(curr_active_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8833fd9",
   "metadata": {},
   "source": [
    "## Pseudo2D Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed34de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.Extensions.pyqtgraph_helpers import LayoutScrollability, pyqtplot_build_image_bounds_extent\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.TemplateDebugger import BaseTemplateDebuggingMixin, build_pf1D_heatmap_with_labels_and_peaks, TrackTemplates\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.BinByBinDecodingDebugger import BinByBinDecodingDebugger \n",
    "\n",
    "# Example usage:\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps).trimmed_to_non_overlapping() \n",
    "global_laps_epochs_df = global_laps.to_dataframe()\n",
    "global_laps_epochs_df\n",
    "\n",
    "## INPUTS: \n",
    "time_bin_size: float = 0.250\n",
    "a_lap_id: int = 9\n",
    "a_decoder_name = 'long_LR'\n",
    "epoch_id_col_name = 'lap_id'\n",
    "## COMPUTED: \n",
    "a_decoder_idx: int = track_templates.get_decoder_names().index(a_decoder_name)\n",
    "a_decoder = deepcopy(track_templates.long_LR_decoder)\n",
    "(_out_decoded_time_bin_edges, _out_decoded_unit_specific_time_binned_spike_counts, _out_decoded_active_unit_lists, _out_decoded_active_p_x_given_n, _out_decoded_active_plots_data) = BinByBinDecodingDebugger.build_spike_counts_and_decoder_outputs(a_decoder=a_decoder, epochs_df=global_laps_epochs_df, spikes_df=global_spikes_df, epoch_id_col_name=epoch_id_col_name, time_bin_size=time_bin_size)\n",
    "win, out_pf1D_decoder_template_objects, (_out_decoded_active_plots, _out_decoded_active_plots_data) = BinByBinDecodingDebugger.build_time_binned_decoder_debug_plots(a_decoder=a_decoder, an_epoch_id=a_lap_id, _out_decoded_time_bin_edges=_out_decoded_time_bin_edges, _out_decoded_active_p_x_given_n=_out_decoded_active_p_x_given_n,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  _out_decoded_active_unit_lists=_out_decoded_active_unit_lists, _out_decoded_active_plots_data=_out_decoded_active_plots_data, debug_print=True)\n",
    "\n",
    "## All-in-one mode:\n",
    "# win, out_pf1D_decoder_template_objects, (_out_decoded_active_plots, _out_decoded_active_plots_data) = BinByBinDecodingDebugger.plot_bin_by_bin_decoding_example(curr_active_pipeline=curr_active_pipeline, track_templates=track_templates, time_bin_size=time_bin_size, a_lap_id=a_lap_id, a_decoder_name=a_decoder_name)\n",
    "\n",
    "print(f\"Returned window: {win}\")\n",
    "print(f\"Returned decoder objects: {out_pf1D_decoder_template_objects}\")\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736f4d28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc01304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff24133e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125508a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345ec76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_cm_x_grid_bin_bounds\n",
    "\n",
    "global_session.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e03666",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pf1D_decoder_template_objects[0].plots_data.spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe2e4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lap_specific_spikes_df = _out_decoded_active_plots_data[a_lap_id].spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1529c71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = dict()\n",
    "_out['_display_directional_merged_pfs'] = curr_active_pipeline.display(display_function='_display_directional_merged_pfs', active_session_configuration_context=None) # _display_directional_merged_pfs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece249c2",
   "metadata": {},
   "source": [
    "n_epoch_time_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721d7f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "win.nextRow()\n",
    "lbl = win.addLabel(text='HUGE', colspan=n_epoch_time_bins) # , row=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a0506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the span to cover all columns in the row\n",
    "win.ci.layout.setRowStretchFactor(win.ci.rowCount() - 1, 1)  # Adjust the stretch factor for the new row\n",
    "win.ci.layout.setColumnStretchFactor(0, n_epoch_time_bins)   # Ensure it spans all columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f91cc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "spanning_plot2 = win.addPlot(title=\"Spanning Plot3\", row=1, rowspan=1, col=0, colspan=n_epoch_time_bins)  # Add the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7a808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spanning_plot2.setTitle(\"Spanning Plot - Covers Entire Width\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f611651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the span to cover all columns in the row\n",
    "win.ci.layout.setRowStretchFactor(win.ci.rowCount() - 1, 1)  # Adjust the stretch factor for the new row\n",
    "win.ci.layout.setColumnStretchFactor(0, n_epoch_time_bins)   # Ensure it spans all columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cae0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.decoder_difference import display_predicted_position_difference\n",
    "\n",
    "active_computed_data = curr_active_pipeline.computation_results[global_epoch_name]\n",
    "active_resampled_pos_df = active_computed_data.extended_stats.time_binned_position_df.copy() # active_computed_data.extended_stats.time_binned_position_df  # 1717 rows × 16 columns\n",
    "active_resampled_measured_positions = active_resampled_pos_df[['x','y']].to_numpy() # The measured positions resampled (interpolated) at the window centers. \n",
    "display_predicted_position_difference(active_one_step_decoder, active_two_step_decoder, active_resampled_measured_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd6298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(p_x_given_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1738f798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.TemplateDebugger import BaseTemplateDebuggingMixin, build_pf1D_heatmap_with_labels_and_peaks, TrackTemplates\n",
    "\n",
    "_obj = BaseTemplateDebuggingMixin.init_from_decoder(a_decoder=a_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe064948",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "curr_img, out_colors_heatmap_image_matrix = build_pf1D_heatmap_with_labels_and_peaks(pf1D_decoder=a_decoder, visible_aclus=active_bin_aclus, plot_item=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c18797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.TemplateDebugger import TemplateDebugger\n",
    "\n",
    "_out_TemplateDebugger: TemplateDebugger = TemplateDebugger.init_templates_debugger(track_templates) # , included_any_context_neuron_ids\n",
    "\n",
    "# _out_ui.root_dockAreaWindow\n",
    "# _out_ui.dock_widgets[a_decoder_name]\n",
    "\n",
    "## Plots:\n",
    "# _out_plots.pf1D_heatmaps[a_decoder_name] = visualize_heatmap_pyqtgraph(curr_curves, title=title_str, show_value_labels=False, show_xticks=False, show_yticks=False, show_colorbar=False, win=None, defer_show=True) # Sort to match first decoder (long_LR)\n",
    "# Adds aclu text labels with appropriate colors to y-axis: uses `sorted_shared_sort_neuron_IDs`:\n",
    "# curr_win, curr_img = _out_plots.pf1D_heatmaps[a_decoder_name] # win, img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eecf66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: \n",
    "a_decoder_aclu_to_color_map = deepcopy(_out_TemplateDebugger.plots_data['sort_helper_neuron_id_to_neuron_colors_dicts'][a_decoder_idx])\n",
    "a_decoder_aclu_to_color_map\n",
    "# _out_TemplateDebugger.plots_data['out_colors_heatmap_image_matrix_dicts'][a_decoder_idx]\n",
    "an_img_extents = deepcopy(_out_TemplateDebugger.plots_data['active_pfs_img_extents_dict'])[a_decoder_name] # [0.0, 0, 289.2117008543986, 35.0]\n",
    "an_img_extents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0aa9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out_TemplateDebugger.params\n",
    "# _out_TemplateDebugger.plots_data.data_keys\n",
    "\n",
    "a_decoder_name\n",
    "\n",
    "\n",
    "a_decoder_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd155ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd6e7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import easy_independent_decoding\n",
    "\n",
    "\n",
    "time_bin_size: float = 0.500 # 500ms\n",
    "t_start = 0.0\n",
    "t_end = 2093.8978568242164\n",
    "_decoded_pos_outputs, (unit_specific_time_binned_spike_counts, time_bin_edges, spikes_df) = easy_independent_decoding(long_LR_decoder, spikes_df=spikes_df, time_bin_size=time_bin_size, t_start=t_start, t_end=t_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9e1715",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_template_debugger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9851ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_t_bin_idx: int = 0\n",
    "# active_aclus_list = _out_decoded_active_unit_lists[a_row.lap_id][a_t_bin_idx]\n",
    "\n",
    "_out_TemplateDebugger.update_cell_emphasis(solo_emphasized_aclus=active_bin_aclus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4173061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_TemplateDebugger.pf1D_heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b761e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.indexing_helpers import compute_paginated_grid_config\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.pyqtplot_common import pyqtplot_common_setup\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.Extensions.pyqtgraph_helpers import LayoutScrollability, pyqtplot_build_image_bounds_extent, set_small_title\n",
    "from neuropy.utils.matplotlib_helpers import _scale_current_placefield_to_acceptable_range, _build_neuron_identity_label # for display_all_pf_2D_pyqtgraph_binned_image_rendering\n",
    "from pyphocorehelpers.gui.Qt.color_helpers import ColormapHelpers\n",
    "\n",
    "class HeatmapLayout(pg.QtWidgets.QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Create layout\n",
    "        layout = pg.QtWidgets.QVBoxLayout(self)\n",
    "        layout.setContentsMargins(0, 0, 0, 0)\n",
    "        layout.setSpacing(0)\n",
    "        \n",
    "        # Top row: variable number of heatmaps\n",
    "        self.top_row = pg.GraphicsLayoutWidget()\n",
    "        self.top_row.setContentsMargins(0, 0, 0, 0)\n",
    "        self.top_plots = []\n",
    "        layout.addWidget(self.top_row)\n",
    "\n",
    "        # Bottom row: single heatmap\n",
    "        self.bottom_row = pg.GraphicsLayoutWidget()\n",
    "        self.bottom_row.setContentsMargins(0, 0, 0, 0)\n",
    "        self.bottom_plot = self.bottom_row.addPlot()\n",
    "        self.bottom_plot.setContentsMargins(0, 0, 0, 0)\n",
    "        self.bottom_img = pg.ImageItem()\n",
    "        self.bottom_plot.addItem(self.bottom_img)\n",
    "        layout.addWidget(self.bottom_row)\n",
    "        \n",
    "        # Style plots\n",
    "        for p in [self.bottom_plot]:\n",
    "            p.showAxis('left', True)\n",
    "            p.showAxis('bottom', True)\n",
    "            p.getAxis('left').setLabel(\"Y-Axis\")\n",
    "            p.getAxis('bottom').setLabel(\"X-Axis\")\n",
    "            p.setContentsMargins(0, 0, 0, 0)\n",
    "            p.setDefaultPadding(0)\n",
    "            \n",
    "\n",
    "    def update_top_heatmaps(self, data_list):\n",
    "        self.top_row.clear()\n",
    "        self.top_plots = []\n",
    "        for data in data_list:\n",
    "            plot = self.top_row.addPlot()\n",
    "            plot.setContentsMargins(0, 0, 0, 0)\n",
    "            plot.setDefaultPadding(0)\n",
    "            img = pg.ImageItem(data)\n",
    "            plot.addItem(img)\n",
    "            plot.showAxis('left', True)\n",
    "            plot.getAxis('left').setLabel(\"Y-Axis\")\n",
    "            plot.hideAxis('bottom')\n",
    "            self.top_plots.append(plot)\n",
    "            self.top_row.nextRow()\n",
    "\n",
    "    def update_bottom_heatmap(self, data):\n",
    "        self.bottom_img.setImage(data)\n",
    "\n",
    "## Testing\n",
    "window = pg.QtWidgets.QMainWindow()\n",
    "widget = HeatmapLayout()\n",
    "\n",
    "# Example data\n",
    "top_data_list = [np.random.rand(10, 10), np.random.rand(15, 10)]\n",
    "bottom_data = np.random.rand(20, 20)\n",
    "\n",
    "widget.update_top_heatmaps(top_data_list)\n",
    "widget.update_bottom_heatmap(bottom_data)\n",
    "\n",
    "window.setCentralWidget(widget)\n",
    "window.resize(800, 600)\n",
    "window.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99251ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parent_root_widget = None\n",
    "root_render_widget = None\n",
    "# Need to go from (n_epochs, n_neurons, n_pos_bins) -> (n_neurons, n_xbins, n_ybins)\n",
    "n_epochs, n_neurons, n_pos_bins = np.shape(z_scored_tuning_map_matrix)\n",
    "images = z_scored_tuning_map_matrix.transpose(1, 2, 0) # (71, 57, 22)\n",
    "xbin_edges=active_one_step_decoder.xbin\n",
    "assert (len(xbin_edges)-1) == n_pos_bins, f\"n_pos_bins: {n_pos_bins}, len(xbin_edges): {len(xbin_edges)} \"\n",
    "# ybin_edges=active_one_step_decoder.ybin\n",
    "ybin_edges = np.arange(n_epochs+1) - 0.5 # correct ybin_edges are n_epochs\n",
    "root_render_widget, parent_root_widget, app = pyqtplot_common_setup(f'TrialByTrialActivityArray: {np.shape(images)}', app=app, parent_root_widget=parent_root_widget, root_render_widget=root_render_widget) ## 🚧 TODO: BUG: this makes a new QMainWindow to hold this item, which is inappropriate if it's to be rendered as a child of another control\n",
    "\n",
    "pg.setConfigOptions(imageAxisOrder='col-major') # this causes the placefields to be rendered horizontally, like they were in _temp_pyqtplot_plot_image_array\n",
    "\n",
    "\n",
    "\n",
    "## build pg.GraphicsLayoutWidget(...) required to hold the decoding preview\n",
    "root = pg.GraphicsLayoutWidget(title='Decoding Example')\n",
    "\n",
    "\n",
    "root.addItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b18f74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.SpecificComputationValidation import SpecificComputationValidator\n",
    "\n",
    "def _build_default_required_computation_keys_computation_validator_fn_factory():\n",
    "    def _subfn(curr_active_pipeline, computation_filter_name='maze'):\n",
    "        has_all_required_local_keys: bool = np.all(np.isin((a_fn_callable.input_requires or []),  list(curr_active_pipeline.computation_results[computation_filter_name].computed_data.keys())))\n",
    "        has_all_required_global_keys: bool = np.all(np.isin((a_fn_callable.requires_global_keys or []),  list(curr_active_pipeline.global_computation_results.computed_data.keys())))\n",
    "        has_all_required_keys: bool = (has_all_required_local_keys and has_all_required_global_keys)\n",
    "        return has_all_required_keys\n",
    "    return _subfn\n",
    "\n",
    "\n",
    "should_use_nice_display_names: bool = False\n",
    "display_function_items = widget.get_display_function_items()\n",
    "display_fn_validators_dict = {}\n",
    "\n",
    "for a_fcn_name, a_disp_fn_item in display_function_items.items():\n",
    "    # extract the info from the function:\n",
    "    # if hasattr(a_fcn, 'short_name') and a_fcn.short_name is not None:\n",
    "    #     active_name = a_fcn.short_name or a_fcn_name\n",
    "    # else:\n",
    "    #     active_name = a_fcn_name\n",
    "\n",
    "    # active_name: str = a_disp_fn_item.name\n",
    "    if should_use_nice_display_names:\n",
    "        active_name: str = a_disp_fn_item.best_display_name\n",
    "    else:\n",
    "        active_name: str = a_disp_fn_item.name # function name\n",
    "\n",
    "    a_fn_callable = a_disp_fn_item.fn_callable\n",
    "\n",
    "    if ((not hasattr(a_fn_callable, 'validate_computation_test')) or (a_fn_callable.validate_computation_test is None)):\n",
    "        a_fn_callable.validate_computation_test = _build_default_required_computation_keys_computation_validator_fn_factory()\n",
    "\n",
    "    display_fn_validators_dict[a_fcn_name] = SpecificComputationValidator.init_from_decorated_fn(a_fn_callable)\n",
    "    # a_disp_fn_item\n",
    "    # a_fn_handle = widget.curr_active_pipeline.plot.__getattr__(a_disp_fn_item.name)\n",
    "    # a_fn_handle\n",
    "\n",
    "    # a_validate_computation_test = lambda curr_active_pipeline, computation_filter_name='maze': (curr_active_pipeline.computation_results[computation_filter_name].computed_data['pf1D_Decoder'], curr_active_pipeline.computation_results[computation_filter_name].computed_data['pf2D_Decoder'])\n",
    "\n",
    "\n",
    "# display_function_items\n",
    "# a_fn_handle.\n",
    "display_fn_validators_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3bbc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "display_fn_validators_dict = {}\n",
    "\n",
    "\n",
    "{k:SpecificComputationValidator.init_from_decorated_fn(v) for k,v in self.registered_merged_computation_function_dict.items() if hasattr(v, 'validate_computation_test') and (v.validate_computation_test is not None)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d2c89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.computation_results['maze_any'].computed_data\n",
    "\n",
    "_out = curr_active_pipeline.display('_display_plot_marginal_1D_most_likely_position_comparisons', active_session_configuration_context='maze_any', most_likely_positions_mode='standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0170fae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out = dict()\n",
    "# _out['_display_1d_placefield_occupancy'] = curr_active_pipeline.display('_display_1d_placefield_occupancy') # _display_1d_placefield_occupancy\n",
    "\n",
    "# _out = dict()\n",
    "# _out['_display_1d_placefield_occupancy'] = curr_active_pipeline.display(display_function='_display_1d_placefield_occupancy', active_session_configuration_context='kdiba_gor01_one_2006-6-09_1-22-43_maze_any_any') # _display_1d_placefield_occupancy\n",
    "\n",
    "_out = dict()\n",
    "_out['_display_1d_placefield_occupancy'] = curr_active_pipeline.display(display_function='_display_1d_placefield_occupancy', active_session_configuration_context=IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43',filter_name='maze1_any',lap_dir='any'), plot_pos_bin_axes=False) # _display_1d_placefield_occupancy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce055b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsWidgets.EpochsEditorItem import EpochsEditor # perform_plot_laps_diagnoser\n",
    "\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "long_epoch_context, short_epoch_context, global_epoch_context = [curr_active_pipeline.filtered_contexts[a_name] for a_name in (long_epoch_name, short_epoch_name, global_epoch_name)]\n",
    "long_epoch_obj, short_epoch_obj = [Epoch(curr_active_pipeline.sess.epochs.to_dataframe().epochs.label_slice(an_epoch_name.removesuffix('_any'))) for an_epoch_name in [long_epoch_name, short_epoch_name]] #TODO 2023-11-10 20:41: - [ ] Issue with getting actual Epochs from sess.epochs for directional laps: emerges because long_epoch_name: 'maze1_any' and the actual epoch label in curr_active_pipeline.sess.epochs is 'maze1' without the '_any' part.\n",
    "long_session, short_session, global_session = [curr_active_pipeline.filtered_sessions[an_epoch_name] for an_epoch_name in [long_epoch_name, short_epoch_name, global_epoch_name]]\n",
    "\n",
    "# sess = curr_active_pipeline.sess\n",
    "sess = global_session\n",
    "\n",
    "# pos_df = sess.compute_position_laps() # ensures the laps are computed if they need to be:\n",
    "position_obj = deepcopy(sess.position)\n",
    "position_obj.compute_higher_order_derivatives()\n",
    "pos_df = position_obj.compute_smoothed_position_info(N=20) ## Smooth the velocity curve to apply meaningful logic to it\n",
    "pos_df = position_obj.to_dataframe()\n",
    "# Drop rows with missing data in columns: 't', 'velocity_x_smooth' and 2 other columns. This occurs from smoothing\n",
    "pos_df = pos_df.dropna(subset=['t', 'x_smooth', 'velocity_x_smooth', 'acceleration_x_smooth']).reset_index(drop=True)\n",
    "curr_laps_df = sess.laps.to_dataframe()\n",
    "curr_laps_df\n",
    "epochs_editor = EpochsEditor.init_laps_diagnoser(pos_df, curr_laps_df, include_velocity=True, include_accel=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1b2f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show step-by-step how the decoder works\n",
    "\n",
    "## Show pseudo2D merged placefields:\n",
    "_out = dict()\n",
    "_out['_display_directional_merged_pfs'] = curr_active_pipeline.display(display_function='_display_directional_merged_pfs', active_session_configuration_context=None) # _display_directional_merged_pfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bc2059",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionsResults\n",
    "\n",
    "all_neuron_stats_table: pd.DataFrame = AcrossSessionsResults.build_neuron_identities_df_for_CSV(curr_active_pipeline=curr_active_pipeline)\n",
    "all_neuron_stats_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6c97ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.sess.neurons\n",
    "\n",
    "# co_filter_epochs_and_spikes("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed02317",
   "metadata": {},
   "source": [
    "### <a id='toc7_1_1_'></a>[2025-01-20 - Decoding step-by-step](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7d8dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import get_proper_global_spikes_df\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import easy_independent_decoding\n",
    "\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "all_directional_pf1D_Decoder: BasePositionDecoder = deepcopy(directional_merged_decoders_result.all_directional_pf1D_Decoder) # all-directions\n",
    "# directional_merged_decoders_result\n",
    "\n",
    "# a_1D_decoder: PfND = directional_merged_decoders_result.all_directional_decoder_dict['long_LR']\n",
    "\n",
    "long_LR_decoder: BasePositionDecoder = deepcopy(track_templates.long_LR_decoder)\n",
    "\n",
    "# ratemap: Ratemap = all_directional_pf1D_Decoder.ratemap\n",
    "\n",
    "## Pass in epochs to decode, for example, the laps\n",
    "laps = deepcopy(curr_active_pipeline.sess.laps)\n",
    "\n",
    "spikes_df: pd.DataFrame = deepcopy(curr_active_pipeline.sess.spikes_df)\n",
    "# spikes_df: pd.DataFrame = get_proper_global_spikes_df(curr_active_pipeline)\n",
    "# spikes_df = spikes_df.spikes.sliced_by_neuron_id(all_directional_pf1D_Decoder.neuron_IDs)\n",
    "# spikes_df\n",
    "\n",
    "## Given a list of discrete, equally-sized `time_bin_edges`, and a `spikes_df` pd.DataFrame of neuron spike times:\n",
    "\n",
    "## use the column 'aclu', which contains a distinct unit ID\n",
    "\n",
    "## count up the number of spikes occuring for each neuron (aclu-value) in each time bin, according to the column 't_rel_seconds' and collect the result in a numpy matrix `unit_specific_time_binned_spike_counts`\n",
    "\n",
    "\n",
    "# _ratemap\n",
    "# neuron_ids = deepcopy(spikes_df.spikes.neuron_ids) # array([ 5, 10, 14, 15, 24, 25, 26, 31, 32, 33, 41, 49, 50, 51, 55, 58, 64, 69, 70, 73, 74, 75, 76, 78, 82, 83, 85, 86, 90, 92, 93, 96])\n",
    "# array([  3,   4,   5,   7,   9,  10,  11,  14,  15,  16,  17,  21,  24,  25,  26,  31,  32,  33,  34,  35,  36,  37,  41,  45,  48,  49,  50,  51,  53,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  66,  67,  68,  69,  70,  71,  73,  74,  75,  76,  78,  82,  83,  84,  85,  86,  88,  89,  90,  92,  93,  96,  98, 100, 102, 107, 108])\n",
    "# neuron_ids\n",
    "# neuron_IDs = deepcopy(all_directional_pf1D_Decoder.neuron_IDs) # array([  2,   5,   8,  10,  14,  15,  23,  24,  25,  26,  31,  32,  33,  41,  49,  50,  51,  55,  58,  64,  69,  70,  73,  74,  75,  76,  78,  82,  83,  85,  86,  90,  92,  93,  96, 109])\n",
    "# neuron_IDs\n",
    "\n",
    "neuron_IDs = deepcopy(long_LR_decoder.neuron_IDs) # array([  2,   5,   8,  10,  14,  15,  23,  24,  25,  26,  31,  32,  33,  41,  49,  50,  51,  55,  58,  64,  69,  70,  73,  74,  75,  76,  78,  82,  83,  85,  86,  90,  92,  93,  96, 109])\n",
    "neuron_IDs\n",
    "\n",
    "# all_directional_pf1D_Decoder.slic\n",
    "spikes_df = spikes_df.spikes.sliced_by_neuron_id(neuron_IDs) ## filter everything down\n",
    "# all_directional_pf1D_Decoder.pf.spikes_df = deepcopy(spikes_df)\n",
    "## Need to update .pf._filtered_spikes_df now:\n",
    "\n",
    "# all_directional_pf1D_Decoder = all_directional_pf1D_Decoder.get_by_id(ids=neuron_IDs, defer_compute_all=True)\n",
    "# all_directional_pf1D_Decoder\n",
    "\n",
    "# ratemap = ratemap.get_by_id(ids=neuron_IDs)\n",
    "# all_directional_pf1D_Decoder._ratemap = ratemap\n",
    "# all_directional_pf1D_Decoder.compute()\n",
    "# ratemap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3b046d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curr_active_pipeline.filtered_epochs\n",
    "time_bin_size: float = 0.025\n",
    "t_start = 0.0\n",
    "t_end = 2093.8978568242164\n",
    "time_bin_edges: NDArray = np.arange(t_start, t_end + time_bin_size, time_bin_size)\n",
    "# time_bin_edges\n",
    "unique_units = np.unique(spikes_df['aclu']) # sorted\n",
    "unit_specific_time_binned_spike_counts: NDArray = np.array([\n",
    "    np.histogram(spikes_df.loc[spikes_df['aclu'] == unit, 't_rel_seconds'], bins=time_bin_edges)[0]\n",
    "    for unit in unique_units\n",
    "])\n",
    "unit_specific_time_binned_spike_counts\n",
    " \n",
    "## OUTPUT: time_bin_edges, unit_specific_time_binned_spike_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a7916c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## `easy_independent_decoding`\n",
    "_decoded_pos_outputs, (unit_specific_time_binned_spike_counts, time_bin_edges, spikes_df) = easy_independent_decoding(long_LR_decoder, spikes_df=spikes_df, time_bin_size=time_bin_size, t_start=t_start, t_end=t_end)\n",
    "most_likely_positions, p_x_given_n, most_likely_position_indicies, flat_outputs_container = _decoded_pos_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1b3216",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_x_given_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809362d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(most_likely_positions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2a6c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "_decoded_pos_outputs = long_LR_decoder.decode(unit_specific_time_binned_spike_counts=unit_specific_time_binned_spike_counts, time_bin_size=time_bin_size, output_flat_versions=True, debug_print=True)\n",
    "# _decoded_pos_outputs = all_directional_pf1D_Decoder.decode(unit_specific_time_binned_spike_counts=unit_specific_time_binned_spike_counts, time_bin_size=0.020, output_flat_versions=True, debug_print=True)\n",
    "_decoded_pos_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbae7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_directional_pf1D_Decoder.neuron_IDs # array([  2,   5,   8,  10,  14,  15,  23,  24,  25,  26,  31,  32,  33,  41,  49,  50,  51,  55,  58,  64,  69,  70,  73,  74,  75,  76,  78,  82,  83,  85,  86,  90,  92,  93,  96, 109])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ee5251",
   "metadata": {},
   "outputs": [],
   "source": [
    "_decoded_pos_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c71ddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.laps import Laps\n",
    "\n",
    "\n",
    "curr_laps_df = Laps._compute_lap_dir_from_smoothed_velocity(laps_df=curr_laps_df, global_session=global_session, replace_existing=True)\n",
    "curr_laps_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd23d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_editor.plots.lap_epoch_widgets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe294f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.get_session_context()\n",
    "\n",
    "# Context(format_name= 'kdiba', animal= 'gor01', exper_name= 'one', session_name= '2006-6-09_1-22-43')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56697b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_df = deepcopy(epochs_editor.get_user_labeled_epochs_df())\n",
    "laps_df\n",
    "laps_df.to_clipboard(sep=',', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341aaedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop the first two laps:\n",
    "laps_df = laps_df[laps_df['lap_id'] > 2].reset_index(drop=True)\n",
    "laps_df\n",
    "## re-index\n",
    "laps_df['lap_id'] = laps_df.index\n",
    "laps_df['label'] = laps_df.index\n",
    "laps_df.to_clipboard(sep=',', excel=False)\n",
    "# laps_df[['start', 'stop', 'lap_dir']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad33e3c",
   "metadata": {
    "tags": [
     "active-2025-01-13"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import override_laps\n",
    "\n",
    "override_laps_df: Optional[pd.DataFrame] = UserAnnotationsManager.get_hardcoded_laps_override_dict().get(curr_active_pipeline.get_session_context(), None)\n",
    "if override_laps_df is not None:\n",
    "    print(f'overriding laps....')\n",
    "    display(override_laps_df)\n",
    "    override_laps(curr_active_pipeline, override_laps_df=override_laps_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ea0059",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacing_computation_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff3fcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "override_laps_df\n",
    "# override_laps_obj.filtered_by_lap_flat_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c601c54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_filtered_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b80e699",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.replace_session_laps_with_estimates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2482b0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.plotting.placemaps import plot_placefield_occupancy\n",
    "\n",
    "plot_placefield_occupancy(global_pf1D, plot_pos_bin_axes=True)\n",
    "# global_pf1D.plot_occupancy(plot_pos_bin_axes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2808c7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to separate out the main-track vs.the platforms so that I can impose continuity constraints (for filtering replays via step-sizes) only on the bins of the main track.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd9d391",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.sess.epochs\n",
    "# global_session.epochs\n",
    "# long_session.epochs\n",
    "# short_session.epochs\n",
    "## find first lap\n",
    "global_laps\n",
    "\n",
    "# curr_active_pipeline.sess.position.to_dataframe()\n",
    "long_session.position.to_dataframe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca411f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "active_sess_config = deepcopy(curr_active_pipeline.active_sess_config)\n",
    "# absolute_start_timestamp: float = active_sess_config.absolute_start_timestamp\n",
    "loaded_track_limits = active_sess_config.loaded_track_limits # x_midpoint, \n",
    "loaded_track_limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d8bd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "(first_valid_pos_time, last_valid_pos_time) = curr_active_pipeline.find_first_and_last_valid_position_times()\n",
    "first_valid_pos_time, last_valid_pos_time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f464ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.get_all_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e68bec8",
   "metadata": {
    "tags": [
     "active",
     "great"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.plotting.figure import pretty_plot\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.placefield import plot_1d_placecell_validations\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.placefield import plot_single_cell_1D_placecell_validation\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.placefield import _subfn_plot_pf1D_placefield\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import test_plotRaw_v_time\n",
    "\n",
    "\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "\n",
    "\n",
    "# global_session.config.plotting_config\n",
    "active_config = deepcopy(curr_active_pipeline.active_configs[global_epoch_name])\n",
    "active_pf1D = deepcopy(global_pf1D)\n",
    "\n",
    "fig = plt.figure(figsize=(23, 9.7), clear=True, num='test_plotRaw_v_time')\n",
    "# Need axes:\n",
    "# Layout Subplots in Figure:\n",
    "gs = fig.add_gridspec(1, 8)\n",
    "gs.update(wspace=0, hspace=0.05) # set the spacing between axes. # `wspace=0`` is responsible for sticking the pf and the activity axes together with no spacing\n",
    "ax_activity_v_time = fig.add_subplot(gs[0, :-1]) # all except the last element are the trajectory over time\n",
    "ax_pf_tuning_curve = fig.add_subplot(gs[0, -1], sharey=ax_activity_v_time) # The last element is the tuning curve\n",
    "# if should_include_labels:\n",
    "    # ax_pf_tuning_curve.set_title('Normalized Placefield', fontsize='14')\n",
    "ax_pf_tuning_curve.set_xticklabels([])\n",
    "ax_pf_tuning_curve.set_yticklabels([])\n",
    "\n",
    "\n",
    "cellind: int = 2\n",
    "\n",
    "kwargs = {}\n",
    "# jitter the curve_value for each spike based on the time it occured along the curve:\n",
    "spikes_color_RGB = kwargs.get('spikes_color', (0, 0, 0))\n",
    "spikes_alpha = kwargs.get('spikes_alpha', 0.8)\n",
    "# print(f'spikes_color: {spikes_color_RGB}')\n",
    "should_plot_bins_grid = kwargs.get('should_plot_bins_grid', False)\n",
    "\n",
    "should_include_trajectory = kwargs.get('should_include_trajectory', True) # whether the plot should include \n",
    "should_include_labels = kwargs.get('should_include_labels', True) # whether the plot should include text labels, like the title, axes labels, etc\n",
    "should_include_plotRaw_v_time_spikes = kwargs.get('should_include_spikes', True) # whether the plot should include plotRaw_v_time-spikes, should be set to False to plot completely with the new all spikes mode\n",
    "use_filtered_positions: bool = kwargs.pop('use_filtered_positions', False)\n",
    "\n",
    "# position_plot_kwargs = {'color': '#393939c8', 'linewidth': 1.0, 'zorder':5} | kwargs.get('position_plot_kwargs', {}) # passed into `active_epoch_placefields1D.plotRaw_v_time`\n",
    "position_plot_kwargs = {'color': '#757575c8', 'linewidth': 1.0, 'zorder':5} | kwargs.get('position_plot_kwargs', {}) # passed into `active_epoch_placefields1D.plotRaw_v_time`\n",
    "\n",
    "\n",
    "# _out = test_plotRaw_v_time(active_pf1D=active_pf1D, cellind=cellind)\n",
    "# spike_plot_kwargs = {'linestyle':'none', 'markersize':5.0, 'marker': '.', 'markerfacecolor':spikes_color_RGB, 'markeredgecolor':spikes_color_RGB, 'zorder':10} ## OLDER\n",
    "spike_plot_kwargs = {'zorder':10} ## OLDER\n",
    "\n",
    "\n",
    "# active_pf1D.plotRaw_v_time(cellind, ax=ax_activity_v_time, spikes_alpha=spikes_alpha,\n",
    "# \tposition_plot_kwargs=position_plot_kwargs,\n",
    "# \tspike_plot_kwargs=spike_plot_kwargs,\n",
    "# \tshould_include_labels=should_include_labels, should_include_trajectory=should_include_trajectory, should_include_spikes=should_include_plotRaw_v_time_spikes,\n",
    "# \tuse_filtered_positions=use_filtered_positions,\n",
    "# ) # , spikes_color=spikes_color, spikes_alpha=spikes_alpha\n",
    "\n",
    "_out = test_plotRaw_v_time(active_pf1D=active_pf1D, cellind=cellind, ax=ax_activity_v_time, spikes_alpha=spikes_alpha,\n",
    "    position_plot_kwargs=position_plot_kwargs,\n",
    "    spike_plot_kwargs=spike_plot_kwargs,\n",
    "    should_include_labels=should_include_labels, should_include_trajectory=should_include_trajectory, should_include_spikes=should_include_plotRaw_v_time_spikes,\n",
    "    use_filtered_positions=use_filtered_positions,\n",
    ")\n",
    "\n",
    "_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be863cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_out = _subfn_plot_pf1D_placefield(active_epoch_placefields1D=active_pf1D, placefield_cell_index=cellind,\n",
    "                                ax_activity_v_time=ax_activity_v_time, ax_pf_tuning_curve=ax_pf_tuning_curve, pf_tuning_curve_ax_position='right')\n",
    "_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b30c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as itt\n",
    "from mpl_multitab import MplMultiTab\n",
    "\n",
    "n_cells = active_placefields1D.ratemap.n_neurons\n",
    "out_figures_list = []\n",
    "out_axes_list = []\n",
    "\n",
    "if should_save:\n",
    "    curr_parent_out_path = plotting_config.active_output_parent_dir.joinpath('1d Placecell Validation')\n",
    "    curr_parent_out_path.mkdir(parents=True, exist_ok=True)        \n",
    "    \n",
    "# Tabbed Matplotlib Figure Mode:\n",
    "ui = MplMultiTab(title='plot_1d_placecell_validations')\n",
    "\n",
    "\n",
    "for a_decoder_name, a_decoder in track_templates.get_decoders_dict().items():\n",
    "    print(f'a_decoder_name: {a_decoder}')\n",
    "    curr_pf1D = a_decoder.pf\n",
    "    curr_pf1D.    \n",
    "\n",
    "    fig = ui.add_tab(f'Dataset {c.upper()}', f'Observation {m}')\n",
    "    ax = fig.subplots()\n",
    "    \n",
    "\n",
    "\n",
    "for i in np.arange(n_cells):\n",
    "    curr_cell_id = active_placefields1D.cell_ids[i]\n",
    "    # fig = ui.add_tab(f'Dataset {modifier_string}', f'Cell {curr_cell_id}') # Tabbed mode only\n",
    "    fig = ui.add_tab(f'Cell{curr_cell_id}')\n",
    "\n",
    "    fig, axs = plot_single_cell_1D_placecell_validation(active_placefields1D, i, extant_fig=fig, **(plot_kwargs or {}))\n",
    "    out_figures_list.append(fig)\n",
    "    out_axes_list.append(axs)\n",
    "\n",
    "# once done, save out as specified\n",
    "common_basename = active_placefields1D.str_for_filename(prefix_string=modifier_string)\n",
    "if should_save:\n",
    "    common_basename = active_placefields1D.str_for_filename(prefix_string=modifier_string)\n",
    "    if save_mode == 'separate_files':\n",
    "        # make a subdirectory for this run (with these parameters and such)\n",
    "        curr_specific_parent_out_path = curr_parent_out_path.joinpath(common_basename)\n",
    "        curr_specific_parent_out_path.mkdir(parents=True, exist_ok=True)\n",
    "        print(f'Attempting to write {n_cells} separate figures to {str(curr_specific_parent_out_path)}')\n",
    "        for i in np.arange(n_cells):\n",
    "            print('Saving figure {} of {}...'.format(i, n_cells))\n",
    "            curr_cell_id = active_placefields1D.cell_ids[i]\n",
    "            fig = out_figures_list[i]\n",
    "            # curr_cell_filename = 'pf1D-' + modifier_string + _filename_for_placefield(active_placefields1D, curr_cell_id) + '.png'\n",
    "            curr_cell_basename = '-'.join([common_basename, f'cell_{curr_cell_id:02d}'])\n",
    "            # add the file extension\n",
    "            curr_cell_filename = f'{curr_cell_basename}.png'\n",
    "            active_pf_curr_cell_output_filepath = curr_specific_parent_out_path.joinpath(curr_cell_filename)\n",
    "            fig.savefig(active_pf_curr_cell_output_filepath)\n",
    "    elif save_mode == 'pdf':\n",
    "        print('saving multipage pdf...')\n",
    "        curr_cell_basename = common_basename\n",
    "        # add the file extension\n",
    "        curr_cell_filename = f'{curr_cell_basename}-multipage_pdf.pdf'\n",
    "        pdf_save_path = curr_parent_out_path.joinpath(curr_cell_filename)\n",
    "        save_to_multipage_pdf(out_figures_list, save_file_path=pdf_save_path)\n",
    "    else:\n",
    "        raise ValueError\n",
    "    print('\\t done.')\n",
    "\n",
    "\n",
    "# ui.show() # Tabbed mode only\n",
    "_final_out = MatplotlibRenderPlots(name=f'{common_basename}', figures=out_figures_list, axes=out_axes_list, ui=ui)\n",
    "## OUTPUT: _final_out\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38ee8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_pf1D.run_spk_pos\n",
    "active_pf1D.spk_pos\n",
    "active_pf1D.run_spk_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c8e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_pf1D.ratemap_spiketrains\n",
    "active_pf1D.ratemap_spiketrains_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d290ccab",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = plot_1d_placecell_validations(active_pf1D, active_config.plotting_config, modifier_string='lap_only', should_save=False)\n",
    "# _out = curr_active_pipeline.display('_display_1d_placefield_validations', 'maze_any')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f853e158",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out.ui.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71088cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib_configuration_update(\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e362334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with matplotlib_interactivity(is_interactive=True):\n",
    "_out.figures[0].show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc6123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qclu_included_aclus = curr_active_pipeline.determine_good_aclus_by_qclu(included_qclu_values=[1,2,4,9])\n",
    "qclu_included_aclus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9e4db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_neuron_ids_list = [a_decoder.pf.ratemap.neuron_ids for a_decoder in (long_LR_decoder, long_RL_decoder, short_LR_decoder, short_RL_decoder)]\n",
    "original_neuron_ids_list = [a_decoder.pf.ratemap.neuron_ids for a_decoder in track_templates.get_decoders_dict().values()]\n",
    "original_neuron_ids_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9a96b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_names = track_templates.get_decoder_names() # ('long_LR', 'long_RL', 'short_LR', 'short_RL')\n",
    "decoder_names = TrackTemplates.get_decoder_names() # ('long_LR', 'long_RL', 'short_LR', 'short_RL')\n",
    "\n",
    "link = #00fff7\n",
    "link_visited = #ffaaff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a46a4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_print = True\n",
    "## INPUTS: included_qclu_values\n",
    "included_qclu_values = [1, 2]\n",
    "\n",
    "# modified_neuron_ids_dict = track_templates.determine_decoder_aclus_filtered_by_qclu(included_qclu_values=included_qclu_values)\n",
    "\n",
    "# filtered_track_templates = track_templates.filtered_by_frate_and_qclu(minimum_inclusion_fr_Hz=None, included_qclu_values=None)\n",
    "# filtered_track_templates = track_templates.filtered_by_frate_and_qclu(included_qclu_values=included_qclu_values)\n",
    "filtered_track_templates = track_templates.filtered_by_frate_and_qclu(minimum_inclusion_fr_Hz=5.0, included_qclu_values=[1, 2])\n",
    "\n",
    "# modified_neuron_ids_dict\n",
    "filtered_track_templates.decoder_neuron_IDs_list\n",
    "_out = dict()\n",
    "_out['_display_short_long_firing_rate_index_comparison'] = curr_active_pipeline.display(display_function='_display_short_long_firing_rate_index_comparison', active_session_configuration_context=None) # _display_short_long_firing_rate_index_comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a1ed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_included_aclus_dict = {}\n",
    "# for a_decoder in track_templates.get_decoders_dict().values():\n",
    "    # a_decoder.pf.spikes_df\n",
    "for a_decoder_name, a_decoder in track_templates.get_decoders_dict().items():\n",
    "    neuron_identities: pd.DataFrame = deepcopy(a_decoder.pf.filtered_spikes_df).spikes.extract_unique_neuron_identities()\n",
    "    if debug_print:\n",
    "        print(f\"original {len(neuron_identities)}\")\n",
    "    filtered_neuron_identities: pd.DataFrame = neuron_identities[neuron_identities.neuron_type == NeuronType.PYRAMIDAL]\n",
    "    if debug_print:\n",
    "        print(f\"post PYRAMIDAL filtering {len(filtered_neuron_identities)}\")\n",
    "    filtered_neuron_identities = filtered_neuron_identities[['aclu', 'shank', 'cluster', 'qclu']]\n",
    "    filtered_neuron_identities = filtered_neuron_identities[np.isin(filtered_neuron_identities.qclu, included_qclu_values)] # drop [6, 7], which are said to have double fields - 80 remain\n",
    "    if debug_print:\n",
    "        print(f\"post (qclu != [6, 7]) filtering {len(filtered_neuron_identities)}\")\n",
    "    # filtered_neuron_identities\n",
    "    final_included_aclus = filtered_neuron_identities['aclu'].to_numpy()\n",
    "    final_included_aclus_dict[a_decoder_name] = final_included_aclus.tolist()\n",
    "\n",
    "\n",
    "final_included_aclus_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543a7317",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.display_output_history_list\n",
    "curr_active_pipeline.display_output_last_added_context\n",
    "curr_active_pipeline.last_added_display_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd79d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_templates.any_decoder_neuron_IDs\n",
    "track_templates.decoder_neuron_IDs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acad4458",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650eea58",
   "metadata": {
    "tags": [
     "all",
     "spike_raster_window",
     "display",
     "gui",
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import Spike2DRaster\n",
    "from pyphoplacecellanalysis.GUI.Qt.SpikeRasterWindows.Spike3DRasterWindowWidget import Spike3DRasterWindowWidget\n",
    "from pyphoplacecellanalysis.GUI.Qt.PlaybackControls.Spike3DRasterBottomPlaybackControlBarWidget import Spike3DRasterBottomPlaybackControlBar\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import SynchronizedPlotMode\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.spike_raster_widgets import _setup_spike_raster_window_for_debugging\n",
    "\n",
    "# For PlotWidget\n",
    "pg.setConfigOptions(useOpenGL=True)\n",
    "\n",
    "# curr_active_pipeline.reload_default_display_functions()\n",
    "# Gets the existing SpikeRasterWindow or creates a new one if one doesn't already exist:\n",
    "spike_raster_window, (active_2d_plot, active_3d_plot, main_graphics_layout_widget, main_plot_widget, background_static_scroll_plot_widget) = Spike3DRasterWindowWidget.find_or_create_if_needed(curr_active_pipeline, force_create_new=True, use_docked_pyqtgraph_plots=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f87367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.SpikeRasterWindows.Spike3DRasterWindowWidget import Spike3DRasterWindowWidget\n",
    "# active_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.plot._display_spike_rasters_pyqtplot_2D(**kwargs).values()\n",
    "\n",
    "\n",
    "active_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.display('_display_spike_rasters_pyqtplot_2D', active_session_configuration_context='maze_any')\n",
    "# active_2d_plot, active_3d_plot, spike_raster_window = curr_active_pipeline.dsiplay('_display_spike_rasters_window')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2bce24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.SpikeRasterWindows.Spike3DRasterWindowWidget import Spike3DRasterWindowWidget\n",
    "\n",
    "# spike_raster_window, (active_2d_plot, active_3d_plot, main_graphics_layout_widget, main_plot_widget, background_static_scroll_plot_widget) = Spike3DRasterWindowWidget.find_or_create_if_needed(curr_active_pipeline, force_create_new=False)\n",
    "spike_raster_window, (active_2d_plot, active_3d_plot, *_out_args) = Spike3DRasterWindowWidget.find_or_create_if_needed(curr_active_pipeline, force_create_new=False)\n",
    "\n",
    "active_2d_plot\n",
    "active_3d_plot\n",
    "spike_raster_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcd6c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_2d_plot.find_matplotlib_render_plot_widget('interval_overview')\n",
    "intervals_overview_dock, intervals_overview_time_sync_pyqtgraph_widget = active_2d_plot.find_dock_item_tuple(identifier='interval_overview')\n",
    "# root_graphics_layout_widget = active_2d_plot.ui.matplotlib_view_widgets[name].getRootGraphicsLayoutWidget()\n",
    "# plot_item = active_2d_plot.ui.matplotlib_view_widgets[name].getRootPlotItem()\n",
    "intervals_overview_root_graphics_layout_widget = intervals_overview_time_sync_pyqtgraph_widget.getRootGraphicsLayoutWidget()\n",
    "intervals_overview_plot_item = intervals_overview_time_sync_pyqtgraph_widget.getRootPlotItem()\n",
    "\n",
    "\n",
    "# intervals_overview_plot_item.set\n",
    "# intervals_plot_item.setXRange(self.spikes_window.active_window_start_time, self.spikes_window.active_window_end_time, padding=0)\n",
    "\n",
    "intervals_overview_plot_item.setXRange(active_2d_plot.spikes_window.total_data_start_time, active_2d_plot.spikes_window.total_data_end_time, padding=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0c8093",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_overview_plot_item.setClipToView(True) # Usually default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac0b331",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.get_leaf_only_flat_dock_identifiers_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd7284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_docked_pyqtgraph_plots_mode: bool = spike_raster_window.params.use_docked_pyqtgraph_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a46242",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_global_menus_actionsDict, global_flat_action_dict, _all_outputs_dict = _setup_spike_raster_window_for_debugging(spike_raster_window, wants_docked_raster_window_track=True, enable_interval_overview_track=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39cfd03",
   "metadata": {
    "tags": [
     "run-group-mergedcolorplot",
     "run-spike_raster_window_test"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import Spike2DRaster\n",
    "from pyphoplacecellanalysis.GUI.Qt.SpikeRasterWindows.Spike3DRasterWindowWidget import Spike3DRasterWindowWidget\n",
    "from pyphoplacecellanalysis.GUI.Qt.PlaybackControls.Spike3DRasterBottomPlaybackControlBarWidget import Spike3DRasterBottomPlaybackControlBar\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import SynchronizedPlotMode\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.spike_raster_widgets import _setup_spike_raster_window_for_debugging\n",
    "\n",
    "# For PlotWidget\n",
    "pg.setConfigOptions(useOpenGL=True)\n",
    "# pg.setConfigOptions(useOpenGL=False)\n",
    "\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-Spike3DRasterWindowWidget.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "# Gets the existing SpikeRasterWindow or creates a new one if one doesn't already exist:\n",
    "spike_raster_window, (active_2d_plot, active_3d_plot, _all_outputs_dict) = Spike3DRasterWindowWidget.find_or_create_if_needed(curr_active_pipeline, force_create_new=True,\n",
    "    wants_docked_raster_window_track=True, enable_interval_overview_track=True, allow_replace_hardcoded_main_plots_with_tracks=True,\n",
    ")\n",
    "main_graphics_layout_widget = _all_outputs_dict['main_graphics_layout_widget'] \n",
    "main_plot_widget = _all_outputs_dict['main_plot_widget']\n",
    "background_static_scroll_plot_widget = _all_outputs_dict['background_static_scroll_plot_widget']\n",
    "\n",
    "all_global_menus_actionsDict = _all_outputs_dict['all_global_menus_actionsDict']\n",
    "global_flat_action_dict = _all_outputs_dict['global_flat_action_dict']\n",
    "# all_global_menus_actionsDict, global_flat_action_dict, _all_outputs_dict = _setup_spike_raster_window_for_debugging(spike_raster_window, wants_docked_raster_window_track=True, enable_interval_overview_track=True, allow_replace_hardcoded_main_plots_with_tracks=False)\n",
    "# all_global_menus_actionsDict, global_flat_action_dict, _all_outputs_dict = _setup_spike_raster_window_for_debugging(spike_raster_window, wants_docked_raster_window_track=True, enable_interval_overview_track=True, allow_replace_hardcoded_main_plots_with_tracks=False)\n",
    "\n",
    "# # preview_overview_scatter_plot: pg.ScatterPlotItem  = active_2d_plot.plots.preview_overview_scatter_plot # ScatterPlotItem \n",
    "# # preview_overview_scatter_plot.setDownsampling(auto=True, method='subsample', dsRate=10)\n",
    "# main_graphics_layout_widget: pg.GraphicsLayoutWidget = active_2d_plot.ui.main_graphics_layout_widget\n",
    "# wrapper_layout: pg.QtWidgets.QVBoxLayout = active_2d_plot.ui.wrapper_layout\n",
    "# main_content_splitter = active_2d_plot.ui.main_content_splitter # QSplitter\n",
    "# layout = active_2d_plot.ui.layout\n",
    "# background_static_scroll_window_plot = active_2d_plot.plots.background_static_scroll_window_plot # PlotItem\n",
    "# main_plot_widget = active_2d_plot.plots.main_plot_widget # PlotItem\n",
    "# active_window_container_layout = active_2d_plot.ui.active_window_container_layout # GraphicsLayout, first item of `main_graphics_layout_widget` -- just the active raster window I think, there is a strange black space above it\n",
    "# bottom_bar: Spike3DRasterBottomPlaybackControlBar = spike_raster_window.bottom_playback_control_bar_widget\n",
    "# # bottom_bar.log_print('test manual log entry')\n",
    "# bottom_bar.add_log_line('test manual log entry')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ed0bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spike_raster_window.on_crosshair_trace_toggled()\n",
    "active_2d_plot.layout_dockGroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7009ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "# decoding_time_bin_size = 0.025\n",
    "# filter_epochs_decoder_result, active_filter_epochs, default_figure_name = long_results['specific_epochs_decoding'][('Ripples', decoding_time_bin_size)]\n",
    "\n",
    "_out = dict()\n",
    "_out['_display_plot_decoded_epoch_slices'] = curr_active_pipeline.display(display_function='_display_plot_decoded_epoch_slices', active_session_configuration_context=IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='one',session_name='2006-6-09_1-22-43',filter_name='maze2_any',lap_dir='any'), filter_epochs='replay') # _display_plot_decoded_epoch_slices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e54270",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import _build_additional_window_menus\n",
    "## Build the additional menus:\n",
    "output_references = _build_additional_window_menus(spike_raster_window, owning_pipeline_reference=curr_active_pipeline, computation_result, active_display_fn_identifying_ctx) ## the menus on the other hand take the entire pipeline, because they might need that valuable DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38054838",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recompute the one and two-step decoding computations continuously\n",
    "\n",
    "# ['_perform_position_decoding_computation', '_perform_two_step_position_decoding_computation']\n",
    "# ['position_decoding', 'position_decoding_two_step']\n",
    "\n",
    "debug_print: bool = False\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_perform_position_decoding_computation', '_perform_two_step_position_decoding_computation'],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t  computation_kwargs_list=[{'override_decoding_time_bin_size': 0.025, 'debug_print': debug_print}, {'debug_print': debug_print}],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t  enabled_filter_names=None, fail_on_exception=True, debug_print=debug_print)\n",
    "\n",
    "active_one_step_decoder = curr_active_pipeline.computation_results[active_config_name].computed_data.get('pf2D_Decoder', None)\n",
    "\n",
    "\n",
    "assert active_one_step_decoder is not None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b8665f",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_one_step_decoder.flat_p_x_given_n.shape # (472, 66151)\n",
    "np.shape(active_one_step_decoder.p_x_given_n) # (59, 8, 66151)\n",
    "np.shape(active_one_step_decoder.P_x) # (472, 1)\n",
    "active_one_step_decoder.original_position_data_shape # (59, 8)\n",
    "active_one_step_decoder.flat_position_size # 472\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e690d756",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['_perform_two_step_position_decoding_computation'],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t  computation_kwargs_list=[{'ndim': 2, 'debug_print': debug_print}],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t  enabled_filter_names=None, fail_on_exception=True, debug_print=debug_print)\n",
    "\n",
    "active_two_step_decoder = curr_active_pipeline.computation_results[active_config_name].computed_data.get('pf2D_TwoStepDecoder', None)\n",
    "assert active_two_step_decoder is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb672a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_one_step_decoder.xbin\n",
    "active_one_step_decoder.ybin\n",
    "\n",
    "active_two_step_decoder.xbin\n",
    "active_two_step_decoder.ybin\n",
    "\n",
    "# active_two_step_decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a82d026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import AddNewDecodedPosition_MatplotlibPlotCommand, AddNewLongShortDecodedEpochSlices_MatplotlibPlotCommand, AddNewTrackTemplatesDecodedEpochSlicesRows_MatplotlibPlotCommand # for add matplotlib plot action\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import AddNewDirectionalDecodedEpochs_MatplotlibPlotCommand, AddNewDecodedPosteriors_MatplotlibPlotCommand, AddNewDecodedEpochMarginal_MatplotlibPlotCommand\n",
    "from pyphoplacecellanalysis.GUI.Qt.Menus.SpecificMenus.CreateLinkedWidget_MenuProvider import CreateNewTimeSynchronizedPlotterCommand, CreateNewTimeSynchronizedCombinedPlotterCommand\n",
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.TimeSynchronizedPositionDecoderPlotter import TimeSynchronizedPositionDecoderPlotter\n",
    "\n",
    "active_config_name = None # kwargs.get('active_config_name', None)\n",
    "active_config_name = global_any_name\n",
    "active_context = None\n",
    "display_output = {}\n",
    "active_pf_2D_dt = curr_active_pipeline.computation_results[active_config_name].computed_data.get('pf2D_dt', None)\n",
    "active_one_step_decoder = curr_active_pipeline.computation_results[active_config_name].computed_data.get('pf2D_Decoder', None)\n",
    "active_two_step_decoder = curr_active_pipeline.computation_results[active_config_name].computed_data.get('pf2D_TwoStepDecoder', None)\n",
    "_out = CreateNewTimeSynchronizedPlotterCommand(spike_raster_window, active_pf_2D_dt=active_pf_2D_dt, plotter_type='decoder', curr_active_pipeline=curr_active_pipeline, active_context=active_context, active_config_name=active_config_name, display_output=display_output, action_identifier='actionTimeSynchronizedDecoderPlotter')\n",
    "_out.execute()\n",
    "a_plotter_obj, _a_conn = display_output['synchronizedPlotter_decoder']\n",
    "active_ax = a_plotter_obj.ui.root_plot\n",
    "a_plotter_obj: TimeSynchronizedPositionDecoderPlotter = a_plotter_obj # TimeSynchronizedPositionDecoderPlotter \n",
    "(long_rects_outputs, short_rects_outputs) = a_plotter_obj.add_track_shapes()\n",
    "a_plotter_obj.update(t=active_2d_plot.active_window_start_time, defer_render=False)\n",
    "\n",
    "## OUTPUTS: active_ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fd0483",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_one_step_decoder.xbin\n",
    "active_one_step_decoder.ybin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ea8f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_plotter_obj.params.x_range\n",
    "a_plotter_obj.params.y_range\n",
    "a_plotter_obj.params.image_bounds_extent # [0.0, 86.33093525179856, 287.7697841726619, 115.10791366906471]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e38ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import LinearTrackDimensions, test_LinearTrackDimensions_2D_pyqtgraph\n",
    "\n",
    "long_track_dims = LinearTrackDimensions(track_length=170.0)\n",
    "short_track_dims = LinearTrackDimensions(track_length=100.0)\n",
    "\n",
    "app, w, cw, (ax0, ax1), (long_track_dims, long_rect_items, long_rects), (short_track_dims, short_rect_items, short_rects) = test_LinearTrackDimensions_2D_pyqtgraph(long_track_dims, short_track_dims)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ae2b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import LinearTrackInstance\n",
    "from neuropy.utils.mixins.dict_representable import overriding_dict_with\n",
    "\n",
    "loaded_track_limits = {'long_xlim': np.array([59.0774, 228.69]),\n",
    "    'long_unit_xlim': np.array([0.205294, 0.794698]),\n",
    "    'short_xlim': np.array([94.0156, 193.757]),\n",
    "    'short_unit_xlim': np.array([0.326704, 0.673304]),\n",
    "    'long_ylim': np.array([138.164, 146.12]),\n",
    "    'long_unit_ylim': np.array([0.48012, 0.507766]),\n",
    "    'short_ylim': np.array([138.021, 146.263]),\n",
    "    'short_unit_ylim': np.array([0.479622, 0.508264]),\n",
    "}\n",
    "\n",
    "## INPUTS: active_ax\n",
    "\n",
    "long_track_inst, short_track_inst = LinearTrackInstance.init_LS_tracks_from_loaded_track_limits(loaded_track_limits=loaded_track_limits)\n",
    "# long_rects_outputs, short_rects_outputs = \n",
    "# long_track_inst\n",
    "# # Centered above and below the y=0.0 line:\n",
    "# long_offset = (long_track_inst.grid_bin_bounds.center_point[0], 0.75)\n",
    "# short_offset = (short_track_inst.grid_bin_bounds.center_point[0], -0.75)\n",
    "\n",
    "# active_ax = a_plotter_obj.ui.root_plot\n",
    "\n",
    "\n",
    "# long_track_combined_collection, long_rect_items, long_rects = long_track_inst.plot_rects(active_ax)\n",
    "# short_track_combined_collection, short_rect_items, short_rects = short_track_inst.plot_rects(active_ax)\n",
    "\n",
    "# long_epoch_matplotlib_config = long_short_display_config_manager.long_epoch_config.as_matplotlib_kwargs()\n",
    "# long_kwargs = deepcopy(long_epoch_matplotlib_config)\n",
    "long_kwargs = dict(edgecolor='#0000FFFF', facecolor=\"#0000FFB7\")\n",
    "# long_kwargs = dict(edgecolor='#000000ff', facecolor='#000000ff')\n",
    "# long_rects_outputs = long_track_inst.plot_rects(active_ax, offset=long_offset, matplotlib_rect_kwargs_override=overriding_dict_with(lhs_dict=long_kwargs, **dict(linewidth=2, zorder=-99)))\n",
    "long_rects_outputs = long_track_inst.plot_rects(active_ax, matplotlib_rect_kwargs_override=overriding_dict_with(lhs_dict=long_kwargs, **dict(linewidth=2, zorder=-99)))\n",
    "\n",
    "# short_epoch_matplotlib_config = long_short_display_config_manager.short_epoch_config.as_matplotlib_kwargs()\n",
    "# short_kwargs = deepcopy(short_epoch_matplotlib_config)\n",
    "short_kwargs = dict(edgecolor='#FF0000FF', facecolor=\"#FF0000B7\")\n",
    "# short_kwargs = dict(edgecolor='#000000ff', facecolor='#000000ff')\n",
    "# short_rects_outputs = short_track_inst.plot_rects(active_ax, offset=short_offset, matplotlib_rect_kwargs_override=overriding_dict_with(lhs_dict=short_kwargs, **dict(linewidth=2, zorder=-99)))\n",
    "short_rects_outputs = short_track_inst.plot_rects(active_ax, matplotlib_rect_kwargs_override=overriding_dict_with(lhs_dict=short_kwargs, **dict(linewidth=2, zorder=-99)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11968a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.Mixins.InteractivePlotterMixins import InteractivePyvistaPlotter_PointAndPathPlottingMixin\n",
    "from pyphoplacecellanalysis.GUI.PyVista.InteractivePlotter.InteractivePlaceCellDataExplorer import InteractivePlaceCellDataExplorer\n",
    "\n",
    "_out = dict()\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out['_display_3d_interactive_spike_and_behavior_browser'] = curr_active_pipeline.display(display_function='_display_3d_interactive_spike_and_behavior_browser', active_session_configuration_context=IdentifyingContext(format_name='kdiba',animal='gor01',exper_name='two',session_name='2006-6-07_16-40-19',filter_name='maze_any',lap_dir='any')) # _display_3d_interactive_spike_and_behavior_browser\n",
    "_out['_display_3d_interactive_spike_and_behavior_browser']\n",
    "ipspikesDataExplorer = _out['_display_3d_interactive_spike_and_behavior_browser']['ipspikesDataExplorer']\n",
    "p = _out['_display_3d_interactive_spike_and_behavior_browser']['plotter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40395133",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipspikesDataExplorer.animal_current_location_point ## actor\n",
    "ipspikesDataExplorer.plots_data['animal_current_location_point']\n",
    "ipspikesDataExplorer.plots['animal_current_location_point']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06df5a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipspikesDataExplorer.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af35fc52",
   "metadata": {},
   "source": [
    "## Adding Grid_bin_bound position validations as tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff98bb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_man = curr_active_pipeline.get_output_manager()\n",
    "fig_man.get_figure_output_parent_and_basename(final_context=curr_active_pipeline.get_session_context(), make_folder_if_needed=False)\n",
    "\n",
    "# FileOutputManager(figure_output_location=<FigureOutputLocation.DAILY_PROGRAMMATIC_OUTPUT_FOLDER: 'daily_programmatic_output_folder'>, context_to_path_mode=<ContextToPathMode.HIERARCHY_UNIQUE: 'hierarchy_unique'>, override_output_parent_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efd0cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import SynchronizedPlotMode\n",
    "\n",
    "## Add to timeline\n",
    "active_2d_plot: Spike2DRaster = active_2d_plot\n",
    "\n",
    "\n",
    "_bounds_validation_track_axs = {}\n",
    "a_dock_identifier: str = 'BoundsValidation_x'\n",
    "_bounds_validation_track_axs[a_dock_identifier] = active_2d_plot.add_new_matplotlib_render_plot_widget(name=a_dock_identifier, sync_mode=SynchronizedPlotMode.TO_GLOBAL_DATA)[2][0]\n",
    "\n",
    "a_dock_identifier: str = 'BoundsValidation_y'\n",
    "_bounds_validation_track_axs[a_dock_identifier] = active_2d_plot.add_new_matplotlib_render_plot_widget(name=a_dock_identifier, sync_mode=SynchronizedPlotMode.TO_GLOBAL_DATA)[2][0]\n",
    "_bounds_validation_track_axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa3dcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, ax in _bounds_validation_track_axs.items():\n",
    "\tax.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2a0dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_out = dict()\n",
    "_out['_display_grid_bin_bounds_validation_x'] = curr_active_pipeline.display(display_function='_display_grid_bin_bounds_validation', active_session_configuration_context=None, is_x_axis=True, ax=_bounds_validation_track_axs['BoundsValidation_x']) # _display_grid_bin_bounds_validation\n",
    "_out['_display_grid_bin_bounds_validation_y'] = curr_active_pipeline.display(display_function='_display_grid_bin_bounds_validation', active_session_configuration_context=None, is_x_axis=False, ax=_bounds_validation_track_axs['BoundsValidation_y']) # _display_grid_bin_bounds_validation\n",
    "\n",
    "## sync only after so the grid_bin_bounds lines extend across the whole thing\n",
    "active_2d_plot.sync_matplotlib_render_plot_widget('BoundsValidation_x', sync_mode=SynchronizedPlotMode.TO_WINDOW)\n",
    "active_2d_plot.sync_matplotlib_render_plot_widget('BoundsValidation_y', sync_mode=SynchronizedPlotMode.TO_WINDOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1ba555",
   "metadata": {},
   "source": [
    "## Other from pre-2025-07-02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b952fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_rects_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fe14e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_one_step_decoder.P_x.shape # active_one_step_decoder.P_x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f12a92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_plotter_obj.params.image_bounds_extent\n",
    "a_plotter_obj.params.x_range\n",
    "a_plotter_obj.params.y_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bee998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_plotter_obj.params.posterior_variable_to_render = 'p_x_given_n'\n",
    "a_plotter_obj.posterior_variable_to_render = 'p_x_given_n_and_x_prev'\n",
    "a_plotter_obj.update(t=active_2d_plot.active_window_start_time, defer_render=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfc5daa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf50adb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.params.enable_non_marginalized_raw_result = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7bcfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_plotter_obj.time_window_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca93e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.active_window_start_time\n",
    "# active_2d_plot.animation_active_time_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc81db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "on_window_changed(self, start_t, end_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab851679",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca040e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_flat_action_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6a535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: global_flat_action_dict\n",
    "\n",
    "menu_commands = [\n",
    "    # 'AddTimeCurves.Position', ## 2025-03-11 02:32 Running this too soon after launching the window causes weird black bars on the top and bottom of the window\n",
    "    'AddTimeCurves.ThetaPhase',\n",
    "    # 'DockedWidgets.LongShortDecodedEpochsDockedMatplotlibView',\n",
    "    # 'DockedWidgets.DirectionalDecodedEpochsDockedMatplotlibView',\n",
    "    # 'DockedWidgets.TrackTemplatesDecodedEpochsDockedMatplotlibView',\n",
    "    # 'DockedWidgets.Pseudo2DDecodedEpochsDockedMatplotlibView', # [/c:/Users/pho/repos/Spike3DWorkEnv/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/Qt/Menus/SpecificMenus/DockedWidgets_MenuProvider.py:141](vscode://file/c:/Users/pho/repos/Spike3DWorkEnv/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/GUI/Qt/Menus/SpecificMenus/DockedWidgets_MenuProvider.py:141)`'actionPseudo2DDecodedEpochsDockedMatplotlibView': AddNewDecodedPosteriors_MatplotlibPlotCommand`\n",
    "    #  'DockedWidgets.ContinuousPseudo2DDecodedMarginalsDockedMatplotlibView',\n",
    "]\n",
    "# menu_commands = ['actionPseudo2DDecodedEpochsDockedMatplotlibView', 'actionContinuousPseudo2DDecodedMarginalsDockedMatplotlibView'] # , 'AddTimeIntervals.SessionEpochs'\n",
    "\n",
    "# Run after a 0.5 second delay\n",
    "for a_command in menu_commands:\n",
    "    # all_global_menus_actionsDict[a_command].trigger()\n",
    "    global_flat_action_dict[a_command].trigger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce46022",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.clear_all_3D_time_curves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b6ad1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.update_3D_time_curves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17552aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_time_curves_datasource = active_2d_plot.params.time_curves_datasource\n",
    "active_time_curves_datasource.merge(on='t', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac52164",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.plots.time_curves['default_plot_datasource.y position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1a31e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_plot_item = list(active_2d_plot.plots.time_curves.values())[0]\n",
    "\n",
    "## override theta phase pen:\n",
    "## firing statistics to bins instead of boolean masking by those meeting criteria\n",
    "spikes_df: pd.DataFrame = get_proper_global_spikes_df(curr_active_pipeline)\n",
    "theta_phase_radians = spikes_df['theta_phase_radians'].to_numpy()\n",
    "\n",
    "\n",
    "cmap = pg.colormap.get('CET-C2s') # rainbow\n",
    "\n",
    "# Example 1: Gradient pen\n",
    "# cmap = pg.colormap.get('CET-L17') # prepare a linear color map\n",
    "# cmap.reverse()                    # reverse it to put light colors at the top \n",
    "pen = cmap.getPen(span=(0.0, (2.0*np.pi)), width=5) # gradient from blue (y=0) to white (y=1)\n",
    "# plot a curve drawn with a pen colored according to y value:\n",
    "curve1 = pg.PlotDataItem(y=y_data1, pen=pen)\n",
    "\n",
    "\n",
    "theta_cmap = cmap.map(theta_phase_radians, mode='qcolor') # List[QColor]\n",
    "theta_cmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997b5694",
   "metadata": {},
   "outputs": [],
   "source": [
    "pen = pg.mkPen(theta_cmap, width=2)\n",
    "\n",
    "# for i in range(len(x)-1):\n",
    "#     t = i/(len(x)-1)\n",
    "#     pen = pg.mkPen(cmap.map(t, mode='qcolor'), width=2)    \n",
    "    \n",
    "# pen = pg.mkPen(\n",
    "#     color='red',           # Color: string, tuple (R,G,B), or QColor\n",
    "#     width=2,              # Line width in pixels\n",
    "#     style=QtCore.Qt.DashLine,  # Line style: SolidLine, DashLine, DotLine, etc.\n",
    "#     cosmetic=True,        # Whether line width scales with zoom\n",
    "#     capStyle=QtCore.Qt.RoundCap,  # End cap style\n",
    "#     joinStyle=QtCore.Qt.RoundJoin  # Join style for corners\n",
    "# )\n",
    "a_plot_item.setPen(pen)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f08cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = pg.mkQApp()\n",
    "w = pg.PlotWidget()\n",
    "\n",
    "x = np.linspace(0, 10, 200)\n",
    "y = np.sin(x)                       # or any “value” array\n",
    "cmap = pg.colormap.get('CET-C2s')       # rainbow\n",
    "\n",
    "for i in range(len(x)-1):\n",
    "    t = i/(len(x)-1)\n",
    "    pen = pg.mkPen(cmap.map(t, mode='qcolor'), width=2)\n",
    "    w.plot(x[i:i+2], y[i:i+2], pen=pen)\n",
    "\n",
    "w.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0101d1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import FixedCustomColormaps\n",
    "\n",
    "# active_cmap = FixedCustomColormaps.get_custom_greyscale_with_low_values_dropped_cmap(low_value_cutoff=0.01, full_opacity_threshold=0.25, invert_for_black_bg=True)\n",
    "active_cmap = FixedCustomColormaps.get_custom_greyscale_with_low_values_dropped_cmap(low_value_cutoff=0.01, full_opacity_threshold=0.25, invert_for_black_bg=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742ae0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_2d_plot.dock_manager_widget\n",
    "active_dockGroup_dock_dict = active_2d_plot.get_dockGroup_dock_dict()\n",
    "# active_dockGroup_dock_dict['ContinuousDecode_ - t_bin_size: 0.025']\n",
    "\n",
    "active_dockGroup_dock_dict['ContinuousDecode_ - t_bin_size: 0.025']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e4e5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_2d_plot.root_window.ui.menus.global_window_menus.docked_widgets\n",
    "\n",
    "active_2d_plot.ui.menus.global_window_menus.docked_widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3832eac4",
   "metadata": {},
   "source": [
    "#### Testing a Matplotlib-backed widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada6c1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.PyqtgraphTimeSynchronizedWidget import PyqtgraphTimeSynchronizedWidget  \n",
    "\n",
    "active_2d_plot: Spike2DRaster = active_2d_plot  \n",
    "\n",
    "\n",
    "a_dock_id: str = 'ContinuousDecode_long_LR - t_bin_size: 0.025'\n",
    "# a_dock, widget = active_2d_plot.find_dock_item_tuple(identifier='ContinuousDecode_long_LR')\n",
    "# a_dock, widget = active_2d_plot.find_dock_item_tuple(identifier='ContinuousDecode_long_RL')\n",
    "a_dock, widget = active_2d_plot.find_dock_item_tuple(identifier=a_dock_id)\n",
    "# widget.plots\n",
    "# widget.plots_data\n",
    "# img.set_cmap('viridis')  # or any \n",
    "an_ax = widget.ax\n",
    "# widget\n",
    "an_ax.set_facecolor('black')  # Set axes background to black\n",
    "# an_ax.set_facecolor('white')  # Set axes background to white\n",
    "\n",
    "\n",
    "# img.set_cmap('viridis')  # or any valid colormap name\n",
    "# widget.getRootPlotItem().setXRange(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time, padding=0) ## global frame  \n",
    "# widget.update(None)  \n",
    "\n",
    "im_posterior_x = widget.plots.im_posterior_x\n",
    "# im_posterior_x.set_cmap(active_cmap)  # or any valid colormap name\n",
    "# widget.update()\n",
    "# widget\n",
    "# plt.draw()\n",
    "im_posterior_x # AxesImage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff5bcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.PyqtgraphTimeSynchronizedWidget import PyqtgraphTimeSynchronizedWidget  \n",
    "\n",
    "active_2d_plot: Spike2DRaster = active_2d_plot  \n",
    "\n",
    "\n",
    "a_dock_id: str = 'ContinuousDecode_long_LR - t_bin_size: 0.025'\n",
    "# a_dock, widget = active_2d_plot.find_dock_item_tuple(identifier='ContinuousDecode_long_LR')\n",
    "# a_dock, widget = active_2d_plot.find_dock_item_tuple(identifier='ContinuousDecode_long_RL')\n",
    "a_dock, widget = active_2d_plot.find_dock_item_tuple(identifier=a_dock_id)\n",
    "# widget.plots\n",
    "# widget.plots_data\n",
    "# img.set_cmap('viridis')  # or any \n",
    "an_ax = widget.ax\n",
    "# widget\n",
    "an_ax.set_facecolor('black')  # Set axes background to black\n",
    "# an_ax.set_facecolor('white')  # Set axes background to white\n",
    "\n",
    "\n",
    "# img.set_cmap('viridis')  # or any valid colormap name\n",
    "# widget.getRootPlotItem().setXRange(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time, padding=0) ## global frame  \n",
    "# widget.update(None)  \n",
    "\n",
    "im_posterior_x = widget.plots.im_posterior_x\n",
    "# im_posterior_x.set_cmap(active_cmap)  # or any valid colormap name\n",
    "# widget.update()\n",
    "# widget\n",
    "# plt.draw()\n",
    "im_posterior_x # AxesImage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bbad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.temporal_axis_length\n",
    "active_2d_plot.active_time_window\n",
    "\n",
    "np.diff(active_2d_plot.active_time_window)\n",
    "\n",
    "active_2d_plot.active_window_duration\n",
    "active_2d_plot.render_window_duration\n",
    "(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e063fd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "widget.plots\n",
    "# widget.plots_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e86d20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "images = an_ax.get_images()\n",
    "images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884493a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_img = images[0]\n",
    "an_img\n",
    "an_img.set_cmap(active_cmap)  # or any valid colormap name\n",
    "plt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5599478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import FigureToImageHelpers\n",
    "\n",
    "## INPUTS: im_posterior_x\n",
    "relative_data_output_parent_folder = Path('data').resolve()\n",
    "Assert.path_exists(relative_data_output_parent_folder)\n",
    "\n",
    "output_pdf_path: Path = relative_data_output_parent_folder.joinpath('timeline_exported.pdf')\n",
    "# FigureToImageHelpers.export_axesimage_to_paged_pdf(ax_image=im_posterior_x, x_extent=(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time), chunk_width=active_2d_plot.active_window_duration, output_pdf_path=output_pdf_path, figsize=(8, 11), dpi=150, override_cmap=None, debug_max_num_pages=5)\n",
    "FigureToImageHelpers.export_wrapped_axesimage_to_paged_pdf(ax_image=im_posterior_x, x_extent=(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time), chunk_width=active_2d_plot.active_window_duration, output_pdf_path=output_pdf_path, figsize=(8, 11), dpi=150,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\trows_per_page=5, debug_max_num_pages=25,\t\t    \n",
    "                                                # rows_per_page=15, debug_max_num_pages=3,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e5764e",
   "metadata": {},
   "source": [
    "#### Testing multiple matplotlib tracks at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74cc8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "\n",
    "formatted_title_strings_dict = DisplayColorsEnum.get_matplotlib_formatted_title_dict()\n",
    "decoder_names_list: List[str] = list(formatted_title_strings_dict.keys())\n",
    "\n",
    "## get the whole stack\n",
    "active_dockGroup_dock_dict = active_2d_plot.get_dockGroup_dock_dict()\n",
    "_curr_active_dock_group = active_dockGroup_dock_dict['ContinuousDecode_ - t_bin_size: 0.025'] # {'long_LR': 'Long◀', 'long_RL': 'Long▶', 'short_LR': 'Short◀', 'short_RL': 'Short▶'}\n",
    "_curr_decoders_dock_item_names_list: List[str] = [v.name() for v in _curr_active_dock_group] # ['ContinuousDecode_long_LR - t_bin_size: 0.025', 'ContinuousDecode_long_RL - t_bin_size: 0.025', 'ContinuousDecode_short_LR - t_bin_size: 0.025', 'ContinuousDecode_short_RL - t_bin_size: 0.025']\n",
    "im_posterior_x_stack = [v.widgets[0].plots.im_posterior_x for v in _curr_active_dock_group]\n",
    "\n",
    "_curr_decoder_name_to_decoders_dock_item_name_map = {}\n",
    "_remaining_dock_names = set(_curr_decoders_dock_item_names_list)\n",
    "\n",
    "# _curr_decoders_dock_item_names_list\n",
    "for a_decoder_name in decoder_names_list:\n",
    "\tfor a_dock_name in _remaining_dock_names: #_curr_decoders_dock_item_names_list:\n",
    "\t\tif (a_decoder_name in a_dock_name):\n",
    "\t\t\t_curr_decoder_name_to_decoders_dock_item_name_map[a_decoder_name] = a_dock_name\n",
    "\t\t\t_remaining_dock_names.remove(a_dock_name)\n",
    "\t\t\tbreak\n",
    "\n",
    "assert len(_curr_decoder_name_to_decoders_dock_item_name_map) == len(decoder_names_list), f\"decoder_names_list: {decoder_names_list} != list(_curr_decoder_name_to_decoders_dock_item_name_map.keys()): {_curr_decoder_name_to_decoders_dock_item_name_map}\"\n",
    "track_labels: List[str] = [formatted_title_strings_dict[a_decoder_name] for a_decoder_name, a_dock_name in _curr_decoder_name_to_decoders_dock_item_name_map.items()]\n",
    "track_labels\n",
    "\n",
    "## OUTPUTS: im_posterior_x_stack, track_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ff81d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import FigureToImageHelpers\n",
    "\n",
    "## INPUTS: im_posterior_x_stack, track_labels, \n",
    "output_pdf_path: Path = relative_data_output_parent_folder.joinpath('timeline_exported_stack.pdf')\n",
    "FigureToImageHelpers.export_wrapped_axesimage_to_paged_pdf(ax_image=im_posterior_x_stack, x_extent=(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time), chunk_width=active_2d_plot.active_window_duration, output_pdf_path=output_pdf_path, figsize=(8, 11), dpi=150,\n",
    "        \t\t\t\t\t\t\t\t\t\t\t\trows_per_page=5, debug_max_num_pages=3,\t\t    \n",
    "                                                        # rows_per_page=15, debug_max_num_pages=3,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\ttrack_labels=track_labels,\n",
    "                                                    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6bc040",
   "metadata": {},
   "source": [
    "#### Testing a Pyqtgraph-backed widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1552576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.PyqtgraphTimeSynchronizedWidget import PyqtgraphTimeSynchronizedWidget  \n",
    "\n",
    "active_2d_plot: Spike2DRaster = active_2d_plot  \n",
    "\n",
    "\n",
    "a_dock_id: str = 'intervals'\n",
    "a_dock, widget = active_2d_plot.find_dock_item_tuple(identifier=a_dock_id)\n",
    "# widget.plots\n",
    "# widget.plots_data\n",
    "# img.set_cmap('viridis')  # or any \n",
    "widget: PyqtgraphTimeSynchronizedWidget = widget\n",
    "root_plot_item: pg.PlotItem = widget.getRootPlotItem()\n",
    "root_plot_item\n",
    "# an_ax = widget\n",
    "# an_ax\n",
    "# widget\n",
    "# an_ax.set_facecolor('black')  # Set axes background to black\n",
    "# an_ax.set_facecolor('white')  # Set axes background to white\n",
    "\n",
    "\n",
    "# img.set_cmap('viridis')  # or any valid colormap name\n",
    "# widget.getRootPlotItem().setXRange(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time, padding=0) ## global frame  \n",
    "# widget.update(None)  \n",
    "\n",
    "# im_posterior_x = widget.plots.im_posterior_x\n",
    "# im_posterior_x.set_cmap(active_cmap)  # or any valid colormap name\n",
    "# widget.update()\n",
    "# widget\n",
    "# plt.draw()\n",
    "# im_posterior_x # AxesImage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07b3ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import FigureToImageHelpers\n",
    "\n",
    "## INPUTS: root_plot_item\n",
    "relative_data_output_parent_folder = Path('data').resolve()\n",
    "Assert.path_exists(relative_data_output_parent_folder)\n",
    "\n",
    "output_pdf_path: Path = relative_data_output_parent_folder.joinpath('timeline_exported_pyqtgraph.pdf')\n",
    "FigureToImageHelpers.export_wrapped_pyqtgraph_to_paged_pdf(plot_item=root_plot_item, x_extent=(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time), chunk_width=active_2d_plot.active_window_duration, output_pdf_path=output_pdf_path, figsize=(8, 11), dpi=150,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\trows_per_page=5, debug_max_num_pages=25,\t\t    \n",
    "                                                # rows_per_page=15, debug_max_num_pages=3,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e5afc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_outputs_path.joinpath('timeline_exported.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cb96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.SpecificDockWidgetManipulatingMixin import SpecificDockWidgetManipulatingMixin\n",
    "\n",
    "\n",
    "\n",
    "## measured positions\n",
    "## INPUTS: curr_active_pipeline, an_ax, \n",
    "measured_position_df: pd.DataFrame = deepcopy(curr_active_pipeline.sess.position.to_dataframe())\n",
    "\n",
    "widget.plots_data.measured_position_df = None\n",
    "widget.plots.measured_position_artists = None\n",
    "if measured_position_df is not None:\n",
    "    widget.plots_data.measured_position_df = measured_position_df\n",
    "    _out_artists = SpecificDockWidgetManipulatingMixin._perform_overlay_measured_position(matplotlib_fig_axes=[an_ax], measured_position_df=measured_position_df)\n",
    "    widget.plots.measured_position_artists = _out_artists\n",
    "    widget.draw() # alternative to accessing through full path?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d493184",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.dock_manager_widget.get_leaf_only_flat_dock_identifiers_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9a8974",
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_window = spike_raster_window.spikes_window # SpikesDataframeWindow; pyphoplacecellanalysis.General.Model.TimeWindow.TimeWindow\n",
    "spikes_window.update_window_start_end(451.8908457518555, 451.9895490613999) ## Works but does not trigger refresh/update of the window. The changes are reflected as soon as you try to scroll at all though.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c6ec5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a203ce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "menu_commands = ['AddTimeIntervals.Replays', 'AddTimeIntervals.Laps', 'AddTimeIntervals.SessionEpochs'] # , 'AddTimeIntervals.SessionEpochs', 'AddTimeIntervals.PBEs', 'AddTimeIntervals.Ripples',\n",
    "for a_command in menu_commands:\n",
    "    assert a_command in global_flat_action_dict, f\"a_command: '{a_command}' is not present in global_flat_action_dict: {list(global_flat_action_dict.keys())}\"\n",
    "    # add_renderables_menu[a_command].trigger()\n",
    "    global_flat_action_dict[a_command].trigger()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f895e3",
   "metadata": {},
   "source": [
    "main_content_splitter (QSplitter)\n",
    "\tmain_graphics_layout_widget (CustomGraphicsLayoutWidget)\n",
    "\t\tqt_scrollarea_hcontainer (QWidget)\n",
    "\t\t\tUnnamed (QScrollBar)\n",
    "\t\tqt_scrollarea_vcontainer (QWidget)\n",
    "\t\t\tUnnamed (QScrollBar)\n",
    "\t\tUnnamed (QOpenGLWidget)\n",
    "\twrapper_widget (QWidget)\n",
    "\t\tdynamic_docked_widget_container (NestedDockAreaWidget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbac1ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "from PyQt5.QtWidgets import QAbstractScrollArea\n",
    "from PyQt5.QtWidgets import QSizePolicy\n",
    "\n",
    "from pyphoplacecellanalysis.General.Mixins.DisplayHelpers import debug_widget_geometry\n",
    "from pyphocorehelpers.gui.Qt.TopLevelWindowHelper import print_widget_hierarchy\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.spike_raster_widgets import _get_required_static_layout_height\n",
    "\n",
    "main_graphics_layout_widget: pg.GraphicsLayoutWidget = active_2d_plot.ui.main_graphics_layout_widget\n",
    "wrapper_layout: pg.QtWidgets.QVBoxLayout = active_2d_plot.ui.wrapper_layout\n",
    "main_content_splitter = active_2d_plot.ui.main_content_splitter # QSplitter\n",
    "\n",
    "## Tracks\n",
    "dynamic_docked_widget_container = active_2d_plot.ui.dynamic_docked_widget_container\n",
    "dynamic_docked_widget_container_parent_wrapper = dynamic_docked_widget_container.parentWidget() # 'wrapper_widget'\n",
    "\n",
    "## Hard-coded\n",
    "layout = active_2d_plot.ui.layout\n",
    "background_static_scroll_window_plot = active_2d_plot.plots.background_static_scroll_window_plot # PlotItem\n",
    "\n",
    "main_plot_widget = active_2d_plot.plots.main_plot_widget # PlotItem\n",
    "\n",
    "root_layout: pg.GraphicsLayout = active_2d_plot.plots.background_static_scroll_window_plot.parentWidget()\n",
    "static_children_bounding_rect = root_layout.childrenBoundingRect() # QRectF\n",
    "required_static_children_bounding_rect_height: float = static_children_bounding_rect.height()\n",
    "required_static_children_bounding_rect_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d567bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_2d_plot.ui.dynamic_docked_widget_container\n",
    "# dynamic_docked_widget_container.parent().objectName()\n",
    "# dynamic_docked_widget_container.parentWidget().objectName()\n",
    "\n",
    "debug_widget_geometry(dynamic_docked_widget_container, widget_name='dynamic_docked_widget_container')\n",
    "debug_widget_geometry(dynamic_docked_widget_container_parent_wrapper, widget_name='dynamic_docked_widget_container_parent_wrapper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81954f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_docked_widget_container_parent_wrapper.setSizePolicy(QtGui.QSizePolicy.Expanding, QtGui.QSizePolicy.Expanding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eccdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.spike_raster_widgets import _get_required_static_layout_height\n",
    "\n",
    "required_static_children_bounding_rect_height: float = _get_required_static_layout_height(active_2d_plot=active_2d_plot)\n",
    "print(f'required_static_children_bounding_rect_height: {required_static_children_bounding_rect_height}')\n",
    "main_graphics_layout_widget.setMaximumHeight(required_static_children_bounding_rect_height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd68cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_widget_geometry(main_graphics_layout_widget, widget_name='main_graphics_layout_widget')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ed1a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_widget_hierarchy(main_graphics_layout_widget)\n",
    "\n",
    "# PyQt5.QtCore.QRect(0, 221, 1855, 640)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f0cb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.spike_raster_widgets import _get_required_static_layout_height\n",
    "\n",
    "main_graphics_layout_widget.setSizeAdjustPolicy(QAbstractScrollArea.SizeAdjustPolicy.AdjustToContentsOnFirstShow)                    \n",
    "required_static_children_bounding_rect_height: float = _get_required_static_layout_height(active_2d_plot=active_2d_plot)\n",
    "print(f'required_static_children_bounding_rect_height: {required_static_children_bounding_rect_height}')\n",
    "# main_graphics_layout_widget.setMaximumHeight(required_static_children_bounding_rect_height)\n",
    "\n",
    "# main_graphics_layout_widget.resize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60210451",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_widget_hierarchy(active_2d_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ebf4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.print_helpers import strip_type_str_to_classname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e035fa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5.QtWidgets import QOpenGLWidget\n",
    "\n",
    "main_graphics_layout_widget.childrenRect()\n",
    "\n",
    "open_gl_widget: QOpenGLWidget = main_graphics_layout_widget.children()[-1]\n",
    "open_gl_widget.childrenRect()\n",
    "open_gl_widget.contentsRect()\n",
    "# open_gl_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54c3c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_layout: pg.GraphicsLayout = main_plot_widget.parentWidget()\n",
    "main_layout\n",
    "# main_plot_widget.parent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8fb146",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_layout.childrenBoundingRect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd819d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_layout.parentWidget().parentWidget()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d433e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_widget_geometry(main_plot_widget)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fe9c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5.QtWidgets import QAbstractScrollArea\n",
    "from PyQt5.QtWidgets import QSizePolicy\n",
    "\n",
    "main_graphics_layout_widget.setSizeAdjustPolicy(QAbstractScrollArea.SizeAdjustPolicy.AdjustToContentsOnFirstShow)\n",
    "# main_graphics_layout_widget.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Preferred)\n",
    "# main_graphics_layout_widget.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Preferred)\n",
    "main_graphics_layout_widget.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bbe298",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_layout: pg.GraphicsLayout = active_2d_plot.plots.background_static_scroll_window_plot.parentWidget()\n",
    "static_children_bounding_rect = root_layout.childrenBoundingRect() # QRectF\n",
    "required_static_children_bounding_rect_height: float = static_children_bounding_rect.height()\n",
    "\n",
    "main_graphics_layout_widget.setMaximumHeight(required_static_children_bounding_rect_height)\n",
    "# main_graphics_layout_widget.setMaximumSize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5378254",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_docked_widget_container_parent_wrapper.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)\n",
    "dynamic_docked_widget_container.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b41680",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_static_scroll_plot_widget = active_2d_plot.plots.get('background_static_scroll_plot_widget', None) # PlotItem\n",
    "if background_static_scroll_plot_widget is not None:\n",
    "    background_static_scroll_plot_widget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009e00df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "background_static_scroll_window_plot = active_2d_plot.plots.get('background_static_scroll_window_plot', None) # PlotItem\n",
    "if background_static_scroll_window_plot is not None:\n",
    "    # background_static_scroll_window_plot # PlotItem\n",
    "    plot_data_item.setDownsampling(auto=True, ds=1, mode='subsample')\n",
    "    plot_data_item.setClipToView(True)\n",
    "    \n",
    "    # background_static_scroll_window_plot.setClipToView(True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cddd357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# background_static_scroll_window_plot.parent()\n",
    "background_static_scroll_window_plot.dataItems[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577cbb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preview_overview_scatter_plot = active_2d_plot.plots.get('preview_overview_scatter_plot', None) # ScatterPlotItem\n",
    "preview_overview_scatter_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d975c61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "debug_widget_geometry(preview_overview_scatter_plot, widget_name='preview_overview_scatter_plot')\n",
    "print_widget_hierarchy(preview_overview_scatter_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1525b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "main_plot_widget.scatterPlot().setClipToView(True) # Usually default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6932cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "main_content_splitter.size()\n",
    "main_content_splitter.sizes()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e19af68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.gui.Qt.TopLevelWindowHelper import print_widget_hierarchy\n",
    "\n",
    "print_widget_hierarchy(main_content_splitter, indent_level_chars='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9950a936",
   "metadata": {},
   "outputs": [],
   "source": [
    "required_static_children_bounding_rect_height: float = _get_required_static_layout_height(active_2d_plot=active_2d_plot)\n",
    "main_graphics_layout_widget.setMaximumHeight(required_static_children_bounding_rect_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac259d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: main_content_splitter\n",
    "\n",
    "original_sizes = np.array(main_content_splitter.sizes())\n",
    "original_sizes\n",
    "\n",
    "## INPUTS: required_static_children_bounding_rect_height\n",
    "extra_v_height = (original_sizes[-1] - required_static_children_bounding_rect_height)\n",
    "extra_v_height\n",
    "\n",
    "desired_sizes = deepcopy(original_sizes)\n",
    "desired_sizes[-1] = required_static_children_bounding_rect_height\n",
    "desired_sizes[0] = desired_sizes[0] + extra_v_height\n",
    "\n",
    "assert np.sum(desired_sizes) == np.sum(original_sizes)\n",
    "\n",
    "\n",
    "main_content_splitter.setSizes(desired_sizes.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655af96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_content_splitter.children()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed1caa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import Spike2DRaster\n",
    "from pyphoplacecellanalysis.GUI.Qt.SpikeRasterWindows.Spike3DRasterWindowWidget import Spike3DRasterWindowWidget\n",
    "from pyphoplacecellanalysis.GUI.Qt.PlaybackControls.Spike3DRasterBottomPlaybackControlBarWidget import Spike3DRasterBottomPlaybackControlBar\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import SynchronizedPlotMode\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.spike_raster_widgets import _setup_spike_raster_window_for_debugging\n",
    "\n",
    "all_global_menus_actionsDict, global_flat_action_dict, _all_outputs_dict = _setup_spike_raster_window_for_debugging(spike_raster_window, wants_docked_raster_window_track=True, enable_interval_overview_track=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f18a66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61246c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import SynchronizedPlotMode\n",
    "\n",
    "\n",
    "with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-prepare_pyqtgraph_rasterPlot_track_with_sync.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "    # _raster_overview_tracks_out_dict = active_2d_plot.prepare_pyqtgraph_rasterPlot_track(name_modifier_suffix='raster_overview', should_link_to_main_plot_widget=False, sync_mode=SynchronizedPlotMode.TO_GLOBAL_DATA, downsampling_rate=5)\n",
    "    _raster_overview_tracks_out_dict = active_2d_plot.prepare_pyqtgraph_rasterPlot_track(name_modifier_suffix='raster_overview', should_link_to_main_plot_widget=False, sync_mode=SynchronizedPlotMode.NO_SYNC, downsampling_rate=5)\n",
    "    raster_overview_dock_config, raster_overview_time_sync_pyqtgraph_widget, raster_overview_root_graphics_layout_widget, raster_overview_plot_item, raster_overview_display_outputs_tuple = _raster_overview_tracks_out_dict['rasters[raster_overview]']\n",
    "    active_2d_plot.sync_matplotlib_render_plot_widget('rasters[raster_overview]', sync_mode=SynchronizedPlotMode.NO_SYNC) # disable continued sync\n",
    "    \n",
    "    # _all_outputs_dict['_raster_tracks_out_dict'] = _raster_tracks_out_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87237fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a623c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.sync_matplotlib_render_plot_widget('rasters[raster_overview]', sync_mode=SynchronizedPlotMode.TO_GLOBAL_DATA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fdfc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(_raster_overview_tracks_out_dict.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d47ca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_overview_dock_config, raster_overview_time_sync_pyqtgraph_widget, raster_overview_root_graphics_layout_widget, raster_overview_plot_item, raster_overview_display_outputs_tuple = _raster_overview_tracks_out_dict['raster_overview']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9223c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add scroller:\n",
    "\n",
    "def _add_scroll_region(active_2d_plot, parent_plot, clipItem=None, should_connect=False):\n",
    "    \"\"\" adds the scroll region control to the specified raster plot\n",
    "    \n",
    "    scroll_window_region, _conn = _add_scroll_region(active_2d_plot, parent_plot=background_static_scroll_window_plot, clipItem=active_2d_plot.plots.preview_overview_scatter_plot)\n",
    "    \n",
    "    active_2d_plot.ui.scroll_window_region = scroll_window_region\n",
    "    \"\"\"\n",
    "    from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsObjects.CustomLinearRegionItem import CustomLinearRegionItem\n",
    "    if clipItem is None:\n",
    "        clipItem = active_2d_plot.plots.preview_overview_scatter_plot\n",
    "        \n",
    "    # linear_region_display_kwargs = dict(pen=pg.mkPen('#ffffff'), brush=pg.mkBrush('#f004'), hoverBrush=pg.mkBrush('#fff4'), hoverPen=pg.mkPen('#f00'))\n",
    "    # linear_region_display_kwargs = dict(pen=pg.mkPen('#1d0000f8', width=2), brush=pg.mkBrush('#00000090'), hoverBrush=pg.mkBrush('#fff40090'), hoverPen=pg.mkPen('#f00000ff', width=2.5))\n",
    "    # linear_region_display_kwargs = dict(pen=pg.mkPen('#1d0000f8'), brush=pg.mkBrush('#ffffff90'), hoverBrush=pg.mkBrush('#fff40090'), hoverPen=pg.mkPen('#fffffff4'))\n",
    "    linear_region_display_kwargs = dict(pen=pg.mkPen('#ffffffe2', width=1.0), brush=pg.mkBrush('#ffffff90'), hoverBrush=pg.mkBrush('#fff40090'), hoverPen=pg.mkPen('#ff0505f4', width=1.5))\n",
    "\n",
    "\t# Add the linear region overlay:\n",
    "    scroll_window_region = CustomLinearRegionItem(**linear_region_display_kwargs, clipItem=clipItem) # bound the LinearRegionItem to the plotted data\n",
    "    scroll_window_region.setObjectName('scroll_window_region')\n",
    "    scroll_window_region.setZValue(10)\n",
    "    \n",
    "    ## Set position from spikes_window:\n",
    "    confirmed_valid_window_start_t = active_2d_plot.spikes_window.total_data_start_time\n",
    "    if (active_2d_plot.spikes_window.window_duration == 0.0):\n",
    "        # invalid window length, just choose something reasonable the user can grab, say 5% of the total window data\n",
    "        total_data_duration = active_2d_plot.spikes_window.total_data_end_time - active_2d_plot.spikes_window.total_data_start_time\n",
    "        reasonable_active_window_duration = float(total_data_duration) * 0.05 # 5%\n",
    "        ## UGHH, it works but please note that the final window is actually going to be MORE than 5% of the total data duration because of the temporal_zoom_factor > 1.0. \n",
    "    else:\n",
    "        reasonable_active_window_duration = float(active_2d_plot.spikes_window.window_duration)        \n",
    "    # Compute the final reasonable window end_t:\n",
    "    confirmed_valid_window_end_t = confirmed_valid_window_start_t + reasonable_active_window_duration\n",
    "        \n",
    "    scroll_window_region.setRegion([confirmed_valid_window_start_t, confirmed_valid_window_end_t]) # adjust scroll control\n",
    "    \n",
    "    # Add the LinearRegionItem to the ViewBox, but tell the ViewBox to exclude this item when doing auto-range calculations.\n",
    "    parent_plot.addItem(scroll_window_region, ignoreBounds=True)\n",
    "    if should_connect:\n",
    "        _conn = scroll_window_region.sigRegionChanged.connect(active_2d_plot._Render2DScrollWindowPlot_on_linear_region_item_update)\n",
    "    else:\n",
    "        _conn = None\n",
    "        \n",
    "    return scroll_window_region, _conn\n",
    "\n",
    "\n",
    "# scroll_window_region, _conn = _add_scroll_region(active_2d_plot=active_2d_plot, parent_plot=background_static_scroll_window_plot, clipItem=active_2d_plot.plots.preview_overview_scatter_plot)\n",
    "\n",
    "scroll_window_region, _conn = _add_scroll_region(active_2d_plot=active_2d_plot, parent_plot=raster_overview_plot_item, clipItem=raster_overview_plot_item)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42f2298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scroll_window_region.remove()\n",
    "\n",
    "\n",
    "raster_overview_plot_item.removeItem(scroll_window_region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993a507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scroll_window_region.sigRegionChanged.disconnect(_conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd43fc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## teardown `background_static_scroll_window_plot`\n",
    "background_static_scroll_window_plot.hide()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c0c871",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.ui.scroll_window_region.disconnect()\n",
    "active_2d_plot.ui.scroll_window_region.hide()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b577453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOPS BETTER START COOKING'243_22562_220-pycharm-support-libs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0b3b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_plot_widget = _all_outputs_dict.get('main_plot_widget', None)\n",
    "if main_plot_widget is not None:\n",
    "    main_plot_widget.hide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a28499",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_window_container_layout = _all_outputs_dict.get('active_window_container_layout', None)\n",
    "if active_window_container_layout is not None:\n",
    "    active_window_container_layout.setVisible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c186676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_static_scroll_window_plot = _all_outputs_dict.get('background_static_scroll_window_plot', None)\n",
    "background_static_scroll_window_plot.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5f9dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_global_menus_actionsDict, global_flat_action_dict = spike_raster_window.build_all_menus_actions_dict()\n",
    "global_flat_action_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48715b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.decod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2bc7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add Renderables ____________________________________________________________________________________________________ #\n",
    "# add_renderables_menu = active_2d_plot.ui.menus.custom_context_menus.add_renderables[0].programmatic_actions_dict\n",
    "menu_commands = ['AddTimeIntervals.Replays', 'AddTimeIntervals.Laps', 'AddTimeIntervals.SessionEpochs'] # , 'AddTimeIntervals.SessionEpochs', 'AddTimeIntervals.PBEs', 'AddTimeIntervals.Ripples',\n",
    "for a_command in menu_commands:\n",
    "    assert a_command in global_flat_action_dict, f\"a_command: '{a_command}' is not present in global_flat_action_dict: {list(global_flat_action_dict.keys())}\"\n",
    "    # add_renderables_menu[a_command].trigger()\n",
    "    global_flat_action_dict[a_command].trigger()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae14b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feb774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccad938",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(spike_raster_window.spike_raster_plt_2d.params.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743a2479",
   "metadata": {},
   "outputs": [],
   "source": [
    "_raster_tracks_out_dict = active_2d_plot.prepare_pyqtgraph_rasterPlot_track(name_modifier_suffix='raster_window', should_link_to_main_plot_widget=False, )\n",
    "dock_config, time_sync_pyqtgraph_widget, raster_root_graphics_layout_widget, raster_plot_item, rasters_display_outputs_tuple = list(_raster_tracks_out_dict.values())[0]\n",
    "an_app, a_win, a_plots, a_plots_data = rasters_display_outputs_tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae4fada",
   "metadata": {},
   "outputs": [],
   "source": [
    "_interval_tracks_out_dict = active_2d_plot.prepare_pyqtgraph_intervalPlot_tracks(enable_interval_overview_track=True, should_remove_all_and_re_add=True, should_link_to_main_plot_widget=False)\n",
    "interval_window_dock_config, intervals_dock, intervals_time_sync_pyqtgraph_widget, intervals_root_graphics_layout_widget, intervals_plot_item = _interval_tracks_out_dict['intervals']\n",
    "if 'interval_overview' in _interval_tracks_out_dict:\n",
    "    interval_overview_window_dock_config, intervals_overview_dock, intervals_overview_time_sync_pyqtgraph_widget, intervals_overview_root_graphics_layout_widget, intervals_overview_plot_item = _interval_tracks_out_dict['interval_overview']\n",
    "    intervals_overview_plot_item.setXRange(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time, padding=0) ## global frame\n",
    "    # intervals_overview_time_sync_pyqtgraph_widget.setMaximumHeight(39)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f2fcb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a016e6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_dock.setMaximumHeight(39)\n",
    "intervals_overview_dock.setMaximumHeight(39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b35efdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals_time_sync_pyqtgraph_widget.setMaximumHeight(39)\n",
    "intervals_overview_time_sync_pyqtgraph_widget.setMaximumHeight(39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e413f522",
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_window = spike_raster_window.spikes_window # SpikesDataframeWindow; pyphoplacecellanalysis.General.Model.TimeWindow.TimeWindow\n",
    "spikes_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aded71e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.total_data_start_time\n",
    "spike_raster_window.total_data_end_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51bfa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.total_data_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2d9eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setXLink\n",
    "# a_win # CustomGraphicsLayoutWidget \n",
    "# time_sync_pyqtgraph_widget # PyqtgraphTimeSynchronizedWidget \n",
    "# raster_plot_item\n",
    "\n",
    "### Zoom to entire data time range:\n",
    "# active_2d_plot\n",
    "raster_plot_item.setXLink(None)\n",
    "raster_plot_item.setXRange(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time, padding=0) ## global frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c754c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_dock_ids_list = active_2d_plot.get_group_only_flat_dock_identifiers_list()\n",
    "leaf_dock_ids_list = active_2d_plot.get_leaf_only_flat_dock_identifiers_list()\n",
    "group_dock_ids_list\n",
    "\n",
    "\n",
    "group_dock_raw_identifiers_list = [v.lstrip('GROUP[').rstrip(']') for v in group_dock_ids_list] # 'GROUP[ContinuousDecode_0.03]' -> 'ContinuousDecode_0.03'\n",
    "group_dock_raw_identifiers_list\n",
    "# spike_raster_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb984228",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_group_container_id: str = group_dock_ids_list[0] # 'GROUP[ContinuousDecode_0.03]'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e70360",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dock_items_dict: Dict[str, List[Dock]] = active_2d_plot.get_dockGroup_dock_dict()\n",
    "grouped_dock_items_dict\n",
    "\n",
    "# {'ContinuousDecode_ - t_bin_size: 0.025': [<Dock ContinuousDecode_long_LR - t_bin_size: 0.025 (65, 200)>,\n",
    "#   <Dock ContinuousDecode_long_RL - t_bin_size: 0.025 (65, 200)>,\n",
    "#   <Dock ContinuousDecode_short_LR - t_bin_size: 0.025 (65, 200)>,\n",
    "#   <Dock ContinuousDecode_short_RL - t_bin_size: 0.025 (65, 200)>],\n",
    "#  'ContinuousDecode_0.03': [<Dock DirectionalDecodersDecoded[long_LR]0.03 (65, 200)>,\n",
    "#   <Dock DirectionalDecodersDecoded[long_RL]0.03 (65, 200)>,\n",
    "#   <Dock DirectionalDecodersDecoded[short_LR]0.03 (65, 200)>,\n",
    "#   <Dock DirectionalDecodersDecoded[short_RL]0.03 (65, 200)>]}\n",
    "\n",
    "a_group_container_id: str = group_dock_ids_list[0]\n",
    "a_group_id: str = group_dock_raw_identifiers_list[0]\n",
    "flat_group_dockitems_list: List[Dock] = grouped_dock_items_dict[a_group_id]\n",
    "flat_group_dockitems_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba94a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup children:\n",
    "for a_dock in flat_group_dockitems_list:\n",
    "    # a_dock_identifier: str = a_dock.name()\n",
    "    # ## format nested child docks:\n",
    "    # a_dock.config.showCloseButton = False\n",
    "    # a_dock.config.showCollapseButton = False\n",
    "    # a_dock.config.showGroupButton = False\n",
    "    # a_dock.config.corner_radius='0px'\n",
    "    # a_dock.updateStyle()\n",
    "    active_2d_plot.dock_manager_widget.displayDockArea.addDock(dock=a_dock) ## move the dock items as children to the new container\n",
    "    # active_2d_plot.displayDockArea.moveDock(\n",
    "    # nested_dynamic_docked_widget_container.displayDockArea.addDock(dock=a_dock) ## move the dock items as children to the new container\n",
    "    \n",
    "## remove the group\n",
    "active_2d_plot.dock_manager_widget.remove_display_dock(identifier=a_group_container_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d570e8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.dock_manager_widget.unwrap_docks_in_nested_dock_area(dock_group_name='ContinuousDecode_0.03')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fa4144",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dock all Grouped results from `'DockedWidgets.Pseudo2DDecodedEpochsDockedMatplotlibView'`\n",
    "## INPUTS: active_2d_plot\n",
    "nested_dock_items, nested_dynamic_docked_widget_container_widgets = active_2d_plot.ui.dynamic_docked_widget_container.layout_dockGroups()\n",
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()\n",
    "## OUTPUTS: nested_dock_items, nested_dynamic_docked_widget_container_widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8362a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import add_continuous_decoded_posterior\n",
    "\n",
    "(nested_dock_items, nested_dynamic_docked_widget_container_widgets), (a_continuously_decoded_dict, pseudo2D_decoder, all_directional_pf1D_Decoder_dict) = add_continuous_decoded_posterior(spike_raster_window=spike_raster_window, curr_active_pipeline=curr_active_pipeline, desired_time_bin_size=0.05, debug_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967df72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Increase the window duration centered\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import plot_attached_BinByBinDecodingDebugger\n",
    "\n",
    "## INPUTS: a_decoder, a_decoded_result\n",
    "win, out_pf1D_decoder_template_objects, (plots_container, plots_data), _on_update_fcn = plot_attached_BinByBinDecodingDebugger(spike_raster_window, curr_active_pipeline, a_decoder=a_decoder, a_decoded_result=a_decoded_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62a8afa",
   "metadata": {
    "tags": [
     "active-2025-02-25"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import plot_attached_BinByBinDecodingDebugger\n",
    "## Plot one of the continuous results for the most recently computed time_bin_size:\n",
    "\n",
    "\n",
    "# all_directional_pf1D_Decoder_dict\n",
    "a_decoder_name: str = 'long'\n",
    "a_decoder = results1D.decoders[a_decoder_name]\n",
    "a_decoded_result = results1D.continuous_results[a_decoder_name]\n",
    "\n",
    "## INPUTS: a_decoder, a_decoded_result\n",
    "win, out_pf1D_decoder_template_objects, (plots_container, plots_data), _on_update_fcn = plot_attached_BinByBinDecodingDebugger(spike_raster_window, curr_active_pipeline, a_decoder=a_decoder, a_decoded_result=a_decoded_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a20a893",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_main_raster_plot: bool = (active_2d_plot.plots.main_plot_widget is not None)\n",
    "_raster_tracks_out_dict = active_2d_plot.prepare_pyqtgraph_rasterPlot_track(name_modifier_suffix='raster_window', should_link_to_main_plot_widget=has_main_raster_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcbc56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.External.pyqtgraph.dockarea.Dock import Dock, DockDisplayConfig\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import FigureWidgetDockDisplayConfig\n",
    "\n",
    "flat_dock_item_tuple_dict: Dict[str, Tuple] = active_2d_plot.get_flat_dock_item_tuple_dict()\n",
    "group_only_flat_dockwidgets_dict = {k:a_widget for k, (a_dock, a_widget) in flat_dock_item_tuple_dict.items() if ('GROUP' == a_dock.config.additional_metadata.get('type', 'LEAF')) }\n",
    "leaf_only_flat_dockwidgets_dict = {k:a_widget for k, (a_dock, a_widget) in flat_dock_item_tuple_dict.items() if ('LEAF' == a_dock.config.additional_metadata.get('type', 'LEAF')) }\n",
    "group_only_flat_dockwidgets_dict\n",
    "leaf_only_flat_dockwidgets_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea403e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "active_2d_plot.get_flat_dockitems_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff28fdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import AddNewDecodedPosteriors_MatplotlibPlotCommand\n",
    "from pyphoplacecellanalysis.External.pyqtgraph.dockarea.Dock import Dock, DockDisplayConfig\n",
    "\n",
    "flat_dock_item_tuple_dict: Dict[str, Tuple] = active_2d_plot.get_flat_dock_item_tuple_dict()\n",
    "flat_dock_item_tuple_dict\n",
    "\n",
    "# flat_docks_dict = {k:a_dock for k, (a_dock, a_widget) in flat_dock_item_tuple_dict.items() if ('ContinuousDecode_ - t_bin_size: 0.025' in a_dock.config.dock_group_names) }\n",
    "flat_dockwidgets_dict = {k:a_widget for k, (a_dock, a_widget) in flat_dock_item_tuple_dict.items() if ('ContinuousDecode_ - t_bin_size: 0.025' in a_dock.config.dock_group_names) }\n",
    "flat_dockwidgets_dict\n",
    "\n",
    "# flat_dock_item_tuple_dict = {k:a_widget if a_dock.grou for k, (a_dock, a_widget) in flat_dock_item_tuple_dict.items()}\n",
    "\n",
    "# flat_dockwidgets_list = active_2d_plot.get_flat_widgets_list()\n",
    "# flat_dockwidgets_list\n",
    "# active_2d_plot.get_dock_groups()\n",
    "\n",
    "_all_tracks_out_artists = {}\n",
    "for k, a_widget in flat_dockwidgets_dict.items():\n",
    "    _out_artists = AddNewDecodedPosteriors_MatplotlibPlotCommand._perform_overlay_measured_position(identifier_name=k, widget=a_widget, matplotlib_fig=a_widget.fig, matplotlib_fig_axes=a_widget.axes, measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()))\n",
    "    _all_tracks_out_artists[k] = _out_artists\n",
    "    a_widget.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8fc993",
   "metadata": {},
   "outputs": [],
   "source": [
    "_all_tracks_out_artists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8580701",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, a_widget in flat_dockwidgets_dict.items():\n",
    "    a_widget.plots.measured_position_artists = _all_tracks_out_artists[k]\n",
    "    \n",
    "    # a_widget.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21b7f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "bottom_playback_control_bar_widget = spike_raster_window.bottom_playback_control_bar_widget # Spike3DRasterBottomPlaybackControlBar \n",
    "comboActiveJumpTargetSeries = bottom_playback_control_bar_widget.ui.comboActiveJumpTargetSeries # QComboBox \n",
    "comboActiveJumpTargetSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd1d42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Dock all Grouped results from `'DockedWidgets.Pseudo2DDecodedEpochsDockedMatplotlibView'`\n",
    "## INPUTS: active_2d_plot\n",
    "nested_dock_items, nested_dynamic_docked_widget_container_widgets = active_2d_plot.ui.dynamic_docked_widget_container.layout_dockGroups()\n",
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()\n",
    "## OUTPUTS: nested_dock_items, nested_dynamic_docked_widget_container_widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191b20f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()\n",
    "grouped_dock_items_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8084d27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.ui.dynamic_docked_widget_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53ed9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.NestedDockAreaWidget import NestedDockAreaWidget\n",
    "\n",
    "dock_manager_widget: NestedDockAreaWidget = active_2d_plot.dock_manager_widget\n",
    "grouped_dock_items_dict = dock_manager_widget.get_dockGroup_dock_dict()\n",
    "grouped_dock_items_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3ee32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dock_items_dict = active_2d_plot.dock_manager_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c521a076",
   "metadata": {},
   "outputs": [],
   "source": [
    "comboActiveJumpTargetSeries.setCurrentText('Laps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5ebfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.Specific2DRenderTimeEpochs import General2DRenderTimeEpochs, Replays_2DRenderTimeEpochs, Ripples_2DRenderTimeEpochs, SessionEpochs2DRenderTimeEpochs, PBE_2DRenderTimeEpochs, Laps2DRenderTimeEpochs, SpikeBurstIntervals_2DRenderTimeEpochs, NewNonPBE_2DRenderTimeEpochs # Time Intervals/Epochs\n",
    "\n",
    "background_static_scroll_window_plot = active_2d_plot.plots.background_static_scroll_window_plot # PlotItem\n",
    "main_plot_widget = active_2d_plot.plots.main_plot_widget # PlotItem\n",
    "\n",
    "for an_interval_rendering_plot in active_2d_plot.interval_rendering_plots:\n",
    "    _out = NewNonPBE_2DRenderTimeEpochs.add_render_time_epochs(curr_sess=curr_active_pipeline.sess.non_pbe, destination_plot=an_interval_rendering_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f45c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.params.debug_print = True\n",
    "spike_raster_window.enable_debug_print = True\n",
    "active_2d_plot.params.debug_print = True\n",
    "# active_2d_plot.debug_print = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61371822",
   "metadata": {},
   "outputs": [],
   "source": [
    "extant_conn = spike_raster_window.ui.additional_connections.get('spike_3d_to_2d_window_crosshair_connection', None)\n",
    "extant_conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7200fc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.ui.left_side_bar_connections = spike_raster_window.SpikeRasterLeftSidebarControlsMixin_connectSignals(spike_raster_window.ui.leftSideToolbarWidget)\n",
    "spike_raster_window.ui.left_side_bar_connections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0491ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fix window title to display the session context post-hoc\n",
    "desired_window_title: str = curr_active_pipeline.get_complete_session_identifier_string() # 'kdiba_gor01_two_2006-6-07_16-40-19__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 8, 9]-frateThresh_5.0'\n",
    "spike_raster_window.window().setWindowTitle(desired_window_title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b12684",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.params.is_crosshair_trace_enabled = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c0c6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_crosshairs to `active_2d_plot`\n",
    "active_time_sync_pyqtgraph_widgets: Dict[str, PyqtgraphTimeSynchronizedWidget] = {identifier:active_matplotlib_view_widget for identifier, active_matplotlib_view_widget in active_2d_plot.ui.matplotlib_view_widgets.items() if active_matplotlib_view_widget.is_pyqtgraph_based()}\n",
    "active_time_sync_pyqtgraph_widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da93cc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_name, a_time_sync_widget in active_2d_plot.ui.matplotlib_view_widgets.items():\n",
    "    print(f'a_name: {a_name}')\n",
    "    # a_time_sync_widget.plots_data\n",
    "    a_time_sync_widget.plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd315de",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_side_bar_controls = spike_raster_window.ui.leftSideToolbarWidget\n",
    "left_side_bar_controls.crosshair_trace_time = \"test\"\n",
    "\n",
    "left_side_bar_controls.ui.lblCrosshairTraceStaticLabel.setVisible(True)\n",
    "left_side_bar_controls.ui.lblCrosshairTraceValue.setVisible(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d4effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.PyQtPlots.TimeSynchronizedPlotters.PyqtgraphTimeSynchronizedWidget import PyqtgraphTimeSynchronizedWidget\n",
    "\n",
    "def on_crosshair_updated_signal(self, name, trace_value):\n",
    "    print(f'on_crosshair_updated_signal(self: {self}, name: \"{name}\", trace_value: \"{trace_value}\")')\n",
    "    left_side_bar_controls = spike_raster_window.ui.leftSideToolbarWidget\n",
    "    left_side_bar_controls.crosshair_trace_time = trace_value\n",
    "    \n",
    "    # self.ui.lblCrosshairTraceStaticLabel.setVisible(True)\n",
    "    # self.ui.lblCrosshairTraceValue.setVisible(True)\n",
    "\n",
    "\n",
    "for a_name, a_time_sync_widget in active_2d_plot.ui.matplotlib_view_widgets.items():\n",
    "    print(f'a_name: {a_name}')\n",
    "    try:\n",
    "        a_time_sync_widget.update_crosshair_trace(wants_crosshairs_trace=True)\n",
    "        a_time_sync_widget.sigCrosshairsUpdated.connect(on_crosshair_updated_signal)\n",
    "    except KeyError as e:\n",
    "        # KeyError: 'connections'\n",
    "        pass\n",
    "        print(f'\\tfailed.')\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6843c773",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_time_sync_pyqtgraph_widgets['new_curves_separate_plot'].update_crosshair_trace(wants_crosshairs_trace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76ab4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277a736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4254723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(spike_raster_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05d7666",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.plots.main_plot_widget\n",
    "\n",
    "main_plot_widget = active_2d_plot.plots.main_plot_widget # PlotItem\n",
    "main_plot_widget.setMinimumHeight(20.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9cf1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_window_container_layout\n",
    "# main_graphics_layout_widget.ci # GraphicsLayout\n",
    "main_graphics_layout_widget.ci.childItems()\n",
    "# main_graphics_layout_widget.setHidden(True) ## hides too much\n",
    "main_graphics_layout_widget.setHidden(False)\n",
    "\n",
    "# main_graphics_layout_widget\n",
    "\n",
    "active_window_container_layout.setBorder(pg.mkPen('yellow', width=4.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7399378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# active_window_container_layout.allChildItems()\n",
    "active_window_container_layout.setPreferredHeight(200.0)\n",
    "active_window_container_layout.setMaximumHeight(800.0)\n",
    "active_window_container_layout.setSpacing(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a6aaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set stretch factors to control priority\n",
    "main_graphics_layout_widget.ci.layout.setRowStretchFactor(0, 400)  # Plot1: lowest priority\n",
    "main_graphics_layout_widget.ci.layout.setRowStretchFactor(1, 2)  # Plot2: mid priority\n",
    "main_graphics_layout_widget.ci.layout.setRowStretchFactor(2, 2)  # Plot3: highest priority\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5f61dd",
   "metadata": {
    "tags": [
     "_perform_plot_multi_decoder_meas_pred_position_track",
     "active-2025-01-16"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalDecodersContinuouslyDecodedResult\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import SynchronizedPlotMode\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_1D_most_likely_position_comparsions\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DecoderIdentityColors\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_plot_multi_decoder_meas_pred_position_track\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "\n",
    "## Build the new dock track:\n",
    "dock_identifier: str = 'Continuous Decoding Performance'\n",
    "ts_widget, fig, ax, dDisplayItem = active_2d_plot.add_new_matplotlib_render_plot_widget(name=dock_identifier)\n",
    "\n",
    "## Get the needed data:\n",
    "directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "previously_decoded_keys: List[float] = list(continuously_decoded_result_cache_dict.keys()) # [0.03333]\n",
    "print(F'previously_decoded time_bin_sizes: {previously_decoded_keys}')\n",
    "\n",
    "time_bin_size: float = directional_decoders_decode_result.most_recent_decoding_time_bin_size\n",
    "print(f'time_bin_size: {time_bin_size}')\n",
    "continuously_decoded_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_decode_result.most_recent_continuously_decoded_dict\n",
    "all_directional_continuously_decoded_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = {k:v for k, v in (continuously_decoded_dict or {}).items() if k in TrackTemplates.get_decoder_names()} ## what is plotted in the `f'{a_decoder_name}_ContinuousDecode'` rows by `AddNewDirectionalDecodedEpochs_MatplotlibPlotCommand`\n",
    "## OUT: all_directional_continuously_decoded_dict\n",
    "## Draw the position meas/decoded on the plot widget\n",
    "## INPUT: fig, ax_list, all_directional_continuously_decoded_dict, track_templates\n",
    "\n",
    "_out_artists =  _perform_plot_multi_decoder_meas_pred_position_track(curr_active_pipeline, fig, ax_list, desired_time_bin_size=1.0, enable_flat_line_drawing=True)\n",
    "\n",
    "## sync up the widgets\n",
    "active_2d_plot.sync_matplotlib_render_plot_widget(dock_identifier, sync_mode=SynchronizedPlotMode.TO_WINDOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b589d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Need to figure out what the heck is going on, why are they all decoding to the same position?\n",
    "curr_active_pipeline.find_validators_providing_results(probe_provided_result_keys=['DirectionalDecodersDecoded'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb84d393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders'] # uses `DirectionalMergedDecoders`.\n",
    "\n",
    "# all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_merged_decoders_result.all_directional_decoder_dict # This does not work, because the values in the returned dictionary are PfND, not 1D decoders\n",
    "all_directional_pf1D_Decoder_value = directional_merged_decoders_result.all_directional_pf1D_Decoder\n",
    "\n",
    "pseudo2D_decoder: BasePositionDecoder = all_directional_pf1D_Decoder_value\n",
    "pseudo2D_decoder.xbin_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6256a7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder2D_result: DecodedFilterEpochsResult = continuously_decoded_dict['pseudo2D']\n",
    "decoder2D_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcd9f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder2D_result.filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a618e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_name:types.DecoderName = 'long_LR'\n",
    "\n",
    "\n",
    "result: DecodedFilterEpochsResult = all_directional_continuously_decoded_dict[decoder_name]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5477803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.binning_helpers import BinningContainer\n",
    "\n",
    "time_binning_container: BinningContainer = result.time_bin_containers[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd34e905",
   "metadata": {},
   "outputs": [],
   "source": [
    "marginals_out = result.compute_marginals()\n",
    "marginals_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677f13f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_x_given_n = result.p_x_given_n_list[0]\n",
    "p_x_given_n.shape # (63, 36101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1dbc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow, LayoutScrollability\n",
    "\n",
    "out = BasicBinnedImageRenderingWindow(p_x_given_n.T, xbins=time_binning_container.centers, ybins=pseudo2D_decoder.xbin_centers, name='p_x_given_n', title=\"Continuously Decoded Position Posterior\", variable_label='p_x_given_n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38325e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df['truth_decoder_name'] = pos_df['truth_decoder_name'].fillna('')\n",
    "pos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bed9c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_color_dict: Dict[types.DecoderName, str] = DecoderIdentityColors.build_decoder_color_dict()\n",
    "\n",
    "decoded_pos_line_kwargs = dict(lw=1.0, color='gray', alpha=0.8, marker='+', markersize=6, animated=False)\n",
    "inactive_decoded_pos_line_kwargs = dict(lw=0.3, alpha=0.2, marker='.', markersize=2, animated=False)\n",
    "active_decoded_pos_line_kwargs = dict(lw=1.0, alpha=0.8, marker='+', markersize=6, animated=False)\n",
    "\n",
    "\n",
    "_out_data = {}\n",
    "_out_data_plot_kwargs = {}\n",
    "# curr_active_pipeline.global_computation_results.t\n",
    "for a_decoder_name, a_decoder in track_templates.get_decoders_dict().items():\n",
    "    a_continuously_decoded_result = all_directional_continuously_decoded_dict[a_decoder_name]\n",
    "    a_decoder_color = decoder_color_dict[a_decoder_name]\n",
    "    \n",
    "    assert len(a_continuously_decoded_result.p_x_given_n_list) == 1\n",
    "    p_x_given_n = a_continuously_decoded_result.p_x_given_n_list[0]\n",
    "    # p_x_given_n = a_continuously_decoded_result.p_x_given_n_list[0]['p_x_given_n']\n",
    "    time_bin_containers = a_continuously_decoded_result.time_bin_containers[0]\n",
    "    time_window_centers = time_bin_containers.centers\n",
    "    # p_x_given_n.shape # (62, 4, 209389)\n",
    "    a_marginal_x = a_continuously_decoded_result.marginal_x_list[0]\n",
    "    # active_time_window_variable = a_decoder.active_time_window_centers\n",
    "    active_time_window_variable = time_window_centers\n",
    "    active_most_likely_positions_x = a_marginal_x['most_likely_positions_1D'] # a_decoder.most_likely_positions[:,0].T\n",
    "    _out_data[a_decoder_name] = pd.DataFrame({'t': time_window_centers, 'x': active_most_likely_positions_x, 'binned_time': np.arange(len(time_window_centers))})\n",
    "    _out_data[a_decoder_name] = _out_data[a_decoder_name].position.adding_lap_info(laps_df=laps_df, inplace=False)\n",
    "    _out_data[a_decoder_name] = _out_data[a_decoder_name].time_point_event.adding_true_decoder_identifier(t_start=t_start, t_delta=t_delta, t_end=t_end) ## ensures ['maze_id', 'is_LR_dir']\n",
    "    _out_data[a_decoder_name]['is_active_decoder_time'] = (_out_data[a_decoder_name]['truth_decoder_name'].fillna('', inplace=False) == a_decoder_name)\n",
    "\n",
    "    # is_active_decoder_time = (_out_data[a_decoder_name]['truth_decoder_name'] == a_decoder_name)\n",
    "    active_decoder_time_points = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] == a_decoder_name]['t'].to_numpy()\n",
    "    active_decoder_most_likely_positions_x = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] == a_decoder_name]['x'].to_numpy()\n",
    "    active_decoder_inactive_time_points = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] != a_decoder_name]['t'].to_numpy()\n",
    "    active_decoder_inactive_most_likely_positions_x = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] != a_decoder_name]['x'].to_numpy()\n",
    "    ## could fill y with np.nan instead of getting shorter?\n",
    "    _out_data_plot_kwargs[a_decoder_name] = (dict(x=active_decoder_time_points, y=active_decoder_most_likely_positions_x, color=a_decoder_color, **active_decoded_pos_line_kwargs), dict(x=active_decoder_inactive_time_points, y=active_decoder_inactive_most_likely_positions_x, color=a_decoder_color, **inactive_decoded_pos_line_kwargs))\n",
    "\n",
    "_out_data_plot_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8972db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _out_data[a_decoder_name] = _out_data[a_decoder_name].position.adding_lap_info(laps_df=laps_df, inplace=False)\n",
    "# _out_data[a_decoder_name] = _out_data[a_decoder_name].time_point_event.adding_true_decoder_identifier(t_start=t_start, t_delta=t_delta, t_end=t_end) ## ensures ['maze_id', 'is_LR_dir']\n",
    "\n",
    "# is_active_decoder_time = (_out_data[a_decoder_name]['truth_decoder_name'] == a_decoder_name)\n",
    "active_decoder_time_points = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] == a_decoder_name]['t'].to_numpy()\n",
    "active_decoder_most_likely_positions_x = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] == a_decoder_name]['x'].to_numpy()\n",
    "active_decoder_inactive_time_points = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] != a_decoder_name]['t'].to_numpy()\n",
    "active_decoder_inactive_most_likely_positions_x = _out_data[a_decoder_name][_out_data[a_decoder_name]['truth_decoder_name'] != a_decoder_name]['x'].to_numpy()\n",
    "\n",
    "_out_data[a_decoder_name] = ((active_decoder_time_points, active_decoder_most_likely_positions_x), (active_decoder_inactive_time_points, active_decoder_inactive_most_likely_positions_x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dd7358",
   "metadata": {},
   "outputs": [],
   "source": [
    "partitioned_dfs = partition_df_dict(pos_df, partitionColumn='truth_decoder_name')\n",
    "\n",
    "a_decoder_name: str = 'short_LR'\n",
    "a_binned_time_grouped_df = partitioned_dfs[a_decoder_name].groupby('binned_time', axis='index', dropna=True)\n",
    "a_binned_time_grouped_df = a_binned_time_grouped_df.median().dropna(axis='index', subset=['x']) ## without the `.dropna(axis='index', subset=['x'])` part it gets an exhaustive df for all possible values of 'binned_time', even those not listed\n",
    "\n",
    "a_matching_binned_times = a_binned_time_grouped_df.reset_index(drop=False)['binned_time']\n",
    "a_matching_binned_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f61fd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "## split into two dfs for each decoder -- the supported and the unsupported\n",
    "partition\n",
    "\n",
    "PandasHelpers.safe_pandas_get_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f2e753",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df.dropna(axis='index', subset=['lap', 'truth_decoder_name'], inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604e0329",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_df: pd.DataFrame = global_laps_obj.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990b67c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import find_epochs_overlapping_other_epochs\n",
    "\n",
    "## INPUTS: global_laps\n",
    "_out_split_pseudo2D_posteriors_dict = {}\n",
    "_out_split_pseudo2D_out_dict = {}\n",
    "pre_filtered_col_names = ['pre_filtered_most_likely_position_indicies', 'pre_filtered_most_likely_position'] # 'pre_filtered_time_bin_containers', 'pre_filtered_p_x_given_n', \n",
    "post_filtered_col_names = [a_col_name.removeprefix('pre_filtered_') for a_col_name in pre_filtered_col_names] # ['time_bin_containers', 'most_likely_position_indicies', 'most_likely_position']\n",
    "print(post_filtered_col_names)\n",
    "for a_time_bin_size, pseudo2D_decoder_continuously_decoded_result in continuously_decoded_pseudo2D_decoder_dict.items():\n",
    "    print(f'a_time_bin_size: {a_time_bin_size}')\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size] = {'pre_filtered_p_x_given_n': None, 'pre_filtered_time_bin_containers': None, 'pre_filtered_most_likely_position_indicies': None, 'pre_filtered_most_likely_position': None, \n",
    "                                                     'is_timebin_included': None, 'p_x_given_n': None} # , 'time_window_centers': None\n",
    "    # pseudo2D_decoder_continuously_decoded_result: DecodedFilterEpochsResult = continuously_decoded_dict.get('pseudo2D', None)\n",
    "    assert len(pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list) == 1\n",
    "    p_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0]\n",
    "    # p_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0]['p_x_given_n']\n",
    "    time_bin_containers = pseudo2D_decoder_continuously_decoded_result.time_bin_containers[0]\n",
    "    # time_window_centers = time_bin_containers.centers\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position_indicies'] = deepcopy(pseudo2D_decoder_continuously_decoded_result.most_likely_position_indicies_list[0])\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position'] = deepcopy(pseudo2D_decoder_continuously_decoded_result.most_likely_positions_list[0])\n",
    "    ## INPUTS: time_bin_containers, global_laps\n",
    "    left_edges = deepcopy(time_bin_containers.left_edges)\n",
    "    right_edges = deepcopy(time_bin_containers.right_edges)\n",
    "    continuous_time_binned_computation_epochs_df: pd.DataFrame = pd.DataFrame({'start': left_edges, 'stop': right_edges, 'label': np.arange(len(left_edges))})\n",
    "    is_timebin_included: NDArray = find_epochs_overlapping_other_epochs(epochs_df=continuous_time_binned_computation_epochs_df, epochs_df_required_to_overlap=deepcopy(global_laps))\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_p_x_given_n'] = p_x_given_n\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_time_bin_containers'] = time_bin_containers\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['is_timebin_included'] = is_timebin_included\n",
    "    # continuous_time_binned_computation_epochs_df['is_in_laps'] = is_timebin_included\n",
    "    ## filter by whether it's included or not:\n",
    "    p_x_given_n = p_x_given_n[:, :, is_timebin_included]\n",
    "    # time_window_centers = \n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['p_x_given_n'] = p_x_given_n\n",
    "    # _out_split_pseudo2D_out_dict[a_time_bin_size]['time_window_centers'] = time_window_centers[is_timebin_included]\n",
    "    # p_x_given_n.shape # (62, 4, 209389)\n",
    "\n",
    "    ## Split across the 2nd axis to make 1D posteriors that can be displayed in separate dock rows:\n",
    "    assert p_x_given_n.shape[1] == 4, f\"expected the 4 pseudo-y bins for the decoder in p_x_given_n.shape[1]. but found p_x_given_n.shape: {p_x_given_n.shape}\"\n",
    "    # split_pseudo2D_posteriors_dict = {k:np.squeeze(p_x_given_n[:, i, :]) for i, k in enumerate(('long_LR', 'long_RL', 'short_LR', 'short_RL'))}\n",
    "    _out_split_pseudo2D_posteriors_dict[a_time_bin_size] = deepcopy(p_x_given_n)\n",
    "    \n",
    "    # for a_col_name in pre_filtered_col_names:\n",
    "    #     filtered_col_name = a_col_name.removeprefix('pre_filtered_')\n",
    "    #     print(f'a_col_name: {a_col_name}, filtered_col_name: {filtered_col_name}, shape: {np.shape(_out_split_pseudo2D_out_dict[a_time_bin_size][a_col_name])}')\n",
    "    #     _out_split_pseudo2D_out_dict[a_time_bin_size][filtered_col_name] = _out_split_pseudo2D_out_dict[a_time_bin_size][a_col_name][is_timebin_included, :]\n",
    "        \n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['most_likely_position_indicies'] = _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position_indicies'][:, is_timebin_included]\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['most_likely_position'] = _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position'][is_timebin_included, :]\n",
    "    \n",
    "\n",
    "p_x_given_n.shape # (n_position_bins, n_decoding_models, n_time_bins) - (57, 4, 29951)\n",
    "\n",
    "## OUTPUTS: _out_split_pseudo2D_posteriors_dict, _out_split_pseudo2D_out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d25155",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_most_likely_position_comparsions\n",
    "\n",
    "# fig, axs = plot_most_likely_position_comparsions(pho_custom_decoder, axs=ax, sess.position.to_dataframe())\n",
    "fig, axs = plot_most_likely_position_comparsions(computation_result.computed_data['pf2D_Decoder'], computation_result.sess.position.to_dataframe(), **overriding_dict_with(lhs_dict={'show_posterior':True, 'show_one_step_most_likely_positions_plots':True}, **kwargs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0cf8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93036009",
   "metadata": {},
   "source": [
    "### <a id='toc7_1_2_'></a>[🔝 Dock Track Widgets](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67f05bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.add_new_embedded_pyqtgraph_render_plot_widget("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f78e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_main_raster_plot = False\n",
    "_interval_tracks_out_dict = active_2d_plot.prepare_pyqtgraph_intervalPlot_tracks(enable_interval_overview_track=False, should_link_to_main_plot_widget=has_main_raster_plot)\n",
    "interval_window_dock_config, interval_dock_item, intervals_time_sync_pyqtgraph_widget, intervals_root_graphics_layout_widget, intervals_plot_item = _interval_tracks_out_dict['intervals']\n",
    "# dock_config, interval_overview_dock_item, intervals_overview_time_sync_pyqtgraph_widget, intervals_overview_root_graphics_layout_widget, intervals_overview_plot_item = _interval_tracks_out_dict['interval_overview']\n",
    "interval_window_dock_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2042a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_dock_item.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cc9d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval_dock_item.setMaximumHeight(89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9865df",
   "metadata": {},
   "outputs": [],
   "source": [
    "_interval_tracks_out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4637029",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.dock_manager_widget.add_display_dock("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9f3acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.get_flat_dockitems_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f946a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.layout_dockGroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb8dc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.get_group_only_flat_dock_identifiers_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d822fa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.get_leaf_only_flat_dock_identifiers_list()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd739ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_dock in active_2d_plot.get_flat_dockitems_list():\n",
    "    a_dock.showTitleBar()\n",
    "    # a_dock.updateStyle()\n",
    "    a_dock.config\n",
    "    a_dock.setOrientation('horizontal', force=True)\n",
    "    a_dock.updateStyle()\n",
    "    a_dock.update() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f51940",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dock Tree Widget should register with `dock_manager_widget` (DynamicDockDisplayAreaContentMixin) so that it recieves and issues updates when dock items are added/changed/closed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fc1767",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import DockDisplayColors, CustomDockDisplayConfig\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.NestedDockAreaWidget import NestedDockAreaWidget\n",
    "\n",
    "name='group_dock_widget'\n",
    "dockSize=(500,50*4)\n",
    "dockAddLocationOpts=['bottom']\n",
    "\n",
    "display_config = CustomDockDisplayConfig(showCloseButton=True, showCollapseButton=True, showGroupButton=True, orientation='horizontal')\n",
    "## Add the container to hold dynamic matplotlib plot widgets:\n",
    "nested_dynamic_docked_widget_container = NestedDockAreaWidget()\n",
    "nested_dynamic_docked_widget_container.setObjectName(\"nested_dynamic_docked_widget_container\")\n",
    "nested_dynamic_docked_widget_container.setSizePolicy(pg.QtGui.QSizePolicy.Expanding, pg.QtGui.QSizePolicy.Preferred)\n",
    "nested_dynamic_docked_widget_container.setMinimumHeight(40)\n",
    "nested_dynamic_docked_widget_container.setContentsMargins(0, 0, 0, 0)\n",
    "_, dDisplayItem = active_2d_plot.ui.dynamic_docked_widget_container.add_display_dock(name, dockSize=dockSize, display_config=display_config, widget=nested_dynamic_docked_widget_container, dockAddLocationOpts=dockAddLocationOpts, autoOrientation=False)\n",
    "dDisplayItem.setOrientation('horizontal', force=True)\n",
    "dDisplayItem.updateStyle()\n",
    "dDisplayItem.update() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0aea9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_docked_widget_container: NestedDockAreaWidget  = active_2d_plot.ui.dynamic_docked_widget_container\n",
    "# dynamic_docked_widget_container.dynamic_display_dict\n",
    "\n",
    "name_list = ['intervals', 'rasters[raster_window]', 'new_curves_separate_plot']\n",
    "for a_name in name_list:\n",
    "    a_dock = dynamic_docked_widget_container.find_display_dock(a_name)\n",
    "    a_dock\n",
    "    a_dock.hideTitleBar()\n",
    "    # a_dock.labelHidden = True\n",
    "    a_dock.updateStyle()\n",
    "    \n",
    "\n",
    "\n",
    "# dynamic_docked_widget_container.find_display_dock('intervals').hideTitleBar()\n",
    "# dynamic_docked_widget_container.find_display_dock('rasters[raster_window]').hideTitleBar()\n",
    "# dynamic_docked_widget_container.find_display_dock('new_curves_separate_plot').hideTitleBar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9939b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_print_dock_sizes(active_2d_plot):\n",
    "    \"\"\" prints the size variables for each Dock item \n",
    "    \"\"\"\n",
    "    from pyphoplacecellanalysis.General.Mixins.DisplayHelpers import debug_widget_geometry\n",
    "\n",
    "    flat_dockitems_list = active_2d_plot.ui.dynamic_docked_widget_container.get_flat_dockitems_list()\n",
    "    for a_dock in flat_dockitems_list:\n",
    "        print(f'a_dock: {a_dock}')\n",
    "        debug_widget_geometry(a_dock)\n",
    "        \n",
    "    print('\\tdone.')\n",
    "        \n",
    "\n",
    "debug_print_dock_sizes(active_2d_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c932dcce",
   "metadata": {
    "tags": [
     "dock-widgets"
    ]
   },
   "outputs": [],
   "source": [
    "flat_widgets_list = active_2d_plot.ui.dynamic_docked_widget_container.get_flat_widgets_list()\n",
    "flat_dockitems_list = active_2d_plot.ui.dynamic_docked_widget_container.get_flat_dockitems_list()\n",
    "flat_dock_identifiers_list = active_2d_plot.ui.dynamic_docked_widget_container.get_flat_dock_identifiers_list()\n",
    "# flat_dockitems_list\n",
    "flat_dock_identifiers_list\n",
    "# flat_widgets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03657d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "rasters_dock = active_2d_plot.ui.dynamic_docked_widget_container.find_display_dock('rasters[raster_window]')\n",
    "rasters_dock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98199475",
   "metadata": {},
   "outputs": [],
   "source": [
    "rasters_dock.stretch()\n",
    "rasters_dock.setStretch(y=240)\n",
    "rasters_dock.stretch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4405ffad",
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_dock_items = {}\n",
    "nested_dynamic_docked_widget_container_widgets = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fd4da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()\n",
    "# flat_widgets_list = active_2d_plot.ui.dynamic_docked_widget_container.get_flat_widgets_list()\n",
    "# dock_group_name: str = 'ContinuousDecode_ - t_bin_size: 0.025'\n",
    "dock_group_name: str = 'ContinuousDecode_ - t_bin_size: 0.05'\n",
    "flat_group_dockitems_list = grouped_dock_items_dict[dock_group_name]\n",
    "dDisplayItem, nested_dynamic_docked_widget_container = active_2d_plot.ui.dynamic_docked_widget_container.build_wrapping_nested_dock_area(flat_group_dockitems_list, dock_group_name=dock_group_name)\n",
    "nested_dock_items[dock_group_name] = dDisplayItem\n",
    "nested_dynamic_docked_widget_container_widgets[dock_group_name] = nested_dynamic_docked_widget_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432310ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: active_2d_plot\n",
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()\n",
    "nested_dock_items = {}\n",
    "nested_dynamic_docked_widget_container_widgets = {}\n",
    "for dock_group_name, flat_group_dockitems_list in grouped_dock_items_dict.items():\n",
    "    dDisplayItem, nested_dynamic_docked_widget_container = active_2d_plot.ui.dynamic_docked_widget_container.build_wrapping_nested_dock_area(flat_group_dockitems_list, dock_group_name=dock_group_name)\n",
    "    nested_dock_items[dock_group_name] = dDisplayItem\n",
    "    nested_dynamic_docked_widget_container_widgets[dock_group_name] = nested_dynamic_docked_widget_container\n",
    "\n",
    "## OUTPUTS: nested_dock_items, nested_dynamic_docked_widget_container_widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d095b42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_wrapping_nested_dock_area\n",
    "\n",
    "dynamic_docked_widget_container = active_2d_plot.ui.dynamic_docked_widget_container # NestedDockAreaWidget \n",
    "dynamic_docked_widget_container.build_wrapping_nested_dock_area(f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0f9b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_crosshairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85366f3c",
   "metadata": {},
   "source": [
    "## <a id='toc7_2_'></a>[2025-02-17 - Dock Item \"Track\" sizing](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f80e740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.NestedDockAreaWidget import NestedDockAreaWidget\n",
    "\n",
    "dock_manager_widget: NestedDockAreaWidget  = active_2d_plot.dock_manager_widget\n",
    "dock_manager_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7954acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()\n",
    "grouped_dock_items_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbc4bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_dock_items, nested_dynamic_docked_widget_container_widgets = dock_manager_widget.layout_dockGroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9b64d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dock_manager_widget.get_flat_dockitems_list()\n",
    "\n",
    "flat_dockitems_list = dock_manager_widget.get_flat_dockitems_list() ## get the non-grouped dockitems\n",
    "flat_dockitems_list\n",
    "# flat_dockitems_list[0].widgets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497f2289",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dock: Dock = flat_dockitems_list[-1]\n",
    "a_dock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9496b8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_dock_stretch_sizes_list = [a_dock.stretch() for a_dock in flat_dockitems_list] # [(500, 40), (500, 50), (65, 200), (65, 200), (65, 200), (65, 200), (500, 321), (500, 25)]\n",
    "flat_dock_stretch_sizes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d0b1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_dock_stretch_sizes = np.array(flat_dock_stretch_sizes_list)\n",
    "total_height: float = np.sum(flat_dock_stretch_sizes, axis=0)[-1] ## total height of all docks\n",
    "total_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c6c246",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_dock_configs_list = [a_dock.config for a_dock in flat_dockitems_list]\n",
    "flat_dock_configs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dad856",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dock: Dock = flat_dockitems_list[0]\n",
    "a_dock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71138bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_keys_if_possible(curr_key='dynamic_display_dict', curr_value=dock_manager_widget.dynamic_display_dict, max_depth=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb42af97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.External.pyqtgraph.dockarea.Dock import Dock, DockDisplayConfig, DockLabel\n",
    "\n",
    "print(f'active_2d_plot.get_leaf_only_flat_dock_identifiers_list(): {active_2d_plot.get_leaf_only_flat_dock_identifiers_list()}')\n",
    "leaf_only_flat_docks_dict: Dict[str, Dock] = {k:active_2d_plot.find_display_dock(k) for k in active_2d_plot.get_leaf_only_flat_dock_identifiers_list()}\n",
    "print(f'leaf_only_flat_docks_dict: {leaf_only_flat_docks_dict}')\n",
    "\n",
    "leaf_only_flat_docks_geometry_size_list = [(a_dock.width(), a_dock.height()) for k, a_dock in leaf_only_flat_docks_dict.items()] # [(1855, 69), (1855, 69), (1855, 71), (1855, 71), (1855, 71), (1855, 73), (1855, 64), (1855, 85), (1855, 30)]\n",
    "leaf_only_flat_docks_geometry_sizes = np.vstack(leaf_only_flat_docks_geometry_size_list)\n",
    "leaf_only_flat_docks_geometry_sizes\n",
    "\n",
    "\n",
    "single_track_height_unit: int = 30 ## how tall a single track height unit is, determining the minimum height of a track\n",
    "\n",
    "\n",
    "total_leaf_only_flat_docks_geometry_size = np.sum(leaf_only_flat_docks_geometry_sizes, axis=0)\n",
    "total_leaf_only_flat_docks_geometry_size\n",
    "\n",
    "leaf_only_flat_docks_stretch_list = [a_dock.stretch() for k, a_dock in leaf_only_flat_docks_dict.items()] # [(500, 40), (500, 50), (65, 200), (65, 200), (65, 200), (65, 200), (10, 4), (10, 4), (10, 1)]\n",
    "leaf_only_flat_docks_stretchs = np.vstack(leaf_only_flat_docks_stretch_list)\n",
    "leaf_only_flat_docks_stretchs\n",
    "\n",
    "# leaf_only_flat_docks_dict\n",
    "\n",
    "# active_2d_plot.get_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb50aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_only_flat_docks_dict['intervals'].setStretch(x=10, y=4)\n",
    "\n",
    "leaf_only_flat_docks_dict['new_curves_separate_plot'].setStretch(x=10, y=4)\n",
    "for a_name in ['ContinuousDecode_long_LR - t_bin_size: 0.025', 'ContinuousDecode_long_RL - t_bin_size: 0.025', 'ContinuousDecode_short_LR - t_bin_size: 0.025', 'ContinuousDecode_short_RL - t_bin_size: 0.025']:\n",
    "\tleaf_only_flat_docks_dict[a_name].setStretch(x=10, y=4)\n",
    "\tleaf_only_flat_docks_dict[a_name].setMinimumHeight(30)  # Set a smaller minimum height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591bd986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.External.pyqtgraph.dockarea.Dock import debug_widget_geometry\n",
    "\n",
    "# active_2d_plot.get_leaf_only_flat_dock_identifiers_list()\n",
    "\n",
    "dock_items_dict = {k:v[-1] for k, v in output_dict.items()}\n",
    "# dock_items_dict = {k:v[-1] for k, v in MASKED_output_dict.items()}\n",
    "dock_items_dict\n",
    "\n",
    "a_dock_item = dock_items_dict['PBE_marginal_over_track_ID']\n",
    "a_dock_item.setStretch(x=10, y=1)  # Same larger height stretch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b0acc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for k, v in dock_items_dict.items():\n",
    "    print(f'k: {k}')\n",
    "    # debug_widget_geometry(v, widget_name=k)\n",
    "    # Allow one dock to be smaller than its minimum size hint\n",
    "    v.widgetArea.setMinimumHeight(30)  # Set a smaller minimum height\n",
    "    \n",
    "    v.debug_print(widget_name=k)\n",
    "    # Assuming you have three docks\n",
    "    # v.stretch()  # Small height stretch\n",
    "\n",
    "    # smallDock.setStretch(x=10, y=1)  # Small height stretch\n",
    "    # tallDock1.setStretch(x=10, y=3)  # Larger height stretch\n",
    "    # tallDock2.setStretch(x=10, y=3)  # Same larger height stretch\n",
    "\n",
    "    # v.label.debug_print(label_name=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3fe261",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.dissolve_all_dockGroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db33f073",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.layout_dockGroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c45eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_dock_items_dict: Dict[str, List[Dock]] = active_2d_plot.get_dockGroup_dock_dict()\n",
    "grouped_dock_items_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693f5fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.dock_manager_widget.nested_dock_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9046712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a_group_id, a_group_dock in active_2d_plot.dock_manager_widget.nested_dock_items.items():\n",
    "# \ta_group_container_id: str = f'GROUP[{a_group_id}]'\n",
    "# \tdel active_2d_plot.dock_manager_widget.nested_dock_items[a_group_id]\n",
    "\t\n",
    "# active_2d_plot.dock_manager_widget.nested_dock_items.clear()\n",
    "active_2d_plot.dock_manager_widget.nested_dock_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99688c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_dock_ids_list = active_2d_plot.get_group_only_flat_dock_identifiers_list()\n",
    "group_dock_ids_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14beb813",
   "metadata": {},
   "source": [
    "## 🎯🔜 Adjust SpikeRaster2D default plot sizings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184de423",
   "metadata": {
    "tags": [
     "2025-05-12"
    ]
   },
   "outputs": [],
   "source": [
    "## extract the components so the `background_static_scroll_window_plot` scroll bar is the right size:\n",
    "active_2d_plot = spike_raster_window.spike_raster_plt_2d\n",
    "preview_overview_scatter_plot: pg.ScatterPlotItem  = active_2d_plot.plots.preview_overview_scatter_plot # ScatterPlotItem\n",
    "# preview_overview_scatter_plot.setDownsampling(auto=True, method='subsample', dsRate=10)\n",
    "main_graphics_layout_widget: pg.GraphicsLayoutWidget = active_2d_plot.ui.main_graphics_layout_widget\n",
    "wrapper_layout: pg.QtWidgets.QVBoxLayout = active_2d_plot.ui.wrapper_layout\n",
    "main_content_splitter = active_2d_plot.ui.main_content_splitter # QSplitter\n",
    "active_window_container_layout = active_2d_plot.ui.active_window_container_layout\n",
    "layout = active_2d_plot.ui.layout\n",
    "\n",
    "has_main_raster_plot: bool = (active_2d_plot.plots.main_plot_widget is not None)\n",
    "if has_main_raster_plot:\n",
    "    main_plot_widget = active_2d_plot.plots.main_plot_widget # PlotItem\n",
    "    main_plot_widget.setMinimumHeight(20.0)\n",
    "else:\n",
    "    active_window_container_layout.setVisible(False)\n",
    "\n",
    "background_static_scroll_window_plot = active_2d_plot.plots.background_static_scroll_window_plot # PlotItem\n",
    "background_static_scroll_window_plot.setMinimumHeight(50.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a139fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_plot_widget.size()\n",
    "main_plot_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee18a487",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_plot_widget.hide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dc5dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_static_scroll_window_plot.size()\n",
    "background_static_scroll_window_plot.setMaximumHeight(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ce21ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "_raster_tracks_out_dict = active_2d_plot.prepare_pyqtgraph_rasterPlot_track(name_modifier_suffix='raster_window', should_link_to_main_plot_widget=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6059b40a",
   "metadata": {},
   "source": [
    "#### <a id='toc7_2_1_1_'></a>[Spike3DRasterWindow - Right Sidebar Widgets](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eff235",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.on_update_right_sidebar_visible_interval_info_tables()\n",
    "spike_raster_window.build_dock_area_managing_tree_widget()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9d696e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Qt.Widgets.EpochRenderConfigWidget.EpochRenderConfigWidget import EpochRenderConfigWidget, EpochRenderConfigsListWidget\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import DockDisplayColors, CustomDockDisplayConfig\n",
    "\n",
    "an_epochs_display_list_widget: EpochRenderConfigsListWidget = spike_raster_window.build_epoch_intervals_visual_configs_widget()\n",
    "an_epochs_display_list_widget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549f454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_raster_plot.ui.epochs_render_configs_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa59d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.build_neuron_visual_configs_widget()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3738059c",
   "metadata": {},
   "source": [
    "## <a id='toc7_3_'></a>[💯 2025-01-22 - Add Selection Widget for SpikeRaster3DWindow](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bb8383",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_plt_2d: Spike2DRaster = spike_raster_window.spike_raster_plt_2d\n",
    "a_range_selection_widget, range_selection_root_graphics_layout_widget, range_selection_plot_item, range_selection_dDisplayItem = spike_raster_plt_2d.add_new_embedded_pyqtgraph_render_plot_widget(name='range_selection_capture_widget', dockSize=(500,25))\n",
    "range_selection_dDisplayItem.setMaximumHeight(25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cde7d38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c1edcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attrs import define, field, Factory\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsObjects.CustomInfiniteLine import CustomInfiniteLine\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsObjects.CustomLinearRegionItem import CustomLinearRegionItem\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.GraphicsObjects.CustomIntervalRectsItem import CustomIntervalRectsItem\n",
    "\n",
    "\n",
    "@define(slots=False)\n",
    "class UserTimelineSelections:\n",
    "    point_selections: List[pg.TargetItem] = field(default=Factory(list))\n",
    "    line_selections: List[CustomInfiniteLine] = field(default=Factory(list))\n",
    "    range_selections: List[CustomLinearRegionItem] = field(default=Factory(list))\n",
    "    \n",
    "\n",
    "selections: UserTimelineSelections = UserTimelineSelections()\n",
    "selections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af0c666",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Add three infinite lines with labels\n",
    "inf1 = pg.InfiniteLine(movable=True, angle=90, label='x={value:0.2f}', \n",
    "                       labelOpts={'position':0.1, 'color': (200,200,100), 'fill': (200,200,200,50), 'movable': True})\n",
    "inf2 = pg.InfiniteLine(movable=True, angle=0, pen=(0, 0, 200), bounds = [-20, 20], hoverPen=(0,200,0), label='y={value:0.2f}mm', \n",
    "                       labelOpts={'color': (200,0,0), 'movable': True, 'fill': (0, 0, 200, 100)})\n",
    "inf3 = pg.InfiniteLine(movable=True, angle=45, pen='g', label='diagonal',\n",
    "                       labelOpts={'rotateAxis': [1, 0], 'fill': (0, 200, 0, 100), 'movable': True})\n",
    "inf1.setPos([2,2])\n",
    "p1.addItem(inf1)\n",
    "p1.addItem(inf2)\n",
    "p1.addItem(inf3)\n",
    "\n",
    "targetItem1 = pg.TargetItem()\n",
    "\n",
    "targetItem2 = pg.TargetItem(\n",
    "    pos=(30, 5),\n",
    "    size=20,\n",
    "    symbol=\"star\",\n",
    "    pen=\"#F4511E\",\n",
    "    label=\"vert={1:0.2f}\",\n",
    "    labelOpts={\n",
    "        \"offset\": QtCore.QPoint(15, 15)\n",
    "    }\n",
    ")\n",
    "targetItem2.label().setAngle(45)\n",
    "\n",
    "targetItem3 = pg.TargetItem(\n",
    "    pos=(10, 10),\n",
    "    size=10,\n",
    "    symbol=\"x\",\n",
    "    pen=\"#00ACC1\",\n",
    ")\n",
    "targetItem3.setLabel(\n",
    "    \"Third Label\",\n",
    "    {\n",
    "        \"anchor\": QtCore.QPointF(0.5, 0.5),\n",
    "        \"offset\": QtCore.QPointF(30, 0),\n",
    "        \"color\": \"#558B2F\",\n",
    "        \"rotateAxis\": (0, 1)\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "def callableFunction(x, y):\n",
    "    return f\"Square Values: ({x**2:.4f}, {y**2:.4f})\"\n",
    "\n",
    "targetItem4 = pg.TargetItem(\n",
    "    pos=(10, -10),\n",
    "    label=callableFunction\n",
    ")\n",
    "\n",
    "p1.addItem(targetItem1)\n",
    "p1.addItem(targetItem2)\n",
    "p1.addItem(targetItem3)\n",
    "p1.addItem(targetItem4)\n",
    "\n",
    "# Add a linear region with a label\n",
    "lr = pg.LinearRegionItem(values=[70, 80])\n",
    "p1.addItem(lr)\n",
    "label = pg.InfLineLabel(lr.lines[1], \"region 1\", position=0.95, rotateAxis=(1,0), anchor=(1, 1))\n",
    "\n",
    "\n",
    "\n",
    "vb=DragSelectViewBox()\n",
    "plotItem=pg.PlotItem(viewBox=vb)\n",
    "plotWidget=pg.PlotWidget(plotItem=plotItem)\n",
    "plotWidget.plot([0,1,2,3],[10,5,7,3],pen='b')\n",
    "plotWidget.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be99f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QMainWindow, QVBoxLayout, QWidget\n",
    "import pyqtgraph as pg\n",
    "\n",
    "@function_attributes(short_name=None, tags=['pyqtgraph', 'selection', 'interactive'], input_requires=[], output_provides=[], uses=[], used_by=[], creation_date='2025-06-16 10:26', related_items=[])\n",
    "class PlotWithSelection(pg.PlotWidget):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        # Initialize variables to track the selection\n",
    "        self.start_pos = None\n",
    "        self.end_pos = None\n",
    "        self.is_selecting = False\n",
    "        \n",
    "        # Disable default panning\n",
    "        self.setMouseTracking(True)\n",
    "        self.plotItem.vb.setMouseEnabled(x=False, y=False)  # Disable default panning/zooming\n",
    "\n",
    "    def mousePressEvent(self, event):\n",
    "        if event.button() == Qt.LeftButton:\n",
    "            # Get the position where the mouse was clicked\n",
    "            pos = self.plotItem.vb.mapSceneToView(event.pos())\n",
    "            self.start_pos = pos.x()\n",
    "            self.is_selecting = True\n",
    "        else:\n",
    "            super().mousePressEvent(event)\n",
    "\n",
    "    def mouseMoveEvent(self, event):\n",
    "        if self.is_selecting:\n",
    "            # Update the end position while dragging\n",
    "            pos = self.plotItem.vb.mapSceneToView(event.pos())\n",
    "            self.end_pos = pos.x()\n",
    "            self.update_selection()\n",
    "        else:\n",
    "            super().mouseMoveEvent(event)\n",
    "\n",
    "    def mouseReleaseEvent(self, event):\n",
    "        if event.button() == Qt.LeftButton and self.is_selecting:\n",
    "            # Get the final position where the mouse was released\n",
    "            pos = self.plotItem.vb.mapSceneToView(event.pos())\n",
    "            self.end_pos = pos.x()\n",
    "\n",
    "            # Ensure that the start and end positions are valid\n",
    "            if self.start_pos is not None and self.end_pos is not None:\n",
    "                # Create a new LinearRegionItem\n",
    "                region = pg.LinearRegionItem(values=(min(self.start_pos, self.end_pos), max(self.start_pos, self.end_pos)))\n",
    "                self.addItem(region)\n",
    "\n",
    "            # Reset the selection state\n",
    "            self.start_pos = None\n",
    "            self.end_pos = None\n",
    "            self.is_selecting = False\n",
    "        else:\n",
    "            super().mouseReleaseEvent(event)\n",
    "\n",
    "    def update_selection(self):\n",
    "        # Optionally, you can draw a temporary selection line here\n",
    "        pass\n",
    "\n",
    "# Example usage\n",
    "win = QMainWindow()\n",
    "central_widget = QWidget()\n",
    "layout = QVBoxLayout(central_widget)\n",
    "\n",
    "plot_widget = PlotWithSelection()\n",
    "plot_widget.plot([1, 5, 2, 4, 3], pen='r')  # Example data\n",
    "\n",
    "layout.addWidget(plot_widget)\n",
    "win.setCentralWidget(central_widget)\n",
    "win.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599e7a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "range_selection_plot_item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ded6097",
   "metadata": {},
   "source": [
    "### 2025-06-16 - Matplotlib `SpanSelector` approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c613cd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.widgets import SpanSelector\n",
    "\n",
    "dock_titles = ['ContinuousDecode_long_LR - t_bin_size: 0.025', 'ContinuousDecode_long_RL - t_bin_size: 0.025', 'ContinuousDecode_short_LR - t_bin_size: 0.025', 'ContinuousDecode_short_RL - t_bin_size: 0.025']\n",
    "for a_dock_title in dock_titles:\n",
    "    a_dock, widget = active_2d_plot.find_dock_item_tuple(identifier=a_dock_title)\n",
    "    # widget.plots_data\n",
    "    widget.params.user_selections = [] ## empty selections to start\n",
    "    widget.ui.span_selector = None\n",
    "    widget.ui.span_selector_fn = None\n",
    "\n",
    "    def onselect(xmin, xmax):\n",
    "        \"\"\" captures: widget, y, line2, ax2, fig, \n",
    "        \"\"\"\n",
    "        indmin, indmax = np.searchsorted(widget.plots_data.time_window_centers, (xmin, xmax))\n",
    "        indmax = min(len(widget.plots_data.time_window_centers) - 1, indmax)\n",
    "        region_x = widget.plots_data.time_window_centers[indmin:indmax]\n",
    "        # region_y = widget.plots_data.xbin[indmin:indmax]\n",
    "        if len(region_x) >= 2:\n",
    "            widget.params.user_selections.append(region_x)            \n",
    "            # line2.set_data(region_x, region_y)\n",
    "            # ax2.set_xlim(region_x[0], region_x[-1])\n",
    "            # ax2.set_ylim(region_y.min(), region_y.max())\n",
    "            # fig.canvas.draw_idle()\n",
    "            \n",
    "    widget.ui.span_selector_fn = onselect\n",
    "\n",
    "    widget.ui.span_selector = SpanSelector(\n",
    "        widget.ax,\n",
    "        widget.ui.span_selector_fn,\n",
    "        \"horizontal\",\n",
    "        useblit=True,\n",
    "        props=dict(alpha=0.5, facecolor=\"tab:blue\"),\n",
    "        interactive=True,\n",
    "        drag_from_anywhere=True\n",
    "    )\n",
    "    # Set useblit=True on most backends for enhanced performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94b0209",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_dock, widget = active_2d_plot.find_dock_item_tuple(identifier='ContinuousDecode_long_RL - t_bin_size: 0.025')\n",
    "\n",
    "# widget.plots_data.xbin\n",
    "# widget.plots_data.time_\n",
    "widget.params.user_selections # [array([548.812, 548.838, 548.862, 548.888]), array([549.062, 549.088, 549.112, 549.138]), array([548.213, 548.237, 548.263, 548.288])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fcda63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [array([548.812, 548.838, 548.862, 548.888]), array([549.062, 549.088, 549.112, 549.138]), array([548.213, 548.237, 548.263, 548.288])]\n",
    "# 5 skip bins\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316fdc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.widgets import SpanSelector\n",
    "\n",
    "\n",
    "# class StatefulSpanSelector(SpanSelector):\n",
    "#     \"\"\" a version of MAtplotlib's SpanSelector widget that contains its selection state, callback function, and related information to provide a more object-oriented approach\n",
    "#     \"\"\"\n",
    "#     def onselect(self, xmin, xmax):\n",
    "#         indmin, indmax = np.searchsorted(x, (xmin, xmax))\n",
    "#         indmax = min(len(x) - 1, indmax)\n",
    "\n",
    "#         region_x = x[indmin:indmax]\n",
    "#         region_y = y[indmin:indmax]\n",
    "\n",
    "#         if len(region_x) >= 2:\n",
    "#             line2.set_data(region_x, region_y)\n",
    "#             ax2.set_xlim(region_x[0], region_x[-1])\n",
    "#             ax2.set_ylim(region_y.min(), region_y.max())\n",
    "#             fig.canvas.draw_idle()\n",
    "\n",
    "\n",
    "\n",
    "# Fixing random state for reproducibility\n",
    "np.random.seed(19680801)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(8, 6))\n",
    "\n",
    "x = np.arange(0.0, 5.0, 0.01)\n",
    "y = np.sin(2 * np.pi * x) + 0.5 * np.random.randn(len(x))\n",
    "\n",
    "ax1.plot(x, y)\n",
    "ax1.set_ylim(-2, 2)\n",
    "ax1.set_title('Press left mouse button and drag '\n",
    "              'to select a region in the top graph')\n",
    "\n",
    "line2, = ax2.plot([], [])\n",
    "\n",
    "\n",
    "def onselect(xmin, xmax):\n",
    "    \"\"\" captures: x, y, line2, ax2, fig, \n",
    "    \"\"\"\n",
    "    indmin, indmax = np.searchsorted(x, (xmin, xmax))\n",
    "    indmax = min(len(x) - 1, indmax)\n",
    "\n",
    "    region_x = x[indmin:indmax]\n",
    "    region_y = y[indmin:indmax]\n",
    "\n",
    "    if len(region_x) >= 2:\n",
    "        line2.set_data(region_x, region_y)\n",
    "        ax2.set_xlim(region_x[0], region_x[-1])\n",
    "        ax2.set_ylim(region_y.min(), region_y.max())\n",
    "        fig.canvas.draw_idle()\n",
    "        \n",
    "\n",
    "\n",
    "span = SpanSelector(\n",
    "    ax1,\n",
    "    onselect,\n",
    "    \"horizontal\",\n",
    "    useblit=True,\n",
    "    props=dict(alpha=0.5, facecolor=\"tab:blue\"),\n",
    "    interactive=True,\n",
    "    drag_from_anywhere=True\n",
    ")\n",
    "# Set useblit=True on most backends for enhanced performance.\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8736da11",
   "metadata": {},
   "source": [
    "# <a id='toc10_'></a>[Other Misc Plotting Stuff](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521bba12",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.plot._display_directional_template_debugger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb5ba90",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_template_debugger')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e9208a",
   "metadata": {},
   "source": [
    "### <a id='toc10_1_1_'></a>[Resume display stuff](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50f2ef8",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from flexitext import flexitext\n",
    "from neuropy.utils.matplotlib_helpers import FormattedFigureText, FigureMargins ## flexitext version\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out = curr_active_pipeline.display('_display_directional_track_template_pf1Ds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d2b444",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# _restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n",
    "_restore_previous_matplotlib_settings_callback = matplotlib_configuration_update(is_interactive=True, backend='Qt5Agg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080c1041",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_two_step_decoder_prediction_error_2D', global_epoch_context, variable_name='p_x_given_n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e05b045",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_plot_most_likely_position_comparisons', global_epoch_context) # , variable_name='p_x_given_n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddebd9e",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_laps_overview')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d805c37",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_laps_overview')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3c3cea",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "'_display_directional_laps_overview'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb98e796",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "# '_display_directional_merged_pfs'\n",
    "_out = curr_active_pipeline.display('_display_directional_merged_pfs', plot_all_directions=False, plot_long_directional=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47076a61",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "'_display_1d_placefield_occupancy'\n",
    "'_display_placemaps_pyqtplot_2D'\n",
    " '_display_2d_placefield_occupancy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481df233",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_2d_placefield_occupancy', global_any_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694d0a20",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_grid_bin_bounds_validation')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fbe6ee",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "_out = curr_active_pipeline.display('_display_running_and_replay_speeds_over_time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58951b11",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.utils.matplotlib_helpers import add_rectangular_selector, add_range_selector\n",
    "\n",
    "\n",
    "# epoch_name = global_any_name\n",
    "epoch_name = short_epoch_name\n",
    "computation_result = curr_active_pipeline.computation_results[epoch_name]\n",
    "grid_bin_bounds = computation_result.computation_config['pf_params'].grid_bin_bounds\n",
    "epoch_context = curr_active_pipeline.filtered_contexts[epoch_name]\n",
    "print(grid_bin_bounds)     \n",
    "fig, ax = computation_result.computed_data.pf2D.plot_occupancy(identifier_details_list=[epoch_name], active_context=epoch_context) \n",
    "\n",
    "# rect_selector, set_extents, reset_extents = add_rectangular_selector(fig, ax, initial_selection=grid_bin_bounds) # (24.82, 257.88), (125.52, 149.19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada4720b",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import add_vertical_track_bounds_lines\n",
    "\n",
    "grid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\n",
    "long_track_line_collection, short_track_line_collection = add_vertical_track_bounds_lines(grid_bin_bounds=grid_bin_bounds, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b862a66",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.peak_location_representing import compute_placefield_center_of_mass_positions\n",
    "\n",
    "\n",
    "epoch_name = global_any_name\n",
    "computation_result = curr_active_pipeline.computation_results[epoch_name]\n",
    "grid_bin_bounds = deepcopy(computation_result.computation_config['pf_params'].grid_bin_bounds)\n",
    "epoch_context = curr_active_pipeline.filtered_contexts[epoch_name]\n",
    "\n",
    "grid_bin_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65654f01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5905e90b",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "grid_bin_bounds = deepcopy(long_pf2D.config.grid_bin_bounds)\n",
    "grid_bin_bounds\n",
    "long_pf2D.xbin\n",
    "long_pf2D.ybin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befc3d1d",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "occupancy = deepcopy(long_pf2D.occupancy) # occupancy.shape # (60, 15)\n",
    "xbin = deepcopy(long_pf2D.xbin)\n",
    "ybin = deepcopy(long_pf2D.ybin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0416d4",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "from scipy import ndimage # used for `compute_placefield_center_of_masses`\n",
    "from neuropy.utils.mixins.peak_location_representing import compute_occupancy_center_of_mass_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6352663",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "occupancy_x_center_dict = {k:compute_occupancy_center_of_mass_positions(v.pf.occupancy, xbin=v.pf.xbin, ybin=v.pf.ybin).item() for k, v in track_templates.get_decoders_dict().items()}\n",
    "occupancy_x_center_dict # {'long_LR': 162.99271603199625, 'long_RL': 112.79866056603696, 'short_LR': 138.45611791646, 'short_RL': 130.78889937230684}\n",
    "\n",
    "occupancy_mask_x_center_dict = {k:compute_occupancy_center_of_mass_positions(v.pf.visited_occupancy_mask, xbin=v.pf.xbin, ybin=v.pf.ybin).item() for k, v in track_templates.get_decoders_dict().items()}\n",
    "occupancy_mask_x_center_dict # {'long_LR': 135.66781520875904, 'long_RL': 130.0042755113645, 'short_LR': 133.77996864296085, 'short_RL': 143.21920147195175}\n",
    "\n",
    "\n",
    "# {k:compute_occupancy_center_of_mass_positions(v.pf.occupancy, xbin=v.pf.xbin, ybin=v.pf.ybin).item() for k, v in track_templates.get_decoders_dict().items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb029d8",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "occupancy = deepcopy(long_pf2D.occupancy) # occupancy.shape # (60, 15)\n",
    "xbin = deepcopy(long_pf2D.xbin)\n",
    "ybin = deepcopy(long_pf2D.ybin)\n",
    "\n",
    "# masked_nonzero_occupancy = deepcopy(long_pf2D.nan_never_visited_occupancy)\n",
    "\n",
    "masked_nonzero_occupancy = deepcopy(long_pf2D.visited_occupancy_mask)\n",
    "\n",
    "# occupancy_CoM_positions = compute_occupancy_center_of_mass_positions(occupancy, xbin=long_pf2D.xbin, ybin=long_pf2D.ybin)\n",
    "occupancy_CoM_positions = compute_occupancy_center_of_mass_positions(masked_nonzero_occupancy, xbin=long_pf2D.xbin, ybin=long_pf2D.ybin) # array([127.704, 145.63])\n",
    "occupancy_CoM_positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097c3b06",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "long_pf2D.nan_never_visited_occupancy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4caa06",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.registered_display_function_docs_dict# '_display_grid_bin_bounds_validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f963a7",
   "metadata": {
    "tags": [
     "all",
     "2025-01-23"
    ]
   },
   "outputs": [],
   "source": [
    "## Extracting on 2024-02-06 to display the LR/RL directions instead of the All/Long/Short pfs:\n",
    "def _display_directional_merged_pfs(owning_pipeline_reference, global_computation_results, computation_results, active_configs, include_includelist=None, save_figure=True, included_any_context_neuron_ids=None,\n",
    "                                    plot_all_directions=True, plot_long_directional=False, plot_short_directional=False, **kwargs):\n",
    "    \"\"\" Plots the merged pseduo-2D pfs/ratemaps. Plots: All-Directions, Long-Directional, Short-Directional in seperate windows. \n",
    "    \n",
    "    History: this is the Post 2022-10-22 display_all_pf_2D_pyqtgraph_binned_image_rendering-based method:\n",
    "    \"\"\"\n",
    "    from pyphoplacecellanalysis.Pho2D.PyQtPlots.plot_placefields import pyqtplot_plot_image_array, display_all_pf_2D_pyqtgraph_binned_image_rendering\n",
    "    from pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow \n",
    "    from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import LayoutScrollability\n",
    "\n",
    "    defer_render = kwargs.pop('defer_render', False)\n",
    "    directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "    active_merged_pf_plots_data_dict = {} #empty dict\n",
    "    \n",
    "    if plot_all_directions:\n",
    "        active_merged_pf_plots_data_dict[owning_pipeline_reference.build_display_context_for_session(track_config='All-Directions', display_fn_name='display_all_pf_2D_pyqtgraph_binned_image_rendering')] = directional_merged_decoders_result.all_directional_pf1D_Decoder.pf # all-directions\n",
    "    if plot_long_directional:\n",
    "        active_merged_pf_plots_data_dict[owning_pipeline_reference.build_display_context_for_session(track_config='Long-Directional', display_fn_name='display_all_pf_2D_pyqtgraph_binned_image_rendering')] = directional_merged_decoders_result.long_directional_pf1D_Decoder.pf # Long-only\n",
    "    if plot_short_directional:\n",
    "        active_merged_pf_plots_data_dict[owning_pipeline_reference.build_display_context_for_session(track_config='Short-Directional', display_fn_name='display_all_pf_2D_pyqtgraph_binned_image_rendering')] = directional_merged_decoders_result.short_directional_pf1D_Decoder.pf # Short-only\n",
    "\n",
    "    out_plots_dict = {}\n",
    "    \n",
    "    for active_context, active_pf_2D in active_merged_pf_plots_data_dict.items():\n",
    "        # figure_format_config = {} # empty dict for config\n",
    "        neuron_values = deepcopy(active_pf_2D.peak_tuning_curve_center_of_mass_bin_coordinates)\n",
    "        sort_indices = np.lexsort((neuron_values[:, 1], neuron_values[:, 0]))\n",
    "        figure_format_config = {'scrollability_mode': LayoutScrollability.NON_SCROLLABLE, 'included_unit_indicies': sort_indices} # kwargs # kwargs as default figure_format_config\n",
    "        out_all_pf_2D_pyqtgraph_binned_image_fig: BasicBinnedImageRenderingWindow  = display_all_pf_2D_pyqtgraph_binned_image_rendering(active_pf_2D, figure_format_config) # output is BasicBinnedImageRenderingWindow\n",
    "    \n",
    "        # Set the window title from the context\n",
    "        out_all_pf_2D_pyqtgraph_binned_image_fig.setWindowTitle(f'{active_context.get_description()}')\n",
    "        out_plots_dict[active_context] = out_all_pf_2D_pyqtgraph_binned_image_fig\n",
    "\n",
    "        # Tries to update the display of the item:\n",
    "        names_list = [v for v in list(out_all_pf_2D_pyqtgraph_binned_image_fig.plots.keys()) if v not in ('name', 'context')]\n",
    "        for a_name in names_list:\n",
    "            # Adjust the size of the text for the item by passing formatted text\n",
    "            a_plot: pg.PlotItem = out_all_pf_2D_pyqtgraph_binned_image_fig.plots[a_name].mainPlotItem # PlotItem \n",
    "            # no clue why 2 is a good value for this...\n",
    "            a_plot.titleLabel.setMaximumHeight(2)\n",
    "            a_plot.layout.setRowFixedHeight(0, 2)\n",
    "            a_plot.layout.setRowFixedHeight(1, 10)\n",
    "            plot_viewbox = a_plot.getViewBox()\n",
    "            # plot_viewbox.setMinimumHeight(200)  # Set a reasonable minimum height\n",
    "            plot_viewbox.setMaximumHeight(15)  # Set a fixed height to prevent stretching\n",
    "            plot_viewbox.setBorder(None)  # Remove the border\n",
    "            plot_viewbox.setBackgroundColor(None)\n",
    "                        \n",
    "            # # Add a spacer at the bottom\n",
    "            # spacer = pg.QtWidgets.QGraphicsWidget()\n",
    "            # spacer.setSizePolicy(pg.QtWidgets.QSizePolicy.Expanding, pg.QtWidgets.QSizePolicy.Expanding)  # Flexible spacer\n",
    "            # # Add the spacer to the layout\n",
    "            # row_count = a_plot.layout.rowCount()  # Get current row count\n",
    "            # a_plot.layout.addItem(spacer, row_count, 0, 1, a_plot.layout.columnCount())  # Add spacer to the last row\n",
    "            \n",
    "\n",
    "        if not defer_render:\n",
    "            out_all_pf_2D_pyqtgraph_binned_image_fig.show()\n",
    "\n",
    "    return out_plots_dict\n",
    "\n",
    "\n",
    "out_plots_dict = _display_directional_merged_pfs(curr_active_pipeline, curr_active_pipeline.global_computation_results, computation_results=None, active_configs=None, include_includelist=None, save_figure=True, included_any_context_neuron_ids=None,\n",
    "                                    plot_all_directions=True, plot_long_directional=False, plot_short_directional=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15824da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_all_pf_2D_pyqtgraph_binned_image_fig: BasicBinnedImageRenderingWindow = list(out_plots_dict.values())[0]\n",
    "# Tries to update the display of the item:\n",
    "names_list = [v for v in list(out_all_pf_2D_pyqtgraph_binned_image_fig.plots.keys()) if v not in ('name', 'context')]\n",
    "for a_name in names_list:\n",
    "    # Adjust the size of the text for the item by passing formatted text\n",
    "    a_plot: pg.PlotItem = out_all_pf_2D_pyqtgraph_binned_image_fig.plots[a_name].mainPlotItem # PlotItem \n",
    "    # no clue why 2 is a good value for this...\n",
    "    a_plot.titleLabel.setMaximumHeight(2)\n",
    "    a_plot.layout.setRowFixedHeight(0, 2)\n",
    "    a_plot.getViewBox().setBorder(None)  # Remove the border\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c38fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_plot.layoutDirection()\n",
    "a_plot.layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f36e973",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyphocorehelpers.gui.Qt.color_helpers import ColormapHelpers\n",
    "        \n",
    "ColormapHelpers.mpl_to_pg_colormap(color_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf715bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_pf2D = directional_merged_decoders_result.all_directional_pf1D_Decoder.pf # all-directions\n",
    "active_pf2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054feb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.shape()\n",
    "\n",
    "neuron_values = deepcopy(active_pf2D.peak_tuning_curve_center_of_mass_bin_coordinates)\n",
    "\n",
    "sort_indices = np.lexsort((neuron_values[:, 1], neuron_values[:, 0]))\n",
    "sort_indices\n",
    "\n",
    "neuron_values[sort_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfeb03c",
   "metadata": {
    "tags": [
     "all"
    ]
   },
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "# _out = curr_active_pipeline.display('_display_directional_merged_pfs', plot_all_directions=True, plot_long_directional=False, plot_short_directional=False)\n",
    "_out = curr_active_pipeline.display('_display_directional_merged_pf_decoded_epochs') # scrollable_figure=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb499f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_directional_merged_pf_decoded_epochs_marginals') # scrollable_figure=True\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cce23e",
   "metadata": {},
   "source": [
    "# <a id='toc21_'></a>[✅ `batch_user_completion_helpers` Batch Computation Testing](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ecbe84",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_2_'></a>[Call `export_rank_order_results_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22800b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import export_rank_order_results_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "# _across_session_results_extended_dict = {}\n",
    "\n",
    "# additional_session_context = None\n",
    "# try:\n",
    "#     if custom_suffix is not None:\n",
    "#         additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "#         print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "# except NameError as err:\n",
    "#     additional_session_context = None\n",
    "#     print(f'NO CUSTOM SUFFIX.')    \n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | export_rank_order_results_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                # # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None)\n",
    "                                                should_save_pkl=False, should_save_CSV=True,\n",
    "                                                )\n",
    "\n",
    "\n",
    "callback_outputs = _across_session_results_extended_dict['export_rank_order_results_completion_function']\n",
    "merged_complete_ripple_epoch_stats_df_output_path = callback_outputs['merged_complete_ripple_epoch_stats_df_output_path']\n",
    "minimum_inclusion_fr_Hz = callback_outputs['minimum_inclusion_fr_Hz']\n",
    "included_qclu_values = callback_outputs['included_qclu_values']\n",
    "print(f'merged_complete_ripple_epoch_stats_df_output_path: {merged_complete_ripple_epoch_stats_df_output_path}') # \"2024-11-15_Lab-2006-6-09_1-22-43_merged_complete_epoch_stats_df.csv\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34757ebd",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_3_'></a>[Call `compute_and_export_session_wcorr_shuffles_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf5cc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_session_wcorr_shuffles_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "# additional_session_context = None\n",
    "# try:\n",
    "#     if custom_suffix is not None:\n",
    "#         additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "#         print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "# except NameError as err:\n",
    "#     additional_session_context = None\n",
    "#     print(f'NO CUSTOM SUFFIX.')    \n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_session_wcorr_shuffles_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                # # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None)\n",
    "                                                )\n",
    "\n",
    "\n",
    "callback_outputs = _across_session_results_extended_dict['compute_and_export_session_wcorr_shuffles_completion_function']\n",
    "wcorr_shuffles_data_output_filepath = callback_outputs['wcorr_shuffles_data_output_filepath']\n",
    "standalone_MAT_filepath = callback_outputs['standalone_MAT_filepath']\n",
    "ripple_WCorrShuffle_df_export_CSV_path = callback_outputs['ripple_WCorrShuffle_df_export_CSV_path']\n",
    "print(f'wcorr_shuffles_data_output_filepath: {wcorr_shuffles_data_output_filepath}') # \"2024-11-15_Lab-2006-6-09_1-22-43_merged_complete_epoch_stats_df.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5693589d",
   "metadata": {},
   "source": [
    "### Call `compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fd5080",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _subfn_compute_complete_df_metrics\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "try:\n",
    "    if _across_session_results_extended_dict is not None:\n",
    "        pass\n",
    "    else:\n",
    "        _across_session_results_extended_dict = {}\n",
    "except NameError as err:\n",
    "    _across_session_results_extended_dict = {}\n",
    "    \n",
    "additional_session_context = None\n",
    "try:\n",
    "    if custom_suffix is not None:\n",
    "        additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "        print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "except NameError as err:\n",
    "    additional_session_context = None\n",
    "    print(f'NO CUSTOM SUFFIX.')    \n",
    "\n",
    "# ripple_decoding_time_bin_size_override = 0.058\n",
    "ripple_decoding_time_bin_size_override = 0.025\n",
    "laps_decoding_time_bin_size_override = 0.025\n",
    "# ripple_decoding_time_bin_size_override = 0.050\n",
    "# laps_decoding_time_bin_size_override = 0.050\n",
    "\n",
    "needs_recompute_heuristics = True\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                ripple_decoding_time_bin_size_override=ripple_decoding_time_bin_size_override,\n",
    "                                                laps_decoding_time_bin_size_override=laps_decoding_time_bin_size_override,\n",
    "                                                needs_recompute_heuristics=needs_recompute_heuristics, allow_append_to_session_h5_file=False, save_hdf=True, force_recompute_all_decoding=True, \n",
    "                                                )\n",
    "\n",
    "callback_outputs = _across_session_results_extended_dict['compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function']\n",
    "ripple_decoding_time_bin_size_override = callback_outputs['ripple_decoding_time_bin_size_override']\n",
    "print(f'ripple_decoding_time_bin_size_override: {ripple_decoding_time_bin_size_override}')\n",
    "output_csv_paths = callback_outputs['output_csv_paths']\n",
    "print(f'output_csv_paths: {output_csv_paths}')\n",
    "output_hdf_paths = callback_outputs['output_hdf_paths']\n",
    "print(f'output_hdf_paths: {output_hdf_paths}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c82f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benedict import benedict\n",
    "\n",
    "_across_session_results_extended_dict = benedict(_across_session_results_extended_dict)\n",
    "out_ripple_all_scores_merged_df_csv = Path(_across_session_results_extended_dict['compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function.output_csv_paths.ripple_all_scores_merged_df']).resolve()\n",
    "Assert.path_exists(out_ripple_all_scores_merged_df_csv)\n",
    "\n",
    "out_ripple_all_scores_merged_df_csv.parent\n",
    "'C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2025-03-08_Apogee-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 8, 9]-frateThresh_5.0-(ripple_all_scores_merged_df)_tbin-0.025.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286f1cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_across_session_results_extended_dict['compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8daa277",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_ripple_all_scores_merged_hdf5_files = [Path(v).resolve() for v in _across_session_results_extended_dict['compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function.output_hdf_paths']]\n",
    "Assert.path_exists(out_ripple_all_scores_merged_hdf5_files[0])\n",
    "print(f'out_ripple_all_scores_merged_hdf5_files[0]: \"{out_ripple_all_scores_merged_hdf5_files[0].as_posix()}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101d7d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_path = '/home/halechr/FastData/collected_outputs/2024-11-22_Lab-kdiba_gor01_one_2006-6-12_15-55-31__withNormalComputedReplays-qclu_[1, 2]-frateThresh_5.0-(ripple_all_scores_merged_df)_tbin-0.025.csv'\n",
    "csv_path = '/home/halechr/FastData/collected_outputs/2024-11-22_Lab-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0-(ripple_all_scores_merged_df)_tbin-0.016.csv'\n",
    "test_df = pd.read_csv(csv_path)\n",
    "test_df\n",
    "\n",
    "\n",
    "test_df[np.logical_not(test_df['short_best_jump'].isnull())]['short_best_jump']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121efeb3",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_5_'></a>[Call `perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5732d32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _subfn_compute_complete_df_metrics\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "return_full_decoding_results: bool = True\n",
    "save_hdf: bool = False\n",
    "save_csvs:bool = False\n",
    "# _across_session_results_extended_dict = {}\n",
    "\n",
    "try:\n",
    "    if _across_session_results_extended_dict is not None:\n",
    "        pass\n",
    "    else:\n",
    "        _across_session_results_extended_dict = {}\n",
    "except NameError as err:\n",
    "    _across_session_results_extended_dict = {}\n",
    "    \n",
    "additional_session_context = None\n",
    "try:\n",
    "    if custom_suffix is not None:\n",
    "        additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "        print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "except NameError as err:\n",
    "    additional_session_context = None\n",
    "    print(f'NO CUSTOM SUFFIX.')\n",
    "\n",
    "# %pdb on\n",
    "## Combine the output of `perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function` into two dataframes for the laps, one per-epoch and one per-time-bin\n",
    "# desired_shared_decoding_time_bin_sizes = np.linspace(start=0.030, stop=0.5, num=10)\n",
    "# desired_shared_decoding_time_bin_sizes = np.linspace(start=0.005, stop=0.03, num=10)\n",
    "# _across_session_results_extended_dict = _across_session_results_extended_dict | perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function(a_dummy, None,\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\tcurr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "# \t\t\t\t\t\t\t\t\t\t\t\tacross_session_results_extended_dict=_across_session_results_extended_dict, save_hdf=save_hdf, return_full_decoding_results=return_full_decoding_results,\n",
    "#                                                 desired_shared_decoding_time_bin_sizes=desired_shared_decoding_time_bin_sizes,\n",
    "#                                                 )\n",
    "\n",
    "# desired_laps_decoding_time_bin_size = [None] # doesn't work\n",
    "# desired_laps_decoding_time_bin_size = [1.5] # large so it doesn't take long\n",
    "# desired_ripple_decoding_time_bin_size = [0.010, 0.020]\n",
    "# desired_ripple_decoding_time_bin_size = [0.010, 0.020, 0.025]\n",
    "\n",
    "# desired_shared_decoding_time_bin_sizes = np.array([0.025, 0.030, 0.044, 0.050, 0.058, 0.072, 0.086, 0.100])\n",
    "# desired_shared_decoding_time_bin_sizes = np.array([0.025, 0.030, 0.044, 0.050, 0.058,])\n",
    "# desired_shared_decoding_time_bin_sizes = np.array([0.010, 0.025, 0.058,])\n",
    "desired_shared_decoding_time_bin_sizes = np.array([0.025, 0.050,])\n",
    "# desired_shared_decoding_time_bin_sizes = np.array([0.058,])\n",
    "# custom_all_param_sweep_options, param_sweep_option_n_values = parameter_sweeps(desired_laps_decoding_time_bin_size=desired_laps_decoding_time_bin_size,\n",
    "#                                                                                 desired_ripple_decoding_time_bin_size=desired_ripple_decoding_time_bin_size,\n",
    "#                                                                         use_single_time_bin_per_epoch=[False],\n",
    "#                                                                         minimum_event_duration=[desired_ripple_decoding_time_bin_size[-1]])\n",
    "\n",
    "# Shared time bin sizes\n",
    "custom_all_param_sweep_options, param_sweep_option_n_values = parameter_sweeps(desired_shared_decoding_time_bin_size=desired_shared_decoding_time_bin_sizes, use_single_time_bin_per_epoch=[False], minimum_event_duration=[desired_shared_decoding_time_bin_sizes[-1]]) # with Ripples\n",
    "\n",
    "\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict, save_hdf=save_hdf, save_csvs=save_csvs, return_full_decoding_results=return_full_decoding_results,\n",
    "                                                # desired_shared_decoding_time_bin_sizes = np.linspace(start=0.030, stop=0.5, num=4),\n",
    "                                                custom_all_param_sweep_options=custom_all_param_sweep_options, # directly provide the parameter sweeps\n",
    "                                                # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None)\n",
    "                                                additional_session_context = None,\n",
    "                                                )\n",
    "\n",
    "\n",
    "if return_full_decoding_results:\n",
    "    # with `return_full_decoding_results == True`\n",
    "    out_path, output_laps_decoding_accuracy_results_df, output_extracted_result_tuples, combined_multi_timebin_outputs_tuple, output_full_directional_merged_decoders_result, output_directional_decoders_epochs_decode_results_dict, output_saved_individual_sweep_files_dict = _across_session_results_extended_dict['perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function']\n",
    "    # validate the result:\n",
    "    {k:v.all_directional_laps_filter_epochs_decoder_result.decoding_time_bin_size for k,v in output_full_directional_merged_decoders_result.items()}\n",
    "    # assert np.all([np.isclose(dict(k)['desired_shared_decoding_time_bin_size'], v.all_directional_laps_filter_epochs_decoder_result.decoding_time_bin_size) for k,v in output_full_directional_merged_decoders_result.items()]), f\"the desired time_bin_size in the parameters should match the one used that will appear in the decoded result\"\n",
    "\n",
    "else:\n",
    "    # with `return_full_decoding_results == False`\n",
    "    out_path, output_laps_decoding_accuracy_results_df, output_extracted_result_tuples, combined_multi_timebin_outputs_tuple, output_saved_individual_sweep_files_dict = _across_session_results_extended_dict['perform_sweep_decoding_time_bin_sizes_marginals_dfs_completion_function']\n",
    "    output_full_directional_merged_decoders_result = None\n",
    "\n",
    "\n",
    "(several_time_bin_sizes_laps_df, laps_out_path, several_time_bin_sizes_time_bin_laps_df, laps_time_bin_marginals_out_path), (several_time_bin_sizes_ripple_df, ripple_out_path, several_time_bin_sizes_time_bin_ripple_df, ripple_time_bin_marginals_out_path) = combined_multi_timebin_outputs_tuple\n",
    "\n",
    "#  exported files: {'laps_out_path': WindowsPath('K:/scratch/collected_outputs/2024-09-27-kdiba_gor01_two_2006-6-07_16-40-19_None-(laps_marginals_df).csv'), 'laps_time_bin_marginals_out_path': WindowsPath('K:/scratch/collected_outputs/2024-09-27-kdiba_gor01_two_2006-6-07_16-40-19_None-(laps_time_bin_marginals_df).csv'), 'ripple_out_path': WindowsPath('K:/scratch/collected_outputs/2024-09-27-kdiba_gor01_two_2006-6-07_16-40-19_None-(ripple_marginals_df).csv'), 'ripple_time_bin_marginals_out_path': WindowsPath('K:/scratch/collected_outputs/2024-09-27-kdiba_gor01_two_2006-6-07_16-40-19_None-(ripple_time_bin_marginals_df).csv')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fc9d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.get_all_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc64a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_saved_individual_sweep_files_dict\n",
    "# combined_multi_timebin_outputs_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcd8258",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import DisplaySpecifyingIdentifyingContext, CollisionOutcome\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Computation import PipelineWithComputedPipelineStageMixin\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Computation import session_context_filename_formatting_fn\n",
    "from pyphocorehelpers.print_helpers import get_now_day_str, get_now_rounded_time_str\n",
    "\n",
    "curr_active_pipeline.session_name\n",
    "# complete_session_context, (curr_session_context,  additional_session_context) = curr_active_pipeline.get_complete_session_context(parts_separator='_')\n",
    "\n",
    "# complete_session_context.get_description(separator='|') # 'kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays_qclu_[1, 2, 4, 6, 7, 9]_frateThresh_5.0'\n",
    "# complete_session_context.get_specific_purpose_description(specific_purpose='filename_formatting') # 'kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays_qclu_[1, 2, 4, 6, 7, 9]_frateThresh_5.0'\n",
    "# curr_active_pipeline.get_complete_session_identifier_string(parts_separator='_', sub_parts_separator='|') # 'kdiba-gor01-one-2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0'\n",
    "curr_active_pipeline.get_complete_session_identifier_string(parts_separator='_', custom_parameter_keyvalue_parts_separator='-', session_identity_parts_separator='_')\n",
    "\n",
    "# \"kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_1.0\"\n",
    "\n",
    "out_path, out_filename, out_basename = curr_active_pipeline.build_complete_session_identifier_filename_string(output_date_str=None, data_identifier_str=\"(ripple_WCorrShuffle_df)\", parent_output_path=None, out_extension='.csv', extra_parts=None, ensure_no_duplicate_parts=False)\n",
    "out_filename # '2024-11-19_0148AM-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0-(ripple_WCorrShuffle_df).csv'\n",
    "# out_path, out_filename, out_basename = curr_active_pipeline.build_complete_session_identifier_filename_string(output_date_str=get_now_rounded_time_str(), data_identifier_str=\"(ripple_WCorrShuffle_df)\", parent_output_path=None, out_extension='.csv', extra_parts=None, ensure_no_duplicate_parts=False)\n",
    "# out_path, out_filename, out_basename = curr_active_pipeline.build_complete_session_identifier_filename_string(data_identifier_str=\"(ripple_WCorrShuffle_df)\", parent_output_path=None, out_extension='.csv', extra_parts=None, ensure_no_duplicate_parts=True)\n",
    "out_path, out_filename, out_basename = curr_active_pipeline.build_complete_session_identifier_filename_string(data_identifier_str=\"(ripple_WCorrShuffle_df)\", parent_output_path=None, out_extension='.csv', suffix_string='_tbin-0.025')\n",
    "out_filename  # '2024-11-19_0148AM-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0-(ripple_WCorrShuffle_df)_tbin-0.025.csv'\n",
    "\n",
    "# \"2024-11-18_1020PM-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_1.0-(ripple_WCorrShuffle_df)_tbin-0.025.csv\"\n",
    "# \"2024-11-19_0125AM-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_5.0-(ripple_WCorrShuffle_df).csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8b1579",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_session_context.get_raw_identifying_context()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a21cabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_session_context\n",
    "\n",
    "# ['format_name', 'animal', 'exper_name', 'session_name']\n",
    "curr_session_context.get_description()\n",
    "curr_session_context.get_specific_purpose_description(specific_purpose='filename_formatting')\n",
    "\n",
    "curr_session_context.to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82ac92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_test_complete_session_context: DisplaySpecifyingIdentifyingContext = DisplaySpecifyingIdentifyingContext.init_from_context(a_context=curr_active_pipeline.get_session_context(), \n",
    "        specific_purpose_display_dict={'filename_formatting': session_context_filename_formatting_fn,},\n",
    "        #  display_dict={'epochs_source': lambda k, v: to_filename_conversion_dict[v],\n",
    "        #         'included_qclu_values': lambda k, v: f\"qclu_{v}\",\n",
    "        #         'minimum_inclusion_fr_Hz': lambda k, v: f\"frateThresh_{v:.1f}\",\n",
    "        # },\n",
    "    )\n",
    "_test_complete_session_context\n",
    "_test_complete_session_context.get_description()\n",
    "_test_complete_session_context.get_specific_purpose_description(specific_purpose='filename_formatting')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ef185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "additional_session_context.get_description()\n",
    "additional_session_context.get_specific_purpose_description(specific_purpose='filename_formatting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c4da3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _test_complete_session_context: DisplaySpecifyingIdentifyingContext = curr_session_context.adding_context(collision_prefix='_additional', strategy=CollisionOutcome.FAIL_IF_DIFFERENT, **additional_session_context.to_dict())\n",
    "_test_complete_session_context: DisplaySpecifyingIdentifyingContext = curr_session_context.adding_context(collision_prefix='_additional', strategy=CollisionOutcome.FAIL_IF_DIFFERENT, **additional_session_context.get_raw_identifying_context().to_dict())\n",
    "\n",
    "\n",
    "_test_complete_session_context\n",
    "_test_complete_session_context.get_description()\n",
    "_test_complete_session_context.get_specific_purpose_description(specific_purpose='filename_formatting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5026a5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.get_complete_session_identifier_string(parts_separator='_')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14a1e08",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_6_'></a>[Call `compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb60e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import DisplaySpecifyingIdentifyingContext, IdentifyingContext\n",
    "# from pyphoplacecellanalysis.General.Pipeline.Stages.Computation import PipelineWithComputedPipelineStageMixin\n",
    "\n",
    "complete_session_context, (session_context, additional_session_context) = curr_active_pipeline.get_complete_session_context()\n",
    "session_context\n",
    "additional_session_context\n",
    "complete_session_context\n",
    "\n",
    "\n",
    "session_context.get_description()\n",
    "additional_session_context.get_description()\n",
    "complete_session_context.get_description()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0d9a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_session_context.get_specific_purpose_description(specific_purpose='filename_formatting') # additional_session_context.get_specific_purpose_description(specific_purpose='filename_formatting')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76164cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_session_context.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e58214",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_session_context.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c303453",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_session_context.get_specific_purpose_description(specific_purpose='filename_formatting') # '-_withNormalComputedReplays-frateThresh_5.0-qclu_[1, 2, 4, 6, 7, 9]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9185d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_session_context.get_description() # 'kdiba_gor01_two_2006-6-12_16-53-46__withNormalComputedReplays_qclu_[1, 2, 4, 6, 7, 9]_frateThresh_5.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a789e08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_context = complete_session_context\n",
    "active_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc10c9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "active_context.get_description()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497465d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "# return_full_decoding_results: bool = True\n",
    "# save_hdf: bool = True\n",
    "# save_csvs:bool = True\n",
    "\n",
    "try:\n",
    "    _across_session_results_extended_dict\n",
    "except NameError as e:\n",
    "    _across_session_results_extended_dict = {} # initialize\n",
    "\n",
    "additional_session_context = None\n",
    "try:\n",
    "    if custom_suffix is not None:\n",
    "        additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "        print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "except NameError as err:\n",
    "    additional_session_context = None\n",
    "    print(f'NO CUSTOM SUFFIX.')    \n",
    "    \n",
    "rank_order_results = curr_active_pipeline.global_computation_results.computed_data.get('RankOrder', None)\n",
    "if rank_order_results is not None:\n",
    "    minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "else:        \n",
    "    ## get from parameters:\n",
    "    minimum_inclusion_fr_Hz: float = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.minimum_inclusion_fr_Hz\n",
    "    included_qclu_values: List[int] = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.included_qclu_values\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict, included_qclu_values=included_qclu_values, minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, drop_previous_result_and_compute_fresh=True, num_wcorr_shuffles=1024,\n",
    "                                                # # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None)\n",
    "                                                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb49fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function' in _across_session_results_extended_dict\n",
    "compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_output = deepcopy(_across_session_results_extended_dict['compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function'])\n",
    "# compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_output\n",
    "callback_outputs = deepcopy(_across_session_results_extended_dict['compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function'])\n",
    "\n",
    "custom_suffix = callback_outputs['custom_suffix']\n",
    "replay_epoch_variations = callback_outputs['replay_epoch_variations']\n",
    "replay_epoch_outputs = callback_outputs['replay_epoch_outputs']\n",
    "\n",
    "replay_epoch_name = 'normal_computed'\n",
    "a_replay_epoch_variation: Epoch = replay_epoch_variations[replay_epoch_name]\n",
    "a_replay_epoch_outputs = replay_epoch_outputs[replay_epoch_name]\n",
    "\n",
    "## Unpack `a_replay_epoch_outputs`\n",
    "exported_evt_file_path = a_replay_epoch_outputs['exported_evt_file_path']\n",
    "did_change = a_replay_epoch_outputs['did_change']\n",
    "custom_save_filenames = a_replay_epoch_outputs['custom_save_filenames']\n",
    "custom_save_filepaths = a_replay_epoch_outputs['custom_save_filepaths']\n",
    "custom_suffix = a_replay_epoch_outputs['custom_suffix']\n",
    "wcorr_ripple_shuffle_all_df = a_replay_epoch_outputs['wcorr_ripple_shuffle_all_df']\n",
    "all_shuffles_only_best_decoder_wcorr_df = a_replay_epoch_outputs['all_shuffles_only_best_decoder_wcorr_df']\n",
    "standalone_pkl_filepath = a_replay_epoch_outputs['standalone_pkl_filepath']\n",
    "standalone_mat_filepath = a_replay_epoch_outputs['standalone_mat_filepath']\n",
    "active_context = a_replay_epoch_outputs['active_context']\n",
    "export_files_dict = a_replay_epoch_outputs['export_files_dict']\n",
    "# params_description_str = a_replay_epoch_outputs['params_description_str']\n",
    "# footer_annotation_text = a_replay_epoch_outputs['footer_annotation_text']\n",
    "# out_hist_fig_result = a_replay_epoch_outputs['out_hist_fig_result']\n",
    "\n",
    "\n",
    "custom_save_filenames\n",
    "custom_save_filepaths\n",
    "export_files_dict\n",
    "# print_keys_if_possible('callback_outputs', compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_output, max_depth=3)\n",
    "# a_replay_epoch_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d41b45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_strs = []\n",
    "for k, v in a_replay_epoch_outputs.items():\n",
    "    code_strs.append(f\"{k} = a_replay_epoch_outputs['{k}']\")\n",
    "\n",
    "print('\\n'.join(code_strs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6d6e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_output['export_files_dict']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8beeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_epoch_outputs = deepcopy(compute_and_export_session_alternative_replay_wcorr_shuffles_completion_function_output['replay_epoch_outputs'])\n",
    "# replay_epoch_outputs\n",
    "\n",
    "normal_computed_replay_epoch_outputs = replay_epoch_outputs['normal_computed']\n",
    "normal_computed_replay_epoch_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a3bfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(replay_epoch_outputs.keys())\n",
    "\n",
    "export_files_dict = normal_computed_replay_epoch_outputs['export_files_dict']\n",
    "export_files_dict\n",
    "\n",
    "export_file_path_ripple_WCorrShuffle_df = export_files_dict['ripple_WCorrShuffle_df'] # 'W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2024-11-18_1020PM-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_1.0-(ripple_WCorrShuffle_df)_tbin-0.025.csv'\n",
    "export_file_path_ripple_WCorrShuffle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a46edd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_save_filepaths = normal_computed_replay_epoch_outputs['custom_save_filepaths'] ## these seem to be misnamed AND redundant\n",
    "custom_save_filepaths\n",
    "\n",
    "ripple_csv_out_path = custom_save_filepaths['ripple_csv_out_path'] # 'K:/scratch/collected_outputs/2024-11-18-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_1.0_withNormalComputedReplays-frateThresh_1.0-qclu_[1, 2, 4, 6, 7, 9]-(ripple_marginals_df).csv'\n",
    "ripple_csv_out_path\n",
    "\n",
    "ripple_csv_time_bin_marginals = custom_save_filepaths['ripple_csv_time_bin_marginals'] # 'K:/scratch/collected_outputs/2024-11-18-kdiba_gor01_one_2006-6-09_1-22-43__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 9]-frateThresh_1.0_withNormalComputedReplays-frateThresh_1.0-qclu_[1, 2, 4, 6, 7, 9]-(ripple_time_bin_marginals_df).csv'\n",
    "ripple_csv_time_bin_marginals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3f496b",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_7_'></a>[Call `compute_and_export_session_trial_by_trial_performance_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "be44b166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using custom suffix: \"_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 8, 9]-frateThresh_5.0\" - additional_session_context: \"custom_suffix:_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 8, 9]-frateThresh_5.0\"\n",
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "compute_and_export_session_trial_by_trial_performance_completion_function(curr_session_context: format_name:kdiba|animal:gor01|exper_name:one|session_name:2006-6-12_15-55-31, curr_session_basedir: W:\\Data\\KDIBA\\gor01\\one\\2006-6-12_15-55-31, ...)\n",
      "\tCURR_BATCH_OUTPUT_PREFIX: 2025-07-11_Apogee-2006-6-12_15-55-31-_withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 8, 9]-frateThresh_5.0\n",
      "\tminimum_inclusion_fr_Hz: 5.0\n",
      "\tincluded_qclu_values: [1, 2, 4, 6, 7, 8, 9]\n",
      "WARN: on_complete_success_execution_session: encountered exception CapturedException(, traceback=C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:1322<fn: perform_compute_marginals>: AssertionError) while performing .compute_and_export_session_trial_by_trial_performance_completion_function(...) for curr_session_context: format_name:kdiba|animal:gor01|exper_name:one|session_name:2006-6-12_15-55-31\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_session_trial_by_trial_performance_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "return_full_decoding_results: bool = True\n",
    "save_hdf: bool = True\n",
    "save_csvs:bool = True\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "additional_session_context = None\n",
    "try:\n",
    "    if custom_suffix is not None:\n",
    "        additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "        print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "except NameError as err:\n",
    "    additional_session_context = None\n",
    "    print(f'NO CUSTOM SUFFIX.')    \n",
    "    \n",
    "active_laps_decoding_time_bin_size: float = 0.025\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_session_trial_by_trial_performance_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict, active_laps_decoding_time_bin_size=active_laps_decoding_time_bin_size,\n",
    "                                                # # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None)\n",
    "                                                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e427751",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_outputs = _across_session_results_extended_dict['compute_and_export_session_trial_by_trial_performance_completion_function']\n",
    "a_trial_by_trial_result: TrialByTrialActivityResult = callback_outputs['a_trial_by_trial_result']\n",
    "subset_neuron_IDs_dict = callback_outputs['subset_neuron_IDs_dict']\n",
    "subset_decode_results_dict = callback_outputs['subset_decode_results_dict']\n",
    "subset_decode_results_track_id_correct_performance_dict = callback_outputs['subset_decode_results_track_id_correct_performance_dict']\n",
    "directional_active_lap_pf_results_dicts: Dict[types.DecoderName, TrialByTrialActivity] = a_trial_by_trial_result.directional_active_lap_pf_results_dicts\n",
    "_out_subset_decode_results_track_id_correct_performance_dict = callback_outputs['subset_decode_results_track_id_correct_performance_dict']\n",
    "_out_subset_decode_results_dict = callback_outputs['subset_decode_results_dict']\n",
    "neuron_group_split_stability_dfs_tuple = callback_outputs['neuron_group_split_stability_dfs_tuple']\n",
    "neuron_group_split_stability_aclus_tuple = callback_outputs['neuron_group_split_stability_aclus_tuple']\n",
    "\n",
    "appearing_stability_df, disappearing_stability_df, appearing_or_disappearing_stability_df, stable_both_stability_df, stable_neither_stability_df, stable_long_stability_df, stable_short_stability_df = neuron_group_split_stability_dfs_tuple\n",
    "appearing_aclus, disappearing_aclus, appearing_or_disappearing_aclus, stable_both_aclus, stable_neither_aclus, stable_long_aclus, stable_short_aclus = neuron_group_split_stability_aclus_tuple\n",
    "# (complete_decoded_context_correctness_tuple, laps_marginals_df, all_directional_pf1D_Decoder, all_test_epochs_df, test_all_directional_decoder_result, all_directional_laps_filter_epochs_decoder_result, _out_separate_decoder_results)  = _out_subset_decode_results_dict['any_decoder'] ## get the result for all cells\n",
    "# filtered_laps_time_bin_marginals_df: pd.DataFrame = callback_outputs['subset_decode_results_time_bin_marginals_df_dict']['filtered_laps_time_bin_marginals_df']\n",
    "# active_results: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy({k:v.decoder_result for k, v in _out_separate_decoder_results[0].items()})\n",
    "# active_results: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy({k:v for k, v in _out_separate_decoder_results[1].items()})\n",
    "# filtered_laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dcdbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_group_split_stability_dfs_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a95b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aTbyT:TrialByTrialActivity = a_trial_by_trial_result.directional_active_lap_pf_results_dicts['long_LR']\n",
    "aTbyT.C_trial_by_trial_correlation_matrix.shape # (40, 21, 21)\n",
    "aTbyT.z_scored_tuning_map_matrix.shape # (21, 40, 57) (n_epochs, n_neurons, n_pos_bins)\n",
    "\n",
    "(directional_viewer, directional_image_layer_dict, custom_direction_split_layers_dict) = aTbyT.plot_napari_trial_by_trial_correlation_matrix(directional_active_lap_pf_results_dicts=a_trial_by_trial_result.directional_active_lap_pf_results_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3305a31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(a_trial_by_trial_result.any_decoder_neuron_IDs)\n",
    "a_trial_by_trial_result.any_decoder_neuron_IDs[37] # 58\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bbad28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directional_viewer.Config()\n",
    "directional_viewer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276588e6",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_8_'></a>[Call `compute_and_export_cell_first_spikes_characteristics_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a69538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_cell_first_spikes_characteristics_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "try:\n",
    "    _across_session_results_extended_dict\n",
    "except NameError as e:\n",
    "    _across_session_results_extended_dict = {} # initialize\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_cell_first_spikes_characteristics_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                # # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None)\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855bd06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import figures_plot_cell_first_spikes_characteristics_completion_function\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "try:\n",
    "    _across_session_results_extended_dict\n",
    "except NameError as e:\n",
    "    _across_session_results_extended_dict = {} # initialize\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | figures_plot_cell_first_spikes_characteristics_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                # # additional_session_context=additional_session_context,\n",
    "                                                # additional_session_context=IdentifyingContext(custom_suffix=None),\n",
    "                                                later_appearing_cell_lap_start_id=4,\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4624b606",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_9_'></a>[Call `kdiba_session_post_fixup_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef1b68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyphoplacecellanalysis.General.type_aliases as types\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import PostHocPipelineFixup, kdiba_session_post_fixup_completion_function, SimpleBatchComputationDummy\n",
    "\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "# additional_session_context = None\n",
    "# try:\n",
    "#     if custom_suffix is not None:\n",
    "#         additional_session_context = IdentifyingContext(custom_suffix=custom_suffix)\n",
    "#         print(f'Using custom suffix: \"{custom_suffix}\" - additional_session_context: \"{additional_session_context}\"')\n",
    "# except NameError as err:\n",
    "#     additional_session_context = None\n",
    "#     print(f'NO CUSTOM SUFFIX.')    \n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | kdiba_session_post_fixup_completion_function(a_dummy, None,\n",
    "                                                curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                force_recompute=False, is_dry_run=False,\n",
    "                                                )\n",
    "\n",
    "\n",
    "# callback_outputs = _across_session_results_extended_dict['kdiba_session_post_fixup_completion_function'] # 'PostHocPipelineFixup'\n",
    "# loaded_track_limits = callback_outputs['loaded_track_limits']\n",
    "# a_config_dict = callback_outputs['a_config_dict']\n",
    "# print(f'loaded_track_limits: {loaded_track_limits}') \n",
    "    \n",
    "\n",
    "#  'computation_results[\"maze_any\"]': False, 'filtered_sessions[\"maze1_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze1_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze1_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze1_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze2_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze2_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze2_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze2_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze1_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_even\"].config.pix2cm': False, 'filtered_sessions[\"maze1_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.grid_bin': True, 'filtered_sessions[\"maze1_even\"].config.track_start_t': True, 'filtered_sessions[\"maze1_even\"].config.track_end_t': True, 'filtered_sessions[\"maze2_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_even\"].config.pix2cm': False, 'filtered_sessions[\"maze2_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.grid_bin': True, 'filtered_sessions[\"maze2_even\"].config.track_start_t': True, 'filtered_sessions[\"maze2_even\"].config.track_end_t': True, 'filtered_sessions[\"maze_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze_even\"].config.pix2cm': False, 'filtered_sessions[\"maze_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.grid_bin': True, 'filtered_sessions[\"maze_even\"].config.track_start_t': True, 'filtered_sessions[\"maze_even\"].config.track_end_t': True, 'filtered_sessions[\"maze1_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_any\"].config.pix2cm': False, 'filtered_sessions[\"maze1_any\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.grid_bin': True, 'filtered_sessions[\"maze1_any\"].config.track_start_t': True, 'filtered_sessions[\"maze1_any\"].config.track_end_t': True, 'filtered_sessions[\"maze2_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_any\"].config.pix2cm': False, 'filtered_sessions[\"maze2_any\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.grid_bin': True, 'filtered_sessions[\"maze2_any\"].config.track_start_t': True, 'filtered_sessions[\"maze2_any\"].config.track_end_t': True, 'filtered_sessions[\"maze_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze_any\"].config.pix2cm': False, 'filtered_sessions[\"maze_any\"].config.real_unit_grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.real_cm_grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.grid_bin': True, 'filtered_sessions[\"maze_any\"].config.track_start_t': False, 'filtered_sessions[\"maze_any\"].config.track_end_t': False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdfd908",
   "metadata": {},
   "outputs": [],
   "source": [
    "_across_session_results_extended_dict\n",
    "\n",
    "# 'filtered_sessions[\"maze1_odd\"].loaded_track_limits': False,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.pix2cm': False,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.real_unit_grid_bin_bounds': True,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.real_cm_grid_bin_bounds': True,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.grid_bin_bounds': True,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.grid_bin': True,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.track_start_t': True,\n",
    "#    'filtered_sessions[\"maze1_odd\"].config.track_end_t': True,\n",
    "\n",
    "['real_unit_grid_bin_bounds', 'real_cm_grid_bin_bounds', 'grid_bin_bounds', 'grid_bin', 'track_start_t', 'track_end_t']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c43d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.filtered_sessions[\"maze1_odd\"].config.real_unit_grid_bin_bounds\n",
    "curr_active_pipeline.filtered_sessions[\"maze_even\"].config.grid_bin_bounds\n",
    "curr_active_pipeline.filtered_sessions[\"maze1_odd\"].config.grid_bin_bounds\n",
    "curr_active_pipeline.filtered_sessions[\"maze1_odd\"].config.loaded_track_limits\n",
    "curr_active_pipeline.filtered_sessions[\"maze1_odd\"].config.track_start_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650ee1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.filtered_sessions['maze1_even'].config.real_unit_grid_bin_bounds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a3bd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# extended_computations_include_includelist=['ratemap_peaks_prominence2d', 'rank_order_shuffle_analysis', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring',] # do only specified\n",
    "computation_functions_name_includelist = ['_perform_baseline_placefield_computation', '_perform_time_dependent_placefield_computation', '_perform_extended_statistics_computation', '_perform_position_decoding_computation', '_perform_firing_rate_trends_computation', '_perform_pf_find_ratemap_peaks_computation', '_perform_time_dependent_pf_sequential_surprise_computation_perform_two_step_position_decoding_computation']\n",
    " #['rank_order_shuffle_analysis', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'ratemap_peaks_prominence2d', ] # do only specified\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=computation_functions_name_includelist, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=False, force_recompute_override_computations_includelist=force_recompute_override_computations_includelist, debug_print=True)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963bf33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_include_function_names # {'_perform_pf_find_ratemap_peaks_computation': False, '_perform_time_dependent_pf_sequential_surprise_computation_perform_two_step_position_decoding_computation': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3d93e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=computation_functions_name_includelist, computation_kwargs_list=None, enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b70e5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# curr_active_pipeline.perform_computations(computation_functions_name_includelist=computation_functions_name_includelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2bc08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# curr_active_pipeline.active_configs # Dict[types.FilterContextName, InteractivePlaceCellConfig]\n",
    "# curr_active_pipeline.computation_results # Dict[types.FilterContextName, ComputationResult]\n",
    "\n",
    "# curr_active_pipeline.computation_results['maze1_odd'].computation_config # DynamicContainer\n",
    "# curr_active_pipeline.computation_results['maze1_odd'].computation_config.pf_params # PlacefieldComputationParameters\n",
    "\n",
    "\n",
    "grid_bin_bounds = deepcopy(curr_active_pipeline.computation_results['maze1_odd'].computation_config.pf_params.grid_bin_bounds) # ((0.0, 287.7697841726619), (115.10791366906477, 172.66187050359713))\n",
    "\n",
    "grid_bin = deepcopy(curr_active_pipeline.computation_results['maze1_odd'].computation_config.pf_params.grid_bin) # (3.8054171165052444, 1.4477079927649104)\n",
    "\n",
    "grid_bin_bounds\n",
    "# long_any_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98c40c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'DirectionalDecodersEpochsEvaluations' via compute_and_export_decoders_epochs_decoding_and_evaluation_dfs_completion_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05538438",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1885e4bc",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_10_'></a>[Call `generalized_decode_epochs_dict_and_export_results_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a876004",
   "metadata": {
    "tags": [
     "run-2025-04-11_full-session_marginals",
     "run-group-transition-matricies"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "generalized_decode_epochs_dict_and_export_results_completion_function(curr_session_context: format_name:kdiba|animal:gor01|exper_name:one|session_name:2006-6-12_15-55-31, curr_session_basedir: W:\\Data\\KDIBA\\gor01\\one\\2006-6-12_15-55-31, epochs_decoding_time_bin_size: 0.025, force_recompute: True, ...)\n",
      "\textant_result_decoding_time_bin_size: 0.05\n",
      "\t\tERROR: valid_EpochComputations_result.epochs_decoding_time_bin_size: 0.05 != epochs_decoding_time_bin_size: 0.025.\n",
      "\tA FULL RECOMPUTE WILL BE NEEDED!\n",
      "\t\t dropped_EpochComputations_result removed!.\n",
      "included includelist is specified: ['split_to_directional_laps', 'non_PBE_epochs_results', 'generalized_specific_epochs_decoding'], so only performing these extended computations.\n",
      "Running batch_evaluate_required_computations(...) with global_epoch_name: \"maze_any\"\n",
      "done with all batch_evaluate_required_computations(...).\n",
      "\tPost-load global computations: needs_computation_output_dict: ['split_to_directional_laps', 'non_PBE_epochs_results', 'generalized_specific_epochs_decoding']\n",
      "included includelist is specified: ['split_to_directional_laps', 'non_PBE_epochs_results', 'generalized_specific_epochs_decoding'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze_any\"\n",
      "2024-01-02 - split_to_directional_laps _perform_try_computation_if_needed, remove_provided_keys\n",
      "removed results: ['DirectionalLaps'] because force_recompute was True.\n",
      "`split_to_directional_laps` missing.\n",
      "\t Recomputing `split_to_directional_laps`...\n",
      "for global computations: Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['_split_to_directional_laps'], ...)...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function DirectionalPlacefieldGlobalComputationFunctions._split_to_directional_laps at 0x000001EF2CC85A60>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function DirectionalPlacefieldGlobalComputationFunctions._split_to_directional_laps at 0x000001F0611040D0>\n",
      "WARN: _split_to_directional_laps(...): include_includelist: ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any'] is specified but include_includelist is currently ignored! Continuing with defaults.\n",
      "DirectionalLapsResult.init_from_pipeline_natural_epochs(...): was_modified: False\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "\t done.\n",
      "2024-01-02 - non_PBE_epochs_results _perform_try_computation_if_needed, remove_provided_keys\n",
      "`non_PBE_epochs_results` missing.\n",
      "\t Recomputing `non_PBE_epochs_results`...\n",
      "for global computations: Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['perform_compute_non_PBE_epochs'], ...)...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function EpochComputationFunctions.perform_compute_non_PBE_epochs at 0x000001EF2D039B80>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function EpochComputationFunctions.perform_compute_non_PBE_epochs at 0x000001F077F31C10>\n",
      "perform_compute_non_PBE_epochs(..., training_data_portion=0.8333333333333334, epochs_decoding_time_bin_size: 0.025, frame_divide_bin_size: 10.0)\n",
      "available RAM: 33.86 GB\n",
      "Total memory required: 3.00 GB\n",
      "WARN: perform_compute_non_PBE_epochs(...): include_includelist: ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any'] is specified but include_includelist is currently ignored! Continuing with defaults.\n",
      "Uses 1D Placefields\n",
      "Uses 2D Placefields\n",
      "epochs_decoding_time_bin_size = 0.025, frame_divide_bin_size = 10.0\n",
      "WARN: Epoch[37]: with 4 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[43]: with 18 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[51]: with 9 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[69]: with 9 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[77]: with 6 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[105]: with 9 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[133]: with 16 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[5]: with 18 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[29]: with 12 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[32]: with 9 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[38]: with 23 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[40]: with 7 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[77]: with 20 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[82]: with 42 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[89]: with 92 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[95]: with 30 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[119]: with 11 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[124]: with 9 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[129]: with 29 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[131]: with 35 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[132]: with 16 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[134]: with 11 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[143]: with 12 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[152]: with 22 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[156]: with 9 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[157]: with 10 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "\t done.\n",
      "2024-01-02 - generalized_specific_epochs_decoding _perform_try_computation_if_needed, remove_provided_keys\n",
      "`generalized_specific_epochs_decoding` missing.\n",
      "\t Recomputing `generalized_specific_epochs_decoding`...\n",
      "for global computations: Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['perform_generalized_specific_epochs_decoding'], ...)...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function EpochComputationFunctions.perform_generalized_specific_epochs_decoding at 0x000001EF2D039C10>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function EpochComputationFunctions.perform_generalized_specific_epochs_decoding at 0x000001F138E31A60>\n",
      "\tepochs_decoding_time_bin_size: 0.025\n",
      "for global computations: Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['merged_directional_placefields', 'directional_decoders_decode_continuous', 'directional_decoders_evaluate_epochs', 'directional_decoders_epoch_heuristic_scoring', 'non_PBE_epochs_results'], ...)...\n",
      "\trun_specific_computations_single_context(including only 5 out of 16 registered computation functions): active_computation_functions: [<function DirectionalPlacefieldGlobalComputationFunctions._build_merged_directional_placefields at 0x000001EF2CC85AF0>, <function DirectionalPlacefieldGlobalComputationFunctions._decode_continuous_using_directional_decoders at 0x000001EF2CC85B80>, <function DirectionalPlacefieldGlobalComputationFunctions._decode_and_evaluate_epochs_using_directional_decoders at 0x000001EF2CC85C10>, <function DirectionalPlacefieldGlobalComputationFunctions._decoded_epochs_heuristic_scoring at 0x000001EF2CC85CA0>, <function EpochComputationFunctions.perform_compute_non_PBE_epochs at 0x000001EF2D039B80>]...\n",
      "Performing _execute_computation_functions(...) with 5 registered_computation_functions...\n",
      "Executing [0/5]: <function DirectionalPlacefieldGlobalComputationFunctions._build_merged_directional_placefields at 0x000001F10946DB80>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: ripple_decoding_time_bin_size 0.025 < min_possible_time_bin_size (0.042). This used to be enforced but continuing anyway.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing [1/5]: <function DirectionalPlacefieldGlobalComputationFunctions._decode_continuous_using_directional_decoders at 0x000001F10946DD30>\n",
      "\thad_existing_DirectionalDecodersDecoded_result == True. Using existing result and updating.\n",
      "\ttime_bin_size: 0.025\n",
      "(time_bin_size == 0.025) already found in cache. Not recomputing.\n",
      "Executing [2/5]: <function DirectionalPlacefieldGlobalComputationFunctions._decode_and_evaluate_epochs_using_directional_decoders at 0x000001F10946DEE0>\n",
      "laps_decoding_time_bin_size: 0.025, ripple_decoding_time_bin_size: 0.025, pos_bin_size: 4.877453969028168\n",
      "laps_decoding_time_bin_size: 0.025, ripple_decoding_time_bin_size: 0.025, pos_bin_size: 4.877453969028168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance: WCorr:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 37/74\n",
      "\tagreeing_rows_ratio: 0.5\n",
      "Performance: Ripple: WCorr\n",
      "agreeing_rows_count/num_total_epochs: 49/133\n",
      "\tagreeing_rows_ratio: 0.3684210526315789\n",
      "Performance: Simple PF PearsonR:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 23/74\n",
      "\tagreeing_rows_ratio: 0.3108108108108108\n",
      "Performance: Ripple: Simple PF PearsonR\n",
      "agreeing_rows_count/num_total_epochs: 50/133\n",
      "\tagreeing_rows_ratio: 0.37593984962406013\n",
      "Executing [3/5]: <function DirectionalPlacefieldGlobalComputationFunctions._decoded_epochs_heuristic_scoring at 0x000001F10946DF70>\n",
      "same_thresh_cm: 10.700000000000001\n",
      "Executing [4/5]: <function EpochComputationFunctions.perform_compute_non_PBE_epochs at 0x000001F138E311F0>\n",
      "perform_compute_non_PBE_epochs(..., training_data_portion=0.8333333333333334, epochs_decoding_time_bin_size: 0.025, frame_divide_bin_size: 10.0)\n",
      "available RAM: 24.23 GB\n",
      "Total memory required: 3.00 GB\n",
      "WARN: perform_compute_non_PBE_epochs(...): include_includelist: ['maze1_odd', 'maze2_odd', 'maze_odd', 'maze1_even', 'maze2_even', 'maze_even', 'maze1_any', 'maze2_any', 'maze_any'] is specified but include_includelist is currently ignored! Continuing with defaults.\n",
      "Uses 1D Placefields\n",
      "Uses 2D Placefields\n",
      "epochs_decoding_time_bin_size = 0.025, frame_divide_bin_size = 10.0\n",
      "WARN: Epoch[37]: with 4 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[43]: with 18 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[51]: with 9 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[69]: with 9 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[77]: with 6 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[105]: with 9 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[133]: with 16 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[5]: with 18 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[29]: with 12 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[32]: with 9 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[38]: with 23 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[40]: with 7 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[77]: with 20 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[82]: with 42 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[89]: with 92 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[95]: with 30 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[119]: with 11 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[124]: with 9 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[129]: with 29 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[131]: with 35 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[132]: with 16 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[134]: with 11 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[143]: with 12 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[152]: with 22 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[156]: with 9 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[157]: with 10 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "\t all computations complete! (Computed 5 with no errors!.\n",
      "included includelist is specified: ['non_PBE_epochs_results'], so only performing these extended computations.\n",
      "Running batch_extended_computations(...) with global_epoch_name: \"maze_any\"\n",
      "done with all batch_extended_computations(...).\n",
      ".adding_from_old_GeneralDecoderDictDecodedEpochsDictResult(...):\n",
      ".adding_directional_pseudo2D_decoder_results_filtered_by_spikes_per_t_bin_masked(...):\n",
      "a_new_identifier: \"trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore\"\n",
      "\t a_new_data_grain_identifier: \"trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore|data_grain:per_time_bin\"\n",
      "a_masked_updated_context: trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:nan_filled|data_grain:per_time_bin\n",
      "\t a_new_data_grain_identifier: \"trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore|data_grain:per_epoch\"\n",
      "a_masked_updated_context: trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:nan_filled|data_grain:per_epoch\n",
      "a_modified_context: \"trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:nan_filled\"\n",
      "a_new_identifier: \"trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore\"\n",
      "\t a_new_data_grain_identifier: \"trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore|data_grain:per_time_bin\"\n",
      "a_masked_updated_context: trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:nan_filled|data_grain:per_time_bin\n",
      "\t a_new_data_grain_identifier: \"trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore|data_grain:per_epoch\"\n",
      "a_masked_updated_context: trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:nan_filled|data_grain:per_epoch\n",
      "a_modified_context: \"trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:nan_filled\"\n",
      "GenericDecoderDictDecodedEpochsDictResult.computing_for_global_epoch(...):\n",
      "Found best match for a_result with 4 matching attributes:\ttrained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore\n",
      "\n",
      "Found best match for a_decoder with 4 matching attributes:\ttrained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore\n",
      "\n",
      "Found best match for a_decoded_marginal_posterior_df with 5 matching attributes:\ttrained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore|data_grain:per_time_bin\n",
      "\n",
      "Warning: Different contexts matched: result=trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore, decoder=trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore, posterior=trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore|data_grain:per_time_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found best match for a_result with 5 matching attributes:\ttrained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore\n",
      "\n",
      "Found best match for a_decoder with 5 matching attributes:\ttrained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore\n",
      "\n",
      "Found best match for a_decoded_marginal_posterior_df with 6 matching attributes:\ttrained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore|data_grain:per_time_bin\n",
      "\n",
      "Warning: Different contexts matched: result=trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore, decoder=trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore, posterior=trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore|data_grain:per_time_bin\n",
      "trying to compute for known_named_decoding_epochs_type=\"non_pbe_endcaps\"...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ta_masked_decoded_epoch_context: trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:non_pbe_endcaps|masked_time_bin_fill_type:ignore|data_grain:per_time_bin|decoding_time_bin_size:0.025\n",
      "\ta_masked_decoded_epoch_context: trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:non_pbe_endcaps|masked_time_bin_fill_type:last_valid|data_grain:per_time_bin|decoding_time_bin_size:0.025\n",
      "WARN: Epoch[10]: with 17 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[22]: with 4 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[45]: with 12 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[49]: with 9 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[61]: with 23 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[64]: with 6 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[82]: with 5 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[87]: with 9 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[100]: with 15 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[113]: with 19 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[118]: with 41 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[126]: with 57 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[132]: with 30 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[133]: with 25 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[136]: with 36 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[148]: with 3 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[160]: with 8 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[172]: with 10 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[178]: with 9 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[185]: with 29 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[188]: with 15 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[190]: with 10 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[193]: with 14 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[204]: with 37 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[205]: with 12 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[213]: with 73 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[214]: with 21 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[220]: with 8 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "WARN: Epoch[221]: with 9 time_bins has no time bins with enough firing to infer back-filled positions from, so all entries will be NaN.\n",
      "\ta_masked_decoded_epoch_context: trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:non_pbe_endcaps|masked_time_bin_fill_type:nan_filled|data_grain:per_time_bin|decoding_time_bin_size:0.025\n",
      "\ta_masked_decoded_epoch_context: trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:non_pbe_endcaps|masked_time_bin_fill_type:dropped|data_grain:per_time_bin|decoding_time_bin_size:0.025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\MultiContextComputationFunctions\\DirectionalPlacefieldGlobalComputationFunctions.py:2435: RuntimeWarning: invalid value encountered in divide\n",
      "  directional_all_epoch_bins_marginal = np.stack([np.sum(v.p_x_given_n, axis=-1)/np.sum(v.p_x_given_n, axis=(-2, -1)) for v in directional_marginals], axis=0) # sum over all time-bins within the epoch to reach a consensus\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\MultiContextComputationFunctions\\DirectionalPlacefieldGlobalComputationFunctions.py:2463: RuntimeWarning: invalid value encountered in divide\n",
      "  track_identity_all_epoch_bins_marginal = np.stack([np.sum(v.p_x_given_n, axis=-1)/np.sum(v.p_x_given_n, axis=(-2, -1)) for v in track_identity_marginals], axis=0) # sum over all time-bins within the epoch to reach a consensus\n",
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\General\\Pipeline\\Stages\\ComputationFunctions\\MultiContextComputationFunctions\\DirectionalPlacefieldGlobalComputationFunctions.py:2484: RuntimeWarning: invalid value encountered in divide\n",
      "  non_marginalized_decoder_all_epoch_bins_marginal = np.stack([np.sum(v.p_x_given_n, axis=-1)/np.sum(v.p_x_given_n, axis=(-2, -1)) for v in non_marginalized_decoder_marginals], axis=0) # sum over all time-bins within the epoch to reach a consensus .shape: (4, )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tupdating results for context: trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:non_pbe_endcaps|masked_time_bin_fill_type:ignore|data_grain:per_time_bin|decoding_time_bin_size:0.025\n",
      "\tupdating results for context: trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:non_pbe_endcaps|masked_time_bin_fill_type:last_valid|data_grain:per_time_bin|decoding_time_bin_size:0.025\n",
      "\tupdating results for context: trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:non_pbe_endcaps|masked_time_bin_fill_type:nan_filled|data_grain:per_time_bin|decoding_time_bin_size:0.025\n",
      "\tupdating results for context: trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:non_pbe_endcaps|masked_time_bin_fill_type:dropped|data_grain:per_time_bin|decoding_time_bin_size:0.025\n",
      "done.\n",
      "\tdone.\n",
      "IndexError: IdentifyingContext<('laps', 1, 'pseudo2D', 0.025)>. Skipping .creating_new_spikes_per_t_bin_masked_variants(...) for a_context: trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025.\n",
      "IndexError: IdentifyingContext<('laps', 1, 'pseudo2D', 0.025, 'pbe', 'ignore', 'per_time_bin')>. Skipping .creating_new_spikes_per_t_bin_masked_variants(...) for a_context: trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore|data_grain:per_time_bin.\n",
      "IndexError: IdentifyingContext<('laps', 1, 'pseudo2D', 0.025, 'laps', 'ignore', 'per_time_bin')>. Skipping .creating_new_spikes_per_t_bin_masked_variants(...) for a_context: trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore|data_grain:per_time_bin.\n",
      "IndexError: IdentifyingContext<('non_pbe', 1, 'pseudo2D', 0.025, 'laps', 'ignore', 'per_time_bin')>. Skipping .creating_new_spikes_per_t_bin_masked_variants(...) for a_context: trained_compute_epochs:non_pbe|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore|data_grain:per_time_bin.\n",
      "WARN: Epoch[10]: len(a_time_bin_edges): 0 != (num_time_bins+1): 1.\n",
      "\tcomputed 9 new results\n",
      "WARN: column: \"data_grain\" not in df!\n",
      "Found best match for a_result with 6 matching attributes:\ttrained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore\n",
      "\n",
      "Found best match for a_decoder with 6 matching attributes:\ttrained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore\n",
      "\n",
      "Warning: Different contexts matched: result=trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore, decoder=trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore, posterior=trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore|data_grain:per_time_bin\n",
      "WARN: column: \"data_grain\" not in df!\n",
      "Found best match for a_result with 6 matching attributes:\ttrained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore\n",
      "\n",
      "Found best match for a_decoder with 6 matching attributes:\ttrained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore\n",
      "\n",
      "Warning: Different contexts matched: result=trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore, decoder=trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore, posterior=trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore|data_grain:per_time_bin\n",
      "WARN: column: \"data_grain\" not in df!\n",
      "WARN: column: \"data_grain\" not in df!\n",
      "\t\tdone.\n",
      "\t all computations complete! (Computed 1 with no errors!.\n",
      "\t done.\n",
      "done with all batch_extended_computations(...).\n",
      "included includelist is specified: ['split_to_directional_laps', 'non_PBE_epochs_results', 'generalized_specific_epochs_decoding'], so only performing these extended computations.\n",
      "Running batch_evaluate_required_computations(...) with global_epoch_name: \"maze_any\"\n",
      "done with all batch_evaluate_required_computations(...).\n",
      "\tPost-load global computations: needs_computation_output_dict: ['split_to_directional_laps', 'non_PBE_epochs_results', 'generalized_specific_epochs_decoding']\n",
      "\t...recomputation done.\n",
      "\tepochs_decoding_time_bin_size: 0.025\n",
      "\t creating new across_session_results_extended_dict['generalized_decode_epochs_dict_and_export_results_completion_function']['a_new_fully_generic_result'] result.\n",
      "csv_save_paths_dict: {'FAT': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2025-07-11_0730AM-kdiba_gor01_one_2006-6-12_15-55-31__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 8, 9]-frateThresh_5.0-(FAT)_tbin-0.025.csv')}\n",
      "\n",
      "csv_save_paths_dict: {'FAT': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/collected_outputs/2025-07-11_0730AM-kdiba_gor01_one_2006-6-12_15-55-31__withNormalComputedReplays-qclu_[1, 2, 4, 6, 7, 8, 9]-frateThresh_5.0-(FAT)_tbin-0.025.csv')}\n",
      "\n",
      "\t\tdone.\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GenericDecoderDictDecodedEpochsDictResult(\n",
       "    spikes_df_dict=<['format_name:kdiba|animal:gor01|exper_name:one|session_name:2006-6-12_15-55-31', '', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:nan_filled', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:nan_filled|data_grain:per_time_bin', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:global|masked_time_bin_fill_type:nan_filled|data_grain:per_time_bin', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:nan_filled', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:nan_filled|data_grain:per_time_bin', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:non_pbe|masked_time_bin_fill_type:nan_filled', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:nan_filled', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:nan_filled', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:non_pbe_endcaps|masked_time_bin_fill_type:nan_filled|data_grain:per_time_bin|decoding_time_bin_size:0.025']>,\n",
       "    decoders=<['trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:nan_filled|data_grain:per_time_bin', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:nan_filled|data_grain:per_epoch', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:nan_filled|data_grain:per_time_bin', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:nan_filled|data_grain:per_epoch', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:global|masked_time_bin_fill_type:ignore|data_grain:per_time_bin', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:global|masked_time_bin_fill_type:nan_filled|data_grain:per_time_bin', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:non_pbe_endcaps|masked_time_bin_fill_type:ignore|data_grain:per_time_bin|decoding_time_bin_size:0.025', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:non_pbe_endcaps|masked_time_bin_fill_type:last_valid|data_grain:per_time_bin|decoding_time_bin_size:0.025', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:non_pbe_endcaps|masked_time_bin_fill_type:nan_filled|data_grain:per_time_bin|decoding_time_bin_size:0.025', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:non_pbe_endcaps|masked_time_bin_fill_type:dropped|data_grain:per_time_bin|decoding_time_bin_size:0.025', 'trained_compute_epochs:non_pbe|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore|data_grain:per_time_bin', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:dropped|data_grain:per_time_bin', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:dropped|data_grain:per_time_bin', 'trained_compute_epochs:non_pbe|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:dropped|data_grain:per_time_bin', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:dropped|data_grain:per_time_bin', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore|data_grain:per_epoch', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore|data_grain:per_epoch', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:dropped|data_grain:per_epoch', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:dropped|data_grain:per_epoch']>,\n",
       "    filter_epochs_to_decode_dict=<['trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:laps', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:last_valid', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:nan_filled', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:pbe', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:last_valid', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:nan_filled', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:non_pbe', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:non_pbe|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:non_pbe|masked_time_bin_fill_type:last_valid', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:non_pbe|masked_time_bin_fill_type:nan_filled', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:nan_filled', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:nan_filled', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:global|masked_time_bin_fill_type:ignore|data_grain:per_time_bin', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:non_pbe_endcaps|masked_time_bin_fill_type:ignore|data_grain:per_time_bin|decoding_time_bin_size:0.025', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:non_pbe_endcaps|masked_time_bin_fill_type:last_valid|data_grain:per_time_bin|decoding_time_bin_size:0.025', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:non_pbe_endcaps|masked_time_bin_fill_type:nan_filled|data_grain:per_time_bin|decoding_time_bin_size:0.025', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:non_pbe_endcaps|masked_time_bin_fill_type:dropped|data_grain:per_time_bin|decoding_time_bin_size:0.025']>,\n",
       "    filter_epochs_specific_decoded_result=<['trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:laps', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:last_valid', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:nan_filled', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:pbe', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:last_valid', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:nan_filled', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:non_pbe', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:non_pbe|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:non_pbe|masked_time_bin_fill_type:last_valid', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:non_pbe|masked_time_bin_fill_type:nan_filled', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:nan_filled|data_grain:per_time_bin', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:nan_filled|data_grain:per_epoch', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:nan_filled', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:nan_filled|data_grain:per_time_bin', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:nan_filled|data_grain:per_epoch', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:nan_filled', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:global|masked_time_bin_fill_type:ignore|data_grain:per_time_bin', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:global|masked_time_bin_fill_type:nan_filled|data_grain:per_time_bin', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:non_pbe_endcaps|masked_time_bin_fill_type:ignore|data_grain:per_time_bin|decoding_time_bin_size:0.025', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:non_pbe_endcaps|masked_time_bin_fill_type:last_valid|data_grain:per_time_bin|decoding_time_bin_size:0.025', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:non_pbe_endcaps|masked_time_bin_fill_type:nan_filled|data_grain:per_time_bin|decoding_time_bin_size:0.025', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:non_pbe_endcaps|masked_time_bin_fill_type:dropped|data_grain:per_time_bin|decoding_time_bin_size:0.025', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:dropped|data_grain:per_time_bin', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:dropped|data_grain:per_time_bin', 'trained_compute_epochs:non_pbe|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:dropped|data_grain:per_time_bin', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:dropped|data_grain:per_time_bin', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore|data_grain:per_epoch', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore|data_grain:per_epoch', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:dropped|data_grain:per_epoch', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:dropped|data_grain:per_epoch']>,\n",
       "    filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict=<['trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:last_valid', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:nan_filled', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:last_valid', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:nan_filled', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:non_pbe|masked_time_bin_fill_type:ignore', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:non_pbe|masked_time_bin_fill_type:last_valid', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:non_pbe|masked_time_bin_fill_type:nan_filled', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore|data_grain:per_time_bin', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:nan_filled|data_grain:per_time_bin', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:ignore|data_grain:per_epoch', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:nan_filled|data_grain:per_epoch', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore|data_grain:per_time_bin', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:nan_filled|data_grain:per_time_bin', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:ignore|data_grain:per_epoch', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:nan_filled|data_grain:per_epoch', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:global|masked_time_bin_fill_type:ignore|data_grain:per_time_bin', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:global|masked_time_bin_fill_type:nan_filled|data_grain:per_time_bin', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:non_pbe_endcaps|masked_time_bin_fill_type:ignore|data_grain:per_time_bin|decoding_time_bin_size:0.025', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:non_pbe_endcaps|masked_time_bin_fill_type:last_valid|data_grain:per_time_bin|decoding_time_bin_size:0.025', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:non_pbe_endcaps|masked_time_bin_fill_type:nan_filled|data_grain:per_time_bin|decoding_time_bin_size:0.025', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:non_pbe_endcaps|masked_time_bin_fill_type:dropped|data_grain:per_time_bin|decoding_time_bin_size:0.025', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:dropped|data_grain:per_time_bin', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:dropped|data_grain:per_time_bin', 'trained_compute_epochs:non_pbe|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:dropped|data_grain:per_time_bin', 'trained_compute_epochs:non_pbe|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:dropped|data_grain:per_time_bin', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:laps|masked_time_bin_fill_type:dropped|data_grain:per_epoch', 'trained_compute_epochs:laps|pfND_ndim:1|decoder_identifier:pseudo2D|time_bin_size:0.025|known_named_decoding_epochs_type:pbe|masked_time_bin_fill_type:dropped|data_grain:per_epoch']>\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext, DisplaySpecifyingIdentifyingContext, set_context_print_options\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "\n",
    "# Usage example:\n",
    "reset_printer = set_context_print_options(include_property_names=True)\n",
    "\n",
    "# Later to restore default behavior:\n",
    "# reset_printer()\n",
    "\n",
    "import pyphoplacecellanalysis.General.type_aliases as types\n",
    "from neuropy.utils.mixins.binning_helpers import BinningContainer, BinningInfo\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import generalized_decode_epochs_dict_and_export_results_completion_function, SimpleBatchComputationDummy\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult #, KnownNamedDecoderTrainedComputeEpochsType, KnownNamedDecodingEpochsType, MaskedTimeBinFillType, DataTimeGrain, GenericResultTupleIndexType\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "# epochs_decoding_time_bin_size: float = 0.050\n",
    "epochs_decoding_time_bin_size: float = 0.025\n",
    "## Settings:\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-generalized_decode_epochs_dict_and_export_results_completion_function.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | generalized_decode_epochs_dict_and_export_results_completion_function(a_dummy, None,\n",
    "                                                    curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                    across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                    force_recompute=True,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tepochs_decoding_time_bin_size=epochs_decoding_time_bin_size,\n",
    "                                                )\n",
    "\n",
    "callback_outputs = _across_session_results_extended_dict['generalized_decode_epochs_dict_and_export_results_completion_function'] # 'PostHocPipelineFixup'\n",
    "a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult = callback_outputs['a_new_fully_generic_result']\n",
    "csv_save_paths_dict: Dict[str, Path] = callback_outputs['csv_save_paths_dict']\n",
    "a_new_fully_generic_result\n",
    "\n",
    "# a_config_dict = callback_outputs['a_config_dict']\n",
    "# print(f'loaded_track_limits: {loaded_track_limits}') \n",
    "\n",
    "## OUTPUTS: a_new_fully_generic_result\n",
    " \n",
    "#  'computation_results[\"maze_any\"]': False, 'filtered_sessions[\"maze1_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze1_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze1_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze1_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze2_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze2_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze2_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze2_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze1_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_even\"].config.pix2cm': False, 'filtered_sessions[\"maze1_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.grid_bin': True, 'filtered_sessions[\"maze1_even\"].config.track_start_t': True, 'filtered_sessions[\"maze1_even\"].config.track_end_t': True, 'filtered_sessions[\"maze2_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_even\"].config.pix2cm': False, 'filtered_sessions[\"maze2_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.grid_bin': True, 'filtered_sessions[\"maze2_even\"].config.track_start_t': True, 'filtered_sessions[\"maze2_even\"].config.track_end_t': True, 'filtered_sessions[\"maze_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze_even\"].config.pix2cm': False, 'filtered_sessions[\"maze_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.grid_bin': True, 'filtered_sessions[\"maze_even\"].config.track_start_t': True, 'filtered_sessions[\"maze_even\"].config.track_end_t': True, 'filtered_sessions[\"maze1_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_any\"].config.pix2cm': False, 'filtered_sessions[\"maze1_any\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.grid_bin': True, 'filtered_sessions[\"maze1_any\"].config.track_start_t': True, 'filtered_sessions[\"maze1_any\"].config.track_end_t': True, 'filtered_sessions[\"maze2_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_any\"].config.pix2cm': False, 'filtered_sessions[\"maze2_any\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.grid_bin': True, 'filtered_sessions[\"maze2_any\"].config.track_start_t': True, 'filtered_sessions[\"maze2_any\"].config.track_end_t': True, 'filtered_sessions[\"maze_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze_any\"].config.pix2cm': False, 'filtered_sessions[\"maze_any\"].config.real_unit_grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.real_cm_grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.grid_bin': True, 'filtered_sessions[\"maze_any\"].config.track_start_t': False, 'filtered_sessions[\"maze_any\"].config.track_end_t': False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773b4b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_context = IdentifyingContext(pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='ignore', data_grain='per_time_bin')\n",
    "search_context = IdentifyingContext(pfND_ndim=2, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='ignore', data_grain='per_time_bin')\n",
    "a_ctxt, a_result, a_decoder, _ = a_new_fully_generic_result.get_results_matching_contexts(context_query=search_context, return_multiple_matches=False, debug_print=True)\n",
    "a_ctxt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4d37a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import DecodingResultND\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import ComputeGlobalEpochBase\n",
    "\n",
    "a_new_global_epoch_base_obj: ComputeGlobalEpochBase = ComputeGlobalEpochBase.init_from_pipeline(curr_active_pipeline=curr_active_pipeline)\n",
    "results1D, results2D = ComputeGlobalEpochBase.compute_all(curr_active_pipeline, single_global_epoch=a_new_global_epoch_base_obj.single_global_epoch_df,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   epochs_decoding_time_bin_size=0.025,\n",
    "                                                        #    frame_divide_bin_size=0.50,\n",
    "                                                           frame_divide_bin_size=10.00,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t   compute_1D=False, compute_2D=True)\n",
    "results2D\n",
    "## 7.5m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1424139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import BasePositionDecoder\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import SingleEpochDecodedResult\n",
    "\n",
    "## INPUTS: results2D\n",
    "global_pos_df: pd.DataFrame = deepcopy(results2D.pos_df) # computation_result.sess.position.to_dataframe()\n",
    "a_new_global2D_decoder: BasePositionDecoder = deepcopy(results2D.a_new_global2D_decoder)\n",
    "a_result2D: DecodedFilterEpochsResult = deepcopy(results2D.a_result2D)\n",
    "active_two_step_result, _OLD_two_step_decoder_result = BasePositionDecoder.perform_compute_two_step_decoder(active_decoder=a_new_global2D_decoder, active_one_step_result=a_result2D, pos_df=global_pos_df)\n",
    "# two_step_decoder_result\n",
    "active_two_step_result\n",
    "\n",
    "## OUTPUTS: active_two_step_result: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cfeed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_result2D: DecodedFilterEpochsResult = deepcopy(results2D.a_result2D)\n",
    "masked_a_result2D, _mask_index_tuple = a_result2D.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), min_num_spikes_per_bin_to_be_considered_active=5, min_num_unique_active_neurons_per_time_bin=1, masked_bin_fill_mode='ignore')\n",
    "# masked_a_result2D, _mask_index_tuple = a_result2D.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), min_num_spikes_per_bin_to_be_considered_active=5, min_num_unique_active_neurons_per_time_bin=1, masked_bin_fill_mode='nan_filled')\n",
    "# masked_a_result2D, _mask_index_tuple = a_result2D.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), min_num_spikes_per_bin_to_be_considered_active=5, min_num_unique_active_neurons_per_time_bin=1, masked_bin_fill_mode='last_valid')\n",
    "a_result2D = masked_a_result2D ## overwrite a_result2D\n",
    "## get 1D marginals to compare to 1D decoder:\n",
    "n_timebins, flat_time_bin_containers, timebins_p_x_given_n = a_result2D.flatten()\n",
    "flat_time_window_centers = np.hstack([v.centers for v in flat_time_bin_containers])\n",
    "timebins_marginal_x_p_x_given_n: NDArray = np.concatenate([a_marginal_x['p_x_given_n'] for a_marginal_x in masked_a_result2D.marginal_x_list], axis=-1) # (59, 83756) - (n_x_bins, n_flat_t_bins)\n",
    "assert np.shape(timebins_marginal_x_p_x_given_n)[-1] == n_timebins, f\"timebins_marginal_x_p_x_given_n.shape: {np.shape(timebins_marginal_x_p_x_given_n)}'s last dimension should equal n_timebins: {n_timebins}\"\n",
    "assert len(flat_time_window_centers) == n_timebins, f\"len(flat_time_window_centers): {len(flat_time_window_centers)} should equal n_timebins: {n_timebins}\"\n",
    "\n",
    "## OUTPUTS: flat_time_window_centers, timebins_marginal_x_p_x_given_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7863e0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import DockDisplayColors, CustomDockDisplayConfig\n",
    "\n",
    "## INPUTS: active_2d_plot\n",
    "\n",
    "## Do separately for the long/short epochs instead of using the global decoder built across all data:\n",
    "# masked_bin_fill_mode = 'ignore'\n",
    "masked_bin_fill_mode = 'nan_filled'\n",
    "# masked_bin_fill_mode = 'last_valid'\n",
    "_mask_kwargs = dict(min_num_spikes_per_bin_to_be_considered_active=2, min_num_unique_active_neurons_per_time_bin=1, masked_bin_fill_mode=masked_bin_fill_mode)\n",
    "\n",
    "for a_track_length in ['long', 'short']:\n",
    "    a_decoder: BasePositionDecoder = results2D.decoders[a_track_length]\n",
    "    a_result2D: DecodedFilterEpochsResult = deepcopy(results2D.continuous_results[a_track_length])\n",
    "    masked_a_result2D, _mask_index_tuple = a_result2D.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), **_mask_kwargs)\n",
    "    a_result2D = masked_a_result2D ## overwrite a_result2D\n",
    "    ## get 1D marginals to compare to 1D decoder:\n",
    "    n_timebins, flat_time_bin_containers, timebins_p_x_given_n = a_result2D.flatten()\n",
    "    flat_time_window_centers: NDArray = np.hstack([v.centers for v in flat_time_bin_containers])\n",
    "    timebins_marginal_x_p_x_given_n: NDArray = np.concatenate([a_marginal_x['p_x_given_n'] for a_marginal_x in masked_a_result2D.marginal_x_list], axis=-1) # (59, 83756) - (n_x_bins, n_flat_t_bins)\n",
    "    assert np.shape(timebins_marginal_x_p_x_given_n)[-1] == n_timebins, f\"timebins_marginal_x_p_x_given_n.shape: {np.shape(timebins_marginal_x_p_x_given_n)}'s last dimension should equal n_timebins: {n_timebins}\"\n",
    "    assert len(flat_time_window_centers) == n_timebins, f\"len(flat_time_window_centers): {len(flat_time_window_centers)} should equal n_timebins: {n_timebins}\"\n",
    "\n",
    "    ## OUTPUTS: flat_time_window_centers, timebins_marginal_x_p_x_given_n\n",
    "    ## INPUTS: flat_time_window_centers, timebins_marginal_x_p_x_given_n, a_new_global2D_decoder, global_pos_df\n",
    "    active_time_bin_size: float = a_result2D.decoding_time_bin_size\n",
    "    info_string: str = f'{active_time_bin_size:.3f}'\n",
    "    dock_group_sep_character: str = '_'\n",
    "    showCloseButton = True\n",
    "    _common_dock_config_kwargs = {'dock_group_names': [dock_group_sep_character.join([f'Result2D_MarginalX', info_string])], 'showCloseButton': showCloseButton, 'showTimelineSyncModeButton': True}\n",
    "\n",
    "    # dock_configs: Dict[str, CustomDockDisplayConfig] = {k:deepcopy(CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_global_dock_colors, **_common_dock_config_kwargs)) for k in unique_decoder_names}\n",
    "    # dock_configs: Dict[str, CustomDockDisplayConfig] = {k:deepcopy(CustomDockDisplayConfig(custom_get_colors_callback_fn=DockDisplayColors.get_random_dock_colors_for_key_fn(key=k), **_common_dock_config_kwargs)) for k in unique_decoder_names}\n",
    "    # pf1D_Decoder_dict = {k:deepcopy(v) for k, v in a_decoder.items() if k in unique_decoder_names}\n",
    "    # pf1D_Decoder_dict = {k:deepcopy(a_decoder) for k in unique_decoder_names} ## this is dumb, but it provides xlims!\n",
    "    # output_dict = active_2d_plot.add_docked_decoded_results_dict_tracks(name=f'LapsDecode', a_decoded_result_dict=a_pseudo2D_split_to_1D_continuous_results_dict, dock_configs=dock_configs,\n",
    "    #                                                                                             pf1D_Decoder_dict=pf1D_Decoder_dict,\n",
    "    #                                                                                             measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "    #                                                                                             extended_dock_title_info=info_string)\n",
    "\n",
    "\n",
    "    # # pf1D_Decoder_dict = {k:deepcopy(v) for k, v in a_decoder.items() if k in unique_decoder_names\n",
    "    key_name: str = f'Result2D_MarginalX[{a_track_length}]'\n",
    "    ## a_1D_continuous_decoded_result: SingleEpochDecodedResult\n",
    "    a_dock_config = CustomDockDisplayConfig(custom_get_colors_callback_fn=DockDisplayColors.get_random_dock_colors_for_key_fn(key=key_name), **_common_dock_config_kwargs)\n",
    "    # a_1D_decoder: BasePositionDecoder = pf1D_Decoder_dict[a_decoder_name]\n",
    "    # add_docked_decoded_posterior_track(name=name, time_window_centers=a_1D_decoded_result.time_bin_container.centers, a_1D_posterior=a_1D_decoded_result.p_x_given_n, xbin=xbin, measured_position_df=measured_position_df, **kwargs)\n",
    "    # _out_tuple = active_2d_plot.add_docked_decoded_posterior_track_from_result(name=f'{name}[{a_decoder_name}]', a_dock_config=a_dock_config, a_1D_decoded_result=a_1D_decoded_result,\n",
    "    #                                                                                         xbin = deepcopy(a_1D_decoder.xbin), measured_position_df=deepcopy(measured_position_df), **kwargs) # , should_defer_render=False\n",
    "\n",
    "    _out_tuple = active_2d_plot.add_docked_decoded_posterior_track(name=key_name, a_dock_config=a_dock_config, time_window_centers=flat_time_window_centers, a_1D_posterior=timebins_marginal_x_p_x_given_n,\n",
    "                                                                                            xbin = deepcopy(a_new_global2D_decoder.xbin), measured_position_df=deepcopy(global_pos_df)) # , should_defer_render=False\n",
    "    identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = _out_tuple\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59283a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import DockDisplayColors, CustomDockDisplayConfig\n",
    "\n",
    "## INPUTS: flat_time_window_centers, timebins_marginal_x_p_x_given_n, a_new_global2D_decoder, global_pos_df\n",
    "active_time_bin_size: float = a_result2D.decoding_time_bin_size\n",
    "info_string: str = f'{active_time_bin_size:.3f}'\n",
    "dock_group_sep_character: str = '_'\n",
    "showCloseButton = True\n",
    "_common_dock_config_kwargs = {'dock_group_names': [dock_group_sep_character.join([f'Result2D_MarginalX', info_string])], 'showCloseButton': showCloseButton, 'showTimelineSyncModeButton': True}\n",
    "\n",
    "# dock_configs: Dict[str, CustomDockDisplayConfig] = {k:deepcopy(CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_global_dock_colors, **_common_dock_config_kwargs)) for k in unique_decoder_names}\n",
    "# dock_configs: Dict[str, CustomDockDisplayConfig] = {k:deepcopy(CustomDockDisplayConfig(custom_get_colors_callback_fn=DockDisplayColors.get_random_dock_colors_for_key_fn(key=k), **_common_dock_config_kwargs)) for k in unique_decoder_names}\n",
    "# pf1D_Decoder_dict = {k:deepcopy(v) for k, v in a_decoder.items() if k in unique_decoder_names}\n",
    "# pf1D_Decoder_dict = {k:deepcopy(a_decoder) for k in unique_decoder_names} ## this is dumb, but it provides xlims!\n",
    "# output_dict = active_2d_plot.add_docked_decoded_results_dict_tracks(name=f'LapsDecode', a_decoded_result_dict=a_pseudo2D_split_to_1D_continuous_results_dict, dock_configs=dock_configs,\n",
    "#                                                                                             pf1D_Decoder_dict=pf1D_Decoder_dict,\n",
    "#                                                                                             measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "#                                                                                             extended_dock_title_info=info_string)\n",
    "\n",
    "\n",
    "# # pf1D_Decoder_dict = {k:deepcopy(v) for k, v in a_decoder.items() if k in unique_decoder_names\n",
    "key_name: str = f'Result2D_MarginalX[{a_track_length}]'\n",
    "## a_1D_continuous_decoded_result: SingleEpochDecodedResult\n",
    "a_dock_config = CustomDockDisplayConfig(custom_get_colors_callback_fn=DockDisplayColors.get_random_dock_colors_for_key_fn(key=key_name), **_common_dock_config_kwargs)\n",
    "# a_1D_decoder: BasePositionDecoder = pf1D_Decoder_dict[a_decoder_name]\n",
    "# add_docked_decoded_posterior_track(name=name, time_window_centers=a_1D_decoded_result.time_bin_container.centers, a_1D_posterior=a_1D_decoded_result.p_x_given_n, xbin=xbin, measured_position_df=measured_position_df, **kwargs)\n",
    "# _out_tuple = active_2d_plot.add_docked_decoded_posterior_track_from_result(name=f'{name}[{a_decoder_name}]', a_dock_config=a_dock_config, a_1D_decoded_result=a_1D_decoded_result,\n",
    "#                                                                                         xbin = deepcopy(a_1D_decoder.xbin), measured_position_df=deepcopy(measured_position_df), **kwargs) # , should_defer_render=False\n",
    "\n",
    "_out_tuple = active_2d_plot.add_docked_decoded_posterior_track(name=key_name, a_dock_config=a_dock_config, time_window_centers=flat_time_window_centers, a_1D_posterior=timebins_marginal_x_p_x_given_n,\n",
    "                                                                                        xbin = deepcopy(a_new_global2D_decoder.xbin), measured_position_df=deepcopy(global_pos_df)) # , should_defer_render=False\n",
    "\n",
    "\n",
    "identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = _out_tuple\n",
    "# ## Add `a_decoded_result` to the plots_data\n",
    "# widget.plots_data.a_decoded_result = a_1D_decoded_result\n",
    "# widget.plots_data.a_decoder = deepcopy(a_1D_decoder)\n",
    "# output_dict[a_decoder_name] = (identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem) ## add again\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a177899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_result2D.marginal_x_list\n",
    "(epochs_directional_marginals_tuple, epochs_track_identity_marginals_tuple, epochs_non_marginalized_decoder_marginals_tuple), epochs_marginals_df = a_result2D.compute_marginals(additional_transfer_column_names=['start','stop','label','duration','lap_id','lap_dir'])\n",
    "epochs_directional_marginals, epochs_directional_all_epoch_bins_marginal, epochs_most_likely_direction_from_decoder, epochs_is_most_likely_direction_LR_dir  = epochs_directional_marginals_tuple\n",
    "epochs_track_identity_marginals, epochs_track_identity_all_epoch_bins_marginal, epochs_most_likely_track_identity_from_decoder, epochs_is_most_likely_track_identity_Long = epochs_track_identity_marginals_tuple\n",
    "non_marginalized_decoder_marginals, non_marginalized_decoder_all_epoch_bins_marginal, most_likely_decoder_idxs, non_marginalized_decoder_all_epoch_bins_decoder_probs_df = epochs_non_marginalized_decoder_marginals_tuple\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0a80c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export to images output folder:\n",
    "from pyphocorehelpers.plotting.media_output_helpers import save_array_as_image, save_array_as_video\n",
    "\n",
    "# image, out_path = save_array_as_image(timebins_p_x_given_n, desired_height=512, desired_width=None, skip_img_normalization=True, out_path='')\n",
    "# image\n",
    "\n",
    "timebins_p_x_given_n_for_video = deepcopy(timebins_p_x_given_n) # timebins_p_x_given_n.shape: (59, 8, 83756) - (n_x_bins, n_y_bins, n_t_bins)\n",
    "timebins_p_x_given_n_for_video = timebins_p_x_given_n_for_video.transpose((2, 1, 0)) # (n_frames, n_height_bins, n_width_bins)\n",
    "video_out_path = save_array_as_video(array=timebins_p_x_given_n_for_video, video_filename='output/videos/2025-06-30_global2D_decoder.avi', isColor=False)\n",
    "print(f'video_out_path: {video_out_path}')\n",
    "reveal_in_system_file_manager(video_out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb9668",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timebins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9099e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_export_path = Path('data').resolve()\n",
    "\n",
    "an_export_basepath = parent_export_path.joinpath(f'{BATCH_DATE_TO_USE}_{epochs_decoding_time_bin_size}_results2D')\n",
    "out_PKL_export_path: Path = an_export_basepath.with_suffix('.pkl').resolve()\n",
    "out_HDF5_export_path: Path = an_export_basepath.with_suffix('.hdf').resolve()\n",
    "\n",
    "print(f'out_PKL_export_path: {out_PKL_export_path}')\n",
    "results2D.save(pkl_output_path=out_PKL_export_path)\n",
    "\n",
    "\n",
    "# print(f'out_HDF5_export_path: {out_HDF5_export_path}')\n",
    "# active_two_step_result: DecodedFilterEpochsResult = active_two_step_result\n",
    "# active_two_step_result.to_hdf(out_HDF5_export_path, key='active_two_step_result')\n",
    "# out_HDF5_export_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb72536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_export_path = Path('data').resolve()\n",
    "\n",
    "a_new_active_two_step_result_export_basepath = parent_export_path.joinpath(f'{BATCH_DATE_TO_USE}_{epochs_decoding_time_bin_size}_active_two_step_result')\n",
    "# a_new_fully_generic_result_HDF5_export_path: Path = a_new_fully_generic_result_export_basepath.with_suffix('.h5').resolve()\n",
    "# a_new_fully_generic_result.to_hdf(file_path=a_new_fully_generic_result_HDF5_export_path, key='a_new_fully_generic_result', debug_print=True, OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True) # , OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True\n",
    "\n",
    "# out_PKL_export_path: Path = a_new_active_two_step_result_export_basepath.with_suffix('.pkl').resolve()\n",
    "out_HDF5_export_path: Path = a_new_active_two_step_result_export_basepath.with_suffix('.hdf').resolve()\n",
    "\n",
    "# print(f'out_PKL_export_path: {out_PKL_export_path}')\n",
    "# a_new_fully_generic_result.save(pkl_output_path=out_PKL_export_path)\n",
    "\n",
    "print(f'out_HDF5_export_path: {out_HDF5_export_path}')\n",
    "active_two_step_result: DecodedFilterEpochsResult = active_two_step_result\n",
    "active_two_step_result.to_hdf(out_HDF5_export_path, key='active_two_step_result')\n",
    "out_HDF5_export_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45966b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_export_path = Path('data').resolve()\n",
    "\n",
    "a_new_fully_generic_result_export_basepath = parent_export_path.joinpath(f'{BATCH_DATE_TO_USE}_{epochs_decoding_time_bin_size}_a_new_fully_generic_result')\n",
    "# a_new_fully_generic_result_HDF5_export_path: Path = a_new_fully_generic_result_export_basepath.with_suffix('.h5').resolve()\n",
    "# a_new_fully_generic_result.to_hdf(file_path=a_new_fully_generic_result_HDF5_export_path, key='a_new_fully_generic_result', debug_print=True, OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True) # , OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True\n",
    "\n",
    "out_PKL_export_path: Path = a_new_fully_generic_result_export_basepath.with_suffix('.pkl').resolve()\n",
    "# out_HDF5_export_path: Path = a_new_fully_generic_result_export_basepath.with_suffix('.hdf').resolve()\n",
    "\n",
    "# print(f'out_PKL_export_path: {out_PKL_export_path}')\n",
    "a_new_fully_generic_result.save(pkl_output_path=out_PKL_export_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f924bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import LinearTrackInstance, _perform_plot_matplotlib_2D_tracks\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.mixins.decoder_plotting_mixins import DecodedTrajectoryMatplotlibPlotter\n",
    "from neuropy.utils.matplotlib_helpers import perform_update_title_subtitle\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.mixins.decoder_plotting_mixins import multi_DecodedTrajectoryMatplotlibPlotter_side_by_side\n",
    "\n",
    "n_axes: int = 10\n",
    "posterior_masking_value: float = 0.02 # for 2D\n",
    "a_decoded_traj_plotter, (fig, axs, decoded_epochs_pages) = multi_DecodedTrajectoryMatplotlibPlotter_side_by_side(a_result2D=results2D.a_result2D, a_new_global_decoder2D=results2D.a_new_global2D_decoder,\n",
    "                                                                                                                global_session=global_session, n_axes=n_axes, posterior_masking_value=posterior_masking_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f63c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_keys_if_possible('a_result2D', a_result2D, max_depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd837ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_keys_if_possible('a_result2D', a_result2D, max_depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c85d700",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_step_decoder_result['all_scaling_factors_k'] = Zhang_Two_Step.compute_scaling_factor_k(prev_one_step_bayesian_decoder.flat_p_x_given_n)\n",
    "_perform_two_step_position_decoding_computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bc6a92",
   "metadata": {
    "tags": [
     "run-2025-04-11_full-session_marginals"
    ]
   },
   "outputs": [],
   "source": [
    "# Save To pickle:\n",
    "## INPUTS: a_new_fully_generic_result\n",
    "# BATCH_DATE_TO_USE: str = f'2025-04-11_Apogee'\n",
    "# BATCH_DATE_TO_USE: str = f'2025-04-11_GL_{epochs_decoding_time_bin_size}'\n",
    "\n",
    "# parent_export_path = Path('/home/halechr/repos/Spike3D/data').resolve()\n",
    "parent_export_path = Path('data').resolve()\n",
    "\n",
    "a_new_fully_generic_result_export_basepath = parent_export_path.joinpath(f'{BATCH_DATE_TO_USE}_{epochs_decoding_time_bin_size}_a_new_fully_generic_result')\n",
    "# a_new_fully_generic_result_HDF5_export_path: Path = a_new_fully_generic_result_export_basepath.with_suffix('.h5').resolve()\n",
    "# a_new_fully_generic_result.to_hdf(file_path=a_new_fully_generic_result_HDF5_export_path, key='a_new_fully_generic_result', debug_print=True, OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True) # , OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True\n",
    "\n",
    "out_PKL_export_path: Path = a_new_fully_generic_result_export_basepath.with_suffix('.pkl').resolve()\n",
    "print(f'out_PKL_export_path: {out_PKL_export_path}')\n",
    "a_new_fully_generic_result.save(pkl_output_path=out_PKL_export_path)\n",
    "# \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca9a6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyphoplacecellanalysis.General.type_aliases as types\n",
    "from neuropy.utils.mixins.binning_helpers import BinningContainer, BinningInfo\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import generalized_decode_epochs_dict_and_export_results_completion_function, SimpleBatchComputationDummy\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult #, KnownNamedDecoderTrainedComputeEpochsType, KnownNamedDecodingEpochsType, MaskedTimeBinFillType, DataTimeGrain, GenericResultTupleIndexType\n",
    "\n",
    "## Load from previous pickle:\n",
    "# input_path = Path(f'/home/halechr/repos/Spike3D/data/2025-04-11_Apogee_a_new_fully_generic_result.pkl').resolve()\n",
    "input_path = Path(f'data/2025-04-11_Apogee_a_new_fully_generic_result.pkl').resolve()\n",
    "Assert.path_exists(input_path)\n",
    "a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult = GenericDecoderDictDecodedEpochsDictResult.from_file(pkl_path=input_path)\n",
    "a_new_fully_generic_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532ec01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.time_slicing import TimeColumnAliasesProtocol\n",
    "\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "epochs_decoding_time_bin_size = 0.025\n",
    "# epochs_decoding_time_bin_size = 0.050\n",
    "\n",
    "## ensure all optional fields are present before output:\n",
    "# Add the maze_id to the active_filter_epochs so we can see how properties change as a function of which track the replay event occured on:\n",
    "for k in list(a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict.keys()):\n",
    "    a_df = a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict[k]\n",
    "    ## note in per-epoch mode we use the start of the epoch (because for example laps are long and we want to see as soon as it starts) but for time bins we use the center time.\n",
    "    time_column_name: str = TimeColumnAliasesProtocol.find_first_extant_suitable_columns_name(a_df, col_connonical_name='t', required_columns_synonym_dict={\"t\":{'t_bin_center', 'lap_start_t', 'ripple_start_t', 'epoch_start_t'}}, should_raise_exception_on_fail=True)\n",
    "    assert time_column_name in a_df\n",
    "    a_df['delta_aligned_start_t'] = a_df[time_column_name] - t_delta ## subtract off t_delta\n",
    "    a_df = a_df.across_session_identity.add_session_df_columns(session_name=session_name, time_bin_size=epochs_decoding_time_bin_size, curr_session_t_delta=t_delta, time_col=time_column_name)\n",
    "    a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict[k] = a_df\n",
    "    # display(a_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64837420",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export to CSVs:\n",
    "csv_save_paths = {}\n",
    "active_export_parent_output_path = a_dummy.collected_outputs_path.resolve()\n",
    "# Assert.path_exists(parent_output_path)\n",
    "\n",
    "## INPUTS: collected_outputs_path\n",
    "decoding_time_bin_size: float = epochs_decoding_time_bin_size\n",
    "\n",
    "complete_session_context, (session_context, additional_session_context) = curr_active_pipeline.get_complete_session_context()\n",
    "active_context = complete_session_context ## This context isn't enough! Easiest to build using `curr_active_pipeline` directly.\n",
    "\n",
    "def _subfn_custom_export_df_to_csv(export_df: pd.DataFrame, data_identifier_str: str = f'(laps_marginals_df)', parent_output_path: Path=None):\n",
    "    \"\"\" captures CURR_BATCH_DATE_TO_USE, `curr_active_pipeline`\n",
    "    \"\"\"\n",
    "    output_date_str: str = get_now_rounded_time_str(rounded_minutes=10)\n",
    "    out_path, out_filename, out_basename = curr_active_pipeline.build_complete_session_identifier_filename_string(output_date_str=output_date_str, data_identifier_str=data_identifier_str, parent_output_path=parent_output_path, out_extension='.csv')\n",
    "    export_df.to_csv(out_path)\n",
    "    return out_path \n",
    "\n",
    "\n",
    "custom_export_df_to_csv_fn = _subfn_custom_export_df_to_csv\n",
    "\n",
    "\n",
    "# build_complete_session_identifier_filename_string\n",
    "\n",
    "\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "earliest_delta_aligned_t_start, t_delta, latest_delta_aligned_t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "# tbin_values_dict={'laps': decoding_time_bin_size, 'pbe': decoding_time_bin_size, 'non_pbe': decoding_time_bin_size, 'FAT': decoding_time_bin_size}\n",
    "\n",
    "# csv_save_paths_dict = GenericDecoderDictDecodedEpochsDictResult._perform_export_dfs_dict_to_csvs(extracted_dfs_dict=a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict,\n",
    "csv_save_paths_dict = a_new_fully_generic_result.export_csvs(\n",
    "                                        parent_output_path=active_export_parent_output_path.resolve(),\n",
    "                                        active_context=active_context, session_name=session_name, #curr_active_pipeline=curr_active_pipeline,\n",
    "                                        decoding_time_bin_size=decoding_time_bin_size,\n",
    "                                        curr_session_t_delta=t_delta, \n",
    "                                        custom_export_df_to_csv_fn=custom_export_df_to_csv_fn,\n",
    "                                        )\n",
    "\n",
    "print(f'csv_save_paths_dict: {csv_save_paths_dict}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1269a3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_new_fully_generic_result.get_matching_contexts(IdentifyingContext(), return_multiple_matches=True, ) ## this only returns 3 results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97171718",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get old results\n",
    "# decoder_laps_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict)\n",
    "# all_directional_ripple_filter_epochs_decoder_result: DecodedFilterEpochsResult = directional_merged_decoders_result.laps_all_epoch_bins_marginals_df\n",
    "# decoder_laps_filter_epochs_decoder_result_dict.compute_marginals()\n",
    "laps_all_epoch_bins_marginals_df = deepcopy(directional_merged_decoders_result.laps_all_epoch_bins_marginals_df)\n",
    "laps_all_epoch_bins_marginals_df\n",
    "\n",
    "\n",
    "# active_marginals=ripple_track_identity_marginals, columns=['P_LR', 'P_RL']\n",
    "# active_marginals=ripple_track_identity_marginals, columns=['P_Long', 'P_Short']\n",
    "# _build_multiple_per_time_bin_marginals(a_decoder_result=decoder_laps_filter_epochs_decoder_result_dict, active_marginals_tuple=(laps_directional_all_epoch_bins_marginal, laps_track_identity_all_epoch_bins_marginal), columns_tuple=(['P_LR', 'P_RL'], ['P_Long', 'P_Short']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d1bf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get new results\n",
    "best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_matching_contexts(context_query=IdentifyingContext(trained_compute_epochs='laps', time_bin_size=0.025, known_named_decoding_epochs_type='laps', decoder_identifier='pseudo2D', masked_time_bin_fill_type='ignore'), debug_print=True, return_multiple_matches=False)\n",
    "\n",
    "## Plot them against each other for comparison\n",
    "a_decoded_marginal_posterior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3de43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_result.decoding_time_bin_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7788f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_laps_filter_epochs_decoder_result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff79ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "\n",
    "curr_active_pipeline.reload_default_computation_functions()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552cdd7d",
   "metadata": {},
   "source": [
    "### Call `compute_and_export_session_extended_placefield_peak_information_completion_function`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f93d69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext, DisplaySpecifyingIdentifyingContext, set_context_print_options\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "\n",
    "# Usage example:\n",
    "reset_printer = set_context_print_options(include_property_names=True)\n",
    "\n",
    "# Later to restore default behavior:\n",
    "# reset_printer()\n",
    "\n",
    "import pyphoplacecellanalysis.General.type_aliases as types\n",
    "from neuropy.utils.mixins.binning_helpers import BinningContainer, BinningInfo\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import compute_and_export_session_extended_placefield_peak_information_completion_function, SimpleBatchComputationDummy\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult #, KnownNamedDecoderTrainedComputeEpochsType, KnownNamedDecodingEpochsType, MaskedTimeBinFillType, DataTimeGrain, GenericResultTupleIndexType\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-compute_and_export_session_extended_placefield_peak_information_completion_function.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | compute_and_export_session_extended_placefield_peak_information_completion_function(a_dummy, None,\n",
    "                                                    curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                    across_session_results_extended_dict=_across_session_results_extended_dict, save_csv=True, save_json=False\n",
    "                                                )\n",
    "\n",
    "callback_outputs = _across_session_results_extended_dict['compute_and_export_session_extended_placefield_peak_information_completion_function'] # 'PostHocPipelineFixup'\n",
    "csv_output_path: str = callback_outputs['csv_output_path']\n",
    "csv_output_path\n",
    "\n",
    "# a_config_dict = callback_outputs['a_config_dict']\n",
    "# print(f'loaded_track_limits: {loaded_track_limits}') \n",
    "\n",
    "## OUTPUTS: a_new_fully_generic_result\n",
    " \n",
    "#  'computation_results[\"maze_any\"]': False, 'filtered_sessions[\"maze1_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze1_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze1_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze1_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze2_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze2_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze2_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze2_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze_odd\"].loaded_track_limits': True, 'filtered_sessions[\"maze_odd\"].config.pix2cm': False, 'filtered_sessions[\"maze_odd\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze_odd\"].config.grid_bin': True, 'filtered_sessions[\"maze_odd\"].config.track_start_t': True, 'filtered_sessions[\"maze_odd\"].config.track_end_t': True, 'filtered_sessions[\"maze1_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_even\"].config.pix2cm': False, 'filtered_sessions[\"maze1_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_even\"].config.grid_bin': True, 'filtered_sessions[\"maze1_even\"].config.track_start_t': True, 'filtered_sessions[\"maze1_even\"].config.track_end_t': True, 'filtered_sessions[\"maze2_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_even\"].config.pix2cm': False, 'filtered_sessions[\"maze2_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_even\"].config.grid_bin': True, 'filtered_sessions[\"maze2_even\"].config.track_start_t': True, 'filtered_sessions[\"maze2_even\"].config.track_end_t': True, 'filtered_sessions[\"maze_even\"].loaded_track_limits': True, 'filtered_sessions[\"maze_even\"].config.pix2cm': False, 'filtered_sessions[\"maze_even\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze_even\"].config.grid_bin': True, 'filtered_sessions[\"maze_even\"].config.track_start_t': True, 'filtered_sessions[\"maze_even\"].config.track_end_t': True, 'filtered_sessions[\"maze1_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze1_any\"].config.pix2cm': False, 'filtered_sessions[\"maze1_any\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze1_any\"].config.grid_bin': True, 'filtered_sessions[\"maze1_any\"].config.track_start_t': True, 'filtered_sessions[\"maze1_any\"].config.track_end_t': True, 'filtered_sessions[\"maze2_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze2_any\"].config.pix2cm': False, 'filtered_sessions[\"maze2_any\"].config.real_unit_grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.real_cm_grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.grid_bin_bounds': True, 'filtered_sessions[\"maze2_any\"].config.grid_bin': True, 'filtered_sessions[\"maze2_any\"].config.track_start_t': True, 'filtered_sessions[\"maze2_any\"].config.track_end_t': True, 'filtered_sessions[\"maze_any\"].loaded_track_limits': True, 'filtered_sessions[\"maze_any\"].config.pix2cm': False, 'filtered_sessions[\"maze_any\"].config.real_unit_grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.real_cm_grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.grid_bin_bounds': False, 'filtered_sessions[\"maze_any\"].config.grid_bin': True, 'filtered_sessions[\"maze_any\"].config.track_start_t': False, 'filtered_sessions[\"maze_any\"].config.track_end_t': False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd91f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save To pickle:\n",
    "## INPUTS: a_new_fully_generic_result\n",
    "# BATCH_DATE_TO_USE: str = f'2025-04-11_Apogee'\n",
    "# BATCH_DATE_TO_USE: str = f'2025-04-11_GL_{epochs_decoding_time_bin_size}'\n",
    "\n",
    "# parent_export_path = Path('/home/halechr/repos/Spike3D/data').resolve()\n",
    "parent_export_path = Path('data').resolve()\n",
    "\n",
    "a_new_fully_generic_result_export_basepath = parent_export_path.joinpath(f'{BATCH_DATE_TO_USE}_{epochs_decoding_time_bin_size}_a_new_fully_generic_result')\n",
    "# a_new_fully_generic_result_HDF5_export_path: Path = a_new_fully_generic_result_export_basepath.with_suffix('.h5').resolve()\n",
    "# a_new_fully_generic_result.to_hdf(file_path=a_new_fully_generic_result_HDF5_export_path, key='a_new_fully_generic_result', debug_print=True, OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True) # , OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True\n",
    "\n",
    "out_PKL_export_path: Path = a_new_fully_generic_result_export_basepath.with_suffix('.pkl').resolve()\n",
    "print(f'out_PKL_export_path: {out_PKL_export_path}')\n",
    "a_new_fully_generic_result.save(pkl_output_path=out_PKL_export_path)\n",
    "# \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d523ee",
   "metadata": {},
   "source": [
    "# 2025-06-05 - Theta Phase Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859549d4",
   "metadata": {
    "tags": [
     "2025-06-05_thetaphaseanalysis"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.TimeCurves.SpecificTimeCurves import PositionRenderTimeCurves, ConfigurableRenderTimeCurves, ThetaPhaseRenderTimeCurves\n",
    "\n",
    "\n",
    "def circular_diff(angles):\n",
    "    \"\"\"\n",
    "    Calculate circular difference for angular data.\n",
    "    Handles wrap-around at 2π.\n",
    "    \"\"\"\n",
    "    diff = np.diff(angles)\n",
    "    # Wrap differences to [-π, π]\n",
    "    diff = (diff + np.pi) % (2 * np.pi) - np.pi\n",
    "    return np.abs(diff)\n",
    "\n",
    "\n",
    "## firing statistics to bins instead of boolean masking by those meeting criteria\n",
    "spikes_df: pd.DataFrame = get_proper_global_spikes_df(curr_active_pipeline)\n",
    "spikes_df['accel'] = spikes_df['speed'].diff().abs() / spikes_df['t_rel_seconds'].diff()\n",
    "spikes_df['theta_phase_radians_per_sec'] = spikes_df['theta_phase_radians'].diff().abs() / spikes_df['t_rel_seconds'].diff()\n",
    "\n",
    "# Handle circular statistics for theta phase\n",
    "theta_phase_circular_diff = circular_diff(spikes_df['theta_phase_radians'].to_numpy())\n",
    "time_diff = spikes_df['t_rel_seconds'].diff().iloc[1:].to_numpy()  # Skip first NaN\n",
    "spikes_df['theta_phase_radians_per_sec'] = np.concatenate([[np.nan], theta_phase_circular_diff / time_diff])\n",
    "\n",
    "\n",
    "theta_phase_radians = spikes_df['theta_phase_radians'].to_numpy()\n",
    "spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41f9fe9",
   "metadata": {
    "tags": [
     "2025-05-27_theta-phase-added",
     "2025-06-05_thetaphaseanalysis"
    ]
   },
   "outputs": [],
   "source": [
    "# active_2d_plot.get_leaf_only_flat_dock_identifiers_list()\n",
    "a_time_sync_pyqtgraph_widget, root_graphics_layout_widget, plot_item, dDisplayItem = active_2d_plot.add_new_embedded_pyqtgraph_render_plot_widget(name='thetaPhase', dockSize=(1, 4), sync_mode=SynchronizedPlotMode.TO_WINDOW)\n",
    "theta_phase_line_actor = plot_item.plot(spikes_df['t_rel_seconds'].to_numpy(), spikes_df['theta_phase_radians'].to_numpy(), pen='#FFFFFF', symbolBrush='#FFFFFF', symbolPen='#FFFFFF', symbol='o', symbolSize=2, name=\"theta_phase\")\n",
    "# theta_phase_line_actor = plot_item.scatterPlot(spikes_df['t_rel_seconds'].to_nump+y(), spikes_df['theta_phase_radians'].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb3fb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "spikes_df.plot.scatter(x='speed', y='theta_phase_radians', title='Speed v. Theta Phase')\n",
    "# .corrcoef(\n",
    "spikes_df[['speed','theta_phase_radians']].corr(method='pearson')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2407cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUITS: spikes_df\n",
    "spikes_df.plot.scatter(x='x', y='theta_phase_radians_per_sec', title='x (pos) v. Theta-freq (rad/sec)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf0dbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUITS: spikes_df\n",
    "spikes_df.plot.scatter(x='speed', y='theta_phase_radians_per_sec', title='Speed v. Theta-freq (rad/sec)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dd4756",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## INPUITS: spikes_df\n",
    "spikes_df.plot.scatter(x='accel', y='theta_phase_radians_per_sec', title='Accel v. Theta-freq (rad/sec)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ff4de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spikes_df[['x','theta_phase_radians']].corr(method='pearson')\n",
    "# spikes_df[['speed','theta_phase_radians']].corr(method='pearson')\n",
    "# spikes_df[['accel','theta_phase_radians']].corr(method='pearson')\n",
    "\n",
    "filtered_spikes_df = deepcopy(spikes_df)\n",
    "filtered_spikes_df = filtered_spikes_df.dropna(how='any', subset=['x', 'speed', 'accel', 'theta_phase_radians_per_sec']) \n",
    "filtered_spikes_df\n",
    "np.corrcoef(filtered_spikes_df['x'].dropna().to_numpy(), filtered_spikes_df['theta_phase_radians_per_sec'].to_numpy())[1, 0]\n",
    "np.corrcoef(filtered_spikes_df['speed'].dropna().to_numpy(), filtered_spikes_df['theta_phase_radians_per_sec'].to_numpy())[1, 0]\n",
    "np.corrcoef(filtered_spikes_df['accel'].dropna().to_numpy(), filtered_spikes_df['theta_phase_radians_per_sec'].to_numpy())[1, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4d6290",
   "metadata": {},
   "outputs": [],
   "source": [
    "x: -0.01011012051718423\n",
    "speed: 0.06179871169990722\n",
    "accel: 0.01011012051718423"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f1a8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.clear_all_3D_time_curves()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062d587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.params.time_curves_datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0168c821",
   "metadata": {
    "tags": [
     "2025-06-05_thetaphaseanalysis"
    ]
   },
   "outputs": [],
   "source": [
    "_out = PositionRenderTimeCurves.add_render_time_curves(curr_sess=global_session, destination_plot=active_2d_plot)\n",
    "_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d5149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out.active_data_column_names\n",
    "_out.df\n",
    "_out._data_series_specs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcff71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.params.use_docked_pyqtgraph_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed012e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_docked_pyqtgraph_plots: bool = active_2d_plot.params.use_docked_pyqtgraph_plots\n",
    "use_docked_pyqtgraph_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f57ef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.ui.main_time_curves_view_widget # PlotItem \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed7fcaf",
   "metadata": {
    "tags": [
     "2025-06-05_thetaphaseanalysis"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c806e672",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9738b9d5",
   "metadata": {
    "tags": [
     "2025-06-05_thetaphaseanalysis"
    ]
   },
   "outputs": [],
   "source": [
    "a_widget.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e065c5",
   "metadata": {
    "tags": [
     "2025-06-05_thetaphaseanalysis"
    ]
   },
   "outputs": [],
   "source": [
    "spikes_df['t_rel_seconds'].to_numpy(), spikes_df['theta_phase_radians'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2aa502",
   "metadata": {
    "tags": [
     "2025-06-05_thetaphaseanalysis"
    ]
   },
   "outputs": [],
   "source": [
    "# 'theta_phase_radians'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1beeb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "# %aimport pyphoplacecellanalysis.Analysis.Decoder.context_dependent\n",
    "\n",
    "## Get a specific context to plot: \n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=2, decoder_identifier='long_LR', time_bin_size=0.025, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore')\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', time_bin_size=0.025, known_named_decoding_epochs_type='pbe') # , decoder_identifier='long_LR', masked_time_bin_fill_type='ignore', pfND_ndim=2\n",
    "\n",
    "best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, debug_print=True)\n",
    "print(f'best_matching_context: {best_matching_context}')\n",
    "# a_decoded_marginal_posterior_df\n",
    "## OUTPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder\n",
    "a_decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19730492",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "\n",
    "a_new_fully_generic_result = a_new_fully_generic_result.compute_continuous_fn(curr_active_pipeline=curr_active_pipeline, debug_print=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ba7dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(a_new_fully_generic_result.decoders.keys())\n",
    "\n",
    "\n",
    "search_context = IdentifyingContext(pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global') # , data_grain= 'per_time_bin -- not really relevant: ['masked_time_bin_fill_type', 'known_named_decoding_epochs_type', 'data_grain']\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=search_context, return_multiple_matches=True, debug_print=True)\n",
    "# a_context, a_result, a_decoder, _ = a_new_fully_generic_result.get_results_matching_contexts(context_query=search_context, return_multiple_matches=False, debug_print=True)\n",
    "# a_decoder\n",
    "flat_context_list\n",
    "# flat_decoder_context_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef17ee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get a specific context to plot:\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='long_LR', time_bin_size=0.025, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore')\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore') # , decoder_identifier='long_LR'\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, known_named_decoding_epochs_type='laps') # , masked_time_bin_fill_type='ignore', decoder_identifier='long_LR'\n",
    "\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', time_bin_size=0.025) # , known_named_decoding_epochs_type='laps'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "flat_context_list\n",
    "## OUTPUTS: flat_context_list: List[IdentifyingContext], flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict\n",
    "## OUTPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e64168",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', time_bin_size=0.025) # , known_named_decoding_epochs_type='laps'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "flat_context_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5977a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import build_single_plotly_marginal_scatter_and_hist_over_time\n",
    "\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "epochs_decoding_time_bin_size: float = 0.025\n",
    "\n",
    "#INPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder\n",
    "_flat_out_figs_dict = {}\n",
    "\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "flat_context_list\n",
    "\n",
    "for a_ctxt, a_decoded_marginal_posterior_df in flat_decoded_marginal_posterior_df_context_dict.items():\n",
    "    print(a_ctxt)\n",
    "    \n",
    "    # Add the maze_id to the active_filter_epochs so we can see how properties change as a function of which track the replay event occured on:\n",
    "    a_decoded_marginal_posterior_df = a_decoded_marginal_posterior_df.across_session_identity.add_session_df_columns(session_name=session_name, time_bin_size=epochs_decoding_time_bin_size, curr_session_t_delta=t_delta) # , time_col='t'\n",
    "        \n",
    "    a_fig, a_figure_context = build_single_plotly_marginal_scatter_and_hist_over_time(a_decoded_posterior_df=a_decoded_marginal_posterior_df, a_target_context=a_ctxt)\n",
    "    a_fig = a_fig.update_layout(height=300, margin=dict(t=20, b=0),  # Set top and bottom margins to 0\n",
    "                        )  # Set your desired height\n",
    "    _flat_out_figs_dict[a_figure_context] = a_fig\n",
    "\n",
    "    a_fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eac0c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _plot_plotly_stack_marginal_scatter_and_hist_over_time\n",
    "\n",
    "\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "epochs_decoding_time_bin_size: float = 0.025\n",
    "\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type='laps', data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "_flat_out_figs_dict = _plot_plotly_stack_marginal_scatter_and_hist_over_time(flat_decoded_marginal_posterior_df_context_dict=flat_decoded_marginal_posterior_df_context_dict, session_name=session_name, t_delta=t_delta, epochs_decoding_time_bin_size=epochs_decoding_time_bin_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307e4bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='non_pbe', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type='pbe', data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "_flat_out_figs_dict = _plot_plotly_stack_marginal_scatter_and_hist_over_time(flat_decoded_marginal_posterior_df_context_dict=flat_decoded_marginal_posterior_df_context_dict, session_name=session_name, t_delta=t_delta, epochs_decoding_time_bin_size=epochs_decoding_time_bin_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ff5846",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ensure all optional fields are present before output:\n",
    "# Add the maze_id to the active_filter_epochs so we can see how properties change as a function of which track the replay event occured on:\n",
    "for k in list(a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict.keys()):\n",
    "    a_df = a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict[k]\n",
    "    ## note in per-epoch mode we use the start of the epoch (because for example laps are long and we want to see as soon as it starts) but for time bins we use the center time.\n",
    "    time_column_name: str = TimeColumnAliasesProtocol.find_first_extant_suitable_columns_name(a_df, col_connonical_name='t', required_columns_synonym_dict={\"t\":{'t_bin_center', 'lap_start_t', 'ripple_start_t', 'epoch_start_t'}}, should_raise_exception_on_fail=True)\n",
    "    assert time_column_name in a_df\n",
    "    a_df['delta_aligned_start_t'] = a_df[time_column_name] - t_delta ## subtract off t_delta\n",
    "    a_df = a_df.across_session_identity.add_session_df_columns(session_name=session_name, time_bin_size=epochs_decoding_time_bin_size, curr_session_t_delta=t_delta, time_col=time_column_name)\n",
    "    a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict[k] = a_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4819748",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='non_pbe', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size= 0.025, data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps', known_named_decoding_epochs_type='pbe'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "_flat_out_figs_dict = _plot_plotly_stack_marginal_scatter_and_hist_over_time(flat_decoded_marginal_posterior_df_context_dict=flat_decoded_marginal_posterior_df_context_dict, session_name=session_name, t_delta=t_delta, epochs_decoding_time_bin_size=epochs_decoding_time_bin_size)\n",
    "# flat_decoded_marginal_posterior_df_context_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61b7ea0",
   "metadata": {},
   "source": [
    "#### 🟢🟢⚓🟢🟢 Add to SpikeRaster2D as tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fd2c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot = spike_raster_window.spike_raster_plt_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1b9486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=0.025, masked_time_bin_fill_type='last_valid', data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps'\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=0.025, masked_time_bin_fill_type='ignore', data_grain='per_time_bin', known_named_decoding_epochs_type= 'global') # , known_named_decoding_epochs_type='laps'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "# print(f'flat_context_list: {flat_context_list}')\n",
    "flat_decoded_marginal_posterior_df_context_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963dd30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, DockDisplayColors\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "\n",
    "\n",
    "# search_context = IdentifyingContext(pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global') # , data_grain= 'per_time_bin -- not really relevant: ['masked_time_bin_fill_type', 'known_named_decoding_epochs_type', 'data_grain']\n",
    "# flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=search_context, return_multiple_matches=True, debug_print=True)\n",
    "# # a_context, a_result, a_decoder, _ = a_new_fully_generic_result.get_results_matching_contexts(context_query=search_context, return_multiple_matches=False, debug_print=True)\n",
    "# # a_decoder\n",
    "# flat_context_list\n",
    "# flat_decoder_context_dict\n",
    "\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=0.025, masked_time_bin_fill_type='ignore', data_grain='per_time_bin', known_named_decoding_epochs_type= 'global') # , known_named_decoding_epochs_type='laps'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "# print(f'flat_context_list: {flat_context_list}')\n",
    "flat_decoded_marginal_posterior_df_context_dict\n",
    "\n",
    "unique_decoder_names_map: Dict = {'laps': ['long_LR', 'long_RL', 'short_LR', 'short_RL'], 'non_pbe': ['long', 'short']}\n",
    "\n",
    "\n",
    "for a_ctxt, a_result in flat_result_context_dict.items():\n",
    "    ## INPUTS: laps_pseudo2D_continuous_specific_decoded_result: DecodedFilterEpochsResult\n",
    "    a_decoder = flat_decoder_context_dict[a_ctxt]\n",
    "    \n",
    "    unique_decoder_names = unique_decoder_names_map[a_ctxt.get('trained_compute_epochs', None)] # ['long', 'short']\n",
    "    unique_decoder_names = [f\"{a_ctxt}[{k}]\" for k in unique_decoder_names]\n",
    "    \n",
    "    a_pseudo2D_split_to_1D_continuous_results_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = a_result.split_pseudo2D_result_to_1D_result(pseudo2D_decoder_names_list=unique_decoder_names)    \n",
    "    a_pseudo2D_split_to_1D_continuous_results_dict = {k:v for k, (_o, v) in zip(unique_decoder_names, a_pseudo2D_split_to_1D_continuous_results_dict.items())} ## change to the long unique indicies so they match the decoders\n",
    "    \n",
    "    # a_pseudo2D_split_to_1D_continuous_results_dict\n",
    "    \n",
    "    active_time_bin_size: float = a_result.decoding_time_bin_size\n",
    "    info_string: str = f'{active_time_bin_size:.3f}'\n",
    "    dock_group_sep_character: str = '_'\n",
    "    showCloseButton = True\n",
    "    _common_dock_config_kwargs = {'dock_group_names': [dock_group_sep_character.join([f'LapsDecode', info_string])], 'showCloseButton': showCloseButton, 'showTimelineSyncModeButton': True}\n",
    "\n",
    "    # dock_configs: Dict[str, CustomDockDisplayConfig] = {k:deepcopy(CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_global_dock_colors, **_common_dock_config_kwargs)) for k in unique_decoder_names}\n",
    "    dock_configs: Dict[str, CustomDockDisplayConfig] = {k:deepcopy(CustomDockDisplayConfig(custom_get_colors_callback_fn=DockDisplayColors.get_random_dock_colors_for_key_fn(key=k), **_common_dock_config_kwargs)) for k in unique_decoder_names}\n",
    "    \n",
    "    # flat_decoder_context_dict\n",
    "\n",
    "    # pf1D_Decoder_dict = {k:deepcopy(v) for k, v in a_decoder.items() if k in unique_decoder_names}\n",
    "\n",
    "    pf1D_Decoder_dict = {k:deepcopy(a_decoder) for k in unique_decoder_names} ## this is dumb, but it provides xlims!\n",
    "\n",
    "    output_dict = active_2d_plot.add_docked_decoded_results_dict_tracks(name=f'LapsDecode', a_decoded_result_dict=a_pseudo2D_split_to_1D_continuous_results_dict, dock_configs=dock_configs,\n",
    "                                                                                                pf1D_Decoder_dict=pf1D_Decoder_dict,\n",
    "                                                                                                measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "                                                                                                extended_dock_title_info=info_string)\n",
    "\n",
    "\n",
    "    # # pf1D_Decoder_dict = {k:deepcopy(v) for k, v in a_decoder.items() if k in unique_decoder_names}\n",
    "\n",
    "    # ## a_1D_continuous_decoded_result: SingleEpochDecodedResult\n",
    "    # a_dock_config = dock_configs[a_decoder_name]\n",
    "    # a_1D_decoder: BasePositionDecoder = pf1D_Decoder_dict[a_decoder_name]\n",
    "    # _out_tuple = self.add_docked_decoded_posterior_track_from_result(name=f'{name}[{a_decoder_name}]', a_dock_config=a_dock_config, a_1D_decoded_result=a_1D_decoded_result,\n",
    "    #                                                                                         xbin = deepcopy(a_1D_decoder.xbin), measured_position_df=deepcopy(measured_position_df), **kwargs) # , should_defer_render=False\n",
    "    # identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = _out_tuple\n",
    "    # ## Add `a_decoded_result` to the plots_data\n",
    "    # widget.plots_data.a_decoded_result = a_1D_decoded_result\n",
    "    # widget.plots_data.a_decoder = deepcopy(a_1D_decoder)\n",
    "    # output_dict[a_decoder_name] = (identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem) ## add again\n",
    "\n",
    "\n",
    "# output_dict = active_2d_plot.add_docked_decoded_results_dict_tracks(name=f'LapsDecode', a_decoded_result_dict=a_pseudo2D_split_to_1D_continuous_results_dict, dock_configs=dock_configs, pf1D_Decoder_dict=flat_decoder_context_dict,\n",
    "#                                                                                             measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "#                                                                                             extended_dock_title_info=info_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f0c8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dock_item.sigToggleTimelineSyncModeClicked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31e8981",
   "metadata": {},
   "outputs": [],
   "source": [
    "dock_item.sigToggleTimelineSyncModeClicked.disconnect(_conn)\n",
    "dock_item.sigToggleTimelineSyncModeClicked.disconnect_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bd65ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.sync_matplotlib_render_plot_widget(identifier_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfc623b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, DockDisplayColors\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import SynchronizedPlotMode\n",
    "\n",
    "# epochs_decoding_time_bin_size: float = 0.025\n",
    "epochs_decoding_time_bin_size: float = 0.050\n",
    "# # search_context = IdentifyingContext(pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type= 'nan_filled') # , data_grain= 'per_time_bin -- not really relevant: ['masked_time_bin_fill_type', 'known_named_decoding_epochs_type', 'data_grain']\n",
    "# search_context = IdentifyingContext(pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type= 'ignore')\n",
    "# flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=search_context, return_multiple_matches=True, debug_print=True)\n",
    "# # a_context, a_result, a_decoder, _ = a_new_fully_generic_result.get_results_matching_contexts(context_query=search_context, return_multiple_matches=False, debug_print=True)\n",
    "# # a_decoder\n",
    "# # flat_context_list\n",
    "# flat_decoded_marginal_posterior_df_context_dict\n",
    "\n",
    "for a_ctxt, a_df in flat_decoded_marginal_posterior_df_context_dict.items():\n",
    "    time_bin_size = epochs_decoding_time_bin_size\n",
    "    info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "    plot_row_identifier: str = a_ctxt.get_description(subset_includelist=['known_named_decoding_epochs_type', 'masked_time_bin_fill_type'], include_property_names=True, key_value_separator=':', separator='|', replace_separator_in_property_names='-')\n",
    "    a_time_window_centers = a_df['t_bin_center'].to_numpy() \n",
    "    a_1D_posterior = a_df[['P_Long', 'P_Short']].to_numpy().T\n",
    "\n",
    "    identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dock_item = active_2d_plot.add_docked_marginal_track(name=plot_row_identifier, time_window_centers=a_time_window_centers, a_1D_posterior=a_1D_posterior, extended_dock_title_info=info_string, sync_mode=SynchronizedPlotMode.TO_GLOBAL_DATA)\n",
    "    active_2d_plot.sync_matplotlib_render_plot_widget(identifier=identifier_name, sync_mode=SynchronizedPlotMode.TO_GLOBAL_DATA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdabf069",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.sync_matplotlib_render_plot_widget(identifier=identifier_name, sync_mode=SynchronizedPlotMode.TO_GLOBAL_DATA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa923b9e",
   "metadata": {},
   "source": [
    "### Figures via `figures_plot_generalized_decode_epochs_dict_and_export_results_completion_function`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b3284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.SpecificComputationValidation import DependencyGraph, SpecificComputationValidator, SpecificComputationResultsSpecification\n",
    "# from pyphoplacecellanalysis.General.Model.SpecificComputationValidation import plan_computation_execution\n",
    "\n",
    "# # _comp_specifiers_dict: Dict[str, SpecificComputationValidator] = curr_active_pipeline.get_merged_computation_function_validators()\n",
    "# # validators = deepcopy(_comp_specifiers_dict) # { ... }  # Your validators here\n",
    "# # print(validators)\n",
    "# # graph = DependencyGraph(validators)\n",
    "\n",
    "# # Get the execution plan for a specific computation\n",
    "# computation_plan = plan_computation_execution(curr_active_pipeline, ['directional_decoders_decode_continuous'], debug_print=True)\n",
    "\n",
    "# # Print the execution order\n",
    "# print(\"Functions to execute in order:\")\n",
    "# for i, func_name in enumerate(computation_plan['execution_order']):\n",
    "#     print(f\"{i+1}. {func_name}\")\n",
    "\n",
    "\n",
    "# owning_pipeline_reference.stage.resolve_and_execute_full_required_computation_plan(computation_functions_name_includelist=['directional_decoders_decode_continuous'],\n",
    "#                                         computation_kwargs_list=[{'time_bin_size': time_bin_size, 'should_disable_cache':False}], \n",
    "#                                         enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75be131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: computation_kwargs_list=[{'num_shuffles': 100, 'skip_laps': False, 'minimum_inclusion_fr_Hz':2.0, 'included_qclu_values':[1,2,4,5,6,7]}]\n",
    "computation_kwargs_list=[{'num_shuffles': 100, 'skip_laps': False, 'minimum_inclusion_fr_Hz':2.0, 'included_qclu_values':[1,2,4,5,6,7]}]\n",
    "\n",
    "\n",
    "## Resolve all required pre-req dependencies to execute this function:\n",
    "ordered_required_dependent_computation_fn_names: List[str] = DependencyGraph.resolve_computation_dependencies(curr_active_pipeline, ['directional_decoders_decode_continuous'])\n",
    "# ordered_computation_functions # ['_split_to_directional_laps', '_build_merged_directional_placefields', '_decode_continuous_using_directional_decoders']\n",
    "needs_computation_output_dict, valid_computed_results_output_list, remaining_include_function_names = batch_evaluate_required_computations(curr_active_pipeline, include_includelist=ordered_required_dependent_computation_fn_names, include_global_functions=True, fail_on_exception=False, progress_print=True,\n",
    "                                                    force_recompute=False, force_recompute_override_computations_includelist=[], debug_print=False)\n",
    "print(f'Post-load global computations: needs_computation_output_dict: {[k for k,v in needs_computation_output_dict.items() if (v is not None)]}')\n",
    "\n",
    "## OUTPUTS: needs_computation_output_dict\n",
    "if len(remaining_include_function_names) > 0:\n",
    "\tprint(f'have {len(remaining_include_function_names)} functions to compute: {remaining_include_function_names}')\n",
    "\tcurr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=remaining_include_function_names, computation_kwargs_list=computation_kwargs_list, enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "else:\n",
    "\tprint(f'not computations required, have all required keys!')\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6625e5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "active_computation_functions = self.find_registered_computation_functions(computation_functions_name_includelist, search_mode=FunctionsSearchMode.ANY) # find_registered_computation_functions is a pipeline.stage property\n",
    "contains_any_global_functions = np.any([v.is_global for v in active_computation_functions])\n",
    "## INPUTS: computation_kwargs_list=[{'num_shuffles': 100, 'skip_laps': False, 'minimum_inclusion_fr_Hz':2.0, 'included_qclu_values':[1,2,4,5,6,7]}]\n",
    "computation_kwargs_list=[{'num_shuffles': 100, 'skip_laps': False, 'minimum_inclusion_fr_Hz':2.0, 'included_qclu_values':[1,2,4,5,6,7]}]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09bc311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_computed_results_output_list\n",
    "remaining_include_function_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f70cebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the execution order\n",
    "print(\"Functions to execute in order:\")\n",
    "for i, func_name in enumerate(computation_plan['execution_order']):\n",
    "    print(f\"{i+1}. {func_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365ee233",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# required_global_computation_results = ['EpochComputations', 'EpochComputations']\n",
    "\n",
    "\n",
    "## Does this not perform the required pre-req computations if they're missing? For example this function requires: `requires_global_keys=['DirectionalLaps', 'DirectionalMergedDecoders']`, so does it do those if they're missing, or not because they aren't in the computations list?\n",
    "owning_pipeline_reference.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'],\n",
    "                                        computation_kwargs_list=[{'time_bin_size': time_bin_size, 'should_disable_cache':False}], \n",
    "                                        enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048c713f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import figures_plot_generalized_decode_epochs_dict_and_export_results_completion_function, SimpleBatchComputationDummy\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult #, KnownNamedDecoderTrainedComputeEpochsType, KnownNamedDecodingEpochsType, MaskedTimeBinFillType, DataTimeGrain, GenericResultTupleIndexType\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "## Settings:\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-generalized_decode_epochs_dict_and_export_results_completion_function.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "\n",
    "complete_session_context, (session_context, additional_session_context) = curr_active_pipeline.get_complete_session_context()\n",
    "\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-figures_plot_generalized_decode_epochs_dict_and_export_results_completion_function.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | figures_plot_generalized_decode_epochs_dict_and_export_results_completion_function(a_dummy, None,\n",
    "                                                    # curr_session_context=curr_active_pipeline.get_session_context(),\n",
    "                                                    curr_session_context=complete_session_context,\n",
    "                                                    curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                    across_session_results_extended_dict=_across_session_results_extended_dict,\n",
    "                                                    # extreme_threshold=0.5, opacity_max=0.7, thickness_ramping_multiplier=35,\n",
    "                                                    # extreme_threshold=0.8, opacity_max=0.7, thickness_ramping_multiplier=100,\n",
    "                                                    # extreme_threshold=0.5, included_figures_names=['_display_decoded_trackID_marginal_hairy_position'],\n",
    "                                                    included_figures_names=['_display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay'],\n",
    "                                                    # included_figures_names=['_display_generalized_decoded_yellow_blue_marginal_epochs', '_display_decoded_trackID_marginal_hairy_position', '_display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay'],\n",
    "                                                    # included_figures_names=['_display_directional_merged_pf_decoded_stacked_epoch_slices', '_display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay'],\n",
    "                                                )\n",
    "\n",
    "# _across_session_results_extended_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f011fdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.indexing_helpers import flatten_dict\n",
    "from benedict import benedict\n",
    "\n",
    "## INPUTS: out_custom_formats_dict\n",
    "\n",
    "# _flattened_paths_dict = {} ## Outputs:\n",
    "\n",
    "_out_dict = _across_session_results_extended_dict.get('figures_plot_generalized_decode_epochs_dict_and_export_results_completion_function', {}).get('_display_directional_merged_pf_decoded_stacked_epoch_slices', {}) \n",
    "out_custom_formats_dict = _out_dict['out_custom_formats_dict']\n",
    "## UPDATES: out_custom_formats_dict\n",
    "# out_custom_formats_dict.merge(_out_dict['out_custom_formats_dict'])\n",
    "# save_paths_dict.merge(_out_dict.get('out_paths', {}))\n",
    "\n",
    "export_paths = _out_dict['export_paths']\n",
    "save_paths_dict = benedict(_out_dict.get('export_paths', {}))\n",
    "parent_specific_session_output_folder = _out_dict['parent_specific_session_output_folder']\n",
    "\n",
    "# save_paths_dict = _out_dict.get('out_paths', {})\n",
    "# for epoch_name, a_variant_paths_dict in save_paths_dict.items():\n",
    "# \t## loop over all variants:\n",
    "#     for a_variant_name, a_path in a_variant_paths_dict.items():\n",
    "#         if a_path is not None:\n",
    "#             _curr_key = f\"{epoch_name}.{a_variant_name}\"\n",
    "#             _flattened_paths_dict[_curr_key] = a_path\n",
    "\n",
    "\n",
    "# _flattened_paths_dict\n",
    "\n",
    "# {'laps.psuedo2D_nan_filled': Path('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/array_to_images/2025-05-16/gor01_one_2006-6-08_14-26-15_trackID_weighted_position_posterior/laps/psuedo2D_nan_filled'),\n",
    "#  'ripple.psuedo2D_nan_filled': Path('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/array_to_images/2025-05-16/gor01_one_2006-6-08_14-26-15_trackID_weighted_position_posterior/ripple/psuedo2D_nan_filled')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d173192",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.image_helpers import ImageHelpers\n",
    "from pyphocorehelpers.plotting.media_output_helpers import vertical_image_stack, horizontal_image_stack, image_grid # used in `_subfn_build_combined_output_images`\n",
    "\n",
    "def build_horizontally_concatenated_images_from_export_folder(image_folder_path: Path, image_glob: str = \"*.png\", x_padding: int = 2, canvas_image_node_scale: float=None, max_num_to_add: int = 1000, combined_img_padding=4, combined_img_separator_color=None, debug_print = False):\n",
    "    \"\"\" Adds the images matching the glob in the `image_folder_path` to the canvas, or creates a new canvas, as needed\n",
    "    \n",
    "    Usage:\n",
    "    \n",
    "        img_export_folder = Path('K:/scratch/collected_outputs/figures/_temp_individual_posteriors/2025-06-03/gor01_two_2006-6-12_16-53-46/ripple/combined/multi').resolve()\n",
    "        Assert.path_exists(img_export_folder)\n",
    "        _img_path, _single_epoch_combined_img = build_horizontally_concatenated_images_from_export_folder(image_folder_path=img_export_folder, image_glob=\"p_x_given_n*.png\",\n",
    "                                                                                                        #    combined_img_padding=8, combined_img_separator_color='#1eff00',\n",
    "                                                                                                        combined_img_padding=8, combined_img_separator_color='#061304',\n",
    "                                                                                                        )\n",
    "        _img_path\n",
    "\n",
    "    \"\"\"\n",
    "    from pyphocorehelpers.image_helpers import ImageHelpers\n",
    "    from pyphocorehelpers.plotting.media_output_helpers import vertical_image_stack, horizontal_image_stack, image_grid # used in `_subfn_build_combined_output_images`\n",
    "    \n",
    "\n",
    "    def _subfn_get_img_obsidian_global_unique_name(an_img_path: Path) -> str:    \n",
    "        \"\"\" from my personal export path conventions, builds a globally unique image name (which has to be the case for a canvas)\"\"\"\n",
    "        \n",
    "        img_path_name_parts = an_img_path.parts\n",
    "        date_part_index = next((i for i, part in enumerate(img_path_name_parts) if re.match(r'^\\d{4}-\\d{2}-\\d{2}', part)), None)\n",
    "        session_part_index: int = date_part_index + 1\n",
    "        img_out_context_parts: List[str] = img_path_name_parts[session_part_index:] # ('gor01_two_2006-6-07_16-40-19_normal_computed_[1, 2]_5.0', 'ripple', 'psuedo2D_nan_filled', 'raw_rgba', 'p_x_given_n[9].png')\n",
    "        return '-'.join(img_out_context_parts) # 'gor01_two_2006-6-07_16-40-19_normal_computed_[1, 2]_5.0-ripple-psuedo2D_nan_filled-raw_rgba-p_x_given_n[9].png'\n",
    "\n",
    "\n",
    "    # ==================================================================================================================================================================================================================================================================================== #\n",
    "    # BEGIN FUNCTION BODY                                                                                                                                                                                                                                                                  #\n",
    "    # ==================================================================================================================================================================================================================================================================================== #\n",
    "    images_dict: Dict = ImageHelpers.load_png_images_pathlib(image_folder_path, image_glob=image_glob)\n",
    "    n_images: int = len(images_dict)\n",
    "    # Print the loaded images\n",
    "    print(f\"Loaded {len(images_dict)} PNG images from '{image_folder_path}'.\")\n",
    "\n",
    "    _output_combined_dir = image_folder_path # joinpath(joined_export_folder_name, custom_export_format_series_name).resolve()\n",
    "    # _output_combined_dir.mkdir(parents=True, exist_ok=True)\n",
    "    _output_combined_image_save_dirs = []\n",
    "\n",
    "    n_added: int = 0\n",
    "    \n",
    "    # text_node = TextNode(x=initial_x, y=initial_y, width=200, height=100, text=f\"#{image_group_name}\")\n",
    "    # target_canvas.add_node(text_node)\n",
    "    flat_image_list = []\n",
    "    if canvas_image_node_scale is None:\n",
    "        canvas_image_node_scale = 1.0\n",
    "        \n",
    "    image_sizes = np.vstack([(int(round(canvas_image_node_scale * float(an_img.size[0]))), int(round(canvas_image_node_scale * float(an_img.size[1])))) for i, (img_name, an_img) in enumerate(images_dict.items())]) # (n_images, 2)\n",
    "    # if debug_print:\n",
    "    #     print(f'image_sizes: {np.shape(image_sizes)}, max_img_sizes: {np.max(image_sizes, axis=0)}')\n",
    "\n",
    "    # total_grouped_image_size = np.sum(image_sizes, axis=0)\n",
    "    \n",
    "    if debug_print:\n",
    "        print(f'max_img_sizes: {np.max(image_sizes, axis=0)}')\n",
    "\n",
    "    total_grouped_image_size = (np.sum(image_sizes[:, 0], axis=0), np.max(image_sizes[:, 1], axis=0))  ## since being stacked horizontally, use the sum of the widths, but the max of the heights\n",
    "    total_grouped_images_padding = (int(round(float(x_padding)*float(n_images-1))), 0)\n",
    "\n",
    "    group_padding = np.array((50, 30))\n",
    "    total_group_size = total_grouped_image_size + np.array(total_grouped_images_padding) + (2 * group_padding)\n",
    "    # group_offset = np.array((initial_x, initial_y)) - group_padding\n",
    "        \n",
    "    a_found_filename: Optional[str] = None\n",
    "    for i, (img_name, an_img) in enumerate(images_dict.items()):\n",
    "        if i < max_num_to_add:\n",
    "            an_img_path: Path = image_folder_path.joinpath(f'{img_name}.png')\n",
    "            assert an_img_path.exists(), f\"an_img_path: {an_img_path} does not exist\"        \n",
    "            if a_found_filename is None:\n",
    "                a_found_filename = deepcopy(an_img_path.stem)\n",
    "            # global_unique_image_filename: str = f\"{_subfn_get_img_obsidian_global_unique_name(an_img_path=an_img_path)}\"\n",
    "            an_img_width, an_img_height = an_img.size            \n",
    "            if canvas_image_node_scale is not None:\n",
    "                an_img_width = int(round(canvas_image_node_scale * float(an_img_width)))\n",
    "                an_img_height = int(round(canvas_image_node_scale * float(an_img_height)))\n",
    "            # node_url_str: str = vault_relative_image_dir_filepath\n",
    "            # node_url_str: str = an_img_vault_filepath.relative_to(obsidian_vault_root_path).as_posix()\n",
    "            # file_node = FileNode(x=initial_x, y=initial_y, width=an_img_width, height=an_img_height, file=node_url_str)\n",
    "            # target_canvas.add_node(file_node)\n",
    "            flat_image_list.append(an_img)\n",
    "            # initial_x = initial_x + an_img_width + x_padding\n",
    "            n_added = n_added + 1\n",
    "            \n",
    "        else:\n",
    "            # print(f'skipping because max_num_to_add: {max_num_to_add}')\n",
    "            pass\n",
    "        \n",
    "    # END for i, (img_name, an_i...\n",
    "    print(f'added {n_added} images to canvas.')\n",
    "    \n",
    "    ## OUTPUT: flat_image_list\n",
    "    \n",
    "    _single_epoch_combined_img = horizontal_image_stack(flat_image_list, padding=combined_img_padding, separator_color=combined_img_separator_color)\n",
    "    _single_epoch_combined_img\n",
    "    \n",
    "    ## Save the image:\n",
    "    _img_path = _output_combined_dir.joinpath(f'merged_{a_found_filename}.png').resolve()\n",
    "    _single_epoch_combined_img.save(_img_path)\n",
    "    # _output_combined_image_save_dirs.append(_img_path)\n",
    "\n",
    "    return _img_path, _single_epoch_combined_img\n",
    "\n",
    "\n",
    "img_export_folder = Path('K:/scratch/collected_outputs/figures/_temp_individual_posteriors/2025-06-03/gor01_two_2006-6-12_16-53-46/ripple/combined/multi').resolve()\n",
    "Assert.path_exists(img_export_folder)\n",
    "_img_path, _single_epoch_combined_img = build_horizontally_concatenated_images_from_export_folder(image_folder_path=img_export_folder, image_glob=\"p_x_given_n*.png\",\n",
    "                                                                                                #    combined_img_padding=8, combined_img_separator_color='#1eff00',\n",
    "                                                                                                   combined_img_padding=8, combined_img_separator_color='#061304',\n",
    "                                                                                                   )\n",
    "_img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c86190",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# _flattened_paths_dict = {} ## Outputs:\n",
    "\n",
    "_out_dict = _across_session_results_extended_dict.get('figures_plot_generalized_decode_epochs_dict_and_export_results_completion_function', {}).get('_display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay', {}) # FigureCollector \n",
    "save_paths_dict = _out_dict.get('out_paths', {})\n",
    "out_custom_formats_dict = _out_dict['out_custom_formats_dict']\n",
    "\n",
    "# out_custom_formats_dict = benedict(_out_dict['out_custom_formats_dict'])\n",
    "parent_output_folder = _out_dict['parent_output_folder']\n",
    "_parent_save_context = _out_dict['parent_save_context']\n",
    "\n",
    "parent_output_folder\n",
    "_parent_save_context\n",
    "\n",
    "_specific_session_output_folder = _out_dict['parent_specific_session_output_folder']\n",
    "_specific_session_output_folder\n",
    "# {'laps.psuedo2D_nan_filled': Path('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/array_to_images/2025-05-16/gor01_one_2006-6-08_14-26-15_trackID_weighted_position_posterior/laps/psuedo2D_nan_filled'),\n",
    "#  'ripple.psuedo2D_nan_filled': Path('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/array_to_images/2025-05-16/gor01_one_2006-6-08_14-26-15_trackID_weighted_position_posterior/ripple/psuedo2D_nan_filled')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd430d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "\n",
    "out_custom_formats_dict = _out_dict.get('out_custom_formats_dict', None)\n",
    "if out_custom_formats_dict is not None:\n",
    "    _out_final_merged_image_save_paths, _out_final_merged_images = PosteriorExporting.post_export_build_combined_images(out_custom_formats_dict=out_custom_formats_dict)\n",
    "    _out_dict['final_merged_image_save_paths'] = deepcopy(_out_final_merged_image_save_paths)\n",
    "    # across_session_results_extended_dict['figures_plot_generalized_decode_epochs_dict_and_export_results_completion_function'].update({\n",
    "    #     '_display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay': _out,\n",
    "    # })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fda2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_dict['final_merged_image_save_paths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b417db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out_custom_formats_dict = benedict(out_custom_formats_dict)\n",
    "\n",
    "save_paths_dict.keypaths()\n",
    "save_paths_dict.flatten(separator='|')\n",
    "# list(out_custom_formats_dict.keys())\n",
    "# out_custom_formats_dict.keypaths()\n",
    "# out_custom_formats_dict.merge()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cf4e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_custom_formats_dict['ripple'].keypaths()\n",
    "\n",
    "active_decoder_names = ['long_LR', 'long_RL', 'short_LR', 'short_RL', 'psuedo2D_ignore']\n",
    "out_custom_formats_dict['ripple.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70609d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.plotting.media_output_helpers import vertical_image_stack, horizontal_image_stack, image_grid\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "\n",
    "_out_final_merged_image_save_paths, _out_final_merged_images = PosteriorExporting.post_export_build_combined_images(out_custom_formats_dict=out_cusstom_formats_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e39fa1f",
   "metadata": {},
   "source": [
    "### Export to image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31ee8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.data_exporting import HeatmapExportConfig\n",
    "from benedict import benedict\n",
    "\n",
    "# Run an export function again _______________________________________________________________________________________________________________________________________________________________________________________________________________________________________________________ #\n",
    "pseudo2D_split_to_1D_custom_export_formats: Dict[str, HeatmapExportConfig] = {\n",
    "    # 'greyscale_shared_norm': HeatmapExportConfig.init_greyscale(desired_height=desired_height, post_render_image_functions_builder_fn=ImagePostRenderFunctionSets._build_no_op_image_export_functions_dict),\n",
    "    'viridis_shared_norm': HeatmapExportConfig(colormap='viridis', vmin=0.0, vmax=1.0, export_kind=HeatmapExportKind.COLORMAPPED, desired_height=desired_height, post_render_image_functions_builder_fn=ImagePostRenderFunctionSets._build_no_op_image_export_functions_dict),\n",
    "}\n",
    "\n",
    "\n",
    "pseudo2D_split_to_1D_out_paths, pseudo2D_split_to_1D_out_custom_formats_dict = PosteriorExporting.perform_export_all_decoded_posteriors_as_images(decoder_laps_filter_epochs_decoder_result_dict=None,\n",
    "                                                                                                            decoder_ripple_filter_epochs_decoder_result_dict=a_pseudo2D_split_to_1D_continuous_results_dict, ## just the ripples\n",
    "                                                                                                        _save_context=_parent_save_context, parent_output_folder=_specific_session_output_folder,\n",
    "                                                                                                        desired_height=desired_height, custom_export_formats=pseudo2D_split_to_1D_custom_export_formats, combined_img_padding=6, combined_img_separator_color=(0, 0, 0, 0))\n",
    "if not isinstance(graphics_output_dict['out_paths'], benedict):\n",
    "    graphics_output_dict['out_paths'] = benedict(graphics_output_dict['out_paths']) # 'out_paths': out_paths\n",
    "# graphics_output_dict['out_paths'].merge(pseudo2D_split_to_1D_out_paths)\n",
    "graphics_output_dict['out_paths'].merge({k:v for k, v in pseudo2D_split_to_1D_out_paths.items() if (v is not None)})\n",
    "\n",
    "if not isinstance(graphics_output_dict['out_custom_formats_dict'], benedict):\n",
    "    graphics_output_dict['out_custom_formats_dict'] = benedict(graphics_output_dict['out_custom_formats_dict']) # 'out_paths': out_paths\n",
    "# graphics_output_dict['out_custom_formats_dict'].merge(pseudo2D_split_to_1D_out_custom_formats_dict)\n",
    "graphics_output_dict['out_custom_formats_dict'].merge({k:v for k, v in pseudo2D_split_to_1D_out_custom_formats_dict.items() if (v is not None)})\n",
    "\n",
    "# print(f'\\tout_paths: {pseudo2D_split_to_1D_out_paths}')\n",
    "print(f'done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b704eaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo2D_split_to_1D_out_paths = benedict(pseudo2D_split_to_1D_out_paths)\n",
    "pseudo2D_split_to_1D_out_custom_formats_dict = benedict(pseudo2D_split_to_1D_out_custom_formats_dict)\n",
    "# pseudo2D_split_to_1D_out_paths\n",
    "pseudo2D_split_to_1D_out_custom_formats_dict.keypaths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9767c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo2D_split_to_1D_out_custom_formats_dict['laps/long_LR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1e68a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo2D_split_to_1D_out_custom_formats_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbee9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.plotting.media_output_helpers import vertical_image_stack, horizontal_image_stack, image_grid\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "\n",
    "_out_final_merged_image_save_paths, _out_final_merged_images = PosteriorExporting.post_export_build_combined_images(pseudo2D_split_to_1D_out_custom_formats_dict)\n",
    "_out_final_merged_image_save_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f6be07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "an_active_img.reduce(factor=(4, 1)) ## scale image down by 1/4 in height but leave the original width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960a6580",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_posterior_saved_path\n",
    "merged_dir\n",
    "a_merged_posterior_export_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e86294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_final_merged_image_save_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b2a66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_final_merged_images[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837c717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_paths_dict.keypaths()\n",
    "save_paths_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22507ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_custom_formats_dict.keypaths()\n",
    "# out_custom_formats_dict.flatten()\n",
    "# out_custom_formats_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b414b333",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c014e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_paths = benedict(_out_dict['export_paths'])\n",
    "flat_export_paths = export_paths.flatten(separator='|')\n",
    "flat_export_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9f4712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d631bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = curr_active_pipeline.display('_display_generalized_decoded_yellow_blue_marginal_epochs', curr_active_pipeline.get_session_context(), defer_render=True, save_figure=True, is_dark_mode=False) # , override_fig_man=custom_fig_man\n",
    "collector = _out['collector'] # FigureCollector \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62b582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "\n",
    "_out = curr_active_pipeline.display('_display_decoded_trackID_marginal_hairy_position', curr_active_pipeline.get_session_context(), defer_render=False, save_figure=False,\n",
    "\t\t\t\t\t\t\t\t\t#  extreme_threshold=0.5, \n",
    "                                    # opacity_max=0.7, thickness_ramping_multiplier=35,\n",
    "\t\t\t\t\t\t\t\t\textreme_threshold=0.8, opacity_max=0.7, thickness_ramping_multiplier=50,\n",
    "                                    #  prob_to_thickness_ramping_function= lambda p: max(0.0, (p - 0.5) * 15),\n",
    "                                    #  extreme_threshold=0.9, prob_to_thickness_ramping_function= lambda p: 6.0, ## constant for all probabilities\n",
    "\t\t\t\t\t\t\t\t\t#  extreme_threshold=0.1, prob_to_thickness_ramping_function= lambda p: (5.0 * p), \n",
    "\t\t\t\t\t\t\t\t\t#  ax = \n",
    "\t\t\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t\t\t ) # , override_fig_man=custom_fig_man\n",
    "collector = _out['collector'] # FigureCollector \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0a34b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed96530e",
   "metadata": {},
   "source": [
    "### Figures via `figures_plot_generalized_decode_epochs_dict_and_export_results_completion_function`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcece57",
   "metadata": {},
   "source": [
    "### <a id='toc21_1_10_'></a>[Call `export_session_h5_file_completion_function`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e847ed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyphoplacecellanalysis.General.type_aliases as types\n",
    "from neuropy.utils.mixins.binning_helpers import BinningContainer, BinningInfo\n",
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.UserCompletionHelpers.batch_user_completion_helpers import export_session_h5_file_completion_function, SimpleBatchComputationDummy\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult #, KnownNamedDecoderTrainedComputeEpochsType, KnownNamedDecodingEpochsType, MaskedTimeBinFillType, DataTimeGrain, GenericResultTupleIndexType\n",
    "a_dummy = SimpleBatchComputationDummy(BATCH_DATE_TO_USE, collected_outputs_path, True)\n",
    "\n",
    "## Settings:\n",
    "_across_session_results_extended_dict = {}\n",
    "\n",
    "_across_session_results_extended_dict = _across_session_results_extended_dict | export_session_h5_file_completion_function(a_dummy, None,\n",
    "                                                    curr_session_context=curr_active_pipeline.get_session_context(), curr_session_basedir=curr_active_pipeline.sess.basepath.resolve(), curr_active_pipeline=curr_active_pipeline,\n",
    "                                                    across_session_results_extended_dict=_across_session_results_extended_dict)\n",
    "\n",
    "callback_outputs = _across_session_results_extended_dict['export_session_h5_file_completion_function']\n",
    "hdf5_output_path: Dict[str, Path] = callback_outputs['hdf5_output_path']\n",
    "Assert.path_exists(hdf5_output_path)\n",
    "hdf5_output_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e2705a",
   "metadata": {},
   "source": [
    "# <a id='toc24_'></a>[2025-03-04 - Final Histogram](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7a94ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benedict import benedict\n",
    "filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict = benedict(a_general_decoder_dict_decoded_epochs_dict_result.filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict)\n",
    "filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict.keypaths() # ['laps', 'laps.ignore', 'laps.last_valid', 'laps.nan_filled', 'non_pbe', 'non_pbe.ignore', 'non_pbe.last_valid', 'non_pbe.nan_filled', 'pbe', 'pbe.ignore', 'pbe.last_valid', 'pbe.nan_filled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cb49e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "template: str = 'plotly_dark' # set plotl template\n",
    "pio.templates.default = template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed73ff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_export_path = Path(r'K:\\scratch\\output').resolve()\n",
    "non_pbe_marginals_PKL_export_path: Path = non_pbe_marginals_export_basepath.with_suffix('.pkl').resolve()\n",
    "a_general_decoder_dict_decoded_epochs_dict_result.save(pkl_output_path=non_pbe_marginals_PKL_export_path)\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26590c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_a_general_decoder_dict_decoded_epochs_dict_result: GeneralDecoderDictDecodedEpochsDictResult =  GeneralDecoderDictDecodedEpochsDictResult.from_file(pkl_path=non_pbe_marginals_PKL_export_path)\n",
    "loaded_a_general_decoder_dict_decoded_epochs_dict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fde2b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_pbe_marginals_export_basepath = parent_export_path.joinpath(f'{BATCH_DATE_TO_USE}_non_pbe_marginals_export')\n",
    "non_pbe_marginals_HDF5_export_path: Path = non_pbe_marginals_export_basepath.with_suffix('.h5').resolve()\n",
    "a_general_decoder_dict_decoded_epochs_dict_result.to_hdf(file_path=non_pbe_marginals_HDF5_export_path, key='a_general_decoder_dict_decoded_epochs_dict_result', debug_print=True) # , OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c933ae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: a_new_fully_generic_result\n",
    "BATCH_DATE_TO_USE: str = f'2025-04-11_Apogee'\n",
    "\n",
    "# parent_export_path = Path('/home/halechr/repos/Spike3D/data').resolve()\n",
    "parent_export_path = Path('data').resolve()\n",
    "\n",
    "a_new_fully_generic_result_export_basepath = parent_export_path.joinpath(f'{BATCH_DATE_TO_USE}_a_new_fully_generic_result')\n",
    "# a_new_fully_generic_result_HDF5_export_path: Path = a_new_fully_generic_result_export_basepath.with_suffix('.h5').resolve()\n",
    "# a_new_fully_generic_result.to_hdf(file_path=a_new_fully_generic_result_HDF5_export_path, key='a_new_fully_generic_result', debug_print=True, OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True) # , OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True\n",
    "\n",
    "out_PKL_export_path: Path = a_new_fully_generic_result_export_basepath.with_suffix('.pkl').resolve()\n",
    "print(f'out_PKL_export_path: {out_PKL_export_path}')\n",
    "a_new_fully_generic_result.save(pkl_output_path=out_PKL_export_path)\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a003258",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loaded_a_general_decoder_dict_decoded_epochs_dict_result: GeneralDecoderDictDecodedEpochsDictResult =  GeneralDecoderDictDecodedEpochsDictResult.from_file(pkl_path=out_PKL_export_path)\n",
    "loaded_a_general_decoder_dict_decoded_epochs_dict_result\n",
    "non_pbe_marginals_export_basepath = parent_export_path.joinpath(f'{BATCH_DATE_TO_USE}_non_pbe_marginals_export')\n",
    "non_pbe_marginals_HDF5_export_path: Path = non_pbe_marginals_export_basepath.with_suffix('.h5').resolve()\n",
    "a_general_decoder_dict_decoded_epochs_dict_result.to_hdf(file_path=non_pbe_marginals_HDF5_export_path, key='a_general_decoder_dict_decoded_epochs_dict_result', debug_print=True) # , OVERRIDE_ALLOW_GLOBAL_NESTED_EXPANSION=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02555045",
   "metadata": {},
   "outputs": [],
   "source": [
    "## OUTPUTS: flat_context_list: List[IdentifyingContext], flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict\n",
    "## OUTPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc27e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute and plot the new tracks:\n",
    "# non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict, non_PBE_marginal_over_track_ID, (time_bin_containers, time_window_centers) = nonPBE_results._build_merged_joint_placefields_and_decode(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)))\n",
    "unique_added_track_identifiers = nonPBE_results.add_to_SpikeRaster2D_tracks(active_2d_plot=active_2d_plot, non_PBE_all_directional_pf1D_Decoder=non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result=pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict=continuous_decoded_results_dict, non_PBE_marginal_over_track_ID=non_PBE_marginal_over_track_ID, time_window_centers=time_window_centers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8a218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_raster_window.enable_interaction_events_debug_print = True\n",
    "spike_raster_window.enable_debug_print = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645e0aa6",
   "metadata": {
    "tags": [
     "active-2025-03-11"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import build_single_plotly_marginal_scatter_and_hist_over_time\n",
    "\n",
    "#INPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder\n",
    "_flat_out_figs_dict = {}\n",
    "a_fig, a_figure_context = build_single_plotly_marginal_scatter_and_hist_over_time(a_decoded_posterior_df=a_decoded_marginal_posterior_df, a_target_context=a_target_context)\n",
    "_flat_out_figs_dict[a_figure_context] = a_fig\n",
    "\n",
    "a_fig.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d39b4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_decoded_marginal_posterior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69dd71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = a_general_decoder_dict_decoded_epochs_dict_result.build_plotly_marginal_scatter_and_hist_over_time()\n",
    "\n",
    "# _flat_out_figs_dict = a_general_decoder_dict_decoded_epochs_dict_result.build_plotly_marginal_scatter_and_hist_over_time(debug_print=False)\n",
    "\n",
    "# display(list(_flat_out_figs_dict.values())[0])\n",
    "\n",
    "# Display all figures in the dictionary\n",
    "for fig in _flat_out_figs_dict.values():\n",
    "    display(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33e4ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_pre_post_delta_scatter\n",
    "## INPUTS: a_general_decoder_dict_decoded_epochs_dict_result\n",
    "\n",
    "histogram_bins: int = 25\n",
    "debug_print = False\n",
    "# 'masked_laps': 'Laps (Masked)', 'masked_laps': 'Laps (Nan-masked)')\n",
    "# masked_bin_fill_modes: ['ignore', 'last_valid', 'nan_filled', 'dropped']\n",
    "\n",
    "_flat_out_figs_dict = {}\n",
    "\n",
    "for a_known_decoded_epochs_type, a_decoded_posterior_dfs_dict in a_general_decoder_dict_decoded_epochs_dict_result.filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict.items():\n",
    "    if debug_print:\n",
    "        print(f'a_known_decoded_epochs_type: \"{a_known_decoded_epochs_type}\"')\n",
    "    for masking_bin_fill_mode, a_decoded_posterior_df in a_decoded_posterior_dfs_dict.items():\n",
    "        if debug_print:\n",
    "            print(f'\\tmasking_bin_fill_mode: \"{masking_bin_fill_mode}\"')\n",
    "        plot_row_identifier: str = f'{a_known_decoded_epochs_type.capitalize()} - {masking_bin_fill_mode.capitalize()} decoder' # should be like 'Laps (Masked) from Non-PBE decoder'\n",
    "        \n",
    "        fig, figure_context = plotly_pre_post_delta_scatter(data_results_df=deepcopy(a_decoded_posterior_df), out_scatter_fig=None, \n",
    "                                        histogram_variable_name='P_Short', hist_kwargs=dict(), histogram_bins=histogram_bins,\n",
    "                                        common_plot_kwargs=dict(),\n",
    "                                        px_scatter_kwargs = dict(x='delta_aligned_start_t', y='P_Short', title=plot_row_identifier))\n",
    "        _flat_out_figs_dict[figure_context] = fig\n",
    "        \n",
    "# ['laps', 'non_PBE']\n",
    "# ['a', 'masked', 'dropping_masked']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b1d063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(list(_flat_out_figs_dict.values())[0])\n",
    "\n",
    "# # Display all figures in the dictionary\n",
    "# for fig in _flat_out_figs_dict.values():\n",
    "#     display(fig)\n",
    "\n",
    "from pyphoplacecellanalysis.External.pyqtgraph.Qt import QtWidgets\n",
    "from pyphoplacecellanalysis.External.pyqtgraph.dockarea import DockArea, Dock\n",
    "import pyphoplacecellanalysis.External.pyqtgraph as pg\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.PlotlyFigurePyQtWidget import PlotlyDockContainer, PlotlyWidget\n",
    "\n",
    "## INPUTS: _flat_out_figs_dict\n",
    "# Create the container\n",
    "container: PlotlyDockContainer = PlotlyDockContainer()\n",
    "# Display all figures in the dictionary\n",
    "for a_fig_context, fig in _flat_out_figs_dict.items():\n",
    "    container.add_figure(fig, name=f\"{a_fig_context}\", position='bottom')\n",
    "\n",
    "# Show the container\n",
    "container.resize(1200, 800)\n",
    "container.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d06c39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bf036ef",
   "metadata": {},
   "source": [
    "### <a id='toc24_1_1_'></a>[Plotting Tracks on Spike2DRaster](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b821068",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Never used: all at once:\n",
    "a_dock_config = None\n",
    "_out_tuple = active_2d_plot.add_docked_decoded_posterior_track_from_result(name=f'laps_pseudo2D_continuous_specific_decoded_result', a_dock_config=a_dock_config, a_1D_decoded_result=laps_pseudo2D_continuous_specific_decoded_result,\n",
    "                                                                                xbin = deepcopy(non_PBE_all_directional_pf1D_Decoder.xbin), measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "                                                                                extended_dock_title_info='test')\n",
    "active_2d_plot.sync_matplotlib_render_plot_widget(identifier=identifier_name, sync_mode=SynchronizedPlotMode.TO_GLOBAL_DATA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb37b1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, DockDisplayColors\n",
    "\n",
    "active_time_bin_size: float = pseudo2D_continuous_specific_decoded_result.decoding_time_bin_size\n",
    "info_string: str = f'{active_time_bin_size:.3f}'\n",
    "dock_group_sep_character: str = '_'\n",
    "showCloseButton = True\n",
    "_common_dock_config_kwargs = {'dock_group_names': [dock_group_sep_character.join([f'LapsDecode', info_string])], 'showCloseButton': showCloseButton}\n",
    "dock_configs: Dict[str, CustomDockDisplayConfig] = dict(zip(unique_decoder_names,\n",
    "                        (CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_long_dock_colors, **_common_dock_config_kwargs),\n",
    "                        CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_short_dock_colors, **_common_dock_config_kwargs))))\n",
    "                        \n",
    "\n",
    "pf1D_Decoder_dict = {k:deepcopy(v) for k, v in results1D.decoders.items() if k in unique_decoder_names}\n",
    "\n",
    "output_dict = active_2d_plot.add_docked_decoded_results_dict_tracks(name=f'LapsDecode', a_decoded_result_dict=laps_pseudo2D_split_to_1D_continuous_results_dict, dock_configs=dock_configs, pf1D_Decoder_dict=pf1D_Decoder_dict,\n",
    "                                                                                            measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "                                                                                            extended_dock_title_info=info_string, dockSize=(10, 4))\n",
    "\n",
    "a_dock_config = CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_global_dock_colors, **_common_dock_config_kwargs)\n",
    "marginal_y_p_x_given_n_list = [deepcopy(v.p_x_given_n) for v in laps_pseudo2D_continuous_specific_decoded_result.marginal_y_list]\n",
    "_out_tuple = active_2d_plot.add_docked_decoded_posterior_slices_track(name=f'PBE_marginal_over_track_ID', a_dock_config=a_dock_config,\n",
    "                                                                                slices_time_window_centers=laps_pseudo2D_continuous_specific_decoded_result.time_window_centers, slices_posteriors=marginal_y_p_x_given_n_list,\n",
    "                                                                                xbin=None, xbin_labels=unique_decoder_names, measured_position_df=None, extended_dock_title_info=info_string, posterior_heatmap_imshow_kwargs=dict(), dockSize=(10, 1))\n",
    "output_dict['PBE_marginal_over_track_ID'] = _out_tuple\n",
    "# active_2d_plot.layout_dockGroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44547381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "\n",
    "## INPUTS: masked_laps_pseudo2D_split_to_1D_continuous_results_dict, masked_laps_pseudo2D_continuous_specific_decoded_result\n",
    "_common_dock_config_kwargs = {'dock_group_names': [dock_group_sep_character.join([f'MASKED_LapsDecode', info_string])], 'showCloseButton': showCloseButton}\n",
    "masked_dock_configs: Dict[str, CustomDockDisplayConfig] = dict(zip(unique_decoder_names,\n",
    "                        (CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_long_dock_colors, **_common_dock_config_kwargs),\n",
    "                        CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_short_dock_colors, **_common_dock_config_kwargs))))\n",
    "                        \n",
    "\n",
    "pf1D_Decoder_dict = {k:deepcopy(v) for k, v in results1D.decoders.items() if k in unique_decoder_names}\n",
    "\n",
    "MASKED_output_dict = active_2d_plot.add_docked_decoded_results_dict_tracks(name=f'MASKED_LapsDecode', a_decoded_result_dict=masked_laps_pseudo2D_split_to_1D_continuous_results_dict, dock_configs=masked_dock_configs, pf1D_Decoder_dict=pf1D_Decoder_dict,\n",
    "                                                                                            measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "                                                                                            extended_dock_title_info=info_string, dockSize=(10, 4))\n",
    "\n",
    "a_dock_config = CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Epochs.get_global_dock_colors, **_common_dock_config_kwargs)\n",
    "marginal_y_p_x_given_n_list = [deepcopy(v.p_x_given_n) for v in masked_laps_pseudo2D_continuous_specific_decoded_result.marginal_y_list]\n",
    "_masked_out_tuple = active_2d_plot.add_docked_decoded_posterior_slices_track(name=f'MASKED_PBE_marginal_over_track_ID', a_dock_config=a_dock_config,\n",
    "                                                                                slices_time_window_centers=masked_laps_pseudo2D_continuous_specific_decoded_result.time_window_centers, slices_posteriors=marginal_y_p_x_given_n_list,\n",
    "                                                                                xbin=None, xbin_labels=unique_decoder_names, measured_position_df=None, extended_dock_title_info=info_string, posterior_heatmap_imshow_kwargs=dict(), dockSize=(10, 1))\n",
    "MASKED_output_dict['MASKED_PBE_marginal_over_track_ID'] = _masked_out_tuple\n",
    "# active_2d_plot.layout_dockGroups()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7abd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flat_time_window_centers, flat_marginal_y_p_x_given_n = laps_pseudo2D_continuous_specific_decoded_result.get_pseudo2D_result_to_pseudo2D_marginalization_result(pseudo2D_decoder_names_list=unique_decoder_names) ## this is wrong\n",
    "time_bin_size = epochs_decoding_time_bin_size\n",
    "info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "# identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dock_item = active_2d_plot.add_docked_marginal_track(name='non-PBE_marginal_over_track_ID',\n",
    "#                                                                                         time_window_centers=flat_time_window_centers, a_1D_posterior=flat_marginal_y_p_x_given_n, extended_dock_title_info=info_string)\n",
    "\n",
    "marginal_y_p_x_given_n_list = [deepcopy(v.p_x_given_n) for v in laps_pseudo2D_continuous_specific_decoded_result.marginal_y_list]\n",
    "_out_tuple = active_2d_plot.add_docked_decoded_posterior_slices_track(name=f'PBE_marginal_over_track_ID', a_dock_config=None,\n",
    "                                                                                slices_time_window_centers=laps_pseudo2D_continuous_specific_decoded_result.time_window_centers, slices_posteriors=marginal_y_p_x_given_n_list,\n",
    "                                                                                xbin=None, measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "                                                                                extended_dock_title_info=info_string, posterior_heatmap_imshow_kwargs=dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05b98bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_pseudo2D_continuous_specific_decoded_result.p_x_given_n_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcb7eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timebins, flat_time_bin_containers, timebins_p_x_given_n = laps_pseudo2D_continuous_specific_decoded_result.flatten()\n",
    "\n",
    "desired_total_n_timebins, updated_is_masked_bin, updated_time_bin_containers, updated_timebins_p_x_given_n = laps_pseudo2D_continuous_specific_decoded_result.flatten_to_masked_values()\n",
    "\n",
    "# flat_time_bin_containers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e43cb3",
   "metadata": {},
   "source": [
    "### <a id='toc24_1_2_'></a>[Plotting Histograms Directly](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff6b535",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot: directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_pre_post_delta_scatter\n",
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import plot_histograms\n",
    "\n",
    "## INPUTS: masked_pseudo2D_continuous_specific_decoded_result\n",
    "masked_pseudo2D_continuous_specific_decoded_result = deepcopy(masked_pseudo2D_continuous_specific_decoded_result)\n",
    "ripple_weighted_corr_merged_df\n",
    "\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "## INPUTS: track_marginal_posterior_df\n",
    "\n",
    "# You can use it like this:\n",
    "_out0: \"MatplotlibRenderPlots\" = plot_histograms(data_type='Laps', session_spec='1 Session', data_results_df=track_marginal_posterior_df, time_bin_duration_str=\"25 ms\")\n",
    "# _out1: \"MatplotlibRenderPlots\" = plot_histograms(data_type='Ripples', session_spec='All Sessions', data_results_df=all_sessions_ripple_time_bin_df, time_bin_duration_str=\"75 ms\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01af1de8",
   "metadata": {},
   "source": [
    "# 'DirectionalDecodersEpochsEvaluations' Manipulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20af0225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DecoderDecodedEpochsResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "\n",
    "if ('DirectionalDecodersEpochsEvaluations' in curr_active_pipeline.global_computation_results.computed_data) and (curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations'] is not None):\n",
    "    directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "    directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)\n",
    "\n",
    "    ## UNPACK HERE via direct property access:\n",
    "    pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "    ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "    laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "    print(f'{pos_bin_size = }, {ripple_decoding_time_bin_size = }, {laps_decoding_time_bin_size = }') # pos_bin_size = 3.8054171165052444, ripple_decoding_time_bin_size = 0.025, laps_decoding_time_bin_size = 0.2\n",
    "    decoder_laps_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict\n",
    "    decoder_ripple_filter_epochs_decoder_result_dict = directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict\n",
    "    decoder_laps_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_df_dict\n",
    "    decoder_ripple_radon_transform_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_df_dict\n",
    "\n",
    "    # New items:\n",
    "    decoder_laps_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_laps_radon_transform_extras_dict\n",
    "    decoder_ripple_radon_transform_extras_dict = directional_decoders_epochs_decode_result.decoder_ripple_radon_transform_extras_dict\n",
    "\n",
    "    # Weighted correlations:\n",
    "    laps_weighted_corr_merged_df = directional_decoders_epochs_decode_result.laps_weighted_corr_merged_df\n",
    "    ripple_weighted_corr_merged_df = directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "    decoder_laps_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_laps_weighted_corr_df_dict\n",
    "    decoder_ripple_weighted_corr_df_dict = directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict\n",
    "\n",
    "    # Pearson's correlations:\n",
    "    laps_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.laps_simple_pf_pearson_merged_df\n",
    "    ripple_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603edd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_session_name: str = curr_active_pipeline.session_name # '2006-6-08_14-26-15'\n",
    "CURR_BATCH_OUTPUT_PREFIX: str = f\"{BATCH_DATE_TO_USE}-{curr_session_name}\"\n",
    "print(f'CURR_BATCH_OUTPUT_PREFIX: {CURR_BATCH_OUTPUT_PREFIX}')\n",
    "\n",
    "# active_context = curr_active_pipeline.get_session_context().adding_context_if_missing(custom_\n",
    "\n",
    "# session_name: str = curr_active_pipeline.session_name\n",
    "\n",
    "active_context = curr_active_pipeline.get_session_context()\n",
    "session_name: str = f\"{curr_active_pipeline.session_name}{custom_suffix}\" ## appending this here is a hack, but it makes the correct filename\n",
    "active_context = active_context.adding_context_if_missing(suffix=custom_suffix)\n",
    "session_ctxt_key:str = active_context.get_description(separator='|', subset_includelist=(IdentifyingContext._get_session_context_keys() + ['suffix']))\n",
    "\n",
    "earliest_delta_aligned_t_start, t_delta, latest_delta_aligned_t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "active_context\n",
    "session_ctxt_key\n",
    "# Shifts the absolute times to delta-relative values, as would be needed to draw on a 'delta_aligned_start_t' axis:\n",
    "delta_relative_t_start, delta_relative_t_delta, delta_relative_t_end = np.array([earliest_delta_aligned_t_start, t_delta, latest_delta_aligned_t_end]) - t_delta\n",
    "# decoder_user_selected_epoch_times_dict, any_good_selected_epoch_times = DecoderDecodedEpochsResult.load_user_selected_epoch_times(curr_active_pipeline)\n",
    "# any_good_selected_epoch_indicies = filtered_ripple_simple_pf_pearson_merged_df.epochs.matching_epoch_times_slice(any_good_selected_epoch_times)\n",
    "# df = filter_epochs_dfs_by_annotation_times(curr_active_pipeline, any_good_selected_epoch_times, ripple_decoding_time_bin_size=ripple_decoding_time_bin_size, filtered_ripple_simple_pf_pearson_merged_df, ripple_weighted_corr_merged_df)\n",
    "# df\n",
    "\n",
    "# collected_outputs_path = self.collected_outputs_path.resolve()\n",
    "\n",
    "collected_outputs_path = collected_outputs_path.resolve()\n",
    "\n",
    "## Export CSVs:\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d550bf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "def _update_ripple_df(a_ripple_df):\n",
    "    \"\"\" captures: session_name, t_start, t_delta, t_end, ripple_decoding_time_bin_size \"\"\"\n",
    "    if ('time_bin_size' not in a_ripple_df.columns) and (ripple_decoding_time_bin_size is not None):\n",
    "        ## add the column\n",
    "        a_ripple_df['time_bin_size'] = ripple_decoding_time_bin_size\n",
    "    # Add the maze_id to the active_filter_epochs so we can see how properties change as a function of which track the replay event occured on:\n",
    "    a_ripple_df = DecoderDecodedEpochsResult.add_session_df_columns(a_ripple_df, session_name=session_name, time_bin_size=None, t_start=t_start, curr_session_t_delta=t_delta, t_end=t_end, time_col='ripple_start_t')\n",
    "    return a_ripple_df\n",
    "\n",
    "directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df = _update_ripple_df(directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df)\n",
    "directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df = _update_ripple_df(directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df)\n",
    "    \n",
    "ripple_weighted_corr_merged_df = directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "ripple_simple_pf_pearson_merged_df = directional_decoders_epochs_decode_result.ripple_simple_pf_pearson_merged_df\n",
    "\n",
    "## UPDATES: directional_decoders_epochs_decode_result\n",
    "## OUTPUTS: ripple_simple_pf_pearson_merged_df, ripple_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127cd14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_simple_pf_pearson_merged_df\n",
    "ripple_weighted_corr_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec606dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "# directional_decoders_epochs_decode_result.decoder_ripple_weighted_corr_df_dict # vector for each decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161d321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_pseudo2D_continuous_specific_decoded_result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fa02d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot: directional_decoders_epochs_decode_result.ripple_weighted_corr_merged_df\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_pre_post_delta_scatter\n",
    "from pyphoplacecellanalysis.Pho2D.statistics_plotting_helpers import plot_histograms\n",
    "\n",
    "## INPUTS: masked_pseudo2D_continuous_specific_decoded_result\n",
    "masked_pseudo2D_continuous_specific_decoded_result = deepcopy(masked_pseudo2D_continuous_specific_decoded_result)\n",
    "ripple_weighted_corr_merged_df\n",
    "\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "# You can use it like this:\n",
    "_out0: \"MatplotlibRenderPlots\" = plot_histograms(data_type='Continuous', session_spec='1 Session', data_results_df=masked_pseudo2D_continuous_specific_decoded_result, time_bin_duration_str=\"25 ms\")\n",
    "# _out1: \"MatplotlibRenderPlots\" = plot_histograms(data_type='Ripples', session_spec='All Sessions', data_results_df=all_sessions_ripple_time_bin_df, time_bin_duration_str=\"75 ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e17e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram_bins = 'auto'\n",
    "histogram_bins: int = 25\n",
    "\n",
    "# ripple_weighted_corr_merged_df = ripple_weighted_corr_merged_df[['P_Short','delta_aligned_start_t', 'time_bin_size']]\n",
    "ripple_weighted_corr_merged_df = ripple_weighted_corr_merged_df[['P_Short','delta_aligned_start_t', 'time_bin_size']]\n",
    "new_ripple_fig, new_ripple_fig_context = plotly_pre_post_delta_scatter(data_results_df=ripple_weighted_corr_merged_df, out_scatter_fig=None, histogram_bins=histogram_bins,\n",
    "                                                                        px_scatter_kwargs=dict(title='Ripple'), histogram_variable_name='P_Short')\n",
    "\n",
    "# new_laps_fig = new_laps_fig.update_layout(fig_size_kwargs, \n",
    "#     xaxis_title=\"X Axis Title\",\n",
    "#     yaxis_title=\"Y Axis Title\",\n",
    "#     legend_title=\"Legend Title\",\n",
    "#     font=dict(\n",
    "#         family=\"Courier New, monospace\",\n",
    "#         size=18,\n",
    "#         color=\"RebeccaPurple\"\n",
    "#     ),\n",
    "# )\n",
    "# Update x-axis labels\n",
    "# new_laps_fig.update_xaxes(title_text=\"Num Time Bins\", row=1, col=1)\n",
    "# new_laps_fig.update_xaxes(title_text=\"Delta-aligned Event Time (seconds)\", row=1, col=2)\n",
    "# new_laps_fig.update_xaxes(title_text=\"Num Time Bins\", row=1, col=3)\n",
    "\n",
    "\n",
    "_extras_output_dict = {}\n",
    "_extras_output_dict[\"y_mid_line\"] = new_ripple_fig.add_hline(y=0.5, line=dict(color=\"rgba(0.8,0.8,0.8,.75)\", width=2), row='all', col='all')\n",
    "\n",
    "new_ripple_fig\n",
    "\n",
    "\n",
    "\n",
    "# # Update layout to add a title to the legend\n",
    "# new_fig_ripples.update_layout(\n",
    "#     legend_title_text='Is User Selected'  # Add a title to the legend\n",
    "# )\n",
    "\n",
    "# fig_to_clipboard(new_fig_ripples, **fig_size_kwargs)\n",
    "\n",
    "# new_laps_fig_context: IdentifyingContext = new_laps_fig_context.adding_context_if_missing(epoch='withNewKamranExportedReplays', num_sessions=num_sessions, plot_type='scatter+hist', comparison='pre-post-delta', variable_name=variable_name)\n",
    "# figure_out_paths = save_plotly(a_fig=new_laps_fig, a_fig_context=new_laps_fig_context)\n",
    "# new_laps_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59a55fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_PBE_marginal_over_track_ID # (2, 44887) - which track it's using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a48222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import find_epochs_overlapping_other_epochs\n",
    "\n",
    "# INPUTS: track_marginal_posterior_df\n",
    "\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "global_session = curr_active_pipeline.filtered_sessions[global_epoch_name]\n",
    "\n",
    "# global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps) # .trimmed_to_non_overlapping()\n",
    "global_laps_epochs_df = global_laps.to_dataframe()\n",
    "# active_test_epochs_df: pd.DataFrame = deepcopy(global_laps_epochs_df)\n",
    "global_laps_epochs_df\n",
    "\n",
    "\n",
    "# global_laps_epochs_df\n",
    "is_included: NDArray = find_epochs_overlapping_other_epochs(epochs_df=track_marginal_posterior_df, epochs_df_required_to_overlap=deepcopy(global_laps_epochs_df))\n",
    "track_marginal_posterior_df['is_in_laps'] = is_included\n",
    "track_marginal_posterior_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ad6c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_PBE_marginal_over_track_ID.shape # (2, 44887) - which track it's using\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01fe90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window_centers.shape # (44887,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9176dca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Build into a marginal df like `all_sessions_laps_df`:\n",
    "track_marginal_posterior_df : pd.DataFrame = pd.DataFrame({'t':deepcopy(time_window_centers), 'P_Long': np.squeeze(non_PBE_marginal_over_track_ID[0, :]), 'P_Short': np.squeeze(non_PBE_marginal_over_track_ID[1, :]), 'time_bin_size': pseudo2D_continuous_specific_decoded_result.decoding_time_bin_size})\n",
    "track_marginal_posterior_df['delta_aligned_start_t'] = track_marginal_posterior_df['t'] - t_delta ## subtract off t_delta\n",
    "track_marginal_posterior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af44479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "template: str = 'plotly_dark' # set plotl template\n",
    "pio.templates.default = template\n",
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import plotly_pre_post_delta_scatter\n",
    "\n",
    "\n",
    "histogram_bins: int = 25\n",
    "\n",
    "# new_laps_fig = plotly_pre_post_delta_scatter(data_results_df=deepcopy(all_sessions_laps_df), out_scatter_fig=fig_laps, histogram_bins=histogram_bins, px_scatter_kwargs = dict(title='Laps'))\n",
    "fig, figure_context = plotly_pre_post_delta_scatter(data_results_df=deepcopy(track_marginal_posterior_df)[['delta_aligned_start_t', 'P_Long', 'time_bin_size']], out_scatter_fig=None, histogram_bins=histogram_bins, px_scatter_kwargs = dict(title='Continuous'))\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3b13c7",
   "metadata": {},
   "source": [
    "### <a id='toc25_1_1_'></a>[🚧🔜 2025-02-26 -  Plot 1D pseudo2D Continuous Decodings and their marginals over TrackID on SpikeRaster2D track - uses `AddNewDecodedPosteriors_MatplotlibPlotCommand.prepare_and_perform_custom_decoder_decoded_epochs(...)`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9569f931",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_bin_size = epochs_decoding_time_bin_size\n",
    "info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dock_item = active_2d_plot.add_docked_marginal_track(name='non-PBE_marginal_over_track_ID',\n",
    "                                                                                        time_window_centers=time_window_centers, a_1D_posterior=non_PBE_marginal_over_track_ID, extended_dock_title_info=info_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfd6308",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_decoded_results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94401b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AddNewDecodedEpochMarginal_MatplotlibPlotCommand._perform_add_new_decoded_posterior_marginal_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4f1cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dock all Grouped results from `'DockedWidgets.Pseudo2DDecodedEpochsDockedMatplotlibView'`\n",
    "## INPUTS: active_2d_plot\n",
    "nested_dock_items, nested_dynamic_docked_widget_container_widgets = active_2d_plot.ui.dynamic_docked_widget_container.layout_dockGroups()\n",
    "grouped_dock_items_dict = active_2d_plot.ui.dynamic_docked_widget_container.get_dockGroup_dock_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e99ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d58a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_ax.remove(line_measured_position)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6931df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_results = curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['non_PBE_epochs_results'], computation_kwargs_list=[dict(epochs_decoding_time_bin_size=0.025, frame_divide_bin_size=5.0, compute_1D=True, compute_2D=False, drop_previous_result_and_compute_fresh=True, skip_training_test_split=False)],\n",
    "                                                                                                                                            enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3232a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['non_PBE_epochs_results'], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb2b869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs_decoding_time_bin_size = 0.050\n",
    "# subdivide_bin_size = 0.250\n",
    "\n",
    "epochs_decoding_time_bin_size = 1.0\n",
    "subdivide_bin_size = 1.0\n",
    "\n",
    "_out_results = curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['non_PBE_epochs_results'], computation_kwargs_list=[dict(epochs_decoding_time_bin_size=epochs_decoding_time_bin_size, frame_divide_bin_size=subdivide_bin_size, compute_1D=True, compute_2D=True, drop_previous_result_and_compute_fresh=False)],\n",
    "                                                                                                                                            enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b103e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [np.shape(v) for v in a_result.p_x_given_n_list]\n",
    "\n",
    "np.sum([np.prod(np.shape(v)) for v in a_result.p_x_given_n_list])\n",
    "\n",
    "# np.vstack([np.shape(v) for v in a_result.p_x_given_n_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464af0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.Loading import saveData, loadData\n",
    "\n",
    "# output_save_parent_path: Path = Path(r\"C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\data\").resolve()\n",
    "output_save_parent_path: Path = curr_active_pipeline.get_output_path().resolve()\n",
    "# hdf5_output_path: Path = curr_active_pipeline.get_output_path().joinpath('2025-02-14_results_nonPBEDecoding_2D.h5')\n",
    "# pkl_output_path: Path = output_save_parent_path.joinpath('2025-02-18_results_EpochComputations_nonPBEDecoding.pkl')\n",
    "pkl_output_path: Path = output_save_parent_path.joinpath('2025-02-20_results_EpochComputations_nonPBEDecoding.pkl')\n",
    "print(f'pkl_output_path: \"{pkl_output_path}\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5d8014",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "saveData(pkl_output_path, nonPBE_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad5e355",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load from pickle:\n",
    "print(f'pkl_output_path: {pkl_output_path}')\n",
    "nonPBE_results = loadData(pkl_path=pkl_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b617c11",
   "metadata": {},
   "source": [
    "## <a id='toc32_2_'></a>[Get 1D representations of the Pseudo2D track (4 decoders) so they can be plotted on seperate tracks and bin-debugged independently.](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b821104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "\n",
    "epochs_decoding_time_bin_size: float = 0.050\n",
    "\n",
    "# output_dict = active_2d_plot.compute_if_needed_and_add_continuous_decoded_posterior(curr_active_pipeline=curr_active_pipeline, desired_time_bin_size=0.025, debug_print=True)\n",
    "output_dict = active_2d_plot.compute_if_needed_and_add_continuous_decoded_posterior(curr_active_pipeline=curr_active_pipeline, desired_time_bin_size=epochs_decoding_time_bin_size, debug_print=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2e7918",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d23c891",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "\n",
    "\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "directional_merged_decoders_result.laps_all_epoch_bins_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d035e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "\n",
    "\n",
    "# epochs_decoding_time_bin_size: float = 0.025\n",
    "\n",
    "## get the result data:\n",
    "try:\n",
    "    ## Uses the `global_computation_results.computed_data['DirectionalDecodersDecoded']`\n",
    "    directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "    # pseudo2D_decoder: BasePositionDecoder = directional_decoders_decode_result.pseudo2D_decoder\n",
    "    all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "    a_continuously_decoded_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_decode_result.continuously_decoded_result_cache_dict.get(epochs_decoding_time_bin_size, None)\n",
    "    all_time_bin_sizes_output_dict: Dict[float, Dict[types.DecoderName, SingleEpochDecodedResult]] = directional_decoders_decode_result.split_pseudo2D_continuous_result_to_1D_continuous_result()\n",
    "    a_split_pseudo2D_continuous_result_to_1D_continuous_result_dict: Dict[types.DecoderName, SingleEpochDecodedResult] = all_time_bin_sizes_output_dict.get(epochs_decoding_time_bin_size, None)\n",
    "    \n",
    "    assert a_continuously_decoded_dict is not None, f\"a_continuously_decoded_dict is None even after recomputing!\"\n",
    "    assert a_split_pseudo2D_continuous_result_to_1D_continuous_result_dict is not None, f\"a_split_pseudo2D_continuous_result_to_1D_continuous_result_dict is None even after recomputing!\"\n",
    "    info_string: str = f\" - t_bin_size: {epochs_decoding_time_bin_size:.3f}\"\n",
    "    \n",
    "    _a_continuously_decoded_pseudo2D_result: DecodedFilterEpochsResult = deepcopy(a_continuously_decoded_dict['pseudo2D'])\n",
    "    assert _a_continuously_decoded_pseudo2D_result is not None\n",
    "    all_time_bin_decoded_pseudo2D_result: SingleEpochDecodedResult = _a_continuously_decoded_pseudo2D_result.get_result_for_epoch(0)\n",
    "\n",
    "\n",
    "except (KeyError, AttributeError) as e:\n",
    "    # KeyError: 'DirectionalDecodersDecoded'\n",
    "    print(f'add_all_computed_time_bin_sizes_pseudo2D_decoder_decoded_epochs(...) failed to add any tracks, perhaps because the pipeline is missing any computed \"DirectionalDecodersDecoded\" global results. Error: \"{e}\". Skipping.')\n",
    "    a_continuously_decoded_dict = None\n",
    "    pseudo2D_decoder = None        \n",
    "    pass\n",
    "\n",
    "except Exception as e:\n",
    "    raise\n",
    "\n",
    "\n",
    "## OUTPUTS: all_time_bin_decoded_pseudo2D_result\n",
    "np.shape(all_time_bin_decoded_pseudo2D_result.p_x_given_n) # (59, 4, 34744)\n",
    "\n",
    "marginal_x = deepcopy(all_time_bin_decoded_pseudo2D_result.marginal_x['p_x_given_n'])\n",
    "marginal_y = deepcopy(all_time_bin_decoded_pseudo2D_result.marginal_y['p_x_given_n'])\n",
    "\n",
    "\n",
    "np.shape(marginal_x) # (59, 34744)\n",
    "np.shape(marginal_y) # (4, 34744) -- marginalization of position bins\n",
    "\n",
    "\n",
    "## OUTPUTS: a_continuously_decoded_dict, a_split_pseudo2D_continuous_result_to_1D_continuous_result_dict\n",
    "# a_continuously_decoded_pseudo2D_result.build_per_time_bin_marginals_df(active_marginals_tuple=(laps_directional_all_epoch_bins_marginal, laps_track_identity_all_epoch_bins_marginal), columns_tuple=(['P_LR', 'P_RL'], ['P_Long', 'P_Short']))\n",
    "\n",
    "\n",
    "# a_split_pseudo2D_continuous_result_to_1D_continuous_result_dict\n",
    "all_time_bin_decoded_pseudo2D_result.time_bin_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95ec3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame('t': all_time_bin_decoded_pseudo2D_result.time_bin_edges.to_numpy(), })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d672dc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: all_time_bin_decoded_pseudo2D_result\n",
    "\n",
    "unique_decoder_names = ['long_LR', 'long_RL', 'short_LR', 'short_RL']\n",
    "# unique_decoder_names = ['long', 'short']\n",
    "\n",
    "# a_pseudo2D_split_to_1D_continuous_results_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = all_time_bin_decoded_pseudo2D_result.split_pseudo2D_result_to_1D_result(pseudo2D_decoder_names_list=unique_decoder_names)\n",
    "a_non_PBE_marginal_over_track_ID, a_non_PBE_marginal_over_track_ID_posterior_df = DirectionalPseudo2DDecodersResult.build_generalized_non_marginalized_raw_posteriors(_a_continuously_decoded_pseudo2D_result, unique_decoder_names=unique_decoder_names) #[0]['p_x_given_n']\n",
    "\n",
    "a_non_PBE_marginal_over_track_ID_posterior_df['t_bin_center'] = a_non_PBE_marginal_over_track_ID_posterior_df['t']\n",
    "## Add the combined columns:\n",
    "### TrackID:\n",
    "a_non_PBE_marginal_over_track_ID_posterior_df['P_Long'] = (a_non_PBE_marginal_over_track_ID_posterior_df['P_Long_lr'] + a_non_PBE_marginal_over_track_ID_posterior_df['P_Long_rl'])\n",
    "a_non_PBE_marginal_over_track_ID_posterior_df['P_Short'] = (a_non_PBE_marginal_over_track_ID_posterior_df['P_Short_lr'] + a_non_PBE_marginal_over_track_ID_posterior_df['P_Short_rl'])\n",
    "### Direction:\n",
    "a_non_PBE_marginal_over_track_ID_posterior_df['P_LR'] = (a_non_PBE_marginal_over_track_ID_posterior_df['P_Long_lr'] + a_non_PBE_marginal_over_track_ID_posterior_df['P_Short_lr'])\n",
    "a_non_PBE_marginal_over_track_ID_posterior_df['P_RL'] = (a_non_PBE_marginal_over_track_ID_posterior_df['P_Long_rl'] + a_non_PBE_marginal_over_track_ID_posterior_df['P_Short_rl'])\n",
    "\n",
    "a_non_PBE_marginal_over_track_ID_posterior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53513e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_ctxt = IdentifyingContext()\n",
    "\n",
    "a_df = deepcopy(a_non_PBE_marginal_over_track_ID_posterior_df)\n",
    "## INPUTS: a_df\n",
    "\n",
    "time_bin_size = epochs_decoding_time_bin_size\n",
    "info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "plot_row_identifier: str = a_ctxt.get_description(subset_includelist=['known_named_decoding_epochs_type', 'masked_time_bin_fill_type'], include_property_names=True, key_value_separator=':', separator='|', replace_separator_in_property_names='-')\n",
    "a_time_window_centers = a_df['t_bin_center'].to_numpy() \n",
    "a_1D_posterior = a_df[['P_Long', 'P_Short']].to_numpy().T\n",
    "\n",
    "identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dock_item = active_2d_plot.add_docked_marginal_track(name=plot_row_identifier, time_window_centers=a_time_window_centers, a_1D_posterior=a_1D_posterior, extended_dock_title_info=info_string)\n",
    "_all_tracks_out_artists[identifier_name] = widget\n",
    "matplotlib_fig_axes[0].set_xlim(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time)\n",
    "widget.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474d2414",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae4b6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalDecodersContinuouslyDecodedResult, DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import SingleEpochDecodedResult\n",
    "\n",
    "## INPUTS: laps_pseudo2D_continuous_specific_decoded_result: DecodedFilterEpochsResult\n",
    "unique_decoder_names = ['long', 'short']\n",
    "laps_pseudo2D_split_to_1D_continuous_results_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = laps_pseudo2D_continuous_specific_decoded_result.split_pseudo2D_result_to_1D_result(pseudo2D_decoder_names_list=unique_decoder_names)\n",
    "masked_laps_pseudo2D_split_to_1D_continuous_results_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = masked_laps_pseudo2D_continuous_specific_decoded_result.split_pseudo2D_result_to_1D_result(pseudo2D_decoder_names_list=unique_decoder_names)\n",
    "\n",
    "# OUTPUTS: laps_pseudo2D_split_to_1D_continuous_results_dict, masked_laps_pseudo2D_split_to_1D_continuous_results_dict\n",
    "\n",
    "# active_marginals=ripple_track_identity_marginals, columns=['P_LR', 'P_RL'] \n",
    "# active_marginals=ripple_track_identity_marginals, columns=['P_Long', 'P_Short']\n",
    "# laps_track_identity_all_epoch_bins_marginal\n",
    "\n",
    "## INPUTS: laps_pseudo2D_continuous_specific_decoded_result: DecodedFilterEpochsResult\n",
    "flat_time_window_centers, flat_marginal_y_p_x_given_n = laps_pseudo2D_continuous_specific_decoded_result.get_pseudo2D_result_to_pseudo2D_marginalization_result(pseudo2D_decoder_names_list=unique_decoder_names)\n",
    "flat_marginal_y_p_x_given_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904527b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_all_tracks_out_artists = {}\n",
    "for a_ctxt, a_df in flat_decoded_marginal_posterior_df_context_dict.items():\n",
    "    time_bin_size = epochs_decoding_time_bin_size\n",
    "    info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "    plot_row_identifier: str = a_ctxt.get_description(subset_includelist=['known_named_decoding_epochs_type', 'masked_time_bin_fill_type'], include_property_names=True, key_value_separator=':', separator='|', replace_separator_in_property_names='-')\n",
    "    a_time_window_centers = a_df['t_bin_center'].to_numpy() \n",
    "    a_1D_posterior = a_df[['P_Long', 'P_Short']].to_numpy().T\n",
    "\n",
    "    identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dock_item = active_2d_plot.add_docked_marginal_track(name=plot_row_identifier, time_window_centers=a_time_window_centers, a_1D_posterior=a_1D_posterior, extended_dock_title_info=info_string)\n",
    "    _all_tracks_out_artists[identifier_name] = widget\n",
    "    intervals_overview_plot_item.setXRange(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time, padding=0) ## global frame\n",
    "    matplotlib_fig_axes[0].set_xlim(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time)\n",
    "    widget.draw()\n",
    "\n",
    "\n",
    "## Make a new matplotlib figure (in a new window) that contains a copy of `matplotlib_fig_axes` inserted \n",
    "\n",
    "\n",
    "\n",
    "# active_2d_plot.add_docked_marginal_track("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3c784d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.mixins.indexing_helpers import get_dict_subset\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalDecodersContinuouslyDecodedResult, DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import SingleEpochDecodedResult\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, DockDisplayColors\n",
    "\n",
    "debug_print = True\n",
    "\n",
    "## Uses the `global_computation_results.computed_data['DirectionalDecodersDecoded']`\n",
    "directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "pseudo2D_decoder: BasePositionDecoder = directional_decoders_decode_result.pseudo2D_decoder  # merged pseudo2D decoder\n",
    "all_directional_pf1D_Decoder_dict: Dict[types.DecoderName, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict ## separate 1D decoders\n",
    "\n",
    "continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "\n",
    "\n",
    "all_time_bin_sizes_output_dict: Dict[float, Dict[types.DecoderName, SingleEpochDecodedResult]] = directional_decoders_decode_result.split_pseudo2D_continuous_result_to_1D_continuous_result()\n",
    "## OUTPUTS: all_directional_pf1D_Decoder_dict, all_time_bin_sizes_output_dict, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50c1170",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uses `AddNewDecodedPosteriors_MatplotlibPlotCommand._perform_add_new_decoded_posterior_row(...)` to build the 4 tracks from the split result:\n",
    "# active_2d_plot.add_new_embedded_pyqtgraph_render_plot_widget(\n",
    "\"\"\"\n",
    "add_new_matplotlib_render_plot_widget\n",
    "add_new_matplotlib_render_plot_widget\n",
    "add_new_embedded_pyqtgraph_render_plot_widget\n",
    "\"\"\"\n",
    "## INPUTS: all_time_bin_sizes_output_dict\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DisplayColorsEnum\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import AddNewDecodedPosteriors_MatplotlibPlotCommand\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, DockDisplayColors\n",
    "\n",
    "## plot only a single time bin for now:\n",
    "cached_decoded_time_bin_size_list = list(all_time_bin_sizes_output_dict.keys())\n",
    "assert len(cached_decoded_time_bin_size_list) > 0\n",
    "active_time_bin_size: float = cached_decoded_time_bin_size_list[0]\n",
    "info_string: str = f'{active_time_bin_size:.2f}'\n",
    "## one for each of the four decoders:\n",
    "a_split_pseudo2D_continuous_result_to_1D_continuous_result_dict: Dict[types.DecoderName, SingleEpochDecodedResult] = all_time_bin_sizes_output_dict[active_time_bin_size]\n",
    "dock_group_sep_character: str = '_'\n",
    "showCloseButton = True\n",
    "_common_dock_config_kwargs = {'dock_group_names': [dock_group_sep_character.join([f'ContinuousDecode', info_string])], 'showCloseButton': showCloseButton}\n",
    "dock_configs = dict(zip(('long_LR', 'long_RL', 'short_LR', 'short_RL'),\n",
    "\t\t\t\t\t\t(CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Laps.get_LR_dock_colors, **_common_dock_config_kwargs),\n",
    "                        CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Laps.get_RL_dock_colors, **_common_dock_config_kwargs),\n",
    "                        CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Laps.get_LR_dock_colors, **_common_dock_config_kwargs),\n",
    "                        CustomDockDisplayConfig(custom_get_colors_callback_fn=DisplayColorsEnum.Laps.get_RL_dock_colors, **_common_dock_config_kwargs))))\n",
    "\n",
    "\n",
    "## all at once:\n",
    "output_dict = active_2d_plot.add_docked_decoded_results_dict_tracks(name=f'DirectionalDecodersDecoded', a_decoded_result_dict=a_split_pseudo2D_continuous_result_to_1D_continuous_result_dict, dock_configs=dock_configs, pf1D_Decoder_dict=all_directional_pf1D_Decoder_dict,\n",
    "                                                                                            measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "                                                                                            extended_dock_title_info=info_string)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6828e1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Need all_directional_pf1D_Decoder_dict\n",
    "output_dict = {}\n",
    "for a_decoder_name, a_1D_continuous_decoded_result in a_split_pseudo2D_continuous_result_to_1D_continuous_result_dict.items():\n",
    "    ## a_1D_continuous_decoded_result: SingleEpochDecodedResult\n",
    "    a_dock_config = dock_configs[a_decoder_name]\n",
    "    a_1D_decoder: BasePositionDecoder = all_directional_pf1D_Decoder_dict[a_decoder_name]\n",
    "    # _out_tuple = AddNewDecodedPosteriors_MatplotlibPlotCommand._perform_add_new_decoded_posterior_row(curr_active_pipeline=curr_active_pipeline, active_2d_plot=active_2d_plot, a_dock_config=a_dock_config, a_decoder_name=a_decoder_name, a_position_decoder=a_1D_decoder,\n",
    "    #                                                             time_window_centers=a_1D_continuous_decoded_result.time_bin_container.centers, a_1D_posterior=a_1D_continuous_decoded_result.p_x_given_n, extended_dock_title_info=info_string)\n",
    "    _out_tuple = active_2d_plot.add_docked_decoded_posterior_track(name=f'DirectionalDecodersDecoded[{a_decoder_name}]', a_dock_config=a_dock_config,\n",
    "                                                                                            time_window_centers=a_1D_continuous_decoded_result.time_bin_container.centers, a_1D_posterior=a_1D_continuous_decoded_result.p_x_given_n,\n",
    "                                                                                            xbin = deepcopy(a_1D_decoder.xbin), measured_position_df=deepcopy(curr_active_pipeline.sess.position.to_dataframe()),\n",
    "                                                                                            extended_dock_title_info=info_string)\n",
    "\n",
    "    identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = _out_tuple\n",
    "    ## Add `a_decoded_result` to the plots_data\n",
    "    widget.plots_data.a_decoded_result = a_1D_continuous_decoded_result\n",
    "    widget.plots_data.a_decoder = deepcopy(a_1D_decoder)\n",
    "    output_dict[a_decoder_name] = _out_tuple\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56538c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_decoder_name, an_out_tuple in output_dict.items():\n",
    "    identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = an_out_tuple\n",
    "    print(f'a_decoder_name: {a_decoder_name} -- identifier_name: \"{identifier_name}\"')\n",
    "\n",
    "    # dDisplayItem.orientation\n",
    "    dDisplayItem.autoOrient = False\n",
    "    # dDisplayItem.setOrientation('horizontal', force=True)\n",
    "    dDisplayItem.setOrientation('vertical', force=True)\n",
    "    dDisplayItem.label.relayout_text()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f833550",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_decoder_name, an_out_tuple in output_dict.items():\n",
    "    identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = an_out_tuple\n",
    "    print(f'a_decoder_name: {a_decoder_name} -- identifier_name: \"{identifier_name}\"')\n",
    "    # widget.plots_data.data_keys\n",
    "    widget.plots_data.a_decoded_result = a_1D_continuous_decoded_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450d37f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import plot_attached_BinByBinDecodingDebugger\n",
    "\n",
    "a_decoder_name: types.DecoderName = 'long_LR'\n",
    "identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dDisplayItem = output_dict[a_decoder_name]\n",
    "a_1D_continuous_decoded_result = widget.plots_data.a_decoded_result\n",
    "a_decoder = widget.plots_data.a_decoder\n",
    "## INPUTS: a_decoder, a_decoded_result\n",
    "win, out_pf1D_decoder_template_objects, (plots_container, plots_data), _on_update_fcn = plot_attached_BinByBinDecodingDebugger(spike_raster_window, curr_active_pipeline, a_decoder=a_decoder, a_decoded_result=a_1D_continuous_decoded_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b217f221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_1D_continuous_decoded_result.epoch_info_tuple\n",
    "a_1D_continuous_decoded_result.time_bin_container.center_info.step\n",
    "a_1D_continuous_decoded_result.time_bin_container.edge_info.step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c4a72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.DockingWidgets.DynamicDockDisplayAreaContent import CustomDockDisplayConfig, CustomCyclicColorsDockDisplayConfig, NamedColorScheme\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.SpikeRasters import new_plot_raster_plot #, NewSimpleRaster, paired_separately_sort_neurons\n",
    "\n",
    "_raster_tracks_out_dict = {}\n",
    "## Enables creating a new pyqtgraph-based track to display the intervals/epochs\n",
    "dock_config = CustomCyclicColorsDockDisplayConfig(named_color_scheme=NamedColorScheme.grey, showCloseButton=True, showCollapseButton=False, showGroupButton=False, corner_radius=\"0px\", hideTitleBar=True)\n",
    "name = f'rasters[{name_modifier_suffix}]'\n",
    "time_sync_pyqtgraph_widget, raster_root_graphics_layout_widget, raster_plot_item, raster_dock = self.add_new_embedded_pyqtgraph_render_plot_widget(name=name, dockSize=(500, 120), display_config=dock_config)\n",
    "\n",
    "if raster_plot_item not in self.params.custom_interval_rendering_plots:\n",
    "    self.params.custom_interval_rendering_plots.append(raster_plot_item) ## this signals that it should recieve updates for its intervals somewhere else\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15a97f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# all_time_bin_sizes_output_dict = {'non_marginalized_raw_result': [], 'marginal_over_direction': [], 'marginal_over_track_ID': []}\n",
    "# flat_all_time_bin_sizes_output_tuples_list: List[Tuple] = []\n",
    "\n",
    "for time_bin_size, a_continuously_decoded_dict in continuously_decoded_result_cache_dict.items():\n",
    "    ## Each iteration here adds 4 more tracks -- one for each decoding context\n",
    "    \n",
    "    # a_continuously_decoded_dict: Dict[str, DecodedFilterEpochsResult]\n",
    "    if debug_print:\n",
    "        print(f'time_bin_size: {time_bin_size}')\n",
    "\n",
    "    info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "    \n",
    "    ## Uses the `global_computation_results.computed_data['DirectionalDecodersDecoded']`\n",
    "    # all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "    # continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "\n",
    "    continuously_decoded_dict = a_continuously_decoded_dict\n",
    "    \n",
    "\n",
    "    # continuously_decoded_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(directional_decoders_decode_result.most_recent_continuously_decoded_dict)\n",
    "    assert continuously_decoded_dict is not None\n",
    "\n",
    "    ## Get the separate 1D results, these are ready-to-go:\n",
    "    all_directional_pf1D_Decoder_continuous_results_dict: Dict[types.DecoderName, SingleEpochDecodedResult] = {k:v.get_result_for_epoch(0) for k, v in get_dict_subset(continuously_decoded_dict, subset_includelist=None, subset_excludelist=['pseudo2D']).items()}\n",
    "    \n",
    "\n",
    "    ## Extract the Pseudo2D results as separate 1D tracks\n",
    "    ## INPUTS: most_recent_continuously_decoded_dict: Dict[str, DecodedFilterEpochsResult], info_string\n",
    "    \n",
    "    # all_directional_continuously_decoded_dict = most_recent_continuously_decoded_dict or {}\n",
    "    pseudo2D_decoder_continuously_decoded_result: DecodedFilterEpochsResult = continuously_decoded_dict.get('pseudo2D', None)\n",
    "    assert len(pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list) == 1\n",
    "    single_pseudo2D_decoder_continuously_decoded_result: SingleEpochDecodedResult = pseudo2D_decoder_continuously_decoded_result.get_result_for_epoch(0)\n",
    "    \n",
    "\n",
    "    p_x_given_n = single_pseudo2D_decoder_continuously_decoded_result.p_x_given_n ## continuous -- meaning single epoch\n",
    "    # p_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0]['p_x_given_n']\n",
    "    time_bin_container = single_pseudo2D_decoder_continuously_decoded_result.time_bin_container\n",
    "    time_window_centers = time_bin_container.centers\n",
    "    \n",
    "\n",
    "    # p_x_given_n.shape # (62, 4, 209389)\n",
    "\n",
    "    ## Split across the 2nd axis to make 1D posteriors that can be displayed in separate dock rows:\n",
    "    assert p_x_given_n.shape[1] == 4, f\"expected the 4 pseudo-y bins for the decoder in p_x_given_n.shape[1]. but found p_x_given_n.shape: {p_x_given_n.shape}\"\n",
    "    split_pseudo2D_posteriors_dict = {k:np.squeeze(p_x_given_n[:, i, :]) for i, k in enumerate(('long_LR', 'long_RL', 'short_LR', 'short_RL'))}\n",
    "\n",
    "    # Need all_directional_pf1D_Decoder_dict\n",
    "    output_dict = {}\n",
    "    output_pseudo2D_split_to_1D_continuous_results_dict: Dict[types.DecoderName, SingleEpochDecodedResult] = {}\n",
    "\n",
    "    # for a_decoder_name, a_1D_posterior in split_pseudo2D_posteriors_dict.items():\n",
    "    for i, a_decoder_name in enumerate(('long_LR', 'long_RL', 'short_LR', 'short_RL')):\n",
    "        ## make separate `SingleEpochDecodedResult` objects\n",
    "        \n",
    "        # all_directional_pf1D_Decoder_continuous_results_dict\n",
    "        output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name] = deepcopy(single_pseudo2D_decoder_continuously_decoded_result) ## copy the whole pseudo2D result\n",
    "        # output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].p_x_given_n = a_1D_posterior ## or could squish them here\n",
    "        output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].p_x_given_n = np.squeeze(output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].p_x_given_n[:, i, :]) ## or could squish them here\n",
    "        \n",
    "        # _out_tuple = dict(a_decoder_name=a_decoder_name, a_position_decoder=pseudo2D_decoder, time_window_centers=time_window_centers, a_1D_posterior=a_1D_posterior)\n",
    "        # identifier_name, widget, matplotlib_fig, matplotlib_fig_axes = _out_tuple\n",
    "        # output_dict[a_decoder_name] = _out_tuple\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## OUTPUTS: all_directional_pf1D_Decoder_dict: Dict[types.DecoderName, BasePositionDecoder], all_directional_pf1D_Decoder_continuous_results_dict: Dict[types.DecoderName, SingleEpochDecodedResult]\n",
    "## OUTPUTS: pseudo2D_decoder: BasePositionDecoder, single_pseudo2D_decoder_continuously_decoded_result: SingleEpochDecodedResult, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea54c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].p_x_given_n.shape\n",
    "# output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].most_likely_positions\n",
    "\n",
    "# output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name]._test_find_fields_by_shape_metadata()\n",
    "\n",
    "## Marginals are wrong afterwards, and most-likely positions have too many dimensions\n",
    "\n",
    "\n",
    "# pseudo2D_decoder_continuously_decoded_result.perform_compute_marginals\n",
    "output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].most_likely_positions\n",
    "output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].marginal_x\n",
    "\n",
    "output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].marginal_x['p_x_given_n'].shape ## these are okay, (n_x_bins, n_t_bins)\n",
    "output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].marginal_y['p_x_given_n'].shape ## these are bad, (n_decoder_names, n_t_bins)\n",
    "\n",
    "\n",
    "output_pseudo2D_split_to_1D_continuous_results_dict[a_decoder_name].most_likely_positions["
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522aab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo2D_decoder_continuously_decoded_result.pos_bin_edges\n",
    "pseudo2D_decoder_continuously_decoded_result.n_pos_bins\n",
    "continuously_decoded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566c4c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_bin_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1687f8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_pseudo2D_decoder_continuously_decoded_result.to_hdf(\n",
    "import h5py\n",
    "\n",
    "hdf5_output_path: Path = curr_active_pipeline.get_output_path().joinpath('test_data.h5')\n",
    "with h5py.File(hdf5_output_path, 'w') as f: ## open the path as a HDF5 file handle:\n",
    "    single_pseudo2D_decoder_continuously_decoded_result.to_hdf(f, key='single_pseudo2D_decoder_continuously_decoded_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5b63de",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_pseudo2D_decoder_continuously_decoded_result\n",
    "single_pseudo2D_decoder_continuously_decoded_result.marginal_y['p_x_given_n'].shape\n",
    "single_pseudo2D_decoder_continuously_decoded_result.marginal_x['p_x_given_n'].shape\n",
    "\n",
    "\n",
    "\n",
    "# single_pseudo2D_decoder_continuously_decoded_result.epoch_info_tuple\n",
    "single_pseudo2D_decoder_continuously_decoded_result.p_x_given_n.shape # (59, 4, 69487)\n",
    "# single_pseudo2D_decoder_continuously_decoded_result.get_posterior_as_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66ce480",
   "metadata": {},
   "source": [
    "# <a id='toc34_'></a>[General Decoding Record with Frozen Decoding Parameters Tuples](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0889b292",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dict of decoding results, where the decoders used for decoding are built from: nonPBE_Long, nonPBE_Short, Laps_LongLR, Laps_LongRL, Laps_ShortLR, Laps_ShortRL\n",
    "## qclu, frHz\n",
    "# All Decoders should be continuous (decoding the entire session as a single epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e6797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import EpochsAccessor, Epoch, ensure_dataframe, ensure_Epoch\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import EpochComputationFunctions, EpochComputationsComputationsContainer, DecodingResultND, Compute_NonPBE_Epochs, KnownFilterEpochs\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import GeneralDecoderDictDecodedEpochsDictResult, GenericResultTupleIndexType, KnownNamedDecodingEpochsType, MaskedTimeBinFillType\n",
    "\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "\n",
    "## Unpack from pipeline:\n",
    "nonPBE_results: EpochComputationsComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['EpochComputations']\n",
    "a_new_NonPBE_Epochs_obj: Compute_NonPBE_Epochs = nonPBE_results.a_new_NonPBE_Epochs_obj\n",
    "results1D: DecodingResultND = nonPBE_results.results1D\n",
    "results2D: DecodingResultND = nonPBE_results.results2D\n",
    "\n",
    "epochs_decoding_time_bin_size = nonPBE_results.epochs_decoding_time_bin_size\n",
    "frame_divide_bin_size = nonPBE_results.frame_divide_bin_size\n",
    "\n",
    "print(f'{epochs_decoding_time_bin_size = }, {frame_divide_bin_size = }')\n",
    "\n",
    "assert (results1D is not None)\n",
    "# assert (results2D is not None)\n",
    "\n",
    "## New computed properties:\n",
    "a_general_decoder_dict_decoded_epochs_dict_result: GeneralDecoderDictDecodedEpochsDictResult = nonPBE_results.a_general_decoder_dict_decoded_epochs_dict_result ## get the pre-decoded result\n",
    "a_general_decoder_dict_decoded_epochs_dict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098dbf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# 2025-02-20 20:06 New `nonPBE_results._build_merged_joint_placefields_and_decode` method                              #\n",
    "# ==================================================================================================================== #\n",
    "non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict, non_PBE_marginal_over_track_ID, (time_bin_containers, time_window_centers, track_marginal_posterior_df) = nonPBE_results._build_merged_joint_placefields_and_decode(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)))\n",
    "masked_pseudo2D_continuous_specific_decoded_result, _mask_index_tuple = pseudo2D_continuous_specific_decoded_result.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)))\n",
    "## OUTPUTS: pseudo2D_continuous_specific_decoded_result, non_PBE_marginal_over_track_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1ffbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'DirectionalMergedDecoders' in curr_active_pipeline.global_computation_results.computed_data:\n",
    "    # DirectionalMergedDecoders: Get the result after computation:\n",
    "    directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "    a_new_fully_generic_result = a_new_fully_generic_result.adding_directional_pseudo2D_decoder_results_filtered_by_spikes_per_t_bin_masked(directional_merged_decoders_result=directional_merged_decoders_result)\n",
    "else:\n",
    "    print('WARN: missing \"DirectionalMergedDecoders\" global result. Skipping.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f11aef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.get_complete_session_context()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37a4b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict, non_PBE_marginal_over_track_ID, (time_bin_containers, time_window_centers, track_marginal_posterior_df), masked_pseudo2D_continuous_specific_decoded_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf7487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@function_attributes(short_name=None, tags=['WORKING'], input_requires=[], output_provides=[], uses=[], used_by=[], creation_date='2025-03-04 11:36', related_items=[])\n",
    "def add_decoded_posterior_row(active_2d_plot, identifier_name: str, a_decoder: BasePositionDecoder, a_decoded_result: DecodedFilterEpochsResult, extended_dock_title_info: Optional[str]=None):\n",
    "    \"\"\" adds a new decoder track to the active_2d_plot \n",
    "    \"\"\"\n",
    "    from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import SynchronizedPlotMode\n",
    "    from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import plot_1D_most_likely_position_comparsions\n",
    "    from neuropy.utils.matplotlib_helpers import get_heatmap_cmap\n",
    "    from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import FixedCustomColormaps\n",
    "    from pyphocorehelpers.gui.Qt.color_helpers import ColormapHelpers\n",
    "\n",
    "    ## ✅ Add a new row for each of the four 1D directional decoders:\n",
    "    # identifier_name: str = f'ContinuousDecode_{a_decoder_name}'\n",
    "    if extended_dock_title_info is not None:\n",
    "        identifier_name += extended_dock_title_info ## add extra info like the time_bin_size in ms\n",
    "    # print(f'identifier_name: {identifier_name}')\n",
    "\n",
    "    # print(f'identifier_name: {identifier_name}')\n",
    "    widget, matplotlib_fig, matplotlib_fig_axes, dock_item = active_2d_plot.add_new_matplotlib_render_plot_widget(name=identifier_name, dockSize=(65, 200), display_config=None, sync_mode=SynchronizedPlotMode.TO_WINDOW)\n",
    "    an_ax = matplotlib_fig_axes[0]\n",
    "\n",
    "    active_decoder = deepcopy(a_decoder)\n",
    "    assert a_decoded_result is not None, f\"a_decoded_result should not be None anymore.\"\n",
    "\n",
    "    if a_decoded_result is not None:\n",
    "        active_result = deepcopy(a_decoded_result) # already decoded\n",
    "        assert (active_result.num_filter_epochs == 1), f\"currently only supports decoded results (DecodedFilterEpochsResult) computed with a single epoch for all time bins, but active_result.num_filter_epochs: {active_result.num_filter_epochs}\"\n",
    "        active_marginals = active_result.marginal_x_list[0]\n",
    "    else:\n",
    "        # no previously decoded result, fallback to the decoder's internal properties        \n",
    "        active_marginals = active_decoder.marginal.x\n",
    "        \n",
    "\n",
    "    variable_name='x'\n",
    "    active_bins = deepcopy(active_decoder.xbin)\n",
    "    time_window_centers = deepcopy(active_result.time_bin_containers[0].centers)\n",
    "    # active_most_likely_positions = active_marginals.most_likely_positions_1D # Raw decoded positions\n",
    "    active_most_likely_positions = None\n",
    "    active_posterior = active_marginals.p_x_given_n\n",
    "\n",
    "    # active_posterior = deepcopy(a_1D_posterior)\n",
    "    \n",
    "    # most_likely_positions_mode: 'standard'|'corrected'\n",
    "    # fig, curr_ax = curr_active_pipeline.display('_display_plot_marginal_1D_most_likely_position_comparisons', _active_config_name, variable_name='x', most_likely_positions_mode='corrected', ax=an_ax) # ax=active_2d_plot.ui.matplotlib_view_widget.ax\n",
    "    posterior_heatmap_imshow_kwargs = dict(\n",
    "        cmap = get_heatmap_cmap(cmap='viridis', bad_color='black', under_color='white', over_color='red'),\n",
    "    )\n",
    "\n",
    "    measured_position_df = None # Note: for some reason setting `measured_position_df` to anything other than None here messes up the plotting entirely. Set it to None now, and if we want measured positions plot them after\n",
    "    ## Actual plotting portion:\n",
    "    fig, an_ax = plot_1D_most_likely_position_comparsions(measured_position_df=None, time_window_centers=time_window_centers, xbin=active_bins,\n",
    "                                                            posterior=active_posterior,\n",
    "                                                            active_most_likely_positions_1D=active_most_likely_positions,\n",
    "                                                            ax=an_ax, variable_name=variable_name, debug_print=True, enable_flat_line_drawing=False,\n",
    "                                                            posterior_heatmap_imshow_kwargs=posterior_heatmap_imshow_kwargs)\n",
    "\n",
    "\n",
    "\n",
    "    widget.plots_data.active_decoder = active_decoder\n",
    "    widget.plots_data.a_decoded_result = a_decoded_result\n",
    "\n",
    "    # active_bins = active_decoder.xbin\n",
    "\n",
    "    # # active_most_likely_positions = active_marginals.most_likely_positions_1D # Raw decoded positions\n",
    "    # active_most_likely_positions = None\n",
    "    # active_posterior = active_marginals.p_x_given_n\n",
    "    return widget, matplotlib_fig, an_ax, dock_item\n",
    "\n",
    "\n",
    "add_decoded_posterior_row(active_2d_plot, identifier_name=f'Masked Non-PBE Pseudo2D', a_decoder=deepcopy(non_PBE_all_directional_pf1D_Decoder), a_decoded_result=masked_pseudo2D_continuous_specific_decoded_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb796232",
   "metadata": {},
   "source": [
    "# <a id='toc36_'></a>[2025-03-11 Apply the masking strategy introduced with the non-PBE epoch analyses on the other `DecodedFilterEpochsResult`s produced by the lap-constructed decoders (TrackTemplates)](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342da66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from neuropy.core.epoch import ensure_dataframe, ensure_Epoch\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring\n",
    "from neuropy.utils.result_context import DisplaySpecifyingIdentifyingContext\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import EpochFilteringMode, _compute_proper_filter_epochs\n",
    "\n",
    "KnownNamedDecoderTrainedComputeEpochsType = Literal['laps', 'non_pbe']\n",
    "# nonPBE_results = non\n",
    "\n",
    "filtered_epochs_df = None\n",
    "\n",
    "## INPUTS: curr_active_pipeline, track_templates, a_decoded_filter_epochs_decoder_result_dict\n",
    "\n",
    "## INPUTS: directional_decoders_epochs_decode_result, filtered_epochs_df\n",
    "\n",
    "\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = deepcopy(curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']) ## GENERAL\n",
    "# a_new_fully_generic_result = _subfn_add_spikes_per_t_bin_masked_variants(a_new_fully_generic_result, directional_decoders_epochs_decode_result=directional_decoders_epochs_decode_result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ba386b",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict, non_PBE_marginal_over_track_ID, (time_bin_containers, time_window_centers, track_marginal_posterior_df) = nonPBE_results._build_merged_joint_placefields_and_decode(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)))\n",
    "masked_pseudo2D_continuous_specific_decoded_result, _mask_index_tuple = pseudo2D_continuous_specific_decoded_result.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)))\n",
    "# (all_time_bin_indicies, last_valid_indicies) = _mask_index_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5739b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from typing import Literal\n",
    "# Define a type that can only be one of these specific strings\n",
    "KnownNamedDecodingEpochsType = Literal['laps', 'replay', 'ripple', 'pbe', 'non_pbe']\n",
    "# Define a type that can only be one of these specific strings\n",
    "MaskedTimeBinFillType = Literal['ignore', 'last_valid', 'nan_filled', 'dropped'] ## used in `DecodedFilterEpochsResult.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(...)` to specify how invalid bins (due to too few spikes) are treated.\n",
    "\n",
    "GenericResultTupleIndexType: TypeAlias = IdentifyingContext # an template/stand-in variable that aims to abstract away the unique-hashable index of a single result computed with a given set of parameters. Not yet fully implemented 2025-03-09 17:50 \n",
    "\n",
    "test_identifier: IdentifyingContext = IdentifyingContext(known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='last_valid')\n",
    "\n",
    "test_identifier.get_description(include_property_names=True, separator=\"|\", key_value_separator=':') # , replace_separator_in_property_names='|'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828384eb",
   "metadata": {
    "tags": [
     "active-2025-03-11"
    ]
   },
   "outputs": [],
   "source": [
    "## OUTPUTS:\n",
    "# a_new_fully_generic_result\n",
    "\n",
    "for a_context, a_marginal_df in a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict.items():\n",
    "    param_sep_str: str = '¦'\n",
    "    # param_sep_str: str = ''\n",
    "    # param_sep_str: str = ' ⁖'\n",
    "    key_val_sep_str: str = ':'\n",
    "    a_ctxt_str: str = a_context.get_description(separator=param_sep_str, replace_separator_in_property_names='_', include_property_names=True, key_value_separator=key_val_sep_str)\n",
    "    # a_ctxt_str: str = a_context.get_initialization_code_string()\n",
    "    print(f'a_context: \"<{a_ctxt_str}>\" - np.shape(a_marginal_df): {np.shape(a_marginal_df)}')\n",
    "    \n",
    "\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:laps¦masked_time_bin_fill_type:ignore\" - np.shape(a_marginal_df): (14350, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:laps¦masked_time_bin_fill_type:last_valid\" - np.shape(a_marginal_df): (14350, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:laps¦masked_time_bin_fill_type:nan_filled\" - np.shape(a_marginal_df): (14350, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:pbe¦masked_time_bin_fill_type:ignore\" - np.shape(a_marginal_df): (1569, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:pbe¦masked_time_bin_fill_type:last_valid\" - np.shape(a_marginal_df): (1569, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:pbe¦masked_time_bin_fill_type:nan_filled\" - np.shape(a_marginal_df): (1569, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:non_pbe¦masked_time_bin_fill_type:ignore\" - np.shape(a_marginal_df): (43377, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:non_pbe¦masked_time_bin_fill_type:last_valid\" - np.shape(a_marginal_df): (43377, 9)\n",
    "# a_context: \"trained_compute_epochs:non_pbe¦known_named_decoding_epochs_type:non_pbe¦masked_time_bin_fill_type:nan_filled\" - np.shape(a_marginal_df): (43377, 9)\n",
    "# a_context: \"trained_compute_epochs:laps¦pfND_ndim:1¦decoder_identifier:pseudo2D¦time_bin_size:0.025¦known_named_decoding_epochs_type:laps¦masked_time_bin_fill_type:ignore¦data_grain:per_time_bin\" - np.shape(a_marginal_df): (14350, 15)\n",
    "# a_context: \"trained_compute_epochs:laps¦pfND_ndim:1¦decoder_identifier:pseudo2D¦time_bin_size:0.025¦known_named_decoding_epochs_type:laps¦masked_time_bin_fill_type:ignore¦data_grain:per_epoch\" - np.shape(a_marginal_df): (74, 6)\n",
    "# a_context: \"trained_compute_epochs:laps¦pfND_ndim:1¦decoder_identifier:pseudo2D¦time_bin_size:0.025¦known_named_decoding_epochs_type:pbe¦masked_time_bin_fill_type:ignore¦data_grain:per_time_bin\" - np.shape(a_marginal_df): (1165, 15)\n",
    "# a_context: \"trained_compute_epochs:laps¦pfND_ndim:1¦decoder_identifier:pseudo2D¦time_bin_size:0.025¦known_named_decoding_epochs_type:pbe¦masked_time_bin_fill_type:ignore¦data_grain:per_epoch\" - np.shape(a_marginal_df): (133, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188ef752",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a_new_fully_generic_result.filter_epochs_pseudo2D_continuous_specific_decoded_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38476959",
   "metadata": {},
   "source": [
    "##### <a id='toc36_1_1_1_1_'></a>[2025-03-11 11:13 not sure if this is the old version or if it adds something to the `a_new_fully_generic_result`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f9ccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Common/shared for all decoded epochs:\n",
    "unique_decoder_names = ['long', 'short']\n",
    "non_PBE_all_directional_pf1D_Decoder, pseudo2D_continuous_specific_decoded_result, continuous_decoded_results_dict, non_PBE_marginal_over_track_ID, (time_bin_containers, time_window_centers, track_marginal_posterior_df) = nonPBE_results._build_merged_joint_placefields_and_decode(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline))) # , filter_epochs=deepcopy(global_any_laps_epochs_obj)\n",
    "\n",
    "## from dict of filter_epochs to decode:\n",
    "global_replays_df: pd.DataFrame = TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].replay))\n",
    "filter_epochs_to_decode_dict: Dict[KnownNamedDecodingEpochsType, Epoch] = {'laps': ensure_Epoch(deepcopy(global_any_laps_epochs_obj)),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   'pbe': ensure_Epoch(deepcopy(global_session.pbe.get_non_overlapping())),\n",
    "\t\t\t\t\t\t\t\t#  'ripple': ensure_Epoch(deepcopy(global_session.ripple)),\n",
    "\t\t\t\t\t\t\t\t#   'replay': ensure_Epoch(deepcopy(global_replays_df)),\n",
    "\t\t\t\t\t\t\t\t  'non_pbe': ensure_Epoch(deepcopy(global_session.non_pbe)),\n",
    "\t\t\t\t\t\t\t\t  }\n",
    "# filter_epochs_to_decode_dict\n",
    "\n",
    "## Perform the decoding and masking as needed for invalid bins:\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "a_general_decoder_dict_decoded_epochs_dict_result: GeneralDecoderDictDecodedEpochsDictResult = EpochComputationsComputationsContainer._build_output_decoded_posteriors(non_PBE_all_directional_pf1D_Decoder=non_PBE_all_directional_pf1D_Decoder, # pseudo2D_continuous_specific_decoded_result=pseudo2D_continuous_specific_decoded_result,\n",
    "    filter_epochs_to_decode_dict=filter_epochs_to_decode_dict,\n",
    "    unique_decoder_names=unique_decoder_names, spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), epochs_decoding_time_bin_size=epochs_decoding_time_bin_size,\n",
    "    session_name=session_name, t_start=t_start, t_delta=t_delta, t_end=t_end,\n",
    ")\n",
    "\n",
    "\n",
    "## OUTPUTS: filter_epochs_pseudo2D_continuous_specific_decoded_result, filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict\n",
    "# 58sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d05ac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# filter_epochs_pseudo2D_continuous_specific_decoded_result, filter_epochs_decoded_filter_epoch_track_marginal_posterior_df_dict\n",
    "retro_general_decoder_dict_decoded_epochs_dict_result: GeneralDecoderDictDecodedEpochsDictResult = EpochComputationsComputationsContainer._build_output_decoded_posteriors(non_PBE_all_directional_pf1D_Decoder=non_PBE_all_directional_pf1D_Decoder, # pseudo2D_continuous_specific_decoded_result=pseudo2D_continuous_specific_decoded_result,\n",
    "    filter_epochs_to_decode_dict=filter_epochs_to_decode_dict,\n",
    "    unique_decoder_names=unique_decoder_names, spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), epochs_decoding_time_bin_size=epochs_decoding_time_bin_size,\n",
    "    session_name=session_name, t_start=t_start, t_delta=t_delta, t_end=t_end,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021b0ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try fresh 2025-03-11-style decoding of the TrackTemplates:\n",
    "global_session = curr_active_pipeline.filtered_sessions[global_epoch_name]\n",
    "\n",
    "## from dict of filter_epochs to decode:\n",
    "global_replays_df: pd.DataFrame = TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(deepcopy(global_session.replay))\n",
    "global_any_laps_epochs_obj = curr_active_pipeline.computation_results[global_epoch_name].computation_config.pf_params.computation_epochs # global_session.get\n",
    "filter_epochs_to_decode_dict: Dict[KnownNamedDecodingEpochsType, Epoch] = {'laps': ensure_Epoch(deepcopy(global_any_laps_epochs_obj)),\n",
    "                                                                        'pbe': ensure_Epoch(deepcopy(global_session.pbe.get_non_overlapping())),\n",
    "                                #  'ripple': ensure_Epoch(deepcopy(global_session.ripple)),\n",
    "                                #   'replay': ensure_Epoch(deepcopy(global_replays_df)),\n",
    "                                'non_pbe': ensure_Epoch(deepcopy(global_session.non_pbe)),\n",
    "                                }\n",
    "# filter_epochs_to_decode_dict\n",
    "\n",
    "## constrain all epochs to be at least two decoding time bins long, or drop them entirely:\n",
    "filter_epochs_to_decode_dict = {k:_compute_proper_filter_epochs(epochs_df=v, desired_decoding_time_bin_size=epochs_decoding_time_bin_size, minimum_event_duration=(2.0 * epochs_decoding_time_bin_size), mode=EpochFilteringMode.DropShorter)[0] for k, v in filter_epochs_to_decode_dict.items()} # `[0]` gets just the dataframe, as in DropShorter mode the time_bin_size is unchanged\n",
    "\n",
    "## Perform the decoding and masking as needed for invalid bins:\n",
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6a401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_decoders_epochs_decode_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41fef63",
   "metadata": {},
   "source": [
    "# 2025-03-24 Get the old result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8652f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = deepcopy(curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']) ## GENERAL\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = deepcopy(curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders'])\n",
    "spikes_df = deepcopy(get_proper_global_spikes_df(curr_active_pipeline))\n",
    "\n",
    "laps_all_epoch_bins_marginals_df: pd.DataFrame = deepcopy(directional_merged_decoders_result.laps_all_epoch_bins_marginals_df)\n",
    "laps_time_bin_marginals_df: pd.DataFrame = deepcopy(directional_merged_decoders_result.laps_time_bin_marginals_df)\n",
    "laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf31bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_name: str = curr_active_pipeline.session_name\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "laps_time_bin_marginals_df = laps_time_bin_marginals_df.across_session_identity.add_session_df_columns(session_name=session_name, time_bin_size=0.025, t_start=t_start, curr_session_t_delta=t_delta, t_end=t_end)\n",
    "laps_time_bin_marginals_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03d3caf",
   "metadata": {},
   "source": [
    "# 2025-03-24 11:19 TimeBinAggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36957842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "\n",
    "# INPUT: a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult \n",
    "a_new_fully_generic_result.get_matching_contexts(context_query=IdentifyingContext(data_grain= 'per_epoch'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a5eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_new_fully_generic_result.get_matching_contexts(context_query=IdentifyingContext())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f289430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "a_new_fully_generic_result.get_matching_contexts(context_query=IdentifyingContext(trained_compute_epochs='laps', decoder_identifier='pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type='laps',\n",
    "    masked_time_bin_fill_type='ignore',\n",
    "    # masked_time_bin_fill_type='dropped',\n",
    "    data_grain= 'per_time_bin'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51118ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get all non-global, `data_grain= 'per_time_bin'`\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=IdentifyingContext(trained_compute_epochs='laps', decoder_identifier='pseudo2D', time_bin_size=0.025,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t known_named_decoding_epochs_type=['pbe', 'laps'],\n",
    "    masked_time_bin_fill_type='ignore',\n",
    "    # masked_time_bin_fill_type='dropped',\n",
    "    data_grain= 'per_time_bin'))        \n",
    "        \n",
    "flat_decoded_marginal_posterior_df_context_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8390426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_matching_context, a_result, a_decoder, a_decoded_time_bin_marginal_posterior_df = a_new_fully_generic_result.get_results_matching_contexts(context_query=IdentifyingContext(trained_compute_epochs='laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'global', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'), return_multiple_matches=False)\n",
    "best_matching_context, a_result, a_decoder, a_decoded_time_bin_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=IdentifyingContext(trained_compute_epochs='laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type='laps',\n",
    "    masked_time_bin_fill_type='ignore',\n",
    "    # masked_time_bin_fill_type='dropped',\n",
    "    data_grain= 'per_time_bin'))\n",
    "\n",
    "a_decoded_time_bin_marginal_posterior_df\n",
    "\n",
    "## OUTPUTS: a_decoded_time_bin_marginal_posterior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592a128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_matching_context, a_result, a_decoder, a_decoded_time_bin_marginal_posterior_df = a_new_fully_generic_result.get_results_matching_contexts(context_query=IdentifyingContext(trained_compute_epochs='laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'global', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'), return_multiple_matches=False)\n",
    "best_matching_context, a_result, a_decoder, a_decoded_time_bin_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=IdentifyingContext(trained_compute_epochs='laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type='pbe',\n",
    "    masked_time_bin_fill_type='ignore',\n",
    "    # masked_time_bin_fill_type='dropped',\n",
    "    data_grain= 'per_time_bin'))\n",
    "\n",
    "a_decoded_time_bin_marginal_posterior_df\n",
    "\n",
    "## OUTPUTS: a_decoded_time_bin_marginal_posterior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729d8a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(list(a_decoded_time_bin_marginal_posterior_df.columns)) # ['P_LR', 'P_RL', 'P_Long', 'P_Short', 'long_LR', 'long_RL', 'short_LR', 'short_RL', 'result_t_bin_idx', 'epoch_df_idx', 'parent_epoch_label', 'label', 'start', 't_bin_center', 'stop', 'delta_aligned_start_t', 'session_name', 'time_bin_size', 'pre_post_delta_category', 'trained_compute_epochs', 'pfND_ndim', 'decoder_identifier', 'known_named_decoding_epochs_type', 'masked_time_bin_fill_type', 'data_grain', 'is_t_bin_center_fake', 'rolling_avg_P_Short', 'mean_P_Short']\n",
    "broken_columns_dict = {IdentifyingContext(known_named_decoding_epochs_type= 'global', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'): ['result_t_bin_idx', 'epoch_df_idx', 'parent_epoch_label'],\n",
    "                      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses.time_bin_aggregation import TimeBinAggregation\n",
    "\n",
    "## INPUTS: a_decoded_time_bin_marginal_posterior_df\n",
    "\n",
    "n_rolling_avg_window_tbins: int = 3\n",
    "# Create a copy to avoid modifying the original\n",
    "result_df = a_decoded_time_bin_marginal_posterior_df.copy()\n",
    "epoch_partitioned_dfs_dict = a_decoded_time_bin_marginal_posterior_df.pho.partition_df_dict(partitionColumn='parent_epoch_label')\n",
    "\n",
    "# Process each partition\n",
    "for k, df in epoch_partitioned_dfs_dict.items():\n",
    "    rolling_avg = TimeBinAggregation.ToPerEpoch.peak_rolling_avg(df=df, column='P_Short', window=n_rolling_avg_window_tbins)    \n",
    "    # Calculate the mean of P_Short for this group\n",
    "    mean_p_short = TimeBinAggregation.ToPerEpoch.mean(df=df, column='P_Short')\n",
    "\n",
    "    # Get indices from this partition\n",
    "    indices = df.index\n",
    "    # Assign the result to the corresponding rows in the result dataframe\n",
    "    result_df.loc[indices, 'rolling_avg_P_Short'] = rolling_avg\n",
    "    result_df.loc[indices, 'mean_P_Short'] = mean_p_short  # Same mean value for all rows in group\n",
    "    \n",
    "    # result_df.loc[indices\n",
    "\n",
    "## OUTPUTS: result_df\n",
    "\n",
    "a_decoded_time_bin_marginal_posterior_df = deepcopy(result_df)\n",
    "a_decoded_time_bin_marginal_posterior_df\n",
    "\n",
    "# Then keep only the first entry for each 'parent_epoch_label'\n",
    "a_decoded_per_epoch_marginals_df = a_decoded_time_bin_marginal_posterior_df.groupby('parent_epoch_label').first().reset_index()\n",
    "a_decoded_per_epoch_marginals_df\n",
    "\n",
    "## OUTPUTS: a_decoded_time_bin_marginal_posterior_df, a_decoded_per_epoch_marginals_df\n",
    "## Columns of interest: 'rolling_avg_P_Short'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bc734a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.analyses.time_bin_aggregation import TimeBinAggregation\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "\n",
    "a_decoded_per_epoch_marginals_df, a_decoded_time_bin_marginal_posterior_df = GenericDecoderDictDecodedEpochsDictResult._perform_per_epoch_time_bin_aggregation(a_decoded_time_bin_marginal_posterior_df=a_decoded_time_bin_marginal_posterior_df, probabilitY_column_to_aggregate='P_Short', n_rolling_avg_window_tbins=3)\n",
    "\n",
    "a_decoded_time_bin_marginal_posterior_df\n",
    "a_decoded_per_epoch_marginals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae48cb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext, CollisionOutcome\n",
    "from neuropy.analyses.time_bin_aggregation import TimeBinAggregation\n",
    "\n",
    "## get all non-global, `data_grain= 'per_time_bin'`\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=IdentifyingContext(trained_compute_epochs='laps', decoder_identifier='pseudo2D', time_bin_size=0.025,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t known_named_decoding_epochs_type=['pbe', 'laps'],\n",
    "    masked_time_bin_fill_type=('ignore', 'dropped'),\n",
    "    # masked_time_bin_fill_type='dropped',\n",
    "    data_grain= 'per_time_bin'))        \n",
    "\n",
    "\n",
    "\n",
    "_newly_updated_values_tuple = a_new_fully_generic_result.compute_all_per_epoch_aggregations_from_per_time_bin_results(flat_decoded_marginal_posterior_df_context_dict=flat_decoded_marginal_posterior_df_context_dict)\n",
    "per_time_bin_to_per_epoch_context_map_dict, flat_decoded_marginal_posterior_df_per_epoch_marginals_df_context_dict, flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict = _newly_updated_values_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fdc5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if TimeBinAggegreations are performed:\n",
    "per_time_bin_flat_context_list, per_time_bin_flat_result_context_dict, per_time_bin_flat_decoder_context_dict, per_time_bin_flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=IdentifyingContext(trained_compute_epochs='laps', decoder_identifier='pseudo2D', known_named_decoding_epochs_type=['pbe', 'laps'], data_grain= 'per_time_bin'))        \n",
    "per_time_bin_keys = list(per_time_bin_flat_decoded_marginal_posterior_df_context_dict.keys())\n",
    "\n",
    "## get all non-global, `data_grain= 'per_time_bin'`\n",
    "per_epoch_flat_context_list, per_epoch_flat_result_context_dict, per_epoch_flat_decoder_context_dict, per_epoch_flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=IdentifyingContext(trained_compute_epochs='laps', decoder_identifier='pseudo2D', known_named_decoding_epochs_type=['pbe', 'laps'], data_grain= 'per_epoch'))        \n",
    "per_epoch_keys = list(per_epoch_flat_decoded_marginal_posterior_df_context_dict.keys())\n",
    "len(per_time_bin_keys) == len(per_epoch_keys)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5a33a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## INPUTS: flat_decoded_marginal_posterior_df_context_dict\n",
    "per_time_bin_to_per_epoch_context_map_dict = {}\n",
    "flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict = {}\n",
    "flat_decoded_marginal_posterior_df_per_epoch_marginals_df_context_dict = {}\n",
    "for a_per_time_bin_ctxt, a_decoded_time_bin_marginal_posterior_df in flat_decoded_marginal_posterior_df_context_dict.items():\n",
    "    a_decoded_per_epoch_marginals_df, a_decoded_time_bin_marginal_posterior_df = GenericDecoderDictDecodedEpochsDictResult._perform_per_epoch_time_bin_aggregation(a_decoded_time_bin_marginal_posterior_df=a_decoded_time_bin_marginal_posterior_df, probabilitY_column_to_aggregate='P_Short', n_rolling_avg_window_tbins=3)\n",
    "    a_per_epoch_ctxt = TimeBinAggregation.ToPerEpoch.get_per_epoch_ctxt_from_per_time_bin_ctxt(a_per_time_bin_ctxt=a_per_time_bin_ctxt)\n",
    "    per_time_bin_to_per_epoch_context_map_dict[a_per_time_bin_ctxt] = a_per_epoch_ctxt\n",
    "    flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict[a_per_time_bin_ctxt] = deepcopy(a_decoded_time_bin_marginal_posterior_df)\n",
    "    flat_decoded_marginal_posterior_df_per_epoch_marginals_df_context_dict[a_per_epoch_ctxt] = a_decoded_per_epoch_marginals_df\n",
    "\n",
    "\n",
    "## OUTPUTS: per_time_bin_to_per_epoch_context_map_dict, flat_decoded_marginal_posterior_df_per_epoch_marginals_df_context_dict, flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict\n",
    "flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict\n",
    "flat_decoded_marginal_posterior_df_per_epoch_marginals_df_context_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f9ca7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: per_time_bin_to_per_epoch_context_map_dict, flat_decoded_marginal_posterior_df_per_epoch_marginals_df_context_dict, flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict\n",
    "# flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict\n",
    "# flat_decoded_marginal_posterior_df_per_epoch_marginals_df_context_dict\n",
    "\n",
    "for a_per_time_bin_ctxt, a_decoded_time_bin_marginal_posterior_df in flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict.items():\n",
    "    a_per_epoch_ctxt = per_time_bin_to_per_epoch_context_map_dict[a_per_time_bin_ctxt]\n",
    "    a_decoded_time_bin_marginal_posterior_df = flat_decoded_marginal_posterior_df_per_time_bin_marginals_df_context_dict[a_per_time_bin_ctxt]\n",
    "    a_decoded_per_epoch_marginals_df = flat_decoded_marginal_posterior_df_per_epoch_marginals_df_context_dict[a_per_epoch_ctxt]\n",
    "    a_new_fully_generic_result.filter_epochs_decoded_track_marginal_posterior_df_dict[a_per_time_bin_ctxt] = a_decoded_time_bin_marginal_posterior_df\n",
    "    a_best_matching_context, a_result, a_decoder, a_decoded_time_bin_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(a_per_time_bin_ctxt)\n",
    "    # a_best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_matching_context(a_per_time_bin_ctxt, return_multiple_matches=False)\n",
    "    # a_result\n",
    "    print(f'updating: \"{a_per_epoch_ctxt}\"')\n",
    "    print(f\"\\tWARN: TODO 2025-04-07 19:22: - [ ] a_result is wrong, it's the per-time-bin version not the per-epoch version\") #TODO 2025-04-07 19:22: - [ ] a_result is wrong, it's the per-time-bin version not the per-epoch version\n",
    "\n",
    "    ## need to get updated a_decoder, a_result\n",
    "    \n",
    "    # a_dropping_masked_pseudo2D_continuous_specific_decoded_result, _dropping_mask_index_tuple = a_result.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(spikes_df=deepcopy(spikes_df), masked_bin_fill_mode=a_masked_bin_fill_mode) ## Masks the low-firing bins so they don't confound the analysis.\n",
    "    # ## Computes marginals for `dropping_masked_laps_pseudo2D_continuous_specific_decoded_result`\n",
    "    # a_dropping_masked_decoded_marginal_posterior_df = DirectionalPseudo2DDecodersResult.perform_compute_specific_marginals(a_result=a_dropping_masked_pseudo2D_continuous_specific_decoded_result, marginal_context=a_masked_updated_context)\n",
    "    a_new_fully_generic_result.updating_results_for_context(new_context=a_per_epoch_ctxt, a_result=deepcopy(a_result), a_decoder=deepcopy(a_decoder), a_decoded_marginal_posterior_df=deepcopy(a_decoded_per_epoch_marginals_df)) ## update using the result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd3ce45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a_new_fully_generic_result.updating_results_for_context(new_context=a_masked_updated_context, a_result=deepcopy(a_dropping_masked_pseudo2D_continuous_specific_decoded_result), a_decoder=deepcopy(a_decoder), a_decoded_marginal_posterior_df=deepcopy(a_dropping_masked_decoded_marginal_posterior_df)) ## update using the result\n",
    "\n",
    "\n",
    "## INPUTS: a_new_fully_generic_result\n",
    "base_contexts_list = [IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=time_bin_size, known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='ignore', data_grain='per_time_bin'),\n",
    "                    IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=time_bin_size, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore', data_grain='per_time_bin'),\n",
    "                    IdentifyingContext(trained_compute_epochs='non_pbe', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=time_bin_size, known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='ignore', data_grain='per_time_bin'),\n",
    "                    IdentifyingContext(trained_compute_epochs='non_pbe', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=time_bin_size, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore', data_grain='per_time_bin')]\n",
    "masked_contexts_dict = {}\n",
    "\n",
    "for a_base_context in base_contexts_list:\n",
    "\n",
    "    a_best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_matching_contexts(a_base_context, return_multiple_matches=False)\n",
    "    ## `a_decoder` is None for some reason?`\n",
    "    ## INPUTS: a_result, masked_bin_fill_mode\n",
    "    a_masked_updated_context: IdentifyingContext = deepcopy(a_best_matching_context).overwriting_context(masked_time_bin_fill_type=a_masked_bin_fill_mode, data_grain='per_time_bin')\n",
    "    masked_contexts_dict[a_base_context] = a_masked_updated_context\n",
    "    if debug_print:\n",
    "        print(f'a_masked_updated_context: {a_masked_updated_context}')\n",
    "    \n",
    "    ## MASKED with NaNs (no backfill):\n",
    "    a_dropping_masked_pseudo2D_continuous_specific_decoded_result, _dropping_mask_index_tuple = a_result.mask_computed_DecodedFilterEpochsResult_by_required_spike_counts_per_time_bin(spikes_df=deepcopy(spikes_df), masked_bin_fill_mode=a_masked_bin_fill_mode) ## Masks the low-firing bins so they don't confound the analysis.\n",
    "    ## Computes marginals for `dropping_masked_laps_pseudo2D_continuous_specific_decoded_result`\n",
    "    a_dropping_masked_decoded_marginal_posterior_df = DirectionalPseudo2DDecodersResult.perform_compute_specific_marginals(a_result=a_dropping_masked_pseudo2D_continuous_specific_decoded_result, marginal_context=a_masked_updated_context)\n",
    "    a_new_fully_generic_result.updating_results_for_context(new_context=a_masked_updated_context, a_result=deepcopy(a_dropping_masked_pseudo2D_continuous_specific_decoded_result), a_decoder=deepcopy(a_decoder), a_decoded_marginal_posterior_df=deepcopy(a_dropping_masked_decoded_marginal_posterior_df)) ## update using the result\n",
    "    \n",
    "## OUTPUTS: masked_contexts_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4273d42a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c76f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import build_single_plotly_marginal_scatter_and_hist_over_time\n",
    "\n",
    "## INPUTS: a_decoded_time_bin_marginal_posterior_df\n",
    "#INPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder\n",
    "_flat_out_figs_dict = {}\n",
    "# a_target_context = curr_active_pipeline.build_display_context_for_filtered_session(filtered_session_name='maze_any', display_fn_name='DirectionalMergedDecoders')\n",
    "a_target_context = curr_active_pipeline.build_display_context_for_session(display_fn_name='a_decoded_time_bin_marginal_posterior_df', time_bin_size=0.025)\n",
    "a_fig, a_figure_context = build_single_plotly_marginal_scatter_and_hist_over_time(a_decoded_posterior_df=a_decoded_time_bin_marginal_posterior_df, a_target_context=a_target_context, y='P_Short')\n",
    "_flat_out_figs_dict[a_figure_context] = a_fig\n",
    "\n",
    "a_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d75da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.plotly.Extensions.plotly_helpers import build_single_plotly_marginal_scatter_and_hist_over_time\n",
    "\n",
    "## INPUTS: a_decoded_per_epoch_marginals_df\n",
    "#INPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder\n",
    "y_var_name: str = 'rolling_avg_P_Short'\n",
    "_flat_out_figs_dict = {}\n",
    "# a_target_context = curr_active_pipeline.build_display_context_for_filtered_session(filtered_session_name='maze_any', display_fn_name='DirectionalMergedDecoders')\n",
    "a_target_context = curr_active_pipeline.build_display_context_for_session(display_fn_name='a_decoded_per_epoch_marginals_df', time_bin_size=0.025)\n",
    "a_fig, a_figure_context = build_single_plotly_marginal_scatter_and_hist_over_time(a_decoded_posterior_df=a_decoded_per_epoch_marginals_df, a_target_context=a_target_context, y=y_var_name)\n",
    "_flat_out_figs_dict[a_figure_context] = a_fig\n",
    "\n",
    "a_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ce3de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUTS: a_target_context: IdentifyingContext, a_result: DecodedFilterEpochsResult, a_decoded_marginal_posterior_df: pd.DataFrame, a_decoder: BasePositionDecoder\n",
    "_flat_out_figs_dict = {}\n",
    "# a_target_context = curr_active_pipeline.build_display_context_for_filtered_session(filtered_session_name='maze_any', display_fn_name='DirectionalMergedDecoders')\n",
    "a_target_context = curr_active_pipeline.build_display_context_for_session(display_fn_name='laps_per_epoch_marginals_df', time_bin_size=0.025)\n",
    "a_fig, a_figure_context = build_single_plotly_marginal_scatter_and_hist_over_time(a_decoded_posterior_df=laps_per_epoch_marginals_df, a_target_context=a_target_context)\n",
    "_flat_out_figs_dict[a_figure_context] = a_fig\n",
    "\n",
    "a_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a467e0bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca9e4656",
   "metadata": {},
   "source": [
    "# 2025-04-11 - Full-session decoded marginal outputs as yellow-blue plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421fcd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _plot_all_time_decoded_marginal_figures\n",
    "\n",
    "\n",
    "## INPUTS: a_new_fully_generic_result\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='nan_filled', data_grain='per_time_bin')\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='ignore', data_grain='per_time_bin')\n",
    "best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=a_target_context, debug_print=False)\n",
    "epochs_decoding_time_bin_size = best_matching_context.get('time_bin_size', None)\n",
    "assert epochs_decoding_time_bin_size is not None\n",
    "\n",
    "## INPUTS: spike_raster_window, active_2d_plot\n",
    "_all_tracks_active_out_figure_paths, _all_tracks_out_artists, _all_tracks_out_axes = _plot_all_time_decoded_marginal_figures(curr_active_pipeline=curr_active_pipeline, best_matching_context=best_matching_context, a_decoded_marginal_posterior_df=a_decoded_marginal_posterior_df, spike_raster_window=spike_raster_window, active_2d_plot=active_2d_plot, epochs_decoding_time_bin_size=epochs_decoding_time_bin_size)\n",
    "_all_tracks_active_out_figure_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d24974",
   "metadata": {},
   "source": [
    "# 🔶 2025-01-15 - Lap Transition Matrix Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10b1c34e",
   "metadata": {
    "tags": [
     "run-group-transition-matricies"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions failed: Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv_UV\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 274, in check\n",
      "    superreload(m, reload, self.old_objects, self.shell)\n",
      "  File \"c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv_UV\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv_UV\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv_UV\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 365, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"c:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\.venv_UV\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 323, in update_instances\n",
      "    object.__setattr__(ref, \"__class__\", new)\n",
      "TypeError: can't apply this __setattr__ to ComputationFunctionRegistryHolder object\n",
      "]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for global computations: Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['directional_decoders_decode_continuous'], ...)...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function DirectionalPlacefieldGlobalComputationFunctions._decode_continuous_using_directional_decoders at 0x000001F0632CD9D0>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function DirectionalPlacefieldGlobalComputationFunctions._decode_continuous_using_directional_decoders at 0x000001F0632D30D0>\n",
      "\thad_existing_DirectionalDecodersDecoded_result == True. Using existing result and updating.\n",
      "\ttime_bin_size: 0.025\n",
      "(time_bin_size == 0.025) already found in cache. Not recomputing.\n",
      "\t all computations complete! (Computed 1 with no errors!.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0.025: DecodedFilterEpochsResult(decoding_time_bin_size: float,\n",
       " \tfilter_epochs: neuropy.core.epoch.Epoch,\n",
       " \tnum_filter_epochs: int,\n",
       " \tmost_likely_positions_list: list | shape (n_epochs),\n",
       " \tp_x_given_n_list: list | shape (n_epochs),\n",
       " \tmarginal_x_list: list | shape (n_epochs),\n",
       " \tmarginal_y_list: list | shape (n_epochs),\n",
       " \tmost_likely_position_indicies_list: list | shape (n_epochs),\n",
       " \tspkcount: list | shape (n_epochs),\n",
       " \tnbins: numpy.ndarray | shape (n_epochs),\n",
       " \ttime_bin_containers: list | shape (n_epochs),\n",
       " \ttime_bin_edges: list | shape (n_epochs),\n",
       " \tepoch_description_list: list | shape (n_epochs),\n",
       " \tpos_bin_edges: numpy.ndarray | shape (n_pos_bins+1)\n",
       " ),\n",
       " 0.05: DecodedFilterEpochsResult(decoding_time_bin_size: float,\n",
       " \tfilter_epochs: neuropy.core.epoch.Epoch,\n",
       " \tnum_filter_epochs: int,\n",
       " \tmost_likely_positions_list: list | shape (n_epochs),\n",
       " \tp_x_given_n_list: list | shape (n_epochs),\n",
       " \tmarginal_x_list: list | shape (n_epochs),\n",
       " \tmarginal_y_list: list | shape (n_epochs),\n",
       " \tmost_likely_position_indicies_list: list | shape (n_epochs),\n",
       " \tspkcount: list | shape (n_epochs),\n",
       " \tnbins: numpy.ndarray | shape (n_epochs),\n",
       " \ttime_bin_containers: list | shape (n_epochs),\n",
       " \ttime_bin_edges: list | shape (n_epochs),\n",
       " \tepoch_description_list: list | shape (n_epochs),\n",
       " \tpos_bin_edges: numpy.ndarray | shape (n_pos_bins+1)\n",
       " )}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import TransitionMatrixComputations\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalDecodersContinuouslyDecodedResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import plot_blocked_transition_matrix\n",
    "from neuropy.utils.matplotlib_helpers import perform_update_title_subtitle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import _perform_plot_P_Context_State_Transition_Matrix, _perform_plot_position_Transition_Matrix\n",
    "\n",
    "# desired_time_bin_size = 0.050 # 50ms\n",
    "desired_time_bin_size = 0.025 # 25ms\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'], computation_kwargs_list=[{'time_bin_size': desired_time_bin_size, 'should_disable_cache': False}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n",
    "\n",
    "\n",
    "## Uses the `global_computation_results.computed_data['DirectionalDecodersDecoded']`\n",
    "directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "# all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "pseudo2D_decoder: BasePositionDecoder = directional_decoders_decode_result.pseudo2D_decoder\n",
    "\n",
    "# all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "continuously_decoded_pseudo2D_decoder_dict = directional_decoders_decode_result.continuously_decoded_pseudo2D_decoder_dict\n",
    "# continuously_decoded_result_cache_dict\n",
    "continuously_decoded_pseudo2D_decoder_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab688a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import EpochComputationFunctions, EpochComputationsComputationsContainer\n",
    "from neuropy.utils.mixins.binning_helpers import BinningContainer, BinningInfo\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import complete_all_transition_matricies, build_transition_matricies\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import split_transition_matricies_results_pre_post_delta_category\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import LongShortTrackDataframeAccessor\n",
    "\n",
    "valid_EpochComputations_result: EpochComputationsComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['EpochComputations']\n",
    "a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult = valid_EpochComputations_result.a_generic_decoder_dict_decoded_epochs_dict_result\n",
    "\n",
    "\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.050, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore') # , decoder_identifier='long_LR'\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore', data_grain='per_epoch') # , time_bin_size=0.050, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore', decoder_identifier='long_LR'\n",
    "\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='ignore', data_grain='per_epoch') ## Laps\n",
    "# any_matching_contexts_list, result_context_dict, decoder_context_dict, decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context)\n",
    "\n",
    "# common_constraint_dict = dict(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, masked_time_bin_fill_type='ignore')\n",
    "common_constraint_dict = dict(trained_compute_epochs='laps', time_bin_size=0.025, masked_time_bin_fill_type='nan_filled') # , pfND_ndim=1\n",
    "\n",
    "## Laps context:\n",
    "a_laps_target_context: IdentifyingContext = IdentifyingContext(known_named_decoding_epochs_type='laps', **common_constraint_dict, data_grain='per_epoch') ## Laps\n",
    "laps_target_context_results = complete_all_transition_matricies(a_new_fully_generic_result=a_new_fully_generic_result, a_target_context=a_laps_target_context)\n",
    "laps_matched_result_tuple_context_dict, (laps_time_bin_container_context_dict, laps_position_transition_matrix_context_dict, laps_context_state_transition_matrix_context_dict, laps_combined_transition_matrix_context_dict), (laps_mean_context_state_transition_matrix_context_dict, laps_mean_position_transition_matrix_context_dict) = laps_target_context_results\n",
    "# a_best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = out_matched_result_tuple_context_dict[a_ctxt]\n",
    "a_laps_best_matching_context, a_laps_result, a_laps_decoder, a_laps_decoded_marginal_posterior_df = list(laps_matched_result_tuple_context_dict.values())[0] # [-1]\n",
    "\n",
    "## PBEs context:\n",
    "a_PBEs_target_context: IdentifyingContext = IdentifyingContext(known_named_decoding_epochs_type='pbe', **common_constraint_dict, data_grain='per_epoch') ## Laps\n",
    "pbes_target_context_results = complete_all_transition_matricies(a_new_fully_generic_result=a_new_fully_generic_result, a_target_context=a_PBEs_target_context)\n",
    "pbes_matched_result_tuple_context_dict, (pbes_time_bin_container_context_dict, pbes_position_transition_matrix_context_dict, pbes_context_state_transition_matrix_context_dict, pbes_combined_transition_matrix_context_dict), (pbes_mean_context_state_transition_matrix_context_dict, pbes_mean_position_transition_matrix_context_dict) = pbes_target_context_results\n",
    "a_pbes_best_matching_context, a_pbes_result, a_pbes_decoder, a_pbes_decoded_marginal_posterior_df = list(pbes_matched_result_tuple_context_dict.values())[0] # [-1] # pbes_matched_result_tuple_context_dict[a_PBEs_target_context]\n",
    "## INPUTS: laps_context_state_transition_matrix_context_dict\n",
    "out_context_state_transition_matrix_context_dict = deepcopy(laps_context_state_transition_matrix_context_dict)\n",
    "out_matched_result_tuple_context_dict = deepcopy(laps_matched_result_tuple_context_dict)\n",
    "\n",
    "an_out_best_matching_context, an_out_result, an_out_decoder, an_out_decoded_marginal_posterior_df = list(out_matched_result_tuple_context_dict.values())[0] # [-1]\n",
    "a_context_state_transition_matrix_list: List[NDArray] = list(out_context_state_transition_matrix_context_dict.values())[0]\n",
    "\n",
    "## INPUTS: an_out_decoded_marginal_posterior_df, a_context_state_transition_matrix_list\n",
    "a_mean_context_state_transition_matrix_dict = split_transition_matricies_results_pre_post_delta_category(an_out_decoded_marginal_posterior_df=an_out_decoded_marginal_posterior_df, a_context_state_transition_matrix_list=a_context_state_transition_matrix_list)\n",
    "a_mean_context_state_transition_matrix_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66cab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_laps_decoder: BasePositionDecoder = deepcopy(a_laps_decoder)\n",
    "a_laps_decoder.pf.plot_occupancy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4337b537",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.plotting.placemaps import plot_placefield_occupancy, perform_plot_occupancy\n",
    "\n",
    "valid_EpochComputations_result: EpochComputationsComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['EpochComputations']\n",
    "a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult = valid_EpochComputations_result.a_generic_decoder_dict_decoded_epochs_dict_result\n",
    "\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.050, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore') # , decoder_identifier='long_LR'\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore', data_grain='per_epoch') # , time_bin_size=0.050, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore', decoder_identifier='long_LR'\n",
    "\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='ignore', data_grain='per_epoch') ## Laps\n",
    "# any_matching_contexts_list, result_context_dict, decoder_context_dict, decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context)\n",
    "\n",
    "# common_constraint_dict = dict(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, masked_time_bin_fill_type='ignore')\n",
    "common_constraint_dict = dict(trained_compute_epochs='laps', time_bin_size=0.025, masked_time_bin_fill_type='nan_filled') # , pfND_ndim=1\n",
    "\n",
    "## Laps context:\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(known_named_decoding_epochs_type='laps', data_grain='per_time_bin', **common_constraint_dict) ## Laps , data_grain='per_epoch'\n",
    "best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=a_target_context)\n",
    "\n",
    "# ## Global context:\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(known_named_decoding_epochs_type='global', data_grain='per_time_bin', **common_constraint_dict) ## Laps , data_grain='per_epoch'\n",
    "best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=a_target_context)\n",
    "\n",
    "\n",
    "\n",
    "# # a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=0.025, masked_time_bin_fill_type='last_valid', data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps'\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', time_bin_size=0.025, masked_time_bin_fill_type='ignore', data_grain='per_time_bin', known_named_decoding_epochs_type= 'global') # , known_named_decoding_epochs_type='laps'\n",
    "# flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True, debug_print=True)\n",
    "# # print(f'flat_context_list: {flat_context_list}')\n",
    "# flat_decoded_marginal_posterior_df_context_dict\n",
    "\n",
    "\n",
    "# best_matching_context\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d0e184",
   "metadata": {},
   "source": [
    "## 2025-05-15 - Decoded vs Measured Occupancy\n",
    "- [ ] wrap in normal matplotlib-specific decoration/output code to add session_name footer, enable saving to file, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3bf977",
   "metadata": {
    "tags": [
     "2025-05-15_decoded_vs_measured_occupancy"
    ]
   },
   "outputs": [],
   "source": [
    "# MeasuredVsDecodedOccupancy._display_measured_vs_decoded_occupancy_distributions(owning_pipeline_reference=curr_active_pipeline, \n",
    "\n",
    "# _display_measured_vs_decoded_occupancy_distributions\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n",
    "\n",
    "_out = curr_active_pipeline.display('_display_measured_vs_decoded_occupancy_distributions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75adb632",
   "metadata": {},
   "source": [
    "## ⚓🎯 2025-05-15 - Within-epoch transition and run-length sequence analyis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00371dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import WithinEpochTimeBinDynamics, TimeBinCategorization\n",
    "\n",
    "\n",
    "sequence_dwell_epochs_df = WithinEpochTimeBinDynamics.analyze_subsequence_temporal_dynamics(curr_active_pipeline, time_bin_size=0.025)\n",
    "# sequence_dwell_epochs_df = WithinEpochTimeBinDynamics.analyze_subsequence_temporal_dynamics(curr_active_pipeline, time_bin_size=0.050)\n",
    "# int_column_names = [k for k in sequence_dwell_epochs_df.columns if k.startswith('n_')]\n",
    "\n",
    "# sequence_dwell_epochs_df.infer_objects()\n",
    "sequence_dwell_epochs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ba557a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(sequence_dwell_epochs_df.columns)) # ['epoch_start_t', 'epoch_end_t', 'epoch_label', 'pre_post_delta_category', 'pre_post_delta_id', 'delta_aligned_start_t', 'n_t_bins', 'n_transitions', 'mean_len.pLONG', 'mean_len.pSHORT', 'mean_len.MIXED', 'var_len.pLONG', 'var_len.pSHORT', 'var_len.MIXED', 'n_bins.pLONG', 'n_bins.pSHORT', 'n_bins.MIXED', 'lengths', 'bins_ratio.pLONG', 'bins_ratio.pSHORT', 'bins_ratio.MIXED']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0d796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_post_split_sequence_dwell_epochs_df_dict = sequence_dwell_epochs_df.pho.partition_df_dict('pre_post_delta_category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232c86a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_post_split_sequence_dwell_epochs_df_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1307d2d3",
   "metadata": {},
   "source": [
    "I have a df `sequence_dwell_epochs_df` with many numeric columns that I want to compare histograms for, based on their category in column 'pre_post_delta_category' (with a histogram plotted for each value in this column, for each variable)\n",
    "\n",
    "numeric_col_of_interest_names = ['n_t_bins', 'n_transitions', 'mean_len.pLONG', 'mean_len.pSHORT', 'mean_len.MIXED', 'var_len.pLONG', 'var_len.pSHORT', 'var_len.MIXED', 'n_bins.pLONG', 'n_bins.pSHORT', 'n_bins.MIXED', 'bins_ratio.pLONG', 'bins_ratio.pSHORT', 'bins_ratio.MIXED']\n",
    "\n",
    "write valid python code to plot a stack of these histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9695fc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "numeric_col_of_interest_names = ['n_t_bins', 'n_transitions', 'mean_len.pLONG', 'mean_len.pSHORT', 'mean_len.MIXED', 'var_len.pLONG', 'var_len.pSHORT', 'var_len.MIXED', 'n_bins.pLONG', 'n_bins.pSHORT', 'n_bins.MIXED', 'bins_ratio.pLONG', 'bins_ratio.pSHORT', 'bins_ratio.MIXED']\n",
    "\n",
    "cols=numeric_col_of_interest_names\n",
    "cats=sequence_dwell_epochs_df['pre_post_delta_category'].dropna().unique()\n",
    "fig, axes=plt.subplots(len(cols),1,figsize=(8,2*len(cols)), num='temporal_decoding_dynamics_within_bins', clear=True)\n",
    "\n",
    "for ax, col in zip(axes,cols):\n",
    "    for cat in cats:\n",
    "        ax.hist(sequence_dwell_epochs_df.loc[sequence_dwell_epochs_df['pre_post_delta_category']==cat,col].dropna(), \n",
    "                alpha=0.5,label=cat, bins=25)\n",
    "    ax.set_title(col)\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3573ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# render_scrollable_colored_table_from_dataframe(sequence_dwell_epochs_df, cmap_name='plasma', max_height=500, width='80%') # , cmap_name=cmap_name, max_height=max_height, width=width, **kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2c6523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch_split_df_dict    \n",
    "\n",
    "results\n",
    "\n",
    "# epoch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7c3549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "from scipy.stats import mannwhitneyu, poisson, fisher_exact\n",
    "\n",
    "def compare_epoch_dynamics(cond1: List[Dict], cond2: List[Dict]) -> Dict:\n",
    "    \"\"\"\n",
    "    Given two lists of analyze_epoch_dynamics outputs (one per condition),\n",
    "    computes:\n",
    "      - mean±sem of n_transitions\n",
    "      - Mann–Whitney U test on n_transitions\n",
    "      - pooled dwell times per state and MWU test per state\n",
    "    Returns dict with stats.\n",
    "    \"\"\"\n",
    "    def sem(x): return np.std(x, ddof=1)/np.sqrt(len(x))\n",
    "    \n",
    "    # extract transitions\n",
    "    t1 = np.array([e['transitions'] for e in cond1])\n",
    "    t2 = np.array([e['transitions'] for e in cond2])\n",
    "    \n",
    "    # extract dwell times per state\n",
    "    def gather(cond, state):\n",
    "        return np.concatenate([e['subsequences'][state] for e in cond]) or np.array([])\n",
    "    stats = {'transitions': {\n",
    "                 'cond1_mean_sem': (t1.mean(), sem(t1)),\n",
    "                 'cond2_mean_sem': (t2.mean(), sem(t2)),\n",
    "                 'mw_u': mannwhitneyu(t1, t2, alternative='two-sided').statistic,\n",
    "                 'mw_p': mannwhitneyu(t1, t2, alternative='two-sided').pvalue\n",
    "             }}\n",
    "    \n",
    "    for state in ['pure.Long','pure.Short','mixed']:\n",
    "        d1 = gather(cond1, state)\n",
    "        d2 = gather(cond2, state)\n",
    "        u, p = mannwhitneyu(d1, d2, alternative='two-sided')\n",
    "        stats[state] = {\n",
    "            'cond1_n': len(d1), 'cond2_n': len(d2),\n",
    "            'cond1_mean_sem': (d1.mean() if d1.size else np.nan, sem(d1) if d1.size>1 else np.nan),\n",
    "            'cond2_mean_sem': (d2.mean() if d2.size else np.nan, sem(d2) if d2.size>1 else np.nan),\n",
    "            'mw_u': u, 'mw_p': p\n",
    "        }\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80999256",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_result['parent_epoch_label']\n",
    "\n",
    "a_decoded_marginal_posterior_df\n",
    "P_Long_df = a_decoded_marginal_posterior_df[['start', 'stop', 'P_Long']]\n",
    "P_Long_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46a5fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = analyze_epoch_dynamics(p_long=p_long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44323891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0bfebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b85914ba",
   "metadata": {},
   "source": [
    "## -[ ] Lap Transition Matrix vs. PBEs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09796af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_time_bin_container.centers\n",
    "a_time_bin_container.left_edges\n",
    "a_time_bin_container.right_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7458e721",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_context_state_transition_matrix: NDArray = np.stack(out_context_state_transition_matrix_context_dict[a_ctxt]) # np.stack(out_context_state_transition_matrix_context_dict[a_ctxt]).shape\n",
    "a_mean_context_state_transition_matrix: NDArray = np.nanmean(a_context_state_transition_matrix, axis=0) #.shape (4, 4)\n",
    "a_mean_context_state_transition_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312814dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs_decoding_time_bin_size: float = 0.025\n",
    "epochs_decoding_time_bin_size: float = 0.025\n",
    "\n",
    "_all_tracks_out_artists = {}\n",
    "for a_ctxt, a_df in flat_decoded_marginal_posterior_df_context_dict.items():\n",
    "    time_bin_size = epochs_decoding_time_bin_size\n",
    "    info_string: str = f\" - t_bin_size: {time_bin_size}\"\n",
    "    plot_row_identifier: str = a_ctxt.get_description(subset_includelist=['known_named_decoding_epochs_type', 'masked_time_bin_fill_type'], include_property_names=True, key_value_separator=':', separator='|', replace_separator_in_property_names='-')\n",
    "    a_time_window_centers = a_df['t_bin_center'].to_numpy() \n",
    "    a_1D_posterior = a_df[['P_Long', 'P_Short']].to_numpy().T\n",
    "\n",
    "    identifier_name, widget, matplotlib_fig, matplotlib_fig_axes, dock_item = active_2d_plot.add_docked_marginal_track(name=plot_row_identifier, time_window_centers=a_time_window_centers, a_1D_posterior=a_1D_posterior, extended_dock_title_info=info_string)\n",
    "    _all_tracks_out_artists[identifier_name] = widget\n",
    "    intervals_overview_plot_item.setXRange(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time, padding=0) ## global frame\n",
    "    matplotlib_fig_axes[0].set_xlim(active_2d_plot.total_data_start_time, active_2d_plot.total_data_end_time)\n",
    "    widget.draw()\n",
    "\n",
    "\n",
    "## Make a new matplotlib figure (in a new window) that contains a copy of `matplotlib_fig_axes` inserted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58d8df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _perform_compute_transition_matrix(continuously_decoded_pseudo2D_decoder_dict):\n",
    "    \"\"\" Computes the context state transition matrix from the continuous posteriors\n",
    "    \n",
    "    Usage:\n",
    "    \n",
    "    ## Uses the `global_computation_results.computed_data['DirectionalDecodersDecoded']`\n",
    "    directional_decoders_decode_result: DirectionalDecodersContinuouslyDecodedResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersDecoded']\n",
    "    # all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "    pseudo2D_decoder: BasePositionDecoder = directional_decoders_decode_result.pseudo2D_decoder\n",
    "\n",
    "    # all_directional_pf1D_Decoder_dict: Dict[str, BasePositionDecoder] = directional_decoders_decode_result.pf1D_Decoder_dict\n",
    "    continuously_decoded_result_cache_dict = directional_decoders_decode_result.continuously_decoded_result_cache_dict\n",
    "    continuously_decoded_pseudo2D_decoder_dict = directional_decoders_decode_result.continuously_decoded_pseudo2D_decoder_dict\n",
    "    # continuously_decoded_result_cache_dict\n",
    "    continuously_decoded_pseudo2D_decoder_dict\n",
    "\n",
    "    output_transition_matrix_dict = _perform_compute_transition_matrix(continuously_decoded_pseudo2D_decoder_dict=continuously_decoded_pseudo2D_decoder_dict)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    output_transition_matrix_dict = {}\n",
    "    \n",
    "    for a_time_bin_size, a_pseudo2D_decoder_continuously_decoded_result in continuously_decoded_pseudo2D_decoder_dict.items():\n",
    "        print(f'a_time_bin_size: {a_time_bin_size}')\n",
    "        # a_pseudo2D_decoder_continuously_decoded_result.active_filter_epochs\n",
    "        assert len(a_pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list) == 1\n",
    "        a_p_x_given_n = deepcopy(a_pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0])\n",
    "        ## OUTPUTS: a_p_x_given_n\n",
    "        \n",
    "        ## INPUTS: a_p_x_given_n\n",
    "        n_position_bins, n_decoding_models, n_time_bins = a_p_x_given_n.shape\n",
    "        \n",
    "        # 1. Determine the most likely model for each time bin\n",
    "        sum_over_positions = a_p_x_given_n.sum(axis=0)  # (n_decoding_models, n_time_bins)\n",
    "        best_model_each_bin = sum_over_positions.argmax(axis=0)  # (n_time_bins,)\n",
    "        print(f'best_model_each_bin.shape: {np.shape(best_model_each_bin)}')\n",
    "        # sum_over_positions.shape # (4, n_time_bins)\n",
    "        \n",
    "        sum_over_positions.shape\n",
    "        \n",
    "        # 2. Determine the most likely position for each time bin (conditional on chosen model)\n",
    "        best_position_each_bin = np.array([\n",
    "            p_x_given_n[:, best_model_each_bin[t], t].argmax()\n",
    "            for t in range(n_time_bins)\n",
    "        ])\n",
    "\n",
    "        print(f'best_position_each_bin: {np.shape(best_position_each_bin)}')\n",
    "        \n",
    "        # 2. Determine the most likely position for each time bin (conditional on chosen model)\n",
    "        a_model_p_x_given_n = np.array([\n",
    "            sum_over_positions[best_model_each_bin[t], t] / np.sum(sum_over_positions[:, t])\n",
    "            for t in range(n_time_bins)\n",
    "        ])\n",
    "\n",
    "\n",
    "        marginal_p_x_given_n_over_positions = deepcopy(sum_over_positions).T\n",
    "        print(f'marginal_p_x_given_n_over_positions: {np.shape(marginal_p_x_given_n_over_positions)}')\n",
    "        # marginal_p_x_given_n_over_positions = marginal_p_x_given_n_over_positions / np.nansum(marginal_p_x_given_n_over_positions, axis=-1, keepdims=True)\n",
    "        # marginal_p_x_given_n_over_positions\n",
    "        \n",
    "        # # Verify normalization (should be very close to 1.0 for all rows)\n",
    "        # verification = np.sum(marginal_p_x_given_n_over_positions, axis=-1)\n",
    "        # print(f\"Normalized sums: min={verification.min()}, max={verification.max()}\")\n",
    "\n",
    "\n",
    "        # Check for zeros or NaNs before normalization\n",
    "        sum_before_norm = np.nansum(marginal_p_x_given_n_over_positions, axis=-1, keepdims=True)\n",
    "        print(f\"Before normalization - min sum: {np.min(sum_before_norm)}, has NaNs: {np.isnan(sum_before_norm).any()}\")\n",
    "\n",
    "        # Safe normalization with handling for zeros\n",
    "        # Replace zeros with ones in the denominator to avoid division by zero\n",
    "        safe_sums = np.where(sum_before_norm == 0, 1.0, sum_before_norm)\n",
    "        marginal_p_x_given_n_over_positions = marginal_p_x_given_n_over_positions / safe_sums\n",
    "\n",
    "        # For rows that summed to zero, set all values to equal probabilities (e.g., 1/n)\n",
    "        zero_sum_rows = (sum_before_norm == 0).squeeze()\n",
    "        if np.any(zero_sum_rows):\n",
    "            n_models = marginal_p_x_given_n_over_positions.shape[-1]\n",
    "            equal_probs = np.ones(n_models) / n_models\n",
    "            # Apply equal probabilities to rows with zero sums\n",
    "            if zero_sum_rows.ndim > 0:  # If it's not a scalar\n",
    "                marginal_p_x_given_n_over_positions[zero_sum_rows] = equal_probs\n",
    "            else:\n",
    "                # Handle the case where there's only one row\n",
    "                marginal_p_x_given_n_over_positions[:] = equal_probs\n",
    "\n",
    "        # Verify normalization\n",
    "        verification = np.sum(marginal_p_x_given_n_over_positions, axis=-1)\n",
    "        print(f\"Normalized sums: min={verification.min()}, max={verification.max()}, has NaNs: {np.isnan(verification).any()}\")\n",
    "\n",
    "\n",
    "        ## OUTPUTS: marginal_p_x_given_n_over_positions (normalized)\n",
    "\n",
    "        # best_model_each_bin\n",
    "        # a_model_p_x_given_n = sum_over_positions[np.squeeze(best_model_each_bin), :]\n",
    "        # a_model_p_x_given_n.shape\n",
    "        # a_model_p_x_given_n\n",
    "        # transition_matrix: NDArray = TransitionMatrixComputations.estimate_transition_matrix_weighted_avg(state_probs=best_model_each_bin)\n",
    "        transition_matrix: NDArray = TransitionMatrixComputations.estimate_transition_matrix_weighted_avg(state_probs=marginal_p_x_given_n_over_positions)\n",
    "        \n",
    "        output_transition_matrix_dict[a_time_bin_size] = transition_matrix\n",
    "        # A_position, A_model, A_combined = TransitionMatrixComputations.build_position_by_decoder_transition_matrix(a_p_x_given_n)\n",
    "\n",
    "        # len(A_position)\n",
    "        # A_position[0].shape\n",
    "        # A_position[1].shape\n",
    "        # A_combined.shape\n",
    "        # A_model.shape\n",
    "        \n",
    "        ## Plotting:\n",
    "        # # plt.figure(figsize=(8,6)); sns.heatmap(A_big, cmap='viridis'); plt.title(\"Transition Matrix A_big\"); plt.show()\n",
    "        # plt.figure(figsize=(8,6)); sns.heatmap(A_position, cmap='viridis'); plt.title(\"Transition Matrix A_position\"); plt.show()\n",
    "        # plt.figure(figsize=(8,6)); sns.heatmap(A_model, cmap='viridis'); plt.title(\"Transition Matrix A_model\"); plt.show()\n",
    "\n",
    "        # plot_blocked_transition_matrix(A_combined, n_position_bins, n_decoding_models)\n",
    "\n",
    "    return output_transition_matrix_dict\n",
    "\n",
    "\n",
    "output_transition_matrix_dict = _perform_compute_transition_matrix(continuously_decoded_pseudo2D_decoder_dict=continuously_decoded_pseudo2D_decoder_dict)\n",
    "output_transition_matrix_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3740ad1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6)); sns.heatmap(output_transition_matrix_dict[0.05], cmap='viridis'); plt.title(\"Transition Matrix P_Context State\"); \n",
    "plt.xlabel('P[t+1]')\n",
    "plt.ylabel('P[t]')\n",
    "state_labels = ['Long_LR', 'Long_RL', 'Short_LR', 'Short_RL']\n",
    "plt.xticks(ticks=(np.arange(len(state_labels))+0.5), labels=state_labels)\n",
    "plt.yticks(ticks=(np.arange(len(state_labels))+0.5), labels=state_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b4ae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('P[t+1]')\n",
    "plt.ylabel('P[t]')\n",
    "\n",
    "state_labels = ['Long_LR', 'Long_RL', 'Short_LR', 'Short_RL']\n",
    "plt.xticks(ticks=(np.arange(len(state_labels))+0.5), labels=state_labels)\n",
    "plt.yticks(ticks=(np.arange(len(state_labels))+0.5), labels=state_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bd10f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "global_session = curr_active_pipeline.filtered_sessions[global_epoch_name]\n",
    "\n",
    "# global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps) # .trimmed_to_non_overlapping()\n",
    "global_laps_epochs_df = global_laps.to_dataframe()\n",
    "# active_test_epochs_df: pd.DataFrame = deepcopy(global_laps_epochs_df)\n",
    "global_laps_epochs_df\n",
    "debug_print = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fcdcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import find_epochs_overlapping_other_epochs\n",
    "\n",
    "## INPUTS: global_laps, continuously_decoded_pseudo2D_decoder_dict\n",
    "_out_split_pseudo2D_posteriors_dict = {}\n",
    "_out_split_pseudo2D_out_dict = {}\n",
    "pre_filtered_col_names = ['pre_filtered_most_likely_position_indicies', 'pre_filtered_most_likely_position'] # 'pre_filtered_time_bin_containers', 'pre_filtered_p_x_given_n', \n",
    "post_filtered_col_names = [a_col_name.removeprefix('pre_filtered_') for a_col_name in pre_filtered_col_names] # ['time_bin_containers', 'most_likely_position_indicies', 'most_likely_position']\n",
    "print(post_filtered_col_names)\n",
    "for a_time_bin_size, pseudo2D_decoder_continuously_decoded_result in continuously_decoded_pseudo2D_decoder_dict.items():\n",
    "    print(f'a_time_bin_size: {a_time_bin_size}')\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size] = {'pre_filtered_p_x_given_n': None, 'pre_filtered_time_bin_containers': None, 'pre_filtered_most_likely_position_indicies': None, 'pre_filtered_most_likely_position': None, \n",
    "                                                     'is_timebin_included': None, 'p_x_given_n': None} # , 'time_window_centers': None\n",
    "    # pseudo2D_decoder_continuously_decoded_result: DecodedFilterEpochsResult = continuously_decoded_dict.get('pseudo2D', None)\n",
    "    assert len(pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list) == 1\n",
    "    p_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0]\n",
    "    # p_x_given_n = pseudo2D_decoder_continuously_decoded_result.p_x_given_n_list[0]['p_x_given_n']\n",
    "    time_bin_containers = pseudo2D_decoder_continuously_decoded_result.time_bin_containers[0]\n",
    "    # time_window_centers = time_bin_containers.centers\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position_indicies'] = deepcopy(pseudo2D_decoder_continuously_decoded_result.most_likely_position_indicies_list[0])\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position'] = deepcopy(pseudo2D_decoder_continuously_decoded_result.most_likely_positions_list[0])\n",
    "    ## INPUTS: time_bin_containers, global_laps\n",
    "    left_edges = deepcopy(time_bin_containers.left_edges)\n",
    "    right_edges = deepcopy(time_bin_containers.right_edges)\n",
    "    continuous_time_binned_computation_epochs_df: pd.DataFrame = pd.DataFrame({'start': left_edges, 'stop': right_edges, 'label': np.arange(len(left_edges))})\n",
    "    is_timebin_included: NDArray = find_epochs_overlapping_other_epochs(epochs_df=continuous_time_binned_computation_epochs_df, epochs_df_required_to_overlap=deepcopy(global_laps))\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_p_x_given_n'] = p_x_given_n\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_time_bin_containers'] = time_bin_containers\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['is_timebin_included'] = is_timebin_included\n",
    "    continuous_time_binned_computation_epochs_df['is_in_laps'] = is_timebin_included\n",
    "    ## filter by whether it's included or not:\n",
    "    p_x_given_n = p_x_given_n[:, :, is_timebin_included]\n",
    "    # time_window_centers = \n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['p_x_given_n'] = p_x_given_n\n",
    "    # _out_split_pseudo2D_out_dict[a_time_bin_size]['time_window_centers'] = time_window_centers[is_timebin_included]\n",
    "    # p_x_given_n.shape # (62, 4, 209389)\n",
    "\n",
    "    ## Split across the 2nd axis to make 1D posteriors that can be displayed in separate dock rows:\n",
    "    assert p_x_given_n.shape[1] == 4, f\"expected the 4 pseudo-y bins for the decoder in p_x_given_n.shape[1]. but found p_x_given_n.shape: {p_x_given_n.shape}\"\n",
    "    # split_pseudo2D_posteriors_dict = {k:np.squeeze(p_x_given_n[:, i, :]) for i, k in enumerate(('long_LR', 'long_RL', 'short_LR', 'short_RL'))}\n",
    "    _out_split_pseudo2D_posteriors_dict[a_time_bin_size] = deepcopy(p_x_given_n)\n",
    "    \n",
    "    # for a_col_name in pre_filtered_col_names:\n",
    "    #     filtered_col_name = a_col_name.removeprefix('pre_filtered_')\n",
    "    #     print(f'a_col_name: {a_col_name}, filtered_col_name: {filtered_col_name}, shape: {np.shape(_out_split_pseudo2D_out_dict[a_time_bin_size][a_col_name])}')\n",
    "    #     _out_split_pseudo2D_out_dict[a_time_bin_size][filtered_col_name] = _out_split_pseudo2D_out_dict[a_time_bin_size][a_col_name][is_timebin_included, :]\n",
    "        \n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['most_likely_position_indicies'] = _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position_indicies'][:, is_timebin_included]\n",
    "    _out_split_pseudo2D_out_dict[a_time_bin_size]['most_likely_position'] = _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position'][is_timebin_included, :]\n",
    "    \n",
    "\n",
    "p_x_given_n.shape # (n_position_bins, n_decoding_models, n_time_bins) - (57, 4, 29951)\n",
    "\n",
    "## OUTPUTS: _out_split_pseudo2D_posteriors_dict, _out_split_pseudo2D_out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e652de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo2D_decoder_continuously_decoded_result.most_likely_position_indicies_list[0].shape # (2, 6948)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69a7e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_split_pseudo2D_out_dict_p_x_given_x = {k:v['pre_filtered_p_x_given_n'] for k, v in _out_split_pseudo2D_out_dict.items()}\n",
    "_out_split_pseudo2D_out_dict_p_x_given_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d83ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_time_binned_computation_epochs_df = continuous_time_binned_computation_epochs_df[continuous_time_binned_computation_epochs_df['is_in_laps']].drop(columns=['is_in_laps'])\n",
    "continuous_time_binned_computation_epochs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b84b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import build_position_by_decoder_transition_matrix, plot_blocked_transition_matrix\n",
    "from neuropy.utils.matplotlib_helpers import perform_update_title_subtitle\n",
    "\n",
    "## INPUTS: _out_split_pseudo2D_posteriors_dict\n",
    "# a_time_bin_size: float = 0.025\n",
    "a_time_bin_size: float = 0.050\n",
    "# a_time_bin_size: float = 0.058\n",
    "# a_time_bin_size: float = 0.250\n",
    "# a_time_bin_size: float = 0.500\n",
    "# a_time_bin_size: float = 0.750\n",
    "\n",
    "print(f'{list(_out_split_pseudo2D_posteriors_dict.keys())}')\n",
    "\n",
    "p_x_given_n = _out_split_pseudo2D_posteriors_dict[a_time_bin_size]\n",
    "is_timebin_included = _out_split_pseudo2D_out_dict[a_time_bin_size]['is_timebin_included']\n",
    "pre_filtered_p_x_given_n = _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_p_x_given_n']\n",
    "pre_filtered_time_bin_containers = _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_time_bin_containers']\n",
    "pre_filtered_most_likely_position_indicies = _out_split_pseudo2D_out_dict[a_time_bin_size]['pre_filtered_most_likely_position_indicies']\n",
    "most_likely_position_indicies = _out_split_pseudo2D_out_dict[a_time_bin_size]['most_likely_position_indicies']\n",
    "\n",
    "\n",
    "did_change = np.diff(is_timebin_included, n=1)\n",
    "split_indicies = np.where(did_change)[0] + 1 # the +1 compensates for the 0-based nature of the indicies, indicating we want to split BEFORE the specified index\n",
    "\n",
    "# lap_split_p_x_given_n_list = np.split(p_x_given_n, split_indicies, axis=-1) # split along the time-bin axis (-1)\n",
    "lap_split_p_x_given_n_list: List[NDArray] = np.split(pre_filtered_p_x_given_n, split_indicies, axis=-1) # split along the time-bin axis (-1)\n",
    "# lap_split_p_x_given_n_list\n",
    "\n",
    "pre_filtered_most_likely_position_indicies_x = np.squeeze(pre_filtered_most_likely_position_indicies[0, :])\n",
    "most_likely_position_indicies_x = np.squeeze(most_likely_position_indicies[0, :])\n",
    "# most_likely_position_indicies_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7fa3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6)); sns.histplot(pre_filtered_most_likely_position_indicies_x); perform_update_title_subtitle(title_string=f\"hist: pre_filtered_most_likely_position_indicies_x - t_bin: {a_time_bin_size}\"); plt.show();\n",
    "plt.figure(figsize=(8,6)); sns.histplot(most_likely_position_indicies_x); perform_update_title_subtitle(title_string=f\"hist: most_likely_position_indicies_x - t_bin: {a_time_bin_size}\"); plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3aa025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13514771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1441d2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: p_x_given_n\n",
    "n_position_bins, n_decoding_models, n_time_bins = p_x_given_n.shape\n",
    "\n",
    "out_tuples = [build_position_by_decoder_transition_matrix(a_p_x_given_n) for a_p_x_given_n in lap_split_p_x_given_n_list]\n",
    "\n",
    "A_position = [v[0] for i, v in enumerate(out_tuples) if (i % 2 == 1)]\n",
    "A_model = [v[1] for i, v in enumerate(out_tuples) if (i % 2 == 1)]\n",
    "A_big = [v[2] for i, v in enumerate(out_tuples) if (i % 2 == 1)]\n",
    "\n",
    "len(A_position)\n",
    "A_position[0].shape\n",
    "A_position[1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8802e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import TransitionMatrixComputations\n",
    "\n",
    "# Visualization ______________________________________________________________________________________________________ #\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow, LayoutScrollability\n",
    "\n",
    "binned_x_transition_matrix_higher_order_list_dict: Dict[types.DecoderName, NDArray] = track_templates.compute_decoder_transition_matricies(n_powers=3)\n",
    "out = TransitionMatrixComputations.plot_transition_matricies(decoders_dict=track_templates.get_decoders_dict(), binned_x_transition_matrix_higher_order_list_dict=binned_x_transition_matrix_higher_order_list_dict)\n",
    "# out\n",
    "\n",
    "\n",
    "# binned_x_transition_matrix_higher_order_list_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92be3631",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_position_overall = np.sum(np.stack(A_position), axis=0) #.shape # (81, 57, 57)\n",
    "# A_position_overall.shape\n",
    "plt.figure(figsize=(8,6)); sns.heatmap(A_position_overall, cmap='viridis'); perform_update_title_subtitle(title_string=f\"Transition Matrix A_position_overall - t_bin: {a_time_bin_size}\"); plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55148899",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(A_position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92508cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example data: linear array\n",
    "# data = [np.random.rand(10, 10) for _ in range(12)]  # 12 heatmaps of size 10x10\n",
    "data = A_position[:20]\n",
    "columns = 5  # Number of columns in the grid\n",
    "\n",
    "# Compute grid dimensions\n",
    "rows = -(-len(data) // columns)  # Ceiling division for number of rows\n",
    "print(f'rows: {rows}, columns: {columns}')\n",
    "\n",
    "# Plot the grid\n",
    "fig, axes = plt.subplots(rows, columns, figsize=(15, 3 * rows))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < len(data):\n",
    "        heatmap = data[i]\n",
    "        # im = ax.imshow(heatmap, cmap='viridis')\n",
    "        sns.heatmap(heatmap, cmap='viridis', ax=ax) ## position\n",
    "        ax.set_title(f\"Heatmap {i + 1}\")\n",
    "    else:\n",
    "        ax.axis('off')  # Turn off unused axes\n",
    "\n",
    "# fig.colorbar(im, ax=axes, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5830bd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\"D\" is E\"pic\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00295aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_position, A_model, A_big = build_position_by_decoder_transition_matrix(p_x_given_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447625fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# plt.figure(figsize=(8,6)); sns.heatmap(A_big, cmap='viridis'); plt.title(\"Transition Matrix A_big\"); plt.show()\n",
    "plt.figure(figsize=(8,6)); sns.heatmap(A_position, cmap='viridis'); perform_update_title_subtitle(title_string=f\"Transition Matrix A_position - t_bin: {a_time_bin_size}\"); plt.show(); \n",
    "plt.figure(figsize=(8,6)); sns.heatmap(A_model, cmap='viridis'); perform_update_title_subtitle(title_string=f\"Transition Matrix A_model - t_bin: {a_time_bin_size}\"); plt.show()\n",
    "\n",
    "_out = plot_blocked_transition_matrix(A_big, n_position_bins, n_decoding_models, extra_title_suffix=f' - t_bin: {a_time_bin_size}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0065a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuously_decoded_result_cache_dict[0.025]['pseudo2D'] # DecodedFilterEpochsResult"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aec3e1",
   "metadata": {},
   "source": [
    "# 2025-04-29 - Simple P(Long) (joint) over position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf1aa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import EpochComputationFunctions, EpochComputationsComputationsContainer\n",
    "from neuropy.utils.mixins.binning_helpers import BinningContainer, BinningInfo\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import complete_all_transition_matricies, build_transition_matricies\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import split_transition_matricies_results_pre_post_delta_category\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import LongShortTrackDataframeAccessor\n",
    "\n",
    "valid_EpochComputations_result: EpochComputationsComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['EpochComputations']\n",
    "a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult = valid_EpochComputations_result.a_generic_decoder_dict_decoded_epochs_dict_result\n",
    "\n",
    "\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.050, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore') # , decoder_identifier='long_LR'\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore', data_grain='per_epoch') # , time_bin_size=0.050, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore', decoder_identifier='long_LR'\n",
    "\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='ignore', data_grain='per_epoch') ## Laps\n",
    "# any_matching_contexts_list, result_context_dict, decoder_context_dict, decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context)\n",
    "\n",
    "# common_constraint_dict = dict(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, masked_time_bin_fill_type='ignore')\n",
    "common_constraint_dict = dict(trained_compute_epochs='laps', time_bin_size=0.025, masked_time_bin_fill_type='nan_filled') # , pfND_ndim=1\n",
    "\n",
    "\n",
    "## Laps context:\n",
    "a_laps_target_context: IdentifyingContext = IdentifyingContext(known_named_decoding_epochs_type='laps', **common_constraint_dict, data_grain='per_epoch') ## Laps\n",
    "laps_target_context_results = complete_all_transition_matricies(a_new_fully_generic_result=a_new_fully_generic_result, a_target_context=a_laps_target_context)\n",
    "laps_matched_result_tuple_context_dict, (laps_time_bin_container_context_dict, laps_position_transition_matrix_context_dict, laps_context_state_transition_matrix_context_dict, laps_combined_transition_matrix_context_dict), (laps_mean_context_state_transition_matrix_context_dict, laps_mean_position_transition_matrix_context_dict) = laps_target_context_results\n",
    "# a_best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = out_matched_result_tuple_context_dict[a_ctxt]\n",
    "a_laps_best_matching_context, a_laps_result, a_laps_decoder, a_laps_decoded_marginal_posterior_df = list(laps_matched_result_tuple_context_dict.values())[0] # [-1]\n",
    "\n",
    "## PBEs context:\n",
    "a_PBEs_target_context: IdentifyingContext = IdentifyingContext(known_named_decoding_epochs_type='pbe', **common_constraint_dict, data_grain='per_epoch') ## Laps\n",
    "pbes_target_context_results = complete_all_transition_matricies(a_new_fully_generic_result=a_new_fully_generic_result, a_target_context=a_PBEs_target_context)\n",
    "pbes_matched_result_tuple_context_dict, (pbes_time_bin_container_context_dict, pbes_position_transition_matrix_context_dict, pbes_context_state_transition_matrix_context_dict, pbes_combined_transition_matrix_context_dict), (pbes_mean_context_state_transition_matrix_context_dict, pbes_mean_position_transition_matrix_context_dict) = pbes_target_context_results\n",
    "a_pbes_best_matching_context, a_pbes_result, a_pbes_decoder, a_pbes_decoded_marginal_posterior_df = list(pbes_matched_result_tuple_context_dict.values())[0] # [-1] # pbes_matched_result_tuple_context_dict[a_PBEs_target_context]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a40bdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_post_delta_a_laps_decoded_marginal_posterior_df_dict = a_laps_decoded_marginal_posterior_df.pho.partition_df_dict('pre_post_delta_category') # pre_post_delta_category\n",
    "# pre_post_delta_a_laps_decoded_marginal_posterior_df_dict['pre-delta']\n",
    "# pre_post_delta_a_laps_decoded_marginal_posterior_df_dict['post-delta']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fdfa19",
   "metadata": {},
   "source": [
    "## 2025-05-01 - Get Pre/Post Delta Split Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d818e15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import LongShortTrackDataframeAccessor\n",
    "from typing import Dict, List, Tuple, Optional, Callable, Union, Any, TypeVar\n",
    "from typing_extensions import TypeAlias\n",
    "import nptyping as ND\n",
    "from nptyping import NDArray\n",
    "# import neuropy.utils.type_aliases as types\n",
    "import pyphoplacecellanalysis.General.type_aliases as types\n",
    "from neuropy.utils.mixins.time_slicing import TimeColumnAliasesProtocol\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import build_decoder_prob_as_a_function_of_position\n",
    "\n",
    "## INPUTS: a_laps_decoder, a_laps_result, a_pbes_result\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "\n",
    "epochs_result_dict: Dict[types.KnownNamedDecodingEpochsType, DecodedFilterEpochsResult] = {'laps': deepcopy(a_laps_result),\n",
    "\t\t\t\t\t  'pbe': deepcopy(a_pbes_result),\n",
    "}\n",
    "# epochs_result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f4bc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_dict, epoch_name_by_pre_post_delta_category_output_dict_dict, epoch_name_by_probability_values_output_dict_dict = build_decoder_prob_as_a_function_of_position(epochs_result_dict=epochs_result_dict, xbin_centers=deepcopy(a_laps_decoder.xbin_centers), t_delta=t_delta, grid_bin_bounds=deepcopy(a_laps_decoder.pf.config.grid_bin_bounds), is_split_by_all_decoders=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dc58c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax_dict, epoch_name_by_pre_post_delta_category_output_dict_dict, epoch_name_by_probability_values_output_dict_dict = build_decoder_prob_as_a_function_of_position(epochs_result_dict=epochs_result_dict, xbin_centers=deepcopy(a_laps_decoder.xbin_centers), t_delta=t_delta, grid_bin_bounds=deepcopy(a_laps_decoder.pf.config.grid_bin_bounds), is_split_by_all_decoders=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aa6bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_name_by_probability_values_output_dict_dict['laps']['long']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4efd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ndarray_preview height=500, width=None, include_plaintext_repr=False, include_shape=False, horizontal_layout=True\n",
    "# %%ndarray_preview height=500, width=200, include_plaintext_repr=False, include_shape=False, horizontal_layout=True\n",
    "# summary_values_dict['all'].shape # .shape (59, 4, 1349)  (n_pos_bins, 4, n_t_bins)\n",
    "# np.nansum(summary_values_dict['all'], axis=0) # .shape (4, n_t_bins)\n",
    "\n",
    "full_joint_p = deepcopy(summary_values_dict['all']) # .shape (n_pos_bins, 4, n_t_bins)\n",
    "full_joint_p = np.nan_to_num(full_joint_p, copy=True, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "full_joint_p\n",
    "\n",
    "any_decoder_p = np.nansum(full_joint_p, axis=1) # .shape (n_pos_bins, n_t_bins)\n",
    "any_decoder_p = np.nan_to_num(any_decoder_p, copy=True, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "any_decoder_p\n",
    "\n",
    "any_decoder_all_t_bins_p = np.nansum(any_decoder_p, axis=-1) # .shape (n_pos_bins)\n",
    "any_decoder_all_t_bins_p = np.nan_to_num(any_decoder_all_t_bins_p, copy=True, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "any_decoder_all_t_bins_p\n",
    "\n",
    "# summary_values_dict['all'][:,:,4]\n",
    "\n",
    "# np.nansum(summary_values_dict['all'][:,:,4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bf8330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# any_decoder_p\n",
    "\n",
    "single_decoder_p = full_joint_p[:, 0, :] / any_decoder_p # .shape (n_pos_bins, n_t_bins)\n",
    "single_decoder_p = np.nan_to_num(single_decoder_p, copy=True, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "single_decoder_p = single_decoder_p / np.nansum(single_decoder_p, axis=0) # all positions should normalize to 1.0\n",
    "single_decoder_p = np.nan_to_num(single_decoder_p, copy=True, nan=0.0, posinf=1.0, neginf=0.0)\n",
    "single_decoder_p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dbd0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nansum(single_decoder_p, axis=-1)\n",
    "np.nansum(single_decoder_p, axis=0) # all positions should normalize to 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903e39e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "any_decoder_p = np.nan_to_num(any_decoder_p, copy=True, nan=0.0, posinf=1.0, neginf=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94176f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ndarray_preview height=500, width=None, include_plaintext_repr=False, include_shape=False, horizontal_layout=True\n",
    "\n",
    "np.nansum(summary_values_dict['all'], axis=-1) # .shape (59, 4) (n_pos_bins, 4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19747dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "summary_values_dict['long'].shape # .shape (n_pos_bins, n_t_bins)\n",
    "\n",
    "\n",
    "# np.nansum(summary_values_dict['long'], axis=0) # .shape (n_t_bins)\n",
    "np.nansum(summary_values_dict['long'], axis=1) # .shape (n_pos_bins)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e05f166",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_laps_decoder.xbin_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216f7766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_bin_bounds\n",
    "# long_results.pf1D.config.grid_bin_bounds\n",
    "\n",
    "a_laps_decoder.pf.config.grid_bin_bounds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e02152b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: a_laps_decoded_marginal_posterior_df\n",
    "# a_laps_decoded_marginal_posterior_df\n",
    "a_laps_decoded_marginal_posterior_df\n",
    "a_laps_decoded_marginal_posterior_df = LongShortTrackDataframeAccessor.add_pre_post_delta_category_column_if_needed(epochs_df=a_laps_decoded_marginal_posterior_df, t_delta=t_delta, start_time_col_name='lap_start_t')\n",
    "a_laps_decoded_marginal_posterior_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27cd6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS\n",
    "Assert.same_length(an_out_result.filter_epochs, an_out_result.p_x_given_n_list)\n",
    "# an_out_result.filter_epochs\n",
    "len(an_out_result.p_x_given_n_list)\n",
    "\n",
    "pre_post_delta_a_laps_decoded_marginal_posterior_df_dict = a_laps_decoded_marginal_posterior_df.pho.partition_df_dict('pre_post_delta_category') # pre_post_delta_category\n",
    "# pre_post_delta_a_laps_decoded_marginal_posterior_df_dict['pre-delta']\n",
    "# pre_post_delta_a_laps_decoded_marginal_posterior_df_dict['post-delta']\n",
    "\n",
    "an_out_result_dict: Dict[str, DecodedFilterEpochsResult] = {'pre-delta': an_out_result.filtered_by_epoch_times(pre_post_delta_a_laps_decoded_marginal_posterior_df_dict['pre-delta']['lap_start_t']),\n",
    "\t\t\t\t\t  'post-delta': an_out_result.filtered_by_epoch_times(pre_post_delta_a_laps_decoded_marginal_posterior_df_dict['post-delta']['lap_start_t']),\n",
    "}\n",
    "an_out_result_dict['pre-delta']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc3e75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import plot_linearized_position_probability\n",
    "\n",
    "# Example usage\n",
    "# fig, prob_values = plot_linearized_position_probability(an_out_result)\n",
    "\n",
    "fig1, ax1, prob_values1 = plot_linearized_position_probability(an_out_result=an_out_result_dict['pre_delta'], figure_title='pre-delta Linearized Position Probability')\n",
    "fig2, ax2, prob_values2 = plot_linearized_position_probability(an_out_result=an_out_result_dict['post_delta'], figure_title='post-delta Linearized Position Probability', ax=ax1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e773f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [v['p_x_given_n'].shape for v in an_out_result.marginal_x_list]\n",
    "# [v.shape for v in an_out_result.p_x_given_n_list]\n",
    "\n",
    "SUMMRY_WUMY = np.squeeze(np.hstack([np.squeeze(v[:,0,:]) for v in an_out_result.p_x_given_n_list])) + np.squeeze(np.hstack([np.squeeze(v[:,1,:]) for v in an_out_result.p_x_given_n_list]))\n",
    "gay_GARRAYU = np.nansum(SUMMRY_WUMY, axis=-1)\n",
    "NORMY_WARMY = np.nansum(gay_GARRAYU)\n",
    "gay_GARRAYU = gay_GARRAYU / NORMY_WARMY\n",
    "gay_GARRAYU\n",
    "\n",
    "\n",
    "plt.figure(num='INNOPCUOUS FIGHURE')\n",
    "plt.scatter(x=np.arange(len(gay_GARRAYU)), y=gay_GARRAYU)\n",
    "plt.ylabel('P(LONG)')\n",
    "plt.xlabel('Position <linearized>')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303c3e45",
   "metadata": {},
   "source": [
    "#### Pre 2025-05-01 Simple way of doing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1846ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.stack(an_out_result.p_x_given_n_list, axis=1)\n",
    "# np.hstack(an_out_result.p_x_given_n_list)\n",
    "\n",
    "    # an_out_result.p_x_given_n_lis\n",
    "\n",
    "gay_GARRAYU=np.nansum(np.hstack([v['p_x_given_n'] for v in an_out_result.marginal_x_list]), axis=-1)\n",
    "NORMY_WARMY = np.nansum(gay_GARRAYU)\n",
    "gay_GARRAYU = gay_GARRAYU / NORMY_WARMY\n",
    "\n",
    "\n",
    "plt.figure(num='PUPPY FIGHURE')\n",
    "plt.scatter(x=np.arange(len(gay_GARRAYU)), y=gay_GARRAYU)\n",
    "plt.ylabel('P(LONG)')\n",
    "plt.xlabel('Position <linearized>')\n",
    "\n",
    "\n",
    "# np.nansum(, axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaccf1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import _perform_plot_P_Context_State_Transition_Matrix, _perform_plot_position_Transition_Matrix\n",
    "\n",
    "## INPUTS: laps_context_state_transition_matrix_context_dict\n",
    "# out_transition_matrix_context_dict = deepcopy(pbes_context_state_transition_matrix_context_dict)\n",
    "out_transition_matrix_context_dict = deepcopy(pbes_position_transition_matrix_context_dict)\n",
    "out_matched_result_tuple_context_dict = deepcopy(pbes_matched_result_tuple_context_dict)\n",
    "\n",
    "an_out_best_matching_context, an_out_result, an_out_decoder, an_out_decoded_marginal_posterior_df = list(out_matched_result_tuple_context_dict.values())[0] # [-1]\n",
    "a_transition_matrix_list: List[NDArray] = list(out_transition_matrix_context_dict.values())[0]\n",
    "\n",
    "## INPUTS: an_out_decoded_marginal_posterior_df, a_context_state_transition_matrix_list\n",
    "# 2024-03-04 - Filter out the epochs based on the criteria:\n",
    "# _, _, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "# filtered_epochs_df, active_spikes_df = filter_and_update_epochs_and_spikes(curr_active_pipeline, global_epoch_name, track_templates, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1)\n",
    "# filtered_valid_epoch_times = filtered_epochs_df[['start', 'stop']].to_numpy()\n",
    "# required_min_percentage_of_active_cells: float = 0.333333 # 20% of active cells\n",
    "# active_min_num_unique_aclu_inclusions_requirement: int = track_templates.min_num_unique_aclu_inclusions_requirement(curr_active_pipeline, required_min_percentage_of_active_cells=required_min_percentage_of_active_cells)\n",
    "# Update epochs and spikes\n",
    "# an_out_decoded_marginal_posterior_df, active_spikes_df = co_filter_epochs_and_spikes(active_spikes_df=active_spikes_df, active_epochs_df=an_out_decoded_marginal_posterior_df, included_aclus=track_templates.any_decoder_neuron_IDs, min_num_unique_aclu_inclusions=active_min_num_unique_aclu_inclusions_requirement, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1, add_unique_aclus_list_column=False, drop_non_epoch_spikes=True)\n",
    "# pbes_mean_context_state_transition_matrix_dict = split_transition_matricies_results_pre_post_delta_category(an_out_decoded_marginal_posterior_df=an_out_decoded_marginal_posterior_df, a_context_state_transition_matrix_list=a_transition_matrix_list)\n",
    "\n",
    "\n",
    "pbes_mean_context_state_transition_matrix_dict = split_transition_matricies_results_pre_post_delta_category(an_out_decoded_marginal_posterior_df=an_out_decoded_marginal_posterior_df, a_context_state_transition_matrix_list=list(deepcopy(pbes_context_state_transition_matrix_context_dict).values())[0])\n",
    "pbes_mean_position_transition_matrix_dict = split_transition_matricies_results_pre_post_delta_category(an_out_decoded_marginal_posterior_df=an_out_decoded_marginal_posterior_df, a_context_state_transition_matrix_list=list(deepcopy(pbes_position_transition_matrix_context_dict).values())[0])\n",
    "\n",
    "pbes_mean_context_state_transition_matrix_dict\n",
    "pbes_mean_position_transition_matrix_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da7552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import _perform_plot_P_Context_State_Transition_Matrix, _perform_plot_position_Transition_Matrix\n",
    "\n",
    "\n",
    "for pre_post_delta_value, a_mean_context_state_transition_matrix in pbes_mean_context_state_transition_matrix_dict.items():\n",
    "    # _perform_plot_P_Context_State_Transition_Matrix(context_state_transition_matrix=a_mean_context_state_transition_matrix, num=f'laps')\n",
    "    _perform_plot_P_Context_State_Transition_Matrix(context_state_transition_matrix=a_mean_context_state_transition_matrix, num=f'PBEs: Context ({pre_post_delta_value})')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9e865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pre_post_delta_value, a_mean_position_transition_matrix in pbes_mean_position_transition_matrix_dict.items():\n",
    "    # _perform_plot_P_Context_State_Transition_Matrix(context_state_transition_matrix=a_mean_context_state_transition_matrix, num=f'laps')\n",
    "    _perform_plot_position_Transition_Matrix(a_position_transition_matrix=a_mean_position_transition_matrix, num=f'PBEs: Positions ({pre_post_delta_value})')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9c7980",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert 'pre_post_delta_category' in an_out_decoded_marginal_posterior_df\n",
    "is_pre_delta = (an_out_decoded_marginal_posterior_df['pre_post_delta_category'] == 'pre-delta')\n",
    "\n",
    "a_context_state_transition_matrix: NDArray = np.stack(a_context_state_transition_matrix_list) # np.stack(out_context_state_transition_matrix_context_dict[a_ctxt]).shape\n",
    "\n",
    "## split on first index:\n",
    "a_context_state_transition_matrix_dict = {'pre-delta': a_context_state_transition_matrix[is_pre_delta], 'post-delta': a_context_state_transition_matrix[np.logical_not(is_pre_delta)]}\n",
    "a_mean_context_state_transition_matrix_dict = {k:np.nanmean(v, axis=0) for k, v in a_context_state_transition_matrix_dict.items()}\n",
    "\n",
    "# np.shape(a_context_state_transition_matrix) # (84, 4, 4) - (n_epochs, n_states, n_states)\n",
    "# a_mean_context_state_transition_matrix: NDArray = np.nanmean(a_context_state_transition_matrix, axis=0) #.shape (4, 4)\n",
    "# a_mean_context_state_transition_matrix\n",
    "a_mean_context_state_transition_matrix_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c28ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_pbes_decoded_marginal_posterior_df[a_pbes_decoded_marginal_posterior_df['pre_post_delta_category'] == 'pre-delta'] # (partitionColumn='pre_post_delta_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92968ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(laps_matched_result_tuple_context_dict.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96268dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_laps_decoded_marginal_posterior_df\n",
    "a_pbes_best_matching_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a869e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_mean_context_state_transition_matrix_context_dict[a_laps_best_matching_context]\n",
    "laps_mean_position_transition_matrix_context_dict[a_laps_best_matching_context]\n",
    "\n",
    "pbes_mean_context_state_transition_matrix_context_dict[a_pbes_best_matching_context]\n",
    "pbes_mean_position_transition_matrix_context_dict[a_pbes_best_matching_context]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa45f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "laps_mean_context_state_transition_matrix_context_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea666e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import _perform_plot_P_Context_State_Transition_Matrix, _perform_plot_position_Transition_Matrix\n",
    "\n",
    "_perform_plot_P_Context_State_Transition_Matrix(context_state_transition_matrix=laps_mean_context_state_transition_matrix_context_dict[a_laps_best_matching_context], num='laps')\n",
    "_perform_plot_P_Context_State_Transition_Matrix(context_state_transition_matrix=pbes_mean_context_state_transition_matrix_context_dict[a_pbes_best_matching_context], num='PBEs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a3036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.transition_matrix import _perform_plot_P_Context_State_Transition_Matrix, _perform_plot_position_Transition_Matrix\n",
    "\n",
    "_perform_plot_position_Transition_Matrix(a_position_transition_matrix=laps_mean_position_transition_matrix_context_dict[a_laps_best_matching_context], num='laps')\n",
    "_perform_plot_position_Transition_Matrix(a_position_transition_matrix=pbes_mean_position_transition_matrix_context_dict[a_pbes_best_matching_context], num='PBEs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a3258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# plt.figure(figsize=(8,6)); sns.heatmap(A_big, cmap='viridis'); plt.title(\"Transition Matrix A_big\"); plt.show()\n",
    "# plt.figure(figsize=(8,6)); sns.heatmap(A_position, cmap='viridis'); perform_update_title_subtitle(title_string=f\"Transition Matrix A_position - t_bin: {a_time_bin_size}\"); plt.show(); \n",
    "# plt.figure(figsize=(8,6)); sns.heatmap(A_model, cmap='viridis'); perform_update_title_subtitle(title_string=f\"Transition Matrix A_model - t_bin: {a_time_bin_size}\"); plt.show()\n",
    "\n",
    "n_position_bins = 59\n",
    "n_decoding_models = 4\n",
    "_out = plot_blocked_transition_matrix(pbes_mean_position_transition_matrix_context_dict[a_pbes_best_matching_context], n_position_bins, n_decoding_models, extra_title_suffix=f' - t_bin: {a_time_bin_size}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7d6da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "FAT_df: pd.DataFrame = deepcopy(a_new_fully_generic_result.single_FAT_df)\n",
    "# len(all_contexts)\n",
    "FAT_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1589048",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# all_contexts\n",
    "unique_values_dict = FAT_df.neuropy.get_column_unique_values_dict(columns_include_subset=['trained_compute_epochs', 'known_named_decoding_epochs_type', 'masked_time_bin_fill_type', 'data_grain', 'decoding_time_bin_size']) # , 'masked_time_bin_fill_type'\n",
    "unique_values_dict\n",
    "\n",
    "# [Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'non_pbe_endcaps', masked_time_bin_fill_type= 'dropped', data_grain= 'per_time_bin', decoding_time_bin_size= 0.025),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_epoch'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'non_pbe', masked_time_bin_fill_type= 'last_valid'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'pbe'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'non_pbe'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'dropped', data_grain= 'per_time_bin'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'dropped', data_grain= 'per_time_bin'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_epoch'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'nan_filled'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'non_pbe_endcaps', masked_time_bin_fill_type= 'last_valid', data_grain= 'per_time_bin', decoding_time_bin_size= 0.025),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'dropped', data_grain= 'per_epoch'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'ignore'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_time_bin'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'ignore'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'non_pbe_endcaps', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin', decoding_time_bin_size= 0.025),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'last_valid'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'nan_filled'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'non_pbe', masked_time_bin_fill_type= 'nan_filled'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'global', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_time_bin'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'non_pbe_endcaps', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_time_bin', decoding_time_bin_size= 0.025),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'ignore', data_grain= 'per_epoch'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'non_pbe', masked_time_bin_fill_type= 'ignore'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'last_valid'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore', data_grain= 'per_epoch'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'dropped', data_grain= 'per_time_bin'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'laps'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'dropped', data_grain= 'per_epoch'),\n",
    "#  Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'nan_filled'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'dropped', data_grain= 'per_time_bin'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'nan_filled'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'global', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'),\n",
    "#  Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_time_bin')]\n",
    "\n",
    "possible_unique_values_dict = {'trained_compute_epochs': ['non_pbe', 'laps'],\n",
    " 'known_named_decoding_epochs_type': ['laps', 'pbe', 'non_pbe', 'global', 'non_pbe_endcaps'],\n",
    " 'masked_time_bin_fill_type': ['ignore', 'last_valid', 'nan_filled', 'dropped'],\n",
    " 'data_grain': ['per_time_bin', 'per_epoch'],\n",
    " 'decoding_time_bin_size': [0.025]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d746d004",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.050, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore') # , decoder_identifier='long_LR'\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore', data_grain='per_epoch') # , time_bin_size=0.050, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type='ignore', decoder_identifier='long_LR'\n",
    "\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='ignore', data_grain='per_epoch') ## Laps\n",
    "# any_matching_contexts_list, result_context_dict, decoder_context_dict, decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context)\n",
    "\n",
    "# common_constraint_dict = dict(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=0.025, masked_time_bin_fill_type='ignore')\n",
    "common_constraint_dict = dict(trained_compute_epochs='laps', time_bin_size=0.025, masked_time_bin_fill_type='nan_filled') # , pfND_ndim=1\n",
    "\n",
    "\n",
    "## Laps context:\n",
    "a_laps_target_context: IdentifyingContext = IdentifyingContext(known_named_decoding_epochs_type='laps', **common_constraint_dict, data_grain='per_epoch') ## Laps\n",
    "laps_target_context_results = complete_all_transition_matricies(a_new_fully_generic_result=a_new_fully_generic_result, a_target_context=a_laps_target_context)\n",
    "laps_matched_result_tuple_context_dict, (laps_time_bin_container_context_dict, laps_position_transition_matrix_context_dict, laps_context_state_transition_matrix_context_dict, laps_combined_transition_matrix_context_dict), (laps_mean_context_state_transition_matrix_context_dict, laps_mean_position_transition_matrix_context_dict) = laps_target_context_results\n",
    "# a_best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = out_matched_result_tuple_context_dict[a_ctxt]\n",
    "a_laps_best_matching_context, a_laps_result, a_laps_decoder, a_laps_decoded_marginal_posterior_df = list(laps_matched_result_tuple_context_dict.values())[0] # [-1]\n",
    "\n",
    "## PBEs context:\n",
    "a_PBEs_target_context: IdentifyingContext = IdentifyingContext(known_named_decoding_epochs_type='pbe', **common_constraint_dict, data_grain='per_epoch') ## Laps\n",
    "pbes_target_context_results = complete_all_transition_matricies(a_new_fully_generic_result=a_new_fully_generic_result, a_target_context=a_PBEs_target_context)\n",
    "pbes_matched_result_tuple_context_dict, (pbes_time_bin_container_context_dict, pbes_position_transition_matrix_context_dict, pbes_context_state_transition_matrix_context_dict, pbes_combined_transition_matrix_context_dict), (pbes_mean_context_state_transition_matrix_context_dict, pbes_mean_position_transition_matrix_context_dict) = pbes_target_context_results\n",
    "a_pbes_best_matching_context, a_pbes_result, a_pbes_decoder, a_pbes_decoded_marginal_posterior_df = list(pbes_matched_result_tuple_context_dict.values())[0] # [-1] # pbes_matched_result_tuple_context_dict[a_PBEs_target_context]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bb3795",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values_dict = FAT_df.neuropy.get_column_unique_values_dict(columns_include_subset=['custom_replay_name', 'included_qclu_values', 'minimum_inclusion_fr_Hz', 'time_bin_size']) # , 'masked_time_bin_fill_type'\n",
    "unique_values_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f75ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0fe9b90",
   "metadata": {},
   "source": [
    "# 2025-05-04 - Add interpolated position to any decoded result df with (P_Long, P_Short, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40962ef9",
   "metadata": {},
   "source": [
    "### Active manual adding of position columns to obtained global result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a360cd",
   "metadata": {
    "tags": [
     "active-2025-05-05"
    ]
   },
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _helper_add_interpolated_position_columns_to_decoded_result_df\n",
    "# from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import _perform_plot_hairy_overlayed_position\n",
    "\n",
    "## INPUTS: a_new_fully_generic_result\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='nan_filled', data_grain='per_time_bin')\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='ignore', data_grain='per_time_bin')\n",
    "best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=a_target_context, debug_print=False)\n",
    "## OUTPUTS: a_result, a_decoder, a_decoded_marginal_posterior_df\n",
    "## INPUTS: curr_active_pipeline, a_result, a_decoder, a_decoded_marginal_posterior_df\n",
    "global_measured_position_df: pd.DataFrame = deepcopy(curr_active_pipeline.sess.position.to_dataframe())\n",
    "a_decoded_marginal_posterior_df: pd.DataFrame = _helper_add_interpolated_position_columns_to_decoded_result_df(a_result=a_result, a_decoder=a_decoder, a_decoded_marginal_posterior_df=a_decoded_marginal_posterior_df,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  global_measured_position_df=global_measured_position_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c843f5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.utils.result_context import IdentifyingContext\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _helper_add_interpolated_position_columns_to_decoded_result_df\n",
    "# from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import _perform_plot_hairy_overlayed_position\n",
    "\n",
    "\n",
    "\n",
    "## INPUTS: a_new_fully_generic_result\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='nan_filled', data_grain='per_time_bin')\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type='ignore', data_grain='per_time_bin') # , known_named_decoding_epochs_type='global'\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=a_target_context, return_multiple_matches=True)\n",
    "\n",
    "# flat_context_list\n",
    "flat_decoded_marginal_posterior_df_context_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2338f685",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=a_target_context, debug_print=False)\n",
    "## OUTPUTS: a_result, a_decoder, a_decoded_marginal_posterior_df\n",
    "## INPUTS: curr_active_pipeline, a_result, a_decoder, a_decoded_marginal_posterior_df\n",
    "global_measured_position_df: pd.DataFrame = deepcopy(curr_active_pipeline.sess.position.to_dataframe())\n",
    "a_decoded_marginal_posterior_df: pd.DataFrame = _helper_add_interpolated_position_columns_to_decoded_result_df(a_result=a_result, a_decoder=a_decoder, a_decoded_marginal_posterior_df=a_decoded_marginal_posterior_df,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  global_measured_position_df=global_measured_position_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d68ac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## now check the histogram for `a_decoded_marginal_posterior_df`\n",
    "a_decoded_marginal_posterior_df: pd.DataFrame = a_decoded_marginal_posterior_df\n",
    "a_decoded_marginal_posterior_df\n",
    "# a_decoded_marginal_posterior_df['binned_x_meas'].hist()\n",
    "a_decoded_marginal_posterior_df.to_csv('output/2025-05-05_decoded_marginal_posterior_df_with_meas_pos.csv')\n",
    "\n",
    "## OUTPUTS: a_decoded_marginal_posterior_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8625601",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c1ef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _helper_add_interpolated_position_columns_to_decoded_result_df\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import _perform_plot_hairy_overlayed_position\n",
    "from neuropy.utils.matplotlib_helpers import draw_epoch_regions\n",
    "\n",
    "## INPUTS: a_decoded_marginal_posterior_df\n",
    "\n",
    "# ## plot the basic lap-positions (measured) over time figure:\n",
    "# _out = dict()\n",
    "# _out['_display_grid_bin_bounds_validation'] = curr_active_pipeline.display(display_function='_display_grid_bin_bounds_validation', active_session_configuration_context=None, include_includelist=[], save_figure=False) # _display_grid_bin_bounds_validation\n",
    "# fig = _out['_display_grid_bin_bounds_validation'].figures[0]\n",
    "# out_axes_list =_out['_display_grid_bin_bounds_validation'].axes\n",
    "# out_plot_data =_out['_display_grid_bin_bounds_validation'].plot_data\n",
    "# ## get the lines2D object to turn off the default position lines:\n",
    "# position_lines_2D = out_plot_data['position_lines_2D']\n",
    "# ## hide all inactive lines:\n",
    "# for a_line in position_lines_2D:\n",
    "#     a_line.set_visible(False)\n",
    "\n",
    "# ax = out_axes_list[0]\n",
    "\n",
    "\n",
    "ax = None\n",
    "    \n",
    "an_pos_line_artist, df_viz = _perform_plot_hairy_overlayed_position(df=deepcopy(a_decoded_marginal_posterior_df), ax=ax, extreme_threshold=0.7) # , thickness_ramping_multiplier=5\n",
    "# df_viz\n",
    "# _out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b126a652",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_pos_line_artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad91da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add epoch indicators:\n",
    "\n",
    "## INPUTS: ax\n",
    "\n",
    "from neuropy.utils.matplotlib_helpers import draw_epoch_regions\n",
    "\n",
    "# epochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, defer_render=False, debug_print=False)\n",
    "# epochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.laps, ax, defer_render=False, debug_print=True)\n",
    "\n",
    "y_height_fraction: float = 0.05\n",
    "n_epoch_types: int = 3\n",
    "relative_y_positions_list = [((float(i)*y_height_fraction), (float(i+1)*y_height_fraction)) for i in np.arange(n_epoch_types)]  # [(0.0, 0.05), (0.05, 0.1), (0.1, 0.15000000000000002)]\n",
    "relative_y_positions_list\n",
    "\n",
    "# relative_y_positions_list = [(0.1, 0.15), (0.15, 0.2)]\n",
    "\n",
    "\n",
    "# relative_y_positions_list = [(0.0, 0.2)]\n",
    "\n",
    "# relative_y_positions=[[0.0, 0.05], [0.05, 0.10], \n",
    "epoch_collection_artists_list_dict = {}\n",
    "\n",
    "common_kwargs = dict(alpha=0.2, linewidths=None)\n",
    "# epochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, facecolor=('red','cyan'), edgecolors=None, labels_kwargs={'y_offset': -0.05, 'size': 14}, **common_kwargs, relative_y_positions=relative_y_positions_list[0], defer_render=True, debug_print=False)\n",
    "# laps_epochs_collection, laps_epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.laps.as_epoch_obj(), ax, facecolor='red', edgecolors='black', labels_kwargs={'y_offset': -16.0, 'size':8}, **common_kwargs, relative_y_positions=relative_y_positions_list[0], defer_render=True, debug_print=False)\n",
    "# replays_epochs_collection, replays_epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.pbe, ax, facecolor='orange', edgecolors=None, labels_kwargs=None, **common_kwargs, relative_y_positions=relative_y_positions_list[0], defer_render=False, debug_print=False)\n",
    "\n",
    "# # epochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, facecolor=('red','cyan'), edgecolors=None, **common_kwargs, relative_y_positions=relative_y_positions_list[0], defer_render=True, debug_print=False)\n",
    "# epoch_collection_artists_list_dict['laps'] = draw_epoch_regions(curr_active_pipeline.sess.laps.as_epoch_obj(), ax, facecolor='red', edgecolors='black', **common_kwargs, relative_y_positions=relative_y_positions_list[0], defer_render=False, debug_print=True)\n",
    "# # epoch_collection_artists_list_dict['replays'] = draw_epoch_regions(curr_active_pipeline.sess.pbe, ax, facecolor='purple', edgecolors=None, **common_kwargs, relative_y_positions=relative_y_positions_list[1], defer_render=False, debug_print=False)\n",
    "\n",
    "\n",
    "# epoch_collection_artists_list_dict['delta'] = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, facecolor=('red','cyan'), edgecolors=None, **common_kwargs, defer_render=False, debug_print=True)\n",
    "epoch_collection_artists_list_dict['laps'] = draw_epoch_regions(curr_active_pipeline.sess.laps.as_epoch_obj(), ax, facecolor='red', edgecolors=None, **common_kwargs, defer_render=False, debug_print=True)\n",
    "epoch_collection_artists_list_dict['replays'] = draw_epoch_regions(curr_active_pipeline.sess.pbe, ax, facecolor='purple', edgecolors=None, **common_kwargs, defer_render=False, debug_print=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aa7934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_all_epoch_artists(epoch_collection_artists_list_dict):\n",
    "    for a_name, a_list in epoch_collection_artists_list_dict.items():\n",
    "        for an_item in a_list:\n",
    "            if an_item is not None:\n",
    "                an_item.remove() ## remove the artist\n",
    "    epoch_collection_artists_list_dict = {} ## clear\n",
    "    return epoch_collection_artists_list_dict\n",
    "\n",
    "\n",
    "epoch_collection_artists_list_dict = remove_all_epoch_artists(epoch_collection_artists_list_dict=epoch_collection_artists_list_dict)\n",
    "\n",
    "\n",
    "# laps_epochs_collection.remove()\n",
    "# laps_epoch_labels.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd57669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, facecolor=[(255, 0, 0), (0, 255, 0)], edgecolors=(0,0,0), labels_kwargs={'y_offset': -16.0, 'size':8, 'rotation':90}, defer_render=False, debug_print=False)\n",
    "\n",
    "epochs_collection, epoch_labels = draw_epoch_regions(curr_active_pipeline.sess.epochs, ax, facecolor=[(255, 0, 0), (0, 255, 0)], edgecolors=(0,0,0), labels_kwargs={'y_offset': -16.0, 'size':8, 'rotation':90}, defer_render=False, debug_print=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d8e569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# epochs_collection.remove()\n",
    "# epoch_labels.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a187527",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out = curr_active_pipeline.display(display_function='_display_decoded_trackID_marginal_hairy_position', active_session_configuration_context=None, include_includelist=[], save_figure=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8286a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz[['P_Long', 'P_Short']].sum(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d66e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(a_decoded_marginal_posterior_df_viz) - 1):\n",
    "    row0 = a_decoded_marginal_posterior_df_viz.iloc[i]\n",
    "    row1 = a_decoded_marginal_posterior_df_viz.iloc[i + 1]\n",
    "    if row0['P_Long'] > 0.9 and row1['P_Long'] > 0.9:\n",
    "        ax.plot([row0['t'], row1['t']], [row0['x_meas'], row1['x_meas']],\n",
    "                color=(1, 0, 0, min(row0['P_Long_Opacity'], row1['P_Long_Opacity'])),\n",
    "                linewidth=max(row0['P_Long_Score'], row1['P_Long_Score']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952b9ec8",
   "metadata": {},
   "source": [
    "# 2025-05-04 - Posterior Example Images Export to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25144acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from pyphocorehelpers.plotting.media_output_helpers import ImageOperationsAndEffects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6a21c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()\n",
    "_out_paths = curr_active_pipeline.display('_display_directional_merged_pf_decoded_stacked_epoch_slices')\n",
    "_out_paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681e725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.assertion_helpers import Assert\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import HeatmapExportConfig, PosteriorExporting\n",
    "\n",
    "curr_active_pipeline.reload_default_display_functions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd08158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a_params_kwargs = {}\n",
    "display_context = curr_active_pipeline.build_display_context_for_session(display_fn_name='trackID_weighted_position_posterior')\n",
    "_out = curr_active_pipeline.display('_display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay', display_context, defer_render=True, save_figure=True,\n",
    "                                    # override_fig_man=custom_fig_man, \n",
    "                                    # parent_output_folder=custom_figure_output_path,\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bfe9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out['out_paths']\n",
    "\n",
    "# {'laps': {'psuedo2D_ignore': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/array_to_images/2025-05-30/gor01_one_2006-6-12_15-55-31_trackID_weighted_position_posterior/laps/psuedo2D_ignore'),\n",
    "#   'psuedo2D_nan_filled': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/array_to_images/2025-05-30/gor01_one_2006-6-12_15-55-31_trackID_weighted_position_posterior/laps/psuedo2D_nan_filled')},\n",
    "#  'ripple': {'psuedo2D_ignore': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/array_to_images/2025-05-30/gor01_one_2006-6-12_15-55-31_trackID_weighted_position_posterior/ripple/psuedo2D_ignore'),\n",
    "#   'psuedo2D_nan_filled': WindowsPath('C:/Users/pho/repos/Spike3DWorkEnv/Spike3D/output/array_to_images/2025-05-30/gor01_one_2006-6-12_15-55-31_trackID_weighted_position_posterior/ripple/psuedo2D_nan_filled')}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4db4eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_parent_save_paths = _out['flat_parent_save_paths']\n",
    "flat_parent_save_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550217b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out['flat_merged_image_paths']\n",
    "_out['parent_output_folder']\n",
    "flat_parent_save_paths = _out['flat_parent_save_paths']\n",
    "flat_parent_save_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d5931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_path in flat_parent_save_paths:\n",
    "    # file_uri_from_path(a_path)\n",
    "    fullwidth_path_widget(a_path=a_path, file_name_label=\"epoch_specific_folder:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6ca625",
   "metadata": {
    "tags": [
     "heu"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _plot_heuristic_evaluation_epochs\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_filter_replay_epochs\n",
    "\n",
    "force_refilter = False\n",
    "# force_refilter = True\n",
    "\n",
    "needs_refilter = False\n",
    "try:\n",
    "    filtered_decoder_filter_epochs_decoder_result_dict\n",
    "    filtered_epochs_df\n",
    "    filtered_ripple_all_epoch_bins_marginals_df\n",
    "    if filtered_decoder_filter_epochs_decoder_result_dict is not None:\n",
    "        needs_refilter = False\n",
    "except NameError:\n",
    "    needs_refilter = True\n",
    "    \n",
    "if needs_refilter or force_refilter:\n",
    "    filtered_epochs_df, filtered_decoder_filter_epochs_decoder_result_dict, filtered_ripple_all_epoch_bins_marginals_df = _perform_filter_replay_epochs(curr_active_pipeline, global_epoch_name, track_templates, decoder_ripple_filter_epochs_decoder_result_dict, ripple_all_epoch_bins_marginals_df, ripple_decoding_time_bin_size=ripple_decoding_time_bin_size, should_only_include_user_selected_epochs=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2146f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)\n",
    "# for k, v in filtered_decoder_filter_epochs_decoder_result_dict.items():\n",
    "# \tdirectional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=0.33333333, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc5b1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _plot_heuristic_evaluation_epochs\n",
    "\n",
    "\n",
    "# filtered_epochs_df\n",
    "# filtered_ripple_all_epoch_bins_marginals_df\n",
    "\n",
    "## 1m 38s\n",
    "\n",
    "ripple_merged_complete_epoch_stats_df['is_valid_epoch'] = True\n",
    "## INPUTS: curr_active_pipeline, track_templates, filtered_decoder_filter_epochs_decoder_result_dict, ripple_merged_complete_epoch_stats_df\n",
    "app, (high_heuristic_paginated_multi_decoder_decoded_epochs_window, high_heuristic_pagination_controller_dict), (low_heuristic_paginated_multi_decoder_decoded_epochs_window, low_heuristic_pagination_controller_dict) = _plot_heuristic_evaluation_epochs(curr_active_pipeline, track_templates, filtered_decoder_filter_epochs_decoder_result_dict, ripple_merged_complete_epoch_stats_df=ripple_merged_complete_epoch_stats_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dc8bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.RankOrderRastersDebugger import RankOrderRastersDebugger\n",
    "\n",
    "__out_ripple_rasters, update_attached_raster_viewer_epoch_callback = paginated_multi_decoder_decoded_epochs_window.build_attached_raster_viewer_widget(track_templates=track_templates, active_spikes_df=active_spikes_df, filtered_epochs_df=long_like_during_post_delta_only_filter_epochs_df) # Long-like-during-post-delta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45522cb0",
   "metadata": {},
   "source": [
    "# <a id='toc12_'></a>[🖼️🎨`PhoPaginatedMultiDecoderDecodedEpochsWindow.plot_full_paginated_decoded_epochs_window(..)` combined windows](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf897ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ripple_decoding_time_bin_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db1add4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(active_epochs_df): 133\n",
      "min_num_unique_aclu_inclusions: 8\n",
      "df_column_names: [['start', 'stop', 'label', 'duration', 'end', 'wcorr', 'P_decoder', 'pearsonr', 'mseq_len', 'mseq_len_ignoring_intrusions', 'mseq_len_ignoring_intrusions_and_repeats', 'mseq_len_ratio_ignoring_intrusions_and_repeats', 'mseq_tcov', 'mseq_dtrav', 'avg_jump_cm', 'travel', 'coverage', 'total_distance_traveled', 'track_coverage_score', 'longest_sequence_length', 'longest_sequence_length_ratio', 'direction_change_bin_ratio', 'congruent_dir_bins_ratio', 'total_congruent_direction_change', 'total_variation', 'integral_second_derivative', 'stddev_of_diff', 'is_user_annotated_epoch', 'is_valid_epoch', 'session_name', 'delta_aligned_start_t', 'pre_post_delta_category', 'maze_id'], ['start', 'stop', 'label', 'duration', 'end', 'wcorr', 'P_decoder', 'pearsonr', 'mseq_len', 'mseq_len_ignoring_intrusions', 'mseq_len_ignoring_intrusions_and_repeats', 'mseq_len_ratio_ignoring_intrusions_and_repeats', 'mseq_tcov', 'mseq_dtrav', 'avg_jump_cm', 'travel', 'coverage', 'total_distance_traveled', 'track_coverage_score', 'longest_sequence_length', 'longest_sequence_length_ratio', 'direction_change_bin_ratio', 'congruent_dir_bins_ratio', 'total_congruent_direction_change', 'total_variation', 'integral_second_derivative', 'stddev_of_diff', 'is_user_annotated_epoch', 'is_valid_epoch', 'session_name', 'delta_aligned_start_t', 'pre_post_delta_category', 'maze_id'], ['start', 'stop', 'label', 'duration', 'end', 'wcorr', 'P_decoder', 'pearsonr', 'mseq_len', 'mseq_len_ignoring_intrusions', 'mseq_len_ignoring_intrusions_and_repeats', 'mseq_len_ratio_ignoring_intrusions_and_repeats', 'mseq_tcov', 'mseq_dtrav', 'avg_jump_cm', 'travel', 'coverage', 'total_distance_traveled', 'track_coverage_score', 'longest_sequence_length', 'longest_sequence_length_ratio', 'direction_change_bin_ratio', 'congruent_dir_bins_ratio', 'total_congruent_direction_change', 'total_variation', 'integral_second_derivative', 'stddev_of_diff', 'is_user_annotated_epoch', 'is_valid_epoch', 'session_name', 'delta_aligned_start_t', 'pre_post_delta_category', 'maze_id'], ['start', 'stop', 'label', 'duration', 'end', 'wcorr', 'P_decoder', 'pearsonr', 'mseq_len', 'mseq_len_ignoring_intrusions', 'mseq_len_ignoring_intrusions_and_repeats', 'mseq_len_ratio_ignoring_intrusions_and_repeats', 'mseq_tcov', 'mseq_dtrav', 'avg_jump_cm', 'travel', 'coverage', 'total_distance_traveled', 'track_coverage_score', 'longest_sequence_length', 'longest_sequence_length_ratio', 'direction_change_bin_ratio', 'congruent_dir_bins_ratio', 'total_congruent_direction_change', 'total_variation', 'integral_second_derivative', 'stddev_of_diff', 'is_user_annotated_epoch', 'is_valid_epoch', 'session_name', 'delta_aligned_start_t', 'pre_post_delta_category', 'maze_id']]\n",
      "len(active_epochs_df): 133\n",
      "min_num_unique_aclu_inclusions: 5\n",
      "pos_bin_size = 4.877453969028168, ripple_decoding_time_bin_size = 0.025\n"
     ]
    }
   ],
   "source": [
    "# from neuropy.core.epoch import ensure_dataframe\n",
    "# from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring\n",
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import PhoPaginatedMultiDecoderDecodedEpochsWindow, DecodedEpochSlicesPaginatedFigureController, EpochSelectionsObject, ClickActionCallbacks\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import co_filter_epochs_and_spikes, get_proper_global_spikes_df\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.ContainerBased.TemplateDebugger import TemplateDebugger\n",
    "\n",
    "# from neuropy.utils.matplotlib_helpers import get_heatmap_cmap\n",
    "# from pyphocorehelpers.gui.Qt.color_helpers import ColormapHelpers, ColorFormatConverter\n",
    "# from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import FixedCustomColormaps\n",
    "# from pyphoplacecellanalysis.GUI.Qt.Widgets.ThinButtonBar.ThinButtonBarWidget import ThinButtonBarWidget\n",
    "# from pyphoplacecellanalysis.GUI.Qt.Widgets.PaginationCtrl.PaginationControlWidget import PaginationControlWidget, PaginationControlWidgetState\n",
    "from neuropy.core.user_annotations import UserAnnotationsManager\n",
    "from pyphoplacecellanalysis.Resources import GuiResources, ActionIcons, silx_resources_rc\n",
    "from neuropy.utils.indexing_helpers import flatten, NumpyHelpers, PandasHelpers\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicThresholdFiltering\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _plot_heuristic_evaluation_epochs\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_filter_replay_epochs\n",
    "\n",
    "\n",
    "should_only_include_user_selected_epochs = False\n",
    "# should_only_include_user_selected_epochs = True\n",
    "\n",
    "# required_min_percentage_of_active_cells: float = 0.33333333 ## default\n",
    "required_min_percentage_of_active_cells: float = 0.20 # min_num_unique_aclu_inclusions: 10\n",
    "\n",
    "force_refilter = False\n",
    "# force_refilter = True\n",
    "\n",
    "needs_refilter = False\n",
    "try:\n",
    "    filtered_decoder_filter_epochs_decoder_result_dict\n",
    "    filtered_epochs_df\n",
    "    filtered_ripple_all_epoch_bins_marginals_df\n",
    "    if filtered_decoder_filter_epochs_decoder_result_dict is not None:\n",
    "        needs_refilter = False\n",
    "except NameError:\n",
    "    needs_refilter = True\n",
    "    \n",
    "if needs_refilter or force_refilter:\n",
    "    filtered_epochs_df, filtered_decoder_filter_epochs_decoder_result_dict, filtered_ripple_all_epoch_bins_marginals_df = _perform_filter_replay_epochs(curr_active_pipeline, global_epoch_name, track_templates, decoder_ripple_filter_epochs_decoder_result_dict, ripple_all_epoch_bins_marginals_df, ripple_decoding_time_bin_size=ripple_decoding_time_bin_size, should_only_include_user_selected_epochs=should_only_include_user_selected_epochs)\n",
    "\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "# directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=required_min_percentage_of_active_cells, debug_print=False) # min_num_unique_aclu_inclusions: 16 seems too high\n",
    "directional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=required_min_percentage_of_active_cells, debug_print=False) # min_num_unique_aclu_inclusions: 16 seems too high\n",
    "\n",
    "# for k, v in filtered_decoder_filter_epochs_decoder_result_dict.items():\n",
    "# \tdirectional_decoders_epochs_decode_result.add_all_extra_epoch_columns(curr_active_pipeline, track_templates=track_templates, required_min_percentage_of_active_cells=required_min_percentage_of_active_cells, debug_print=False)\n",
    "\n",
    "\n",
    "## INPUTS: directional_decoders_epochs_decode_result, filtered_epochs_df\n",
    "decoder_ripple_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "unfiltered_epochs_df = deepcopy(decoder_ripple_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)\n",
    "filtered_decoder_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(filtered_epochs_df[['start', 'stop']].to_numpy()) for a_name, a_result in decoder_ripple_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "\n",
    "ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "print(f'{pos_bin_size = }, {ripple_decoding_time_bin_size = }')\n",
    "\n",
    "## OUTPUTS: unfiltered_epochs_df, decoder_ripple_filter_epochs_decoder_result_dict\n",
    "## OUTPUTS: filtered_epochs_df, filtered_decoder_filter_epochs_decoder_result_dict\n",
    "\n",
    "# posterior_heatmap_imshow_kwargs = {'cmap': orange_posterior_cmap}\n",
    "\n",
    "## pos_bin_size = 4.877453969028168, ripple_decoding_time_bin_size = 0.016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "174b423e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for global computations: Performing run_specific_computations_single_context(..., computation_functions_name_includelist=['directional_decoders_evaluate_epochs'], ...)...\n",
      "\trun_specific_computations_single_context(including only 1 out of 16 registered computation functions): active_computation_functions: [<function DirectionalPlacefieldGlobalComputationFunctions._decode_and_evaluate_epochs_using_directional_decoders at 0x000001F0632CDA60>]...\n",
      "Performing _execute_computation_functions(...) with 1 registered_computation_functions...\n",
      "Executing [0/1]: <function DirectionalPlacefieldGlobalComputationFunctions._decode_and_evaluate_epochs_using_directional_decoders at 0x000001F019DA1EE0>\n",
      "laps_decoding_time_bin_size: 0.025, ripple_decoding_time_bin_size: 0.025, pos_bin_size: 4.877453969028168\n",
      "laps_decoding_time_bin_size: 0.025, ripple_decoding_time_bin_size: 0.025, pos_bin_size: 4.877453969028168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pho\\repos\\Spike3DWorkEnv\\pyPhoPlaceCellAnalysis\\src\\pyphoplacecellanalysis\\Analysis\\Decoder\\reconstruction.py:374: RuntimeWarning: invalid value encountered in divide\n",
      "  posterior /= np.sum(posterior, axis=0) # C(tau, n) = np.sum(posterior, axis=0): normalization condition mentioned in eqn 36 to convert to P_x_given_n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 4.877453969028168)\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 4.877453969028168)\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 4.877453969028168)\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 4.877453969028168)\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 4.877453969028168)\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 4.877453969028168)\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 4.877453969028168)\n",
      "neighbours will be calculated from margin and pos_bin_size. n_neighbours: 1 = int(margin: 4.0 / pos_bin_size: 4.877453969028168)\n",
      "Performance: Radon Transform:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 31/74\n",
      "\tagreeing_rows_ratio: 0.4189189189189189\n",
      "\tPerformance: Ripple: Radon Transform:\n",
      "agreeing_rows_count/num_total_epochs: 50/133\n",
      "\tagreeing_rows_ratio: 0.37593984962406013\n",
      "Performance: WCorr:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 37/74\n",
      "\tagreeing_rows_ratio: 0.5\n",
      "Performance: Ripple: WCorr\n",
      "agreeing_rows_count/num_total_epochs: 49/133\n",
      "\tagreeing_rows_ratio: 0.3684210526315789\n",
      "Performance: Simple PF PearsonR:\n",
      "\tLaps:\n",
      "agreeing_rows_count/num_total_epochs: 23/74\n",
      "\tagreeing_rows_ratio: 0.3108108108108108\n",
      "Performance: Ripple: Simple PF PearsonR\n",
      "agreeing_rows_count/num_total_epochs: 50/133\n",
      "\tagreeing_rows_ratio: 0.37593984962406013\n",
      "\t all computations complete! (Computed 1 with no errors!.\n"
     ]
    }
   ],
   "source": [
    "# directional_decoders_evaluate_epochs\n",
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_evaluate_epochs'], computation_kwargs_list=[{'should_skip_radon_transform': False}], enabled_filter_names=None, fail_on_exception=True, debug_print=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c43059e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_bin_size = 4.877453969028168, active_decoding_time_bin_size = 0.025\n",
      "min_num_unique_aclu_inclusions: 8\n",
      "target_height: 930.0,   desired_final_height = 930\n",
      "target_height: 930.0,   desired_final_height = 930\n",
      "target_height: 930.0,   desired_final_height = 930\n",
      "target_height: 930.0,   desired_final_height = 930\n",
      "PhoDockAreaContainingWindow.GlobalConnectionManagerAccessingMixin_on_setup()\n",
      "PhoDockAreaContainingWindow.try_register_any_control_widgets()\n",
      "\tflat_widgets_list contains 0 items\n",
      "WARN: no text box yet. err: 'ThinButtonBarWidget' object has no attribute 'ui'\n",
      "self.ui.buttons_dict.keys(): ['Refresh', 'Clipboard', 'Copy Selections', 'Load Selections from Annotations', 'Printer', 'Brush', 'Pencil', 'Eraser']\n",
      "is_spacer_visible: False\n",
      "WARN: no text box yet. err: 'ThinButtonBarWidget' object has no attribute 'ui'\n",
      "self.ui.buttons_dict.keys(): ['Refresh', 'Clipboard', 'Copy Selections', 'Load Selections from Annotations', 'Printer', 'Brush', 'Pencil', 'Eraser']\n",
      "is_spacer_visible: False\n",
      "WARN: no text box yet. err: 'ThinButtonBarWidget' object has no attribute 'ui'\n",
      "self.ui.buttons_dict.keys(): ['Refresh', 'Clipboard', 'Copy Selections', 'Load Selections from Annotations', 'Printer', 'Brush', 'Pencil', 'Eraser']\n",
      "is_spacer_visible: False\n",
      "WARN: no text box yet. err: 'ThinButtonBarWidget' object has no attribute 'ui'\n",
      "self.ui.buttons_dict.keys(): ['Refresh', 'Clipboard', 'Copy Selections', 'Load Selections from Annotations', 'Printer', 'Brush', 'Pencil', 'Eraser']\n",
      "is_spacer_visible: False\n",
      "WARN: no text box yet. err: 'ThinButtonBarWidget' object has no attribute 'ui'\n",
      "self.ui.buttons_dict.keys(): ['Refresh', 'Clipboard', 'Copy Selections', 'Load Selections from Annotations', 'Printer', 'Brush', 'Pencil', 'Eraser']\n",
      "is_spacer_visible: False\n",
      "Middle-click any epoch to adjust the Attached Raster Window to that epoch.\n",
      "included_neuron_ids: [ 2  4  5  7  9 10 11 12 14 15 16 17 18 19 20 21 23 24 25 26 27 31 32 35 37 39 40 41 43 44 45 46 49 50 52 53], n_neurons: 36\n",
      "unit_sort_order: [ 2 16  7 20 10 23  4  8  5  6  9 17  0 12 19  3  1 18 15 21 14 13 11 22]\n",
      "desired_sort_arr: [ 7 40 20 45 24 52 15 21 18 19 23 41  4 27 44 10  5 43 37 46 35 32 26 50]\n",
      "WARN: len(neuron_colors): 36 > n_cells: 24: restricting neuron_colors to the correct aclus, but if colors ever get off this is where it is happening!\n",
      "merged_kwargs: {'name': 'spikeRasterOverviewWindowScatterPlotItem', 'pxMode': True, 'symbol': <PyQt5.QtGui.QPainterPath object at 0x000001EF2CE65A50>, 'size': 2, 'pen': {'color': 'w', 'width': 1}, 'hoverable': True}\n",
      "unit_sort_order: [ 6 21 18  2  1  0 15 10  4 20  3  5 17  8 13  7 24 19 16  9 25 22 14 23 12 11]\n",
      "desired_sort_arr: [14 45 40  9  5  2 35 21 11 44 10 12 39 17 27 16 52 41 37 18 53 49 31 50 26 25]\n",
      "WARN: len(neuron_colors): 36 > n_cells: 26: restricting neuron_colors to the correct aclus, but if colors ever get off this is where it is happening!\n",
      "merged_kwargs: {'name': 'spikeRasterOverviewWindowScatterPlotItem', 'pxMode': True, 'symbol': <PyQt5.QtGui.QPainterPath object at 0x000001F145B16F90>, 'size': 2, 'pen': {'color': 'w', 'width': 1}, 'hoverable': True}\n",
      "unit_sort_order: [ 2 20 16  7  4  8  6 10  0  9 23  3 19 12 17 21 13 14  1 18 15 11  5 22]\n",
      "desired_sort_arr: [ 7 45 40 20 15 21 19 24  4 23 52 10 44 27 41 46 32 35  5 43 37 26 18 50]\n",
      "WARN: len(neuron_colors): 36 > n_cells: 24: restricting neuron_colors to the correct aclus, but if colors ever get off this is where it is happening!\n",
      "merged_kwargs: {'name': 'spikeRasterOverviewWindowScatterPlotItem', 'pxMode': True, 'symbol': <PyQt5.QtGui.QPainterPath object at 0x000001F15AB79900>, 'size': 2, 'pen': {'color': 'w', 'width': 1}, 'hoverable': True}\n",
      "unit_sort_order: [ 0 21  6 18 24  2 20 10  4 25  5  3 17  8  7 19 13 15 16 22  1 14  9 11 12 23]\n",
      "desired_sort_arr: [ 2 45 14 40 52  9 44 21 11 53 12 10 39 17 16 41 27 35 37 49  5 31 18 25 26 50]\n",
      "WARN: len(neuron_colors): 36 > n_cells: 26: restricting neuron_colors to the correct aclus, but if colors ever get off this is where it is happening!\n",
      "merged_kwargs: {'name': 'spikeRasterOverviewWindowScatterPlotItem', 'pxMode': True, 'symbol': <PyQt5.QtGui.QPainterPath object at 0x000001F065CC5E40>, 'size': 2, 'pen': {'color': 'w', 'width': 1}, 'hoverable': True}\n",
      "PhoDockAreaContainingWindow.GlobalConnectionManagerAccessingMixin_on_setup()\n",
      "PhoDockAreaContainingWindow.try_register_any_control_widgets()\n",
      "\tflat_widgets_list contains 0 items\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: the selected spikes did not work properly, so none will be shown.\n",
      "WARNING: 'NoneType' object has no attribute 'copy'\n",
      "moving RankOrderRastersDebugger attached window into main window dock...\n",
      "active_session_configuration_name: \"None\", active_session_configuration_context: format_name:kdiba|animal:gor01|exper_name:one|session_name:2006-6-12_15-55-31\n",
      "WARN: 2023-12-11 - enable_pf_peak_indicator_lines is not yet implemented and the lines are not correctly aligned.\n",
      "PhoDockAreaContainingWindow.GlobalConnectionManagerAccessingMixin_on_setup()\n",
      "PhoDockAreaContainingWindow.try_register_any_control_widgets()\n",
      "\tflat_widgets_list contains 0 items\n",
      "._subfn_buildUI_directional_template_debugger_data(...)\n",
      "np.shape(curr_data): (24, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "np.shape(out_colors_heatmap_image_matrix): (24, 59, 4)\n",
      "np.shape(curr_data): (26, 59), np.nanmax(curr_data): 0.16871442757882205, np.nanmin(curr_data): 0.0\n",
      "np.shape(out_colors_heatmap_image_matrix): (26, 59, 4)\n",
      "np.shape(curr_data): (24, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "np.shape(out_colors_heatmap_image_matrix): (24, 59, 4)\n",
      "np.shape(curr_data): (26, 59), np.nanmax(curr_data): 0.18913760071074082, np.nanmin(curr_data): 0.0\n",
      "np.shape(out_colors_heatmap_image_matrix): (26, 59, 4)\n",
      "using overriden dock location.\n",
      "done init\n",
      "params_kwargs: {'max_subplots_per_page': 10, 'scrollable_figure': False, 'use_AnchoredCustomText': False, 'should_suppress_callback_exceptions': False, 'isPaginatorControlWidgetBackedMode': True, 'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True, 'debug_print': True, 'skip_plotting_measured_positions': True, 'enable_decoded_most_likely_position_curve': False, 'enable_decoded_sequence_and_heuristics_curve': False, 'show_pre_merged_debug_sequences': False, 'show_heuristic_criteria_filter_epoch_inclusion_status': False, 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': False, 'enable_weighted_corr_data_provider_modify_axes_rect': False, 'enable_marginal_labels': True, 'marginal_y_bin_labels': ['long', 'short'], 'skip_plotting_most_likely_positions': True}\n",
      "moving yellow-blue marginals attached window into main window dock...\n",
      "WARN: no text box yet. err: 'ThinButtonBarWidget' object has no attribute 'ui'\n",
      "self.ui.buttons_dict.keys(): ['Refresh', 'Clipboard', 'Copy Selections', 'Load Selections from Annotations', 'Printer', 'Brush', 'Pencil', 'Eraser']\n",
      "is_spacer_visible: False\n",
      "add_data_overlays(...): decoder_track_length is None so skipping heuristics plotting\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import FixedCustomColormaps\n",
    "\n",
    "## INPUTS: included_ripple_start_times\n",
    "# 1D_search (only for start times):\n",
    "# matching_specific_start_ts_only_filtered_decoder_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(included_ripple_start_times) for a_name, a_result in filtered_decoder_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "# matching_specific_start_ts_only_filtered_decoder_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = {a_name:deepcopy(a_result) for a_name, a_result in filtered_decoder_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "# # matching_specific_start_ts_only_filtered_decoder_filter_epochs_decoder_result_dict\n",
    "# matching_specific_start_ts_only_filter_epochs_df = deepcopy(matching_specific_start_ts_only_filtered_decoder_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)\n",
    "# matching_specific_start_ts_only_filter_epochs_df\n",
    "\n",
    "# # 2024-03-04 - Filter out the epochs based on the criteria:\n",
    "\n",
    "active_spikes_df = get_proper_global_spikes_df(curr_active_pipeline)\n",
    "# active_min_num_unique_aclu_inclusions_requirement: int = track_templates.min_num_unique_aclu_inclusions_requirement(curr_active_pipeline, required_min_percentage_of_active_cells=0.333333333)\n",
    "# matching_specific_start_ts_only_filter_epochs_df, active_spikes_df = co_filter_epochs_and_spikes(active_spikes_df=active_spikes_df, active_epochs_df=matching_specific_start_ts_only_filter_epochs_df, included_aclus=track_templates.any_decoder_neuron_IDs, min_num_unique_aclu_inclusions=active_min_num_unique_aclu_inclusions_requirement, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1, add_unique_aclus_list_column=True, drop_non_epoch_spikes=True)\n",
    "# filtered_epochs_ripple_simple_pf_pearson_merged_df, active_spikes_df = co_filter_epochs_and_spikes(active_spikes_df=active_spikes_df, active_epochs_df=ripple_simple_pf_pearson_merged_df, included_aclus=track_templates.any_decoder_neuron_IDs, min_num_unique_aclu_inclusions=active_min_num_unique_aclu_inclusions_requirement, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1, add_unique_aclus_list_column=True, drop_non_epoch_spikes=True)\n",
    "# matching_specific_start_ts_only_filter_epochs_df, active_spikes_df = co_filter_epochs_and_spikes(active_spikes_df=active_spikes_df, active_epochs_df=matching_specific_start_ts_only_filter_epochs_df, included_aclus=track_templates.any_decoder_neuron_IDs, min_num_unique_aclu_inclusions=active_min_num_unique_aclu_inclusions_requirement, epoch_id_key_name='ripple_epoch_id', no_interval_fill_value=-1, add_unique_aclus_list_column=True, drop_non_epoch_spikes=True)\n",
    "\n",
    "# filtered_epochs_ripple_simple_pf_pearson_merged_df\n",
    "\n",
    "# ## INPUTS: directional_decoders_epochs_decode_result, filtered_epochs_df\n",
    "# decoder_ripple_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "# unfiltered_epochs_df = deepcopy(decoder_ripple_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)\n",
    "# filtered_decoder_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(filtered_epochs_df[['start', 'stop']].to_numpy()) for a_name, a_result in decoder_ripple_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "\n",
    "## INPUTS: filtered_decoder_filter_epochs_decoder_result_dict\n",
    "\n",
    "pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "\n",
    "\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# BEGIN FCN BODY                                                                                                       #\n",
    "# ==================================================================================================================== #\n",
    "## INPUTS filtered_decoder_filter_epochs_decoder_result_dict\n",
    "# decoder_decoded_epochs_result_dict: generic\n",
    "active_cmap = FixedCustomColormaps.get_custom_greyscale_with_low_values_dropped_cmap(low_value_cutoff=0.01, full_opacity_threshold=0.25)\n",
    "\n",
    "# Replay/PBEs ________________________________________________________________________________________________________ #\n",
    "active_decoder_decoded_epochs_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(filtered_decoder_filter_epochs_decoder_result_dict)\n",
    "active_filter_epochs_df: pd.DataFrame = deepcopy(active_decoder_decoded_epochs_result_dict['long_LR'].filter_epochs) # deepcopy(matching_specific_start_ts_only_filter_epochs_df)\n",
    "epochs_name='ripple'\n",
    "title='Filtered PBEs'\n",
    "known_epochs_type = 'ripple'\n",
    "ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "active_decoding_time_bin_size: float = ripple_decoding_time_bin_size\n",
    "\n",
    "\n",
    "# # Laps _______________________________________________________________________________________________________________ #\n",
    "# ## INPUTS: decoder_laps_filter_epochs_decoder_result_dict, \n",
    "# active_decoder_decoded_epochs_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(decoder_laps_filter_epochs_decoder_result_dict)\n",
    "# active_filter_epochs_df: pd.DataFrame = deepcopy(active_decoder_decoded_epochs_result_dict['long_LR'].filter_epochs) # deepcopy(matching_specific_start_ts_only_filter_epochs_df)\n",
    "# epochs_name='laps'\n",
    "# title='Laps'\n",
    "# known_epochs_type = 'laps'\n",
    "# laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "# active_decoding_time_bin_size: float = laps_decoding_time_bin_size\n",
    "\n",
    "print(f'{pos_bin_size = }, {active_decoding_time_bin_size = }')\n",
    "## INPUTS: active_decoder_decoded_epochs_result_dict, active_filter_epochs_df, directional_decoders_epochs_decode_result, curr_active_pipeline, track_templates, active_spikes_df\n",
    "\n",
    "active_spikes_df = get_proper_global_spikes_df(curr_active_pipeline)\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations'] ## GENERAL\n",
    "(app, paginated_multi_decoder_decoded_epochs_window, pagination_controller_dict), ripple_rasters_plot_tuple, yellow_blue_trackID_marginals_plot_tuple = PhoPaginatedMultiDecoderDecodedEpochsWindow.plot_full_paginated_decoded_epochs_window(curr_active_pipeline=curr_active_pipeline, track_templates=track_templates, active_spikes_df=active_spikes_df,\n",
    "                                                                                                                                                                                                   active_decoder_decoded_epochs_result_dict=deepcopy(active_decoder_decoded_epochs_result_dict), # epochs_name='ripple',\n",
    "                                                                                                                                                                                                   directional_decoders_epochs_decode_result=deepcopy(directional_decoders_epochs_decode_result),\n",
    "                                                                                                                                                                                                   active_filter_epochs_df=active_filter_epochs_df, known_epochs_type=known_epochs_type, title=title,\n",
    "                                                                                                params_kwargs={'enable_per_epoch_action_buttons': False,\n",
    "                                                                                                    'skip_plotting_most_likely_positions': True, 'skip_plotting_measured_positions': True, \n",
    "                                                                                                    'enable_decoded_most_likely_position_curve': False, \n",
    "                                                                                                    'enable_decoded_sequence_and_heuristics_curve': True, 'show_pre_merged_debug_sequences': False, 'show_heuristic_criteria_filter_epoch_inclusion_status': True,\n",
    "                                                                                                     'enable_radon_transform_info': False, 'enable_weighted_correlation_info': True, 'enable_weighted_corr_data_provider_modify_axes_rect': False,\n",
    "                                                                                                    # 'enable_radon_transform_info': False, 'enable_weighted_correlation_info': False,\n",
    "                                                                                                    # 'disable_y_label': True,\n",
    "                                                                                                    'isPaginatorControlWidgetBackedMode': True,\n",
    "                                                                                                    'enable_update_window_title_on_page_change': False, 'build_internal_callbacks': True,\n",
    "                                                                                                    # 'debug_print': True,\n",
    "                                                                                                    'max_subplots_per_page': 9,\n",
    "                                                                                                    # 'scrollable_figure': False,\n",
    "                                                                                                    'scrollable_figure': True,\n",
    "                                                                                                    # 'posterior_heatmap_imshow_kwargs': dict(vmin=0.0075),\n",
    "                                                                                                    'use_AnchoredCustomText': False,\n",
    "                                                                                                    'should_suppress_callback_exceptions': False,\n",
    "                                                                                                    # 'build_fn': 'insets_view',\n",
    "                                                                                                    'track_length_cm_dict': deepcopy(track_templates.get_track_length_dict()),\n",
    "                                                                                                    'posterior_heatmap_imshow_kwargs': dict(cmap=active_cmap), # , vmin=0.1, vmax=1.0\n",
    "                                                                                                    'data_overlay_heuristic_kwargs': dict(same_thresh_fraction_of_track=0.001, max_jump_distance_cm=360.0, max_ignore_bins=25),\n",
    "                                                                                                })\n",
    "attached_yellow_blue_marginals_viewer_widget: DecodedEpochSlicesPaginatedFigureController = paginated_multi_decoder_decoded_epochs_window.attached_yellow_blue_marginals_viewer_widget\n",
    "attached_ripple_rasters_widget: RankOrderRastersDebugger = paginated_multi_decoder_decoded_epochs_window.attached_ripple_rasters_widget\n",
    "attached_directional_template_pfs_debugger: TemplateDebugger = paginated_multi_decoder_decoded_epochs_window.attached_directional_template_pfs_debugger\n",
    "\n",
    "## OUTPUTS: directional_merged_decoders_result\n",
    "# user_interactivity_instructions_dict = {'left-click':'toggle is_good annotation', 'right-click':'select epoch row', 'MMB click':'get clicked time to clipboard'}\n",
    "# user_interactivity_instructions_message: str = ', '.join([f'{k}:{v}' for k, v in user_interactivity_instructions_dict.items()])\n",
    "# print(f'user_interactivity_instructions_message: \"{user_interactivity_instructions_message}\"')\n",
    "# paginated_multi_decoder_decoded_epochs_window.show_message(user_interactivity_instructions_message, durationMs=4000)\n",
    "\n",
    "# add_data_overlays(...): decoder_track_length is None so skipping heuristics plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f91bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paginated_multi_decoder_decoded_epochs_window.attached_yellow_blue_marginals_viewer_widget.plots_data.all_attributes # ['name', 'epoch_slices', 'global_pos_df', 'filter_epochs_decoder_result', 'active_marginal_fn', 'paginator', 'highlighted_epoch_time_bin_idx', 'decoded_position_curves_data', 'marginal_labels_data']\n",
    "\n",
    "filter_epochs_decoder_result: DecodedFilterEpochsResult = paginated_multi_decoder_decoded_epochs_window.attached_yellow_blue_marginals_viewer_widget.plots_data.filter_epochs_decoder_result\n",
    "filter_epochs_decoder_result.nbins\n",
    "filter_epochs: pd.DataFrame = deepcopy(filter_epochs_decoder_result.filter_epochs)\n",
    "filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4ae8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_epochs['n_time_bins'] = filter_epochs_decoder_result.nbins\n",
    "filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea0292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_epochs['est_n_t_bins'] = filter_epochs['duration'] / 0.025\n",
    "filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6f9c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_epochs[filter_epochs['label'] == '370']\n",
    "\n",
    "\n",
    "# filter_epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0155968",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_epochs[filter_epochs['start'] > 1505.164]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fea1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_add_data_overlays = paginated_multi_decoder_decoded_epochs_window.add_data_overlays()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a9c497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import SubsequencesPartitioningResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.DecoderPredictionError import DecodedSequenceAndHeuristicsPlotData\n",
    "\n",
    "decoded_sequence_and_heuristics_curves_data_dict: Dict[types.DecoderName, Dict[float, DecodedSequenceAndHeuristicsPlotData]] = paginated_multi_decoder_decoded_epochs_window.get_children_props(prop_path='plots_data.decoded_sequence_and_heuristics_curves_data')\n",
    "decoded_sequence_and_heuristics_partition_results_dict: Dict[types.DecoderName, Dict[float, SubsequencesPartitioningResult]] = {a_name:{k:v.partition_result for k, v in a_data_dict.items()} for a_name, a_data_dict in decoded_sequence_and_heuristics_curves_data_dict.items()}\n",
    "# decoded_sequence_and_heuristics_curves_data_dict\n",
    "decoded_sequence_and_heuristics_partition_results_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c285e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_sequence_and_heuristics_curves_data_dict ## OUTPUT\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb39e357",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.get_children_props(prop_path='params.data_overlay_heuristic_kwargs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046f2b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "paginated_multi_decoder_decoded_epochs_window.set_children_props(prop_path='params.data_overlay_heuristic_kwargs', value=dict(same_thresh_fraction_of_track=0.005, max_jump_distance_cm=360.0, max_ignore_bins=22))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952d4716",
   "metadata": {},
   "source": [
    "# 🖼️ `export_current_epoch_marginal_and_raster_images` to export rasters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8838a34b",
   "metadata": {},
   "source": [
    "#### Batch (all) epochs export via `export_current_epoch_marginal_and_raster_images`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a2a64ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing an_epoch_idx: 0/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 0)\n",
      "an_epoch: EpochTuple(Index=0, start=5.696836763177998, stop=5.758983291336335, label=0, duration=0.06214652815833688, end=5.758983291336335, score=0.41367333393522127, velocity=-292.64723814169133, intercept=-1439.142571836027, speed=292.64723814169133, wcorr=0.6607759741187557, P_decoder=nan, pearsonr=0.7759962659670695, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-650.3679721148219, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([20, 39, 49, 15, 18, 43, 37, 52, 32]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=0, start=5.696836763177998, stop=5.758983291336335, label=0, duration=0.06214652815833688, end=5.758983291336335, score=0.41367333393522127, velocity=-292.64723814169133, intercept=-1439.142571836027, speed=292.64723814169133, wcorr=0.6607759741187557, P_decoder=nan, pearsonr=0.7759962659670695, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-650.3679721148219, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([20, 39, 49, 15, 18, 43, 37, 52, 32]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=0, start=5.696836763177998, stop=5.758983291336335, label=0, duration=0.06214652815833688, end=5.758983291336335, score=0.41367333393522127, velocity=-292.64723814169133, intercept=-1439.142571836027, speed=292.64723814169133, wcorr=0.6607759741187557, P_decoder=nan, pearsonr=0.7759962659670695, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-650.3679721148219, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([20, 39, 49, 15, 18, 43, 37, 52, 32]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=0, start=5.696836763177998, stop=5.758983291336335, label=0, duration=0.06214652815833688, end=5.758983291336335, score=0.41367333393522127, velocity=-292.64723814169133, intercept=-1439.142571836027, speed=292.64723814169133, wcorr=0.6607759741187557, P_decoder=nan, pearsonr=0.7759962659670695, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-650.3679721148219, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([20, 39, 49, 15, 18, 43, 37, 52, 32]), n_unique_aclus=9)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.13026806747808126, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (5, 59), np.nanmax(curr_data): 0.12755996431569847, np.nanmin(curr_data): 5.18228279931823e-08\n",
      "n_total_cells: 5\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.1490508567103094, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (5, 59), np.nanmax(curr_data): 0.15153529453505524, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 5\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_000\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_000\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_000\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_000\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[0][\"p_x_given_n\"]): (59, 4, 3)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.13287 0.508921 0.119757 0.238452]\n",
      "\t_long_any: 0.35820866983603067, _short_any: 0.6417913301639694\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_000/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_000'\n",
      "processing an_epoch_idx: 1/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 1)\n",
      "an_epoch: EpochTuple(Index=1, start=96.86656160431448, stop=97.25759628403466, label=2, duration=0.39103467972017825, end=97.25759628403466, score=0.3336768701503188, velocity=-13.006543917408484, intercept=-1018.6277979669442, speed=13.006543917408484, wcorr=0.03485232843892751, P_decoder=nan, pearsonr=0.08811047374890134, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-559.1982472736854, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([24, 32, 23, 18, 26, 31,  2, 50, 43, 49, 52, 19, 27, 39]), n_unique_aclus=14)\n",
      "an_epoch: EpochTuple(Index=1, start=96.86656160431448, stop=97.25759628403466, label=2, duration=0.39103467972017825, end=97.25759628403466, score=0.3336768701503188, velocity=-13.006543917408484, intercept=-1018.6277979669442, speed=13.006543917408484, wcorr=0.03485232843892751, P_decoder=nan, pearsonr=0.08811047374890134, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-559.1982472736854, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([24, 32, 23, 18, 26, 31,  2, 50, 43, 49, 52, 19, 27, 39]), n_unique_aclus=14)\n",
      "an_epoch: EpochTuple(Index=1, start=96.86656160431448, stop=97.25759628403466, label=2, duration=0.39103467972017825, end=97.25759628403466, score=0.3336768701503188, velocity=-13.006543917408484, intercept=-1018.6277979669442, speed=13.006543917408484, wcorr=0.03485232843892751, P_decoder=nan, pearsonr=0.08811047374890134, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-559.1982472736854, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([24, 32, 23, 18, 26, 31,  2, 50, 43, 49, 52, 19, 27, 39]), n_unique_aclus=14)\n",
      "an_epoch: EpochTuple(Index=1, start=96.86656160431448, stop=97.25759628403466, label=2, duration=0.39103467972017825, end=97.25759628403466, score=0.3336768701503188, velocity=-13.006543917408484, intercept=-1018.6277979669442, speed=13.006543917408484, wcorr=0.03485232843892751, P_decoder=nan, pearsonr=0.08811047374890134, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-559.1982472736854, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([24, 32, 23, 18, 26, 31,  2, 50, 43, 49, 52, 19, 27, 39]), n_unique_aclus=14)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (10, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 10\n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.14933925445043028, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (10, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 10\n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.18913760071074082, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_002\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_002\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_002\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_002\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[2][\"p_x_given_n\"]): (59, 4, 16)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0297171 0 0.970283 0]\n",
      "\t_long_any: 0.9702829362553985, _short_any: 0.029717063744601185\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.60101 0 0.39899 0]\n",
      "\t_long_any: 0.39898972537941546, _short_any: 0.601010274620585\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.171602 0.562345 0.137941 0.128112]\n",
      "\t_long_any: 0.2660532503894745, _short_any: 0.7339467496105261\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.197457 0.560387 0.196893 0.0452626]\n",
      "\t_long_any: 0.24215581762848792, _short_any: 0.7578441823715119\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.10908 0.115552 0.157043 0.618326]\n",
      "\t_long_any: 0.7753683204822507, _short_any: 0.22463167951774907\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.190803 0.0378431 0.69328 0.0780738]\n",
      "\t_long_any: 0.7713537108433582, _short_any: 0.22864628915664148\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.249456 0.0446697 0.658256 0.0476181]\n",
      "\t_long_any: 0.7058740727893297, _short_any: 0.29412592721067016\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.171602 0.562345 0.137941 0.128112]\n",
      "\t_long_any: 0.2660532503894745, _short_any: 0.7339467496105261\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.15016 0.554904 0.0462999 0.248636]\n",
      "\t_long_any: 0.29493631842043955, _short_any: 0.7050636815795602\n",
      "i: 10, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 11, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.521021 0 0.478979 0]\n",
      "\t_long_any: 0.4789791361740097, _short_any: 0.5210208638259903\n",
      "i: 12, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.505606 0 0.494394 0]\n",
      "\t_long_any: 0.494393861745059, _short_any: 0.5056061382549412\n",
      "i: 13, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 14, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.296986 0.36977 0.241552 0.0916925]\n",
      "\t_long_any: 0.3332440851831773, _short_any: 0.6667559148168228\n",
      "i: 15, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.157475 0.409607 0.370439 0.0624794]\n",
      "\t_long_any: 0.43291848452631027, _short_any: 0.5670815154736897\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_002/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_002'\n",
      "processing an_epoch_idx: 2/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 2)\n",
      "an_epoch: EpochTuple(Index=2, start=121.20142786484212, stop=121.60690093727317, label=3, duration=0.40547307243105024, end=121.60690093727317, score=0.12044238737699428, velocity=-48.77453969028101, intercept=-5860.940268983805, speed=48.77453969028101, wcorr=-0.051843036979327316, P_decoder=0.37508631037510787, pearsonr=-0.09773200850909049, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-534.8633810131578, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([45, 40,  7, 19, 21, 24, 23, 18]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=2, start=121.20142786484212, stop=121.60690093727317, label=3, duration=0.40547307243105024, end=121.60690093727317, score=0.12044238737699428, velocity=-48.77453969028101, intercept=-5860.940268983805, speed=48.77453969028101, wcorr=-0.051843036979327316, P_decoder=0.37508631037510787, pearsonr=-0.09773200850909049, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-534.8633810131578, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([45, 40,  7, 19, 21, 24, 23, 18]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=2, start=121.20142786484212, stop=121.60690093727317, label=3, duration=0.40547307243105024, end=121.60690093727317, score=0.12044238737699428, velocity=-48.77453969028101, intercept=-5860.940268983805, speed=48.77453969028101, wcorr=-0.051843036979327316, P_decoder=0.37508631037510787, pearsonr=-0.09773200850909049, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-534.8633810131578, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([45, 40,  7, 19, 21, 24, 23, 18]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=2, start=121.20142786484212, stop=121.60690093727317, label=3, duration=0.40547307243105024, end=121.60690093727317, score=0.12044238737699428, velocity=-48.77453969028101, intercept=-5860.940268983805, speed=48.77453969028101, wcorr=-0.051843036979327316, P_decoder=0.37508631037510787, pearsonr=-0.09773200850909049, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-534.8633810131578, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([45, 40,  7, 19, 21, 24, 23, 18]), n_unique_aclus=8)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.10500114125474004, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (4, 59), np.nanmax(curr_data): 0.13918661674691393, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 4\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.14773746413841815, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (4, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 4\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_003\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_003\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_003\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_003\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[3][\"p_x_given_n\"]): (59, 4, 17)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.621891 0.0122324 0.360753 0.00512414]\n",
      "\t_long_any: 0.3658767436006062, _short_any: 0.6341232563993943\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.947638 0 0.0523619 0]\n",
      "\t_long_any: 0.05236189222552714, _short_any: 0.9476381077744722\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.600257 0 0.399743 0]\n",
      "\t_long_any: 0.39974334649657717, _short_any: 0.6002566535034224\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.43432 0 0.56568 0]\n",
      "\t_long_any: 0.5656803965582573, _short_any: 0.434319603441743\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.60101 0 0.39899 0]\n",
      "\t_long_any: 0.39898972537941546, _short_any: 0.601010274620585\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 10, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 11, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.589722 0 0.410278 0]\n",
      "\t_long_any: 0.4102783194084989, _short_any: 0.5897216805915015\n",
      "i: 12, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.489634 0 0.510366 0]\n",
      "\t_long_any: 0.5103664151631802, _short_any: 0.48963358483681974\n",
      "i: 13, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 14, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 15, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.646306 0.121921 0.0424546 0.189318]\n",
      "\t_long_any: 0.23177249962483015, _short_any: 0.7682275003751705\n",
      "i: 16, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.3885 0.225026 0.137701 0.248773]\n",
      "\t_long_any: 0.38647475361597433, _short_any: 0.6135252463840257\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_003/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_003'\n",
      "processing an_epoch_idx: 3/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 3)\n",
      "an_epoch: EpochTuple(Index=3, start=125.18313718622085, stop=125.29200881056022, label=4, duration=0.10887162433937192, end=125.29200881056022, score=0.2778537201302385, velocity=-390.1963175222757, intercept=-48814.29569515055, speed=390.1963175222757, wcorr=0.5709676474008923, P_decoder=0.7156806401104922, pearsonr=0.5148496629754991, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-530.881671691779, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([45,  9,  7, 40, 20, 19, 44, 52, 21]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=3, start=125.18313718622085, stop=125.29200881056022, label=4, duration=0.10887162433937192, end=125.29200881056022, score=0.2778537201302385, velocity=-390.1963175222757, intercept=-48814.29569515055, speed=390.1963175222757, wcorr=0.5709676474008923, P_decoder=0.7156806401104922, pearsonr=0.5148496629754991, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-530.881671691779, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([45,  9,  7, 40, 20, 19, 44, 52, 21]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=3, start=125.18313718622085, stop=125.29200881056022, label=4, duration=0.10887162433937192, end=125.29200881056022, score=0.2778537201302385, velocity=-390.1963175222757, intercept=-48814.29569515055, speed=390.1963175222757, wcorr=0.5709676474008923, P_decoder=0.7156806401104922, pearsonr=0.5148496629754991, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-530.881671691779, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([45,  9,  7, 40, 20, 19, 44, 52, 21]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=3, start=125.18313718622085, stop=125.29200881056022, label=4, duration=0.10887162433937192, end=125.29200881056022, score=0.2778537201302385, velocity=-390.1963175222757, intercept=-48814.29569515055, speed=390.1963175222757, wcorr=0.5709676474008923, P_decoder=0.7156806401104922, pearsonr=0.5148496629754991, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-530.881671691779, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([45,  9,  7, 40, 20, 19, 44, 52, 21]), n_unique_aclus=9)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.1146338264762386, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.13918661674691393, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.14773746413841815, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_004\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_004\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_004\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_004\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[4][\"p_x_given_n\"]): (59, 4, 5)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.621891 0.0122324 0.360753 0.00512414]\n",
      "\t_long_any: 0.3658767436006062, _short_any: 0.6341232563993943\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.995101 0 0.00489914 0]\n",
      "\t_long_any: 0.00489913862304192, _short_any: 0.9951008613769583\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.999439 0 0.000560533 0]\n",
      "\t_long_any: 0.0005605329438668441, _short_any: 0.9994394670561335\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.533828 0 0.466172 0]\n",
      "\t_long_any: 0.46617230963258083, _short_any: 0.5338276903674195\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.433296 0.215056 0.27909 0.0725591]\n",
      "\t_long_any: 0.3516485729942037, _short_any: 0.6483514270057958\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_004/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_004'\n",
      "processing an_epoch_idx: 4/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 4)\n",
      "an_epoch: EpochTuple(Index=4, start=125.77956568088848, stop=125.90484177670442, label=5, duration=0.12527609581593424, end=125.90484177670442, score=0.18552906428853377, velocity=-234.11779051335202, intercept=-29384.31485273819, speed=234.11779051335202, wcorr=0.21221767184803259, P_decoder=nan, pearsonr=-0.19771911605929635, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-530.2852431971114, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([43, 45,  2, 37, 49, 20, 15, 39, 24, 52, 31]), n_unique_aclus=11)\n",
      "an_epoch: EpochTuple(Index=4, start=125.77956568088848, stop=125.90484177670442, label=5, duration=0.12527609581593424, end=125.90484177670442, score=0.18552906428853377, velocity=-234.11779051335202, intercept=-29384.31485273819, speed=234.11779051335202, wcorr=0.21221767184803259, P_decoder=nan, pearsonr=-0.19771911605929635, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-530.2852431971114, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([43, 45,  2, 37, 49, 20, 15, 39, 24, 52, 31]), n_unique_aclus=11)\n",
      "an_epoch: EpochTuple(Index=4, start=125.77956568088848, stop=125.90484177670442, label=5, duration=0.12527609581593424, end=125.90484177670442, score=0.18552906428853377, velocity=-234.11779051335202, intercept=-29384.31485273819, speed=234.11779051335202, wcorr=0.21221767184803259, P_decoder=nan, pearsonr=-0.19771911605929635, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-530.2852431971114, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([43, 45,  2, 37, 49, 20, 15, 39, 24, 52, 31]), n_unique_aclus=11)\n",
      "an_epoch: EpochTuple(Index=4, start=125.77956568088848, stop=125.90484177670442, label=5, duration=0.12527609581593424, end=125.90484177670442, score=0.18552906428853377, velocity=-234.11779051335202, intercept=-29384.31485273819, speed=234.11779051335202, wcorr=0.21221767184803259, P_decoder=nan, pearsonr=-0.19771911605929635, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-530.2852431971114, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([43, 45,  2, 37, 49, 20, 15, 39, 24, 52, 31]), n_unique_aclus=11)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.1259578889736905, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.13918661674691393, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.1490508567103094, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.18913760071074082, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_005\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_005\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_005\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_005\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[5][\"p_x_given_n\"]): (59, 4, 6)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.833627 0 0.166373 0]\n",
      "\t_long_any: 0.16637316731327162, _short_any: 0.8336268326867289\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.489634 0 0.510366 0]\n",
      "\t_long_any: 0.5103664151631802, _short_any: 0.48963358483681974\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.00772194 0 0.992278]\n",
      "\t_long_any: 0.9922780562910312, _short_any: 0.007721943708968676\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.10908 0.115552 0.157043 0.618326]\n",
      "\t_long_any: 0.7753683204822507, _short_any: 0.22463167951774907\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_005/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_005'\n",
      "processing an_epoch_idx: 5/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 5)\n",
      "an_epoch: EpochTuple(Index=5, start=127.87251820927486, stop=128.2422946599545, label=6, duration=0.3697764506796375, end=128.2422946599545, score=0.23079840375018695, velocity=181.1625759924704, intercept=23282.59949790838, speed=181.1625759924704, wcorr=-0.2328903456643809, P_decoder=nan, pearsonr=-0.5056768107141933, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-528.192290668725, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([19, 21, 32, 52, 24, 45, 23,  4,  5, 44, 37, 46, 49, 18,  9, 50, 43, 26, 35, 15, 40, 17, 39, 20,  7]), n_unique_aclus=25)\n",
      "an_epoch: EpochTuple(Index=5, start=127.87251820927486, stop=128.2422946599545, label=6, duration=0.3697764506796375, end=128.2422946599545, score=0.23079840375018695, velocity=181.1625759924704, intercept=23282.59949790838, speed=181.1625759924704, wcorr=-0.2328903456643809, P_decoder=nan, pearsonr=-0.5056768107141933, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-528.192290668725, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([19, 21, 32, 52, 24, 45, 23,  4,  5, 44, 37, 46, 49, 18,  9, 50, 43, 26, 35, 15, 40, 17, 39, 20,  7]), n_unique_aclus=25)\n",
      "an_epoch: EpochTuple(Index=5, start=127.87251820927486, stop=128.2422946599545, label=6, duration=0.3697764506796375, end=128.2422946599545, score=0.23079840375018695, velocity=181.1625759924704, intercept=23282.59949790838, speed=181.1625759924704, wcorr=-0.2328903456643809, P_decoder=nan, pearsonr=-0.5056768107141933, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-528.192290668725, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([19, 21, 32, 52, 24, 45, 23,  4,  5, 44, 37, 46, 49, 18,  9, 50, 43, 26, 35, 15, 40, 17, 39, 20,  7]), n_unique_aclus=25)\n",
      "an_epoch: EpochTuple(Index=5, start=127.87251820927486, stop=128.2422946599545, label=6, duration=0.3697764506796375, end=128.2422946599545, score=0.23079840375018695, velocity=181.1625759924704, intercept=23282.59949790838, speed=181.1625759924704, wcorr=-0.2328903456643809, P_decoder=nan, pearsonr=-0.5056768107141933, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-528.192290668725, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([19, 21, 32, 52, 24, 45, 23,  4,  5, 44, 37, 46, 49, 18,  9, 50, 43, 26, 35, 15, 40, 17, 39, 20,  7]), n_unique_aclus=25)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (21, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 21\n",
      "np.shape(curr_data): (15, 59), np.nanmax(curr_data): 0.14933925445043028, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 15\n",
      "np.shape(curr_data): (21, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 21\n",
      "np.shape(curr_data): (15, 59), np.nanmax(curr_data): 0.16577466995625206, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 15\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_006\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_006\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_006\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_006\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[6][\"p_x_given_n\"]): (59, 4, 15)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.406443 0 0.593557 0]\n",
      "\t_long_any: 0.5935574130879633, _short_any: 0.40644258691203716\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.969624 0 0.0303761 0]\n",
      "\t_long_any: 0.030376090532915748, _short_any: 0.969623909467084\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.79816 0.0691538 0.0120775 0.120609]\n",
      "\t_long_any: 0.13268652832482908, _short_any: 0.8673134716751705\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.302043 0 0.697957 0]\n",
      "\t_long_any: 0.6979573809954874, _short_any: 0.30204261900451257\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.838546 0 0.161454 0]\n",
      "\t_long_any: 0.16145425511753264, _short_any: 0.8385457448824679\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0803479 0.858445 0.0155258 0.0456817]\n",
      "\t_long_any: 0.06120756285853399, _short_any: 0.9387924371414667\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.688047 0 0.311953 0]\n",
      "\t_long_any: 0.3119529556646654, _short_any: 0.6880470443353347\n",
      "i: 10, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 11, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 12, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 13, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 14, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.99502 0 0.0049799 0]\n",
      "\t_long_any: 0.00497990368300159, _short_any: 0.995020096316998\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_006/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_006'\n",
      "processing an_epoch_idx: 6/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 6)\n",
      "an_epoch: EpochTuple(Index=6, start=148.42179152811877, stop=148.62091846601106, label=9, duration=0.19912693789228797, end=148.62091846601106, score=0.216097824442588, velocity=-278.71165537302, intercept=-41177.707674146804, speed=278.71165537302, wcorr=0.29304624690922465, P_decoder=nan, pearsonr=0.5135795830151432, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-507.6430173498811, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([52, 40, 49, 27, 43, 20,  5, 46, 32, 16, 23]), n_unique_aclus=11)\n",
      "an_epoch: EpochTuple(Index=6, start=148.42179152811877, stop=148.62091846601106, label=9, duration=0.19912693789228797, end=148.62091846601106, score=0.216097824442588, velocity=-278.71165537302, intercept=-41177.707674146804, speed=278.71165537302, wcorr=0.29304624690922465, P_decoder=nan, pearsonr=0.5135795830151432, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-507.6430173498811, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([52, 40, 49, 27, 43, 20,  5, 46, 32, 16, 23]), n_unique_aclus=11)\n",
      "an_epoch: EpochTuple(Index=6, start=148.42179152811877, stop=148.62091846601106, label=9, duration=0.19912693789228797, end=148.62091846601106, score=0.216097824442588, velocity=-278.71165537302, intercept=-41177.707674146804, speed=278.71165537302, wcorr=0.29304624690922465, P_decoder=nan, pearsonr=0.5135795830151432, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-507.6430173498811, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([52, 40, 49, 27, 43, 20,  5, 46, 32, 16, 23]), n_unique_aclus=11)\n",
      "an_epoch: EpochTuple(Index=6, start=148.42179152811877, stop=148.62091846601106, label=9, duration=0.19912693789228797, end=148.62091846601106, score=0.216097824442588, velocity=-278.71165537302, intercept=-41177.707674146804, speed=278.71165537302, wcorr=0.29304624690922465, P_decoder=nan, pearsonr=0.5135795830151432, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-507.6430173498811, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([52, 40, 49, 27, 43, 20,  5, 46, 32, 16, 23]), n_unique_aclus=11)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.1306753907929282, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.12755996431569847, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.1490508567103094, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.15153529453505524, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_009\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_009\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_009\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_009\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[9][\"p_x_given_n\"]): (59, 4, 8)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.62784 0 0.37216 0]\n",
      "\t_long_any: 0.3721600032203538, _short_any: 0.6278399967796464\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.063261 0 0.936739]\n",
      "\t_long_any: 0.936738980074878, _short_any: 0.06326101992512245\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.011638 0 0.988362 0]\n",
      "\t_long_any: 0.9883620339175774, _short_any: 0.01163796608242227\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_009/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_009'\n",
      "processing an_epoch_idx: 7/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 7)\n",
      "an_epoch: EpochTuple(Index=7, start=153.5056724450551, stop=153.85087290836964, label=11, duration=0.3452004633145407, end=153.85087290836964, score=0.26664637201507946, velocity=-165.08305741326686, intercept=-25150.589843950216, speed=165.08305741326686, wcorr=0.142329118612986, P_decoder=0.47529334002702445, pearsonr=nan, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-502.5591364329448, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([ 5, 46, 10, 37, 23,  4, 21, 19, 45, 17, 41, 20,  7, 40, 24, 49, 43, 18, 31, 26, 50]), n_unique_aclus=21)\n",
      "an_epoch: EpochTuple(Index=7, start=153.5056724450551, stop=153.85087290836964, label=11, duration=0.3452004633145407, end=153.85087290836964, score=0.26664637201507946, velocity=-165.08305741326686, intercept=-25150.589843950216, speed=165.08305741326686, wcorr=0.142329118612986, P_decoder=0.47529334002702445, pearsonr=nan, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-502.5591364329448, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([ 5, 46, 10, 37, 23,  4, 21, 19, 45, 17, 41, 20,  7, 40, 24, 49, 43, 18, 31, 26, 50]), n_unique_aclus=21)\n",
      "an_epoch: EpochTuple(Index=7, start=153.5056724450551, stop=153.85087290836964, label=11, duration=0.3452004633145407, end=153.85087290836964, score=0.26664637201507946, velocity=-165.08305741326686, intercept=-25150.589843950216, speed=165.08305741326686, wcorr=0.142329118612986, P_decoder=0.47529334002702445, pearsonr=nan, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-502.5591364329448, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([ 5, 46, 10, 37, 23,  4, 21, 19, 45, 17, 41, 20,  7, 40, 24, 49, 43, 18, 31, 26, 50]), n_unique_aclus=21)\n",
      "an_epoch: EpochTuple(Index=7, start=153.5056724450551, stop=153.85087290836964, label=11, duration=0.3452004633145407, end=153.85087290836964, score=0.26664637201507946, velocity=-165.08305741326686, intercept=-25150.589843950216, speed=165.08305741326686, wcorr=0.142329118612986, P_decoder=0.47529334002702445, pearsonr=nan, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-502.5591364329448, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([ 5, 46, 10, 37, 23,  4, 21, 19, 45, 17, 41, 20,  7, 40, 24, 49, 43, 18, 31, 26, 50]), n_unique_aclus=21)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (18, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 18\n",
      "np.shape(curr_data): (13, 59), np.nanmax(curr_data): 0.14933925445043028, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 13\n",
      "np.shape(curr_data): (18, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 18\n",
      "np.shape(curr_data): (13, 59), np.nanmax(curr_data): 0.16577466995625206, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 13\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_011\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_011\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_011\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_011\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[10][\"p_x_given_n\"]): (59, 4, 14)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.401826 0.222795 0.0835336 0.291845]\n",
      "\t_long_any: 0.3753785335947758, _short_any: 0.6246214664052238\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.893274 0 0.106726 0]\n",
      "\t_long_any: 0.1067255490762632, _short_any: 0.8932744509237368\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.992093 0 0.00790687 0]\n",
      "\t_long_any: 0.007906872557046241, _short_any: 0.9920931274429539\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.946803 0 0.0531971 0]\n",
      "\t_long_any: 0.05319714740005922, _short_any: 0.9468028525999408\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.679364 0 0.320636 0]\n",
      "\t_long_any: 0.320636268757153, _short_any: 0.6793637312428469\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.999903 0 9.66603e-05 0]\n",
      "\t_long_any: 9.666031303803054e-05, _short_any: 0.9999033396869618\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.99891 0 0.0010902 0]\n",
      "\t_long_any: 0.0010902008394999157, _short_any: 0.9989097991605\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.674286 0 0.325714]\n",
      "\t_long_any: 0.32571386758680254, _short_any: 0.674286132413198\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 10, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.401864 0 0.598136 0]\n",
      "\t_long_any: 0.5981362985923431, _short_any: 0.40186370140765704\n",
      "i: 11, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 12, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.136707 0 0.863293 0]\n",
      "\t_long_any: 0.8632932021199914, _short_any: 0.13670679788000856\n",
      "i: 13, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.000831355 0.757344 0.00694547 0.23488]\n",
      "\t_long_any: 0.24182501172723678, _short_any: 0.7581749882727633\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_011/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_011'\n",
      "processing an_epoch_idx: 8/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 8)\n",
      "an_epoch: EpochTuple(Index=8, start=165.03601918148343, stop=165.26024434680585, label=12, duration=0.22422516532242298, end=165.26024434680585, score=0.3046235456041435, velocity=24.38726984514215, intercept=4266.51674628685, speed=24.38726984514215, wcorr=-0.3773174356632086, P_decoder=0.4007221786125338, pearsonr=0.23012755677179447, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-491.02878969651647, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([41,  9, 11, 53, 49, 21, 18, 26, 31, 50, 37, 43, 52, 19, 45, 20, 15]), n_unique_aclus=17)\n",
      "an_epoch: EpochTuple(Index=8, start=165.03601918148343, stop=165.26024434680585, label=12, duration=0.22422516532242298, end=165.26024434680585, score=0.3046235456041435, velocity=24.38726984514215, intercept=4266.51674628685, speed=24.38726984514215, wcorr=-0.3773174356632086, P_decoder=0.4007221786125338, pearsonr=0.23012755677179447, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-491.02878969651647, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([41,  9, 11, 53, 49, 21, 18, 26, 31, 50, 37, 43, 52, 19, 45, 20, 15]), n_unique_aclus=17)\n",
      "an_epoch: EpochTuple(Index=8, start=165.03601918148343, stop=165.26024434680585, label=12, duration=0.22422516532242298, end=165.26024434680585, score=0.3046235456041435, velocity=24.38726984514215, intercept=4266.51674628685, speed=24.38726984514215, wcorr=-0.3773174356632086, P_decoder=0.4007221786125338, pearsonr=0.23012755677179447, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-491.02878969651647, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([41,  9, 11, 53, 49, 21, 18, 26, 31, 50, 37, 43, 52, 19, 45, 20, 15]), n_unique_aclus=17)\n",
      "an_epoch: EpochTuple(Index=8, start=165.03601918148343, stop=165.26024434680585, label=12, duration=0.22422516532242298, end=165.26024434680585, score=0.3046235456041435, velocity=24.38726984514215, intercept=4266.51674628685, speed=24.38726984514215, wcorr=-0.3773174356632086, P_decoder=0.4007221786125338, pearsonr=0.23012755677179447, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-491.02878969651647, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([41,  9, 11, 53, 49, 21, 18, 26, 31, 50, 37, 43, 52, 19, 45, 20, 15]), n_unique_aclus=17)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (12, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 12\n",
      "np.shape(curr_data): (13, 59), np.nanmax(curr_data): 0.14933925445043028, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 13\n",
      "np.shape(curr_data): (12, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 12\n",
      "np.shape(curr_data): (13, 59), np.nanmax(curr_data): 0.17673647253127112, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 13\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_012\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_012\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_012\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_012\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[11][\"p_x_given_n\"]): (59, 4, 9)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.9273 0 0.0726995]\n",
      "\t_long_any: 0.07269951248541923, _short_any: 0.9273004875145809\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [8.57905e-07 0.991058 6.10956e-06 0.00893493]\n",
      "\t_long_any: 0.008941037292888065, _short_any: 0.9910589627071118\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.00070441 0.970031 0.0174444 0.0118205]\n",
      "\t_long_any: 0.029264848866634215, _short_any: 0.9707351511333657\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.234717 0 0.765283 0]\n",
      "\t_long_any: 0.7652829267821164, _short_any: 0.23471707321788385\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.601046 0 0.398954 0]\n",
      "\t_long_any: 0.39895353316164683, _short_any: 0.6010464668383535\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.475894 0 0.524106 0]\n",
      "\t_long_any: 0.5241060385370104, _short_any: 0.47589396146298935\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.751986 0 0.248014 0]\n",
      "\t_long_any: 0.24801405794551284, _short_any: 0.7519859420544874\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.503304 0 0.496696 0]\n",
      "\t_long_any: 0.4966959681311538, _short_any: 0.5033040318688462\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.232907 0.384556 0.093214 0.289323]\n",
      "\t_long_any: 0.3825366033098493, _short_any: 0.6174633966901505\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_012/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_012'\n",
      "processing an_epoch_idx: 9/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 9)\n",
      "an_epoch: EpochTuple(Index=9, start=186.17864899651613, stop=186.4981061129365, label=15, duration=0.31945711642038077, end=186.4981061129365, score=0.27638716941394886, velocity=-16.258179896759895, intercept=-2790.5726780719187, speed=16.258179896759895, wcorr=0.08162016259937342, P_decoder=0.2869770653754554, pearsonr=-0.042032842623018735, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-469.88615988148376, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([31,  2, 19, 32, 43, 50,  9, 52, 37, 35, 20, 21,  5, 27]), n_unique_aclus=14)\n",
      "an_epoch: EpochTuple(Index=9, start=186.17864899651613, stop=186.4981061129365, label=15, duration=0.31945711642038077, end=186.4981061129365, score=0.27638716941394886, velocity=-16.258179896759895, intercept=-2790.5726780719187, speed=16.258179896759895, wcorr=0.08162016259937342, P_decoder=0.2869770653754554, pearsonr=-0.042032842623018735, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-469.88615988148376, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([31,  2, 19, 32, 43, 50,  9, 52, 37, 35, 20, 21,  5, 27]), n_unique_aclus=14)\n",
      "an_epoch: EpochTuple(Index=9, start=186.17864899651613, stop=186.4981061129365, label=15, duration=0.31945711642038077, end=186.4981061129365, score=0.27638716941394886, velocity=-16.258179896759895, intercept=-2790.5726780719187, speed=16.258179896759895, wcorr=0.08162016259937342, P_decoder=0.2869770653754554, pearsonr=-0.042032842623018735, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-469.88615988148376, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([31,  2, 19, 32, 43, 50,  9, 52, 37, 35, 20, 21,  5, 27]), n_unique_aclus=14)\n",
      "an_epoch: EpochTuple(Index=9, start=186.17864899651613, stop=186.4981061129365, label=15, duration=0.31945711642038077, end=186.4981061129365, score=0.27638716941394886, velocity=-16.258179896759895, intercept=-2790.5726780719187, speed=16.258179896759895, wcorr=0.08162016259937342, P_decoder=0.2869770653754554, pearsonr=-0.042032842623018735, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-469.88615988148376, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([31,  2, 19, 32, 43, 50,  9, 52, 37, 35, 20, 21,  5, 27]), n_unique_aclus=14)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (11, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 11\n",
      "np.shape(curr_data): (10, 59), np.nanmax(curr_data): 0.1328468488320496, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 10\n",
      "np.shape(curr_data): (11, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 11\n",
      "np.shape(curr_data): (10, 59), np.nanmax(curr_data): 0.18913760071074082, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 10\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_015\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_015\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_015\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_015\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[14][\"p_x_given_n\"]): (59, 4, 13)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.128783 0.0814509 0.213746 0.576019]\n",
      "\t_long_any: 0.7897657927074535, _short_any: 0.21023420729254713\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.183717 0 0.816283 0]\n",
      "\t_long_any: 0.8162829441152744, _short_any: 0.1837170558847257\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.505606 0 0.494394 0]\n",
      "\t_long_any: 0.494393861745059, _short_any: 0.5056061382549412\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.142516 0.670245 0.00600658 0.181233]\n",
      "\t_long_any: 0.18723945234279357, _short_any: 0.8127605476572063\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0559744 0 0.944026 0]\n",
      "\t_long_any: 0.944025550508403, _short_any: 0.055974449491597\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.647611 0 0.352389 0]\n",
      "\t_long_any: 0.35238941388164813, _short_any: 0.6476105861183519\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.401826 0.222795 0.0835336 0.291845]\n",
      "\t_long_any: 0.3753785335947758, _short_any: 0.6246214664052238\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.365485 0.458682 0.0682761 0.107557]\n",
      "\t_long_any: 0.17583275644247778, _short_any: 0.8241672435575219\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 10, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.127498 0.00772767 0.792544 0.072231]\n",
      "\t_long_any: 0.8647747139251041, _short_any: 0.13522528607489573\n",
      "i: 11, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0400818 0.0143107 0.683681 0.261926]\n",
      "\t_long_any: 0.9456074893772256, _short_any: 0.05439251062277445\n",
      "i: 12, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.505606 0 0.494394 0]\n",
      "\t_long_any: 0.494393861745059, _short_any: 0.5056061382549412\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_015/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_015'\n",
      "processing an_epoch_idx: 10/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 10)\n",
      "an_epoch: EpochTuple(Index=10, start=232.12680595100392, stop=232.18354576209094, label=20, duration=0.05673981108702719, end=232.18354576209094, score=0.35348898071423096, velocity=-1073.039873185953, intercept=-249053.27306040362, speed=1073.039873185953, wcorr=0.7083253590656743, P_decoder=0.7918069476585267, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-423.938002926996, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([45,  7,  9, 20, 19, 40, 18, 21]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=10, start=232.12680595100392, stop=232.18354576209094, label=20, duration=0.05673981108702719, end=232.18354576209094, score=0.35348898071423096, velocity=-1073.039873185953, intercept=-249053.27306040362, speed=1073.039873185953, wcorr=0.7083253590656743, P_decoder=0.7918069476585267, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-423.938002926996, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([45,  7,  9, 20, 19, 40, 18, 21]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=10, start=232.12680595100392, stop=232.18354576209094, label=20, duration=0.05673981108702719, end=232.18354576209094, score=0.35348898071423096, velocity=-1073.039873185953, intercept=-249053.27306040362, speed=1073.039873185953, wcorr=0.7083253590656743, P_decoder=0.7918069476585267, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-423.938002926996, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([45,  7,  9, 20, 19, 40, 18, 21]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=10, start=232.12680595100392, stop=232.18354576209094, label=20, duration=0.05673981108702719, end=232.18354576209094, score=0.35348898071423096, velocity=-1073.039873185953, intercept=-249053.27306040362, speed=1073.039873185953, wcorr=0.7083253590656743, P_decoder=0.7918069476585267, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-423.938002926996, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([45,  7,  9, 20, 19, 40, 18, 21]), n_unique_aclus=8)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.10832426379331009, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (5, 59), np.nanmax(curr_data): 0.13918661674691393, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 5\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.14773746413841815, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (5, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 5\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_020\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_020\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_020\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_020\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[18][\"p_x_given_n\"]): (59, 4, 3)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.982389 0 0.0176114 0]\n",
      "\t_long_any: 0.017611417683643056, _short_any: 0.9823885823163573\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.996565 0 0.00343536 0]\n",
      "\t_long_any: 0.0034353552816237896, _short_any: 0.996564644718376\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.433296 0.215056 0.27909 0.0725591]\n",
      "\t_long_any: 0.3516485729942037, _short_any: 0.6483514270057958\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_020/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_020'\n",
      "processing an_epoch_idx: 11/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 11)\n",
      "an_epoch: EpochTuple(Index=11, start=248.32778837624937, stop=248.6431597347837, label=22, duration=0.3153713585343212, end=248.6431597347837, score=0.1991561238627585, velocity=32.51635979351988, intercept=8316.556139535502, speed=32.51635979351988, wcorr=-0.3707691686986005, P_decoder=nan, pearsonr=0.5958471867640445, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-407.7370205017505, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([35, 31, 32, 50, 43, 19, 49, 20, 15, 27, 40, 37, 41, 21, 24,  4, 18, 45, 52, 23,  9,  5, 14,  7]), n_unique_aclus=24)\n",
      "an_epoch: EpochTuple(Index=11, start=248.32778837624937, stop=248.6431597347837, label=22, duration=0.3153713585343212, end=248.6431597347837, score=0.1991561238627585, velocity=32.51635979351988, intercept=8316.556139535502, speed=32.51635979351988, wcorr=-0.3707691686986005, P_decoder=nan, pearsonr=0.5958471867640445, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-407.7370205017505, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([35, 31, 32, 50, 43, 19, 49, 20, 15, 27, 40, 37, 41, 21, 24,  4, 18, 45, 52, 23,  9,  5, 14,  7]), n_unique_aclus=24)\n",
      "an_epoch: EpochTuple(Index=11, start=248.32778837624937, stop=248.6431597347837, label=22, duration=0.3153713585343212, end=248.6431597347837, score=0.1991561238627585, velocity=32.51635979351988, intercept=8316.556139535502, speed=32.51635979351988, wcorr=-0.3707691686986005, P_decoder=nan, pearsonr=0.5958471867640445, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-407.7370205017505, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([35, 31, 32, 50, 43, 19, 49, 20, 15, 27, 40, 37, 41, 21, 24,  4, 18, 45, 52, 23,  9,  5, 14,  7]), n_unique_aclus=24)\n",
      "an_epoch: EpochTuple(Index=11, start=248.32778837624937, stop=248.6431597347837, label=22, duration=0.3153713585343212, end=248.6431597347837, score=0.1991561238627585, velocity=32.51635979351988, intercept=8316.556139535502, speed=32.51635979351988, wcorr=-0.3707691686986005, P_decoder=nan, pearsonr=0.5958471867640445, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-407.7370205017505, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([35, 31, 32, 50, 43, 19, 49, 20, 15, 27, 40, 37, 41, 21, 24,  4, 18, 45, 52, 23,  9,  5, 14,  7]), n_unique_aclus=24)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (20, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 20\n",
      "np.shape(curr_data): (15, 59), np.nanmax(curr_data): 0.14646292062398014, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 15\n",
      "np.shape(curr_data): (20, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 20\n",
      "np.shape(curr_data): (15, 59), np.nanmax(curr_data): 0.16577466995625206, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 15\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_022\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_022\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_022\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_022\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[20][\"p_x_given_n\"]): (59, 4, 13)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.00191225 0.000228986 0.0350517 0.962807]\n",
      "\t_long_any: 0.9978587643798095, _short_any: 0.0021412356201905985\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.149334 0 0.850666 0]\n",
      "\t_long_any: 0.8506656652506043, _short_any: 0.1493343347493957\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.505606 0 0.494394 0]\n",
      "\t_long_any: 0.494393861745059, _short_any: 0.5056061382549412\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.58513 0 0.41487 0]\n",
      "\t_long_any: 0.41487048392538084, _short_any: 0.5851295160746186\n",
      "i: 10, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.893618 0 0.106382 0]\n",
      "\t_long_any: 0.10638189772489728, _short_any: 0.8936181022751029\n",
      "i: 11, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 12, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_022/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_022'\n",
      "processing an_epoch_idx: 12/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 12)\n",
      "an_epoch: EpochTuple(Index=12, start=257.4532518638298, stop=257.93598569673486, label=23, duration=0.482733832905069, end=257.93598569673486, score=0.13015419740791634, velocity=-431.26961410352266, intercept=-111010.32945435755, speed=431.26961410352266, wcorr=0.25200898415102285, P_decoder=0.4341577590295712, pearsonr=-0.0785846732493582, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-398.6115570141701, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([45, 40,  7,  9, 20, 44,  4, 10, 24]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=12, start=257.4532518638298, stop=257.93598569673486, label=23, duration=0.482733832905069, end=257.93598569673486, score=0.13015419740791634, velocity=-431.26961410352266, intercept=-111010.32945435755, speed=431.26961410352266, wcorr=0.25200898415102285, P_decoder=0.4341577590295712, pearsonr=-0.0785846732493582, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-398.6115570141701, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([45, 40,  7,  9, 20, 44,  4, 10, 24]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=12, start=257.4532518638298, stop=257.93598569673486, label=23, duration=0.482733832905069, end=257.93598569673486, score=0.13015419740791634, velocity=-431.26961410352266, intercept=-111010.32945435755, speed=431.26961410352266, wcorr=0.25200898415102285, P_decoder=0.4341577590295712, pearsonr=-0.0785846732493582, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-398.6115570141701, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([45, 40,  7,  9, 20, 44,  4, 10, 24]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=12, start=257.4532518638298, stop=257.93598569673486, label=23, duration=0.482733832905069, end=257.93598569673486, score=0.13015419740791634, velocity=-431.26961410352266, intercept=-111010.32945435755, speed=431.26961410352266, wcorr=0.25200898415102285, P_decoder=0.4341577590295712, pearsonr=-0.0785846732493582, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-398.6115570141701, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([45, 40,  7,  9, 20, 44,  4, 10, 24]), n_unique_aclus=9)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.1146338264762386, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (5, 59), np.nanmax(curr_data): 0.13918661674691393, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 5\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.14773746413841815, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (5, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 5\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_023\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_023\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_023\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_023\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[21][\"p_x_given_n\"]): (59, 4, 20)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.621891 0.0122324 0.360753 0.00512414]\n",
      "\t_long_any: 0.3658767436006062, _short_any: 0.6341232563993943\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.947745 0.00795609 0.0393754 0.00492348]\n",
      "\t_long_any: 0.04429889320729925, _short_any: 0.9557011067927005\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.999986 0 1.35768e-05 0]\n",
      "\t_long_any: 1.3576762848550266e-05, _short_any: 0.9999864232371511\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.621891 0.0122324 0.360753 0.00512414]\n",
      "\t_long_any: 0.3658767436006062, _short_any: 0.6341232563993943\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.621891 0.0122324 0.360753 0.00512414]\n",
      "\t_long_any: 0.3658767436006062, _short_any: 0.6341232563993943\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.703331 0.00213347 0.293991 0.000544165]\n",
      "\t_long_any: 0.29453510496529556, _short_any: 0.7054648950347042\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.505591 0.0639106 0.387657 0.0428408]\n",
      "\t_long_any: 0.4304978792973787, _short_any: 0.5695021207026211\n",
      "i: 10, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 11, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.520975 0.113974 0.329386 0.0356652]\n",
      "\t_long_any: 0.3650514179319925, _short_any: 0.6349485820680071\n",
      "i: 12, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 13, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.610049 0.271045 0.062785 0.0561213]\n",
      "\t_long_any: 0.1189063065779441, _short_any: 0.8810936934220556\n",
      "i: 14, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 15, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 16, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.621891 0.0122324 0.360753 0.00512414]\n",
      "\t_long_any: 0.3658767436006062, _short_any: 0.6341232563993943\n",
      "i: 17, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 18, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.43432 0 0.56568 0]\n",
      "\t_long_any: 0.5656803965582573, _short_any: 0.434319603441743\n",
      "i: 19, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.365485 0.458682 0.0682761 0.107557]\n",
      "\t_long_any: 0.17583275644247778, _short_any: 0.8241672435575219\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_023/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_023'\n",
      "processing an_epoch_idx: 13/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 13)\n",
      "an_epoch: EpochTuple(Index=13, start=279.06516015867237, stop=279.1397175603779, label=24, duration=0.07455740170553327, end=279.1397175603779, score=0.4901080440288037, velocity=-877.9417144248707, intercept=-244962.70615071146, speed=877.9417144248707, wcorr=0.7977578337175303, P_decoder=0.8206782823738025, pearsonr=-0.5317527995548049, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-376.9996487193275, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([45, 24,  7, 40, 20, 19, 21, 52]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=13, start=279.06516015867237, stop=279.1397175603779, label=24, duration=0.07455740170553327, end=279.1397175603779, score=0.4901080440288037, velocity=-877.9417144248707, intercept=-244962.70615071146, speed=877.9417144248707, wcorr=0.7977578337175303, P_decoder=0.8206782823738025, pearsonr=-0.5317527995548049, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-376.9996487193275, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([45, 24,  7, 40, 20, 19, 21, 52]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=13, start=279.06516015867237, stop=279.1397175603779, label=24, duration=0.07455740170553327, end=279.1397175603779, score=0.4901080440288037, velocity=-877.9417144248707, intercept=-244962.70615071146, speed=877.9417144248707, wcorr=0.7977578337175303, P_decoder=0.8206782823738025, pearsonr=-0.5317527995548049, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-376.9996487193275, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([45, 24,  7, 40, 20, 19, 21, 52]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=13, start=279.06516015867237, stop=279.1397175603779, label=24, duration=0.07455740170553327, end=279.1397175603779, score=0.4901080440288037, velocity=-877.9417144248707, intercept=-244962.70615071146, speed=877.9417144248707, wcorr=0.7977578337175303, P_decoder=0.8206782823738025, pearsonr=-0.5317527995548049, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-376.9996487193275, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([45, 24,  7, 40, 20, 19, 21, 52]), n_unique_aclus=8)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.10832426379331009, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (4, 59), np.nanmax(curr_data): 0.13918661674691393, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 4\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.14773746413841815, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (4, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 4\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_024\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_024\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_024\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_024\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[22][\"p_x_given_n\"]): (59, 4, 3)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.999885 0 0.000114872 0]\n",
      "\t_long_any: 0.00011487244952214792, _short_any: 0.9998851275504773\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.861103 0 0.138897 0]\n",
      "\t_long_any: 0.13889674726742368, _short_any: 0.861103252732576\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.601046 0 0.398954 0]\n",
      "\t_long_any: 0.39895353316164683, _short_any: 0.6010464668383535\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_024/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_024'\n",
      "processing an_epoch_idx: 14/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 14)\n",
      "an_epoch: EpochTuple(Index=14, start=294.06007600121666, stop=294.43412252981216, label=25, duration=0.3740465285954997, end=294.43412252981216, score=0.11958503524092769, velocity=-236.90490706706706, intercept=-69503.8415805788, speed=236.90490706706706, wcorr=0.20894951981922574, P_decoder=nan, pearsonr=0.5776248860168319, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-362.00473287678324, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([49, 44, 20, 53, 10,  5, 21, 37, 18, 26, 50]), n_unique_aclus=11)\n",
      "an_epoch: EpochTuple(Index=14, start=294.06007600121666, stop=294.43412252981216, label=25, duration=0.3740465285954997, end=294.43412252981216, score=0.11958503524092769, velocity=-236.90490706706706, intercept=-69503.8415805788, speed=236.90490706706706, wcorr=0.20894951981922574, P_decoder=nan, pearsonr=0.5776248860168319, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-362.00473287678324, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([49, 44, 20, 53, 10,  5, 21, 37, 18, 26, 50]), n_unique_aclus=11)\n",
      "an_epoch: EpochTuple(Index=14, start=294.06007600121666, stop=294.43412252981216, label=25, duration=0.3740465285954997, end=294.43412252981216, score=0.11958503524092769, velocity=-236.90490706706706, intercept=-69503.8415805788, speed=236.90490706706706, wcorr=0.20894951981922574, P_decoder=nan, pearsonr=0.5776248860168319, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-362.00473287678324, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([49, 44, 20, 53, 10,  5, 21, 37, 18, 26, 50]), n_unique_aclus=11)\n",
      "an_epoch: EpochTuple(Index=14, start=294.06007600121666, stop=294.43412252981216, label=25, duration=0.3740465285954997, end=294.43412252981216, score=0.11958503524092769, velocity=-236.90490706706706, intercept=-69503.8415805788, speed=236.90490706706706, wcorr=0.20894951981922574, P_decoder=nan, pearsonr=0.5776248860168319, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-362.00473287678324, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([49, 44, 20, 53, 10,  5, 21, 37, 18, 26, 50]), n_unique_aclus=11)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (10, 59), np.nanmax(curr_data): 0.14933925445043028, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 10\n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (10, 59), np.nanmax(curr_data): 0.17673647253127112, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 10\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_025\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_025\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_025\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_025\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[23][\"p_x_given_n\"]): (59, 4, 15)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.952522 0 0.0474778]\n",
      "\t_long_any: 0.04747782775707025, _short_any: 0.9525221722429296\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.173443 0.527749 0.0699114 0.228896]\n",
      "\t_long_any: 0.2988077086440935, _short_any: 0.7011922913559057\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.554975 0 0.445025 0]\n",
      "\t_long_any: 0.445025457995953, _short_any: 0.5549745420040473\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 10, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.401826 0.222795 0.0835336 0.291845]\n",
      "\t_long_any: 0.3753785335947758, _short_any: 0.6246214664052238\n",
      "i: 11, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.173443 0.527749 0.0699114 0.228896]\n",
      "\t_long_any: 0.2988077086440935, _short_any: 0.7011922913559057\n",
      "i: 12, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 13, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.433296 0.215056 0.27909 0.0725591]\n",
      "\t_long_any: 0.3516485729942037, _short_any: 0.6483514270057958\n",
      "i: 14, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.000171214 0.946437 0.000621831 0.05277]\n",
      "\t_long_any: 0.0533917919462637, _short_any: 0.9466082080537362\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_025/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_025'\n",
      "processing an_epoch_idx: 15/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 15)\n",
      "an_epoch: EpochTuple(Index=15, start=320.8021295092767, stop=321.0316385118058, label=28, duration=0.22950900252908468, end=321.0316385118058, score=0.3274839867895077, velocity=86.71029278271433, intercept=28064.24187916333, speed=86.71029278271433, wcorr=-0.4238279393211118, P_decoder=nan, pearsonr=0.5890166066988447, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-335.2626793687232, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([18, 50, 26, 31, 43, 27, 20, 15, 49, 24, 39,  9, 10]), n_unique_aclus=13)\n",
      "an_epoch: EpochTuple(Index=15, start=320.8021295092767, stop=321.0316385118058, label=28, duration=0.22950900252908468, end=321.0316385118058, score=0.3274839867895077, velocity=86.71029278271433, intercept=28064.24187916333, speed=86.71029278271433, wcorr=-0.4238279393211118, P_decoder=nan, pearsonr=0.5890166066988447, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-335.2626793687232, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([18, 50, 26, 31, 43, 27, 20, 15, 49, 24, 39,  9, 10]), n_unique_aclus=13)\n",
      "an_epoch: EpochTuple(Index=15, start=320.8021295092767, stop=321.0316385118058, label=28, duration=0.22950900252908468, end=321.0316385118058, score=0.3274839867895077, velocity=86.71029278271433, intercept=28064.24187916333, speed=86.71029278271433, wcorr=-0.4238279393211118, P_decoder=nan, pearsonr=0.5890166066988447, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-335.2626793687232, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([18, 50, 26, 31, 43, 27, 20, 15, 49, 24, 39,  9, 10]), n_unique_aclus=13)\n",
      "an_epoch: EpochTuple(Index=15, start=320.8021295092767, stop=321.0316385118058, label=28, duration=0.22950900252908468, end=321.0316385118058, score=0.3274839867895077, velocity=86.71029278271433, intercept=28064.24187916333, speed=86.71029278271433, wcorr=-0.4238279393211118, P_decoder=nan, pearsonr=0.5890166066988447, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-335.2626793687232, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([18, 50, 26, 31, 43, 27, 20, 15, 49, 24, 39,  9, 10]), n_unique_aclus=13)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.14933925445043028, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.16577466995625206, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_028\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_028\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_028\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_028\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[25][\"p_x_given_n\"]): (59, 4, 10)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.000400484 0.840719 0.00681533 0.152066]\n",
      "\t_long_any: 0.15888082966061792, _short_any: 0.8411191703393819\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.017912 0.546087 0.0853657 0.350635]\n",
      "\t_long_any: 0.4360008591772542, _short_any: 0.5639991408227458\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.175205 0 0.824795 0]\n",
      "\t_long_any: 0.8247945951824209, _short_any: 0.1752054048175785\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.505606 0 0.494394 0]\n",
      "\t_long_any: 0.494393861745059, _short_any: 0.5056061382549412\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.203509 0.153953 0.340026 0.302511]\n",
      "\t_long_any: 0.6425370637459515, _short_any: 0.35746293625404885\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.554975 0 0.445025 0]\n",
      "\t_long_any: 0.445025457995953, _short_any: 0.5549745420040473\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.355917 0 0.644083 0]\n",
      "\t_long_any: 0.6440834233137029, _short_any: 0.3559165766862972\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.365485 0.458682 0.0682761 0.107557]\n",
      "\t_long_any: 0.17583275644247778, _short_any: 0.8241672435575219\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_028/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_028'\n",
      "processing an_epoch_idx: 16/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 16)\n",
      "an_epoch: EpochTuple(Index=16, start=339.45834523730446, stop=339.80514313979074, label=32, duration=0.34679790248628706, end=339.80514313979074, score=0.19416242697421637, velocity=45.022652021800084, intercept=15530.189162101431, speed=45.022652021800084, wcorr=-0.04344720517638017, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-316.60646364069544, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([31, 37, 50, 43, 20, 39, 46, 18, 52, 15, 45, 27, 49]), n_unique_aclus=13)\n",
      "an_epoch: EpochTuple(Index=16, start=339.45834523730446, stop=339.80514313979074, label=32, duration=0.34679790248628706, end=339.80514313979074, score=0.19416242697421637, velocity=45.022652021800084, intercept=15530.189162101431, speed=45.022652021800084, wcorr=-0.04344720517638017, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-316.60646364069544, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([31, 37, 50, 43, 20, 39, 46, 18, 52, 15, 45, 27, 49]), n_unique_aclus=13)\n",
      "an_epoch: EpochTuple(Index=16, start=339.45834523730446, stop=339.80514313979074, label=32, duration=0.34679790248628706, end=339.80514313979074, score=0.19416242697421637, velocity=45.022652021800084, intercept=15530.189162101431, speed=45.022652021800084, wcorr=-0.04344720517638017, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-316.60646364069544, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([31, 37, 50, 43, 20, 39, 46, 18, 52, 15, 45, 27, 49]), n_unique_aclus=13)\n",
      "an_epoch: EpochTuple(Index=16, start=339.45834523730446, stop=339.80514313979074, label=32, duration=0.34679790248628706, end=339.80514313979074, score=0.19416242697421637, velocity=45.022652021800084, intercept=15530.189162101431, speed=45.022652021800084, wcorr=-0.04344720517638017, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-316.60646364069544, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([31, 37, 50, 43, 20, 39, 46, 18, 52, 15, 45, 27, 49]), n_unique_aclus=13)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (10, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 10\n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.13918661674691393, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (10, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 10\n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.16577466995625206, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_032\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_032\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_032\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_032\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[27][\"p_x_given_n\"]): (59, 4, 14)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0135276 0.0254584 0.0412355 0.919778]\n",
      "\t_long_any: 0.9610140029556062, _short_any: 0.0389859970443935\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.10908 0.115552 0.157043 0.618326]\n",
      "\t_long_any: 0.7753683204822507, _short_any: 0.22463167951774907\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.232907 0.384556 0.093214 0.289323]\n",
      "\t_long_any: 0.3825366033098493, _short_any: 0.6174633966901505\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0010854 0.00413768 0.0066023 0.988175]\n",
      "\t_long_any: 0.994776912291068, _short_any: 0.005223087708931808\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.090287 0 0.909713 0]\n",
      "\t_long_any: 0.9097129806897455, _short_any: 0.0902870193102544\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.729119 0 0.270881 0]\n",
      "\t_long_any: 0.2708809737738029, _short_any: 0.7291190262261975\n",
      "i: 10, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.796464 0 0.203536 0]\n",
      "\t_long_any: 0.20353611840825314, _short_any: 0.7964638815917469\n",
      "i: 11, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.503304 0 0.496696 0]\n",
      "\t_long_any: 0.4966959681311538, _short_any: 0.5033040318688462\n",
      "i: 12, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.505466 0.178749 0.199624 0.116161]\n",
      "\t_long_any: 0.31578491176099827, _short_any: 0.684215088239001\n",
      "i: 13, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_032/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_032'\n",
      "processing an_epoch_idx: 17/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 17)\n",
      "an_epoch: EpochTuple(Index=17, start=383.35305556317326, stop=383.610273991595, label=33, duration=0.25721842842176557, end=383.610273991595, score=0.1952472697744195, velocity=273.13742226557736, intercept=104952.913603403, speed=273.13742226557736, wcorr=-0.20284362146487772, P_decoder=nan, pearsonr=-0.5693736460628468, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-272.71175331482664, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([50, 43, 19, 39, 49,  9, 18, 45, 20, 37, 23, 21, 10, 52, 24, 31, 32,  5, 14, 41]), n_unique_aclus=20)\n",
      "an_epoch: EpochTuple(Index=17, start=383.35305556317326, stop=383.610273991595, label=33, duration=0.25721842842176557, end=383.610273991595, score=0.1952472697744195, velocity=273.13742226557736, intercept=104952.913603403, speed=273.13742226557736, wcorr=-0.20284362146487772, P_decoder=nan, pearsonr=-0.5693736460628468, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-272.71175331482664, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([50, 43, 19, 39, 49,  9, 18, 45, 20, 37, 23, 21, 10, 52, 24, 31, 32,  5, 14, 41]), n_unique_aclus=20)\n",
      "an_epoch: EpochTuple(Index=17, start=383.35305556317326, stop=383.610273991595, label=33, duration=0.25721842842176557, end=383.610273991595, score=0.1952472697744195, velocity=273.13742226557736, intercept=104952.913603403, speed=273.13742226557736, wcorr=-0.20284362146487772, P_decoder=nan, pearsonr=-0.5693736460628468, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-272.71175331482664, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([50, 43, 19, 39, 49,  9, 18, 45, 20, 37, 23, 21, 10, 52, 24, 31, 32,  5, 14, 41]), n_unique_aclus=20)\n",
      "an_epoch: EpochTuple(Index=17, start=383.35305556317326, stop=383.610273991595, label=33, duration=0.25721842842176557, end=383.610273991595, score=0.1952472697744195, velocity=273.13742226557736, intercept=104952.913603403, speed=273.13742226557736, wcorr=-0.20284362146487772, P_decoder=nan, pearsonr=-0.5693736460628468, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-272.71175331482664, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([50, 43, 19, 39, 49,  9, 18, 45, 20, 37, 23, 21, 10, 52, 24, 31, 32,  5, 14, 41]), n_unique_aclus=20)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (15, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 15\n",
      "np.shape(curr_data): (14, 59), np.nanmax(curr_data): 0.14646292062398014, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 14\n",
      "np.shape(curr_data): (15, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 15\n",
      "np.shape(curr_data): (14, 59), np.nanmax(curr_data): 0.16577466995625206, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 14\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_033\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_033\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_033\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_033\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[28][\"p_x_given_n\"]): (59, 4, 11)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.332092 0 0.667908 0]\n",
      "\t_long_any: 0.6679082064751289, _short_any: 0.33209179352487067\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.131692 0 0.868308 0]\n",
      "\t_long_any: 0.8683079047779072, _short_any: 0.13169209522209258\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.441471 0 0.558529 0]\n",
      "\t_long_any: 0.5585287330361992, _short_any: 0.44147126696380146\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.68567 0 0.31433]\n",
      "\t_long_any: 0.31432959715460035, _short_any: 0.6856704028453999\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.67344 0 0.32656 0]\n",
      "\t_long_any: 0.3265599694886136, _short_any: 0.6734400305113869\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.96094 0 0.0390599 0]\n",
      "\t_long_any: 0.039059883574337456, _short_any: 0.9609401164256628\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.270274 0.60036 0.0251879 0.104178]\n",
      "\t_long_any: 0.1293656882170319, _short_any: 0.8706343117829688\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 10, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0869381 0.768053 0.0520664 0.0929422]\n",
      "\t_long_any: 0.14500860282222938, _short_any: 0.8549913971777701\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_033/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_033'\n",
      "processing an_epoch_idx: 18/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 18)\n",
      "an_epoch: EpochTuple(Index=18, start=396.4621637313394, stop=396.791266922839, label=35, duration=0.3291031914995983, end=396.791266922839, score=0.09825715961278729, velocity=-178.8399788643592, intercept=-70673.84141843782, speed=178.8399788643592, wcorr=0.04295770092783556, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-259.6026451466605, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([20, 49, 53, 21, 18, 37,  9, 41]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=18, start=396.4621637313394, stop=396.791266922839, label=35, duration=0.3291031914995983, end=396.791266922839, score=0.09825715961278729, velocity=-178.8399788643592, intercept=-70673.84141843782, speed=178.8399788643592, wcorr=0.04295770092783556, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-259.6026451466605, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([20, 49, 53, 21, 18, 37,  9, 41]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=18, start=396.4621637313394, stop=396.791266922839, label=35, duration=0.3291031914995983, end=396.791266922839, score=0.09825715961278729, velocity=-178.8399788643592, intercept=-70673.84141843782, speed=178.8399788643592, wcorr=0.04295770092783556, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-259.6026451466605, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([20, 49, 53, 21, 18, 37,  9, 41]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=18, start=396.4621637313394, stop=396.791266922839, label=35, duration=0.3291031914995983, end=396.791266922839, score=0.09825715961278729, velocity=-178.8399788643592, intercept=-70673.84141843782, speed=178.8399788643592, wcorr=0.04295770092783556, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-259.6026451466605, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([20, 49, 53, 21, 18, 37,  9, 41]), n_unique_aclus=8)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (5, 59), np.nanmax(curr_data): 0.10832426379331009, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 5\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.12921189215173673, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (5, 59), np.nanmax(curr_data): 0.1332959571110494, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 5\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.17673647253127112, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_035\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_035\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_035\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_035\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[29][\"p_x_given_n\"]): (59, 4, 14)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.415203 0 0.584797]\n",
      "\t_long_any: 0.5847970640941248, _short_any: 0.4152029359058755\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.994207 0 0.00579311]\n",
      "\t_long_any: 0.005793107189756636, _short_any: 0.9942068928102432\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0666754 0.581159 0.0548676 0.297298]\n",
      "\t_long_any: 0.35216535407108257, _short_any: 0.6478346459289179\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.554975 0 0.445025 0]\n",
      "\t_long_any: 0.445025457995953, _short_any: 0.5549745420040473\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.365485 0.458682 0.0682761 0.107557]\n",
      "\t_long_any: 0.17583275644247778, _short_any: 0.8241672435575219\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 10, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 11, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 12, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.554975 0 0.445025 0]\n",
      "\t_long_any: 0.445025457995953, _short_any: 0.5549745420040473\n",
      "i: 13, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0869381 0.768053 0.0520664 0.0929422]\n",
      "\t_long_any: 0.14500860282222938, _short_any: 0.8549913971777701\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_035/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_035'\n",
      "processing an_epoch_idx: 19/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 19)\n",
      "an_epoch: EpochTuple(Index=19, start=406.09214152081404, stop=406.3563641055953, label=36, duration=0.26422258478123695, end=406.3563641055953, score=0.12653411242356538, velocity=585.2944762833802, intercept=237951.7472625177, speed=585.2944762833802, wcorr=-0.35532146742488746, P_decoder=nan, pearsonr=0.8532907143807601, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-249.97266735718586, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([ 4, 50, 15, 37, 52, 41, 20,  5, 49, 23, 39, 24]), n_unique_aclus=12)\n",
      "an_epoch: EpochTuple(Index=19, start=406.09214152081404, stop=406.3563641055953, label=36, duration=0.26422258478123695, end=406.3563641055953, score=0.12653411242356538, velocity=585.2944762833802, intercept=237951.7472625177, speed=585.2944762833802, wcorr=-0.35532146742488746, P_decoder=nan, pearsonr=0.8532907143807601, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-249.97266735718586, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([ 4, 50, 15, 37, 52, 41, 20,  5, 49, 23, 39, 24]), n_unique_aclus=12)\n",
      "an_epoch: EpochTuple(Index=19, start=406.09214152081404, stop=406.3563641055953, label=36, duration=0.26422258478123695, end=406.3563641055953, score=0.12653411242356538, velocity=585.2944762833802, intercept=237951.7472625177, speed=585.2944762833802, wcorr=-0.35532146742488746, P_decoder=nan, pearsonr=0.8532907143807601, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-249.97266735718586, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([ 4, 50, 15, 37, 52, 41, 20,  5, 49, 23, 39, 24]), n_unique_aclus=12)\n",
      "an_epoch: EpochTuple(Index=19, start=406.09214152081404, stop=406.3563641055953, label=36, duration=0.26422258478123695, end=406.3563641055953, score=0.12653411242356538, velocity=585.2944762833802, intercept=237951.7472625177, speed=585.2944762833802, wcorr=-0.35532146742488746, P_decoder=nan, pearsonr=0.8532907143807601, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-249.97266735718586, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([ 4, 50, 15, 37, 52, 41, 20,  5, 49, 23, 39, 24]), n_unique_aclus=12)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (10, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 10\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.1328468488320496, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (10, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 10\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.16577466995625206, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_036\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_036\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_036\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_036\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[30][\"p_x_given_n\"]): (59, 4, 11)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.548264 0.241814 0.120337 0.089585]\n",
      "\t_long_any: 0.2099215321433799, _short_any: 0.7900784678566204\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.157475 0.409607 0.370439 0.0624794]\n",
      "\t_long_any: 0.43291848452631027, _short_any: 0.5670815154736897\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.503304 0 0.496696 0]\n",
      "\t_long_any: 0.4966959681311538, _short_any: 0.5033040318688462\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.663774 0 0.336226 0]\n",
      "\t_long_any: 0.3362255096617519, _short_any: 0.6637744903382482\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.6789 0 0.3211 0]\n",
      "\t_long_any: 0.32109975426654924, _short_any: 0.6789002457334504\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.351901 0 0.648099]\n",
      "\t_long_any: 0.6480991400454634, _short_any: 0.35190085995453674\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.690687 0 0.309313 0]\n",
      "\t_long_any: 0.3093131567123081, _short_any: 0.6906868432876918\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.43432 0 0.56568 0]\n",
      "\t_long_any: 0.5656803965582573, _short_any: 0.434319603441743\n",
      "i: 10, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.43432 0 0.56568 0]\n",
      "\t_long_any: 0.5656803965582573, _short_any: 0.434319603441743\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_036/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_036'\n",
      "processing an_epoch_idx: 20/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 20)\n",
      "an_epoch: EpochTuple(Index=20, start=435.5050211814232, stop=435.572635866818, label=40, duration=0.0676146853948012, end=435.572635866818, score=0.3609061943367975, velocity=-97.54907938054087, intercept=-42247.77672784517, speed=97.54907938054087, wcorr=-0.4023744329263507, P_decoder=nan, pearsonr=-0.5120002394401553, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-220.55978769657668, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([27, 39, 43, 26, 37, 18,  2, 31]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=20, start=435.5050211814232, stop=435.572635866818, label=40, duration=0.0676146853948012, end=435.572635866818, score=0.3609061943367975, velocity=-97.54907938054087, intercept=-42247.77672784517, speed=97.54907938054087, wcorr=-0.4023744329263507, P_decoder=nan, pearsonr=-0.5120002394401553, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-220.55978769657668, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([27, 39, 43, 26, 37, 18,  2, 31]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=20, start=435.5050211814232, stop=435.572635866818, label=40, duration=0.0676146853948012, end=435.572635866818, score=0.3609061943367975, velocity=-97.54907938054087, intercept=-42247.77672784517, speed=97.54907938054087, wcorr=-0.4023744329263507, P_decoder=nan, pearsonr=-0.5120002394401553, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-220.55978769657668, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([27, 39, 43, 26, 37, 18,  2, 31]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=20, start=435.5050211814232, stop=435.572635866818, label=40, duration=0.0676146853948012, end=435.572635866818, score=0.3609061943367975, velocity=-97.54907938054087, intercept=-42247.77672784517, speed=97.54907938054087, wcorr=-0.4023744329263507, P_decoder=nan, pearsonr=-0.5120002394401553, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-220.55978769657668, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([27, 39, 43, 26, 37, 18,  2, 31]), n_unique_aclus=8)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (5, 59), np.nanmax(curr_data): 0.1413380488947274, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 5\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.14933925445043028, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (5, 59), np.nanmax(curr_data): 0.16137889015198256, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 5\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.18913760071074082, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_040\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_040\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_040\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_040\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[32][\"p_x_given_n\"]): (59, 4, 3)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.521601 0 0.478399 0]\n",
      "\t_long_any: 0.47839944521739536, _short_any: 0.5216005547826044\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.226217 0.159135 0.101411 0.513237]\n",
      "\t_long_any: 0.6146485407294751, _short_any: 0.3853514592705247\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_040/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_040'\n",
      "processing an_epoch_idx: 21/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 21)\n",
      "an_epoch: EpochTuple(Index=21, start=442.6495679235086, stop=442.8408305455232, label=41, duration=0.1912626220146194, end=442.8408305455232, score=0.22286643686877727, velocity=83.61349661190592, intercept=37263.7121959465, speed=83.61349661190592, wcorr=-0.29648896966866667, P_decoder=0.17038128027412341, pearsonr=-0.389327760235538, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-213.4152409544913, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([31, 19, 50, 43, 18, 37, 52,  5, 32, 40, 17]), n_unique_aclus=11)\n",
      "an_epoch: EpochTuple(Index=21, start=442.6495679235086, stop=442.8408305455232, label=41, duration=0.1912626220146194, end=442.8408305455232, score=0.22286643686877727, velocity=83.61349661190592, intercept=37263.7121959465, speed=83.61349661190592, wcorr=-0.29648896966866667, P_decoder=0.17038128027412341, pearsonr=-0.389327760235538, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-213.4152409544913, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([31, 19, 50, 43, 18, 37, 52,  5, 32, 40, 17]), n_unique_aclus=11)\n",
      "an_epoch: EpochTuple(Index=21, start=442.6495679235086, stop=442.8408305455232, label=41, duration=0.1912626220146194, end=442.8408305455232, score=0.22286643686877727, velocity=83.61349661190592, intercept=37263.7121959465, speed=83.61349661190592, wcorr=-0.29648896966866667, P_decoder=0.17038128027412341, pearsonr=-0.389327760235538, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-213.4152409544913, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([31, 19, 50, 43, 18, 37, 52,  5, 32, 40, 17]), n_unique_aclus=11)\n",
      "an_epoch: EpochTuple(Index=21, start=442.6495679235086, stop=442.8408305455232, label=41, duration=0.1912626220146194, end=442.8408305455232, score=0.22286643686877727, velocity=83.61349661190592, intercept=37263.7121959465, speed=83.61349661190592, wcorr=-0.29648896966866667, P_decoder=0.17038128027412341, pearsonr=-0.389327760235538, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-213.4152409544913, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([31, 19, 50, 43, 18, 37, 52,  5, 32, 40, 17]), n_unique_aclus=11)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.1328468488320496, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.16577466995625206, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_041\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_041\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_041\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_041\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[33][\"p_x_given_n\"]): (59, 4, 8)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [7.89984e-05 0.000627016 0.000928319 0.998366]\n",
      "\t_long_any: 0.9992939850571524, _short_any: 0.0007060149428478417\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0135276 0.0254584 0.0412355 0.919778]\n",
      "\t_long_any: 0.9610140029556062, _short_any: 0.0389859970443935\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.201576 0 0.798424 0]\n",
      "\t_long_any: 0.7984238823958075, _short_any: 0.20157611760419253\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.07934 0 0.92066 0]\n",
      "\t_long_any: 0.920660019411214, _short_any: 0.07933998058878577\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.131547 0.394143 0.0188665 0.455444]\n",
      "\t_long_any: 0.47431040310049316, _short_any: 0.5256895968995073\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0234338 0.475895 0.00805449 0.492616]\n",
      "\t_long_any: 0.5006709287309232, _short_any: 0.49932907126907694\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.3885 0.225026 0.137701 0.248773]\n",
      "\t_long_any: 0.38647475361597433, _short_any: 0.6135252463840257\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.958385 0.00977402 0.00279884 0.0290419]\n",
      "\t_long_any: 0.031840753429792396, _short_any: 0.9681592465702072\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_041/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_041'\n",
      "processing an_epoch_idx: 22/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 22)\n",
      "an_epoch: EpochTuple(Index=22, start=458.06639202998485, stop=458.13529695465695, label=42, duration=0.06890492467209697, end=458.13529695465695, score=0.3777471450021883, velocity=-1463.236190708118, intercept=-670231.2772050445, speed=1463.236190708118, wcorr=0.8300115382345844, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-197.99841684801504, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([ 7, 45, 11, 17, 20, 19, 21, 24]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=22, start=458.06639202998485, stop=458.13529695465695, label=42, duration=0.06890492467209697, end=458.13529695465695, score=0.3777471450021883, velocity=-1463.236190708118, intercept=-670231.2772050445, speed=1463.236190708118, wcorr=0.8300115382345844, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-197.99841684801504, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([ 7, 45, 11, 17, 20, 19, 21, 24]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=22, start=458.06639202998485, stop=458.13529695465695, label=42, duration=0.06890492467209697, end=458.13529695465695, score=0.3777471450021883, velocity=-1463.236190708118, intercept=-670231.2772050445, speed=1463.236190708118, wcorr=0.8300115382345844, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-197.99841684801504, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([ 7, 45, 11, 17, 20, 19, 21, 24]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=22, start=458.06639202998485, stop=458.13529695465695, label=42, duration=0.06890492467209697, end=458.13529695465695, score=0.3777471450021883, velocity=-1463.236190708118, intercept=-670231.2772050445, speed=1463.236190708118, wcorr=0.8300115382345844, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-197.99841684801504, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([ 7, 45, 11, 17, 20, 19, 21, 24]), n_unique_aclus=8)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.10832426379331009, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (4, 59), np.nanmax(curr_data): 0.13918661674691393, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 4\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.14773746413841815, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (4, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 4\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_042\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_042\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_042\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_042\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[34][\"p_x_given_n\"]): (59, 4, 3)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.600257 0 0.399743 0]\n",
      "\t_long_any: 0.39974334649657717, _short_any: 0.6002566535034224\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.830976 0 0.169024 0]\n",
      "\t_long_any: 0.16902394787002173, _short_any: 0.8309760521299777\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_042/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_042'\n",
      "processing an_epoch_idx: 23/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 23)\n",
      "an_epoch: EpochTuple(Index=23, start=478.8597970638657, stop=479.13286700402386, label=45, duration=0.273069940158166, end=479.13286700402386, score=0.25354080439554755, velocity=39.01963175222534, intercept=18926.85465924119, speed=39.01963175222534, wcorr=0.03160374209741569, P_decoder=0.3222151658213974, pearsonr=-0.48908677055240535, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-177.2050118141342, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([43, 18, 40, 21, 37, 26, 31, 50,  9, 27]), n_unique_aclus=10)\n",
      "an_epoch: EpochTuple(Index=23, start=478.8597970638657, stop=479.13286700402386, label=45, duration=0.273069940158166, end=479.13286700402386, score=0.25354080439554755, velocity=39.01963175222534, intercept=18926.85465924119, speed=39.01963175222534, wcorr=0.03160374209741569, P_decoder=0.3222151658213974, pearsonr=-0.48908677055240535, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-177.2050118141342, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([43, 18, 40, 21, 37, 26, 31, 50,  9, 27]), n_unique_aclus=10)\n",
      "an_epoch: EpochTuple(Index=23, start=478.8597970638657, stop=479.13286700402386, label=45, duration=0.273069940158166, end=479.13286700402386, score=0.25354080439554755, velocity=39.01963175222534, intercept=18926.85465924119, speed=39.01963175222534, wcorr=0.03160374209741569, P_decoder=0.3222151658213974, pearsonr=-0.48908677055240535, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-177.2050118141342, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([43, 18, 40, 21, 37, 26, 31, 50,  9, 27]), n_unique_aclus=10)\n",
      "an_epoch: EpochTuple(Index=23, start=478.8597970638657, stop=479.13286700402386, label=45, duration=0.273069940158166, end=479.13286700402386, score=0.25354080439554755, velocity=39.01963175222534, intercept=18926.85465924119, speed=39.01963175222534, wcorr=0.03160374209741569, P_decoder=0.3222151658213974, pearsonr=-0.48908677055240535, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-177.2050118141342, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([43, 18, 40, 21, 37, 26, 31, 50,  9, 27]), n_unique_aclus=10)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.14933925445043028, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.16577466995625206, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_045\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_045\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_045\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_045\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[36][\"p_x_given_n\"]): (59, 4, 11)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.505606 0 0.494394 0]\n",
      "\t_long_any: 0.494393861745059, _short_any: 0.5056061382549412\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0562457 0.887489 0.000294478 0.0559705]\n",
      "\t_long_any: 0.056265008777520276, _short_any: 0.9437349912224795\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.00041734 0.948009 0.0017128 0.0498605]\n",
      "\t_long_any: 0.051573351165263466, _short_any: 0.9484266488347368\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.395579 0 0.604421 0]\n",
      "\t_long_any: 0.6044212891290719, _short_any: 0.3955787108709279\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.505606 0 0.494394 0]\n",
      "\t_long_any: 0.494393861745059, _short_any: 0.5056061382549412\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.298447 0.570574 0.0618172 0.0691619]\n",
      "\t_long_any: 0.1309791175682417, _short_any: 0.8690208824317585\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 10, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.283819 0 0.716181 0]\n",
      "\t_long_any: 0.7161809221228872, _short_any: 0.2838190778771126\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_045/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_045'\n",
      "processing an_epoch_idx: 24/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 24)\n",
      "an_epoch: EpochTuple(Index=24, start=495.7091861969093, stop=495.9309844832169, label=47, duration=0.22179828630760312, end=495.9309844832169, score=0.19018795365372235, velocity=-48.77453969028444, intercept=-23946.91799521704, speed=48.77453969028444, wcorr=-0.2460370462616427, P_decoder=0.33827973886690116, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-160.3556226810906, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([43, 10, 49,  5, 20, 21, 31,  9, 50, 27, 14, 18, 45, 41]), n_unique_aclus=14)\n",
      "an_epoch: EpochTuple(Index=24, start=495.7091861969093, stop=495.9309844832169, label=47, duration=0.22179828630760312, end=495.9309844832169, score=0.19018795365372235, velocity=-48.77453969028444, intercept=-23946.91799521704, speed=48.77453969028444, wcorr=-0.2460370462616427, P_decoder=0.33827973886690116, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-160.3556226810906, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([43, 10, 49,  5, 20, 21, 31,  9, 50, 27, 14, 18, 45, 41]), n_unique_aclus=14)\n",
      "an_epoch: EpochTuple(Index=24, start=495.7091861969093, stop=495.9309844832169, label=47, duration=0.22179828630760312, end=495.9309844832169, score=0.19018795365372235, velocity=-48.77453969028444, intercept=-23946.91799521704, speed=48.77453969028444, wcorr=-0.2460370462616427, P_decoder=0.33827973886690116, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-160.3556226810906, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([43, 10, 49,  5, 20, 21, 31,  9, 50, 27, 14, 18, 45, 41]), n_unique_aclus=14)\n",
      "an_epoch: EpochTuple(Index=24, start=495.7091861969093, stop=495.9309844832169, label=47, duration=0.22179828630760312, end=495.9309844832169, score=0.19018795365372235, velocity=-48.77453969028444, intercept=-23946.91799521704, speed=48.77453969028444, wcorr=-0.2460370462616427, P_decoder=0.33827973886690116, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-160.3556226810906, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([43, 10, 49,  5, 20, 21, 31,  9, 50, 27, 14, 18, 45, 41]), n_unique_aclus=14)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (10, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 10\n",
      "np.shape(curr_data): (12, 59), np.nanmax(curr_data): 0.14646292062398014, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 12\n",
      "np.shape(curr_data): (10, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 10\n",
      "np.shape(curr_data): (12, 59), np.nanmax(curr_data): 0.16577466995625206, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 12\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_047\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_047\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_047\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_047\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[37][\"p_x_given_n\"]): (59, 4, 9)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.505606 0 0.494394 0]\n",
      "\t_long_any: 0.494393861745059, _short_any: 0.5056061382549412\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.819533 0 0.180467]\n",
      "\t_long_any: 0.18046655822865934, _short_any: 0.8195334417713406\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.840672 0 0.159328 0]\n",
      "\t_long_any: 0.15932804173217463, _short_any: 0.8406719582678258\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.10908 0.115552 0.157043 0.618326]\n",
      "\t_long_any: 0.7753683204822507, _short_any: 0.22463167951774907\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.323112 0 0.676888 0]\n",
      "\t_long_any: 0.6768880364368612, _short_any: 0.32311196356313887\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.936378 0 0.0636224]\n",
      "\t_long_any: 0.06362238498566852, _short_any: 0.9363776150143314\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.961985 0 0.0380146]\n",
      "\t_long_any: 0.0380145642125545, _short_any: 0.9619854357874458\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.726068 0 0.273932 0]\n",
      "\t_long_any: 0.27393155240289135, _short_any: 0.726068447597109\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_047/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_047'\n",
      "processing an_epoch_idx: 25/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 25)\n",
      "an_epoch: EpochTuple(Index=25, start=497.2506535676075, stop=497.4454182679765, label=48, duration=0.19476470036897808, end=497.4454182679765, score=0.22368933360849902, velocity=-0.0, intercept=51.21326667479576, speed=0.0, wcorr=-0.16992023958786784, P_decoder=nan, pearsonr=0.2951792124994539, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-158.81415531039238, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([45, 24, 40, 23, 18,  7, 11, 20, 19]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=25, start=497.2506535676075, stop=497.4454182679765, label=48, duration=0.19476470036897808, end=497.4454182679765, score=0.22368933360849902, velocity=-0.0, intercept=51.21326667479576, speed=0.0, wcorr=-0.16992023958786784, P_decoder=nan, pearsonr=0.2951792124994539, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-158.81415531039238, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([45, 24, 40, 23, 18,  7, 11, 20, 19]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=25, start=497.2506535676075, stop=497.4454182679765, label=48, duration=0.19476470036897808, end=497.4454182679765, score=0.22368933360849902, velocity=-0.0, intercept=51.21326667479576, speed=0.0, wcorr=-0.16992023958786784, P_decoder=nan, pearsonr=0.2951792124994539, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-158.81415531039238, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([45, 24, 40, 23, 18,  7, 11, 20, 19]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=25, start=497.2506535676075, stop=497.4454182679765, label=48, duration=0.19476470036897808, end=497.4454182679765, score=0.22368933360849902, velocity=-0.0, intercept=51.21326667479576, speed=0.0, wcorr=-0.16992023958786784, P_decoder=nan, pearsonr=0.2951792124994539, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-158.81415531039238, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([45, 24, 40, 23, 18,  7, 11, 20, 19]), n_unique_aclus=9)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.10832426379331009, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (4, 59), np.nanmax(curr_data): 0.13918661674691393, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 4\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.14773746413841815, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (4, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 4\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_048\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_048\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_048\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_048\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[38][\"p_x_given_n\"]): (59, 4, 8)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.914217 0 0.085783 0]\n",
      "\t_long_any: 0.08578299727442264, _short_any: 0.9142170027255775\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.60101 0 0.39899 0]\n",
      "\t_long_any: 0.39898972537941546, _short_any: 0.601010274620585\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.703331 0.00213347 0.293991 0.000544165]\n",
      "\t_long_any: 0.29453510496529556, _short_any: 0.7054648950347042\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.171602 0.562345 0.137941 0.128112]\n",
      "\t_long_any: 0.2660532503894745, _short_any: 0.7339467496105261\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.957137 0 0.042863 0]\n",
      "\t_long_any: 0.042862959480528026, _short_any: 0.9571370405194717\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_048/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_048'\n",
      "processing an_epoch_idx: 26/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 26)\n",
      "an_epoch: EpochTuple(Index=26, start=500.226805643877, stop=500.41865194565617, label=50, duration=0.19184630177915096, end=500.41865194565617, score=0.2197805546073494, velocity=-167.22699322381217, intercept=-83436.46827357137, speed=167.22699322381217, wcorr=0.5683280225431278, P_decoder=0.14169397243916607, pearsonr=0.09066164954109235, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-155.83800323412288, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([14, 45,  9, 21, 44, 10, 41, 11, 18, 26, 37, 50]), n_unique_aclus=12)\n",
      "an_epoch: EpochTuple(Index=26, start=500.226805643877, stop=500.41865194565617, label=50, duration=0.19184630177915096, end=500.41865194565617, score=0.2197805546073494, velocity=-167.22699322381217, intercept=-83436.46827357137, speed=167.22699322381217, wcorr=0.5683280225431278, P_decoder=0.14169397243916607, pearsonr=0.09066164954109235, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-155.83800323412288, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([14, 45,  9, 21, 44, 10, 41, 11, 18, 26, 37, 50]), n_unique_aclus=12)\n",
      "an_epoch: EpochTuple(Index=26, start=500.226805643877, stop=500.41865194565617, label=50, duration=0.19184630177915096, end=500.41865194565617, score=0.2197805546073494, velocity=-167.22699322381217, intercept=-83436.46827357137, speed=167.22699322381217, wcorr=0.5683280225431278, P_decoder=0.14169397243916607, pearsonr=0.09066164954109235, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-155.83800323412288, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([14, 45,  9, 21, 44, 10, 41, 11, 18, 26, 37, 50]), n_unique_aclus=12)\n",
      "an_epoch: EpochTuple(Index=26, start=500.226805643877, stop=500.41865194565617, label=50, duration=0.19184630177915096, end=500.41865194565617, score=0.2197805546073494, velocity=-167.22699322381217, intercept=-83436.46827357137, speed=167.22699322381217, wcorr=0.5683280225431278, P_decoder=0.14169397243916607, pearsonr=0.09066164954109235, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-155.83800323412288, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([14, 45,  9, 21, 44, 10, 41, 11, 18, 26, 37, 50]), n_unique_aclus=12)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (12, 59), np.nanmax(curr_data): 0.14933925445043028, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 12\n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (12, 59), np.nanmax(curr_data): 0.16577466995625206, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 12\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_050\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_050\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_050\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_050\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[40][\"p_x_given_n\"]): (59, 4, 8)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.666406 0 0.333594]\n",
      "\t_long_any: 0.3335944527748874, _short_any: 0.666405547225113\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.543054 0 0.456946]\n",
      "\t_long_any: 0.4569461343392612, _short_any: 0.5430538656607389\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.250985 0.692917 0.00624893 0.0498491]\n",
      "\t_long_any: 0.05609802405527569, _short_any: 0.9439019759447247\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.433296 0.215056 0.27909 0.0725591]\n",
      "\t_long_any: 0.3516485729942037, _short_any: 0.6483514270057958\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.218238 0.575644 0.0638975 0.14222]\n",
      "\t_long_any: 0.20611765408589516, _short_any: 0.7938823459141054\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0869381 0.768053 0.0520664 0.0929422]\n",
      "\t_long_any: 0.14500860282222938, _short_any: 0.8549913971777701\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.993549 0 0.00645085]\n",
      "\t_long_any: 0.006450846650760551, _short_any: 0.9935491533492397\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.00186644 0.961177 0.0227257 0.014231]\n",
      "\t_long_any: 0.036956706642139785, _short_any: 0.9630432933578605\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_050/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_050'\n",
      "processing an_epoch_idx: 27/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 27)\n",
      "an_epoch: EpochTuple(Index=27, start=518.398966579698, stop=518.813102687709, label=52, duration=0.4141361080110073, end=518.813102687709, score=0.1710953389821346, velocity=-36.5809047677133, intercept=-18722.526517975628, speed=36.5809047677133, wcorr=-0.20187855831406135, P_decoder=nan, pearsonr=-0.6717867082988784, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-137.66584229830187, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([32, 31, 50, 43, 11, 20, 21, 49, 15, 24, 10, 23, 45]), n_unique_aclus=13)\n",
      "an_epoch: EpochTuple(Index=27, start=518.398966579698, stop=518.813102687709, label=52, duration=0.4141361080110073, end=518.813102687709, score=0.1710953389821346, velocity=-36.5809047677133, intercept=-18722.526517975628, speed=36.5809047677133, wcorr=-0.20187855831406135, P_decoder=nan, pearsonr=-0.6717867082988784, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-137.66584229830187, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([32, 31, 50, 43, 11, 20, 21, 49, 15, 24, 10, 23, 45]), n_unique_aclus=13)\n",
      "an_epoch: EpochTuple(Index=27, start=518.398966579698, stop=518.813102687709, label=52, duration=0.4141361080110073, end=518.813102687709, score=0.1710953389821346, velocity=-36.5809047677133, intercept=-18722.526517975628, speed=36.5809047677133, wcorr=-0.20187855831406135, P_decoder=nan, pearsonr=-0.6717867082988784, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-137.66584229830187, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([32, 31, 50, 43, 11, 20, 21, 49, 15, 24, 10, 23, 45]), n_unique_aclus=13)\n",
      "an_epoch: EpochTuple(Index=27, start=518.398966579698, stop=518.813102687709, label=52, duration=0.4141361080110073, end=518.813102687709, score=0.1710953389821346, velocity=-36.5809047677133, intercept=-18722.526517975628, speed=36.5809047677133, wcorr=-0.20187855831406135, P_decoder=nan, pearsonr=-0.6717867082988784, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-137.66584229830187, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([32, 31, 50, 43, 11, 20, 21, 49, 15, 24, 10, 23, 45]), n_unique_aclus=13)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (10, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 10\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.13918661674691393, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (10, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 10\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.16577466995625206, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_052\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_052\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_052\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_052\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[41][\"p_x_given_n\"]): (59, 4, 17)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0130698 3.89182e-05 0.980709 0.00618232]\n",
      "\t_long_any: 0.986891303512468, _short_any: 0.013108696487532772\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0010854 0.00413768 0.0066023 0.988175]\n",
      "\t_long_any: 0.994776912291068, _short_any: 0.005223087708931808\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.235604 0.075862 0.52586 0.162673]\n",
      "\t_long_any: 0.6885338732110056, _short_any: 0.31146612678899477\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0359215 0 0.964079 0]\n",
      "\t_long_any: 0.9640785332748891, _short_any: 0.03592146672511092\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 10, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 11, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 12, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.808829 0 0.191171]\n",
      "\t_long_any: 0.19117095485433833, _short_any: 0.8088290451456619\n",
      "i: 13, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 14, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 15, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.719588 0 0.280412 0]\n",
      "\t_long_any: 0.2804119544080999, _short_any: 0.7195880455918999\n",
      "i: 16, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.711197 0 0.288803 0]\n",
      "\t_long_any: 0.2888032694280382, _short_any: 0.711196730571962\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_052/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_052'\n",
      "processing an_epoch_idx: 28/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 28)\n",
      "an_epoch: EpochTuple(Index=28, start=533.2427400996676, stop=533.4364910405129, label=53, duration=0.19375094084534794, end=533.4364910405129, score=0.1961007354494521, velocity=-682.843555664047, intercept=-363951.87715627265, speed=682.843555664047, wcorr=-0.1212469706173374, P_decoder=0.1170447065972268, pearsonr=0.7146879492539918, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-122.82206877833232, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([53, 35, 27, 49, 37, 15, 24, 52,  9, 39, 50, 14, 31]), n_unique_aclus=13)\n",
      "an_epoch: EpochTuple(Index=28, start=533.2427400996676, stop=533.4364910405129, label=53, duration=0.19375094084534794, end=533.4364910405129, score=0.1961007354494521, velocity=-682.843555664047, intercept=-363951.87715627265, speed=682.843555664047, wcorr=-0.1212469706173374, P_decoder=0.1170447065972268, pearsonr=0.7146879492539918, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-122.82206877833232, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([53, 35, 27, 49, 37, 15, 24, 52,  9, 39, 50, 14, 31]), n_unique_aclus=13)\n",
      "an_epoch: EpochTuple(Index=28, start=533.2427400996676, stop=533.4364910405129, label=53, duration=0.19375094084534794, end=533.4364910405129, score=0.1961007354494521, velocity=-682.843555664047, intercept=-363951.87715627265, speed=682.843555664047, wcorr=-0.1212469706173374, P_decoder=0.1170447065972268, pearsonr=0.7146879492539918, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-122.82206877833232, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([53, 35, 27, 49, 37, 15, 24, 52,  9, 39, 50, 14, 31]), n_unique_aclus=13)\n",
      "an_epoch: EpochTuple(Index=28, start=533.2427400996676, stop=533.4364910405129, label=53, duration=0.19375094084534794, end=533.4364910405129, score=0.1961007354494521, velocity=-682.843555664047, intercept=-363951.87715627265, speed=682.843555664047, wcorr=-0.1212469706173374, P_decoder=0.1170447065972268, pearsonr=0.7146879492539918, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-122.82206877833232, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([53, 35, 27, 49, 37, 15, 24, 52,  9, 39, 50, 14, 31]), n_unique_aclus=13)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (11, 59), np.nanmax(curr_data): 0.14646292062398014, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 11\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (11, 59), np.nanmax(curr_data): 0.17673647253127112, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 11\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_053\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_053\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_053\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_053\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[42][\"p_x_given_n\"]): (59, 4, 8)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.0424587 0 0.957541]\n",
      "\t_long_any: 0.9575413289295099, _short_any: 0.04245867107048967\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.849393 0 0.150607]\n",
      "\t_long_any: 0.15060739553508862, _short_any: 0.8493926044649113\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.502465 0 0.497535 0]\n",
      "\t_long_any: 0.49753515367278806, _short_any: 0.5024648463272116\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.265632 0 0.734368]\n",
      "\t_long_any: 0.7343675093458686, _short_any: 0.26563249065413075\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.7398 0 0.2602 0]\n",
      "\t_long_any: 0.2601998823615575, _short_any: 0.7398001176384423\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.794163 0 0.205837]\n",
      "\t_long_any: 0.20583698753982638, _short_any: 0.7941630124601736\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0848744 0.0506129 0.0842357 0.780277]\n",
      "\t_long_any: 0.8645127148825162, _short_any: 0.13548728511748365\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0135276 0.0254584 0.0412355 0.919778]\n",
      "\t_long_any: 0.9610140029556062, _short_any: 0.0389859970443935\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_053/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_053'\n",
      "processing an_epoch_idx: 29/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 29)\n",
      "an_epoch: EpochTuple(Index=29, start=535.373478208785, stop=535.4735946375877, label=54, duration=0.1001164288027212, end=535.4735946375877, score=0.25620481129300643, velocity=-292.64723814162363, intercept=-156632.89204984665, speed=292.64723814162363, wcorr=-0.03726438500627031, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-120.69133066921495, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([45,  9, 20, 37, 17, 49, 32, 40]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=29, start=535.373478208785, stop=535.4735946375877, label=54, duration=0.1001164288027212, end=535.4735946375877, score=0.25620481129300643, velocity=-292.64723814162363, intercept=-156632.89204984665, speed=292.64723814162363, wcorr=-0.03726438500627031, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-120.69133066921495, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([45,  9, 20, 37, 17, 49, 32, 40]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=29, start=535.373478208785, stop=535.4735946375877, label=54, duration=0.1001164288027212, end=535.4735946375877, score=0.25620481129300643, velocity=-292.64723814162363, intercept=-156632.89204984665, speed=292.64723814162363, wcorr=-0.03726438500627031, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-120.69133066921495, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([45,  9, 20, 37, 17, 49, 32, 40]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=29, start=535.373478208785, stop=535.4735946375877, label=54, duration=0.1001164288027212, end=535.4735946375877, score=0.25620481129300643, velocity=-292.64723814162363, intercept=-156632.89204984665, speed=292.64723814162363, wcorr=-0.03726438500627031, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-120.69133066921495, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([45,  9, 20, 37, 17, 49, 32, 40]), n_unique_aclus=8)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (5, 59), np.nanmax(curr_data): 0.13026806747808126, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 5\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.13918661674691393, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (5, 59), np.nanmax(curr_data): 0.11369299138191882, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 5\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_054\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_054\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_054\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_054\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[43][\"p_x_given_n\"]): (59, 4, 5)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.621891 0.0122324 0.360753 0.00512414]\n",
      "\t_long_any: 0.3658767436006062, _short_any: 0.6341232563993943\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.831267 0.0322726 0.0284433 0.108017]\n",
      "\t_long_any: 0.136460330009821, _short_any: 0.863539669990179\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.3885 0.225026 0.137701 0.248773]\n",
      "\t_long_any: 0.38647475361597433, _short_any: 0.6135252463840257\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_054/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_054'\n",
      "processing an_epoch_idx: 30/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 30)\n",
      "an_epoch: EpochTuple(Index=30, start=535.6538287852891, stop=535.8123131840257, label=55, duration=0.15848439873661846, end=535.8123131840257, score=0.3889369361997233, velocity=1170.588952566938, intercept=627247.5010778633, speed=1170.588952566938, wcorr=-0.9442392344651768, P_decoder=0.7490598808125207, pearsonr=0.6170840929090388, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-120.41098009271082, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([46, 37,  5, 23, 24,  4, 19, 45, 41,  9, 52, 40,  7, 20]), n_unique_aclus=14)\n",
      "an_epoch: EpochTuple(Index=30, start=535.6538287852891, stop=535.8123131840257, label=55, duration=0.15848439873661846, end=535.8123131840257, score=0.3889369361997233, velocity=1170.588952566938, intercept=627247.5010778633, speed=1170.588952566938, wcorr=-0.9442392344651768, P_decoder=0.7490598808125207, pearsonr=0.6170840929090388, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-120.41098009271082, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([46, 37,  5, 23, 24,  4, 19, 45, 41,  9, 52, 40,  7, 20]), n_unique_aclus=14)\n",
      "an_epoch: EpochTuple(Index=30, start=535.6538287852891, stop=535.8123131840257, label=55, duration=0.15848439873661846, end=535.8123131840257, score=0.3889369361997233, velocity=1170.588952566938, intercept=627247.5010778633, speed=1170.588952566938, wcorr=-0.9442392344651768, P_decoder=0.7490598808125207, pearsonr=0.6170840929090388, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-120.41098009271082, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([46, 37,  5, 23, 24,  4, 19, 45, 41,  9, 52, 40,  7, 20]), n_unique_aclus=14)\n",
      "an_epoch: EpochTuple(Index=30, start=535.6538287852891, stop=535.8123131840257, label=55, duration=0.15848439873661846, end=535.8123131840257, score=0.3889369361997233, velocity=1170.588952566938, intercept=627247.5010778633, speed=1170.588952566938, wcorr=-0.9442392344651768, P_decoder=0.7490598808125207, pearsonr=0.6170840929090388, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-120.41098009271082, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([46, 37,  5, 23, 24,  4, 19, 45, 41,  9, 52, 40,  7, 20]), n_unique_aclus=14)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (13, 59), np.nanmax(curr_data): 0.1306753907929282, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 13\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.13918661674691393, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (13, 59), np.nanmax(curr_data): 0.14773746413841815, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 13\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_055\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_055\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_055\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_055\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[44][\"p_x_given_n\"]): (59, 4, 7)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.936611 0 0.0633891 0]\n",
      "\t_long_any: 0.06338906636391495, _short_any: 0.9366109336360852\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.978235 0 0.021765 0]\n",
      "\t_long_any: 0.02176500457594733, _short_any: 0.9782349954240526\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.817156 0 0.182844 0]\n",
      "\t_long_any: 0.18284379696623476, _short_any: 0.8171562030337649\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.804292 0 0.195708 0]\n",
      "\t_long_any: 0.195708054775233, _short_any: 0.8042919452247671\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.221219 0.308497 0.0117509 0.458533]\n",
      "\t_long_any: 0.47028351139549124, _short_any: 0.5297164886045095\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.999615 0 0.000384689 0]\n",
      "\t_long_any: 0.0003846894974457613, _short_any: 0.9996153105025544\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.823049 0 0.176951 0]\n",
      "\t_long_any: 0.17695106365027896, _short_any: 0.8230489363497209\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_055/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_055'\n",
      "processing an_epoch_idx: 31/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 31)\n",
      "an_epoch: EpochTuple(Index=31, start=536.7972880398156, stop=536.8959299093112, label=56, duration=0.09864186949562281, end=536.8959299093112, score=0.7710799979093376, velocity=-130.0654391740056, intercept=-69583.84431680561, speed=130.0654391740056, wcorr=0.20459345209205448, P_decoder=nan, pearsonr=0.04954399651150209, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-119.26752083818428, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([43, 11,  5, 17, 18, 26, 50, 20, 31, 52, 32]), n_unique_aclus=11)\n",
      "an_epoch: EpochTuple(Index=31, start=536.7972880398156, stop=536.8959299093112, label=56, duration=0.09864186949562281, end=536.8959299093112, score=0.7710799979093376, velocity=-130.0654391740056, intercept=-69583.84431680561, speed=130.0654391740056, wcorr=0.20459345209205448, P_decoder=nan, pearsonr=0.04954399651150209, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-119.26752083818428, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([43, 11,  5, 17, 18, 26, 50, 20, 31, 52, 32]), n_unique_aclus=11)\n",
      "an_epoch: EpochTuple(Index=31, start=536.7972880398156, stop=536.8959299093112, label=56, duration=0.09864186949562281, end=536.8959299093112, score=0.7710799979093376, velocity=-130.0654391740056, intercept=-69583.84431680561, speed=130.0654391740056, wcorr=0.20459345209205448, P_decoder=nan, pearsonr=0.04954399651150209, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-119.26752083818428, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([43, 11,  5, 17, 18, 26, 50, 20, 31, 52, 32]), n_unique_aclus=11)\n",
      "an_epoch: EpochTuple(Index=31, start=536.7972880398156, stop=536.8959299093112, label=56, duration=0.09864186949562281, end=536.8959299093112, score=0.7710799979093376, velocity=-130.0654391740056, intercept=-69583.84431680561, speed=130.0654391740056, wcorr=0.20459345209205448, P_decoder=nan, pearsonr=0.04954399651150209, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-119.26752083818428, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([43, 11,  5, 17, 18, 26, 50, 20, 31, 52, 32]), n_unique_aclus=11)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.14933925445043028, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.16577466995625206, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_056\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_056\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_056\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_056\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[45][\"p_x_given_n\"]): (59, 4, 4)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.271475 0 0.728525 0]\n",
      "\t_long_any: 0.7285246692228783, _short_any: 0.2714753307771219\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.20537 0.455115 0.335104 0.0044114]\n",
      "\t_long_any: 0.3395150373787381, _short_any: 0.6604849626212619\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_056/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_056'\n",
      "processing an_epoch_idx: 32/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 32)\n",
      "an_epoch: EpochTuple(Index=32, start=540.199004058144, stop=540.4423063334543, label=57, duration=0.2433022753102705, end=540.4423063334543, score=0.2144687121181887, velocity=21.677573195678583, intercept=11771.442594980888, speed=21.677573195678583, wcorr=-0.25697322801575156, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-115.86580481985584, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([43, 21, 20, 53, 37,  5,  4, 10, 23, 27, 19, 45,  7, 40, 11]), n_unique_aclus=15)\n",
      "an_epoch: EpochTuple(Index=32, start=540.199004058144, stop=540.4423063334543, label=57, duration=0.2433022753102705, end=540.4423063334543, score=0.2144687121181887, velocity=21.677573195678583, intercept=11771.442594980888, speed=21.677573195678583, wcorr=-0.25697322801575156, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-115.86580481985584, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([43, 21, 20, 53, 37,  5,  4, 10, 23, 27, 19, 45,  7, 40, 11]), n_unique_aclus=15)\n",
      "an_epoch: EpochTuple(Index=32, start=540.199004058144, stop=540.4423063334543, label=57, duration=0.2433022753102705, end=540.4423063334543, score=0.2144687121181887, velocity=21.677573195678583, intercept=11771.442594980888, speed=21.677573195678583, wcorr=-0.25697322801575156, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-115.86580481985584, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([43, 21, 20, 53, 37,  5,  4, 10, 23, 27, 19, 45,  7, 40, 11]), n_unique_aclus=15)\n",
      "an_epoch: EpochTuple(Index=32, start=540.199004058144, stop=540.4423063334543, label=57, duration=0.2433022753102705, end=540.4423063334543, score=0.2144687121181887, velocity=21.677573195678583, intercept=11771.442594980888, speed=21.677573195678583, wcorr=-0.25697322801575156, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-115.86580481985584, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([43, 21, 20, 53, 37,  5,  4, 10, 23, 27, 19, 45,  7, 40, 11]), n_unique_aclus=15)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (13, 59), np.nanmax(curr_data): 0.10832426379331009, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 13\n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.13918661674691393, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (13, 59), np.nanmax(curr_data): 0.1490508567103094, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 13\n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.17673647253127112, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_057\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_057\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_057\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_057\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[46][\"p_x_given_n\"]): (59, 4, 10)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.629003 0 0.370997 0]\n",
      "\t_long_any: 0.37099744101475846, _short_any: 0.6290025589852413\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.960715 0 0.0392851 0]\n",
      "\t_long_any: 0.03928511601048701, _short_any: 0.960714883989513\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.554975 0 0.445025 0]\n",
      "\t_long_any: 0.445025457995953, _short_any: 0.5549745420040473\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.179966 0 0.820034]\n",
      "\t_long_any: 0.8200338132548826, _short_any: 0.17996618674511744\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.401826 0.222795 0.0835336 0.291845]\n",
      "\t_long_any: 0.3753785335947758, _short_any: 0.6246214664052238\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.925832 0 0.0741677 0]\n",
      "\t_long_any: 0.07416774449962651, _short_any: 0.9258322555003737\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.201243 0 0.798757 0]\n",
      "\t_long_any: 0.7987566380037676, _short_any: 0.20124336199623266\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.70435 0 0.29565 0]\n",
      "\t_long_any: 0.29564962290519414, _short_any: 0.7043503770948057\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.999788 0 0.000211741 0]\n",
      "\t_long_any: 0.00021174067768550716, _short_any: 0.9997882593223149\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_057/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_057'\n",
      "processing an_epoch_idx: 33/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 33)\n",
      "an_epoch: EpochTuple(Index=33, start=541.2640966328327, stop=541.4858334792079, label=58, duration=0.22173684637527913, end=541.4858334792079, score=0.22895247822130071, velocity=634.0690159735177, intercept=343453.03042191087, speed=634.0690159735177, wcorr=-0.26156131956146755, P_decoder=0.09276325410519938, pearsonr=-0.3292992672514911, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-114.80071224516723, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([18, 50, 26, 37, 25, 49, 27, 52, 41, 10, 17]), n_unique_aclus=11)\n",
      "an_epoch: EpochTuple(Index=33, start=541.2640966328327, stop=541.4858334792079, label=58, duration=0.22173684637527913, end=541.4858334792079, score=0.22895247822130071, velocity=634.0690159735177, intercept=343453.03042191087, speed=634.0690159735177, wcorr=-0.26156131956146755, P_decoder=0.09276325410519938, pearsonr=-0.3292992672514911, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-114.80071224516723, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([18, 50, 26, 37, 25, 49, 27, 52, 41, 10, 17]), n_unique_aclus=11)\n",
      "an_epoch: EpochTuple(Index=33, start=541.2640966328327, stop=541.4858334792079, label=58, duration=0.22173684637527913, end=541.4858334792079, score=0.22895247822130071, velocity=634.0690159735177, intercept=343453.03042191087, speed=634.0690159735177, wcorr=-0.26156131956146755, P_decoder=0.09276325410519938, pearsonr=-0.3292992672514911, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-114.80071224516723, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([18, 50, 26, 37, 25, 49, 27, 52, 41, 10, 17]), n_unique_aclus=11)\n",
      "an_epoch: EpochTuple(Index=33, start=541.2640966328327, stop=541.4858334792079, label=58, duration=0.22173684637527913, end=541.4858334792079, score=0.22895247822130071, velocity=634.0690159735177, intercept=343453.03042191087, speed=634.0690159735177, wcorr=-0.26156131956146755, P_decoder=0.09276325410519938, pearsonr=-0.3292992672514911, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-114.80071224516723, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([18, 50, 26, 37, 25, 49, 27, 52, 41, 10, 17]), n_unique_aclus=11)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (11, 59), np.nanmax(curr_data): 0.16871442757882205, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 11\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (11, 59), np.nanmax(curr_data): 0.16771957548724484, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 11\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_058\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_058\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_058\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_058\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[47][\"p_x_given_n\"]): (59, 4, 9)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.996444 0 0.00355578]\n",
      "\t_long_any: 0.003555777508637579, _short_any: 0.9964442224913623\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.171602 0.562345 0.137941 0.128112]\n",
      "\t_long_any: 0.2660532503894745, _short_any: 0.7339467496105261\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.849393 0 0.150607]\n",
      "\t_long_any: 0.15060739553508862, _short_any: 0.8493926044649113\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.849393 0 0.150607]\n",
      "\t_long_any: 0.15060739553508862, _short_any: 0.8493926044649113\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0188642 0.679285 0.0141107 0.287741]\n",
      "\t_long_any: 0.30185121892055755, _short_any: 0.6981487810794424\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [3.87131e-05 0.971863 7.72983e-06 0.0280906]\n",
      "\t_long_any: 0.028098281730234098, _short_any: 0.9719017182697648\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.00436394 0.833835 0.000828705 0.160972]\n",
      "\t_long_any: 0.16180084923768895, _short_any: 0.8381991507623111\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.240982 0.48712 0.117172 0.154727]\n",
      "\t_long_any: 0.2718985060221877, _short_any: 0.7281014939778122\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.171602 0.562345 0.137941 0.128112]\n",
      "\t_long_any: 0.2660532503894745, _short_any: 0.7339467496105261\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_058/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_058'\n",
      "processing an_epoch_idx: 34/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 34)\n",
      "an_epoch: EpochTuple(Index=34, start=564.5677851812216, stop=564.7588942034636, label=62, duration=0.1911090222420171, end=564.7588942034636, score=0.20761779158292315, velocity=-55.74233107462211, intercept=-31424.68536207045, speed=55.74233107462211, wcorr=-0.11329973115254494, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-91.49702369677834, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([40, 45, 20,  7, 17, 19, 49, 21]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=34, start=564.5677851812216, stop=564.7588942034636, label=62, duration=0.1911090222420171, end=564.7588942034636, score=0.20761779158292315, velocity=-55.74233107462211, intercept=-31424.68536207045, speed=55.74233107462211, wcorr=-0.11329973115254494, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-91.49702369677834, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([40, 45, 20,  7, 17, 19, 49, 21]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=34, start=564.5677851812216, stop=564.7588942034636, label=62, duration=0.1911090222420171, end=564.7588942034636, score=0.20761779158292315, velocity=-55.74233107462211, intercept=-31424.68536207045, speed=55.74233107462211, wcorr=-0.11329973115254494, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-91.49702369677834, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([40, 45, 20,  7, 17, 19, 49, 21]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=34, start=564.5677851812216, stop=564.7588942034636, label=62, duration=0.1911090222420171, end=564.7588942034636, score=0.20761779158292315, velocity=-55.74233107462211, intercept=-31424.68536207045, speed=55.74233107462211, wcorr=-0.11329973115254494, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-91.49702369677834, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([40, 45, 20,  7, 17, 19, 49, 21]), n_unique_aclus=8)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.10832426379331009, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (5, 59), np.nanmax(curr_data): 0.13918661674691393, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 5\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.14773746413841815, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (5, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 5\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_062\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_062\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_062\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_062\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[51][\"p_x_given_n\"]): (59, 4, 8)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.806542 0.0167766 0.168383 0.00829852]\n",
      "\t_long_any: 0.1766819040630121, _short_any: 0.8233180959369882\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.3885 0.225026 0.137701 0.248773]\n",
      "\t_long_any: 0.38647475361597433, _short_any: 0.6135252463840257\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.99858 0 0.00141953 0]\n",
      "\t_long_any: 0.0014195335565290808, _short_any: 0.9985804664434703\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.610973 0 0.389027 0]\n",
      "\t_long_any: 0.38902709639002486, _short_any: 0.6109729036099754\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_062/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_062'\n",
      "processing an_epoch_idx: 35/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 35)\n",
      "an_epoch: EpochTuple(Index=35, start=587.240915332688, stop=587.3053351396229, label=63, duration=0.06441980693489313, end=587.3053351396229, score=0.46504038149039356, velocity=-292.64723814195634, intercept=-171811.7542738366, speed=292.64723814195634, wcorr=0.5687043787782246, P_decoder=nan, pearsonr=-0.6435357886217425, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-68.82389354531188, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([24, 40, 45, 25,  7, 20, 19, 18]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=35, start=587.240915332688, stop=587.3053351396229, label=63, duration=0.06441980693489313, end=587.3053351396229, score=0.46504038149039356, velocity=-292.64723814195634, intercept=-171811.7542738366, speed=292.64723814195634, wcorr=0.5687043787782246, P_decoder=nan, pearsonr=-0.6435357886217425, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-68.82389354531188, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([24, 40, 45, 25,  7, 20, 19, 18]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=35, start=587.240915332688, stop=587.3053351396229, label=63, duration=0.06441980693489313, end=587.3053351396229, score=0.46504038149039356, velocity=-292.64723814195634, intercept=-171811.7542738366, speed=292.64723814195634, wcorr=0.5687043787782246, P_decoder=nan, pearsonr=-0.6435357886217425, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-68.82389354531188, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([24, 40, 45, 25,  7, 20, 19, 18]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=35, start=587.240915332688, stop=587.3053351396229, label=63, duration=0.06441980693489313, end=587.3053351396229, score=0.46504038149039356, velocity=-292.64723814195634, intercept=-171811.7542738366, speed=292.64723814195634, wcorr=0.5687043787782246, P_decoder=nan, pearsonr=-0.6435357886217425, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-68.82389354531188, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([24, 40, 45, 25,  7, 20, 19, 18]), n_unique_aclus=8)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.10832426379331009, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (4, 59), np.nanmax(curr_data): 0.16871442757882205, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 4\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.14773746413841815, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (4, 59), np.nanmax(curr_data): 0.16771957548724484, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 4\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_063\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_063\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_063\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_063\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[52][\"p_x_given_n\"]): (59, 4, 3)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.999257 0 0.000743169 0]\n",
      "\t_long_any: 0.0007431687099626198, _short_any: 0.9992568312900374\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.535236 0 0.464764 0]\n",
      "\t_long_any: 0.46476366721338813, _short_any: 0.5352363327866119\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_063/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_063'\n",
      "processing an_epoch_idx: 36/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 36)\n",
      "an_epoch: EpochTuple(Index=36, start=587.920011304901, stop=588.0081776598236, label=64, duration=0.08816635492257774, end=588.0081776598236, score=0.6873565957470196, velocity=65.03271958700299, intercept=38481.16156921002, speed=65.03271958700299, wcorr=0.03449050193054153, P_decoder=0.14961308845440394, pearsonr=-0.07079386233804602, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-68.14479757309891, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([18, 49, 37, 26, 50, 31, 32, 43]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=36, start=587.920011304901, stop=588.0081776598236, label=64, duration=0.08816635492257774, end=588.0081776598236, score=0.6873565957470196, velocity=65.03271958700299, intercept=38481.16156921002, speed=65.03271958700299, wcorr=0.03449050193054153, P_decoder=0.14961308845440394, pearsonr=-0.07079386233804602, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-68.14479757309891, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([18, 49, 37, 26, 50, 31, 32, 43]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=36, start=587.920011304901, stop=588.0081776598236, label=64, duration=0.08816635492257774, end=588.0081776598236, score=0.6873565957470196, velocity=65.03271958700299, intercept=38481.16156921002, speed=65.03271958700299, wcorr=0.03449050193054153, P_decoder=0.14961308845440394, pearsonr=-0.07079386233804602, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-68.14479757309891, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([18, 49, 37, 26, 50, 31, 32, 43]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=36, start=587.920011304901, stop=588.0081776598236, label=64, duration=0.08816635492257774, end=588.0081776598236, score=0.6873565957470196, velocity=65.03271958700299, intercept=38481.16156921002, speed=65.03271958700299, wcorr=0.03449050193054153, P_decoder=0.14961308845440394, pearsonr=-0.07079386233804602, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-68.14479757309891, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([18, 49, 37, 26, 50, 31, 32, 43]), n_unique_aclus=8)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.14933925445043028, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.16577466995625206, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_064\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_064\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_064\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_064\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[53][\"p_x_given_n\"]): (59, 4, 4)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.981065 0 0.0189355]\n",
      "\t_long_any: 0.01893547060204915, _short_any: 0.9810645293979506\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.00152076 0.865163 0.00813934 0.125177]\n",
      "\t_long_any: 0.13331595666300802, _short_any: 0.8666840433369919\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0162525 0.042608 0.120847 0.820293]\n",
      "\t_long_any: 0.9411395213060184, _short_any: 0.05886047869398196\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.180847 0 0.819153 0]\n",
      "\t_long_any: 0.8191533320483266, _short_any: 0.18084666795167337\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_064/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_064'\n",
      "processing an_epoch_idx: 37/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 37)\n",
      "an_epoch: EpochTuple(Index=37, start=615.09137659322, stop=615.2380030781496, label=66, duration=0.14662648492958397, end=615.2380030781496, score=0.28917464111226143, velocity=-624.3141080356055, intercept=-383986.32461374067, speed=624.3141080356055, wcorr=0.6562503418935475, P_decoder=0.7688365641178626, pearsonr=0.030022988560363173, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-40.97343228477985, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([18, 23, 45,  7, 20, 40, 52, 21, 41,  5, 19,  4]), n_unique_aclus=12)\n",
      "an_epoch: EpochTuple(Index=37, start=615.09137659322, stop=615.2380030781496, label=66, duration=0.14662648492958397, end=615.2380030781496, score=0.28917464111226143, velocity=-624.3141080356055, intercept=-383986.32461374067, speed=624.3141080356055, wcorr=0.6562503418935475, P_decoder=0.7688365641178626, pearsonr=0.030022988560363173, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-40.97343228477985, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([18, 23, 45,  7, 20, 40, 52, 21, 41,  5, 19,  4]), n_unique_aclus=12)\n",
      "an_epoch: EpochTuple(Index=37, start=615.09137659322, stop=615.2380030781496, label=66, duration=0.14662648492958397, end=615.2380030781496, score=0.28917464111226143, velocity=-624.3141080356055, intercept=-383986.32461374067, speed=624.3141080356055, wcorr=0.6562503418935475, P_decoder=0.7688365641178626, pearsonr=0.030022988560363173, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-40.97343228477985, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([18, 23, 45,  7, 20, 40, 52, 21, 41,  5, 19,  4]), n_unique_aclus=12)\n",
      "an_epoch: EpochTuple(Index=37, start=615.09137659322, stop=615.2380030781496, label=66, duration=0.14662648492958397, end=615.2380030781496, score=0.28917464111226143, velocity=-624.3141080356055, intercept=-383986.32461374067, speed=624.3141080356055, wcorr=0.6562503418935475, P_decoder=0.7688365641178626, pearsonr=0.030022988560363173, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-40.97343228477985, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([18, 23, 45,  7, 20, 40, 52, 21, 41,  5, 19,  4]), n_unique_aclus=12)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (12, 59), np.nanmax(curr_data): 0.10832426379331009, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 12\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.13918661674691393, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (12, 59), np.nanmax(curr_data): 0.14773746413841815, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 12\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_066\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_066\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_066\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_066\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[54][\"p_x_given_n\"]): (59, 4, 6)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.915411 0 0.084589 0]\n",
      "\t_long_any: 0.08458900969438128, _short_any: 0.9154109903056185\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.997337 0 0.00266287 0]\n",
      "\t_long_any: 0.002662874833492344, _short_any: 0.9973371251665076\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.960734 0 0.0392655 0]\n",
      "\t_long_any: 0.039265507096418954, _short_any: 0.9607344929035814\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.221219 0.308497 0.0117509 0.458533]\n",
      "\t_long_any: 0.47028351139549124, _short_any: 0.5297164886045095\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.913127 0 0.0868729 0]\n",
      "\t_long_any: 0.08687291707143915, _short_any: 0.9131270829285607\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.972853 0 0.0271471 0]\n",
      "\t_long_any: 0.027147058166722964, _short_any: 0.9728529418332773\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_066/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_066'\n",
      "processing an_epoch_idx: 38/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 38)\n",
      "an_epoch: EpochTuple(Index=38, start=625.9915950123686, stop=626.3253676414024, label=67, duration=0.33377262903377414, end=626.3253676414024, score=0.2308433998536388, velocity=30.015101347861442, intercept=19031.010327439424, speed=30.015101347861442, wcorr=-0.43364602598009205, P_decoder=nan, pearsonr=-0.896037342286171, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-30.07321386563126, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([50, 43, 52, 37,  4,  5, 41, 49, 15, 31, 20, 39,  9, 35, 40]), n_unique_aclus=15)\n",
      "an_epoch: EpochTuple(Index=38, start=625.9915950123686, stop=626.3253676414024, label=67, duration=0.33377262903377414, end=626.3253676414024, score=0.2308433998536388, velocity=30.015101347861442, intercept=19031.010327439424, speed=30.015101347861442, wcorr=-0.43364602598009205, P_decoder=nan, pearsonr=-0.896037342286171, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-30.07321386563126, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([50, 43, 52, 37,  4,  5, 41, 49, 15, 31, 20, 39,  9, 35, 40]), n_unique_aclus=15)\n",
      "an_epoch: EpochTuple(Index=38, start=625.9915950123686, stop=626.3253676414024, label=67, duration=0.33377262903377414, end=626.3253676414024, score=0.2308433998536388, velocity=30.015101347861442, intercept=19031.010327439424, speed=30.015101347861442, wcorr=-0.43364602598009205, P_decoder=nan, pearsonr=-0.896037342286171, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-30.07321386563126, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([50, 43, 52, 37,  4,  5, 41, 49, 15, 31, 20, 39,  9, 35, 40]), n_unique_aclus=15)\n",
      "an_epoch: EpochTuple(Index=38, start=625.9915950123686, stop=626.3253676414024, label=67, duration=0.33377262903377414, end=626.3253676414024, score=0.2308433998536388, velocity=30.015101347861442, intercept=19031.010327439424, speed=30.015101347861442, wcorr=-0.43364602598009205, P_decoder=nan, pearsonr=-0.896037342286171, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-30.07321386563126, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([50, 43, 52, 37,  4,  5, 41, 49, 15, 31, 20, 39,  9, 35, 40]), n_unique_aclus=15)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (11, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 11\n",
      "np.shape(curr_data): (11, 59), np.nanmax(curr_data): 0.1328468488320496, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 11\n",
      "np.shape(curr_data): (11, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 11\n",
      "np.shape(curr_data): (11, 59), np.nanmax(curr_data): 0.16577466995625206, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 11\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_067\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_067\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_067\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_067\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[55][\"p_x_given_n\"]): (59, 4, 14)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.180847 0 0.819153 0]\n",
      "\t_long_any: 0.8191533320483266, _short_any: 0.18084666795167337\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.180847 0 0.819153 0]\n",
      "\t_long_any: 0.8191533320483266, _short_any: 0.18084666795167337\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.998815 0 0.00118499]\n",
      "\t_long_any: 0.001184990513175848, _short_any: 0.9988150094868239\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.654198 0 0.345802 0]\n",
      "\t_long_any: 0.345802410168063, _short_any: 0.654197589831937\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.503304 0 0.496696 0]\n",
      "\t_long_any: 0.4966959681311538, _short_any: 0.5033040318688462\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.10908 0.115552 0.157043 0.618326]\n",
      "\t_long_any: 0.7753683204822507, _short_any: 0.22463167951774907\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.82846 0 0.17154 0]\n",
      "\t_long_any: 0.1715401780084132, _short_any: 0.8284598219915869\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.220955 0.0417076 0.44744 0.289897]\n",
      "\t_long_any: 0.7373370125898947, _short_any: 0.2626629874101057\n",
      "i: 10, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 11, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 12, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.3885 0.225026 0.137701 0.248773]\n",
      "\t_long_any: 0.38647475361597433, _short_any: 0.6135252463840257\n",
      "i: 13, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.895236 0 0.104764 0]\n",
      "\t_long_any: 0.10476424546579857, _short_any: 0.8952357545342007\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_067/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_067'\n",
      "processing an_epoch_idx: 39/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 39)\n",
      "an_epoch: EpochTuple(Index=39, start=628.0847625805764, stop=628.3504290046403, label=68, duration=0.2656664240639657, end=628.3504290046403, score=0.16623384933286717, velocity=1282.0736147163088, intercept=805503.4843475961, speed=1282.0736147163088, wcorr=0.04689911886483875, P_decoder=0.3926133631140999, pearsonr=0.09109072251197403, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-27.98004629742354, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([43, 26, 18, 37, 49, 40, 23, 21, 19,  7, 20, 45, 32]), n_unique_aclus=13)\n",
      "an_epoch: EpochTuple(Index=39, start=628.0847625805764, stop=628.3504290046403, label=68, duration=0.2656664240639657, end=628.3504290046403, score=0.16623384933286717, velocity=1282.0736147163088, intercept=805503.4843475961, speed=1282.0736147163088, wcorr=0.04689911886483875, P_decoder=0.3926133631140999, pearsonr=0.09109072251197403, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-27.98004629742354, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([43, 26, 18, 37, 49, 40, 23, 21, 19,  7, 20, 45, 32]), n_unique_aclus=13)\n",
      "an_epoch: EpochTuple(Index=39, start=628.0847625805764, stop=628.3504290046403, label=68, duration=0.2656664240639657, end=628.3504290046403, score=0.16623384933286717, velocity=1282.0736147163088, intercept=805503.4843475961, speed=1282.0736147163088, wcorr=0.04689911886483875, P_decoder=0.3926133631140999, pearsonr=0.09109072251197403, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-27.98004629742354, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([43, 26, 18, 37, 49, 40, 23, 21, 19,  7, 20, 45, 32]), n_unique_aclus=13)\n",
      "an_epoch: EpochTuple(Index=39, start=628.0847625805764, stop=628.3504290046403, label=68, duration=0.2656664240639657, end=628.3504290046403, score=0.16623384933286717, velocity=1282.0736147163088, intercept=805503.4843475961, speed=1282.0736147163088, wcorr=0.04689911886483875, P_decoder=0.3926133631140999, pearsonr=0.09109072251197403, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=-27.98004629742354, pre_post_delta_category='pre-delta', maze_id=0, unique_active_aclus=array([43, 26, 18, 37, 49, 40, 23, 21, 19,  7, 20, 45, 32]), n_unique_aclus=13)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (12, 59), np.nanmax(curr_data): 0.1413380488947274, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 12\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.14933925445043028, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (12, 59), np.nanmax(curr_data): 0.16137889015198256, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 12\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_068\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_068\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_068\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_068\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[56][\"p_x_given_n\"]): (59, 4, 11)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.521409 0 0.478591 0]\n",
      "\t_long_any: 0.478590899738605, _short_any: 0.5214091002613951\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.598742 0 0.401258]\n",
      "\t_long_any: 0.4012581597618031, _short_any: 0.5987418402381962\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.67344 0 0.32656 0]\n",
      "\t_long_any: 0.3265599694886136, _short_any: 0.6734400305113869\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.441471 0 0.558529 0]\n",
      "\t_long_any: 0.5585287330361992, _short_any: 0.44147126696380146\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.999727 0 0.000272617 0]\n",
      "\t_long_any: 0.0002726168162374067, _short_any: 0.9997273831837624\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.965164 0 0.0348356 0]\n",
      "\t_long_any: 0.034835625038714714, _short_any: 0.9651643749612847\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 10, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.235604 0.075862 0.52586 0.162673]\n",
      "\t_long_any: 0.6885338732110056, _short_any: 0.31146612678899477\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_068/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_068'\n",
      "processing an_epoch_idx: 40/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 40)\n",
      "an_epoch: EpochTuple(Index=40, start=659.0948971033795, stop=659.1895146550378, label=70, duration=0.09461755165830255, end=659.1895146550378, score=0.5056245005812463, velocity=130.0654391740056, intercept=85978.28194649171, speed=130.0654391740056, wcorr=-0.4608780542358187, P_decoder=0.1837071865554486, pearsonr=-0.3029450723152205, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=3.030088225379586, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([26, 35, 18, 50, 25, 37, 21, 49]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=40, start=659.0948971033795, stop=659.1895146550378, label=70, duration=0.09461755165830255, end=659.1895146550378, score=0.5056245005812463, velocity=130.0654391740056, intercept=85978.28194649171, speed=130.0654391740056, wcorr=-0.4608780542358187, P_decoder=0.1837071865554486, pearsonr=-0.3029450723152205, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=3.030088225379586, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([26, 35, 18, 50, 25, 37, 21, 49]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=40, start=659.0948971033795, stop=659.1895146550378, label=70, duration=0.09461755165830255, end=659.1895146550378, score=0.5056245005812463, velocity=130.0654391740056, intercept=85978.28194649171, speed=130.0654391740056, wcorr=-0.4608780542358187, P_decoder=0.1837071865554486, pearsonr=-0.3029450723152205, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=3.030088225379586, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([26, 35, 18, 50, 25, 37, 21, 49]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=40, start=659.0948971033795, stop=659.1895146550378, label=70, duration=0.09461755165830255, end=659.1895146550378, score=0.5056245005812463, velocity=130.0654391740056, intercept=85978.28194649171, speed=130.0654391740056, wcorr=-0.4608780542358187, P_decoder=0.1837071865554486, pearsonr=-0.3029450723152205, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=3.030088225379586, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([26, 35, 18, 50, 25, 37, 21, 49]), n_unique_aclus=8)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.16871442757882205, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.16771957548724484, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_070\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_070\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_070\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_070\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[57][\"p_x_given_n\"]): (59, 4, 4)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.255942 0.00884809 0.692352 0.0428573]\n",
      "\t_long_any: 0.7352095424631134, _short_any: 0.2647904575368867\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [6.69656e-05 0.991691 0.000373257 0.00786849]\n",
      "\t_long_any: 0.008241744661221006, _short_any: 0.9917582553387791\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.94478 0 0.0552201]\n",
      "\t_long_any: 0.05522006228843716, _short_any: 0.9447799377115624\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.896813 0 0.103187]\n",
      "\t_long_any: 0.10318699590439508, _short_any: 0.8968130040956047\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_070/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_070'\n",
      "processing an_epoch_idx: 41/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 41)\n",
      "an_epoch: EpochTuple(Index=41, start=683.0109885382699, stop=683.4730785416905, label=73, duration=0.4620900034205988, end=683.4730785416905, score=0.11921300846361349, velocity=-0.0, intercept=90.23289842702111, speed=0.0, wcorr=-0.07321102114603179, P_decoder=0.23507812591953522, pearsonr=-0.9429432105756915, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=26.94617966026999, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([11, 52,  5, 21,  9,  4, 10, 43, 26, 32, 49]), n_unique_aclus=11)\n",
      "an_epoch: EpochTuple(Index=41, start=683.0109885382699, stop=683.4730785416905, label=73, duration=0.4620900034205988, end=683.4730785416905, score=0.11921300846361349, velocity=-0.0, intercept=90.23289842702111, speed=0.0, wcorr=-0.07321102114603179, P_decoder=0.23507812591953522, pearsonr=-0.9429432105756915, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=26.94617966026999, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([11, 52,  5, 21,  9,  4, 10, 43, 26, 32, 49]), n_unique_aclus=11)\n",
      "an_epoch: EpochTuple(Index=41, start=683.0109885382699, stop=683.4730785416905, label=73, duration=0.4620900034205988, end=683.4730785416905, score=0.11921300846361349, velocity=-0.0, intercept=90.23289842702111, speed=0.0, wcorr=-0.07321102114603179, P_decoder=0.23507812591953522, pearsonr=-0.9429432105756915, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=26.94617966026999, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([11, 52,  5, 21,  9,  4, 10, 43, 26, 32, 49]), n_unique_aclus=11)\n",
      "an_epoch: EpochTuple(Index=41, start=683.0109885382699, stop=683.4730785416905, label=73, duration=0.4620900034205988, end=683.4730785416905, score=0.11921300846361349, velocity=-0.0, intercept=90.23289842702111, speed=0.0, wcorr=-0.07321102114603179, P_decoder=0.23507812591953522, pearsonr=-0.9429432105756915, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=26.94617966026999, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([11, 52,  5, 21,  9,  4, 10, 43, 26, 32, 49]), n_unique_aclus=11)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.1413380488947274, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.14933925445043028, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.16137889015198256, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.1536547760171339, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_073\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_073\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_073\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_073\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[59][\"p_x_given_n\"]): (59, 4, 19)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.808829 0 0.191171]\n",
      "\t_long_any: 0.19117095485433833, _short_any: 0.8088290451456619\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.15016 0.554904 0.0462999 0.248636]\n",
      "\t_long_any: 0.29493631842043955, _short_any: 0.7050636815795602\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.401826 0.222795 0.0835336 0.291845]\n",
      "\t_long_any: 0.3753785335947758, _short_any: 0.6246214664052238\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.298447 0.570574 0.0618172 0.0691619]\n",
      "\t_long_any: 0.1309791175682417, _short_any: 0.8690208824317585\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.433296 0.215056 0.27909 0.0725591]\n",
      "\t_long_any: 0.3516485729942037, _short_any: 0.6483514270057958\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.904802 0.0710218 0.0132969 0.0108798]\n",
      "\t_long_any: 0.02417671903889118, _short_any: 0.9758232809611085\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.206585 0 0.793415 0]\n",
      "\t_long_any: 0.7934147368515362, _short_any: 0.20658526314846384\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.401826 0.222795 0.0835336 0.291845]\n",
      "\t_long_any: 0.3753785335947758, _short_any: 0.6246214664052238\n",
      "i: 10, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 11, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.15016 0.554904 0.0462999 0.248636]\n",
      "\t_long_any: 0.29493631842043955, _short_any: 0.7050636815795602\n",
      "i: 12, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0654033 0.647619 0.00374163 0.283237]\n",
      "\t_long_any: 0.28697816336020354, _short_any: 0.7130218366397962\n",
      "i: 13, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 14, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 15, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 16, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.690195 0 0.309805]\n",
      "\t_long_any: 0.3098047152377101, _short_any: 0.69019528476229\n",
      "i: 17, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.690195 0 0.309805]\n",
      "\t_long_any: 0.3098047152377101, _short_any: 0.69019528476229\n",
      "i: 18, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.664915 0 0.335085]\n",
      "\t_long_any: 0.3350853629305848, _short_any: 0.6649146370694143\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_073/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_073'\n",
      "processing an_epoch_idx: 42/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 42)\n",
      "an_epoch: EpochTuple(Index=42, start=685.3902820401127, stop=685.6324169561267, label=74, duration=0.24213491601403803, end=685.6324169561267, score=0.2753975649843589, velocity=-1170.5889525663042, intercept=-802356.6281651651, speed=1170.5889525663042, wcorr=0.24926228814751328, P_decoder=nan, pearsonr=-0.36424463084042946, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=29.325473162112758, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([11, 52,  5,  9, 14, 20,  7, 45, 40, 19, 21, 23,  4, 44, 10,  2, 26, 43]), n_unique_aclus=18)\n",
      "an_epoch: EpochTuple(Index=42, start=685.3902820401127, stop=685.6324169561267, label=74, duration=0.24213491601403803, end=685.6324169561267, score=0.2753975649843589, velocity=-1170.5889525663042, intercept=-802356.6281651651, speed=1170.5889525663042, wcorr=0.24926228814751328, P_decoder=nan, pearsonr=-0.36424463084042946, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=29.325473162112758, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([11, 52,  5,  9, 14, 20,  7, 45, 40, 19, 21, 23,  4, 44, 10,  2, 26, 43]), n_unique_aclus=18)\n",
      "an_epoch: EpochTuple(Index=42, start=685.3902820401127, stop=685.6324169561267, label=74, duration=0.24213491601403803, end=685.6324169561267, score=0.2753975649843589, velocity=-1170.5889525663042, intercept=-802356.6281651651, speed=1170.5889525663042, wcorr=0.24926228814751328, P_decoder=nan, pearsonr=-0.36424463084042946, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=29.325473162112758, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([11, 52,  5,  9, 14, 20,  7, 45, 40, 19, 21, 23,  4, 44, 10,  2, 26, 43]), n_unique_aclus=18)\n",
      "an_epoch: EpochTuple(Index=42, start=685.3902820401127, stop=685.6324169561267, label=74, duration=0.24213491601403803, end=685.6324169561267, score=0.2753975649843589, velocity=-1170.5889525663042, intercept=-802356.6281651651, speed=1170.5889525663042, wcorr=0.24926228814751328, P_decoder=nan, pearsonr=-0.36424463084042946, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=29.325473162112758, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([11, 52,  5,  9, 14, 20,  7, 45, 40, 19, 21, 23,  4, 44, 10,  2, 26, 43]), n_unique_aclus=18)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (14, 59), np.nanmax(curr_data): 0.1413380488947274, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 14\n",
      "np.shape(curr_data): (12, 59), np.nanmax(curr_data): 0.14933925445043028, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 12\n",
      "np.shape(curr_data): (14, 59), np.nanmax(curr_data): 0.16137889015198256, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 14\n",
      "np.shape(curr_data): (12, 59), np.nanmax(curr_data): 0.18913760071074082, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 12\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_074\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_074\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_074\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_074\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[60][\"p_x_given_n\"]): (59, 4, 10)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.974683 0 0.0253175]\n",
      "\t_long_any: 0.025317499807701625, _short_any: 0.974682500192299\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.154083 0.598349 0.0231151 0.224453]\n",
      "\t_long_any: 0.24756798106977174, _short_any: 0.7524320189302288\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.365485 0.458682 0.0682761 0.107557]\n",
      "\t_long_any: 0.17583275644247778, _short_any: 0.8241672435575219\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.755185 0 0.244815 0]\n",
      "\t_long_any: 0.24481529465741414, _short_any: 0.7551847053425856\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.807862 0 0.192138 0]\n",
      "\t_long_any: 0.19213798884617786, _short_any: 0.8078620111538222\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.952536 0 0.0474645 0]\n",
      "\t_long_any: 0.04746445045606862, _short_any: 0.9525355495439309\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.957929 0.0372121 0.00189465 0.00296459]\n",
      "\t_long_any: 0.004859242370940965, _short_any: 0.9951407576290595\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.333013 0 0.666987 0]\n",
      "\t_long_any: 0.6669866223533906, _short_any: 0.3330133776466095\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_074/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_074'\n",
      "processing an_epoch_idx: 43/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 43)\n",
      "an_epoch: EpochTuple(Index=43, start=686.735694471281, stop=686.8680054435972, label=75, duration=0.1323109723161906, end=686.8680054435972, score=0.22985422933416014, velocity=351.17668577002814, intercept=241230.9230675881, speed=351.17668577002814, wcorr=0.27660528684221125, P_decoder=nan, pearsonr=0.29984902698191385, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=30.670885593281128, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([24, 23, 14, 45, 20, 40, 11,  7,  9]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=43, start=686.735694471281, stop=686.8680054435972, label=75, duration=0.1323109723161906, end=686.8680054435972, score=0.22985422933416014, velocity=351.17668577002814, intercept=241230.9230675881, speed=351.17668577002814, wcorr=0.27660528684221125, P_decoder=nan, pearsonr=0.29984902698191385, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=30.670885593281128, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([24, 23, 14, 45, 20, 40, 11,  7,  9]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=43, start=686.735694471281, stop=686.8680054435972, label=75, duration=0.1323109723161906, end=686.8680054435972, score=0.22985422933416014, velocity=351.17668577002814, intercept=241230.9230675881, speed=351.17668577002814, wcorr=0.27660528684221125, P_decoder=nan, pearsonr=0.29984902698191385, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=30.670885593281128, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([24, 23, 14, 45, 20, 40, 11,  7,  9]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=43, start=686.735694471281, stop=686.8680054435972, label=75, duration=0.1323109723161906, end=686.8680054435972, score=0.22985422933416014, velocity=351.17668577002814, intercept=241230.9230675881, speed=351.17668577002814, wcorr=0.27660528684221125, P_decoder=nan, pearsonr=0.29984902698191385, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=30.670885593281128, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([24, 23, 14, 45, 20, 40, 11,  7,  9]), n_unique_aclus=9)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.10832426379331009, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (5, 59), np.nanmax(curr_data): 0.14646292062398014, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 5\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.14773746413841815, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (5, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 5\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_075\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_075\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_075\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_075\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[61][\"p_x_given_n\"]): (59, 4, 6)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.912717 0 0.0872834 0]\n",
      "\t_long_any: 0.0872833558007367, _short_any: 0.9127166441992626\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.907965 0 0.0920349 0]\n",
      "\t_long_any: 0.09203494684515531, _short_any: 0.9079650531548449\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.560378 0 0.439622]\n",
      "\t_long_any: 0.4396219259185861, _short_any: 0.5603780740814137\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_075/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_075'\n",
      "processing an_epoch_idx: 44/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 44)\n",
      "an_epoch: EpochTuple(Index=44, start=693.6937401888426, stop=693.840766033507, label=79, duration=0.1470258446643129, end=693.840766033507, score=0.1766807395305636, velocity=39.01963175222522, intercept=27255.944014196924, speed=39.01963175222522, wcorr=0.01989424813060676, P_decoder=0.053989247573396286, pearsonr=0.35234870812671976, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=37.628931310842745, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 9, 18, 21, 49, 37, 10, 39, 17, 41]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=44, start=693.6937401888426, stop=693.840766033507, label=79, duration=0.1470258446643129, end=693.840766033507, score=0.1766807395305636, velocity=39.01963175222522, intercept=27255.944014196924, speed=39.01963175222522, wcorr=0.01989424813060676, P_decoder=0.053989247573396286, pearsonr=0.35234870812671976, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=37.628931310842745, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 9, 18, 21, 49, 37, 10, 39, 17, 41]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=44, start=693.6937401888426, stop=693.840766033507, label=79, duration=0.1470258446643129, end=693.840766033507, score=0.1766807395305636, velocity=39.01963175222522, intercept=27255.944014196924, speed=39.01963175222522, wcorr=0.01989424813060676, P_decoder=0.053989247573396286, pearsonr=0.35234870812671976, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=37.628931310842745, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 9, 18, 21, 49, 37, 10, 39, 17, 41]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=44, start=693.6937401888426, stop=693.840766033507, label=79, duration=0.1470258446643129, end=693.840766033507, score=0.1766807395305636, velocity=39.01963175222522, intercept=27255.944014196924, speed=39.01963175222522, wcorr=0.01989424813060676, P_decoder=0.053989247573396286, pearsonr=0.35234870812671976, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=37.628931310842745, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 9, 18, 21, 49, 37, 10, 39, 17, 41]), n_unique_aclus=9)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (5, 59), np.nanmax(curr_data): 0.10599566525773634, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 5\n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.12921189215173673, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (5, 59), np.nanmax(curr_data): 0.1332959571110494, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 5\n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.14368267619971198, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_079\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_079\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_079\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_079\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[62][\"p_x_given_n\"]): (59, 4, 6)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.321515 0.603926 0.0296815 0.0448775]\n",
      "\t_long_any: 0.07455899690087507, _short_any: 0.9254410030991246\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.941158 0 0.0588422]\n",
      "\t_long_any: 0.058842167726944505, _short_any: 0.9411578322730557\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.987885 0 0.0121147]\n",
      "\t_long_any: 0.01211472334191023, _short_any: 0.98788527665809\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.729447 0 0.270553]\n",
      "\t_long_any: 0.27055349624912184, _short_any: 0.7294465037508784\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.3264 0 0.6736]\n",
      "\t_long_any: 0.6735997915425396, _short_any: 0.32640020845746\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0386034 0.85831 0.0145097 0.0885773]\n",
      "\t_long_any: 0.10308702550388373, _short_any: 0.8969129744961145\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_079/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_079'\n",
      "processing an_epoch_idx: 45/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 45)\n",
      "an_epoch: EpochTuple(Index=45, start=694.509939450887, stop=694.976330252015, label=80, duration=0.466390801128, end=694.976330252015, score=0.1882377160972454, velocity=-184.25937216326773, intercept=-127886.91320206359, speed=184.25937216326773, wcorr=0.0907278979532294, P_decoder=0.29262153881077657, pearsonr=0.5204093088624817, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=38.44513057288714, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([52, 21,  9, 14, 24, 45, 19, 23, 40, 35,  4, 10, 32, 44,  5]), n_unique_aclus=15)\n",
      "an_epoch: EpochTuple(Index=45, start=694.509939450887, stop=694.976330252015, label=80, duration=0.466390801128, end=694.976330252015, score=0.1882377160972454, velocity=-184.25937216326773, intercept=-127886.91320206359, speed=184.25937216326773, wcorr=0.0907278979532294, P_decoder=0.29262153881077657, pearsonr=0.5204093088624817, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=38.44513057288714, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([52, 21,  9, 14, 24, 45, 19, 23, 40, 35,  4, 10, 32, 44,  5]), n_unique_aclus=15)\n",
      "an_epoch: EpochTuple(Index=45, start=694.509939450887, stop=694.976330252015, label=80, duration=0.466390801128, end=694.976330252015, score=0.1882377160972454, velocity=-184.25937216326773, intercept=-127886.91320206359, speed=184.25937216326773, wcorr=0.0907278979532294, P_decoder=0.29262153881077657, pearsonr=0.5204093088624817, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=38.44513057288714, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([52, 21,  9, 14, 24, 45, 19, 23, 40, 35,  4, 10, 32, 44,  5]), n_unique_aclus=15)\n",
      "an_epoch: EpochTuple(Index=45, start=694.509939450887, stop=694.976330252015, label=80, duration=0.466390801128, end=694.976330252015, score=0.1882377160972454, velocity=-184.25937216326773, intercept=-127886.91320206359, speed=184.25937216326773, wcorr=0.0907278979532294, P_decoder=0.29262153881077657, pearsonr=0.5204093088624817, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=38.44513057288714, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([52, 21,  9, 14, 24, 45, 19, 23, 40, 35,  4, 10, 32, 44,  5]), n_unique_aclus=15)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (13, 59), np.nanmax(curr_data): 0.13026806747808126, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 13\n",
      "np.shape(curr_data): (10, 59), np.nanmax(curr_data): 0.14646292062398014, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 10\n",
      "np.shape(curr_data): (13, 59), np.nanmax(curr_data): 0.1140682535565404, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 13\n",
      "np.shape(curr_data): (10, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 10\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_080\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_080\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_080\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_080\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[63][\"p_x_given_n\"]): (59, 4, 19)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.15016 0.554904 0.0462999 0.248636]\n",
      "\t_long_any: 0.29493631842043955, _short_any: 0.7050636815795602\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0320809 0.681363 0.000328426 0.286227]\n",
      "\t_long_any: 0.28655581826957777, _short_any: 0.7134441817304219\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.15016 0.554904 0.0462999 0.248636]\n",
      "\t_long_any: 0.29493631842043955, _short_any: 0.7050636815795602\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0654033 0.647619 0.00374163 0.283237]\n",
      "\t_long_any: 0.28697816336020354, _short_any: 0.7130218366397962\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.15016 0.554904 0.0462999 0.248636]\n",
      "\t_long_any: 0.29493631842043955, _short_any: 0.7050636815795602\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.15016 0.554904 0.0462999 0.248636]\n",
      "\t_long_any: 0.29493631842043955, _short_any: 0.7050636815795602\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 10, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 11, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.995664 0 0.00433632]\n",
      "\t_long_any: 0.004336315988796321, _short_any: 0.9956636840112039\n",
      "i: 12, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.560378 0 0.439622]\n",
      "\t_long_any: 0.4396219259185861, _short_any: 0.5603780740814137\n",
      "i: 13, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.616776 0 0.383224 0]\n",
      "\t_long_any: 0.38322447055759384, _short_any: 0.6167755294424057\n",
      "i: 14, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.621891 0.0122324 0.360753 0.00512414]\n",
      "\t_long_any: 0.3658767436006062, _short_any: 0.6341232563993943\n",
      "i: 15, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.534431 0 0.465569 0]\n",
      "\t_long_any: 0.465569432800365, _short_any: 0.534430567199635\n",
      "i: 16, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.758861 0 0.241139 0]\n",
      "\t_long_any: 0.24113920813308468, _short_any: 0.7588607918669156\n",
      "i: 17, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.862226 0 0.137774 0]\n",
      "\t_long_any: 0.1377736217016795, _short_any: 0.8622263782983206\n",
      "i: 18, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0130117 0.00139468 0.983682 0.00191152]\n",
      "\t_long_any: 0.9855936477274606, _short_any: 0.014406352272539644\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_080/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_080'\n",
      "processing an_epoch_idx: 46/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 46)\n",
      "an_epoch: EpochTuple(Index=46, start=697.9841853519902, stop=698.1784892525757, label=81, duration=0.19430390058550984, end=698.1784892525757, score=0.22629137413903846, velocity=-947.6196282685762, intercept=-661408.5335091216, speed=947.6196282685762, wcorr=0.36468992473839723, P_decoder=nan, pearsonr=0.445404743799809, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=41.91937647399027, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 5, 11, 24, 45, 15,  7, 20, 21, 19, 10, 37, 17, 39]), n_unique_aclus=13)\n",
      "an_epoch: EpochTuple(Index=46, start=697.9841853519902, stop=698.1784892525757, label=81, duration=0.19430390058550984, end=698.1784892525757, score=0.22629137413903846, velocity=-947.6196282685762, intercept=-661408.5335091216, speed=947.6196282685762, wcorr=0.36468992473839723, P_decoder=nan, pearsonr=0.445404743799809, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=41.91937647399027, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 5, 11, 24, 45, 15,  7, 20, 21, 19, 10, 37, 17, 39]), n_unique_aclus=13)\n",
      "an_epoch: EpochTuple(Index=46, start=697.9841853519902, stop=698.1784892525757, label=81, duration=0.19430390058550984, end=698.1784892525757, score=0.22629137413903846, velocity=-947.6196282685762, intercept=-661408.5335091216, speed=947.6196282685762, wcorr=0.36468992473839723, P_decoder=nan, pearsonr=0.445404743799809, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=41.91937647399027, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 5, 11, 24, 45, 15,  7, 20, 21, 19, 10, 37, 17, 39]), n_unique_aclus=13)\n",
      "an_epoch: EpochTuple(Index=46, start=697.9841853519902, stop=698.1784892525757, label=81, duration=0.19430390058550984, end=698.1784892525757, score=0.22629137413903846, velocity=-947.6196282685762, intercept=-661408.5335091216, speed=947.6196282685762, wcorr=0.36468992473839723, P_decoder=nan, pearsonr=0.445404743799809, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=41.91937647399027, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 5, 11, 24, 45, 15,  7, 20, 21, 19, 10, 37, 17, 39]), n_unique_aclus=13)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (10, 59), np.nanmax(curr_data): 0.1259578889736905, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 10\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.13918661674691393, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (10, 59), np.nanmax(curr_data): 0.14773746413841815, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 10\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_081\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_081\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_081\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_081\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[64][\"p_x_given_n\"]): (59, 4, 8)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.779055 0 0.220945]\n",
      "\t_long_any: 0.22094474402131595, _short_any: 0.7790552559786841\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.709972 0 0.290028 0]\n",
      "\t_long_any: 0.29002846810463834, _short_any: 0.709971531895361\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.621891 0.0122324 0.360753 0.00512414]\n",
      "\t_long_any: 0.3658767436006062, _short_any: 0.6341232563993943\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.534431 0 0.465569 0]\n",
      "\t_long_any: 0.465569432800365, _short_any: 0.534430567199635\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.922391 0 0.0776087 0]\n",
      "\t_long_any: 0.0776087140924627, _short_any: 0.9223912859075372\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.5036 0 0.4964]\n",
      "\t_long_any: 0.4963997386574274, _short_any: 0.5036002613425721\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_081/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_081'\n",
      "processing an_epoch_idx: 47/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 47)\n",
      "an_epoch: EpochTuple(Index=47, start=701.9943720988231, stop=702.2490407683654, label=84, duration=0.2546686695422977, end=702.2490407683654, score=0.17968927681713961, velocity=643.8239239117182, intercept=452151.72353149456, speed=643.8239239117182, wcorr=-0.3014244652465532, P_decoder=0.6127795714156982, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=45.929563220823184, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([43, 31, 11,  5, 52,  9, 21, 19, 27, 23, 45,  7, 20, 40, 17]), n_unique_aclus=15)\n",
      "an_epoch: EpochTuple(Index=47, start=701.9943720988231, stop=702.2490407683654, label=84, duration=0.2546686695422977, end=702.2490407683654, score=0.17968927681713961, velocity=643.8239239117182, intercept=452151.72353149456, speed=643.8239239117182, wcorr=-0.3014244652465532, P_decoder=0.6127795714156982, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=45.929563220823184, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([43, 31, 11,  5, 52,  9, 21, 19, 27, 23, 45,  7, 20, 40, 17]), n_unique_aclus=15)\n",
      "an_epoch: EpochTuple(Index=47, start=701.9943720988231, stop=702.2490407683654, label=84, duration=0.2546686695422977, end=702.2490407683654, score=0.17968927681713961, velocity=643.8239239117182, intercept=452151.72353149456, speed=643.8239239117182, wcorr=-0.3014244652465532, P_decoder=0.6127795714156982, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=45.929563220823184, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([43, 31, 11,  5, 52,  9, 21, 19, 27, 23, 45,  7, 20, 40, 17]), n_unique_aclus=15)\n",
      "an_epoch: EpochTuple(Index=47, start=701.9943720988231, stop=702.2490407683654, label=84, duration=0.2546686695422977, end=702.2490407683654, score=0.17968927681713961, velocity=643.8239239117182, intercept=452151.72353149456, speed=643.8239239117182, wcorr=-0.3014244652465532, P_decoder=0.6127795714156982, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=45.929563220823184, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([43, 31, 11,  5, 52,  9, 21, 19, 27, 23, 45,  7, 20, 40, 17]), n_unique_aclus=15)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (11, 59), np.nanmax(curr_data): 0.10832426379331009, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 11\n",
      "np.shape(curr_data): (10, 59), np.nanmax(curr_data): 0.13918661674691393, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 10\n",
      "np.shape(curr_data): (11, 59), np.nanmax(curr_data): 0.1490508567103094, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 11\n",
      "np.shape(curr_data): (10, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 10\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_084\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_084\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_084\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_084\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[65][\"p_x_given_n\"]): (59, 4, 11)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.281389 0 0.718611 0]\n",
      "\t_long_any: 0.7186105622520707, _short_any: 0.28138943774792957\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.989252 0 0.0107477]\n",
      "\t_long_any: 0.010747745093700418, _short_any: 0.9892522549062999\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.66404 0 0.33596 0]\n",
      "\t_long_any: 0.33596029276302786, _short_any: 0.6640397072369721\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.869193 0 0.130807 0]\n",
      "\t_long_any: 0.13080726364217285, _short_any: 0.8691927363578273\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.923086 0.00637672 0.0702102 0.000327162]\n",
      "\t_long_any: 0.0705373135223597, _short_any: 0.9294626864776401\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.505606 0 0.494394 0]\n",
      "\t_long_any: 0.494393861745059, _short_any: 0.5056061382549412\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.99899 0 0.00101049 0]\n",
      "\t_long_any: 0.0010104851053872167, _short_any: 0.9989895148946133\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.999987 0 1.3294e-05 0]\n",
      "\t_long_any: 1.3294002997402158e-05, _short_any: 0.9999867059970028\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.727815 0 0.272185 0]\n",
      "\t_long_any: 0.27218476610156006, _short_any: 0.7278152338984398\n",
      "i: 10, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.441471 0 0.558529 0]\n",
      "\t_long_any: 0.5585287330361992, _short_any: 0.44147126696380146\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_084/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_084'\n",
      "processing an_epoch_idx: 48/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 48)\n",
      "an_epoch: EpochTuple(Index=48, start=704.1025002995739, stop=704.2207415188896, label=85, duration=0.11824121931567788, end=704.2207415188896, score=0.19654526818106147, velocity=634.0690159735177, intercept=446542.86081660195, speed=634.0690159735177, wcorr=-0.09474769696864171, P_decoder=0.4493146838222461, pearsonr=0.618548262246643, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=48.03769142157398, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([52, 19, 21, 45,  7, 40, 24,  4, 14]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=48, start=704.1025002995739, stop=704.2207415188896, label=85, duration=0.11824121931567788, end=704.2207415188896, score=0.19654526818106147, velocity=634.0690159735177, intercept=446542.86081660195, speed=634.0690159735177, wcorr=-0.09474769696864171, P_decoder=0.4493146838222461, pearsonr=0.618548262246643, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=48.03769142157398, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([52, 19, 21, 45,  7, 40, 24,  4, 14]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=48, start=704.1025002995739, stop=704.2207415188896, label=85, duration=0.11824121931567788, end=704.2207415188896, score=0.19654526818106147, velocity=634.0690159735177, intercept=446542.86081660195, speed=634.0690159735177, wcorr=-0.09474769696864171, P_decoder=0.4493146838222461, pearsonr=0.618548262246643, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=48.03769142157398, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([52, 19, 21, 45,  7, 40, 24,  4, 14]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=48, start=704.1025002995739, stop=704.2207415188896, label=85, duration=0.11824121931567788, end=704.2207415188896, score=0.19654526818106147, velocity=634.0690159735177, intercept=446542.86081660195, speed=634.0690159735177, wcorr=-0.09474769696864171, P_decoder=0.4493146838222461, pearsonr=0.618548262246643, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=48.03769142157398, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([52, 19, 21, 45,  7, 40, 24,  4, 14]), n_unique_aclus=9)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.10500114125474004, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (5, 59), np.nanmax(curr_data): 0.14646292062398014, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 5\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.14773746413841815, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (5, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 5\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_085\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_085\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_085\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_085\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[66][\"p_x_given_n\"]): (59, 4, 5)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.15016 0.554904 0.0462999 0.248636]\n",
      "\t_long_any: 0.29493631842043955, _short_any: 0.7050636815795602\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.560239 0 0.439761 0]\n",
      "\t_long_any: 0.4397611934383374, _short_any: 0.5602388065616629\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.965164 0 0.0348356 0]\n",
      "\t_long_any: 0.034835625038714714, _short_any: 0.9651643749612847\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.62374 0 0.37626 0]\n",
      "\t_long_any: 0.3762595448345791, _short_any: 0.6237404551654203\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.659952 0 0.340048]\n",
      "\t_long_any: 0.3400483697144421, _short_any: 0.659951630285558\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_085/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_085'\n",
      "processing an_epoch_idx: 49/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 49)\n",
      "an_epoch: EpochTuple(Index=49, start=705.2988593669143, stop=705.4994608642301, label=86, duration=0.20060149731580168, end=705.4994608642301, score=0.2964240321731439, velocity=-219.48542860621768, intercept=-154588.51930985946, speed=219.48542860621768, wcorr=0.16244705244067953, P_decoder=0.46518873356776136, pearsonr=-0.5797634464563638, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=49.23405048891436, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 9, 45, 35, 46, 32, 43, 37, 26, 20, 23, 10,  4]), n_unique_aclus=12)\n",
      "an_epoch: EpochTuple(Index=49, start=705.2988593669143, stop=705.4994608642301, label=86, duration=0.20060149731580168, end=705.4994608642301, score=0.2964240321731439, velocity=-219.48542860621768, intercept=-154588.51930985946, speed=219.48542860621768, wcorr=0.16244705244067953, P_decoder=0.46518873356776136, pearsonr=-0.5797634464563638, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=49.23405048891436, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 9, 45, 35, 46, 32, 43, 37, 26, 20, 23, 10,  4]), n_unique_aclus=12)\n",
      "an_epoch: EpochTuple(Index=49, start=705.2988593669143, stop=705.4994608642301, label=86, duration=0.20060149731580168, end=705.4994608642301, score=0.2964240321731439, velocity=-219.48542860621768, intercept=-154588.51930985946, speed=219.48542860621768, wcorr=0.16244705244067953, P_decoder=0.46518873356776136, pearsonr=-0.5797634464563638, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=49.23405048891436, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 9, 45, 35, 46, 32, 43, 37, 26, 20, 23, 10,  4]), n_unique_aclus=12)\n",
      "an_epoch: EpochTuple(Index=49, start=705.2988593669143, stop=705.4994608642301, label=86, duration=0.20060149731580168, end=705.4994608642301, score=0.2964240321731439, velocity=-219.48542860621768, intercept=-154588.51930985946, speed=219.48542860621768, wcorr=0.16244705244067953, P_decoder=0.46518873356776136, pearsonr=-0.5797634464563638, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=49.23405048891436, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 9, 45, 35, 46, 32, 43, 37, 26, 20, 23, 10,  4]), n_unique_aclus=12)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (11, 59), np.nanmax(curr_data): 0.1413380488947274, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 11\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.14933925445043028, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (11, 59), np.nanmax(curr_data): 0.16137889015198256, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 11\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_086\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_086\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_086\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_086\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[67][\"p_x_given_n\"]): (59, 4, 9)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.874001 0.0365448 0.0863399 0.00311434]\n",
      "\t_long_any: 0.08945422578615264, _short_any: 0.9105457742138469\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [1.53262e-06 0 0.999998 0]\n",
      "\t_long_any: 0.9999984673766473, _short_any: 1.5326233525913503e-06\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.62784 0 0.37216 0]\n",
      "\t_long_any: 0.3721600032203538, _short_any: 0.6278399967796464\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.395579 0 0.604421 0]\n",
      "\t_long_any: 0.6044212891290719, _short_any: 0.3955787108709279\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.424186 0 0.575814 0]\n",
      "\t_long_any: 0.5758135573775812, _short_any: 0.424186442622419\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.49504 0 0.50496 0]\n",
      "\t_long_any: 0.5049597653122458, _short_any: 0.495040234687754\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.548264 0.241814 0.120337 0.089585]\n",
      "\t_long_any: 0.2099215321433799, _short_any: 0.7900784678566204\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.548264 0.241814 0.120337 0.089585]\n",
      "\t_long_any: 0.2099215321433799, _short_any: 0.7900784678566204\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_086/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_086'\n",
      "processing an_epoch_idx: 50/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 50)\n",
      "an_epoch: EpochTuple(Index=50, start=706.6135825337842, stop=706.9367567683803, label=87, duration=0.3231742345960811, end=706.9367567683803, score=0.225544558546094, velocity=-406.4544974190756, intercept=-287086.9741632693, speed=406.4544974190756, wcorr=0.22874662364289036, P_decoder=0.4190570360332475, pearsonr=-0.5384434193905293, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=50.548773655784316, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 5, 10, 52,  9, 21, 19, 23, 45,  4, 44, 35,  2, 46, 20, 53, 49, 37, 18, 26, 50]), n_unique_aclus=20)\n",
      "an_epoch: EpochTuple(Index=50, start=706.6135825337842, stop=706.9367567683803, label=87, duration=0.3231742345960811, end=706.9367567683803, score=0.225544558546094, velocity=-406.4544974190756, intercept=-287086.9741632693, speed=406.4544974190756, wcorr=0.22874662364289036, P_decoder=0.4190570360332475, pearsonr=-0.5384434193905293, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=50.548773655784316, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 5, 10, 52,  9, 21, 19, 23, 45,  4, 44, 35,  2, 46, 20, 53, 49, 37, 18, 26, 50]), n_unique_aclus=20)\n",
      "an_epoch: EpochTuple(Index=50, start=706.6135825337842, stop=706.9367567683803, label=87, duration=0.3231742345960811, end=706.9367567683803, score=0.225544558546094, velocity=-406.4544974190756, intercept=-287086.9741632693, speed=406.4544974190756, wcorr=0.22874662364289036, P_decoder=0.4190570360332475, pearsonr=-0.5384434193905293, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=50.548773655784316, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 5, 10, 52,  9, 21, 19, 23, 45,  4, 44, 35,  2, 46, 20, 53, 49, 37, 18, 26, 50]), n_unique_aclus=20)\n",
      "an_epoch: EpochTuple(Index=50, start=706.6135825337842, stop=706.9367567683803, label=87, duration=0.3231742345960811, end=706.9367567683803, score=0.225544558546094, velocity=-406.4544974190756, intercept=-287086.9741632693, speed=406.4544974190756, wcorr=0.22874662364289036, P_decoder=0.4190570360332475, pearsonr=-0.5384434193905293, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=50.548773655784316, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 5, 10, 52,  9, 21, 19, 23, 45,  4, 44, 35,  2, 46, 20, 53, 49, 37, 18, 26, 50]), n_unique_aclus=20)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (16, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 16\n",
      "np.shape(curr_data): (15, 59), np.nanmax(curr_data): 0.14933925445043028, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 15\n",
      "np.shape(curr_data): (16, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 16\n",
      "np.shape(curr_data): (15, 59), np.nanmax(curr_data): 0.18913760071074082, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 15\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_087\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_087\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_087\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_087\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[68][\"p_x_given_n\"]): (59, 4, 13)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.157124 0.596439 0.0110939 0.235343]\n",
      "\t_long_any: 0.2464370816539043, _short_any: 0.7535629183460959\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.916481 0 0.0835194 0]\n",
      "\t_long_any: 0.08351940113755012, _short_any: 0.916480598862449\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.735467 0 0.264533 0]\n",
      "\t_long_any: 0.26453332321851997, _short_any: 0.7354666767814796\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.860805 0 0.139195 0]\n",
      "\t_long_any: 0.13919545946199882, _short_any: 0.8608045405380016\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.572583 0.000461109 0.426237 0.000718692]\n",
      "\t_long_any: 0.4269560148703146, _short_any: 0.5730439851296857\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.95028 0.0345074 0.0116848 0.00352783]\n",
      "\t_long_any: 0.015212662889971848, _short_any: 0.9847873371100279\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.641427 0 0.358573 0]\n",
      "\t_long_any: 0.35857271125601897, _short_any: 0.6414272887439811\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.554975 0 0.445025 0]\n",
      "\t_long_any: 0.445025457995953, _short_any: 0.5549745420040473\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 10, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.0385804 0 0.96142]\n",
      "\t_long_any: 0.9614195617848824, _short_any: 0.03858043821511756\n",
      "i: 11, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.849393 0 0.150607]\n",
      "\t_long_any: 0.15060739553508862, _short_any: 0.8493926044649113\n",
      "i: 12, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [8.6703e-06 0.986986 3.34187e-05 0.0129722]\n",
      "\t_long_any: 0.013005596798308365, _short_any: 0.9869944032016917\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_087/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_087'\n",
      "processing an_epoch_idx: 51/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 51)\n",
      "an_epoch: EpochTuple(Index=51, start=710.4212631442351, stop=710.6235849607037, label=89, duration=0.20232181646861136, end=710.6235849607037, score=0.19260704680377072, velocity=-487.74539690252107, intercept=-346532.74632059725, speed=487.74539690252107, wcorr=-0.442975556711753, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=54.35645426623523, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([23,  5, 52, 18, 19,  7, 45,  9, 24, 14, 11, 20, 44, 17, 40]), n_unique_aclus=15)\n",
      "an_epoch: EpochTuple(Index=51, start=710.4212631442351, stop=710.6235849607037, label=89, duration=0.20232181646861136, end=710.6235849607037, score=0.19260704680377072, velocity=-487.74539690252107, intercept=-346532.74632059725, speed=487.74539690252107, wcorr=-0.442975556711753, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=54.35645426623523, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([23,  5, 52, 18, 19,  7, 45,  9, 24, 14, 11, 20, 44, 17, 40]), n_unique_aclus=15)\n",
      "an_epoch: EpochTuple(Index=51, start=710.4212631442351, stop=710.6235849607037, label=89, duration=0.20232181646861136, end=710.6235849607037, score=0.19260704680377072, velocity=-487.74539690252107, intercept=-346532.74632059725, speed=487.74539690252107, wcorr=-0.442975556711753, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=54.35645426623523, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([23,  5, 52, 18, 19,  7, 45,  9, 24, 14, 11, 20, 44, 17, 40]), n_unique_aclus=15)\n",
      "an_epoch: EpochTuple(Index=51, start=710.4212631442351, stop=710.6235849607037, label=89, duration=0.20232181646861136, end=710.6235849607037, score=0.19260704680377072, velocity=-487.74539690252107, intercept=-346532.74632059725, speed=487.74539690252107, wcorr=-0.442975556711753, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=54.35645426623523, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([23,  5, 52, 18, 19,  7, 45,  9, 24, 14, 11, 20, 44, 17, 40]), n_unique_aclus=15)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (11, 59), np.nanmax(curr_data): 0.1146338264762386, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 11\n",
      "np.shape(curr_data): (10, 59), np.nanmax(curr_data): 0.14646292062398014, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 10\n",
      "np.shape(curr_data): (11, 59), np.nanmax(curr_data): 0.14773746413841815, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 11\n",
      "np.shape(curr_data): (10, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 10\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_089\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_089\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_089\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_089\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[69][\"p_x_given_n\"]): (59, 4, 9)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.60101 0 0.39899 0]\n",
      "\t_long_any: 0.39898972537941546, _short_any: 0.601010274620585\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.124735 0.384323 0.00492295 0.48602]\n",
      "\t_long_any: 0.4909425586624707, _short_any: 0.509057441337529\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.441471 0 0.558529 0]\n",
      "\t_long_any: 0.5585287330361992, _short_any: 0.44147126696380146\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.999389 0 0.000610672 0]\n",
      "\t_long_any: 0.0006106715255739929, _short_any: 0.9993893284744257\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.554975 0 0.445025 0]\n",
      "\t_long_any: 0.445025457995953, _short_any: 0.5549745420040473\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_089/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_089'\n",
      "processing an_epoch_idx: 52/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 52)\n",
      "an_epoch: EpochTuple(Index=52, start=712.0747355778003, stop=712.3428596004378, label=90, duration=0.2681240226374939, end=712.3428596004378, score=0.3024438891518873, velocity=-78.03926350445079, intercept=-55343.96180585208, speed=78.03926350445079, wcorr=0.3724419292852041, P_decoder=nan, pearsonr=-0.35287628567706325, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=56.00992669980042, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 5, 11, 21,  9, 14, 19, 40, 23, 45, 27, 35, 32, 46, 43, 18, 26, 17, 31, 37, 50,  2]), n_unique_aclus=21)\n",
      "an_epoch: EpochTuple(Index=52, start=712.0747355778003, stop=712.3428596004378, label=90, duration=0.2681240226374939, end=712.3428596004378, score=0.3024438891518873, velocity=-78.03926350445079, intercept=-55343.96180585208, speed=78.03926350445079, wcorr=0.3724419292852041, P_decoder=nan, pearsonr=-0.35287628567706325, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=56.00992669980042, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 5, 11, 21,  9, 14, 19, 40, 23, 45, 27, 35, 32, 46, 43, 18, 26, 17, 31, 37, 50,  2]), n_unique_aclus=21)\n",
      "an_epoch: EpochTuple(Index=52, start=712.0747355778003, stop=712.3428596004378, label=90, duration=0.2681240226374939, end=712.3428596004378, score=0.3024438891518873, velocity=-78.03926350445079, intercept=-55343.96180585208, speed=78.03926350445079, wcorr=0.3724419292852041, P_decoder=nan, pearsonr=-0.35287628567706325, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=56.00992669980042, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 5, 11, 21,  9, 14, 19, 40, 23, 45, 27, 35, 32, 46, 43, 18, 26, 17, 31, 37, 50,  2]), n_unique_aclus=21)\n",
      "an_epoch: EpochTuple(Index=52, start=712.0747355778003, stop=712.3428596004378, label=90, duration=0.2681240226374939, end=712.3428596004378, score=0.3024438891518873, velocity=-78.03926350445079, intercept=-55343.96180585208, speed=78.03926350445079, wcorr=0.3724419292852041, P_decoder=nan, pearsonr=-0.35287628567706325, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=56.00992669980042, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 5, 11, 21,  9, 14, 19, 40, 23, 45, 27, 35, 32, 46, 43, 18, 26, 17, 31, 37, 50,  2]), n_unique_aclus=21)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (15, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 15\n",
      "np.shape(curr_data): (16, 59), np.nanmax(curr_data): 0.14933925445043028, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 16\n",
      "np.shape(curr_data): (15, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 15\n",
      "np.shape(curr_data): (16, 59), np.nanmax(curr_data): 0.18913760071074082, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 16\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_090\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_090\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_090\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_090\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[70][\"p_x_given_n\"]): (59, 4, 11)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.969109 0 0.0308912]\n",
      "\t_long_any: 0.030891166946545038, _short_any: 0.969108833053455\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.16142 0.780377 0.0181647 0.0400385]\n",
      "\t_long_any: 0.05820318533166714, _short_any: 0.9417968146683338\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.00439682 0 0.995603 0]\n",
      "\t_long_any: 0.9956031834965609, _short_any: 0.004396816503439193\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0161262 0 0.983874 0]\n",
      "\t_long_any: 0.9838738172328275, _short_any: 0.01612618276717284\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.395258 0 0.604742 0]\n",
      "\t_long_any: 0.6047421574217289, _short_any: 0.3952578425782709\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0289519 0.339483 0.111829 0.519736]\n",
      "\t_long_any: 0.6315649967700578, _short_any: 0.36843500322994144\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0781415 0.595004 0.183632 0.143222]\n",
      "\t_long_any: 0.3268542775223986, _short_any: 0.6731457224776014\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.37824 0 0.62176 0]\n",
      "\t_long_any: 0.6217603216764525, _short_any: 0.3782396783235472\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 10, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.235604 0.075862 0.52586 0.162673]\n",
      "\t_long_any: 0.6885338732110056, _short_any: 0.31146612678899477\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_090/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_090'\n",
      "processing an_epoch_idx: 53/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 53)\n",
      "an_epoch: EpochTuple(Index=53, start=713.5096046030521, stop=713.8047622118611, label=91, duration=0.2951576088089496, end=713.8047622118611, score=0.22091837344917475, velocity=-727.1840462915326, intercept=-518815.5553309919, speed=727.1840462915326, wcorr=0.5658971439595538, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=57.444795725052245, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([24, 14,  7, 45, 19, 20, 40, 52,  5, 21, 44, 10, 17, 37, 41, 18]), n_unique_aclus=16)\n",
      "an_epoch: EpochTuple(Index=53, start=713.5096046030521, stop=713.8047622118611, label=91, duration=0.2951576088089496, end=713.8047622118611, score=0.22091837344917475, velocity=-727.1840462915326, intercept=-518815.5553309919, speed=727.1840462915326, wcorr=0.5658971439595538, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=57.444795725052245, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([24, 14,  7, 45, 19, 20, 40, 52,  5, 21, 44, 10, 17, 37, 41, 18]), n_unique_aclus=16)\n",
      "an_epoch: EpochTuple(Index=53, start=713.5096046030521, stop=713.8047622118611, label=91, duration=0.2951576088089496, end=713.8047622118611, score=0.22091837344917475, velocity=-727.1840462915326, intercept=-518815.5553309919, speed=727.1840462915326, wcorr=0.5658971439595538, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=57.444795725052245, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([24, 14,  7, 45, 19, 20, 40, 52,  5, 21, 44, 10, 17, 37, 41, 18]), n_unique_aclus=16)\n",
      "an_epoch: EpochTuple(Index=53, start=713.5096046030521, stop=713.8047622118611, label=91, duration=0.2951576088089496, end=713.8047622118611, score=0.22091837344917475, velocity=-727.1840462915326, intercept=-518815.5553309919, speed=727.1840462915326, wcorr=0.5658971439595538, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=57.444795725052245, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([24, 14,  7, 45, 19, 20, 40, 52,  5, 21, 44, 10, 17, 37, 41, 18]), n_unique_aclus=16)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (14, 59), np.nanmax(curr_data): 0.1146338264762386, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 14\n",
      "np.shape(curr_data): (12, 59), np.nanmax(curr_data): 0.14646292062398014, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 12\n",
      "np.shape(curr_data): (14, 59), np.nanmax(curr_data): 0.14773746413841815, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 14\n",
      "np.shape(curr_data): (12, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 12\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_091\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_091\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_091\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_091\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[71][\"p_x_given_n\"]): (59, 4, 12)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.806542 0.0167766 0.168383 0.00829852]\n",
      "\t_long_any: 0.1766819040630121, _short_any: 0.8233180959369882\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0654033 0.647619 0.00374163 0.283237]\n",
      "\t_long_any: 0.28697816336020354, _short_any: 0.7130218366397962\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.15016 0.554904 0.0462999 0.248636]\n",
      "\t_long_any: 0.29493631842043955, _short_any: 0.7050636815795602\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.850198 0.0827014 0.0579697 0.00913109]\n",
      "\t_long_any: 0.06710081917213764, _short_any: 0.9328991808278626\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.00106834 0.810809 0.000333235 0.187789]\n",
      "\t_long_any: 0.18812225477337713, _short_any: 0.8118777452266244\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.00436394 0.833835 0.000828705 0.160972]\n",
      "\t_long_any: 0.16180084923768895, _short_any: 0.8381991507623111\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0266609 0.765952 0.0052489 0.202139]\n",
      "\t_long_any: 0.2073875925840952, _short_any: 0.7926124074159046\n",
      "i: 10, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0139165 0.963359 0.00673767 0.0159872]\n",
      "\t_long_any: 0.022724876593957586, _short_any: 0.9772751234060424\n",
      "i: 11, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.00230719 0.993012 0.0016437 0.0030375]\n",
      "\t_long_any: 0.004681199209060597, _short_any: 0.9953188007909394\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_091/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_091'\n",
      "processing an_epoch_idx: 54/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 54)\n",
      "an_epoch: EpochTuple(Index=54, start=717.7937214495614, stop=717.9590564048849, label=92, duration=0.16533495532348752, end=717.9590564048849, score=0.254272252604483, velocity=-97.54907938057822, intercept=-69867.69627603178, speed=97.54907938057822, wcorr=0.6191293803208482, P_decoder=0.5179132424761509, pearsonr=-0.6922975407909572, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=61.72891257156152, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([52, 11,  7, 20, 45, 19, 17, 21, 10, 23,  9,  5, 40, 32, 35, 44]), n_unique_aclus=16)\n",
      "an_epoch: EpochTuple(Index=54, start=717.7937214495614, stop=717.9590564048849, label=92, duration=0.16533495532348752, end=717.9590564048849, score=0.254272252604483, velocity=-97.54907938057822, intercept=-69867.69627603178, speed=97.54907938057822, wcorr=0.6191293803208482, P_decoder=0.5179132424761509, pearsonr=-0.6922975407909572, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=61.72891257156152, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([52, 11,  7, 20, 45, 19, 17, 21, 10, 23,  9,  5, 40, 32, 35, 44]), n_unique_aclus=16)\n",
      "an_epoch: EpochTuple(Index=54, start=717.7937214495614, stop=717.9590564048849, label=92, duration=0.16533495532348752, end=717.9590564048849, score=0.254272252604483, velocity=-97.54907938057822, intercept=-69867.69627603178, speed=97.54907938057822, wcorr=0.6191293803208482, P_decoder=0.5179132424761509, pearsonr=-0.6922975407909572, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=61.72891257156152, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([52, 11,  7, 20, 45, 19, 17, 21, 10, 23,  9,  5, 40, 32, 35, 44]), n_unique_aclus=16)\n",
      "an_epoch: EpochTuple(Index=54, start=717.7937214495614, stop=717.9590564048849, label=92, duration=0.16533495532348752, end=717.9590564048849, score=0.254272252604483, velocity=-97.54907938057822, intercept=-69867.69627603178, speed=97.54907938057822, wcorr=0.6191293803208482, P_decoder=0.5179132424761509, pearsonr=-0.6922975407909572, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=61.72891257156152, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([52, 11,  7, 20, 45, 19, 17, 21, 10, 23,  9,  5, 40, 32, 35, 44]), n_unique_aclus=16)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (13, 59), np.nanmax(curr_data): 0.13026806747808126, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 13\n",
      "np.shape(curr_data): (11, 59), np.nanmax(curr_data): 0.13918661674691393, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 11\n",
      "np.shape(curr_data): (13, 59), np.nanmax(curr_data): 0.14773746413841815, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 13\n",
      "np.shape(curr_data): (11, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 11\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_092\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_092\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_092\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_092\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[72][\"p_x_given_n\"]): (59, 4, 7)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.690195 0 0.309805]\n",
      "\t_long_any: 0.3098047152377101, _short_any: 0.69019528476229\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.99945 0 0.000550073 0]\n",
      "\t_long_any: 0.0005500727440212627, _short_any: 0.9994499272559785\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.432816 0 0.567184 0]\n",
      "\t_long_any: 0.5671842203594777, _short_any: 0.43281577964052215\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.615041 0 0.384959 0]\n",
      "\t_long_any: 0.3849585813846372, _short_any: 0.6150414186153629\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.690687 0 0.309313 0]\n",
      "\t_long_any: 0.3093131567123081, _short_any: 0.6906868432876918\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.801262 0 0.198738 0]\n",
      "\t_long_any: 0.1987376236502153, _short_any: 0.8012623763497844\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.000489089 7.77074e-05 0.998953 0.000480605]\n",
      "\t_long_any: 0.999433204031931, _short_any: 0.0005667959680692536\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_092/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_092'\n",
      "processing an_epoch_idx: 55/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 55)\n",
      "an_epoch: EpochTuple(Index=55, start=734.2202499993145, stop=734.4301289317664, label=94, duration=0.20987893245182931, end=734.4301289317664, score=0.3274769220640874, velocity=24.38726984513522, intercept=18147.366174835883, speed=24.38726984513522, wcorr=0.4508819542983849, P_decoder=nan, pearsonr=0.6028603544342566, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=78.15544112131465, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([49, 20, 41, 27, 53, 18, 37, 43, 26, 50, 19,  5, 52]), n_unique_aclus=13)\n",
      "an_epoch: EpochTuple(Index=55, start=734.2202499993145, stop=734.4301289317664, label=94, duration=0.20987893245182931, end=734.4301289317664, score=0.3274769220640874, velocity=24.38726984513522, intercept=18147.366174835883, speed=24.38726984513522, wcorr=0.4508819542983849, P_decoder=nan, pearsonr=0.6028603544342566, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=78.15544112131465, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([49, 20, 41, 27, 53, 18, 37, 43, 26, 50, 19,  5, 52]), n_unique_aclus=13)\n",
      "an_epoch: EpochTuple(Index=55, start=734.2202499993145, stop=734.4301289317664, label=94, duration=0.20987893245182931, end=734.4301289317664, score=0.3274769220640874, velocity=24.38726984513522, intercept=18147.366174835883, speed=24.38726984513522, wcorr=0.4508819542983849, P_decoder=nan, pearsonr=0.6028603544342566, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=78.15544112131465, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([49, 20, 41, 27, 53, 18, 37, 43, 26, 50, 19,  5, 52]), n_unique_aclus=13)\n",
      "an_epoch: EpochTuple(Index=55, start=734.2202499993145, stop=734.4301289317664, label=94, duration=0.20987893245182931, end=734.4301289317664, score=0.3274769220640874, velocity=24.38726984513522, intercept=18147.366174835883, speed=24.38726984513522, wcorr=0.4508819542983849, P_decoder=nan, pearsonr=0.6028603544342566, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=78.15544112131465, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([49, 20, 41, 27, 53, 18, 37, 43, 26, 50, 19,  5, 52]), n_unique_aclus=13)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (11, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 11\n",
      "np.shape(curr_data): (10, 59), np.nanmax(curr_data): 0.14933925445043028, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 10\n",
      "np.shape(curr_data): (11, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 11\n",
      "np.shape(curr_data): (10, 59), np.nanmax(curr_data): 0.17673647253127112, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 10\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_094\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_094\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_094\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_094\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[74][\"p_x_given_n\"]): (59, 4, 9)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.554975 0 0.445025 0]\n",
      "\t_long_any: 0.445025457995953, _short_any: 0.5549745420040473\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.415203 0 0.584797]\n",
      "\t_long_any: 0.5847970640941248, _short_any: 0.4152029359058755\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.957272 0 0.0427284]\n",
      "\t_long_any: 0.04272841729420192, _short_any: 0.957271582705798\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0119574 0.864153 0.1037 0.0201889]\n",
      "\t_long_any: 0.12388918680292176, _short_any: 0.8761108131970783\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.152419 0 0.847581 0]\n",
      "\t_long_any: 0.8475806203574026, _short_any: 0.15241937964259739\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.746966 0 0.253034 0]\n",
      "\t_long_any: 0.25303399020920103, _short_any: 0.7469660097907995\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.355339 0.420271 0.0155982 0.208792]\n",
      "\t_long_any: 0.22439018210280798, _short_any: 0.7756098178971926\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_094/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_094'\n",
      "processing an_epoch_idx: 56/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 56)\n",
      "an_epoch: EpochTuple(Index=56, start=735.2181886882754, stop=735.3754135677591, label=95, duration=0.15722487948369235, end=735.3754135677591, score=0.21580060588720062, velocity=162.5817989676303, intercept=119727.78745492619, speed=162.5817989676303, wcorr=-0.828334019038871, P_decoder=nan, pearsonr=-0.00416777902051757, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=79.15337981027551, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 5, 43, 49, 37, 10, 41, 39, 17, 11, 19, 21, 23, 27, 44, 45,  7, 24]), n_unique_aclus=17)\n",
      "an_epoch: EpochTuple(Index=56, start=735.2181886882754, stop=735.3754135677591, label=95, duration=0.15722487948369235, end=735.3754135677591, score=0.21580060588720062, velocity=162.5817989676303, intercept=119727.78745492619, speed=162.5817989676303, wcorr=-0.828334019038871, P_decoder=nan, pearsonr=-0.00416777902051757, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=79.15337981027551, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 5, 43, 49, 37, 10, 41, 39, 17, 11, 19, 21, 23, 27, 44, 45,  7, 24]), n_unique_aclus=17)\n",
      "an_epoch: EpochTuple(Index=56, start=735.2181886882754, stop=735.3754135677591, label=95, duration=0.15722487948369235, end=735.3754135677591, score=0.21580060588720062, velocity=162.5817989676303, intercept=119727.78745492619, speed=162.5817989676303, wcorr=-0.828334019038871, P_decoder=nan, pearsonr=-0.00416777902051757, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=79.15337981027551, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 5, 43, 49, 37, 10, 41, 39, 17, 11, 19, 21, 23, 27, 44, 45,  7, 24]), n_unique_aclus=17)\n",
      "an_epoch: EpochTuple(Index=56, start=735.2181886882754, stop=735.3754135677591, label=95, duration=0.15722487948369235, end=735.3754135677591, score=0.21580060588720062, velocity=162.5817989676303, intercept=119727.78745492619, speed=162.5817989676303, wcorr=-0.828334019038871, P_decoder=nan, pearsonr=-0.00416777902051757, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=79.15337981027551, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 5, 43, 49, 37, 10, 41, 39, 17, 11, 19, 21, 23, 27, 44, 45,  7, 24]), n_unique_aclus=17)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (13, 59), np.nanmax(curr_data): 0.1146338264762386, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 13\n",
      "np.shape(curr_data): (12, 59), np.nanmax(curr_data): 0.13918661674691393, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 12\n",
      "np.shape(curr_data): (13, 59), np.nanmax(curr_data): 0.1490508567103094, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 13\n",
      "np.shape(curr_data): (12, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 12\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_095\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_095\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_095\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_095\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[75][\"p_x_given_n\"]): (59, 4, 7)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.5897 0 0.4103 0]\n",
      "\t_long_any: 0.4102997719911557, _short_any: 0.589700228008844\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.761959 0 0.238041]\n",
      "\t_long_any: 0.2380409748346363, _short_any: 0.7619590251653637\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.858464 0 0.141536]\n",
      "\t_long_any: 0.1415356088576647, _short_any: 0.8584643911423352\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [8.83035e-05 0.965538 3.91863e-05 0.0343346]\n",
      "\t_long_any: 0.034373811704447456, _short_any: 0.9656261882955538\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.832983 0 0.167017 0]\n",
      "\t_long_any: 0.16701650191731732, _short_any: 0.832983498082682\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.806322 0 0.193678 0]\n",
      "\t_long_any: 0.19367840081872817, _short_any: 0.8063215991812716\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_095/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_095'\n",
      "processing an_epoch_idx: 57/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 57)\n",
      "an_epoch: EpochTuple(Index=57, start=736.0269844342256, stop=736.0938004000345, label=96, duration=0.06681596580892801, end=736.0938004000345, score=0.34572778700442525, velocity=390.19631752260824, intercept=287377.92344734346, speed=390.19631752260824, wcorr=-0.8359831466887983, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=79.9621755562257, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([35, 46, 27, 49,  4, 23,  5,  9, 44, 45, 19]), n_unique_aclus=11)\n",
      "an_epoch: EpochTuple(Index=57, start=736.0269844342256, stop=736.0938004000345, label=96, duration=0.06681596580892801, end=736.0938004000345, score=0.34572778700442525, velocity=390.19631752260824, intercept=287377.92344734346, speed=390.19631752260824, wcorr=-0.8359831466887983, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=79.9621755562257, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([35, 46, 27, 49,  4, 23,  5,  9, 44, 45, 19]), n_unique_aclus=11)\n",
      "an_epoch: EpochTuple(Index=57, start=736.0269844342256, stop=736.0938004000345, label=96, duration=0.06681596580892801, end=736.0938004000345, score=0.34572778700442525, velocity=390.19631752260824, intercept=287377.92344734346, speed=390.19631752260824, wcorr=-0.8359831466887983, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=79.9621755562257, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([35, 46, 27, 49,  4, 23,  5,  9, 44, 45, 19]), n_unique_aclus=11)\n",
      "an_epoch: EpochTuple(Index=57, start=736.0269844342256, stop=736.0938004000345, label=96, duration=0.06681596580892801, end=736.0938004000345, score=0.34572778700442525, velocity=390.19631752260824, intercept=287377.92344734346, speed=390.19631752260824, wcorr=-0.8359831466887983, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=79.9621755562257, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([35, 46, 27, 49,  4, 23,  5,  9, 44, 45, 19]), n_unique_aclus=11)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.1306753907929282, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.13918661674691393, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.12484290630009687, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_096\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_096\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_096\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_096\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[76][\"p_x_given_n\"]): (59, 4, 3)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [2.00521e-05 0 0.99998 0]\n",
      "\t_long_any: 0.9999799479117667, _short_any: 2.0052088233469566e-05\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.675605 0 0.324395 0]\n",
      "\t_long_any: 0.32439483592328805, _short_any: 0.675605164076712\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_096/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_096'\n",
      "processing an_epoch_idx: 58/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 58)\n",
      "an_epoch: EpochTuple(Index=58, start=738.1171107239788, stop=738.4350011213683, label=98, duration=0.3178903973894194, end=738.4350011213683, score=0.15895775242215052, velocity=-292.6472381417344, intercept=-216004.27578805242, speed=292.6472381417344, wcorr=-0.07806562315994119, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=82.05230184597895, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([43, 37, 26, 18, 25, 27, 49, 53, 24, 45,  7, 40, 20, 19, 17, 21,  2, 23, 35, 32,  5, 46]), n_unique_aclus=22)\n",
      "an_epoch: EpochTuple(Index=58, start=738.1171107239788, stop=738.4350011213683, label=98, duration=0.3178903973894194, end=738.4350011213683, score=0.15895775242215052, velocity=-292.6472381417344, intercept=-216004.27578805242, speed=292.6472381417344, wcorr=-0.07806562315994119, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=82.05230184597895, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([43, 37, 26, 18, 25, 27, 49, 53, 24, 45,  7, 40, 20, 19, 17, 21,  2, 23, 35, 32,  5, 46]), n_unique_aclus=22)\n",
      "an_epoch: EpochTuple(Index=58, start=738.1171107239788, stop=738.4350011213683, label=98, duration=0.3178903973894194, end=738.4350011213683, score=0.15895775242215052, velocity=-292.6472381417344, intercept=-216004.27578805242, speed=292.6472381417344, wcorr=-0.07806562315994119, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=82.05230184597895, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([43, 37, 26, 18, 25, 27, 49, 53, 24, 45,  7, 40, 20, 19, 17, 21,  2, 23, 35, 32,  5, 46]), n_unique_aclus=22)\n",
      "an_epoch: EpochTuple(Index=58, start=738.1171107239788, stop=738.4350011213683, label=98, duration=0.3178903973894194, end=738.4350011213683, score=0.15895775242215052, velocity=-292.6472381417344, intercept=-216004.27578805242, speed=292.6472381417344, wcorr=-0.07806562315994119, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=82.05230184597895, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([43, 37, 26, 18, 25, 27, 49, 53, 24, 45,  7, 40, 20, 19, 17, 21,  2, 23, 35, 32,  5, 46]), n_unique_aclus=22)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (17, 59), np.nanmax(curr_data): 0.1413380488947274, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 17\n",
      "np.shape(curr_data): (14, 59), np.nanmax(curr_data): 0.16871442757882205, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 14\n",
      "np.shape(curr_data): (17, 59), np.nanmax(curr_data): 0.16137889015198256, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 17\n",
      "np.shape(curr_data): (14, 59), np.nanmax(curr_data): 0.18913760071074082, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 14\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_098\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_098\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_098\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_098\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[77][\"p_x_given_n\"]): (59, 4, 13)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.122617 0.12392 0.0367212 0.716742]\n",
      "\t_long_any: 0.7534633837644745, _short_any: 0.24653661623552614\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.856242 0 0.143758]\n",
      "\t_long_any: 0.14375848377777023, _short_any: 0.8562415162222298\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.43432 0 0.56568 0]\n",
      "\t_long_any: 0.5656803965582573, _short_any: 0.434319603441743\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.163445 0.219892 0.588674 0.0279889]\n",
      "\t_long_any: 0.6166630070285194, _short_any: 0.3833369929714804\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.999927 0 7.34231e-05 0]\n",
      "\t_long_any: 7.342312532019417e-05, _short_any: 0.9999265768746803\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.997419 0 0.00258115 0]\n",
      "\t_long_any: 0.0025811510574903925, _short_any: 0.9974188489425091\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.661803 0 0.338197 0]\n",
      "\t_long_any: 0.33819669922778495, _short_any: 0.6618033007722149\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.328059 0 0.671941 0]\n",
      "\t_long_any: 0.6719410998228526, _short_any: 0.32805890017714784\n",
      "i: 10, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.89479 0 0.10521 0]\n",
      "\t_long_any: 0.10521037593076334, _short_any: 0.8947896240692368\n",
      "i: 11, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0062902 0.00011003 0.983858 0.00974226]\n",
      "\t_long_any: 0.9935997715569942, _short_any: 0.006400228443005926\n",
      "i: 12, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.804823 0 0.195177 0]\n",
      "\t_long_any: 0.19517703355217694, _short_any: 0.8048229664478228\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_098/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_098'\n",
      "processing an_epoch_idx: 59/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 59)\n",
      "an_epoch: EpochTuple(Index=59, start=739.3676905636676, stop=739.4130639804062, label=99, duration=0.04537341673858464, end=739.4130639804062, score=0.8164659980902089, velocity=-195.09815876130355, intercept=-144015.15728605542, speed=195.09815876130355, wcorr=0.33583026172528047, P_decoder=0.1660770005806396, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=83.30288168566767, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([43, 27, 15, 18, 26, 31, 50, 37]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=59, start=739.3676905636676, stop=739.4130639804062, label=99, duration=0.04537341673858464, end=739.4130639804062, score=0.8164659980902089, velocity=-195.09815876130355, intercept=-144015.15728605542, speed=195.09815876130355, wcorr=0.33583026172528047, P_decoder=0.1660770005806396, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=83.30288168566767, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([43, 27, 15, 18, 26, 31, 50, 37]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=59, start=739.3676905636676, stop=739.4130639804062, label=99, duration=0.04537341673858464, end=739.4130639804062, score=0.8164659980902089, velocity=-195.09815876130355, intercept=-144015.15728605542, speed=195.09815876130355, wcorr=0.33583026172528047, P_decoder=0.1660770005806396, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=83.30288168566767, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([43, 27, 15, 18, 26, 31, 50, 37]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=59, start=739.3676905636676, stop=739.4130639804062, label=99, duration=0.04537341673858464, end=739.4130639804062, score=0.8164659980902089, velocity=-195.09815876130355, intercept=-144015.15728605542, speed=195.09815876130355, wcorr=0.33583026172528047, P_decoder=0.1660770005806396, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=83.30288168566767, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([43, 27, 15, 18, 26, 31, 50, 37]), n_unique_aclus=8)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.14933925445043028, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.16577466995625206, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_099\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_099\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_099\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_099\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[78][\"p_x_given_n\"]): (59, 4, 2)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.21212 0 0.78788 0]\n",
      "\t_long_any: 0.7878801501256957, _short_any: 0.2121198498743045\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.120034 0 0.879966 0]\n",
      "\t_long_any: 0.8799658487130255, _short_any: 0.12003415128697476\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_099/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_099'\n",
      "processing an_epoch_idx: 60/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 60)\n",
      "an_epoch: EpochTuple(Index=60, start=747.3501248767134, stop=747.432515874505, label=101, duration=0.08239099779166281, end=747.432515874505, score=0.4132807842066298, velocity=260.13087834801127, intercept=194473.06422826755, speed=260.13087834801127, wcorr=-0.3800570574512758, P_decoder=0.6459859436146762, pearsonr=0.4579342643385089, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=91.28531599871349, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([45, 19, 21, 18,  7, 20, 40, 14]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=60, start=747.3501248767134, stop=747.432515874505, label=101, duration=0.08239099779166281, end=747.432515874505, score=0.4132807842066298, velocity=260.13087834801127, intercept=194473.06422826755, speed=260.13087834801127, wcorr=-0.3800570574512758, P_decoder=0.6459859436146762, pearsonr=0.4579342643385089, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=91.28531599871349, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([45, 19, 21, 18,  7, 20, 40, 14]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=60, start=747.3501248767134, stop=747.432515874505, label=101, duration=0.08239099779166281, end=747.432515874505, score=0.4132807842066298, velocity=260.13087834801127, intercept=194473.06422826755, speed=260.13087834801127, wcorr=-0.3800570574512758, P_decoder=0.6459859436146762, pearsonr=0.4579342643385089, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=91.28531599871349, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([45, 19, 21, 18,  7, 20, 40, 14]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=60, start=747.3501248767134, stop=747.432515874505, label=101, duration=0.08239099779166281, end=747.432515874505, score=0.4132807842066298, velocity=260.13087834801127, intercept=194473.06422826755, speed=260.13087834801127, wcorr=-0.3800570574512758, P_decoder=0.6459859436146762, pearsonr=0.4579342643385089, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=91.28531599871349, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([45, 19, 21, 18,  7, 20, 40, 14]), n_unique_aclus=8)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.10832426379331009, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (5, 59), np.nanmax(curr_data): 0.14646292062398014, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 5\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.14773746413841815, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (5, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 5\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_101\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_101\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_101\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_101\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[80][\"p_x_given_n\"]): (59, 4, 4)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.78086 0 0.21914 0]\n",
      "\t_long_any: 0.21913979353075033, _short_any: 0.7808602064692494\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [1 0 2.80792e-10 0]\n",
      "\t_long_any: 2.807917610374028e-10, _short_any: 0.9999999997192082\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.997993 0 0.00200739 0]\n",
      "\t_long_any: 0.0020073874686310123, _short_any: 0.9979926125313692\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.666406 0 0.333594]\n",
      "\t_long_any: 0.3335944527748874, _short_any: 0.666405547225113\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_101/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_101'\n",
      "processing an_epoch_idx: 61/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 61)\n",
      "an_epoch: EpochTuple(Index=61, start=761.1802617956419, stop=761.5534788846271, label=102, duration=0.37321708898525685, end=761.5534788846271, score=0.16992415075679357, velocity=-432.00306582818115, intercept=-328747.3738835107, speed=432.00306582818115, wcorr=0.2802209743490821, P_decoder=0.24460977098813594, pearsonr=0.7300267822468833, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=105.11545291764196, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([35,  4, 10, 44, 23, 21, 45, 19, 41, 14,  9, 52, 16, 37, 31, 39, 27,  5, 18, 49, 43]), n_unique_aclus=21)\n",
      "an_epoch: EpochTuple(Index=61, start=761.1802617956419, stop=761.5534788846271, label=102, duration=0.37321708898525685, end=761.5534788846271, score=0.16992415075679357, velocity=-432.00306582818115, intercept=-328747.3738835107, speed=432.00306582818115, wcorr=0.2802209743490821, P_decoder=0.24460977098813594, pearsonr=0.7300267822468833, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=105.11545291764196, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([35,  4, 10, 44, 23, 21, 45, 19, 41, 14,  9, 52, 16, 37, 31, 39, 27,  5, 18, 49, 43]), n_unique_aclus=21)\n",
      "an_epoch: EpochTuple(Index=61, start=761.1802617956419, stop=761.5534788846271, label=102, duration=0.37321708898525685, end=761.5534788846271, score=0.16992415075679357, velocity=-432.00306582818115, intercept=-328747.3738835107, speed=432.00306582818115, wcorr=0.2802209743490821, P_decoder=0.24460977098813594, pearsonr=0.7300267822468833, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=105.11545291764196, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([35,  4, 10, 44, 23, 21, 45, 19, 41, 14,  9, 52, 16, 37, 31, 39, 27,  5, 18, 49, 43]), n_unique_aclus=21)\n",
      "an_epoch: EpochTuple(Index=61, start=761.1802617956419, stop=761.5534788846271, label=102, duration=0.37321708898525685, end=761.5534788846271, score=0.16992415075679357, velocity=-432.00306582818115, intercept=-328747.3738835107, speed=432.00306582818115, wcorr=0.2802209743490821, P_decoder=0.24460977098813594, pearsonr=0.7300267822468833, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=105.11545291764196, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([35,  4, 10, 44, 23, 21, 45, 19, 41, 14,  9, 52, 16, 37, 31, 39, 27,  5, 18, 49, 43]), n_unique_aclus=21)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (15, 59), np.nanmax(curr_data): 0.1146338264762386, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 15\n",
      "np.shape(curr_data): (17, 59), np.nanmax(curr_data): 0.14646292062398014, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 17\n",
      "np.shape(curr_data): (15, 59), np.nanmax(curr_data): 0.1490508567103094, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 15\n",
      "np.shape(curr_data): (17, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 17\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_102\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_102\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_102\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_102\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[81][\"p_x_given_n\"]): (59, 4, 15)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.563214 0.0176144 0.413006 0.00616514]\n",
      "\t_long_any: 0.41917143805214757, _short_any: 0.5808285619478522\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.899609 0 0.100391 0]\n",
      "\t_long_any: 0.10039054752523568, _short_any: 0.8996094524747643\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.560689 0 0.439311 0]\n",
      "\t_long_any: 0.43931105020216465, _short_any: 0.5606889497978357\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.666406 0 0.333594]\n",
      "\t_long_any: 0.3335944527748874, _short_any: 0.666405547225113\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.575847 0 0.424153]\n",
      "\t_long_any: 0.42415293715520674, _short_any: 0.5758470628447931\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.794163 0 0.205837]\n",
      "\t_long_any: 0.20583698753982638, _short_any: 0.7941630124601736\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0320809 0.681363 0.000328426 0.286227]\n",
      "\t_long_any: 0.28655581826957777, _short_any: 0.7134441817304219\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 6.91195e-05 0 0.999931]\n",
      "\t_long_any: 0.9999308804604192, _short_any: 6.911953958065666e-05\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.00129832 0 0.998702]\n",
      "\t_long_any: 0.9987016807114715, _short_any: 0.0012983192885285672\n",
      "i: 10, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.334811 0.340702 0.0213215 0.303166]\n",
      "\t_long_any: 0.3244870639315525, _short_any: 0.6755129360684474\n",
      "i: 11, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 12, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 13, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.530607 0 0.469393 0]\n",
      "\t_long_any: 0.4693927892627292, _short_any: 0.5306072107372706\n",
      "i: 14, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.788408 0 0.211592 0]\n",
      "\t_long_any: 0.21159171789756465, _short_any: 0.7884082821024356\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_102/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_102'\n",
      "processing an_epoch_idx: 62/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 62)\n",
      "an_epoch: EpochTuple(Index=62, start=769.0905348656233, stop=769.3232694664039, label=103, duration=0.23273460078053176, end=769.3232694664039, score=0.271755111646189, velocity=-476.9066103049283, intercept=-366739.10806632275, speed=476.9066103049283, wcorr=0.312828709718376, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=113.02572598762345, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([40,  7, 45, 20, 19, 18, 21,  9, 14, 24,  4]), n_unique_aclus=11)\n",
      "an_epoch: EpochTuple(Index=62, start=769.0905348656233, stop=769.3232694664039, label=103, duration=0.23273460078053176, end=769.3232694664039, score=0.271755111646189, velocity=-476.9066103049283, intercept=-366739.10806632275, speed=476.9066103049283, wcorr=0.312828709718376, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=113.02572598762345, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([40,  7, 45, 20, 19, 18, 21,  9, 14, 24,  4]), n_unique_aclus=11)\n",
      "an_epoch: EpochTuple(Index=62, start=769.0905348656233, stop=769.3232694664039, label=103, duration=0.23273460078053176, end=769.3232694664039, score=0.271755111646189, velocity=-476.9066103049283, intercept=-366739.10806632275, speed=476.9066103049283, wcorr=0.312828709718376, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=113.02572598762345, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([40,  7, 45, 20, 19, 18, 21,  9, 14, 24,  4]), n_unique_aclus=11)\n",
      "an_epoch: EpochTuple(Index=62, start=769.0905348656233, stop=769.3232694664039, label=103, duration=0.23273460078053176, end=769.3232694664039, score=0.271755111646189, velocity=-476.9066103049283, intercept=-366739.10806632275, speed=476.9066103049283, wcorr=0.312828709718376, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=113.02572598762345, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([40,  7, 45, 20, 19, 18, 21,  9, 14, 24,  4]), n_unique_aclus=11)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.10832426379331009, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.14646292062398014, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.14773746413841815, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_103\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_103\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_103\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_103\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[82][\"p_x_given_n\"]): (59, 4, 10)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.99998 0 1.96415e-05 0]\n",
      "\t_long_any: 1.964150825904952e-05, _short_any: 0.9999803584917405\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.746141 0 0.253859 0]\n",
      "\t_long_any: 0.2538586417031121, _short_any: 0.7461413582968877\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.687045 0.223075 0.0128872 0.0769925]\n",
      "\t_long_any: 0.08987967879420958, _short_any: 0.9101203212057905\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.566365 0.13291 0.275665 0.0250604]\n",
      "\t_long_any: 0.30072523341809443, _short_any: 0.6992747665819053\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.810802 0.00103389 0.188067 9.76089e-05]\n",
      "\t_long_any: 0.18816446409924475, _short_any: 0.8118355359007553\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.923086 0.00637672 0.0702102 0.000327162]\n",
      "\t_long_any: 0.0705373135223597, _short_any: 0.9294626864776401\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.817156 0 0.182844 0]\n",
      "\t_long_any: 0.18284379696623476, _short_any: 0.8171562030337649\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_103/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_103'\n",
      "processing an_epoch_idx: 63/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 63)\n",
      "an_epoch: EpochTuple(Index=63, start=770.6948860441335, stop=770.8393314102432, label=104, duration=0.14444536610972136, end=770.8393314102432, score=0.3128452658202263, velocity=-117.05889525667612, intercept=-89986.47611295804, speed=117.05889525667612, wcorr=0.714322632371319, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=114.63007716613356, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([14,  9, 20, 52, 10, 39, 11, 44, 17, 16, 32, 37, 35, 27,  5, 41, 18, 31, 50, 26]), n_unique_aclus=20)\n",
      "an_epoch: EpochTuple(Index=63, start=770.6948860441335, stop=770.8393314102432, label=104, duration=0.14444536610972136, end=770.8393314102432, score=0.3128452658202263, velocity=-117.05889525667612, intercept=-89986.47611295804, speed=117.05889525667612, wcorr=0.714322632371319, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=114.63007716613356, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([14,  9, 20, 52, 10, 39, 11, 44, 17, 16, 32, 37, 35, 27,  5, 41, 18, 31, 50, 26]), n_unique_aclus=20)\n",
      "an_epoch: EpochTuple(Index=63, start=770.6948860441335, stop=770.8393314102432, label=104, duration=0.14444536610972136, end=770.8393314102432, score=0.3128452658202263, velocity=-117.05889525667612, intercept=-89986.47611295804, speed=117.05889525667612, wcorr=0.714322632371319, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=114.63007716613356, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([14,  9, 20, 52, 10, 39, 11, 44, 17, 16, 32, 37, 35, 27,  5, 41, 18, 31, 50, 26]), n_unique_aclus=20)\n",
      "an_epoch: EpochTuple(Index=63, start=770.6948860441335, stop=770.8393314102432, label=104, duration=0.14444536610972136, end=770.8393314102432, score=0.3128452658202263, velocity=-117.05889525667612, intercept=-89986.47611295804, speed=117.05889525667612, wcorr=0.714322632371319, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=114.63007716613356, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([14,  9, 20, 52, 10, 39, 11, 44, 17, 16, 32, 37, 35, 27,  5, 41, 18, 31, 50, 26]), n_unique_aclus=20)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (13, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 13\n",
      "np.shape(curr_data): (18, 59), np.nanmax(curr_data): 0.14933925445043028, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 18\n",
      "np.shape(curr_data): (13, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 13\n",
      "np.shape(curr_data): (18, 59), np.nanmax(curr_data): 0.16577466995625206, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 18\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_104\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_104\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_104\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_104\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[83][\"p_x_given_n\"]): (59, 4, 6)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.883025 0 0.116975]\n",
      "\t_long_any: 0.11697545076242183, _short_any: 0.8830245492375783\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [2.02824e-06 1.35438e-07 0.0181572 0.981841]\n",
      "\t_long_any: 0.9999978363232135, _short_any: 2.1636767867364744e-06\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [8.58433e-06 0.000960347 1.71156e-05 0.999014]\n",
      "\t_long_any: 0.999031068832615, _short_any: 0.0009689311673848594\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.00050097 0.991375 0.00254975 0.0055743]\n",
      "\t_long_any: 0.008124056628343519, _short_any: 0.9918759433716565\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_104/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_104'\n",
      "processing an_epoch_idx: 64/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 64)\n",
      "an_epoch: EpochTuple(Index=64, start=794.9678822564892, stop=795.2257765243994, label=107, duration=0.2578942679101601, end=795.2257765243994, score=0.20840397608533107, velocity=-1059.1042904178203, intercept=-841876.9007474196, speed=1059.1042904178203, wcorr=-0.1311139949753356, P_decoder=nan, pearsonr=-0.04467209167468564, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=138.90307337848935, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 7, 11, 17, 52, 14, 21, 39,  9, 18, 49, 35, 27,  5, 37, 25, 31, 26, 50, 20, 24, 23, 45]), n_unique_aclus=22)\n",
      "an_epoch: EpochTuple(Index=64, start=794.9678822564892, stop=795.2257765243994, label=107, duration=0.2578942679101601, end=795.2257765243994, score=0.20840397608533107, velocity=-1059.1042904178203, intercept=-841876.9007474196, speed=1059.1042904178203, wcorr=-0.1311139949753356, P_decoder=nan, pearsonr=-0.04467209167468564, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=138.90307337848935, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 7, 11, 17, 52, 14, 21, 39,  9, 18, 49, 35, 27,  5, 37, 25, 31, 26, 50, 20, 24, 23, 45]), n_unique_aclus=22)\n",
      "an_epoch: EpochTuple(Index=64, start=794.9678822564892, stop=795.2257765243994, label=107, duration=0.2578942679101601, end=795.2257765243994, score=0.20840397608533107, velocity=-1059.1042904178203, intercept=-841876.9007474196, speed=1059.1042904178203, wcorr=-0.1311139949753356, P_decoder=nan, pearsonr=-0.04467209167468564, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=138.90307337848935, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 7, 11, 17, 52, 14, 21, 39,  9, 18, 49, 35, 27,  5, 37, 25, 31, 26, 50, 20, 24, 23, 45]), n_unique_aclus=22)\n",
      "an_epoch: EpochTuple(Index=64, start=794.9678822564892, stop=795.2257765243994, label=107, duration=0.2578942679101601, end=795.2257765243994, score=0.20840397608533107, velocity=-1059.1042904178203, intercept=-841876.9007474196, speed=1059.1042904178203, wcorr=-0.1311139949753356, P_decoder=nan, pearsonr=-0.04467209167468564, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=138.90307337848935, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 7, 11, 17, 52, 14, 21, 39,  9, 18, 49, 35, 27,  5, 37, 25, 31, 26, 50, 20, 24, 23, 45]), n_unique_aclus=22)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (14, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 14\n",
      "np.shape(curr_data): (18, 59), np.nanmax(curr_data): 0.16871442757882205, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 18\n",
      "np.shape(curr_data): (14, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 14\n",
      "np.shape(curr_data): (18, 59), np.nanmax(curr_data): 0.16771957548724484, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 18\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_107\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_107\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_107\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_107\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[85][\"p_x_given_n\"]): (59, 4, 11)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.468769 0 0.531231]\n",
      "\t_long_any: 0.5312314361453576, _short_any: 0.4687685638546421\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.972184 0 0.027816]\n",
      "\t_long_any: 0.027815985689468616, _short_any: 0.9721840143105313\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0415394 0.0160455 0.754607 0.187808]\n",
      "\t_long_any: 0.9424150971271987, _short_any: 0.057584902872801116\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.0167268 0 0.983273]\n",
      "\t_long_any: 0.9832731675315763, _short_any: 0.016726832468423745\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.204031 0 0.795969]\n",
      "\t_long_any: 0.7959689760751423, _short_any: 0.20403102392485778\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.113398 0.646914 0.202913 0.0367745]\n",
      "\t_long_any: 0.23968754897811145, _short_any: 0.7603124510218887\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.751986 0 0.248014 0]\n",
      "\t_long_any: 0.24801405794551284, _short_any: 0.7519859420544874\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.65477 0 0.34523 0]\n",
      "\t_long_any: 0.3452300566448491, _short_any: 0.654769943355151\n",
      "i: 10, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.621891 0.0122324 0.360753 0.00512414]\n",
      "\t_long_any: 0.3658767436006062, _short_any: 0.6341232563993943\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_107/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_107'\n",
      "processing an_epoch_idx: 65/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 65)\n",
      "an_epoch: EpochTuple(Index=65, start=811.4449451802066, stop=811.5542161641642, label=108, duration=0.10927098395768553, end=811.5542161641642, score=0.34226275673685147, velocity=585.2944762832471, intercept=475031.7933013178, speed=585.2944762832471, wcorr=-0.448554550016741, P_decoder=0.6458021436219974, pearsonr=0.007593810670253564, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=155.38013630220667, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([14,  9, 52, 49, 21, 19, 40,  7, 20, 45]), n_unique_aclus=10)\n",
      "an_epoch: EpochTuple(Index=65, start=811.4449451802066, stop=811.5542161641642, label=108, duration=0.10927098395768553, end=811.5542161641642, score=0.34226275673685147, velocity=585.2944762832471, intercept=475031.7933013178, speed=585.2944762832471, wcorr=-0.448554550016741, P_decoder=0.6458021436219974, pearsonr=0.007593810670253564, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=155.38013630220667, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([14,  9, 52, 49, 21, 19, 40,  7, 20, 45]), n_unique_aclus=10)\n",
      "an_epoch: EpochTuple(Index=65, start=811.4449451802066, stop=811.5542161641642, label=108, duration=0.10927098395768553, end=811.5542161641642, score=0.34226275673685147, velocity=585.2944762832471, intercept=475031.7933013178, speed=585.2944762832471, wcorr=-0.448554550016741, P_decoder=0.6458021436219974, pearsonr=0.007593810670253564, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=155.38013630220667, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([14,  9, 52, 49, 21, 19, 40,  7, 20, 45]), n_unique_aclus=10)\n",
      "an_epoch: EpochTuple(Index=65, start=811.4449451802066, stop=811.5542161641642, label=108, duration=0.10927098395768553, end=811.5542161641642, score=0.34226275673685147, velocity=585.2944762832471, intercept=475031.7933013178, speed=585.2944762832471, wcorr=-0.448554550016741, P_decoder=0.6458021436219974, pearsonr=0.007593810670253564, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=155.38013630220667, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([14,  9, 52, 49, 21, 19, 40,  7, 20, 45]), n_unique_aclus=10)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.10832426379331009, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.14646292062398014, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.14773746413841815, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_108\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_108\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_108\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_108\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[86][\"p_x_given_n\"]): (59, 4, 5)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.979436 0 0.0205638]\n",
      "\t_long_any: 0.020563837349608035, _short_any: 0.9794361626503919\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.441471 0 0.558529 0]\n",
      "\t_long_any: 0.5585287330361992, _short_any: 0.44147126696380146\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.999816 0 0.000184325 0]\n",
      "\t_long_any: 0.00018432472778062502, _short_any: 0.9998156752722198\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.999007 0 0.000992721 0]\n",
      "\t_long_any: 0.0009927205315123102, _short_any: 0.9990072794684882\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.621891 0.0122324 0.360753 0.00512414]\n",
      "\t_long_any: 0.3658767436006062, _short_any: 0.6341232563993943\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_108/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_108'\n",
      "processing an_epoch_idx: 66/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 66)\n",
      "an_epoch: EpochTuple(Index=66, start=812.6678770340513, stop=813.0885257787304, label=109, duration=0.4206487446790561, end=813.0885257787304, score=0.15423429912059206, velocity=-60.96817461285559, intercept=-49501.303318747596, speed=60.96817461285559, wcorr=-0.20940543536151174, P_decoder=0.39971930322943106, pearsonr=0.4596762396265285, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=156.60306815605145, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 5, 45,  7, 20, 40, 19, 21, 24, 23]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=66, start=812.6678770340513, stop=813.0885257787304, label=109, duration=0.4206487446790561, end=813.0885257787304, score=0.15423429912059206, velocity=-60.96817461285559, intercept=-49501.303318747596, speed=60.96817461285559, wcorr=-0.20940543536151174, P_decoder=0.39971930322943106, pearsonr=0.4596762396265285, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=156.60306815605145, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 5, 45,  7, 20, 40, 19, 21, 24, 23]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=66, start=812.6678770340513, stop=813.0885257787304, label=109, duration=0.4206487446790561, end=813.0885257787304, score=0.15423429912059206, velocity=-60.96817461285559, intercept=-49501.303318747596, speed=60.96817461285559, wcorr=-0.20940543536151174, P_decoder=0.39971930322943106, pearsonr=0.4596762396265285, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=156.60306815605145, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 5, 45,  7, 20, 40, 19, 21, 24, 23]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=66, start=812.6678770340513, stop=813.0885257787304, label=109, duration=0.4206487446790561, end=813.0885257787304, score=0.15423429912059206, velocity=-60.96817461285559, intercept=-49501.303318747596, speed=60.96817461285559, wcorr=-0.20940543536151174, P_decoder=0.39971930322943106, pearsonr=0.4596762396265285, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=156.60306815605145, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 5, 45,  7, 20, 40, 19, 21, 24, 23]), n_unique_aclus=9)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.10832426379331009, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (4, 59), np.nanmax(curr_data): 0.13918661674691393, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 4\n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.14773746413841815, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (4, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 4\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_109\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_109\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_109\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_109\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[87][\"p_x_given_n\"]): (59, 4, 17)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.401826 0.222795 0.0835336 0.291845]\n",
      "\t_long_any: 0.3753785335947758, _short_any: 0.6246214664052238\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.999861 0 0.000139155 0]\n",
      "\t_long_any: 0.00013915531102185315, _short_any: 0.9998608446889786\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.999439 0 0.000560533 0]\n",
      "\t_long_any: 0.0005605329438668441, _short_any: 0.9994394670561335\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.483984 0 0.516016 0]\n",
      "\t_long_any: 0.5160161102233353, _short_any: 0.4839838897766648\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 10, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 11, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.554975 0 0.445025 0]\n",
      "\t_long_any: 0.445025457995953, _short_any: 0.5549745420040473\n",
      "i: 12, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.43432 0 0.56568 0]\n",
      "\t_long_any: 0.5656803965582573, _short_any: 0.434319603441743\n",
      "i: 13, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.690687 0 0.309313 0]\n",
      "\t_long_any: 0.3093131567123081, _short_any: 0.6906868432876918\n",
      "i: 14, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 15, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.3885 0.225026 0.137701 0.248773]\n",
      "\t_long_any: 0.38647475361597433, _short_any: 0.6135252463840257\n",
      "i: 16, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.995602 0 0.00439754 0]\n",
      "\t_long_any: 0.004397544788973275, _short_any: 0.9956024552110272\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_109/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_109'\n",
      "processing an_epoch_idx: 67/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 67)\n",
      "an_epoch: EpochTuple(Index=67, start=827.2364609349752, stop=827.410981165478, label=110, duration=0.1745202305028215, end=827.410981165478, score=0.26433939449687394, velocity=-130.06543917410423, intercept=-107555.04105159221, speed=130.06543917410423, wcorr=-0.061506979824372185, P_decoder=0.7670237634397277, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=171.1716520569753, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([24, 45,  7, 20, 40, 19, 18, 21, 52]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=67, start=827.2364609349752, stop=827.410981165478, label=110, duration=0.1745202305028215, end=827.410981165478, score=0.26433939449687394, velocity=-130.06543917410423, intercept=-107555.04105159221, speed=130.06543917410423, wcorr=-0.061506979824372185, P_decoder=0.7670237634397277, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=171.1716520569753, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([24, 45,  7, 20, 40, 19, 18, 21, 52]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=67, start=827.2364609349752, stop=827.410981165478, label=110, duration=0.1745202305028215, end=827.410981165478, score=0.26433939449687394, velocity=-130.06543917410423, intercept=-107555.04105159221, speed=130.06543917410423, wcorr=-0.061506979824372185, P_decoder=0.7670237634397277, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=171.1716520569753, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([24, 45,  7, 20, 40, 19, 18, 21, 52]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=67, start=827.2364609349752, stop=827.410981165478, label=110, duration=0.1745202305028215, end=827.410981165478, score=0.26433939449687394, velocity=-130.06543917410423, intercept=-107555.04105159221, speed=130.06543917410423, wcorr=-0.061506979824372185, P_decoder=0.7670237634397277, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=171.1716520569753, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([24, 45,  7, 20, 40, 19, 18, 21, 52]), n_unique_aclus=9)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.10832426379331009, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (5, 59), np.nanmax(curr_data): 0.13918661674691393, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 5\n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.14773746413841815, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (5, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 5\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_110\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_110\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_110\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_110\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[88][\"p_x_given_n\"]): (59, 4, 7)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.489634 0 0.510366 0]\n",
      "\t_long_any: 0.5103664151631802, _short_any: 0.48963358483681974\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.621891 0.0122324 0.360753 0.00512414]\n",
      "\t_long_any: 0.3658767436006062, _short_any: 0.6341232563993943\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.759723 0 0.240277 0]\n",
      "\t_long_any: 0.24027699762626764, _short_any: 0.7597230023737327\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.856884 0 0.143116 0]\n",
      "\t_long_any: 0.1431158334124244, _short_any: 0.8568841665875762\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.9999 0 0.00010035 0]\n",
      "\t_long_any: 0.00010034953742087798, _short_any: 0.9998996504625799\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.803008 0 0.196992 0]\n",
      "\t_long_any: 0.19699205255366814, _short_any: 0.8030079474463317\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.839241 0 0.160759 0]\n",
      "\t_long_any: 0.16075927504980153, _short_any: 0.8392407249501983\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_110/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_110'\n",
      "processing an_epoch_idx: 68/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 68)\n",
      "an_epoch: EpochTuple(Index=68, start=844.6169064361602, stop=844.7196340635419, label=112, duration=0.1027276273816824, end=844.7196340635419, score=0.3236266451473732, velocity=-438.97085721243536, intercept=-370726.236211375, speed=438.97085721243536, wcorr=0.26325149770163186, P_decoder=0.5642790557384567, pearsonr=0.4353923363518999, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=188.5520975581603, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 4, 11, 45,  7, 20, 19, 17, 40, 21,  9]), n_unique_aclus=10)\n",
      "an_epoch: EpochTuple(Index=68, start=844.6169064361602, stop=844.7196340635419, label=112, duration=0.1027276273816824, end=844.7196340635419, score=0.3236266451473732, velocity=-438.97085721243536, intercept=-370726.236211375, speed=438.97085721243536, wcorr=0.26325149770163186, P_decoder=0.5642790557384567, pearsonr=0.4353923363518999, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=188.5520975581603, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 4, 11, 45,  7, 20, 19, 17, 40, 21,  9]), n_unique_aclus=10)\n",
      "an_epoch: EpochTuple(Index=68, start=844.6169064361602, stop=844.7196340635419, label=112, duration=0.1027276273816824, end=844.7196340635419, score=0.3236266451473732, velocity=-438.97085721243536, intercept=-370726.236211375, speed=438.97085721243536, wcorr=0.26325149770163186, P_decoder=0.5642790557384567, pearsonr=0.4353923363518999, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=188.5520975581603, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 4, 11, 45,  7, 20, 19, 17, 40, 21,  9]), n_unique_aclus=10)\n",
      "an_epoch: EpochTuple(Index=68, start=844.6169064361602, stop=844.7196340635419, label=112, duration=0.1027276273816824, end=844.7196340635419, score=0.3236266451473732, velocity=-438.97085721243536, intercept=-370726.236211375, speed=438.97085721243536, wcorr=0.26325149770163186, P_decoder=0.5642790557384567, pearsonr=0.4353923363518999, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=188.5520975581603, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 4, 11, 45,  7, 20, 19, 17, 40, 21,  9]), n_unique_aclus=10)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.10832426379331009, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.13918661674691393, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.14773746413841815, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_112\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_112\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_112\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_112\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[90][\"p_x_given_n\"]): (59, 4, 5)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.592465 0 0.407535]\n",
      "\t_long_any: 0.40753538436749637, _short_any: 0.5924646156325039\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.999727 0 0.000272617 0]\n",
      "\t_long_any: 0.0002726168162374067, _short_any: 0.9997273831837624\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.980262 0 0.0197379 0]\n",
      "\t_long_any: 0.01973790687644652, _short_any: 0.9802620931235531\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.794888 0.177356 0.000330663 0.0274252]\n",
      "\t_long_any: 0.027755882583908587, _short_any: 0.972244117416092\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.365485 0.458682 0.0682761 0.107557]\n",
      "\t_long_any: 0.17583275644247778, _short_any: 0.8241672435575219\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_112/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_112'\n",
      "processing an_epoch_idx: 69/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 69)\n",
      "an_epoch: EpochTuple(Index=69, start=863.0844400207279, stop=863.324117338052, label=115, duration=0.23967731732409447, end=863.324117338052, score=0.2674638165400383, velocity=195.09815876110704, intercept=168478.8567288167, speed=195.09815876110704, wcorr=-0.3391352337082961, P_decoder=nan, pearsonr=0.7494774475258262, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=207.01963114272803, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([14, 52, 16, 11, 18,  2, 21,  9,  7, 20, 45, 40]), n_unique_aclus=12)\n",
      "an_epoch: EpochTuple(Index=69, start=863.0844400207279, stop=863.324117338052, label=115, duration=0.23967731732409447, end=863.324117338052, score=0.2674638165400383, velocity=195.09815876110704, intercept=168478.8567288167, speed=195.09815876110704, wcorr=-0.3391352337082961, P_decoder=nan, pearsonr=0.7494774475258262, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=207.01963114272803, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([14, 52, 16, 11, 18,  2, 21,  9,  7, 20, 45, 40]), n_unique_aclus=12)\n",
      "an_epoch: EpochTuple(Index=69, start=863.0844400207279, stop=863.324117338052, label=115, duration=0.23967731732409447, end=863.324117338052, score=0.2674638165400383, velocity=195.09815876110704, intercept=168478.8567288167, speed=195.09815876110704, wcorr=-0.3391352337082961, P_decoder=nan, pearsonr=0.7494774475258262, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=207.01963114272803, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([14, 52, 16, 11, 18,  2, 21,  9,  7, 20, 45, 40]), n_unique_aclus=12)\n",
      "an_epoch: EpochTuple(Index=69, start=863.0844400207279, stop=863.324117338052, label=115, duration=0.23967731732409447, end=863.324117338052, score=0.2674638165400383, velocity=195.09815876110704, intercept=168478.8567288167, speed=195.09815876110704, wcorr=-0.3391352337082961, P_decoder=nan, pearsonr=0.7494774475258262, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=207.01963114272803, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([14, 52, 16, 11, 18,  2, 21,  9,  7, 20, 45, 40]), n_unique_aclus=12)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.10832426379331009, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (10, 59), np.nanmax(curr_data): 0.14646292062398014, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 10\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.14773746413841815, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (10, 59), np.nanmax(curr_data): 0.18913760071074082, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 10\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_115\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_115\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_115\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_115\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[92][\"p_x_given_n\"]): (59, 4, 10)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.0460825 0 0.953917]\n",
      "\t_long_any: 0.9539174940518994, _short_any: 0.04608250594810039\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.997791 0 0.00220886]\n",
      "\t_long_any: 0.0022088577083867614, _short_any: 0.9977911422916127\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.808829 0 0.191171]\n",
      "\t_long_any: 0.19117095485433833, _short_any: 0.8088290451456619\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.362943 0.354347 0.0563191 0.226391]\n",
      "\t_long_any: 0.2827097994654639, _short_any: 0.7172902005345367\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.163903 0.814528 0.00505337 0.0165153]\n",
      "\t_long_any: 0.02156868262536014, _short_any: 0.9784313173746394\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.365485 0.458682 0.0682761 0.107557]\n",
      "\t_long_any: 0.17583275644247778, _short_any: 0.8241672435575219\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.999903 0 9.68725e-05 0]\n",
      "\t_long_any: 9.687252917160575e-05, _short_any: 0.9999031274708282\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.738884 0 0.261116]\n",
      "\t_long_any: 0.26111605300852786, _short_any: 0.7388839469914725\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_115/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_115'\n",
      "processing an_epoch_idx: 70/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 70)\n",
      "an_epoch: EpochTuple(Index=70, start=869.0441169693368, stop=869.3380764989415, label=116, duration=0.2939595296047628, end=869.3380764989415, score=0.2612096092935123, velocity=-0.0, intercept=241.43397146689432, speed=0.0, wcorr=-0.05997493688022398, P_decoder=nan, pearsonr=0.675949384619218, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=212.97930809133686, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([50, 43, 37, 20, 40, 15, 31, 27,  5, 39, 26, 32]), n_unique_aclus=12)\n",
      "an_epoch: EpochTuple(Index=70, start=869.0441169693368, stop=869.3380764989415, label=116, duration=0.2939595296047628, end=869.3380764989415, score=0.2612096092935123, velocity=-0.0, intercept=241.43397146689432, speed=0.0, wcorr=-0.05997493688022398, P_decoder=nan, pearsonr=0.675949384619218, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=212.97930809133686, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([50, 43, 37, 20, 40, 15, 31, 27,  5, 39, 26, 32]), n_unique_aclus=12)\n",
      "an_epoch: EpochTuple(Index=70, start=869.0441169693368, stop=869.3380764989415, label=116, duration=0.2939595296047628, end=869.3380764989415, score=0.2612096092935123, velocity=-0.0, intercept=241.43397146689432, speed=0.0, wcorr=-0.05997493688022398, P_decoder=nan, pearsonr=0.675949384619218, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=212.97930809133686, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([50, 43, 37, 20, 40, 15, 31, 27,  5, 39, 26, 32]), n_unique_aclus=12)\n",
      "an_epoch: EpochTuple(Index=70, start=869.0441169693368, stop=869.3380764989415, label=116, duration=0.2939595296047628, end=869.3380764989415, score=0.2612096092935123, velocity=-0.0, intercept=241.43397146689432, speed=0.0, wcorr=-0.05997493688022398, P_decoder=nan, pearsonr=0.675949384619218, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=212.97930809133686, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([50, 43, 37, 20, 40, 15, 31, 27,  5, 39, 26, 32]), n_unique_aclus=12)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (10, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 10\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.14933925445043028, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (10, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 10\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.16577466995625206, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_116\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_116\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_116\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_116\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[93][\"p_x_given_n\"]): (59, 4, 12)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.157475 0.409607 0.370439 0.0624794]\n",
      "\t_long_any: 0.43291848452631027, _short_any: 0.5670815154736897\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.180847 0 0.819153 0]\n",
      "\t_long_any: 0.8191533320483266, _short_any: 0.18084666795167337\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.938418 0 0.061582 0]\n",
      "\t_long_any: 0.061581998260372514, _short_any: 0.9384180017396275\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0236552 0.0275756 0.147867 0.800903]\n",
      "\t_long_any: 0.9487691724225464, _short_any: 0.05123082757745318\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.401826 0.222795 0.0835336 0.291845]\n",
      "\t_long_any: 0.3753785335947758, _short_any: 0.6246214664052238\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.505606 0 0.494394 0]\n",
      "\t_long_any: 0.494393861745059, _short_any: 0.5056061382549412\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.567057 0 0.432943]\n",
      "\t_long_any: 0.4329430782899852, _short_any: 0.5670569217100145\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 10, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 11, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.117585 0.0446327 0.663297 0.174486]\n",
      "\t_long_any: 0.8377822432281022, _short_any: 0.16221775677189723\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_116/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_116'\n",
      "processing an_epoch_idx: 71/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 71)\n",
      "an_epoch: EpochTuple(Index=71, start=877.0023439348442, stop=877.1513665785315, label=117, duration=0.14902264368720353, end=877.1513665785315, score=0.30802684250324547, velocity=429.2159492744788, intercept=376523.8691196991, speed=429.2159492744788, wcorr=-0.47501283472875366, P_decoder=nan, pearsonr=0.3942159439248261, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=220.93753505684435, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([52, 23, 14,  9, 21, 19,  7, 40, 45, 24]), n_unique_aclus=10)\n",
      "an_epoch: EpochTuple(Index=71, start=877.0023439348442, stop=877.1513665785315, label=117, duration=0.14902264368720353, end=877.1513665785315, score=0.30802684250324547, velocity=429.2159492744788, intercept=376523.8691196991, speed=429.2159492744788, wcorr=-0.47501283472875366, P_decoder=nan, pearsonr=0.3942159439248261, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=220.93753505684435, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([52, 23, 14,  9, 21, 19,  7, 40, 45, 24]), n_unique_aclus=10)\n",
      "an_epoch: EpochTuple(Index=71, start=877.0023439348442, stop=877.1513665785315, label=117, duration=0.14902264368720353, end=877.1513665785315, score=0.30802684250324547, velocity=429.2159492744788, intercept=376523.8691196991, speed=429.2159492744788, wcorr=-0.47501283472875366, P_decoder=nan, pearsonr=0.3942159439248261, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=220.93753505684435, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([52, 23, 14,  9, 21, 19,  7, 40, 45, 24]), n_unique_aclus=10)\n",
      "an_epoch: EpochTuple(Index=71, start=877.0023439348442, stop=877.1513665785315, label=117, duration=0.14902264368720353, end=877.1513665785315, score=0.30802684250324547, velocity=429.2159492744788, intercept=376523.8691196991, speed=429.2159492744788, wcorr=-0.47501283472875366, P_decoder=nan, pearsonr=0.3942159439248261, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=220.93753505684435, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([52, 23, 14,  9, 21, 19,  7, 40, 45, 24]), n_unique_aclus=10)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.10500114125474004, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.14646292062398014, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.14773746413841815, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_117\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_117\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_117\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_117\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[94][\"p_x_given_n\"]): (59, 4, 6)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.986891 0 0.013109]\n",
      "\t_long_any: 0.013108993273576593, _short_any: 0.9868910067264235\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.442437 0 0.557563 0]\n",
      "\t_long_any: 0.5575627140561399, _short_any: 0.44243728594386045\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.999812 0 0.000187556 0]\n",
      "\t_long_any: 0.00018755564680171584, _short_any: 0.9998124443531984\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.909875 0 0.0901248 0]\n",
      "\t_long_any: 0.0901248202289557, _short_any: 0.9098751797710434\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_117/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_117'\n",
      "processing an_epoch_idx: 72/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 72)\n",
      "an_epoch: EpochTuple(Index=72, start=892.3357940040296, stop=892.4680128163891, label=119, duration=0.13221881235949695, end=892.4680128163891, score=0.3452485219200923, velocity=-234.1177905133518, intercept=-208673.17698911537, speed=234.1177905133518, wcorr=-0.5940253411068042, P_decoder=0.19888483377263858, pearsonr=-0.7489503933791171, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=236.2709851260297, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([26, 18, 37, 50, 25, 11, 49, 53, 20]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=72, start=892.3357940040296, stop=892.4680128163891, label=119, duration=0.13221881235949695, end=892.4680128163891, score=0.3452485219200923, velocity=-234.1177905133518, intercept=-208673.17698911537, speed=234.1177905133518, wcorr=-0.5940253411068042, P_decoder=0.19888483377263858, pearsonr=-0.7489503933791171, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=236.2709851260297, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([26, 18, 37, 50, 25, 11, 49, 53, 20]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=72, start=892.3357940040296, stop=892.4680128163891, label=119, duration=0.13221881235949695, end=892.4680128163891, score=0.3452485219200923, velocity=-234.1177905133518, intercept=-208673.17698911537, speed=234.1177905133518, wcorr=-0.5940253411068042, P_decoder=0.19888483377263858, pearsonr=-0.7489503933791171, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=236.2709851260297, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([26, 18, 37, 50, 25, 11, 49, 53, 20]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=72, start=892.3357940040296, stop=892.4680128163891, label=119, duration=0.13221881235949695, end=892.4680128163891, score=0.3452485219200923, velocity=-234.1177905133518, intercept=-208673.17698911537, speed=234.1177905133518, wcorr=-0.5940253411068042, P_decoder=0.19888483377263858, pearsonr=-0.7489503933791171, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=236.2709851260297, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([26, 18, 37, 50, 25, 11, 49, 53, 20]), n_unique_aclus=9)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (5, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 5\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.16871442757882205, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (5, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 5\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.17673647253127112, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_119\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_119\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_119\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_119\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[95][\"p_x_given_n\"]): (59, 4, 6)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.000629703 0.984029 0.00069049 0.0146505]\n",
      "\t_long_any: 0.015341002614638239, _short_any: 0.9846589973853616\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.992335 0 0.00766468]\n",
      "\t_long_any: 0.007664676275776705, _short_any: 0.9923353237242232\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.902514 0 0.0974861]\n",
      "\t_long_any: 0.09748611233606302, _short_any: 0.9025138876639371\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.883452 0 0.116548]\n",
      "\t_long_any: 0.11654759251449673, _short_any: 0.8834524074855034\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.554975 0 0.445025 0]\n",
      "\t_long_any: 0.445025457995953, _short_any: 0.5549745420040473\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_119/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_119'\n",
      "processing an_epoch_idx: 73/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 73)\n",
      "an_epoch: EpochTuple(Index=73, start=892.7914328108309, stop=893.0406947631855, label=120, duration=0.2492619523545727, end=893.0406947631855, score=0.20476951771973365, velocity=1430.7198309151463, intercept=1277583.9708550184, speed=1430.7198309151463, wcorr=-0.08378323647548795, P_decoder=0.30188706705826523, pearsonr=-0.9040126214832481, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=236.726623932831, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([27, 43, 35, 32, 46, 23, 44, 19, 45, 24,  7, 20, 31, 37, 18]), n_unique_aclus=15)\n",
      "an_epoch: EpochTuple(Index=73, start=892.7914328108309, stop=893.0406947631855, label=120, duration=0.2492619523545727, end=893.0406947631855, score=0.20476951771973365, velocity=1430.7198309151463, intercept=1277583.9708550184, speed=1430.7198309151463, wcorr=-0.08378323647548795, P_decoder=0.30188706705826523, pearsonr=-0.9040126214832481, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=236.726623932831, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([27, 43, 35, 32, 46, 23, 44, 19, 45, 24,  7, 20, 31, 37, 18]), n_unique_aclus=15)\n",
      "an_epoch: EpochTuple(Index=73, start=892.7914328108309, stop=893.0406947631855, label=120, duration=0.2492619523545727, end=893.0406947631855, score=0.20476951771973365, velocity=1430.7198309151463, intercept=1277583.9708550184, speed=1430.7198309151463, wcorr=-0.08378323647548795, P_decoder=0.30188706705826523, pearsonr=-0.9040126214832481, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=236.726623932831, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([27, 43, 35, 32, 46, 23, 44, 19, 45, 24,  7, 20, 31, 37, 18]), n_unique_aclus=15)\n",
      "an_epoch: EpochTuple(Index=73, start=892.7914328108309, stop=893.0406947631855, label=120, duration=0.2492619523545727, end=893.0406947631855, score=0.20476951771973365, velocity=1430.7198309151463, intercept=1277583.9708550184, speed=1430.7198309151463, wcorr=-0.08378323647548795, P_decoder=0.30188706705826523, pearsonr=-0.9040126214832481, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=236.726623932831, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([27, 43, 35, 32, 46, 23, 44, 19, 45, 24,  7, 20, 31, 37, 18]), n_unique_aclus=15)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (14, 59), np.nanmax(curr_data): 0.1306753907929282, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 14\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.13918661674691393, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (14, 59), np.nanmax(curr_data): 0.1490508567103094, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 14\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_120\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_120\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_120\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_120\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[96][\"p_x_given_n\"]): (59, 4, 10)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.283819 0 0.716181 0]\n",
      "\t_long_any: 0.7161809221228872, _short_any: 0.2838190778771126\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [8.46035e-06 0 0.999992 0]\n",
      "\t_long_any: 0.9999915396491794, _short_any: 8.460350820847916e-06\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.723016 0 0.276984 0]\n",
      "\t_long_any: 0.2769842799648543, _short_any: 0.7230157200351457\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.599249 0 0.400751 0]\n",
      "\t_long_any: 0.40075055023915745, _short_any: 0.5992494497608435\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.943648 0 0.0563523 0]\n",
      "\t_long_any: 0.056352310544496534, _short_any: 0.9436476894555035\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.10908 0.115552 0.157043 0.618326]\n",
      "\t_long_any: 0.7753683204822507, _short_any: 0.22463167951774907\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.232907 0.384556 0.093214 0.289323]\n",
      "\t_long_any: 0.3825366033098493, _short_any: 0.6174633966901505\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0448665 0.259589 0.0771371 0.618407]\n",
      "\t_long_any: 0.6955443884119944, _short_any: 0.30445561158800555\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_120/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_120'\n",
      "processing an_epoch_idx: 74/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 74)\n",
      "an_epoch: EpochTuple(Index=74, start=906.0226529163774, stop=906.2466016017133, label=121, duration=0.2239486853359267, end=906.2466016017133, score=0.2844310353527346, velocity=292.6472381416236, intercept=265214.53078878333, speed=292.6472381416236, wcorr=0.5034709792640022, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=249.95784403837752, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([17, 40, 20,  7, 45, 24, 14,  4, 11]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=74, start=906.0226529163774, stop=906.2466016017133, label=121, duration=0.2239486853359267, end=906.2466016017133, score=0.2844310353527346, velocity=292.6472381416236, intercept=265214.53078878333, speed=292.6472381416236, wcorr=0.5034709792640022, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=249.95784403837752, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([17, 40, 20,  7, 45, 24, 14,  4, 11]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=74, start=906.0226529163774, stop=906.2466016017133, label=121, duration=0.2239486853359267, end=906.2466016017133, score=0.2844310353527346, velocity=292.6472381416236, intercept=265214.53078878333, speed=292.6472381416236, wcorr=0.5034709792640022, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=249.95784403837752, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([17, 40, 20,  7, 45, 24, 14,  4, 11]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=74, start=906.0226529163774, stop=906.2466016017133, label=121, duration=0.2239486853359267, end=906.2466016017133, score=0.2844310353527346, velocity=292.6472381416236, intercept=265214.53078878333, speed=292.6472381416236, wcorr=0.5034709792640022, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=249.95784403837752, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([17, 40, 20,  7, 45, 24, 14,  4, 11]), n_unique_aclus=9)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.10832426379331009, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (5, 59), np.nanmax(curr_data): 0.14646292062398014, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 5\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.14773746413841815, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (5, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 5\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_121\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_121\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_121\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_121\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[97][\"p_x_given_n\"]): (59, 4, 9)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.993646 0 0.00635369 0]\n",
      "\t_long_any: 0.006353687364140872, _short_any: 0.9936463126358602\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.997289 0 0.00271084 0]\n",
      "\t_long_any: 0.002710835140108464, _short_any: 0.9972891648598914\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.998476 0 0.00152358 0]\n",
      "\t_long_any: 0.0015235795076592577, _short_any: 0.9984764204923411\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.669596 0 0.330404 0]\n",
      "\t_long_any: 0.3304038949084531, _short_any: 0.669596105091547\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.974683 0 0.0253175]\n",
      "\t_long_any: 0.025317499807701625, _short_any: 0.974682500192299\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_121/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_121'\n",
      "processing an_epoch_idx: 75/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 75)\n",
      "an_epoch: EpochTuple(Index=75, start=926.7004279292887, stop=926.8782659183489, label=126, duration=0.1778379890602082, end=926.8782659183489, score=0.24484810205528498, velocity=111.4846621492443, intercept=103380.12330811562, speed=111.4846621492443, wcorr=-0.48243952649823124, P_decoder=0.4894953681383925, pearsonr=0.7550714773247188, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=270.6356190512888, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([40, 11,  5, 52,  9, 14, 21, 19, 27, 45,  7, 20, 24]), n_unique_aclus=13)\n",
      "an_epoch: EpochTuple(Index=75, start=926.7004279292887, stop=926.8782659183489, label=126, duration=0.1778379890602082, end=926.8782659183489, score=0.24484810205528498, velocity=111.4846621492443, intercept=103380.12330811562, speed=111.4846621492443, wcorr=-0.48243952649823124, P_decoder=0.4894953681383925, pearsonr=0.7550714773247188, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=270.6356190512888, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([40, 11,  5, 52,  9, 14, 21, 19, 27, 45,  7, 20, 24]), n_unique_aclus=13)\n",
      "an_epoch: EpochTuple(Index=75, start=926.7004279292887, stop=926.8782659183489, label=126, duration=0.1778379890602082, end=926.8782659183489, score=0.24484810205528498, velocity=111.4846621492443, intercept=103380.12330811562, speed=111.4846621492443, wcorr=-0.48243952649823124, P_decoder=0.4894953681383925, pearsonr=0.7550714773247188, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=270.6356190512888, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([40, 11,  5, 52,  9, 14, 21, 19, 27, 45,  7, 20, 24]), n_unique_aclus=13)\n",
      "an_epoch: EpochTuple(Index=75, start=926.7004279292887, stop=926.8782659183489, label=126, duration=0.1778379890602082, end=926.8782659183489, score=0.24484810205528498, velocity=111.4846621492443, intercept=103380.12330811562, speed=111.4846621492443, wcorr=-0.48243952649823124, P_decoder=0.4894953681383925, pearsonr=0.7550714773247188, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=270.6356190512888, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([40, 11,  5, 52,  9, 14, 21, 19, 27, 45,  7, 20, 24]), n_unique_aclus=13)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (10, 59), np.nanmax(curr_data): 0.10832426379331009, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 10\n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.14646292062398014, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (10, 59), np.nanmax(curr_data): 0.14773746413841815, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 10\n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_126\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_126\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_126\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_126\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[100][\"p_x_given_n\"]): (59, 4, 8)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.236026 0 0.763974]\n",
      "\t_long_any: 0.7639744083340275, _short_any: 0.2360255916659723\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.401826 0.222795 0.0835336 0.291845]\n",
      "\t_long_any: 0.3753785335947758, _short_any: 0.6246214664052238\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.911764 0 0.088236]\n",
      "\t_long_any: 0.08823598063688119, _short_any: 0.9117640193631182\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.494651 0 0.505349 0]\n",
      "\t_long_any: 0.5053486303779042, _short_any: 0.4946513696220966\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.700846 0 0.299154 0]\n",
      "\t_long_any: 0.29915350997303825, _short_any: 0.7008464900269615\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.981706 0 0.0182938 0]\n",
      "\t_long_any: 0.01829380597747933, _short_any: 0.9817061940225211\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.912717 0 0.0872834 0]\n",
      "\t_long_any: 0.0872833558007367, _short_any: 0.9127166441992626\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.848817 0 0.151183 0]\n",
      "\t_long_any: 0.15118342160681517, _short_any: 0.8488165783931845\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_126/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_126'\n",
      "processing an_epoch_idx: 76/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 76)\n",
      "an_epoch: EpochTuple(Index=76, start=943.8075884504942, stop=943.9101010380546, label=129, duration=0.10251258756034076, end=943.9101010380546, score=0.25489502654389073, velocity=877.9417144248707, intercept=828850.705626389, speed=877.9417144248707, wcorr=-0.241825041076032, P_decoder=nan, pearsonr=0.4328009425432272, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=287.7427795724943, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([43, 41, 31, 19, 10, 16, 37, 17, 39]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=76, start=943.8075884504942, stop=943.9101010380546, label=129, duration=0.10251258756034076, end=943.9101010380546, score=0.25489502654389073, velocity=877.9417144248707, intercept=828850.705626389, speed=877.9417144248707, wcorr=-0.241825041076032, P_decoder=nan, pearsonr=0.4328009425432272, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=287.7427795724943, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([43, 41, 31, 19, 10, 16, 37, 17, 39]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=76, start=943.8075884504942, stop=943.9101010380546, label=129, duration=0.10251258756034076, end=943.9101010380546, score=0.25489502654389073, velocity=877.9417144248707, intercept=828850.705626389, speed=877.9417144248707, wcorr=-0.241825041076032, P_decoder=nan, pearsonr=0.4328009425432272, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=287.7427795724943, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([43, 41, 31, 19, 10, 16, 37, 17, 39]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=76, start=943.8075884504942, stop=943.9101010380546, label=129, duration=0.10251258756034076, end=943.9101010380546, score=0.25489502654389073, velocity=877.9417144248707, intercept=828850.705626389, speed=877.9417144248707, wcorr=-0.241825041076032, P_decoder=nan, pearsonr=0.4328009425432272, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=287.7427795724943, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([43, 41, 31, 19, 10, 16, 37, 17, 39]), n_unique_aclus=9)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (5, 59), np.nanmax(curr_data): 0.10599566525773634, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 5\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.11320361908745265, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (5, 59), np.nanmax(curr_data): 0.1490508567103094, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 5\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.11861882803387439, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_129\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_129\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_129\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_129\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[102][\"p_x_given_n\"]): (59, 4, 5)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.420461 0 0.579539 0]\n",
      "\t_long_any: 0.5795385759060405, _short_any: 0.42046142409395937\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.000722238 0.901785 0.000161307 0.0973312]\n",
      "\t_long_any: 0.09749248984114864, _short_any: 0.9025075101588511\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.426219 0 0.573781]\n",
      "\t_long_any: 0.5737809922851259, _short_any: 0.42621900771487436\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0869381 0.768053 0.0520664 0.0929422]\n",
      "\t_long_any: 0.14500860282222938, _short_any: 0.8549913971777701\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_129/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_129'\n",
      "processing an_epoch_idx: 77/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 77)\n",
      "an_epoch: EpochTuple(Index=77, start=946.198432666366, stop=946.3541215466103, label=130, duration=0.15568888024426997, end=946.3541215466103, score=0.285239548152044, velocity=-32.516359793526135, intercept=-30525.901155680596, speed=32.516359793526135, wcorr=-0.6709006354769963, P_decoder=nan, pearsonr=0.3584506259947783, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=290.1336237883661, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([43, 26, 31, 18, 37, 50, 25,  5, 27, 49, 52, 53, 20]), n_unique_aclus=13)\n",
      "an_epoch: EpochTuple(Index=77, start=946.198432666366, stop=946.3541215466103, label=130, duration=0.15568888024426997, end=946.3541215466103, score=0.285239548152044, velocity=-32.516359793526135, intercept=-30525.901155680596, speed=32.516359793526135, wcorr=-0.6709006354769963, P_decoder=nan, pearsonr=0.3584506259947783, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=290.1336237883661, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([43, 26, 31, 18, 37, 50, 25,  5, 27, 49, 52, 53, 20]), n_unique_aclus=13)\n",
      "an_epoch: EpochTuple(Index=77, start=946.198432666366, stop=946.3541215466103, label=130, duration=0.15568888024426997, end=946.3541215466103, score=0.285239548152044, velocity=-32.516359793526135, intercept=-30525.901155680596, speed=32.516359793526135, wcorr=-0.6709006354769963, P_decoder=nan, pearsonr=0.3584506259947783, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=290.1336237883661, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([43, 26, 31, 18, 37, 50, 25,  5, 27, 49, 52, 53, 20]), n_unique_aclus=13)\n",
      "an_epoch: EpochTuple(Index=77, start=946.198432666366, stop=946.3541215466103, label=130, duration=0.15568888024426997, end=946.3541215466103, score=0.285239548152044, velocity=-32.516359793526135, intercept=-30525.901155680596, speed=32.516359793526135, wcorr=-0.6709006354769963, P_decoder=nan, pearsonr=0.3584506259947783, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=290.1336237883661, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([43, 26, 31, 18, 37, 50, 25,  5, 27, 49, 52, 53, 20]), n_unique_aclus=13)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (11, 59), np.nanmax(curr_data): 0.16871442757882205, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 11\n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (11, 59), np.nanmax(curr_data): 0.17673647253127112, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 11\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_130\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_130\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_130\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_130\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[103][\"p_x_given_n\"]): (59, 4, 7)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.428119 0 0.571881 0]\n",
      "\t_long_any: 0.5718810256354682, _short_any: 0.42811897436453167\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [2.56565e-05 0.643858 0.000619782 0.355497]\n",
      "\t_long_any: 0.3561166534889715, _short_any: 0.6438833465110286\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.0913671 0 0.908633]\n",
      "\t_long_any: 0.9086328777033735, _short_any: 0.09136712229662688\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.872224 0 0.127776]\n",
      "\t_long_any: 0.12777630302494555, _short_any: 0.8722236969750543\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.896813 0 0.103187]\n",
      "\t_long_any: 0.10318699590439508, _short_any: 0.8968130040956047\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.15016 0.554904 0.0462999 0.248636]\n",
      "\t_long_any: 0.29493631842043955, _short_any: 0.7050636815795602\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_130/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_130'\n",
      "processing an_epoch_idx: 78/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 78)\n",
      "an_epoch: EpochTuple(Index=78, start=947.2814042719547, stop=947.4077555672266, label=131, duration=0.12635129527188838, end=947.4077555672266, score=0.3035084315633069, velocity=390.1963175222535, intercept=369720.82595662185, speed=390.1963175222535, wcorr=-0.8231357148830618, P_decoder=0.6000654630240123, pearsonr=0.6576185433767427, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=291.2165953939548, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([41, 35,  5, 19, 18, 40,  7, 20, 45]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=78, start=947.2814042719547, stop=947.4077555672266, label=131, duration=0.12635129527188838, end=947.4077555672266, score=0.3035084315633069, velocity=390.1963175222535, intercept=369720.82595662185, speed=390.1963175222535, wcorr=-0.8231357148830618, P_decoder=0.6000654630240123, pearsonr=0.6576185433767427, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=291.2165953939548, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([41, 35,  5, 19, 18, 40,  7, 20, 45]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=78, start=947.2814042719547, stop=947.4077555672266, label=131, duration=0.12635129527188838, end=947.4077555672266, score=0.3035084315633069, velocity=390.1963175222535, intercept=369720.82595662185, speed=390.1963175222535, wcorr=-0.8231357148830618, P_decoder=0.6000654630240123, pearsonr=0.6576185433767427, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=291.2165953939548, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([41, 35,  5, 19, 18, 40,  7, 20, 45]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=78, start=947.2814042719547, stop=947.4077555672266, label=131, duration=0.12635129527188838, end=947.4077555672266, score=0.3035084315633069, velocity=390.1963175222535, intercept=369720.82595662185, speed=390.1963175222535, wcorr=-0.8231357148830618, P_decoder=0.6000654630240123, pearsonr=0.6576185433767427, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=291.2165953939548, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([41, 35,  5, 19, 18, 40,  7, 20, 45]), n_unique_aclus=9)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.10832426379331009, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.13918661674691393, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.14773746413841815, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_131\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_131\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_131\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_131\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[104][\"p_x_given_n\"]): (59, 4, 6)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0506487 0.000884536 0.536066 0.4124]\n",
      "\t_long_any: 0.9484667510750833, _short_any: 0.0515332489249174\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.401406 0 0.598594 0]\n",
      "\t_long_any: 0.5985944591588943, _short_any: 0.40140554084110597\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.687045 0.223075 0.0128872 0.0769925]\n",
      "\t_long_any: 0.08987967879420958, _short_any: 0.9101203212057905\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.97045 0 0.0295501 0]\n",
      "\t_long_any: 0.029550132627550164, _short_any: 0.9704498673724501\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.992979 0 0.00702118 0]\n",
      "\t_long_any: 0.007021175206340807, _short_any: 0.9929788247936582\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.759723 0 0.240277 0]\n",
      "\t_long_any: 0.24027699762626764, _short_any: 0.7597230023737327\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_131/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_131'\n",
      "processing an_epoch_idx: 79/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 79)\n",
      "an_epoch: EpochTuple(Index=79, start=948.659963565995, stop=948.7617695940426, label=133, duration=0.10180602804757655, end=948.7617695940426, score=0.5317456752851528, velocity=97.54907938054116, intercept=92788.4368799687, speed=97.54907938054116, wcorr=-0.02813780196870096, P_decoder=0.13031473015867925, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=292.5951546879951, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 9, 31, 26, 18, 37, 50,  2, 19, 43]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=79, start=948.659963565995, stop=948.7617695940426, label=133, duration=0.10180602804757655, end=948.7617695940426, score=0.5317456752851528, velocity=97.54907938054116, intercept=92788.4368799687, speed=97.54907938054116, wcorr=-0.02813780196870096, P_decoder=0.13031473015867925, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=292.5951546879951, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 9, 31, 26, 18, 37, 50,  2, 19, 43]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=79, start=948.659963565995, stop=948.7617695940426, label=133, duration=0.10180602804757655, end=948.7617695940426, score=0.5317456752851528, velocity=97.54907938054116, intercept=92788.4368799687, speed=97.54907938054116, wcorr=-0.02813780196870096, P_decoder=0.13031473015867925, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=292.5951546879951, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 9, 31, 26, 18, 37, 50,  2, 19, 43]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=79, start=948.659963565995, stop=948.7617695940426, label=133, duration=0.10180602804757655, end=948.7617695940426, score=0.5317456752851528, velocity=97.54907938054116, intercept=92788.4368799687, speed=97.54907938054116, wcorr=-0.02813780196870096, P_decoder=0.13031473015867925, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=292.5951546879951, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 9, 31, 26, 18, 37, 50,  2, 19, 43]), n_unique_aclus=9)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.14933925445043028, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.18913760071074082, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_133\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_133\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_133\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_133\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[105][\"p_x_given_n\"]): (59, 4, 5)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.00216796 0.0500948 0.00547845 0.942259]\n",
      "\t_long_any: 0.947737269586754, _short_any: 0.0522627304132457\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.000431017 0.106367 0.00366072 0.889541]\n",
      "\t_long_any: 0.8932018403495728, _short_any: 0.10679815965042706\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.362943 0.354347 0.0563191 0.226391]\n",
      "\t_long_any: 0.2827097994654639, _short_any: 0.7172902005345367\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.131692 0 0.868308 0]\n",
      "\t_long_any: 0.8683079047779072, _short_any: 0.13169209522209258\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.332092 0 0.667908 0]\n",
      "\t_long_any: 0.6679082064751289, _short_any: 0.33209179352487067\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_133/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_133'\n",
      "processing an_epoch_idx: 80/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 80)\n",
      "an_epoch: EpochTuple(Index=80, start=958.0087306194473, stop=958.4327892824076, label=135, duration=0.4240586629603058, end=958.4327892824076, score=0.17957827395858933, velocity=-36.58090476771335, intercept=-34984.315228124695, speed=36.58090476771335, wcorr=-0.0018953851837567902, P_decoder=0.47471297538127166, pearsonr=0.5002590399972703, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=301.9439217414474, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([20, 40, 24,  2, 10,  7, 45, 19, 32, 18, 21, 27]), n_unique_aclus=12)\n",
      "an_epoch: EpochTuple(Index=80, start=958.0087306194473, stop=958.4327892824076, label=135, duration=0.4240586629603058, end=958.4327892824076, score=0.17957827395858933, velocity=-36.58090476771335, intercept=-34984.315228124695, speed=36.58090476771335, wcorr=-0.0018953851837567902, P_decoder=0.47471297538127166, pearsonr=0.5002590399972703, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=301.9439217414474, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([20, 40, 24,  2, 10,  7, 45, 19, 32, 18, 21, 27]), n_unique_aclus=12)\n",
      "an_epoch: EpochTuple(Index=80, start=958.0087306194473, stop=958.4327892824076, label=135, duration=0.4240586629603058, end=958.4327892824076, score=0.17957827395858933, velocity=-36.58090476771335, intercept=-34984.315228124695, speed=36.58090476771335, wcorr=-0.0018953851837567902, P_decoder=0.47471297538127166, pearsonr=0.5002590399972703, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=301.9439217414474, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([20, 40, 24,  2, 10,  7, 45, 19, 32, 18, 21, 27]), n_unique_aclus=12)\n",
      "an_epoch: EpochTuple(Index=80, start=958.0087306194473, stop=958.4327892824076, label=135, duration=0.4240586629603058, end=958.4327892824076, score=0.17957827395858933, velocity=-36.58090476771335, intercept=-34984.315228124695, speed=36.58090476771335, wcorr=-0.0018953851837567902, P_decoder=0.47471297538127166, pearsonr=0.5002590399972703, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=301.9439217414474, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([20, 40, 24,  2, 10,  7, 45, 19, 32, 18, 21, 27]), n_unique_aclus=12)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (11, 59), np.nanmax(curr_data): 0.13026806747808126, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 11\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.13918661674691393, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (11, 59), np.nanmax(curr_data): 0.14773746413841815, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 11\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.18913760071074082, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_135\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_135\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_135\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_135\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[106][\"p_x_given_n\"]): (59, 4, 17)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.984457 0 0.0155427 0]\n",
      "\t_long_any: 0.015542686301889515, _short_any: 0.9844573136981101\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.489634 0 0.510366 0]\n",
      "\t_long_any: 0.5103664151631802, _short_any: 0.48963358483681974\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.999307 0 0.000693209 0]\n",
      "\t_long_any: 0.0006932089459834174, _short_any: 0.9993067910540164\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.511635 0.301654 0.00919815 0.177513]\n",
      "\t_long_any: 0.1867114846394517, _short_any: 0.8132885153605478\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.646306 0.121921 0.0424546 0.189318]\n",
      "\t_long_any: 0.23177249962483015, _short_any: 0.7682275003751705\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.3885 0.225026 0.137701 0.248773]\n",
      "\t_long_any: 0.38647475361597433, _short_any: 0.6135252463840257\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.646306 0.121921 0.0424546 0.189318]\n",
      "\t_long_any: 0.23177249962483015, _short_any: 0.7682275003751705\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.759723 0 0.240277 0]\n",
      "\t_long_any: 0.24027699762626764, _short_any: 0.7597230023737327\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.986033 0 0.0139669 0]\n",
      "\t_long_any: 0.013966859730159091, _short_any: 0.9860331402698415\n",
      "i: 10, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0529158 0 0.947084 0]\n",
      "\t_long_any: 0.9470841577028124, _short_any: 0.05291584229718779\n",
      "i: 11, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.433296 0.215056 0.27909 0.0725591]\n",
      "\t_long_any: 0.3516485729942037, _short_any: 0.6483514270057958\n",
      "i: 12, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 13, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.3885 0.225026 0.137701 0.248773]\n",
      "\t_long_any: 0.38647475361597433, _short_any: 0.6135252463840257\n",
      "i: 14, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.3885 0.225026 0.137701 0.248773]\n",
      "\t_long_any: 0.38647475361597433, _short_any: 0.6135252463840257\n",
      "i: 15, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 16, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.489634 0 0.510366 0]\n",
      "\t_long_any: 0.5103664151631802, _short_any: 0.48963358483681974\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_135/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_135'\n",
      "processing an_epoch_idx: 81/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 81)\n",
      "an_epoch: EpochTuple(Index=81, start=972.7584702676395, stop=972.8738852485549, label=136, duration=0.11541498091537505, end=972.8738852485549, score=0.343333616470374, velocity=438.97085721243536, intercept=427103.46213421616, speed=438.97085721243536, wcorr=-0.743304018411705, P_decoder=0.6558565028733954, pearsonr=-0.13210900184590535, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=316.6936613896396, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([14,  9, 21, 19, 18,  7, 20, 45]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=81, start=972.7584702676395, stop=972.8738852485549, label=136, duration=0.11541498091537505, end=972.8738852485549, score=0.343333616470374, velocity=438.97085721243536, intercept=427103.46213421616, speed=438.97085721243536, wcorr=-0.743304018411705, P_decoder=0.6558565028733954, pearsonr=-0.13210900184590535, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=316.6936613896396, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([14,  9, 21, 19, 18,  7, 20, 45]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=81, start=972.7584702676395, stop=972.8738852485549, label=136, duration=0.11541498091537505, end=972.8738852485549, score=0.343333616470374, velocity=438.97085721243536, intercept=427103.46213421616, speed=438.97085721243536, wcorr=-0.743304018411705, P_decoder=0.6558565028733954, pearsonr=-0.13210900184590535, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=316.6936613896396, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([14,  9, 21, 19, 18,  7, 20, 45]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=81, start=972.7584702676395, stop=972.8738852485549, label=136, duration=0.11541498091537505, end=972.8738852485549, score=0.343333616470374, velocity=438.97085721243536, intercept=427103.46213421616, speed=438.97085721243536, wcorr=-0.743304018411705, P_decoder=0.6558565028733954, pearsonr=-0.13210900184590535, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=316.6936613896396, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([14,  9, 21, 19, 18,  7, 20, 45]), n_unique_aclus=8)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.10832426379331009, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (5, 59), np.nanmax(curr_data): 0.14646292062398014, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 5\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.14773746413841815, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (5, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 5\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_136\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_136\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_136\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_136\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[107][\"p_x_given_n\"]): (59, 4, 5)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.875051 0 0.124949]\n",
      "\t_long_any: 0.12494862703729404, _short_any: 0.8750513729627061\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.401406 0 0.598594 0]\n",
      "\t_long_any: 0.5985944591588943, _short_any: 0.40140554084110597\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.99987 0 0.00013009 0]\n",
      "\t_long_any: 0.0001300903785754204, _short_any: 0.9998699096214242\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.999727 0 0.000272617 0]\n",
      "\t_long_any: 0.0002726168162374067, _short_any: 0.9997273831837624\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.823049 0 0.176951 0]\n",
      "\t_long_any: 0.17695106365027896, _short_any: 0.8230489363497209\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_136/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_136'\n",
      "processing an_epoch_idx: 82/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 82)\n",
      "an_epoch: EpochTuple(Index=82, start=988.8634220219683, stop=988.9881451580441, label=137, duration=0.12472313607577235, end=988.9881451580441, score=0.4344008568563497, velocity=341.4217778318942, intercept=337704.25334238296, speed=341.4217778318942, wcorr=-0.5518959834261157, P_decoder=nan, pearsonr=-0.6227540097635518, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=332.7986131439684, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([14,  7, 52, 21,  9, 40, 19, 44, 17, 20, 11, 45, 24]), n_unique_aclus=13)\n",
      "an_epoch: EpochTuple(Index=82, start=988.8634220219683, stop=988.9881451580441, label=137, duration=0.12472313607577235, end=988.9881451580441, score=0.4344008568563497, velocity=341.4217778318942, intercept=337704.25334238296, speed=341.4217778318942, wcorr=-0.5518959834261157, P_decoder=nan, pearsonr=-0.6227540097635518, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=332.7986131439684, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([14,  7, 52, 21,  9, 40, 19, 44, 17, 20, 11, 45, 24]), n_unique_aclus=13)\n",
      "an_epoch: EpochTuple(Index=82, start=988.8634220219683, stop=988.9881451580441, label=137, duration=0.12472313607577235, end=988.9881451580441, score=0.4344008568563497, velocity=341.4217778318942, intercept=337704.25334238296, speed=341.4217778318942, wcorr=-0.5518959834261157, P_decoder=nan, pearsonr=-0.6227540097635518, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=332.7986131439684, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([14,  7, 52, 21,  9, 40, 19, 44, 17, 20, 11, 45, 24]), n_unique_aclus=13)\n",
      "an_epoch: EpochTuple(Index=82, start=988.8634220219683, stop=988.9881451580441, label=137, duration=0.12472313607577235, end=988.9881451580441, score=0.4344008568563497, velocity=341.4217778318942, intercept=337704.25334238296, speed=341.4217778318942, wcorr=-0.5518959834261157, P_decoder=nan, pearsonr=-0.6227540097635518, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=332.7986131439684, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([14,  7, 52, 21,  9, 40, 19, 44, 17, 20, 11, 45, 24]), n_unique_aclus=13)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.1146338264762386, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.14646292062398014, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.14773746413841815, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_137\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_137\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_137\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_137\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[108][\"p_x_given_n\"]): (59, 4, 5)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.63346 0 0.36654 0]\n",
      "\t_long_any: 0.3665402461102961, _short_any: 0.6334597538897033\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.994691 0 0.00530877 0]\n",
      "\t_long_any: 0.005308773939366188, _short_any: 0.994691226060634\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.753656 0 0.246344 0]\n",
      "\t_long_any: 0.24634391070155842, _short_any: 0.7536560892984414\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_137/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_137'\n",
      "processing an_epoch_idx: 83/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 83)\n",
      "an_epoch: EpochTuple(Index=83, start=1006.6929322531214, stop=1006.8285917036701, label=139, duration=0.135659450548701, end=1006.8285917036701, score=0.3419060527232359, velocity=-468.23558102670404, intercept=-471182.6435620029, speed=468.23558102670404, wcorr=0.32701823654564005, P_decoder=0.013468147471777592, pearsonr=-0.09811581515364096, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=350.6281233751215, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([10, 17, 37, 16, 27, 41, 39, 52, 49, 18, 31, 26, 50, 25]), n_unique_aclus=14)\n",
      "an_epoch: EpochTuple(Index=83, start=1006.6929322531214, stop=1006.8285917036701, label=139, duration=0.135659450548701, end=1006.8285917036701, score=0.3419060527232359, velocity=-468.23558102670404, intercept=-471182.6435620029, speed=468.23558102670404, wcorr=0.32701823654564005, P_decoder=0.013468147471777592, pearsonr=-0.09811581515364096, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=350.6281233751215, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([10, 17, 37, 16, 27, 41, 39, 52, 49, 18, 31, 26, 50, 25]), n_unique_aclus=14)\n",
      "an_epoch: EpochTuple(Index=83, start=1006.6929322531214, stop=1006.8285917036701, label=139, duration=0.135659450548701, end=1006.8285917036701, score=0.3419060527232359, velocity=-468.23558102670404, intercept=-471182.6435620029, speed=468.23558102670404, wcorr=0.32701823654564005, P_decoder=0.013468147471777592, pearsonr=-0.09811581515364096, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=350.6281233751215, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([10, 17, 37, 16, 27, 41, 39, 52, 49, 18, 31, 26, 50, 25]), n_unique_aclus=14)\n",
      "an_epoch: EpochTuple(Index=83, start=1006.6929322531214, stop=1006.8285917036701, label=139, duration=0.135659450548701, end=1006.8285917036701, score=0.3419060527232359, velocity=-468.23558102670404, intercept=-471182.6435620029, speed=468.23558102670404, wcorr=0.32701823654564005, P_decoder=0.013468147471777592, pearsonr=-0.09811581515364096, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=350.6281233751215, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([10, 17, 37, 16, 27, 41, 39, 52, 49, 18, 31, 26, 50, 25]), n_unique_aclus=14)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (14, 59), np.nanmax(curr_data): 0.16871442757882205, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 14\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (14, 59), np.nanmax(curr_data): 0.16771957548724484, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 14\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_139\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_139\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_139\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_139\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[109][\"p_x_given_n\"]): (59, 4, 6)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.421182 0 0.578818]\n",
      "\t_long_any: 0.5788177280172188, _short_any: 0.42118227198278146\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.850023 0 0.149977]\n",
      "\t_long_any: 0.1499765329201707, _short_any: 0.8500234670798297\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0869381 0.768053 0.0520664 0.0929422]\n",
      "\t_long_any: 0.14500860282222938, _short_any: 0.8549913971777701\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.966651 0 0.0333494]\n",
      "\t_long_any: 0.03334941945705325, _short_any: 0.9666505805429473\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.188656 0 0.811344]\n",
      "\t_long_any: 0.8113438035254421, _short_any: 0.18865619647455772\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.000431017 0.106367 0.00366072 0.889541]\n",
      "\t_long_any: 0.8932018403495728, _short_any: 0.10679815965042706\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_139/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_139'\n",
      "processing an_epoch_idx: 84/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 84)\n",
      "an_epoch: EpochTuple(Index=84, start=1010.1174117799383, stop=1010.202997655957, label=141, duration=0.08558587601874024, end=1010.202997655957, score=0.20042352789661777, velocity=-715.359915457031, intercept=-722511.3379391189, speed=715.359915457031, wcorr=-0.13007603520053998, P_decoder=nan, pearsonr=-0.43382272267708405, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=354.05260290193837, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([20, 44, 27, 31, 15, 49, 45, 37,  9, 39]), n_unique_aclus=10)\n",
      "an_epoch: EpochTuple(Index=84, start=1010.1174117799383, stop=1010.202997655957, label=141, duration=0.08558587601874024, end=1010.202997655957, score=0.20042352789661777, velocity=-715.359915457031, intercept=-722511.3379391189, speed=715.359915457031, wcorr=-0.13007603520053998, P_decoder=nan, pearsonr=-0.43382272267708405, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=354.05260290193837, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([20, 44, 27, 31, 15, 49, 45, 37,  9, 39]), n_unique_aclus=10)\n",
      "an_epoch: EpochTuple(Index=84, start=1010.1174117799383, stop=1010.202997655957, label=141, duration=0.08558587601874024, end=1010.202997655957, score=0.20042352789661777, velocity=-715.359915457031, intercept=-722511.3379391189, speed=715.359915457031, wcorr=-0.13007603520053998, P_decoder=nan, pearsonr=-0.43382272267708405, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=354.05260290193837, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([20, 44, 27, 31, 15, 49, 45, 37,  9, 39]), n_unique_aclus=10)\n",
      "an_epoch: EpochTuple(Index=84, start=1010.1174117799383, stop=1010.202997655957, label=141, duration=0.08558587601874024, end=1010.202997655957, score=0.20042352789661777, velocity=-715.359915457031, intercept=-722511.3379391189, speed=715.359915457031, wcorr=-0.13007603520053998, P_decoder=nan, pearsonr=-0.43382272267708405, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=354.05260290193837, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([20, 44, 27, 31, 15, 49, 45, 37,  9, 39]), n_unique_aclus=10)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.1259578889736905, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.13918661674691393, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.12437427480726816, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_141\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_141\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_141\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_141\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[111][\"p_x_given_n\"]): (59, 4, 4)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0126544 0 0.987346 0]\n",
      "\t_long_any: 0.987345602450025, _short_any: 0.012654397549974779\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.534064 0.220417 0.211403 0.0341159]\n",
      "\t_long_any: 0.24551919285719292, _short_any: 0.7544808071428077\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.567057 0 0.432943]\n",
      "\t_long_any: 0.4329430782899852, _short_any: 0.5670569217100145\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_141/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_141'\n",
      "processing an_epoch_idx: 85/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 85)\n",
      "an_epoch: EpochTuple(Index=85, start=1011.1691718813963, stop=1011.2511635194533, label=142, duration=0.08199163805693388, end=1011.2511635194533, score=0.3289251066685124, velocity=65.03271958700299, intercept=65996.45063647759, speed=65.03271958700299, wcorr=-0.7554480551794969, P_decoder=0.1461864879988558, pearsonr=0.11019966940245088, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=355.10436300339643, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([43, 35, 32, 46, 31, 41, 10, 39, 52]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=85, start=1011.1691718813963, stop=1011.2511635194533, label=142, duration=0.08199163805693388, end=1011.2511635194533, score=0.3289251066685124, velocity=65.03271958700299, intercept=65996.45063647759, speed=65.03271958700299, wcorr=-0.7554480551794969, P_decoder=0.1461864879988558, pearsonr=0.11019966940245088, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=355.10436300339643, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([43, 35, 32, 46, 31, 41, 10, 39, 52]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=85, start=1011.1691718813963, stop=1011.2511635194533, label=142, duration=0.08199163805693388, end=1011.2511635194533, score=0.3289251066685124, velocity=65.03271958700299, intercept=65996.45063647759, speed=65.03271958700299, wcorr=-0.7554480551794969, P_decoder=0.1461864879988558, pearsonr=0.11019966940245088, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=355.10436300339643, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([43, 35, 32, 46, 31, 41, 10, 39, 52]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=85, start=1011.1691718813963, stop=1011.2511635194533, label=142, duration=0.08199163805693388, end=1011.2511635194533, score=0.3289251066685124, velocity=65.03271958700299, intercept=65996.45063647759, speed=65.03271958700299, wcorr=-0.7554480551794969, P_decoder=0.1461864879988558, pearsonr=0.11019966940245088, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=355.10436300339643, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([43, 35, 32, 46, 31, 41, 10, 39, 52]), n_unique_aclus=9)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.1306753907929282, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.11682329737370302, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (7, 59), np.nanmax(curr_data): 0.1490508567103094, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 7\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.15153529453505524, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_142\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_142\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_142\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_142\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[112][\"p_x_given_n\"]): (59, 4, 4)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0792262 0 0.920774 0]\n",
      "\t_long_any: 0.9207738006938506, _short_any: 0.0792261993061496\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0247019 0 0.975298 0]\n",
      "\t_long_any: 0.9752980675781165, _short_any: 0.024701932421883527\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.255896 0 0.744104]\n",
      "\t_long_any: 0.7441036580879402, _short_any: 0.25589634191205957\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.15016 0.554904 0.0462999 0.248636]\n",
      "\t_long_any: 0.29493631842043955, _short_any: 0.7050636815795602\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_142/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_142'\n",
      "processing an_epoch_idx: 86/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 86)\n",
      "an_epoch: EpochTuple(Index=86, start=1011.5683166369563, stop=1011.854596170364, label=143, duration=0.2862795334076509, end=1011.854596170364, score=0.17575860644317795, velocity=-124.15337375709083, intercept=-125349.73724196432, speed=124.15337375709083, wcorr=-0.3595521168283452, P_decoder=0.1924583572627196, pearsonr=0.41405911707705173, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=355.5035077589564, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([50, 31, 37,  5, 18, 32, 43, 26, 14, 52, 44, 19, 40, 20]), n_unique_aclus=14)\n",
      "an_epoch: EpochTuple(Index=86, start=1011.5683166369563, stop=1011.854596170364, label=143, duration=0.2862795334076509, end=1011.854596170364, score=0.17575860644317795, velocity=-124.15337375709083, intercept=-125349.73724196432, speed=124.15337375709083, wcorr=-0.3595521168283452, P_decoder=0.1924583572627196, pearsonr=0.41405911707705173, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=355.5035077589564, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([50, 31, 37,  5, 18, 32, 43, 26, 14, 52, 44, 19, 40, 20]), n_unique_aclus=14)\n",
      "an_epoch: EpochTuple(Index=86, start=1011.5683166369563, stop=1011.854596170364, label=143, duration=0.2862795334076509, end=1011.854596170364, score=0.17575860644317795, velocity=-124.15337375709083, intercept=-125349.73724196432, speed=124.15337375709083, wcorr=-0.3595521168283452, P_decoder=0.1924583572627196, pearsonr=0.41405911707705173, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=355.5035077589564, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([50, 31, 37,  5, 18, 32, 43, 26, 14, 52, 44, 19, 40, 20]), n_unique_aclus=14)\n",
      "an_epoch: EpochTuple(Index=86, start=1011.5683166369563, stop=1011.854596170364, label=143, duration=0.2862795334076509, end=1011.854596170364, score=0.17575860644317795, velocity=-124.15337375709083, intercept=-125349.73724196432, speed=124.15337375709083, wcorr=-0.3595521168283452, P_decoder=0.1924583572627196, pearsonr=0.41405911707705173, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=355.5035077589564, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([50, 31, 37,  5, 18, 32, 43, 26, 14, 52, 44, 19, 40, 20]), n_unique_aclus=14)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (12, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 12\n",
      "np.shape(curr_data): (10, 59), np.nanmax(curr_data): 0.14933925445043028, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 10\n",
      "np.shape(curr_data): (12, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 12\n",
      "np.shape(curr_data): (10, 59), np.nanmax(curr_data): 0.16577466995625206, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 10\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_143\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_143\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_143\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_143\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[113][\"p_x_given_n\"]): (59, 4, 12)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.00238492 0.0116631 0.0037519 0.9822]\n",
      "\t_long_any: 0.9859519675124792, _short_any: 0.01404803248752059\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [1.96467e-05 0.00112184 0.00025033 0.998608]\n",
      "\t_long_any: 0.9988585089108981, _short_any: 0.0011414910891020828\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0875703 0 0.91243 0]\n",
      "\t_long_any: 0.9124297157998461, _short_any: 0.08757028420015393\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.474477 0 0.525523]\n",
      "\t_long_any: 0.5255227183062898, _short_any: 0.47447728169371006\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.339512 0.317884 0.230561 0.112043]\n",
      "\t_long_any: 0.3426036005794879, _short_any: 0.6573963994205125\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.401406 0 0.598594 0]\n",
      "\t_long_any: 0.5985944591588943, _short_any: 0.40140554084110597\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.42596 0 0.57404 0]\n",
      "\t_long_any: 0.5740399627647155, _short_any: 0.42596003723528425\n",
      "i: 10, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 11, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.554975 0 0.445025 0]\n",
      "\t_long_any: 0.445025457995953, _short_any: 0.5549745420040473\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_143/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_143'\n",
      "processing an_epoch_idx: 87/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 87)\n",
      "an_epoch: EpochTuple(Index=87, start=1013.3905032241018, stop=1013.9849963596789, label=144, duration=0.5944931355770677, end=1013.9849963596789, score=0.13333823860077462, velocity=-59.3777004925121, intercept=-59951.61584806222, speed=59.3777004925121, wcorr=0.184252644685326, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=357.32569434610195, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([41, 35, 46, 24, 23, 21,  4, 19,  9, 27, 45,  7, 14, 40, 43, 18, 37,  5, 32, 31, 16, 25, 17, 49, 53]), n_unique_aclus=25)\n",
      "an_epoch: EpochTuple(Index=87, start=1013.3905032241018, stop=1013.9849963596789, label=144, duration=0.5944931355770677, end=1013.9849963596789, score=0.13333823860077462, velocity=-59.3777004925121, intercept=-59951.61584806222, speed=59.3777004925121, wcorr=0.184252644685326, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=357.32569434610195, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([41, 35, 46, 24, 23, 21,  4, 19,  9, 27, 45,  7, 14, 40, 43, 18, 37,  5, 32, 31, 16, 25, 17, 49, 53]), n_unique_aclus=25)\n",
      "an_epoch: EpochTuple(Index=87, start=1013.3905032241018, stop=1013.9849963596789, label=144, duration=0.5944931355770677, end=1013.9849963596789, score=0.13333823860077462, velocity=-59.3777004925121, intercept=-59951.61584806222, speed=59.3777004925121, wcorr=0.184252644685326, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=357.32569434610195, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([41, 35, 46, 24, 23, 21,  4, 19,  9, 27, 45,  7, 14, 40, 43, 18, 37,  5, 32, 31, 16, 25, 17, 49, 53]), n_unique_aclus=25)\n",
      "an_epoch: EpochTuple(Index=87, start=1013.3905032241018, stop=1013.9849963596789, label=144, duration=0.5944931355770677, end=1013.9849963596789, score=0.13333823860077462, velocity=-59.3777004925121, intercept=-59951.61584806222, speed=59.3777004925121, wcorr=0.184252644685326, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=357.32569434610195, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([41, 35, 46, 24, 23, 21,  4, 19,  9, 27, 45,  7, 14, 40, 43, 18, 37,  5, 32, 31, 16, 25, 17, 49, 53]), n_unique_aclus=25)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (17, 59), np.nanmax(curr_data): 0.1306753907929282, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 17\n",
      "np.shape(curr_data): (17, 59), np.nanmax(curr_data): 0.16871442757882205, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 17\n",
      "np.shape(curr_data): (17, 59), np.nanmax(curr_data): 0.1490508567103094, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 17\n",
      "np.shape(curr_data): (17, 59), np.nanmax(curr_data): 0.17673647253127112, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 17\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_144\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_144\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_144\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_144\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[114][\"p_x_given_n\"]): (59, 4, 24)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.00957687 0 0.990423 0]\n",
      "\t_long_any: 0.9904231319283782, _short_any: 0.009576868071621766\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0423306 0 0.957669 0]\n",
      "\t_long_any: 0.9576693909526841, _short_any: 0.042330609047315865\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.789001 0 0.210999 0]\n",
      "\t_long_any: 0.21099920302162348, _short_any: 0.7890007969783766\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.823049 0 0.176951 0]\n",
      "\t_long_any: 0.17695106365027896, _short_any: 0.8230489363497209\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.3885 0.225026 0.137701 0.248773]\n",
      "\t_long_any: 0.38647475361597433, _short_any: 0.6135252463840257\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.505606 0 0.494394 0]\n",
      "\t_long_any: 0.494393861745059, _short_any: 0.5056061382549412\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.521601 0 0.478399 0]\n",
      "\t_long_any: 0.47839944521739536, _short_any: 0.5216005547826044\n",
      "i: 10, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.505606 0 0.494394 0]\n",
      "\t_long_any: 0.494393861745059, _short_any: 0.5056061382549412\n",
      "i: 11, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.62784 0 0.37216 0]\n",
      "\t_long_any: 0.3721600032203538, _short_any: 0.6278399967796464\n",
      "i: 12, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.998878 0 0.00112235 0]\n",
      "\t_long_any: 0.001122347107174892, _short_any: 0.9988776528928256\n",
      "i: 13, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.17437 0.0405837 0.231396 0.55365]\n",
      "\t_long_any: 0.7850459216812968, _short_any: 0.2149540783187031\n",
      "i: 14, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0400818 0.0143107 0.683681 0.261926]\n",
      "\t_long_any: 0.9456074893772256, _short_any: 0.05439251062277445\n",
      "i: 15, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.0261771 0 0.973823]\n",
      "\t_long_any: 0.973822930618052, _short_any: 0.026177069381948057\n",
      "i: 16, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 2.05499e-08 0 1]\n",
      "\t_long_any: 0.9999999794500773, _short_any: 2.0549922898487602e-08\n",
      "i: 17, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0136403 0.605931 0.0135124 0.366916]\n",
      "\t_long_any: 0.38042872315064563, _short_any: 0.6195712768493545\n",
      "i: 18, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.164606 0.463534 0.158302 0.213559]\n",
      "\t_long_any: 0.3718601701333321, _short_any: 0.6281398298666679\n",
      "i: 19, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 20, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.896813 0 0.103187]\n",
      "\t_long_any: 0.10318699590439508, _short_any: 0.8968130040956047\n",
      "i: 21, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 22, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.133022 0 0.866978]\n",
      "\t_long_any: 0.8669780835120676, _short_any: 0.13302191648793268\n",
      "i: 23, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.415203 0 0.584797]\n",
      "\t_long_any: 0.5847970640941248, _short_any: 0.4152029359058755\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_144/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_144'\n",
      "processing an_epoch_idx: 88/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 88)\n",
      "an_epoch: EpochTuple(Index=88, start=1015.6968982032267, stop=1015.796584552154, label=145, duration=0.09968634892720729, end=1015.796584552154, score=0.31968793737857487, velocity=325.1635979350142, intercept=330439.9945381008, speed=325.1635979350142, wcorr=-0.8630314465586185, P_decoder=nan, pearsonr=-0.6494630370137575, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=359.63208932522684, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([35, 23, 27, 19, 44, 21, 32, 45,  7, 20, 18, 40,  9, 24, 14]), n_unique_aclus=15)\n",
      "an_epoch: EpochTuple(Index=88, start=1015.6968982032267, stop=1015.796584552154, label=145, duration=0.09968634892720729, end=1015.796584552154, score=0.31968793737857487, velocity=325.1635979350142, intercept=330439.9945381008, speed=325.1635979350142, wcorr=-0.8630314465586185, P_decoder=nan, pearsonr=-0.6494630370137575, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=359.63208932522684, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([35, 23, 27, 19, 44, 21, 32, 45,  7, 20, 18, 40,  9, 24, 14]), n_unique_aclus=15)\n",
      "an_epoch: EpochTuple(Index=88, start=1015.6968982032267, stop=1015.796584552154, label=145, duration=0.09968634892720729, end=1015.796584552154, score=0.31968793737857487, velocity=325.1635979350142, intercept=330439.9945381008, speed=325.1635979350142, wcorr=-0.8630314465586185, P_decoder=nan, pearsonr=-0.6494630370137575, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=359.63208932522684, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([35, 23, 27, 19, 44, 21, 32, 45,  7, 20, 18, 40,  9, 24, 14]), n_unique_aclus=15)\n",
      "an_epoch: EpochTuple(Index=88, start=1015.6968982032267, stop=1015.796584552154, label=145, duration=0.09968634892720729, end=1015.796584552154, score=0.31968793737857487, velocity=325.1635979350142, intercept=330439.9945381008, speed=325.1635979350142, wcorr=-0.8630314465586185, P_decoder=nan, pearsonr=-0.6494630370137575, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=359.63208932522684, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([35, 23, 27, 19, 44, 21, 32, 45,  7, 20, 18, 40,  9, 24, 14]), n_unique_aclus=15)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (13, 59), np.nanmax(curr_data): 0.13026806747808126, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 13\n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.14646292062398014, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (13, 59), np.nanmax(curr_data): 0.14773746413841815, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 13\n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_145\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_145\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_145\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_145\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[115][\"p_x_given_n\"]): (59, 4, 4)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.00410582 0 0.995894 0]\n",
      "\t_long_any: 0.9958941842415601, _short_any: 0.004105815758439958\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.014622 0 0.985378 0]\n",
      "\t_long_any: 0.9853780455386415, _short_any: 0.014621954461358494\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.891158 0 0.108842 0]\n",
      "\t_long_any: 0.10884232198571439, _short_any: 0.8911576780142852\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_145/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_145'\n",
      "processing an_epoch_idx: 89/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 89)\n",
      "an_epoch: EpochTuple(Index=89, start=1016.9110748615349, stop=1016.9934658593265, label=146, duration=0.08239099779166281, end=1016.9934658593265, score=0.3405461980523704, velocity=2731.374222654118, intercept=2777845.1502115075, speed=2731.374222654118, wcorr=-0.810209462883826, P_decoder=0.37447854796390734, pearsonr=0.1200950250412972, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=360.846265983535, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([35, 32, 46, 21, 19, 23, 45, 24]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=89, start=1016.9110748615349, stop=1016.9934658593265, label=146, duration=0.08239099779166281, end=1016.9934658593265, score=0.3405461980523704, velocity=2731.374222654118, intercept=2777845.1502115075, speed=2731.374222654118, wcorr=-0.810209462883826, P_decoder=0.37447854796390734, pearsonr=0.1200950250412972, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=360.846265983535, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([35, 32, 46, 21, 19, 23, 45, 24]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=89, start=1016.9110748615349, stop=1016.9934658593265, label=146, duration=0.08239099779166281, end=1016.9934658593265, score=0.3405461980523704, velocity=2731.374222654118, intercept=2777845.1502115075, speed=2731.374222654118, wcorr=-0.810209462883826, P_decoder=0.37447854796390734, pearsonr=0.1200950250412972, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=360.846265983535, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([35, 32, 46, 21, 19, 23, 45, 24]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=89, start=1016.9110748615349, stop=1016.9934658593265, label=146, duration=0.08239099779166281, end=1016.9934658593265, score=0.3405461980523704, velocity=2731.374222654118, intercept=2777845.1502115075, speed=2731.374222654118, wcorr=-0.810209462883826, P_decoder=0.37447854796390734, pearsonr=0.1200950250412972, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=360.846265983535, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([35, 32, 46, 21, 19, 23, 45, 24]), n_unique_aclus=8)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.1306753907929282, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (3, 59), np.nanmax(curr_data): 0.13918661674691393, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 3\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.12484290630009687, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (3, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 3\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_146\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_146\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_146\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_146\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[116][\"p_x_given_n\"]): (59, 4, 4)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [8.45116e-08 0 1 0]\n",
      "\t_long_any: 0.9999999154883727, _short_any: 8.451162739516891e-08\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.268476 0 0.731524 0]\n",
      "\t_long_any: 0.7315241822198866, _short_any: 0.26847581778011353\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.574668 0 0.425332 0]\n",
      "\t_long_any: 0.42533165379126237, _short_any: 0.5746683462087376\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.65477 0 0.34523 0]\n",
      "\t_long_any: 0.3452300566448491, _short_any: 0.654769943355151\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_146/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_146'\n",
      "processing an_epoch_idx: 90/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 90)\n",
      "an_epoch: EpochTuple(Index=90, start=1021.8438748959452, stop=1021.9778140273411, label=147, duration=0.1339391313958913, end=1021.9778140273411, score=0.4050164840974475, velocity=741.3730032922816, intercept=757759.6341138091, speed=741.3730032922816, wcorr=-0.7019956842952748, P_decoder=0.5276050969360847, pearsonr=-0.4003386379848507, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=365.7790660179453, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([37, 46,  5, 35, 44, 40, 32,  4, 23, 21, 19, 45, 43, 17, 20]), n_unique_aclus=15)\n",
      "an_epoch: EpochTuple(Index=90, start=1021.8438748959452, stop=1021.9778140273411, label=147, duration=0.1339391313958913, end=1021.9778140273411, score=0.4050164840974475, velocity=741.3730032922816, intercept=757759.6341138091, speed=741.3730032922816, wcorr=-0.7019956842952748, P_decoder=0.5276050969360847, pearsonr=-0.4003386379848507, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=365.7790660179453, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([37, 46,  5, 35, 44, 40, 32,  4, 23, 21, 19, 45, 43, 17, 20]), n_unique_aclus=15)\n",
      "an_epoch: EpochTuple(Index=90, start=1021.8438748959452, stop=1021.9778140273411, label=147, duration=0.1339391313958913, end=1021.9778140273411, score=0.4050164840974475, velocity=741.3730032922816, intercept=757759.6341138091, speed=741.3730032922816, wcorr=-0.7019956842952748, P_decoder=0.5276050969360847, pearsonr=-0.4003386379848507, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=365.7790660179453, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([37, 46,  5, 35, 44, 40, 32,  4, 23, 21, 19, 45, 43, 17, 20]), n_unique_aclus=15)\n",
      "an_epoch: EpochTuple(Index=90, start=1021.8438748959452, stop=1021.9778140273411, label=147, duration=0.1339391313958913, end=1021.9778140273411, score=0.4050164840974475, velocity=741.3730032922816, intercept=757759.6341138091, speed=741.3730032922816, wcorr=-0.7019956842952748, P_decoder=0.5276050969360847, pearsonr=-0.4003386379848507, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=365.7790660179453, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([37, 46,  5, 35, 44, 40, 32,  4, 23, 21, 19, 45, 43, 17, 20]), n_unique_aclus=15)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (14, 59), np.nanmax(curr_data): 0.1306753907929282, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 14\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.13918661674691393, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (14, 59), np.nanmax(curr_data): 0.1490508567103094, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 14\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_147\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_147\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_147\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_147\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[117][\"p_x_given_n\"]): (59, 4, 6)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.644524 0 0.355476 0]\n",
      "\t_long_any: 0.35547561854023974, _short_any: 0.6445243814597604\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [3.509e-05 0 0.999965 0]\n",
      "\t_long_any: 0.9999649099604938, _short_any: 3.5090039506229225e-05\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.586933 0 0.413067 0]\n",
      "\t_long_any: 0.4130669428736785, _short_any: 0.5869330571263213\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.8005 0 0.1995 0]\n",
      "\t_long_any: 0.1994997712822058, _short_any: 0.800500228717794\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.578663 0 0.421337 0]\n",
      "\t_long_any: 0.4213367177309204, _short_any: 0.5786632822690797\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.554975 0 0.445025 0]\n",
      "\t_long_any: 0.445025457995953, _short_any: 0.5549745420040473\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_147/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_147'\n",
      "processing an_epoch_idx: 91/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 91)\n",
      "an_epoch: EpochTuple(Index=91, start=1022.6336242515827, stop=1022.7332798806019, label=148, duration=0.09965562901925296, end=1022.7332798806019, score=0.3772622338488859, velocity=-260.1308783480112, intercept=-265843.8074708841, speed=260.1308783480112, wcorr=-0.4849856179202194, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=366.56881537358277, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([35, 40, 46, 31, 16, 27, 44, 10, 37, 39, 52, 21, 49]), n_unique_aclus=13)\n",
      "an_epoch: EpochTuple(Index=91, start=1022.6336242515827, stop=1022.7332798806019, label=148, duration=0.09965562901925296, end=1022.7332798806019, score=0.3772622338488859, velocity=-260.1308783480112, intercept=-265843.8074708841, speed=260.1308783480112, wcorr=-0.4849856179202194, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=366.56881537358277, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([35, 40, 46, 31, 16, 27, 44, 10, 37, 39, 52, 21, 49]), n_unique_aclus=13)\n",
      "an_epoch: EpochTuple(Index=91, start=1022.6336242515827, stop=1022.7332798806019, label=148, duration=0.09965562901925296, end=1022.7332798806019, score=0.3772622338488859, velocity=-260.1308783480112, intercept=-265843.8074708841, speed=260.1308783480112, wcorr=-0.4849856179202194, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=366.56881537358277, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([35, 40, 46, 31, 16, 27, 44, 10, 37, 39, 52, 21, 49]), n_unique_aclus=13)\n",
      "an_epoch: EpochTuple(Index=91, start=1022.6336242515827, stop=1022.7332798806019, label=148, duration=0.09965562901925296, end=1022.7332798806019, score=0.3772622338488859, velocity=-260.1308783480112, intercept=-265843.8074708841, speed=260.1308783480112, wcorr=-0.4849856179202194, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=366.56881537358277, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([35, 40, 46, 31, 16, 27, 44, 10, 37, 39, 52, 21, 49]), n_unique_aclus=13)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.1306753907929282, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (12, 59), np.nanmax(curr_data): 0.12755996431569847, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 12\n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.12484290630009687, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (12, 59), np.nanmax(curr_data): 0.15153529453505524, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 12\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_148\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_148\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_148\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_148\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[118][\"p_x_given_n\"]): (59, 4, 4)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [1.84846e-06 0 0.999998 0]\n",
      "\t_long_any: 0.9999981515440657, _short_any: 1.8484559344915027e-06\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.426219 0 0.573781]\n",
      "\t_long_any: 0.5737809922851259, _short_any: 0.42621900771487436\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.95363 0 0.0463704]\n",
      "\t_long_any: 0.04637038717306484, _short_any: 0.9536296128269351\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_148/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_148'\n",
      "processing an_epoch_idx: 92/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 92)\n",
      "an_epoch: EpochTuple(Index=92, start=1026.1355181386461, stop=1026.224728972884, label=149, duration=0.0892108342377469, end=1026.224728972884, score=0.5604565375341247, velocity=-130.0654391740056, intercept=-133229.83611924062, speed=130.0654391740056, wcorr=0.24660969618920325, P_decoder=0.11670162266355052, pearsonr=-0.5395554085501071, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=370.07070926064625, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([43, 23, 31, 18,  5, 37, 50, 26, 32]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=92, start=1026.1355181386461, stop=1026.224728972884, label=149, duration=0.0892108342377469, end=1026.224728972884, score=0.5604565375341247, velocity=-130.0654391740056, intercept=-133229.83611924062, speed=130.0654391740056, wcorr=0.24660969618920325, P_decoder=0.11670162266355052, pearsonr=-0.5395554085501071, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=370.07070926064625, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([43, 23, 31, 18,  5, 37, 50, 26, 32]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=92, start=1026.1355181386461, stop=1026.224728972884, label=149, duration=0.0892108342377469, end=1026.224728972884, score=0.5604565375341247, velocity=-130.0654391740056, intercept=-133229.83611924062, speed=130.0654391740056, wcorr=0.24660969618920325, P_decoder=0.11670162266355052, pearsonr=-0.5395554085501071, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=370.07070926064625, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([43, 23, 31, 18,  5, 37, 50, 26, 32]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=92, start=1026.1355181386461, stop=1026.224728972884, label=149, duration=0.0892108342377469, end=1026.224728972884, score=0.5604565375341247, velocity=-130.0654391740056, intercept=-133229.83611924062, speed=130.0654391740056, wcorr=0.24660969618920325, P_decoder=0.11670162266355052, pearsonr=-0.5395554085501071, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=370.07070926064625, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([43, 23, 31, 18,  5, 37, 50, 26, 32]), n_unique_aclus=9)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.14933925445043028, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.16577466995625206, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_149\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_149\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_149\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_149\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[119][\"p_x_given_n\"]): (59, 4, 4)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.303059 0 0.696941 0]\n",
      "\t_long_any: 0.6969407129898084, _short_any: 0.3030592870101917\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.175019 0 0.824981 0]\n",
      "\t_long_any: 0.8249812596278134, _short_any: 0.17501874037218665\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [3.92635e-06 0.00352721 1.41713e-05 0.996455]\n",
      "\t_long_any: 0.9964688592477432, _short_any: 0.00353114075225647\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0866039 0.279898 0.115007 0.518491]\n",
      "\t_long_any: 0.6334979026476145, _short_any: 0.36650209735238537\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_149/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_149'\n",
      "processing an_epoch_idx: 93/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 93)\n",
      "an_epoch: EpochTuple(Index=93, start=1028.1721302157966, stop=1028.6184301472967, label=150, duration=0.44629993150010705, end=1028.6184301472967, score=0.17298658840327566, velocity=103.2872605206075, intercept=106415.42046600523, speed=103.2872605206075, wcorr=0.2502865655384523, P_decoder=nan, pearsonr=-0.4588293428073696, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=372.10732133779675, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([35, 46, 41, 32, 23, 18,  4, 40, 21, 45, 19,  9,  7, 14, 20, 52, 49, 11,  5, 10, 37, 43, 25, 16, 39, 17]), n_unique_aclus=26)\n",
      "an_epoch: EpochTuple(Index=93, start=1028.1721302157966, stop=1028.6184301472967, label=150, duration=0.44629993150010705, end=1028.6184301472967, score=0.17298658840327566, velocity=103.2872605206075, intercept=106415.42046600523, speed=103.2872605206075, wcorr=0.2502865655384523, P_decoder=nan, pearsonr=-0.4588293428073696, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=372.10732133779675, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([35, 46, 41, 32, 23, 18,  4, 40, 21, 45, 19,  9,  7, 14, 20, 52, 49, 11,  5, 10, 37, 43, 25, 16, 39, 17]), n_unique_aclus=26)\n",
      "an_epoch: EpochTuple(Index=93, start=1028.1721302157966, stop=1028.6184301472967, label=150, duration=0.44629993150010705, end=1028.6184301472967, score=0.17298658840327566, velocity=103.2872605206075, intercept=106415.42046600523, speed=103.2872605206075, wcorr=0.2502865655384523, P_decoder=nan, pearsonr=-0.4588293428073696, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=372.10732133779675, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([35, 46, 41, 32, 23, 18,  4, 40, 21, 45, 19,  9,  7, 14, 20, 52, 49, 11,  5, 10, 37, 43, 25, 16, 39, 17]), n_unique_aclus=26)\n",
      "an_epoch: EpochTuple(Index=93, start=1028.1721302157966, stop=1028.6184301472967, label=150, duration=0.44629993150010705, end=1028.6184301472967, score=0.17298658840327566, velocity=103.2872605206075, intercept=106415.42046600523, speed=103.2872605206075, wcorr=0.2502865655384523, P_decoder=nan, pearsonr=-0.4588293428073696, is_user_annotated_epoch=True, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=372.10732133779675, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([35, 46, 41, 32, 23, 18,  4, 40, 21, 45, 19,  9,  7, 14, 20, 52, 49, 11,  5, 10, 37, 43, 25, 16, 39, 17]), n_unique_aclus=26)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (18, 59), np.nanmax(curr_data): 0.1306753907929282, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 18\n",
      "np.shape(curr_data): (18, 59), np.nanmax(curr_data): 0.16871442757882205, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 18\n",
      "np.shape(curr_data): (18, 59), np.nanmax(curr_data): 0.1490508567103094, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 18\n",
      "np.shape(curr_data): (18, 59), np.nanmax(curr_data): 0.16771957548724484, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 18\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_150\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_150\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_150\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_150\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[120][\"p_x_given_n\"]): (59, 4, 18)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.00737254 0 0.992627 0]\n",
      "\t_long_any: 0.9926274607668573, _short_any: 0.007372539233142843\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0152314 0 0.984769 0]\n",
      "\t_long_any: 0.9847686000599674, _short_any: 0.015231399940032305\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.8555 0 0.1445 0]\n",
      "\t_long_any: 0.14450046530571733, _short_any: 0.8554995346942829\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.95439 0 0.0456096 0]\n",
      "\t_long_any: 0.04560955044594159, _short_any: 0.9543904495540586\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.999866 0 0.000133693 0]\n",
      "\t_long_any: 0.00013369268764786368, _short_any: 0.9998663073123522\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.690195 0 0.309805]\n",
      "\t_long_any: 0.3098047152377101, _short_any: 0.69019528476229\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.512617 0.252657 0.0406106 0.194116]\n",
      "\t_long_any: 0.23472629065696332, _short_any: 0.7652737093430365\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 10, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.599087 0 0.400913 0]\n",
      "\t_long_any: 0.40091269397253604, _short_any: 0.599087306027464\n",
      "i: 11, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.000124657 0 0.999875]\n",
      "\t_long_any: 0.9998753430617529, _short_any: 0.00012465693824652844\n",
      "i: 12, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0353716 0.000299352 7.5592e-06 0.964321]\n",
      "\t_long_any: 0.964329024899563, _short_any: 0.035670975100437825\n",
      "i: 13, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.665582 0 0.334418]\n",
      "\t_long_any: 0.3344181630639515, _short_any: 0.6655818369360479\n",
      "i: 14, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.3264 0 0.6736]\n",
      "\t_long_any: 0.6735997915425396, _short_any: 0.32640020845746\n",
      "i: 15, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.00310667 0.978196 5.63886e-05 0.0186413]\n",
      "\t_long_any: 0.01869772301636586, _short_any: 0.9813022769836343\n",
      "i: 16, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.505606 0 0.494394 0]\n",
      "\t_long_any: 0.494393861745059, _short_any: 0.5056061382549412\n",
      "i: 17, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.620665 0 0.379335]\n",
      "\t_long_any: 0.3793347009359552, _short_any: 0.6206652990640449\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_150/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_150'\n",
      "processing an_epoch_idx: 94/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 94)\n",
      "an_epoch: EpochTuple(Index=94, start=1030.4905367088504, stop=1030.8126050239662, label=151, duration=0.3220683151157573, end=1030.8126050239662, score=0.20760134866471852, velocity=325.1635979352603, intercept=335347.8963407735, speed=325.1635979352603, wcorr=-0.13821011836402744, P_decoder=nan, pearsonr=0.7785171270180352, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=374.4257278308505, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([27, 35, 49, 11, 53, 43, 50, 20, 39, 37,  5, 18, 15, 52, 31, 40, 32, 24, 23,  9, 10, 14, 41]), n_unique_aclus=23)\n",
      "an_epoch: EpochTuple(Index=94, start=1030.4905367088504, stop=1030.8126050239662, label=151, duration=0.3220683151157573, end=1030.8126050239662, score=0.20760134866471852, velocity=325.1635979352603, intercept=335347.8963407735, speed=325.1635979352603, wcorr=-0.13821011836402744, P_decoder=nan, pearsonr=0.7785171270180352, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=374.4257278308505, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([27, 35, 49, 11, 53, 43, 50, 20, 39, 37,  5, 18, 15, 52, 31, 40, 32, 24, 23,  9, 10, 14, 41]), n_unique_aclus=23)\n",
      "an_epoch: EpochTuple(Index=94, start=1030.4905367088504, stop=1030.8126050239662, label=151, duration=0.3220683151157573, end=1030.8126050239662, score=0.20760134866471852, velocity=325.1635979352603, intercept=335347.8963407735, speed=325.1635979352603, wcorr=-0.13821011836402744, P_decoder=nan, pearsonr=0.7785171270180352, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=374.4257278308505, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([27, 35, 49, 11, 53, 43, 50, 20, 39, 37,  5, 18, 15, 52, 31, 40, 32, 24, 23,  9, 10, 14, 41]), n_unique_aclus=23)\n",
      "an_epoch: EpochTuple(Index=94, start=1030.4905367088504, stop=1030.8126050239662, label=151, duration=0.3220683151157573, end=1030.8126050239662, score=0.20760134866471852, velocity=325.1635979352603, intercept=335347.8963407735, speed=325.1635979352603, wcorr=-0.13821011836402744, P_decoder=nan, pearsonr=0.7785171270180352, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=374.4257278308505, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([27, 35, 49, 11, 53, 43, 50, 20, 39, 37,  5, 18, 15, 52, 31, 40, 32, 24, 23,  9, 10, 14, 41]), n_unique_aclus=23)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (16, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 16\n",
      "np.shape(curr_data): (17, 59), np.nanmax(curr_data): 0.14646292062398014, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 17\n",
      "np.shape(curr_data): (16, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 16\n",
      "np.shape(curr_data): (17, 59), np.nanmax(curr_data): 0.17673647253127112, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 17\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_151\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_151\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_151\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_151\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[121][\"p_x_given_n\"]): (59, 4, 13)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.589753 0 0.410247]\n",
      "\t_long_any: 0.41024733955496706, _short_any: 0.5897526604450327\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.563541 0 0.436459]\n",
      "\t_long_any: 0.436459465127331, _short_any: 0.563540534872669\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.332092 0 0.667908 0]\n",
      "\t_long_any: 0.6679082064751289, _short_any: 0.33209179352487067\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.131547 0.394143 0.0188665 0.455444]\n",
      "\t_long_any: 0.47431040310049316, _short_any: 0.5256895968995073\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.605608 0 0.394392 0]\n",
      "\t_long_any: 0.39439181409137714, _short_any: 0.6056081859086229\n",
      "i: 10, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.128907 0 0.871093 0]\n",
      "\t_long_any: 0.8710926240733732, _short_any: 0.1289073759266262\n",
      "i: 11, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.94846 0 0.0515398]\n",
      "\t_long_any: 0.05153975780406086, _short_any: 0.948460242195939\n",
      "i: 12, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.530353 0 0.469647]\n",
      "\t_long_any: 0.4696470064185898, _short_any: 0.5303529935814102\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_151/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_151'\n",
      "processing an_epoch_idx: 95/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 95)\n",
      "an_epoch: EpochTuple(Index=95, start=1064.2788637292106, stop=1064.653094577603, label=155, duration=0.37423084839247167, end=1064.653094577603, score=0.2846888426051609, velocity=13.935582768655568, intercept=15068.076906711589, speed=13.935582768655568, wcorr=-0.07535539294386522, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=408.2140548512107, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([41, 43, 50, 37, 31, 11, 35, 27, 17]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=95, start=1064.2788637292106, stop=1064.653094577603, label=155, duration=0.37423084839247167, end=1064.653094577603, score=0.2846888426051609, velocity=13.935582768655568, intercept=15068.076906711589, speed=13.935582768655568, wcorr=-0.07535539294386522, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=408.2140548512107, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([41, 43, 50, 37, 31, 11, 35, 27, 17]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=95, start=1064.2788637292106, stop=1064.653094577603, label=155, duration=0.37423084839247167, end=1064.653094577603, score=0.2846888426051609, velocity=13.935582768655568, intercept=15068.076906711589, speed=13.935582768655568, wcorr=-0.07535539294386522, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=408.2140548512107, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([41, 43, 50, 37, 31, 11, 35, 27, 17]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=95, start=1064.2788637292106, stop=1064.653094577603, label=155, duration=0.37423084839247167, end=1064.653094577603, score=0.2846888426051609, velocity=13.935582768655568, intercept=15068.076906711589, speed=13.935582768655568, wcorr=-0.07535539294386522, P_decoder=nan, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=408.2140548512107, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([41, 43, 50, 37, 31, 11, 35, 27, 17]), n_unique_aclus=9)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.1328468488320496, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.16577466995625206, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_155\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_155\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_155\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_155\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[124][\"p_x_given_n\"]): (59, 4, 15)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.430823 0 0.569177 0]\n",
      "\t_long_any: 0.5691769160512143, _short_any: 0.43082308394878605\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.00160261 0.52521 0.0165202 0.456668]\n",
      "\t_long_any: 0.47318780094604385, _short_any: 0.5268121990539564\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [nan nan nan nan]\n",
      "\t_long_any: nan, _short_any: nan\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.395579 0 0.604421 0]\n",
      "\t_long_any: 0.6044212891290719, _short_any: 0.3955787108709279\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.505606 0 0.494394 0]\n",
      "\t_long_any: 0.494393861745059, _short_any: 0.5056061382549412\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.530607 0 0.469393 0]\n",
      "\t_long_any: 0.4693927892627292, _short_any: 0.5306072107372706\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.505606 0 0.494394 0]\n",
      "\t_long_any: 0.494393861745059, _short_any: 0.5056061382549412\n",
      "i: 10, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.530607 0 0.469393 0]\n",
      "\t_long_any: 0.4693927892627292, _short_any: 0.5306072107372706\n",
      "i: 11, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 12, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.225549 0.075572 0.602735 0.0961441]\n",
      "\t_long_any: 0.6988791397533964, _short_any: 0.3011208602466035\n",
      "i: 13, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.203509 0.153953 0.340026 0.302511]\n",
      "\t_long_any: 0.6425370637459515, _short_any: 0.35746293625404885\n",
      "i: 14, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.240982 0.48712 0.117172 0.154727]\n",
      "\t_long_any: 0.2718985060221877, _short_any: 0.7281014939778122\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_155/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_155'\n",
      "processing an_epoch_idx: 96/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 96)\n",
      "an_epoch: EpochTuple(Index=96, start=1064.9692339358153, stop=1065.25972210709, label=156, duration=0.2904881712747738, end=1065.25972210709, score=0.14491973360655372, velocity=212.8343550120679, intercept=226867.1147815776, speed=212.8343550120679, wcorr=-0.3962102009861585, P_decoder=0.22345617145165605, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=408.9044250578154, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 5, 37, 25, 18, 26, 31, 35, 32, 46, 44, 27, 24, 23, 21, 45,  7]), n_unique_aclus=16)\n",
      "an_epoch: EpochTuple(Index=96, start=1064.9692339358153, stop=1065.25972210709, label=156, duration=0.2904881712747738, end=1065.25972210709, score=0.14491973360655372, velocity=212.8343550120679, intercept=226867.1147815776, speed=212.8343550120679, wcorr=-0.3962102009861585, P_decoder=0.22345617145165605, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=408.9044250578154, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 5, 37, 25, 18, 26, 31, 35, 32, 46, 44, 27, 24, 23, 21, 45,  7]), n_unique_aclus=16)\n",
      "an_epoch: EpochTuple(Index=96, start=1064.9692339358153, stop=1065.25972210709, label=156, duration=0.2904881712747738, end=1065.25972210709, score=0.14491973360655372, velocity=212.8343550120679, intercept=226867.1147815776, speed=212.8343550120679, wcorr=-0.3962102009861585, P_decoder=0.22345617145165605, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=408.9044250578154, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 5, 37, 25, 18, 26, 31, 35, 32, 46, 44, 27, 24, 23, 21, 45,  7]), n_unique_aclus=16)\n",
      "an_epoch: EpochTuple(Index=96, start=1064.9692339358153, stop=1065.25972210709, label=156, duration=0.2904881712747738, end=1065.25972210709, score=0.14491973360655372, velocity=212.8343550120679, intercept=226867.1147815776, speed=212.8343550120679, wcorr=-0.3962102009861585, P_decoder=0.22345617145165605, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=408.9044250578154, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([ 5, 37, 25, 18, 26, 31, 35, 32, 46, 44, 27, 24, 23, 21, 45,  7]), n_unique_aclus=16)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (14, 59), np.nanmax(curr_data): 0.1413380488947274, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 14\n",
      "np.shape(curr_data): (11, 59), np.nanmax(curr_data): 0.16871442757882205, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 11\n",
      "np.shape(curr_data): (14, 59), np.nanmax(curr_data): 0.16137889015198256, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 14\n",
      "np.shape(curr_data): (11, 59), np.nanmax(curr_data): 0.16771957548724484, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 11\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_156\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_156\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_156\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_156\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[125][\"p_x_given_n\"]): (59, 4, 12)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.399416 0.0656837 0.0227743 0.512126]\n",
      "\t_long_any: 0.5349007919943249, _short_any: 0.4650992080056749\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.00801939 0 0.991981]\n",
      "\t_long_any: 0.9919806090062706, _short_any: 0.008019390993729591\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [5.87502e-06 0.00766699 3.85855e-05 0.992289]\n",
      "\t_long_any: 0.9923271399551699, _short_any: 0.007672860044829863\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.194246 0.191924 0.326478 0.287353]\n",
      "\t_long_any: 0.6138302421277817, _short_any: 0.386169757872219\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.0426518 0.0155336 0.913401 0.028414]\n",
      "\t_long_any: 0.9418145934928085, _short_any: 0.05818540650719171\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [3.54694e-07 0 1 0]\n",
      "\t_long_any: 0.9999996453061808, _short_any: 3.546938198974331e-07\n",
      "i: 9, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.791315 0 0.208685 0]\n",
      "\t_long_any: 0.20868498954662618, _short_any: 0.7913150104533739\n",
      "i: 10, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.873029 0 0.126971 0]\n",
      "\t_long_any: 0.1269707133402005, _short_any: 0.8730292866597996\n",
      "i: 11, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.56468 0 0.43532 0]\n",
      "\t_long_any: 0.4353203764371175, _short_any: 0.5646796235628826\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_156/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_156'\n",
      "processing an_epoch_idx: 97/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 97)\n",
      "an_epoch: EpochTuple(Index=97, start=1066.0726650507422, stop=1066.1560083681252, label=158, duration=0.08334331738296896, end=1066.1560083681252, score=0.36198416987297444, velocity=325.1635979350142, intercept=346844.7474048194, speed=325.1635979350142, wcorr=0.11247811284248133, P_decoder=0.007134843656709441, pearsonr=-0.27150498735925016, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=410.0078561727423, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([10, 16, 17, 37, 35, 27,  5, 25, 18]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=97, start=1066.0726650507422, stop=1066.1560083681252, label=158, duration=0.08334331738296896, end=1066.1560083681252, score=0.36198416987297444, velocity=325.1635979350142, intercept=346844.7474048194, speed=325.1635979350142, wcorr=0.11247811284248133, P_decoder=0.007134843656709441, pearsonr=-0.27150498735925016, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=410.0078561727423, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([10, 16, 17, 37, 35, 27,  5, 25, 18]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=97, start=1066.0726650507422, stop=1066.1560083681252, label=158, duration=0.08334331738296896, end=1066.1560083681252, score=0.36198416987297444, velocity=325.1635979350142, intercept=346844.7474048194, speed=325.1635979350142, wcorr=0.11247811284248133, P_decoder=0.007134843656709441, pearsonr=-0.27150498735925016, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=410.0078561727423, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([10, 16, 17, 37, 35, 27,  5, 25, 18]), n_unique_aclus=9)\n",
      "an_epoch: EpochTuple(Index=97, start=1066.0726650507422, stop=1066.1560083681252, label=158, duration=0.08334331738296896, end=1066.1560083681252, score=0.36198416987297444, velocity=325.1635979350142, intercept=346844.7474048194, speed=325.1635979350142, wcorr=0.11247811284248133, P_decoder=0.007134843656709441, pearsonr=-0.27150498735925016, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=410.0078561727423, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([10, 16, 17, 37, 35, 27,  5, 25, 18]), n_unique_aclus=9)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.10599566525773634, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.16871442757882205, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.1332959571110494, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (9, 59), np.nanmax(curr_data): 0.16771957548724484, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 9\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_158\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_158\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_158\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_158\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[126][\"p_x_given_n\"]): (59, 4, 4)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.110688 0 0.889312]\n",
      "\t_long_any: 0.8893124344372648, _short_any: 0.11068756556273496\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.0303322 0 0.969668]\n",
      "\t_long_any: 0.9696677793284013, _short_any: 0.030332220671598912\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.063619 0.000702132 0.109062 0.826616]\n",
      "\t_long_any: 0.9356788683357576, _short_any: 0.0643211316642423\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.455746 0 0.544254]\n",
      "\t_long_any: 0.5442537898385795, _short_any: 0.4557462101614206\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_158/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_158'\n",
      "processing an_epoch_idx: 98/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 98)\n",
      "an_epoch: EpochTuple(Index=98, start=1072.363319110009, stop=1072.5843493968714, label=159, duration=0.2210302868625149, end=1072.5843493968714, score=0.18024228480700386, velocity=-341.4217778318941, intercept=-365959.30904857244, speed=341.4217778318941, wcorr=-0.24716185148212907, P_decoder=0.05736987452768679, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=416.298510232009, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([10, 41,  9, 39, 17, 37, 16, 32, 18, 21,  5, 11, 14, 52]), n_unique_aclus=14)\n",
      "an_epoch: EpochTuple(Index=98, start=1072.363319110009, stop=1072.5843493968714, label=159, duration=0.2210302868625149, end=1072.5843493968714, score=0.18024228480700386, velocity=-341.4217778318941, intercept=-365959.30904857244, speed=341.4217778318941, wcorr=-0.24716185148212907, P_decoder=0.05736987452768679, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=416.298510232009, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([10, 41,  9, 39, 17, 37, 16, 32, 18, 21,  5, 11, 14, 52]), n_unique_aclus=14)\n",
      "an_epoch: EpochTuple(Index=98, start=1072.363319110009, stop=1072.5843493968714, label=159, duration=0.2210302868625149, end=1072.5843493968714, score=0.18024228480700386, velocity=-341.4217778318941, intercept=-365959.30904857244, speed=341.4217778318941, wcorr=-0.24716185148212907, P_decoder=0.05736987452768679, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=416.298510232009, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([10, 41,  9, 39, 17, 37, 16, 32, 18, 21,  5, 11, 14, 52]), n_unique_aclus=14)\n",
      "an_epoch: EpochTuple(Index=98, start=1072.363319110009, stop=1072.5843493968714, label=159, duration=0.2210302868625149, end=1072.5843493968714, score=0.18024228480700386, velocity=-341.4217778318941, intercept=-365959.30904857244, speed=341.4217778318941, wcorr=-0.24716185148212907, P_decoder=0.05736987452768679, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=416.298510232009, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([10, 41,  9, 39, 17, 37, 16, 32, 18, 21,  5, 11, 14, 52]), n_unique_aclus=14)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.13026806747808126, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (13, 59), np.nanmax(curr_data): 0.14646292062398014, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 13\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.1332959571110494, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (13, 59), np.nanmax(curr_data): 0.15488993313229502, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 13\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_159\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_159\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_159\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_159\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[127][\"p_x_given_n\"]): (59, 4, 9)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.908637 0 0.0913627]\n",
      "\t_long_any: 0.09136270059386992, _short_any: 0.9086372994061302\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.854999 0 0.145001]\n",
      "\t_long_any: 0.14500085755298642, _short_any: 0.8549991424470136\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.112659 0 0.887341]\n",
      "\t_long_any: 0.8873413291356902, _short_any: 0.11265867086431011\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.907583 0 0.0924174]\n",
      "\t_long_any: 0.0924173764423609, _short_any: 0.9075826235576395\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.20752 0.532761 0.0379864 0.221733]\n",
      "\t_long_any: 0.25971918846234027, _short_any: 0.7402808115376588\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.868273 0 0.131727]\n",
      "\t_long_any: 0.1317270899715942, _short_any: 0.8682729100284059\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.903466 0 0.0965343]\n",
      "\t_long_any: 0.09653431439721868, _short_any: 0.9034656856027808\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.715618 0 0.284382]\n",
      "\t_long_any: 0.28438176163142376, _short_any: 0.7156182383685763\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.185532 0.278758 0.286549 0.249161]\n",
      "\t_long_any: 0.5357102219368333, _short_any: 0.464289778063168\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_159/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_159'\n",
      "processing an_epoch_idx: 99/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 99)\n",
      "an_epoch: EpochTuple(Index=99, start=1094.6250779519323, stop=1094.7721652366454, label=163, duration=0.1470872847130522, end=1094.7721652366454, score=0.2835980198834737, velocity=351.17668577002814, intercept=384496.5521889484, speed=351.17668577002814, wcorr=-0.26125647020659704, P_decoder=0.6016146821562991, pearsonr=-0.6374314037927102, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=438.56026907393243, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([11, 14,  9, 52, 20, 19, 31, 18,  7, 40, 45, 24]), n_unique_aclus=12)\n",
      "an_epoch: EpochTuple(Index=99, start=1094.6250779519323, stop=1094.7721652366454, label=163, duration=0.1470872847130522, end=1094.7721652366454, score=0.2835980198834737, velocity=351.17668577002814, intercept=384496.5521889484, speed=351.17668577002814, wcorr=-0.26125647020659704, P_decoder=0.6016146821562991, pearsonr=-0.6374314037927102, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=438.56026907393243, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([11, 14,  9, 52, 20, 19, 31, 18,  7, 40, 45, 24]), n_unique_aclus=12)\n",
      "an_epoch: EpochTuple(Index=99, start=1094.6250779519323, stop=1094.7721652366454, label=163, duration=0.1470872847130522, end=1094.7721652366454, score=0.2835980198834737, velocity=351.17668577002814, intercept=384496.5521889484, speed=351.17668577002814, wcorr=-0.26125647020659704, P_decoder=0.6016146821562991, pearsonr=-0.6374314037927102, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=438.56026907393243, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([11, 14,  9, 52, 20, 19, 31, 18,  7, 40, 45, 24]), n_unique_aclus=12)\n",
      "an_epoch: EpochTuple(Index=99, start=1094.6250779519323, stop=1094.7721652366454, label=163, duration=0.1470872847130522, end=1094.7721652366454, score=0.2835980198834737, velocity=351.17668577002814, intercept=384496.5521889484, speed=351.17668577002814, wcorr=-0.26125647020659704, P_decoder=0.6016146821562991, pearsonr=-0.6374314037927102, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=438.56026907393243, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([11, 14,  9, 52, 20, 19, 31, 18,  7, 40, 45, 24]), n_unique_aclus=12)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.10832426379331009, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.14646292062398014, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.14773746413841815, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "np.shape(curr_data): (8, 59), np.nanmax(curr_data): 0.1640637667883362, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 8\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_163\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_163\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_163\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_163\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[130][\"p_x_given_n\"]): (59, 4, 6)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.873854 0 0.126146]\n",
      "\t_long_any: 0.12614561322309845, _short_any: 0.8738543867769014\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.554975 0 0.445025 0]\n",
      "\t_long_any: 0.445025457995953, _short_any: 0.5549745420040473\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.582884 0 0.417116 0]\n",
      "\t_long_any: 0.4171156235528013, _short_any: 0.5828843764471987\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.999993 0 7.07311e-06 0]\n",
      "\t_long_any: 7.073111882938063e-06, _short_any: 0.9999929268881173\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.703331 0.00213347 0.293991 0.000544165]\n",
      "\t_long_any: 0.29453510496529556, _short_any: 0.7054648950347042\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.616776 0 0.383224 0]\n",
      "\t_long_any: 0.38322447055759384, _short_any: 0.6167755294424057\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_163/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_163'\n",
      "processing an_epoch_idx: 100/101...\n",
      "WARN: self.disable_emit_changed = True\n",
      "WARN: self.disable_emit_changed = True\n",
      "ScrollBarWithSpinBox valueChanged(new_val: 100)\n",
      "an_epoch: EpochTuple(Index=100, start=1108.4538631916512, stop=1108.543166185962, label=165, duration=0.08930299431085587, end=1108.543166185962, score=0.4709472247812949, velocity=-130.0654391740056, intercept=-143931.73036666802, speed=130.0654391740056, wcorr=-0.16315893408400298, P_decoder=0.16181364138062565, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=452.3890543136513, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([15, 32, 31, 50, 18, 37, 25, 49]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=100, start=1108.4538631916512, stop=1108.543166185962, label=165, duration=0.08930299431085587, end=1108.543166185962, score=0.4709472247812949, velocity=-130.0654391740056, intercept=-143931.73036666802, speed=130.0654391740056, wcorr=-0.16315893408400298, P_decoder=0.16181364138062565, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=452.3890543136513, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([15, 32, 31, 50, 18, 37, 25, 49]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=100, start=1108.4538631916512, stop=1108.543166185962, label=165, duration=0.08930299431085587, end=1108.543166185962, score=0.4709472247812949, velocity=-130.0654391740056, intercept=-143931.73036666802, speed=130.0654391740056, wcorr=-0.16315893408400298, P_decoder=0.16181364138062565, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=452.3890543136513, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([15, 32, 31, 50, 18, 37, 25, 49]), n_unique_aclus=8)\n",
      "an_epoch: EpochTuple(Index=100, start=1108.4538631916512, stop=1108.543166185962, label=165, duration=0.08930299431085587, end=1108.543166185962, score=0.4709472247812949, velocity=-130.0654391740056, intercept=-143931.73036666802, speed=130.0654391740056, wcorr=-0.16315893408400298, P_decoder=0.16181364138062565, pearsonr=nan, is_user_annotated_epoch=False, is_valid_epoch=True, session_name='2006-6-12_15-55-31', delta_aligned_start_t=452.3890543136513, pre_post_delta_category='post-delta', maze_id=1, unique_active_aclus=array([15, 32, 31, 50, 18, 37, 25, 49]), n_unique_aclus=8)\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "WARN: No RankOrderResults\n",
      "len(included_any_context_neuron_ids_dict_dict) != len(decoders_dict), assuming this is a single included_any_context_neuron_ids_dict for all decoders like used in `paired_incremental_sort_neurons(...)`. Fixing. \n",
      "np.shape(curr_data): (5, 59), np.nanmax(curr_data): 0.1641962341211614, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 5\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.16871442757882205, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "np.shape(curr_data): (5, 59), np.nanmax(curr_data): 0.17655229829757768, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 5\n",
      "np.shape(curr_data): (6, 59), np.nanmax(curr_data): 0.16771957548724484, np.nanmin(curr_data): 0.0\n",
      "n_total_cells: 6\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_165\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_165\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_165\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_165\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[132][\"p_x_given_n\"]): (59, 4, 4)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.228634 0 0.771366 0]\n",
      "\t_long_any: 0.7713655429335313, _short_any: 0.22863445706646834\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.00321156 0.699756 0.0212635 0.275768]\n",
      "\t_long_any: 0.29703198942122316, _short_any: 0.7029680105787768\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.607678 0 0.392322]\n",
      "\t_long_any: 0.39232201833983205, _short_any: 0.6076779816601681\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.987885 0 0.0121147]\n",
      "\t_long_any: 0.01211472334191023, _short_any: 0.98788527665809\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_figures/qclu_1246789/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_165/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_figures\\qclu_1246789\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_165'\n",
      "done with 101 epochs.\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.stacked_epoch_slices import PhoPaginatedMultiDecoderDecodedEpochsWindow\n",
    "\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders'] # uses `DirectionalMergedDecoders`.\n",
    "\n",
    "# root_export_path: Path = Path(r\"/media/halechr/MAX/cloud/University of Michigan Dropbox/Pho Hale/Pho Diba Paper 2023/array_as_image\").resolve() # Lab\n",
    "# root_export_path: Path = Path(r'K:/scratch/collected_outputs/figures/array_as_image').resolve()\n",
    "\n",
    "root_export_path: Path = Path(r'K:/scratch/collected_figures/qclu_1246789/array_as_image').resolve()\n",
    "\n",
    "\n",
    "# root_export_path: Path = Path(r'C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\EXTERNAL\\Screenshots\\ProgrammaticDisplayFunctionTesting\\array_as_image').resolve()\n",
    "root_export_path.mkdir(exist_ok=True)\n",
    "Assert.path_exists(root_export_path)\n",
    "\n",
    "complete_session_context, (session_context, additional_session_context) = curr_active_pipeline.get_complete_session_context()\n",
    "_out_path_tuples_dict = paginated_multi_decoder_decoded_epochs_window.export_all_epoch_marginal_and_raster_images(directional_merged_decoders_result=directional_merged_decoders_result, root_export_path=root_export_path, active_context=complete_session_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541163df",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(_out_path_tuples_dict.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9019b4cd",
   "metadata": {},
   "source": [
    "#### Single epoch export via `export_current_epoch_marginal_and_raster_images`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b58d46c3",
   "metadata": {
    "tags": [
     "2025-05-16_working-posterior-and-raster-stack-image-saving"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exported plot to \"K:\\scratch\\collected_outputs\\figures\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_159\\long_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_outputs\\figures\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_159\\long_RL_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_outputs\\figures\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_159\\short_LR_raster.png\"\n",
      "exported plot to \"K:\\scratch\\collected_outputs\\figures\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_159\\short_RL_raster.png\"\n",
      "parent_array_as_image_output_folder: \"K:\\scratch\\collected_outputs\\figures\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\"\n",
      "len(raw_posterior_active_marginals): 133\n",
      "collapsed_per_epoch_marginal_track_identity_point.shape: (133, 2)\n",
      "np.shape(raw_posterior_laps_marginals[127][\"p_x_given_n\"]): (59, 4, 9)\n",
      "i: 0, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.908637 0 0.0913627]\n",
      "\t_long_any: 0.09136270059386992, _short_any: 0.9086372994061302\n",
      "i: 1, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.854999 0 0.145001]\n",
      "\t_long_any: 0.14500085755298642, _short_any: 0.8549991424470136\n",
      "i: 2, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.112659 0 0.887341]\n",
      "\t_long_any: 0.8873413291356902, _short_any: 0.11265867086431011\n",
      "i: 3, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.907583 0 0.0924174]\n",
      "\t_long_any: 0.0924173764423609, _short_any: 0.9075826235576395\n",
      "i: 4, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.20752 0.532761 0.0379864 0.221733]\n",
      "\t_long_any: 0.25971918846234027, _short_any: 0.7402808115376588\n",
      "i: 5, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.868273 0 0.131727]\n",
      "\t_long_any: 0.1317270899715942, _short_any: 0.8682729100284059\n",
      "i: 6, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.903466 0 0.0965343]\n",
      "\t_long_any: 0.09653431439721868, _short_any: 0.9034656856027808\n",
      "i: 7, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0 0.715618 0 0.284382]\n",
      "\t_long_any: 0.28438176163142376, _short_any: 0.7156182383685763\n",
      "i: 8, np.shape(a_single_time_bin_raw_posterior): (59, 4)\n",
      "\tnp.shape(_decoder_prob_arr): (4,), _decoder_prob_arr: [0.185532 0.278758 0.286549 0.249161]\n",
      "\t_long_any: 0.5357102219368333, _short_any: 0.464289778063168\n",
      "long_LR: filtered_decoder_filter_epochs_decoder_result_dict[long_LR].decoding_time_bin_size: 0.025\n",
      "long_RL: filtered_decoder_filter_epochs_decoder_result_dict[long_RL].decoding_time_bin_size: 0.025\n",
      "short_LR: filtered_decoder_filter_epochs_decoder_result_dict[short_LR].decoding_time_bin_size: 0.025\n",
      "short_RL: filtered_decoder_filter_epochs_decoder_result_dict[short_RL].decoding_time_bin_size: 0.025\n",
      "saved image to: \"K:/scratch/collected_outputs/figures/array_as_image/kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0/ripple_159/all_decoders_posteriors_and_rasters_stack_image.png\"\n",
      "exported to 'K:\\scratch\\collected_outputs\\figures\\array_as_image\\kdiba_gor01_one_2006-6-12_15-55-31_normal_computed_[1, 2, 4, 6, 7, 8, 9]_5.0\\ripple_159'\n"
     ]
    }
   ],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "\n",
    "## INPUTS: \n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders'] # uses `DirectionalMergedDecoders`.\n",
    "\n",
    "\n",
    "# root_export_path: Path = Path(r\"/media/halechr/MAX/cloud/University of Michigan Dropbox/Pho Hale/Pho Diba Paper 2023/array_as_image\").resolve() # Lab\n",
    "root_export_path: Path = Path(r'K:/scratch/collected_outputs/figures/array_as_image').resolve()\n",
    "# root_export_path: Path = Path(r'C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\EXTERNAL\\Screenshots\\ProgrammaticDisplayFunctionTesting\\array_as_image').resolve()\n",
    "root_export_path.mkdir(exist_ok=True)\n",
    "Assert.path_exists(root_export_path)\n",
    "\n",
    "complete_session_context, (session_context, additional_session_context) = curr_active_pipeline.get_complete_session_context()\n",
    "epoch_specific_folder, (out_image_save_tuple_dict, _out_rasters_save_paths, merged_img_save_path) = paginated_multi_decoder_decoded_epochs_window.export_current_epoch_marginal_and_raster_images(directional_merged_decoders_result=directional_merged_decoders_result, root_export_path=root_export_path, active_context=complete_session_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795876fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: paginated_multi_decoder_decoded_epochs_window\n",
    "attached_ripple_rasters_widget: RankOrderRastersDebugger = paginated_multi_decoder_decoded_epochs_window.attached_ripple_rasters_widget\n",
    "_out_ripple_rasters = paginated_multi_decoder_decoded_epochs_window\n",
    "epoch_specific_folder, (out_image_save_tuple_dict, _out_rasters_save_paths, merged_img_save_path) = PosteriorExporting._perform_export_current_epoch_marginal_and_raster_images(_out_ripple_rasters=_out_ripple_rasters, directional_merged_decoders_result=directional_merged_decoders_result, \n",
    "    filtered_decoder_filter_epochs_decoder_result_dict=decoder_ripple_filter_epochs_decoder_result_dict, epoch_id_identifier_str='ripple',\n",
    "    # filtered_decoder_filter_epochs_decoder_result_dict=decoder_laps_filter_epochs_decoder_result_dict, epoch_id_identifier_str='lap',\n",
    "    active_session_context=curr_context, \n",
    "    root_export_path = root_export_path,\n",
    ")\n",
    "\n",
    "file_uri_from_path(epoch_specific_folder)\n",
    "fullwidth_path_widget(a_path=epoch_specific_folder, file_name_label=\"epoch_specific_folder:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996c72e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders'] # uses `DirectionalMergedDecoders`.\n",
    "\n",
    "# root_export_path: Path = Path(r'C:\\Users\\pho\\repos\\Spike3DWorkEnv\\Spike3D\\EXTERNAL\\Screenshots\\ProgrammaticDisplayFunctionTesting\\array_as_image').resolve()\n",
    "root_export_path: Path = Path(r'K:/scratch/collected_outputs/figures/array_as_image').resolve()\n",
    "root_export_path.mkdir(exist_ok=True)\n",
    "Assert.path_exists(root_export_path)\n",
    "\n",
    "complete_session_context, (session_context, additional_session_context) = curr_active_pipeline.get_complete_session_context()\n",
    "\n",
    "## INPUTS: paginated_multi_decoder_decoded_epochs_window\n",
    "attached_ripple_rasters_widget: RankOrderRastersDebugger = paginated_multi_decoder_decoded_epochs_window.attached_ripple_rasters_widget\n",
    "_out_ripple_rasters = paginated_multi_decoder_decoded_epochs_window\n",
    "epoch_specific_folder, (out_image_save_tuple_dict, _out_rasters_save_paths, merged_img_save_path) = PosteriorExporting._perform_export_current_epoch_marginal_and_raster_images(_out_ripple_rasters=attached_ripple_rasters_widget, directional_merged_decoders_result=directional_merged_decoders_result, \n",
    "    filtered_decoder_filter_epochs_decoder_result_dict=decoder_ripple_filter_epochs_decoder_result_dict, epoch_id_identifier_str='ripple',\n",
    "    # filtered_decoder_filter_epochs_decoder_result_dict=decoder_laps_filter_epochs_decoder_result_dict, epoch_id_identifier_str='lap',\n",
    "    active_session_context=complete_session_context, \n",
    "    root_export_path = root_export_path,\n",
    ")\n",
    "\n",
    "file_uri_from_path(epoch_specific_folder)\n",
    "fullwidth_path_widget(a_path=epoch_specific_folder, file_name_label=\"epoch_specific_folder:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7051885",
   "metadata": {},
   "source": [
    "### <a id='toc12_1_4_'></a>[2024-02-29 3pm - Get the active user-annotated epoch times from the `paginated_multi_decoder_decoded_epochs_window` and use these to filter `filtered_ripple_simple_pf_pearson_merged_df`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767317a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Inputs: paginated_multi_decoder_decoded_epochs_window\n",
    "any_good_selected_epoch_times = deepcopy(paginated_multi_decoder_decoded_epochs_window.any_good_selected_epoch_times)\n",
    "any_good_selected_epoch_indicies = deepcopy(paginated_multi_decoder_decoded_epochs_window.find_data_indicies_from_epoch_times(paginated_multi_decoder_decoded_epochs_window.any_good_selected_epoch_times))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bc2a41",
   "metadata": {},
   "source": [
    "## <a id='toc12_2_'></a>[:✅:🎯 2024-09-27 - Test programmatic/background saving of stacked decoded epoch figures](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7d0436",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_laps_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict)\n",
    "unfiltered_laps_epochs_df = deepcopy(decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)\n",
    "filtered_decoder_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(filtered_epochs_df[['start', 'stop']].to_numpy()) for a_name, a_result in decoder_ripple_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "\n",
    "laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "print(f'{pos_bin_size = }, {laps_decoding_time_bin_size = }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae48eec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using: perform_export_all_decoded_posteriors_as_images\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import HeatmapExportConfig, PosteriorExporting\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import HeatmapExportKind\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import Assert\n",
    "\n",
    "## INPUTS:: filtered_decoder_filter_epochs_decoder_result_dict, long_like_during_post_delta_only_filter_epochs\n",
    "active_epochs_decoder_result_dict = deepcopy(filtered_decoder_filter_epochs_decoder_result_dict)\n",
    "parent_output_folder = Path('output/array_to_images').resolve()\n",
    "\n",
    "# active_epochs_decoder_result_dict = deepcopy(long_like_during_post_delta_only_filtered_decoder_filter_epochs_decoder_result_dict)\n",
    "# parent_output_folder = Path('output/long_like_during_post_delta').resolve()\n",
    "\n",
    "\n",
    "# active_epochs_decoder_result_dict = deepcopy(filtered_decoder_filter_epochs_decoder_result_dict)\n",
    "\n",
    "\n",
    "## Laps:\n",
    "active_epochs_decoder_result_dict = deepcopy(decoder_laps_filter_epochs_decoder_result_dict)\n",
    "\n",
    "\n",
    "\n",
    "parent_output_folder.mkdir(exist_ok=True)\n",
    "Assert.path_exists(parent_output_folder)\n",
    "posterior_out_folder = parent_output_folder.joinpath(DAY_DATE_TO_USE).resolve()\n",
    "posterior_out_folder.mkdir(parents=True, exist_ok=True)\n",
    "save_path = posterior_out_folder.resolve()\n",
    "_parent_save_context: IdentifyingContext = curr_active_pipeline.build_display_context_for_session('perform_export_all_decoded_posteriors_as_images')\n",
    "_specific_session_output_folder = save_path.joinpath(active_context.get_description(subset_excludelist=['format_name'])).resolve()\n",
    "_specific_session_output_folder.mkdir(parents=True, exist_ok=True)\n",
    "print(f'\\tspecific_session_output_folder: \"{_specific_session_output_folder}\"')\n",
    "\n",
    "custom_export_formats: Dict[str, HeatmapExportConfig] = {\n",
    "    # 'greyscale': HeatmapExportConfig.init_greyscale(desired_height=1200),\n",
    "    'color': HeatmapExportConfig.init_for_export_kind(export_kind=HeatmapExportKind.COLORMAPPED, colormap='Oranges', desired_height=1200),\n",
    "    # 'color': HeatmapExportConfig(colormap=additional_cmaps['long_LR']),\n",
    "    # 'color': HeatmapExportConfig(colormap=cmap1, desired_height=200),\n",
    "\t# 'raw_rgba': HeatmapExportConfig.init_for_export_kind(export_kind=HeatmapExportKind.RAW_RGBA, lower_bound_alpha=0.1, drop_below_threshold=1e-2, desired_height=1200),\n",
    "\t# 'raw_rgba': HeatmapExportConfig.init_for_export_kind(export_kind=HeatmapExportKind.RAW_RGBA, \n",
    "    #                                                     raw_RGBA_only_parameters = dict(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), xbin=deepcopy(a_decoder.xbin), lower_bound_alpha=0.1, drop_below_threshold=1e-2, t_bin_size=0.025),\n",
    "    #                                                     desired_height=1200),\n",
    "}\n",
    "# custom_export_formats = None\n",
    "\n",
    "\n",
    "# `raw_RGBA_only_parameters` dict with keys: ['spikes_df', 'xbin', 'lower_bound_alpha', 'drop_below_threshold', 't_bin_size']\n",
    "\n",
    "\n",
    "out_paths, out_custom_formats_dict = PosteriorExporting.perform_export_all_decoded_posteriors_as_images(decoder_laps_filter_epochs_decoder_result_dict=None, decoder_ripple_filter_epochs_decoder_result_dict=active_epochs_decoder_result_dict,\n",
    "# out_paths, out_custom_formats_dict = PosteriorExporting.perform_export_all_decoded_posteriors_as_images(decoder_laps_filter_epochs_decoder_result_dict=deepcopy(decoder_laps_filter_epochs_decoder_result_dict), decoder_ripple_filter_epochs_decoder_result_dict=None,\n",
    "                                                                                                            _save_context=_parent_save_context, parent_output_folder=_specific_session_output_folder,\n",
    "                                                                                                            desired_height=1200, custom_export_formats=custom_export_formats, combined_img_padding=6, combined_img_separator_color=(0, 0, 0, 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51933623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26558aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_uri_from_path(_specific_session_output_folder)\n",
    "fullwidth_path_widget(a_path=_specific_session_output_folder, file_name_label=\"epoch_specific_folder:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fcf49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_new_fully_generic_result.get_results_matching_contexts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58598b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['generalized_specific_epochs_decoding'],\n",
    "                        computation_kwargs_list=[{'epochs_decoding_time_bin_size': time_bin_size, 'drop_previous_result_and_compute_fresh': True, 'force_recompute': False}], \n",
    "                        enabled_filter_names=None, fail_on_exception=True, debug_print=False) \n",
    "\n",
    "# 11m 5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8607a51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# pbe_trained_decoder_search_context = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, known_named_decoding_epochs_type='pbe', masked_time_bin_fill_type=('ignore', 'nan_filled', 'dropped'), data_grain='per_time_bin') # , decoder_identifier='pseudo2D', data_grain= 'per_time_bin -- not really relevant: ['masked_time_bin_fill_type', 'known_named_decoding_epochs_type', 'data_grain']\n",
    "# laps_trained_decoder_search_context = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='laps', masked_time_bin_fill_type='dropped', data_grain='per_time_bin')\n",
    "pbe_trained_decoder_search_context = IdentifyingContext()\n",
    "flat_context_list, flat_result_context_dict, flat_decoder_context_dict, flat_decoded_marginal_posterior_df_context_dict = a_new_fully_generic_result.get_results_matching_contexts(context_query=pbe_trained_decoder_search_context, return_multiple_matches=True, debug_print=False)\n",
    "flat_context_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0924b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "[Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_time_bin'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'nan_filled'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'dropped', data_grain= 'per_epoch'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'non_pbe_endcaps', masked_time_bin_fill_type= 'dropped', data_grain= 'per_time_bin', decoding_time_bin_size= 0.025),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'non_pbe', masked_time_bin_fill_type= 'last_valid'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'global', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'nan_filled'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'ignore'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'dropped', data_grain= 'per_time_bin'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'non_pbe_endcaps', masked_time_bin_fill_type= 'last_valid', data_grain= 'per_time_bin', decoding_time_bin_size= 0.025),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_epoch'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'global', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_time_bin'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'non_pbe_endcaps', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin', decoding_time_bin_size= 0.025),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'non_pbe', masked_time_bin_fill_type= 'ignore'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'non_pbe_endcaps', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_time_bin', decoding_time_bin_size= 0.025),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'ignore'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'last_valid'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'dropped', data_grain= 'per_epoch'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'laps'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'nan_filled'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'ignore', data_grain= 'per_epoch'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_time_bin'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'dropped', data_grain= 'per_time_bin'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'nan_filled'),\n",
    " Context(trained_compute_epochs= 'non_pbe', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'dropped', data_grain= 'per_time_bin'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'nan_filled', data_grain= 'per_epoch'),\n",
    " Context(trained_compute_epochs= 'non_pbe', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore', data_grain= 'per_time_bin'),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025),\n",
    " Context(trained_compute_epochs= 'laps', pfND_ndim= 1, decoder_identifier= 'pseudo2D', time_bin_size= 0.025, known_named_decoding_epochs_type= 'laps', masked_time_bin_fill_type= 'ignore', data_grain= 'per_epoch'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'non_pbe', masked_time_bin_fill_type= 'nan_filled'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'non_pbe'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'pbe'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'dropped', data_grain= 'per_time_bin'),\n",
    " Context(trained_compute_epochs= 'non_pbe', known_named_decoding_epochs_type= 'pbe', masked_time_bin_fill_type= 'last_valid')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2ceb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_epoch_specific_decoded_results1D_dict, continuous_specific_decoded_results1D_dict, new_decoder1D_dict, new_pf1Ds_dict = self.recompute(curr_active_pipeline=curr_active_pipeline, pfND_ndim=1, epochs_decoding_time_bin_size=epochs_decoding_time_bin_size, skip_training_test_split=skip_training_test_split)\n",
    "frame_divided_epochs_specific_decoded_results1D_dict = {a_name:a_new_decoder.decode_specific_epochs(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), filter_epochs=deepcopy(global_frame_divided_epochs_obj), decoding_time_bin_size=epochs_decoding_time_bin_size, debug_print=False) for a_name, a_new_decoder in new_decoder1D_dict.items()}\n",
    "results1D = DecodingResultND(ndim=1, \n",
    "    test_epoch_results=test_epoch_specific_decoded_results1D_dict, \n",
    "    continuous_results=continuous_specific_decoded_results1D_dict,\n",
    "    decoders=new_decoder1D_dict, pfs=new_pf1Ds_dict,\n",
    "    frame_divided_epochs_results=frame_divided_epochs_specific_decoded_results1D_dict, \n",
    "    frame_divided_epochs_df=deepcopy(global_frame_divided_epochs_df), pos_df=global_pos_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5807baf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get epochs to decode:\n",
    "\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "global_session = curr_active_pipeline.filtered_sessions[global_epoch_name]\n",
    "\n",
    "# global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "global_laps = ensure_Epoch(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps.to_dataframe())) # .trimmed_to_non_overlapping()\n",
    "global_PBEs = ensure_Epoch(deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].pbe)) # .trimmed_to_non_overlapping()\n",
    "\n",
    "epochs_to_decode_dict: Dict = {'laps': global_laps, 'pbe': global_PBEs}\n",
    "## OUTPUTS: epochs_to_decode_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01da635",
   "metadata": {
    "tags": [
     "2025-05-30"
    ]
   },
   "outputs": [],
   "source": [
    "## INPUTS: curr_active_pipeline, epochs_decoding_time_bin_size, epochs_to_decode_dict, a_new_fully_generic_result\n",
    "\n",
    "## UPDATES: a_new_fully_generic_result\n",
    "\n",
    "decoders_dict: Dict[types.DecoderName, BasePositionDecoder] = deepcopy(track_templates.get_decoders_dict())\n",
    "laps_trained_decoder_search_context = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, masked_time_bin_fill_type='ignore', data_grain='per_time_bin') # , data_grain= 'per_time_bin -- not really relevant: ['masked_time_bin_fill_type', 'known_named_decoding_epochs_type', 'data_grain']\n",
    "\n",
    "## Can add:     known_named_decoding_epochs_type='laps', \n",
    "out_dict = {}\n",
    "\n",
    "for a_decoder_name, a_decoder in decoders_dict.items():\n",
    "    ## for each decoder\n",
    "    for an_epoch_to_decode_name, an_epochs_to_decode_obj in epochs_to_decode_dict.items():\n",
    "        ## for each epoch to decode\n",
    "        a_context: IdentifyingContext = deepcopy(laps_trained_decoder_search_context).overwriting_context(decoder_identifier=a_decoder_name, known_named_decoding_epochs_type=an_epoch_to_decode_name)        \n",
    "        a_result: DecodedFilterEpochsResult = a_decoder.decode_specific_epochs(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), filter_epochs=deepcopy(an_epochs_to_decode_obj), decoding_time_bin_size=epochs_decoding_time_bin_size, debug_print=False)\n",
    "        a_new_fully_generic_result.updating_results_for_context(new_context=a_context, a_result=a_result, a_decoder=deepcopy(a_decoder), a_decoded_marginal_posterior_df=None, an_epoch_to_decode=deepcopy(an_epochs_to_decode_obj)) ## update using the result\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b1a689",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict[a_context]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c6757c",
   "metadata": {},
   "source": [
    "# ❌ 2025-05-04 - 11am - New Overlayed plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8880f92f",
   "metadata": {
    "tags": [
     "run-group-mergedcolorplot"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _helper_add_interpolated_position_columns_to_decoded_result_df\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import MultiDecoderColorOverlayedPosteriors\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import EpochComputationFunctions, EpochComputationsComputationsContainer\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import SingleEpochDecodedResult\n",
    "\n",
    "\n",
    "valid_EpochComputations_result: EpochComputationsComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['EpochComputations']\n",
    "a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult = valid_EpochComputations_result.a_generic_decoder_dict_decoded_epochs_dict_result\n",
    "all_decoder_colors_dict = {'long': '#4169E1', 'short': '#DC143C', 'long_LR': '#4169E1', 'long_RL': '#607B00', 'short_LR': '#DC143C', 'short_RL': '#990099'} ## Just hardcoded version of `additional_cmap_names`\n",
    "\n",
    "## INPUTS: a_new_fully_generic_result\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='nan_filled', data_grain='per_time_bin')\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='ignore', data_grain='per_time_bin')\n",
    "best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=a_target_context, debug_print=False)\n",
    "## OUTPUTS: a_result, a_decoder, a_decoded_marginal_posterior_df\n",
    "## INPUTS: curr_active_pipeline, a_result, a_decoder, a_decoded_marginal_posterior_df\n",
    "global_measured_position_df: pd.DataFrame = deepcopy(curr_active_pipeline.sess.position.to_dataframe())\n",
    "a_decoded_marginal_posterior_df: pd.DataFrame = _helper_add_interpolated_position_columns_to_decoded_result_df(a_result=a_result, a_decoder=a_decoder, a_decoded_marginal_posterior_df=a_decoded_marginal_posterior_df, global_measured_position_df=global_measured_position_df)\n",
    "\n",
    "global_decoded_result: SingleEpochDecodedResult = a_result.get_result_for_epoch(0)\n",
    "p_x_given_n: NDArray[ND.Shape[\"N_POS_BINS, 4, N_TIME_BINS\"], np.floating] = deepcopy(global_decoded_result.p_x_given_n) # .shape # (59, 4, 69488)\n",
    "time_bin_centers: NDArray[ND.Shape[\"N_TIME_BINS\"], np.floating] = deepcopy(global_decoded_result.time_bin_container.centers)\n",
    "xbin: NDArray[ND.Shape[\"N_POS_BINS\"], np.floating] = deepcopy(a_decoder.xbin)\n",
    "\n",
    "# with VizTracer(output_file=f\"viztracer_{get_now_time_str()}-MultiDecoderColorOverlayedPosteriors.json\", min_duration=200, tracer_entries=3000000, ignore_frozen=True) as tracer:\n",
    "multi_decoder_color_overlay: MultiDecoderColorOverlayedPosteriors = MultiDecoderColorOverlayedPosteriors(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), p_x_given_n=p_x_given_n, time_bin_centers=time_bin_centers, xbin=xbin, lower_bound_alpha=0.0, drop_below_threshold=1e-3, t_bin_size=0.025)\n",
    "multi_decoder_color_overlay.compute_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a846a220",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = multi_decoder_color_overlay.add_tracks_to_spike_raster_window(active_2d_plot=active_2d_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77b4a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ccd339",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb62af58",
   "metadata": {},
   "source": [
    "# :🔝💯🟢🖼️ 2025-05-16 - Export Overlayed Plots for Pseudo2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ce6986",
   "metadata": {},
   "source": [
    "### Main Figure Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ef555b",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'],\n",
    "                                                  # computation_kwargs_list=[{'time_bin_size': 0.016, 'should_disable_cache':False}], \n",
    "                                                  computation_kwargs_list=[{'time_bin_size': 0.025, 'should_disable_cache':True}], \n",
    "                                                  # computation_kwargs_list=[{'time_bin_size': 0.058, 'should_disable_cache':False}], \n",
    "                                                  enabled_filter_names=None, fail_on_exception=True, debug_print=True)\n",
    "# curr_active_pipeline.perform_specific_computation(computation_functions_name_includelist=['directional_decoders_decode_continuous'], computation_kwargs_list=[{'time_bin_size': 0.058}], #computation_kwargs_list=[{'time_bin_size': 0.025}], \n",
    "#                                                   enabled_filter_names=None, fail_on_exception=True, debug_print=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0506efaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.EpochComputationFunctions import EpochComputationDisplayFunctions\n",
    "import pyphoplacecellanalysis.General.type_aliases as types\n",
    "\n",
    "curr_active_pipeline.reload_default_computation_functions()\n",
    "\n",
    "time_bin_size: float = 0.025\n",
    "_out = EpochComputationDisplayFunctions._display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay(curr_active_pipeline, None, None, None, include_includelist=None, save_figure=True, parent_output_folder=collected_outputs_path, time_bin_size=time_bin_size)\n",
    "\n",
    "# curr_active_pipeline.plot\n",
    "# curr_active_pipeline.registered_display_function_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b2f7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization ______________________________________________________________________________________________________ #\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow, LayoutScrollability\n",
    "from pyphocorehelpers.plotting.media_output_helpers import vertical_image_stack, horizontal_image_stack, image_grid # used in `_subfn_build_combined_output_images`\n",
    "from pyphocorehelpers.image_helpers import ImageHelpers\n",
    "\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import HeatmapExportConfig, HeatmapExportKind\n",
    "\n",
    "out_paths: Dict[types.KnownNamedDecoderTrainedComputeEpochsType, Dict[types.DecoderName, Path]] = _out['out_paths']\n",
    "out_custom_formats_dict: Dict[types.KnownNamedDecodingEpochsType, Dict[types.DecoderName, Dict[str, List[HeatmapExportConfig]]]] = _out['out_custom_formats_dict']\n",
    "\n",
    "out_custom_formats_dict: Dict = _out['out_custom_formats_dict']\n",
    "\n",
    "# flat_imgs = []\n",
    "\n",
    "flat_imgs_dict: Dict[IdentifyingContext, List] = {}\n",
    "flat_merged_images = {}\n",
    "\n",
    "\n",
    "for a_series_name, v_dict in out_custom_formats_dict.items():\n",
    "    # a_series_name: ['laps', 'ripple']\n",
    "    for a_decoder_name, a_rendered_configs_dict in v_dict.items():\n",
    "        \n",
    "        for a_config_name, a_rendered_config_list in a_rendered_configs_dict.items():\n",
    "            # 'raw_rgba'\n",
    "            # print(a_rendered_config_list)\n",
    "            # len(a_rendered_config_list)\n",
    "            \n",
    "            a_ctxt = IdentifyingContext(series=a_series_name, decoder=a_decoder_name, config=a_config_name)\n",
    "            flat_imgs = []\n",
    "            \n",
    "            for i, a_config in enumerate(a_rendered_config_list):      \n",
    "                # posterior_save_path = a_config.posterior_saved_path\n",
    "                _posterior_image = a_config.posterior_saved_image\n",
    "                flat_imgs.append(_posterior_image)\n",
    "                \n",
    "                # print(F'a_rendered_config: {type(a_rendered_config)}')\n",
    "                # type(a_rendered_config_list[0])\n",
    "                # print(F'a_rendered_config: {list(a_rendered_config.keys())}')\n",
    "                # file_uri_from_path(a_path)\n",
    "                # fullwidth_path_widget(a_path=a_path, file_name_label=f\"{a_series_name}[{a_decoder_name}]:\")\n",
    "                # flat_img_out_paths.append(a_path)\n",
    "            ## END  for i, a_config in enum...\n",
    "            ## OUTPUTS: flat_imgs\n",
    "            _merged_img = horizontal_image_stack(flat_imgs, padding=10, separator_color='white')\n",
    "            flat_merged_images[a_series_name] = _merged_img\n",
    "            flat_imgs_dict[a_ctxt] = flat_imgs\n",
    "            \n",
    "\n",
    "# flat_img_out_paths\n",
    "flat_merged_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9328b4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_imgs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398079d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flat_merged_images['laps'].show()\n",
    "\n",
    "flat_merged_images['ripple'].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fabb1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show output paths:\n",
    "\n",
    "flat_img_out_paths = []\n",
    "out_paths = deepcopy(_out['out_paths'])\n",
    "for a_series_name, v_dict in out_paths.items():\n",
    "    # a_series_name: ['laps', 'ripple']\n",
    "    for a_decoder_name, a_path in v_dict.items():\n",
    "        file_uri_from_path(a_path)\n",
    "        fullwidth_path_widget(a_path=a_path, file_name_label=f\"{a_series_name}[{a_decoder_name}]:\")\n",
    "        flat_img_out_paths.append(a_path)\n",
    "        \n",
    "flat_img_out_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c852e01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from benedict import benedict\n",
    "\n",
    "out_custom_formats_dict = benedict(out_custom_formats_dict)\n",
    "out_custom_formats_dict.keypaths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee530a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = dict()\n",
    "_out['trackID_weighted_position_posterior'] = curr_active_pipeline.display(display_function='_display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay', active_session_configuration_context=None) # _display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d60a631",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# _out = curr_active_pipeline.display('_display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay')\n",
    "_out = curr_active_pipeline.display('trackID_weighted_position_posterior')\n",
    "\n",
    "# 'trackID_weighted_position_posterior'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e387d7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using: perform_export_all_decoded_posteriors_as_images\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import HeatmapExportConfig, PosteriorExporting\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import HeatmapExportKind\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import Assert\n",
    "\n",
    "## INPUTS:: filtered_decoder_filter_epochs_decoder_result_dict, long_like_during_post_delta_only_filter_epochs\n",
    "# active_epochs_decoder_result_dict = deepcopy(filtered_decoder_filter_epochs_decoder_result_dict)\n",
    "parent_output_folder = Path('output/array_to_images').resolve()\n",
    "\n",
    "## Build a makeshift dict with just the pseudo2D in it:\n",
    "## INPUTS:\n",
    "a_decoder = deepcopy(flat_decoder_context_dict[active_ctxts[0]])\n",
    "# a_decoder = deepcopy(a_laps_trained_decoder)\n",
    "\n",
    "## INPUTS: active_epochs_decoder_result_dict\n",
    "\n",
    "parent_output_folder.mkdir(exist_ok=True)\n",
    "Assert.path_exists(parent_output_folder)\n",
    "posterior_out_folder = parent_output_folder.joinpath(DAY_DATE_TO_USE).resolve()\n",
    "posterior_out_folder.mkdir(parents=True, exist_ok=True)\n",
    "save_path = posterior_out_folder.resolve()\n",
    "_parent_save_context: IdentifyingContext = curr_active_pipeline.build_display_context_for_session('perform_export_all_decoded_posteriors_as_images')\n",
    "_specific_session_output_folder = save_path.joinpath(active_context.get_description(subset_excludelist=['format_name'])).resolve()\n",
    "_specific_session_output_folder.mkdir(parents=True, exist_ok=True)\n",
    "print(f'\\tspecific_session_output_folder: \"{_specific_session_output_folder}\"')\n",
    "\n",
    "custom_export_formats: Dict[str, HeatmapExportConfig] = {\n",
    "\t# 'raw_rgba': HeatmapExportConfig.init_for_export_kind(export_kind=HeatmapExportKind.RAW_RGBA, lower_bound_alpha=0.1, drop_below_threshold=1e-2, desired_height=1200),\n",
    "\t'raw_rgba': HeatmapExportConfig.init_for_export_kind(export_kind=HeatmapExportKind.RAW_RGBA, \n",
    "                                                        raw_RGBA_only_parameters = dict(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), xbin=deepcopy(a_decoder.xbin), lower_bound_alpha=0.1, drop_below_threshold=1e-2, t_bin_size=0.025,  use_four_decoders_version=False),\n",
    "                                                        desired_height=1200),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\t# 'raw_rgba_four_decoders': HeatmapExportConfig.init_for_export_kind(export_kind=HeatmapExportKind.RAW_RGBA, \n",
    "    #                                                     raw_RGBA_only_parameters = dict(spikes_df=deepcopy(get_proper_global_spikes_df(curr_active_pipeline)), xbin=deepcopy(a_decoder.xbin), lower_bound_alpha=0.1, drop_below_threshold=1e-2, t_bin_size=0.025,  use_four_decoders_version=True),\n",
    "    #                                                     desired_height=1200),\n",
    "\n",
    "}\n",
    "# custom_export_formats = None\n",
    "\n",
    "out_paths, out_custom_formats_dict = PosteriorExporting.perform_export_all_decoded_posteriors_as_images(decoder_laps_filter_epochs_decoder_result_dict=decoder_laps_filter_epochs_decoder_result_dict, decoder_ripple_filter_epochs_decoder_result_dict=decoder_ripple_filter_epochs_decoder_result_dict,\n",
    "# out_paths, out_custom_formats_dict = PosteriorExporting.perform_export_all_decoded_posteriors_as_images(decoder_laps_filter_epochs_decoder_result_dict=deepcopy(decoder_laps_filter_epochs_decoder_result_dict), decoder_ripple_filter_epochs_decoder_result_dict=None,\n",
    "                                                                                                            _save_context=_parent_save_context, parent_output_folder=_specific_session_output_folder,\n",
    "                                                                                                            desired_height=1200, custom_export_formats=custom_export_formats, combined_img_padding=6, combined_img_separator_color=(0, 0, 0, 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cde5cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_uri_from_path(_specific_session_output_folder)\n",
    "fullwidth_path_widget(a_path=_specific_session_output_folder, file_name_label=\"epoch_specific_folder:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a74abe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v_dict in out_paths.items():\n",
    "    for a_decoder_name, a_path in v_dict.items():\n",
    "        file_uri_from_path(a_path)\n",
    "        fullwidth_path_widget(a_path=a_path, file_name_label=f\"{k}[{a_decoder_name}]:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceec6d6",
   "metadata": {},
   "source": [
    "## 2025-05-19 - Re-loading the exported images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48521d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "from neuropy.utils.result_context import DisplaySpecifyingIdentifyingContext\n",
    "from pyphocorehelpers.assertion_helpers import Assert\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorPlottingDatasource, LoadedPosteriorContainer\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import H5FileAggregator\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "from neuropy.utils.result_context import DisplaySpecifyingIdentifyingContext\n",
    "from pyphoplacecellanalysis.Pho2D.data_exporting import LoadedPosteriorContainer\n",
    "from neuropy.utils.indexing_helpers import flatten, flatten_dict\n",
    "from pyphoplacecellanalysis.SpecificResults.AcrossSessionResults import AcrossSessionIdentityDataframeAccessor\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.computer_vision import ComputerVisionComputations\n",
    "\n",
    "# Visualization ______________________________________________________________________________________________________ #\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.BinnedImageRenderingWindow import BasicBinnedImageRenderingWindow, LayoutScrollability\n",
    "from pyphocorehelpers.plotting.media_output_helpers import vertical_image_stack, horizontal_image_stack, image_grid # used in `_subfn_build_combined_output_images`\n",
    "from pyphocorehelpers.image_helpers import ImageHelpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ab168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Using pathlib (more modern approach)\n",
    "\n",
    "# Example usage:\n",
    "a_path = flat_img_out_paths[0].joinpath('raw_rgba').resolve()\n",
    "Assert.path_exists(a_path)\n",
    "print(f'a_path: {a_path}')\n",
    "# parent_output_folder = Path('output/array_to_images').resolve()\n",
    "images_dict = ImageHelpers.load_png_images_pathlib(a_path)\n",
    "\n",
    "# Print the loaded images\n",
    "print(f\"Loaded {len(images_dict)} PNG images:\")\n",
    "# for name, img in images_dict.items():\n",
    "#     print(f\"{name}: {img.format}, {img.size}, {img.mode}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22664bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.data_exporting import PosteriorExporting\n",
    "\n",
    "# specific_epochs_posterior_out_folder = Path('outputs/arr_as_image').resolve()\n",
    "# Assert.path_exists(specific_epochs_posterior_out_folder)\n",
    "\n",
    "_single_epoch_combined_img = horizontal_image_stack(list(images_dict.values()), padding=4, separator_color='white')\n",
    "_single_epoch_combined_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17f3a95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83e1970",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "try:\n",
    "    for custom_export_format_series_name in list(out_custom_export_formats_results_dict[list(out_custom_export_formats_results_dict.keys())[0]].keys()):\n",
    "        _output_combined_dir, _output_combined_image_save_dirs = PosteriorExporting._subfn_build_combined_output_images(single_known_epoch_type_dict=out_custom_export_formats_results_dict, specific_epochs_posterior_out_folder=specific_epochs_posterior_out_folder,\n",
    "                                                                                                    known_epoch_type_name=epochs_name, custom_export_format_series_name=custom_export_format_series_name,\n",
    "                                                                                                    combined_img_padding=4, combined_img_separator_color=None)\n",
    "        \n",
    "except (AssertionError, ValueError) as e:\n",
    "    print(f'WARN: failed to merge images to combined images at the end with error: {e}')\n",
    "except Exception as e:\n",
    "    print(f'WARN: failed to merge images to combined images at the end with error: {e}')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948252f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v_dict in out_paths.items():\n",
    "    for a_decoder_name, a_path in v_dict.items():\n",
    "        file_uri_from_path(a_path)\n",
    "        fullwidth_path_widget(a_path=a_path, file_name_label=f\"{k}[{a_decoder_name}]:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0944bb",
   "metadata": {},
   "source": [
    "## 2025-05-19 - Heuristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc020b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring, HeuristicsResult\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import SerializationHelper_AllCustomDecodingResults, SerializationHelper_CustomDecodingResults\n",
    "from numpy import ma\n",
    "from neuropy.core.epoch import ensure_dataframe\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "\n",
    "## INPUTS: track_templates, a_decoded_filter_epochs_decoder_result_dict\n",
    "decoder_track_length_dict = track_templates.get_track_length_dict() # {'long_LR': 214.0, 'long_RL': 214.0, 'short_LR': 144.0, 'short_RL': 144.0}\n",
    "same_thresh_fraction_of_track: float = 0.05 ## up to 5.0% of the track\n",
    "same_thresh_cm: float = {k:(v * same_thresh_fraction_of_track) for k, v in decoder_track_length_dict.items()}\n",
    "a_same_thresh_cm: float = same_thresh_cm['long_LR']\n",
    "max_jump_distance_cm: float = 60.0\n",
    "print(f'a_same_thresh_cm: {a_same_thresh_cm}')\n",
    "print(f'max_jump_distance_cm: {max_jump_distance_cm}')\n",
    "# print(list(HeuristicReplayScoring.build_all_score_computations_fn_dict().keys())) # ['jump', 'max_jump_cm', 'max_jump_cm_per_sec', 'ratio_jump_valid_bins', 'travel', 'coverage', 'sequential_correlation', 'monotonicity_score', 'laplacian_smoothness']\n",
    "\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps'] # DirectionalLapsResult\n",
    "# a_name: str = 'long_LR'\n",
    "# a_directional_decoders_epochs_decode_result: DecodedFilterEpochsResult = a_decoded_filter_epochs_decoder_result_dict[a_name]\n",
    "\n",
    "## INPUTS: curr_active_pipeline, track_templates, a_decoded_filter_epochs_decoder_result_dict\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = deepcopy(curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']) ## GENERAL\n",
    "a_decoded_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "a_decoded_filter_epochs_decoder_result_dict, _out_new_scores, partition_result_dict = HeuristicReplayScoring.compute_all_heuristic_scores(track_templates=track_templates, a_decoded_filter_epochs_decoder_result_dict=a_decoded_filter_epochs_decoder_result_dict,\n",
    "                                                                                                                                            max_ignore_bins=2, same_thresh_cm=a_same_thresh_cm, max_jump_distance_cm=max_jump_distance_cm)\n",
    "# # a_decoded_filter_epochs_decoder_result_dict\n",
    "a_heuristics_result = HeuristicsResult(heuristic_scores_df_dict=_out_new_scores, partition_result_dict=partition_result_dict)\n",
    "\n",
    "directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict = deepcopy(a_decoded_filter_epochs_decoder_result_dict)\n",
    "# directional_decoders_epochs_decode_result.build_complete_all_scores_merged_df\n",
    "curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations'] = directional_decoders_epochs_decode_result ## MIGHT NEED SAVING\n",
    "print(f'PIPELINE MIGHT NEED SAVING')\n",
    "## INPUTS: curr_active_pipeline, track_templates, a_decoded_filter_epochs_decoder_result_dict\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = deepcopy(curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']) ## GENERAL\n",
    "## INPUTS: directional_decoders_epochs_decode_result, filtered_epochs_df\n",
    "\n",
    "decoder_ripple_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict)\n",
    "unfiltered_epochs_df = deepcopy(decoder_ripple_filter_epochs_decoder_result_dict['long_LR'].filter_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a0c9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "unfiltered_epochs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb89ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_epochs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed89365",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _plot_heuristic_evaluation_epochs\n",
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import _perform_filter_replay_epochs\n",
    "\n",
    "# force_refilter = False\n",
    "force_refilter = True\n",
    "\n",
    "needs_refilter = False\n",
    "try:\n",
    "    filtered_decoder_filter_epochs_decoder_result_dict\n",
    "    filtered_epochs_df\n",
    "    filtered_ripple_all_epoch_bins_marginals_df\n",
    "    if filtered_decoder_filter_epochs_decoder_result_dict is not None:\n",
    "        needs_refilter = False\n",
    "except NameError:\n",
    "    needs_refilter = True\n",
    "    \n",
    "if needs_refilter or force_refilter:\n",
    "    filtered_epochs_df, filtered_decoder_filter_epochs_decoder_result_dict, filtered_ripple_all_epoch_bins_marginals_df = _perform_filter_replay_epochs(curr_active_pipeline, global_epoch_name, track_templates, decoder_ripple_filter_epochs_decoder_result_dict, ripple_all_epoch_bins_marginals_df, ripple_decoding_time_bin_size=ripple_decoding_time_bin_size, should_only_include_user_selected_epochs=True)\n",
    "\n",
    "## INPUTS: `filtered_epochs_df`\n",
    "if filtered_epochs_df is not None:\n",
    "    ## filter\n",
    "    filtered_decoder_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(filtered_epochs_df[['start', 'stop']].to_numpy()) for a_name, a_result in decoder_ripple_filter_epochs_decoder_result_dict.items()} # working filtered\n",
    "    high_heuristic_only_filtered_decoder_filter_epochs_decoder_result_dict = deepcopy(filtered_decoder_filter_epochs_decoder_result_dict)\n",
    "else:\n",
    "    filtered_decoder_filter_epochs_decoder_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = {a_name:a_result.filtered_by_epoch_times(unfiltered_epochs_df[['start', 'stop']].to_numpy()) for a_name, a_result in decoder_ripple_filter_epochs_decoder_result_dict.items()} # working unfiltered\n",
    "\n",
    "ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "print(f'{pos_bin_size = }, {ripple_decoding_time_bin_size = }')\n",
    "\n",
    "## OUTPUT: filtered_decoder_filter_epochs_decoder_result_dict, \n",
    "\n",
    "## 3m 2.2s\n",
    "# 59.1s\n",
    "\n",
    "# same_thresh_cm\n",
    "# a_result: DecodedFilterEpochsResult, an_epoch_idx: int, a_decoder_track_length: float, pos_bin_edges: NDArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fc5774",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_decoder_filter_epochs_decoder_result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c3f4fa",
   "metadata": {},
   "source": [
    "## <a id='toc11_2_'></a>[Find indicies that are included in `high_heuristic_only_filtered_decoder_filter_epochs_decoder_result_dict` from `filtered_decoder_filter_epochs_decoder_result_dict`](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e894afe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: high_heuristic_only_filtered_decoder_filter_epochs_decoder_result_dict, filtered_decoder_filter_epochs_decoder_result_dict\n",
    "# INPUTS: included_heuristic_ripple_start_times, high_heuristic_only_filtered_decoder_filter_epochs_decoder_result_dict, excluded_heuristic_ripple_start_times, low_heuristic_only_filtered_decoder_filter_epochs_decoder_result_dict\n",
    "\n",
    "example_decoder_name = 'long_LR'\n",
    "all_epoch_result: DecodedFilterEpochsResult = deepcopy(filtered_decoder_filter_epochs_decoder_result_dict[example_decoder_name])\n",
    "all_filter_epochs_df: pd.DataFrame = deepcopy(all_epoch_result.filter_epochs)\n",
    "\n",
    "included_filter_epoch_result: DecodedFilterEpochsResult = deepcopy(high_heuristic_only_filtered_decoder_filter_epochs_decoder_result_dict[example_decoder_name])\n",
    "# included_filter_epoch_result: DecodedFilterEpochsResult = deepcopy(low_heuristic_only_filtered_decoder_filter_epochs_decoder_result_dict[example_decoder_name])\n",
    "\n",
    "included_filter_epochs_df: pd.DataFrame = deepcopy(included_filter_epoch_result.filter_epochs)\n",
    "included_filter_epochs_df\n",
    "\n",
    "# included_filter_epoch_times = included_filter_epochs_df[['start', 'stop']].to_numpy() # Both 'start', 'stop' column matching\n",
    "included_filter_epoch_times = included_filter_epochs_df['start'].to_numpy() # Both 'start', 'stop' column matching\n",
    "\n",
    "included_filter_epoch_times_to_all_epoch_index_map = included_filter_epoch_result.find_epoch_times_to_data_indicies_map(epoch_times=included_filter_epoch_times)\n",
    "included_filter_epoch_times_to_all_epoch_index_arr: NDArray = included_filter_epoch_result.find_data_indicies_from_epoch_times(epoch_times=included_filter_epoch_times)\n",
    "len(included_filter_epoch_times_to_all_epoch_index_arr)\n",
    "\n",
    "## OUTPUTS: all_filter_epochs_df, all_filter_epochs_df\n",
    "## OUTPUTS: included_filter_epoch_times_to_all_epoch_index_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f31556",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_active_pipeline.reload_default_display_functions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a12dd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out = dict()\n",
    "\n",
    "included_filter_epochs_df: pd.DataFrame = deepcopy(high_heuristic_only_filtered_decoder_filter_epochs_decoder_result_dict[example_decoder_name].filter_epochs)\n",
    "included_filter_epochs_df\n",
    "_out['trackID_weighted_position_posterior'] = curr_active_pipeline.display(display_function='_display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay', active_session_configuration_context=None, time_bin_size=0.025,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t    filter_epochs_ripple_df=deepcopy(included_filter_epochs_df),\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t) # _display_decoded_trackID_weighted_position_posterior_withMultiColorOverlay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72824473",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out['trackID_weighted_position_posterior']['out_paths']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b4dfb5",
   "metadata": {},
   "source": [
    "## <a id='toc11_3_'></a>[Add the high-heuristic PBEs as an interval-rect dataseries to the continuous viewer](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b130769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: included_filter_epochs_df\n",
    "\n",
    "## Extract the specific results:\n",
    "# included_filter_epochs_df\n",
    "\n",
    "\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.Specific2DRenderTimeEpochs import General2DRenderTimeEpochs, inline_mkColor\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.SpikeRasterWidgets.Spike2DRaster import Spike2DRaster\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.EpochRenderingMixin import EpochRenderingMixin, RenderedEpochsItemsContainer\n",
    "from pyphoplacecellanalysis.General.Model.Datasources.IntervalDatasource import IntervalsDatasource\n",
    "from neuropy.utils.mixins.time_slicing import TimeColumnAliasesProtocol\n",
    "\n",
    "\n",
    "## Use the three dataframes as separate Epoch series:\n",
    "updated_epochs_dfs_dict = {\n",
    "    'HighHeuristic': included_filter_epochs_df,\n",
    "}\n",
    "\n",
    "updated_epochs_formatting_dict = {\n",
    "    'HighHeuristic':dict(y_location=-10.0, height=7.5, pen_color=inline_mkColor('green', 0.8), brush_color=inline_mkColor('green', 0.5)),\n",
    "}\n",
    "\n",
    "required_vertical_offsets, required_interval_heights = EpochRenderingMixin.build_stacked_epoch_layout([1.0], epoch_render_stack_height=40.0, interval_stack_location='below') # ratio of heights to each interval\n",
    "stacked_epoch_layout_dict = {interval_key:dict(y_location=y_location, height=height) for interval_key, y_location, height in zip(list(updated_epochs_formatting_dict.keys()), required_vertical_offsets, required_interval_heights)} # Build a stacked_epoch_layout_dict to update the display\n",
    "# stacked_epoch_layout_dict # {'LapsAll': {'y_location': -3.6363636363636367, 'height': 3.6363636363636367}, 'LapsTrain': {'y_location': -21.818181818181817, 'height': 18.18181818181818}, 'LapsTest': {'y_location': -40.0, 'height': 18.18181818181818}}\n",
    "\n",
    "# replaces 'y_location', 'position' for each dict:\n",
    "updated_epochs_formatting_dict = {k:(v|stacked_epoch_layout_dict[k]) for k, v in updated_epochs_formatting_dict.items()}\n",
    "updated_epochs_formatting_dict\n",
    "\n",
    "# OUTPUTS: updated_epochs_dfs_dict, updated_epochs_formatting_dict\n",
    "## INPUTS: updated_epochs_dfs_dict\n",
    "updated_epochs_dfs_dict = {k:TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(df=v, required_columns_synonym_dict=IntervalsDatasource._time_column_name_synonyms) for k, v in updated_epochs_dfs_dict.items()}\n",
    "\n",
    "## Build interval datasources for them:\n",
    "updated_epochs_dfs_datasources_dict = {k:General2DRenderTimeEpochs.build_render_time_epochs_datasource(v) for k, v in updated_epochs_dfs_dict.items()}\n",
    "## INPUTS: active_2d_plot, train_test_split_laps_epochs_formatting_dict, train_test_split_laps_dfs_datasources_dict\n",
    "assert len(updated_epochs_formatting_dict) == len(updated_epochs_dfs_datasources_dict)\n",
    "for k, an_interval_ds in updated_epochs_dfs_datasources_dict.items():\n",
    "    an_interval_ds.update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, **(updated_epochs_formatting_dict[k] | kwargs)))\n",
    "\n",
    "## Full output: updated_epochs_dfs_datasources_dict\n",
    "# actually add the epochs:\n",
    "for k, an_interval_ds in updated_epochs_dfs_datasources_dict.items():\n",
    "    active_2d_plot.add_rendered_intervals(an_interval_ds, name=f'{k}', debug_print=False) # adds the interval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070d1bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94db2b0f",
   "metadata": {},
   "source": [
    "# TODONO - 2025-06-04 - Paper 2025 Figure Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37e253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Batch.BatchJobCompletion.BatchCompletionHandler import BatchSessionCompletionHandler\n",
    "from neuropy.utils.matplotlib_helpers import matplotlib_file_only\n",
    "from pyphoplacecellanalysis.SpecificResults.PhoDiba2023Paper import main_complete_figure_generations\n",
    "\n",
    "\n",
    "# self.try_complete_figure_generation_to_file(curr_active_pipeline, enable_default_neptune_plots=self.should_generate_all_plots)\n",
    "fail_on_exception: bool = False\n",
    "enable_default_neptune_plots = False\n",
    "completed_good: bool = False\n",
    "\n",
    "try:\n",
    "    ## To file only:\n",
    "    with matplotlib_file_only():\n",
    "        # Perform non-interactive Matplotlib operations with 'AGG' backend\n",
    "        # neptuner = batch_perform_all_plots(curr_active_pipeline, enable_neptune=True, neptuner=None)\n",
    "        main_complete_figure_generations(curr_active_pipeline, enable_default_neptune_plots=enable_default_neptune_plots, save_figures_only=True, save_figure=True)\n",
    "\n",
    "    # IF thst's done, clear all the plots:\n",
    "    # from matplotlib import pyplot as plt\n",
    "    # plt.close('all') # this takes care of the matplotlib-backed figures.\n",
    "    curr_active_pipeline.clear_display_outputs()\n",
    "    curr_active_pipeline.clear_registered_output_files()\n",
    "    completed_good = True # completed successfully (without raising an error at least).\n",
    "\n",
    "except Exception as e:\n",
    "    completed_good =  False\n",
    "    raise\n",
    "    # exception_info = sys.exc_info()\n",
    "    # e = CapturedException(e, exception_info)\n",
    "    # print(f'main_complete_figure_generations failed with exception: {e}')\n",
    "    # if fail_on_exception:\n",
    "    #     raise e.exc\n",
    "\n",
    "\n",
    "\n",
    "## OUTPUTS: completed_good\n",
    "print(f'completed_good: {completed_good}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736407dd",
   "metadata": {},
   "source": [
    "# 2025-06-13 - Heuristic Scores used continuously as replay detection \n",
    "[/c:/Users/pho/repos/Spike3DWorkEnv/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/heuristic_replay_scoring.py:3187](vscode://file/c:/Users/pho/repos/Spike3DWorkEnv/pyPhoPlaceCellAnalysis/src/pyphoplacecellanalysis/Analysis/Decoder/heuristic_replay_scoring.py:3187)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3c4676",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get global/continuous result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5df166",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Analysis.Decoder.context_dependent import GenericDecoderDictDecodedEpochsDictResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import _helper_add_interpolated_position_columns_to_decoded_result_df\n",
    "\n",
    "## Run heuristic continuously to determine when to split sequences and thus where replays are\n",
    "\n",
    "valid_EpochComputations_result: EpochComputationsComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['EpochComputations']\n",
    "a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult = valid_EpochComputations_result.a_generic_decoder_dict_decoded_epochs_dict_result\n",
    "\n",
    "## INPUTS: a_new_fully_generic_result\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='nan_filled', data_grain='per_time_bin')\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='ignore', data_grain='per_time_bin')\n",
    "best_matching_context, a_result, a_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=a_target_context, debug_print=False)\n",
    "## OUTPUTS: a_result, a_decoder, a_decoded_marginal_posterior_df\n",
    "## INPUTS: curr_active_pipeline, a_result, a_decoder, a_decoded_marginal_posterior_df\n",
    "global_measured_position_df: pd.DataFrame = deepcopy(curr_active_pipeline.sess.position.to_dataframe())\n",
    "a_decoded_marginal_posterior_df: pd.DataFrame = _helper_add_interpolated_position_columns_to_decoded_result_df(a_result=a_result, a_decoder=a_decoder, a_decoded_marginal_posterior_df=a_decoded_marginal_posterior_df, global_measured_position_df=global_measured_position_df)\n",
    "\n",
    "global_decoded_result: SingleEpochDecodedResult = a_result.get_result_for_epoch(0)\n",
    "p_x_given_n: NDArray[ND.Shape[\"N_POS_BINS, 4, N_TIME_BINS\"], np.floating] = deepcopy(global_decoded_result.p_x_given_n) # .shape # (59, 4, 69488)\n",
    "time_bin_centers: NDArray[ND.Shape[\"N_TIME_BINS\"], np.floating] = deepcopy(global_decoded_result.time_bin_container.centers)\n",
    "xbin: NDArray[ND.Shape[\"N_POS_BINS\"], np.floating] = deepcopy(a_decoder.xbin)\n",
    "p_x_given_n.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370d7665",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unpack from pipeline:\n",
    "valid_EpochComputations_result: EpochComputationsComputationsContainer = curr_active_pipeline.global_computation_results.computed_data['EpochComputations'] # owning_pipeline_reference.global_computation_results.computed_data['EpochComputations']\n",
    "assert valid_EpochComputations_result is not None\n",
    "epochs_decoding_time_bin_size: float = valid_EpochComputations_result.epochs_decoding_time_bin_size ## just get the standard size. Currently assuming all things are the same size!\n",
    "print(f'epochs_decoding_time_bin_size: {epochs_decoding_time_bin_size}')\n",
    "assert epochs_decoding_time_bin_size == valid_EpochComputations_result.epochs_decoding_time_bin_size, f\"\\tERROR: nonPBE_results.epochs_decoding_time_bin_size: {valid_EpochComputations_result.epochs_decoding_time_bin_size} != epochs_decoding_time_bin_size: {epochs_decoding_time_bin_size}\"\n",
    "a_new_fully_generic_result: GenericDecoderDictDecodedEpochsDictResult = valid_EpochComputations_result.a_generic_decoder_dict_decoded_epochs_dict_result ## get existing\n",
    "\n",
    "active_time_bin_size: float = 0.025\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', masked_time_bin_fill_type='dropped', data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps', time_bin_size=0.025\n",
    "# a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='nan_filled', data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps', time_bin_size=0.025\n",
    "a_target_context: IdentifyingContext = IdentifyingContext(trained_compute_epochs='laps', pfND_ndim=1, time_bin_size=active_time_bin_size, decoder_identifier='pseudo2D', known_named_decoding_epochs_type='global', masked_time_bin_fill_type='ignore', data_grain='per_time_bin') # , known_named_decoding_epochs_type='laps', time_bin_size=0.025\n",
    "best_matching_context, a_pseudo2D_result, a_pseudo2D_decoder, a_decoded_marginal_posterior_df = a_new_fully_generic_result.get_results_best_matching_context(context_query=a_target_context, debug_print=False)\n",
    "# print(f'best_matching_context: {best_matching_context}')\n",
    "best_matching_context\n",
    "\n",
    "print(f'a_pseudo2D_result: {a_pseudo2D_result}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a748bd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attrs import asdict\n",
    "from neuropy.utils.indexing_helpers import PandasHelpers\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring, HeuristicScoresTuple, SubsequencesPartitioningResultScoringComputations\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import SubsequencesPartitioningResult\n",
    "\n",
    "\n",
    "## INPUTS: a_pseudo2D_result\n",
    "unique_decoder_names = ['long_LR', 'long_RL', 'short_LR', 'short_RL'] # ['long', 'short']\n",
    "a_pseudo2D_split_to_1D_continuous_results_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = a_pseudo2D_result.split_pseudo2D_result_to_1D_result(pseudo2D_decoder_names_list=unique_decoder_names, a_pseudo2D_decoder=a_pseudo2D_decoder )\n",
    "a_decoded_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = deepcopy(a_pseudo2D_split_to_1D_continuous_results_dict)\n",
    "a_decoded_filter_epochs_decoder_result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b612a680",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INPUTS: track_templates, a_pseudo2D_split_to_1D_continuous_results_dict \n",
    "# pos_bin_edges: NDArray = deepcopy(xbin)\n",
    "# track_templates: TrackTemplates\n",
    "use_bin_units_instead_of_realworld:bool=False\n",
    "# max_ignore_bins:float = 2 ## for PBEs\n",
    "max_ignore_bins:float = 9 ## for Laps\n",
    "# 5 skip bins\n",
    "# same_thresh_cm: float = 6.0\n",
    "same_thresh_cm: float = 60.0\n",
    "# max_jump_distance_cm: float = 60.0\n",
    "max_jump_distance_cm: float = 200.0\n",
    "debug_print=False\n",
    "\n",
    "# pos_bounds = [np.min([track_templates.long_LR_decoder.xbin, track_templates.short_LR_decoder.xbin]), np.max([track_templates.long_LR_decoder.xbin, track_templates.short_LR_decoder.xbin])] # [37.0773897438341, 253.98616538463315]\n",
    "num_pos_bins: int = track_templates.long_LR_decoder.n_xbin_centers\n",
    "xbin_edges: NDArray = deepcopy(track_templates.long_LR_decoder.xbin)\n",
    "decoder_track_length_dict = track_templates.get_track_length_dict()  # {'long_LR': 214.0, 'long_RL': 214.0, 'short_LR': 144.0, 'short_RL': 144.0}\n",
    "\n",
    "# computation_fn_kwargs_dict: passed to each score function to specify additional required parameters\n",
    "computation_fn_kwargs_dict = {\n",
    "    'main_contiguous_subsequence_len': dict(same_thresh_cm=same_thresh_cm, max_ignore_bins=max_ignore_bins, same_thresh_fraction_of_track=None, max_jump_distance_cm=max_jump_distance_cm, pos_bin_edges=deepcopy(xbin_edges)),\n",
    "    'continuous_seq_len_ratio_no_repeats': dict(same_thresh_cm=same_thresh_cm, max_ignore_bins=max_ignore_bins, same_thresh_fraction_of_track=None, max_jump_distance_cm=max_jump_distance_cm, pos_bin_edges=deepcopy(xbin_edges)),\n",
    "    'continuous_seq_sort': dict(same_thresh_cm=same_thresh_cm, max_ignore_bins=max_ignore_bins, same_thresh_fraction_of_track=None, max_jump_distance_cm=max_jump_distance_cm, pos_bin_edges=deepcopy(xbin_edges)),\n",
    "    'sweep_score':  dict(same_thresh_cm=same_thresh_cm, max_ignore_bins=max_ignore_bins, same_thresh_fraction_of_track=None, max_jump_distance_cm=max_jump_distance_cm, num_pos_bins=num_pos_bins, pos_bin_edges=deepcopy(xbin_edges)),\n",
    "    'track_coverage_score':  dict(same_thresh_cm=same_thresh_cm, max_ignore_bins=max_ignore_bins, same_thresh_fraction_of_track=None, max_jump_distance_cm=max_jump_distance_cm, pos_bin_edges=deepcopy(xbin_edges)),\n",
    "    'total_distance_traveled': dict(same_thresh_cm=same_thresh_cm, max_ignore_bins=max_ignore_bins, same_thresh_fraction_of_track=None, max_jump_distance_cm=max_jump_distance_cm, pos_bin_edges=deepcopy(xbin_edges)),\n",
    "} | {k:deepcopy(dict(same_thresh_cm=same_thresh_cm, max_ignore_bins=max_ignore_bins, same_thresh_fraction_of_track=None, max_jump_distance_cm=max_jump_distance_cm, pos_bin_edges=deepcopy(xbin_edges))) for k in ['mseq_len', 'mseq_len_ignoring_intrusions',\n",
    "                                                                                                                                                                                                                    'mseq_len_ignoring_intrusions_and_repeats', 'mseq_len_ratio_ignoring_intrusions_and_repeats', 'mseq_tcov', 'mseq_dtrav']}\n",
    "# computation_fn_kwargs_dict: passed to each score function to specify additional required parameters\n",
    "if computation_fn_kwargs_dict is None:\n",
    "    raise NotImplementedError(f'YOU BETTER PASS ONE! 2024-12-05')\n",
    "\n",
    "all_subseq_partitioning_score_computations_fn_dict = SubsequencesPartitioningResultScoringComputations.build_all_bin_wise_subseq_partitioning_computation_fn_dict()\n",
    "\n",
    "# BEGIN EXPAND cls._run_all_score_computations _______________________________________________________________________ #\n",
    "\n",
    "## INPUTS: a_decoded_filter_epochs_decoder_result_dict, decoder_track_length_dict\n",
    "partition_result_dict: Dict[types.DecoderName, List[SubsequencesPartitioningResult]] = {} # SubsequencesPartitioningResult\n",
    "# END for `a_decoded_filter_epochs_decoder_result_dict`\n",
    "## OUTPUTS: all_epochs_scores_dict, all_epochs_scores_df\n",
    "# all_epochs_scores_df = pd.DataFrame(all_epochs_scores_dict)\n",
    "\n",
    "_out_new_scores: Dict[str, pd.DataFrame] = {}\n",
    "\n",
    "for a_name, a_result in a_decoded_filter_epochs_decoder_result_dict.items():\n",
    "    ## all four decoders are guaranteed to be independent\n",
    "    # Performs the score computations specified in `all_score_computations_fn_dict` \n",
    "    # Idea is to have a general format for the functions that can be ran, and this function loops through all of them passing them what they need to run (all decoders, all epochs) and then collects their outputs to get simple DataFrames of scores for each epoch.\n",
    "\n",
    "    a_decoder_track_length: float = decoder_track_length_dict[a_name]\n",
    "\n",
    "    _all_epochs_scores_dict = {} # holds a single flat dataframe with scores from across all decoders\n",
    "    _separate_decoder_new_scores_df = {} # holds one df for each decoder name in a_decoded_filter_epochs_decoder_result_dict\n",
    "    _a_separate_decoder_new_scores_dict = {}\n",
    "    # _a_separate_decoder_partition_result_dict: Dict[types.DecoderName, List[SubsequencesPartitioningResult]] = {} # SubsequencesPartitioningResult\n",
    "\n",
    "    partition_result_dict[a_name] = [SubsequencesPartitioningResultScoringComputations._META_build_epoch_SubsequencesPartitioningResult(a_result=a_result, an_epoch_idx=an_epoch_idx, a_decoder_track_length=a_decoder_track_length, same_thresh_cm=same_thresh_cm, max_ignore_bins=int(max_ignore_bins), same_thresh_fraction_of_track=None, max_jump_distance_cm=max_jump_distance_cm, pos_bin_edges=deepcopy(xbin_edges)) for an_epoch_idx in np.arange(a_result.num_filter_epochs)]\n",
    "\n",
    "    ## compute all `subseq_partitioning` scores for this decoder:\n",
    "    for score_computation_name, computation_fn in all_subseq_partitioning_score_computations_fn_dict.items():\n",
    "        score_name: str = score_computation_name # bin_wise_position_difference.short_name or bin_wise_position_difference.__name__\n",
    "        single_decoder_column_name = f\"{score_name}\"\n",
    "        unique_full_decoder_score_column_name: str = f\"{score_name}_{a_name}\"\n",
    "\n",
    "        # 'main_contiguous_subsequence_len_short_LR'\n",
    "        _all_epochs_scores_dict[unique_full_decoder_score_column_name] = [computation_fn(partition_result=a_partition_result, a_result=a_result, an_epoch_idx=an_epoch_idx, a_decoder_track_length=a_decoder_track_length, pos_bin_edges=xbin_edges) for an_epoch_idx, a_partition_result in enumerate(partition_result_dict[a_name])]\n",
    "        _a_separate_decoder_new_scores_dict[single_decoder_column_name] = deepcopy(_all_epochs_scores_dict[unique_full_decoder_score_column_name]) # a single column, all epochs\n",
    "    # END for all_subseq_partitioning_score_computations_fn_dict\n",
    "\n",
    "\n",
    "    ## once done with all scores for this decoder, have `_a_separate_decoder_new_scores_dict`:\n",
    "    _separate_decoder_new_scores_df[a_name] =  pd.DataFrame(_a_separate_decoder_new_scores_dict)\n",
    "    assert np.shape(_separate_decoder_new_scores_df[a_name])[0] == np.shape(a_result.filter_epochs)[0], f\"np.shape(separate_decoder_new_scores_df[a_name])[0]: {np.shape(_separate_decoder_new_scores_df[a_name])[0]} != np.shape(a_result.filter_epochs)[0]: {np.shape(a_result.filter_epochs)[0]}\"\n",
    "    a_result.filter_epochs = PandasHelpers.adding_additional_df_columns(original_df=a_result.filter_epochs, additional_cols_df=_separate_decoder_new_scores_df[a_name]) # update the filter_epochs with the new columns\n",
    "\n",
    "    _out_new_scores[a_name] =  pd.DataFrame([asdict(HeuristicReplayScoring.compute_pho_heuristic_replay_scores(a_result=a_result, an_epoch_idx=an_epoch_idx, pos_bin_edges=deepcopy(xbin_edges), use_bin_units_instead_of_realworld=use_bin_units_instead_of_realworld, max_ignore_bins=max_ignore_bins, same_thresh_cm=same_thresh_cm, max_jump_distance_cm=max_jump_distance_cm), filter=lambda a, v: a.name not in ['position_derivatives_df']) for an_epoch_idx in np.arange(a_result.num_filter_epochs)])\n",
    "    assert np.shape(_out_new_scores[a_name])[0] == np.shape(a_result.filter_epochs)[0], f\"np.shape(_out_new_scores[a_name])[0]: {np.shape(_out_new_scores[a_name])[0]} != np.shape(a_result.filter_epochs)[0]: {np.shape(a_result.filter_epochs)[0]}\"\n",
    "    a_result.filter_epochs = PandasHelpers.adding_additional_df_columns(original_df=a_result.filter_epochs, additional_cols_df=_out_new_scores[a_name]) # update the filter_epochs with the new columns\n",
    "# END for a_name, a_result in....\n",
    "\n",
    "## OUTPUTS: a_decoded_filter_epochs_decoder_result_dict, _out_new_scores, partition_result_dict\n",
    "partition_result_dict = {k:v[0] for k, v in partition_result_dict.items()} ## there's only one entry in this list\n",
    "\n",
    "# _out_new_scores = {k:v[0] for k, v in _out_new_scores.items()}\n",
    "# _out_new_scores\n",
    "\n",
    "# ~1m5s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17f65d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Single decoder test:\n",
    "a_partition_result: SubsequencesPartitioningResult = deepcopy(partition_result_dict[a_name])\n",
    "a_partition_result\n",
    "bin_width, (x_starts, x_centers, x_ends), x_bins = a_partition_result.get_flat_time_bins_info()\n",
    "\n",
    "# a_partition_result.merged_split_position_flatindicies_arrays\n",
    "subsequences_df: pd.DataFrame = deepcopy(a_partition_result.subsequences_df)\n",
    "subsequences_df\n",
    "\n",
    "high_heuristic_only_subsequences_df: pd.DataFrame = subsequences_df[subsequences_df['len_excluding_intrusions'] > 6]\n",
    "high_heuristic_only_subsequences_df\n",
    "\n",
    "\n",
    "# high_heuristic_only_subsequences_df: pd.DataFrame = subsequences_df[subsequences_df['len_excluding_both'] > 5]\n",
    "# high_heuristic_only_subsequences_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0909440",
   "metadata": {},
   "source": [
    "### Add `high_heuristic_only_subsequences_df` as epoch Intervals (rectangles) on the Spike2DRaster interval timeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cee425",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_2d_plot.interval_rendering_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b9a31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add `high_heuristic_only_subsequences_df` as epochs on the Spike2DRaster interval timeline\n",
    "interval_info = active_2d_plot.list_all_rendered_intervals()\n",
    "interval_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff56cfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_display_configs = active_2d_plot.extract_interval_display_config_lists()\n",
    "# epoch_display_configs\n",
    "# active_2d_plot.interval_datasources # RenderPlotsData\n",
    "# datasource_to_update\n",
    "\n",
    "from pyphoplacecellanalysis.PhoPositionalData.plotting.mixins.epochs_plotting_mixins import EpochDisplayConfig\n",
    "\n",
    "out_configs_df = []\n",
    "# rendered_epoch_names = self.interval_datasource_names\n",
    "for a_name, a_config_list in epoch_display_configs.items():\n",
    "    num_configs: int = len(a_config_list)\n",
    "    for (i, a_config) in enumerate(a_config_list):\n",
    "        if num_configs > 1:\n",
    "            config_name: str = f'{a_name}[{i}]'\n",
    "        else:\n",
    "            config_name: str = a_name\n",
    "        # a_config\n",
    "        out_config_dict = {'name': config_name} | deepcopy(a_config.to_dict())\n",
    "        out_configs_df.append(out_config_dict) # [a_name] = result\n",
    "    \n",
    "\n",
    "out_configs_df: pd.DataFrame = pd.DataFrame(out_configs_df)\n",
    "out_configs_df['y0_location'] = out_configs_df['y_location']\n",
    "out_configs_df['y1_location'] = out_configs_df['y0_location'] + out_configs_df['height']\n",
    "out_configs_df\n",
    "any_interval_ymin = np.min(out_configs_df['y0_location'])\n",
    "any_interval_ymax = np.max(out_configs_df['y1_location'])\n",
    "\n",
    "## OUTPUTS: out_configs_df, any_interval_ymin, any_interval_ymax\n",
    "any_interval_ymin, any_interval_ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71f72bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_x_min, curr_x_max, curr_y_min, curr_y_max = active_2d_plot.get_render_intervals_plot_range()\n",
    "(curr_x_min, curr_x_max, curr_y_min, curr_y_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c6fd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_series_positioning_dfs, all_series_compressed_positioning_dfs, all_series_compressed_positioning_update_dicts = active_2d_plot.recover_interval_datasources_positioning_properties()\n",
    "all_series_compressed_positioning_dfs\n",
    "# all_series_compressed_positioning_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1078e89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.Specific2DRenderTimeEpochs import General2DRenderTimeEpochs, inline_mkColor\n",
    "from pyphoplacecellanalysis.GUI.PyQtPlot.Widgets.Mixins.RenderTimeEpochs.EpochRenderingMixin import EpochRenderingMixin\n",
    "from pyphoplacecellanalysis.General.Model.Datasources.IntervalDatasource import IntervalsDatasource\n",
    "from neuropy.utils.mixins.time_slicing import TimeColumnAliasesProtocol\n",
    "from pyphoplacecellanalysis.General.Model.Configs.LongShortDisplayConfig import DecoderIdentityColors\n",
    "\n",
    "decoder_color_dict: Dict[types.DecoderName, str] = DecoderIdentityColors.build_decoder_color_dict()\n",
    "\n",
    "\n",
    "## INPUTS: partition_result_dict, any_interval_ymin\n",
    "_out_epochs_formatting_dict = {}\n",
    "# interval_y_height: float = 0.9\n",
    "# interval_y_padding: float = 0.1\n",
    "# for i, (a_decoder_name, v) in enumerate(partition_result_dict.items()):\n",
    "#     curr_interval_total_y_offset: float = (-float(i) * (interval_y_padding + interval_y_height)) + any_interval_ymin\n",
    "#     _out_epochs_formatting_dict[f\"HSeq_{a_decoder_name}\"] = dict(y_location=curr_interval_total_y_offset, height=interval_y_height, pen_color=inline_mkColor('white', 0.8), brush_color=inline_mkColor('white', 0.5))\n",
    "\n",
    "interval_y_height: float = 0.9\n",
    "interval_y_padding: float = 0.1\n",
    "required_vertical_offsets = []\n",
    "required_interval_heights = []\n",
    "for i, (a_decoder_name, v) in enumerate(partition_result_dict.items()):\n",
    "    # curr_interval_total_y_offset: float = (-float(i) * (interval_y_padding + interval_y_height)) + any_interval_ymin\n",
    "    curr_interval_total_y_offset: float =  -(interval_y_padding + interval_y_height) + any_interval_ymin\n",
    "    _out_epochs_formatting_dict[f\"HSeq_{a_decoder_name}\"] = dict(y_location=curr_interval_total_y_offset, height=interval_y_height,\n",
    "                                                                #   pen_color=inline_mkColor('white', 0.8),\n",
    "                                                                    pen_color=inline_mkColor(decoder_color_dict[a_decoder_name], 0.8),\n",
    "                                                                    brush_color=inline_mkColor('white', 0.5))\n",
    "    required_vertical_offsets.append(curr_interval_total_y_offset)\n",
    "    required_interval_heights.append(interval_y_height)\n",
    "# _out_epochs_formatting_dict = {'HSeq_long_LR': {'y_location': -4.0, 'height': 0.9, 'pen_color': inline_mkColor('white', 0.8), 'brush_color': inline_mkColor('white', 0.5)},\n",
    "#  'HSeq_long_RL': {'y_location': -4.0, 'height': 0.9, 'pen_color': inline_mkColor('white', 0.8), 'brush_color': inline_mkColor('white', 0.5)},\n",
    "#  'HSeq_short_LR': {'y_location': -4.0, 'height': 0.9, 'pen_color': inline_mkColor('white', 0.8), 'brush_color': inline_mkColor('white', 0.5)},\n",
    "#  'HSeq_short_RL': {'y_location': -4.0, 'height': 0.9, 'pen_color': inline_mkColor('white', 0.8), 'brush_color': inline_mkColor('white', 0.5)}}\n",
    "\n",
    "## OUTPUTS: _out_epochs_formatting_dict\n",
    "_out_epochs_formatting_dict\n",
    "\n",
    "required_columns_synonym_dict = {\"start\":{'start_t','begin','start_t'}, \"stop\":['end_t', 'end','stop_t']}\n",
    "# required_vertical_offsets, required_interval_heights = EpochRenderingMixin.build_stacked_epoch_layout([0.23, 0.23, 0.23, 0.23], epoch_render_stack_height=1.0, interval_stack_location='below') # ratio of heights to each interval\n",
    "# required_vertical_offsets, required_interval_heights\n",
    "\n",
    "stacked_epoch_layout_dict = {interval_key:dict(y_location=y_location, height=height) for interval_key, y_location, height in zip(list(_out_epochs_formatting_dict.keys()), required_vertical_offsets, required_interval_heights)} # Build a stacked_epoch_layout_dict to update the display\n",
    "# stacked_epoch_layout_dict # {'LapsAll': {'y_location': -3.6363636363636367, 'height': 3.6363636363636367}, 'LapsTrain': {'y_location': -21.818181818181817, 'height': 18.18181818181818}, 'LapsTest': {'y_location': -40.0, 'height': 18.18181818181818}}\n",
    "\n",
    "# replaces 'y_location', 'position' for each dict:\n",
    "_out_epochs_formatting_dict = {k:(v|stacked_epoch_layout_dict[k]) for k, v in _out_epochs_formatting_dict.items()}\n",
    "_out_epochs_formatting_dict\n",
    "\n",
    "\n",
    "# a_partition_result: SubsequencesPartitioningResult = deepcopy(partition_result_dict[a_name])\n",
    "# a_partition_result\n",
    "# bin_width, (x_starts, x_centers, x_ends), x_bins = a_partition_result.get_flat_time_bins_info()\n",
    "# train_test_split_laps_dfs_dict = {k:TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(df=v, required_columns_synonym_dict=IntervalsDatasource._time_column_name_synonyms) for k, v in partition_result_dict.items()}\n",
    "## Build interval datasources for them:\n",
    "# train_test_split_laps_dfs_datasources_dict = {k:General2DRenderTimeEpochs.build_render_time_epochs_datasource(v) for k, v in train_test_split_laps_dfs_dict.items()}\n",
    "## INPUTS: active_2d_plot, _out_epochs_formatting_dict, train_test_split_laps_dfs_datasources_dict\n",
    "for a_decoder_name, a_partition_result in partition_result_dict.items():\n",
    "    a_heuristic_result_name: str = f\"HSeq_{a_decoder_name}\"\n",
    "    subsequences_df: pd.DataFrame = deepcopy(a_partition_result.subsequences_df)\n",
    "    high_heuristic_only_subsequences_df: pd.DataFrame = subsequences_df[subsequences_df['len_excluding_both'] > 5]\n",
    "    high_heuristic_only_subsequences_df = TimeColumnAliasesProtocol.renaming_synonym_columns_if_needed(df=high_heuristic_only_subsequences_df, required_columns_synonym_dict=required_columns_synonym_dict)\n",
    "    if 't_duration' not in high_heuristic_only_subsequences_df.columns:\n",
    "        high_heuristic_only_subsequences_df['t_duration'] = high_heuristic_only_subsequences_df['stop'] - high_heuristic_only_subsequences_df['start']\n",
    "    an_interval_ds = General2DRenderTimeEpochs.build_render_time_epochs_datasource(high_heuristic_only_subsequences_df)\n",
    "\n",
    "    an_interval_ds.update_visualization_properties(lambda active_df, **kwargs: General2DRenderTimeEpochs._update_df_visualization_columns(active_df, **(_out_epochs_formatting_dict[a_heuristic_result_name] | kwargs)))\n",
    "    active_2d_plot.add_rendered_intervals(an_interval_ds, name=a_heuristic_result_name, debug_print=False) # adds the interval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9890ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21ae8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_heuristic_only_subsequences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9016a2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_partition_result.position_bins_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c908a41d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674d5fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_out_new_scores['long_LR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48fa7a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a88d296",
   "metadata": {},
   "source": [
    "# 2025-06-16 - Need to update heuristic to work on behavioral-scale (laps) movement sequences\\\n",
    "- [ ] Ignore theta-scale oscilations/regressions in decoded position\n",
    "- [ ] Recognize the majority of lap position bins as beloning to the same sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d04b6f",
   "metadata": {},
   "source": [
    "## Compute heuristics for current laps objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748d2bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.epoch import TimeColumnAliasesProtocol\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.reconstruction import DecodedFilterEpochsResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import filter_and_update_epochs_and_spikes\n",
    "from pyphoplacecellanalysis.Analysis.Decoder.heuristic_replay_scoring import HeuristicReplayScoring, HeuristicsResult\n",
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import DirectionalPseudo2DDecodersResult\n",
    "\n",
    "## 2025-06-16 14:22 Copied from `pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions._decoded_epochs_heuristic_scoring` but generalized for laps\n",
    "same_thresh_fraction_of_track: float = 0.05\n",
    "max_ignore_bins:float = 9\n",
    "# max_jump_distance_cm: float = 60.0\n",
    "max_jump_distance_cm: float = 260.0\n",
    "use_bin_units_instead_of_realworld:bool = False\n",
    "\n",
    "\n",
    "# 🟪 2024-02-29 - `compute_pho_heuristic_replay_scores` ______________________________________________________________ #\n",
    "minimum_inclusion_fr_Hz: float = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.minimum_inclusion_fr_Hz\n",
    "included_qclu_values: List[int] = curr_active_pipeline.global_computation_results.computation_config.rank_order_shuffle_analysis.included_qclu_values\n",
    "\n",
    "# rank_order_results = global_computation_results.computed_data['RankOrder'] # : \"RankOrderComputationsContainer\"\n",
    "# minimum_inclusion_fr_Hz: float = rank_order_results.minimum_inclusion_fr_Hz\n",
    "# included_qclu_values: List[int] = rank_order_results.included_qclu_values\n",
    "directional_laps_results: DirectionalLapsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalLaps']\n",
    "track_templates: TrackTemplates = directional_laps_results.get_templates(minimum_inclusion_fr_Hz=minimum_inclusion_fr_Hz, included_qclu_values=included_qclu_values) # non-shared-only -- !! Is minimum_inclusion_fr_Hz=None the issue/difference?\n",
    "# print(f'minimum_inclusion_fr_Hz: {minimum_inclusion_fr_Hz}')\n",
    "# print(f'included_qclu_values: {included_qclu_values}')\n",
    "\n",
    "decoder_track_length_dict = track_templates.get_track_length_dict() # {'long_LR': 214.0, 'long_RL': 214.0, 'short_LR': 144.0, 'short_RL': 144.0}\n",
    "\n",
    "# same_thresh_fraction_of_track: float = 0.025 ## up to 2.5% of the track -- notably worse\n",
    "# same_thresh_fraction_of_track: float = 0.05 ## up to 5.0% of the track\n",
    "\n",
    "# same_thresh_fraction_of_track: float = 0.15 ## up to 15% of the track\n",
    "same_thresh_cm_dict: Dict[types.DecoderName, float] = {k:(v * same_thresh_fraction_of_track) for k, v in decoder_track_length_dict.items()}\n",
    "# same_thresh_n_bin_units: float = {k:(v * same_thresh_fraction_of_track) for k, v in decoder_track_length_dict.items()}\n",
    "\n",
    "a_same_thresh_cm: float = same_thresh_cm_dict['long_LR'] # ALWAYS USE THE SAME FOR ALL TRACKS/DECODERS\n",
    "# a_same_thresh_cm: float = 0.0\n",
    "print(f'same_thresh_cm: {a_same_thresh_cm}')\n",
    "\n",
    "\n",
    "# DirectionalMergedDecoders: Get the result after computation:\n",
    "directional_merged_decoders_result: DirectionalPseudo2DDecodersResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalMergedDecoders']\n",
    "ripple_decoding_time_bin_size: float = directional_merged_decoders_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_merged_decoders_result.laps_decoding_time_bin_size\n",
    "\n",
    "# DirectionalDecodersEpochsEvaluations\n",
    "directional_decoders_epochs_decode_result: DecoderDecodedEpochsResult = curr_active_pipeline.global_computation_results.computed_data['DirectionalDecodersEpochsEvaluations']\n",
    "pos_bin_size: float = directional_decoders_epochs_decode_result.pos_bin_size\n",
    "ripple_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size\n",
    "laps_decoding_time_bin_size: float = directional_decoders_epochs_decode_result.laps_decoding_time_bin_size\n",
    "decoder_laps_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict\n",
    "# decoder_ripple_filter_epochs_decoder_result_dict: Dict[str, DecodedFilterEpochsResult] = directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict\n",
    "\n",
    "decoder_laps_filter_epochs_decoder_result_dict, _laps_out_new_scores, _laps_partition_result_dict = HeuristicReplayScoring.compute_all_heuristic_scores(track_templates=track_templates, a_decoded_filter_epochs_decoder_result_dict=decoder_laps_filter_epochs_decoder_result_dict,\n",
    "                                                            same_thresh_cm=a_same_thresh_cm, max_ignore_bins=max_ignore_bins, max_jump_distance_cm=max_jump_distance_cm, use_bin_units_instead_of_realworld=use_bin_units_instead_of_realworld)\n",
    "a_laps_heuristics_result: HeuristicsResult = HeuristicsResult(is_global=True, heuristic_scores_df_dict=_laps_out_new_scores, partition_result_dict=_laps_partition_result_dict)\n",
    "## OUTPUTS: a_laps_heuristics_result, decoder_laps_filter_epochs_decoder_result_dict, (_laps_out_new_scores, _laps_partition_result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314523c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import SerializationHelper_AllCustomDecodingResults\n",
    "\n",
    "## Serialize the output:\n",
    "output_path = Path(r'K:\\scratch\\output').resolve()\n",
    "Assert.path_exists(output_path)\n",
    "heuristics_pkl_output_path = output_path.joinpath('heuristics_pkl.pkl').resolve()\n",
    "a_laps_heuristics_result.save(pkl_output_path=heuristics_pkl_output_path, status_print=True)\n",
    "heuristics_pkl_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c2d038",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.SpecificResults.PendingNotebookCode import SerializationHelper_AllCustomDecodingResults\n",
    "\n",
    "save_path = curr_active_pipeline.get_output_path().joinpath(f\"{DAY_DATE_TO_USE}_AllCustomDecodingResults.pkl\").resolve()\n",
    "save_path = SerializationHelper_AllCustomDecodingResults.save(track_templates=track_templates, a_directional_decoders_epochs_decode_result=directional_decoders_epochs_decode_result, \n",
    "                                        #    a_decoded_filter_epochs_decoder_result_dict=deepcopy(a_decoded_filter_epochs_decoder_result_dict),\n",
    "                                           pos_bin_size=directional_decoders_epochs_decode_result.pos_bin_size,\n",
    "\t\t\t\t\t\t\t\t\t\t   laps_decoding_time_bin_size=directional_decoders_epochs_decode_result.laps_decoding_time_bin_size,\n",
    "\t\t\t\t\t\t\t\t\t\t   #  ripple_decoding_time_bin_size=directional_decoders_epochs_decode_result.ripple_decoding_time_bin_size,\n",
    "\t\t\t\t\t\t\t\t\t\t    save_path=save_path)\n",
    "save_path\n",
    "\n",
    "\n",
    "# load_path = Path(\"W:/Data/KDIBA/gor01/one/2006-6-09_1-22-43/output/2025-06-16_AllCustomDecodingResults.pkl\")\n",
    "# track_templates, directional_decoders_epochs_decode_result, xbin, xbin_centers =  SerializationHelper_AllCustomDecodingResults.save(load_path=load_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d05c048",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_laps_filter_epochs_decoder_result_dict['long_LR'].filter_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5747f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_decoder_decoded_epochs_result_dict: Dict[types.DecoderName, DecodedFilterEpochsResult] = deepcopy(decoder_laps_filter_epochs_decoder_result_dict)\n",
    "active_filter_epochs_df: pd.DataFrame = deepcopy(active_decoder_decoded_epochs_result_dict['long_LR'].filter_epochs) # deepcopy(matching_specific_start_ts_only_filter_epochs_df)\n",
    "active_filter_epochs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93affb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get laps\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "t_start, t_delta, t_end = curr_active_pipeline.find_LongShortDelta_times()\n",
    "global_session = curr_active_pipeline.filtered_sessions[global_epoch_name]\n",
    "# global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps) # .trimmed_to_non_overlapping()\n",
    "global_laps_epochs_df = global_laps.to_dataframe()\n",
    "# active_test_epochs_df: pd.DataFrame = deepcopy(global_laps_epochs_df)\n",
    "global_laps_epochs_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e6b56d",
   "metadata": {},
   "source": [
    "## Test Plot Heuristic Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185607cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.GUI.Silx.EpochHeuristicPosteriorDebuggerWidget import EpochHeuristicDebugger\n",
    "\n",
    "\n",
    "# a_decoder_decoded_epochs_result: DecodedFilterEpochsResult = deepcopy(directional_decoders_epochs_decode_result.decoder_ripple_filter_epochs_decoder_result_dict['long_LR'])\n",
    "a_decoder_decoded_epochs_result: DecodedFilterEpochsResult = deepcopy(directional_decoders_epochs_decode_result.decoder_laps_filter_epochs_decoder_result_dict['long_LR'])\n",
    "\n",
    "p_x_given_n_masked = deepcopy(a_decoder_decoded_epochs_result.p_x_given_n_list[5])\n",
    "p_x_given_n_masked\n",
    "\n",
    "dbgr = EpochHeuristicDebugger(p_x_given_n_masked=deepcopy(p_x_given_n_masked))\n",
    "dbgr.build_ui()\n",
    "\n",
    "slider = widgets.IntSlider(value=12, min=0, max=(a_decoder_decoded_epochs_result.num_filter_epochs-1))\n",
    "slider.observe(dbgr.on_slider_change, names='value')\n",
    "display(slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7ebc43",
   "metadata": {},
   "source": [
    "## 2025-06-16 - Simple 2D plot with Long Track Shape drawn under the x-axis and the Short Track Shape drawn to the left of the y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a68477",
   "metadata": {
    "tags": [
     "todo-2025-06-16"
    ]
   },
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import create_long_v_short_track_plot_figure\n",
    "\n",
    "active_config = global_session.config\n",
    "fig, ax_dict, long_inst, short_inst, long_out, short_out = create_long_v_short_track_plot_figure(active_config)\n",
    "\n",
    "# Add your data to the main plot\n",
    "# ax_dict[\"ax_main\"].scatter(x_data, y_data)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b732fe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphocorehelpers.geometry_helpers import BoundsRect\n",
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import LinearTrackDimensions, LinearTrackInstance\n",
    "\n",
    "platform_side_length:float=22.0\n",
    "# a_sess_config = deepcopy(active_config)\n",
    "# loaded_track_limits = deepcopy(a_sess_config.loaded_track_limits) # {'long_xlim': array([59.0774, 228.69]), 'short_xlim': array([94.0156, 193.757]), 'long_ylim': array([138.164, 146.12]), 'short_ylim': array([138.021, 146.263])}\n",
    "loaded_track_limits = {'long_xlim': np.array([59.0774, 228.69]),\n",
    " 'long_unit_xlim': np.array([0.205294, 0.794698]),\n",
    " 'short_xlim': np.array([94.0156, 193.757]),\n",
    " 'short_unit_xlim': np.array([0.326704, 0.673304]),\n",
    " 'long_ylim': np.array([138.164, 146.12]),\n",
    " 'long_unit_ylim': np.array([0.48012, 0.507766]),\n",
    " 'short_ylim': np.array([138.021, 146.263]),\n",
    " 'short_unit_ylim': np.array([0.479622, 0.508264])}\n",
    "\n",
    "loaded_track_limits\n",
    "# x_midpoint: float = a_sess_config.x_midpoint\n",
    "# pix2cm: float = a_sess_config.pix2cm\n",
    "\n",
    "long_xlim = loaded_track_limits['long_xlim']\n",
    "long_ylim = loaded_track_limits['long_ylim']\n",
    "\n",
    "## if we have short, build that one too:\n",
    "short_xlim = loaded_track_limits['short_xlim']\n",
    "short_ylim = loaded_track_limits['short_ylim']\n",
    "\n",
    "LONG_from_mat_lims_grid_bin_bounds = BoundsRect(xmin=(long_xlim[0]-platform_side_length), xmax=(long_xlim[1]+platform_side_length), ymin=long_ylim[0], ymax=long_ylim[1])\n",
    "SHORT_from_mat_lims_grid_bin_bounds = BoundsRect(xmin=(short_xlim[0]-platform_side_length), xmax=(short_xlim[1]+platform_side_length), ymin=short_ylim[0], ymax=short_ylim[1])\n",
    "\n",
    "long_track_inst = LinearTrackInstance(LinearTrackDimensions.init_from_grid_bin_bounds(LONG_from_mat_lims_grid_bin_bounds), grid_bin_bounds=LONG_from_mat_lims_grid_bin_bounds)\n",
    "short_track_inst = LinearTrackInstance(LinearTrackDimensions.init_from_grid_bin_bounds(SHORT_from_mat_lims_grid_bin_bounds), grid_bin_bounds=SHORT_from_mat_lims_grid_bin_bounds)\n",
    "\n",
    "## OUTPUTS: long_track_inst, short_track_inst\n",
    "fig, ax_dict, long_inst, short_inst, long_out, short_out = create_long_v_short_track_plot_figure(long_track_inst=long_track_inst, short_track_inst=short_track_inst)\n",
    "\n",
    "# Add your data to the main plot\n",
    "# ax_dict[\"ax_main\"].scatter(x_data, y_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366abba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.Pho2D.track_shape_drawing import create_long_v_short_track_plot_figure_from_loaded_track_limits\n",
    "\n",
    "loaded_track_limits = {'long_xlim': np.array([59.0774, 228.69]),\n",
    " 'long_unit_xlim': np.array([0.205294, 0.794698]),\n",
    " 'short_xlim': np.array([94.0156, 193.757]),\n",
    " 'short_unit_xlim': np.array([0.326704, 0.673304]),\n",
    " 'long_ylim': np.array([138.164, 146.12]),\n",
    " 'long_unit_ylim': np.array([0.48012, 0.507766]),\n",
    " 'short_ylim': np.array([138.021, 146.263]),\n",
    " 'short_unit_ylim': np.array([0.479622, 0.508264])}\n",
    "\n",
    "fig, ax_dict, long_inst, short_inst, long_out, short_out = create_long_v_short_track_plot_figure_from_loaded_track_limits(loaded_track_limits=loaded_track_limits)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8237a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_track_limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874f4d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50010259",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_figures_script_paths = [Path(v) for v in ['C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts\\\\run_kdiba_gor01_one_2006-6-07_11-26-53\\\\figures_kdiba_gor01_one_2006-6-07_11-26-53.py',\n",
    " 'C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts\\\\run_kdiba_gor01_one_2006-6-08_14-26-15\\\\figures_kdiba_gor01_one_2006-6-08_14-26-15.py',\n",
    " 'C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts\\\\run_kdiba_gor01_one_2006-6-09_1-22-43\\\\figures_kdiba_gor01_one_2006-6-09_1-22-43.py',\n",
    " 'C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts\\\\run_kdiba_gor01_one_2006-6-12_15-55-31\\\\figures_kdiba_gor01_one_2006-6-12_15-55-31.py',\n",
    " 'C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts\\\\run_kdiba_gor01_two_2006-6-07_16-40-19\\\\figures_kdiba_gor01_two_2006-6-07_16-40-19.py',\n",
    " 'C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts\\\\run_kdiba_gor01_two_2006-6-08_21-16-25\\\\figures_kdiba_gor01_two_2006-6-08_21-16-25.py',\n",
    " 'C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts\\\\run_kdiba_gor01_two_2006-6-09_22-24-40\\\\figures_kdiba_gor01_two_2006-6-09_22-24-40.py',\n",
    " 'C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts\\\\run_kdiba_gor01_two_2006-6-12_16-53-46\\\\figures_kdiba_gor01_two_2006-6-12_16-53-46.py',\n",
    " 'C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts\\\\run_kdiba_vvp01_one_2006-4-09_17-29-30\\\\figures_kdiba_vvp01_one_2006-4-09_17-29-30.py',\n",
    " 'C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts\\\\run_kdiba_vvp01_one_2006-4-10_12-25-50\\\\figures_kdiba_vvp01_one_2006-4-10_12-25-50.py',\n",
    " 'C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts\\\\run_kdiba_vvp01_two_2006-4-09_16-40-54\\\\figures_kdiba_vvp01_two_2006-4-09_16-40-54.py',\n",
    " 'C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts\\\\run_kdiba_vvp01_two_2006-4-10_12-58-3\\\\figures_kdiba_vvp01_two_2006-4-10_12-58-3.py',\n",
    " 'C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts\\\\run_kdiba_pin01_one_11-02_17-46-44\\\\figures_kdiba_pin01_one_11-02_17-46-44.py',\n",
    " 'C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts\\\\run_kdiba_pin01_one_11-02_19-28-0\\\\figures_kdiba_pin01_one_11-02_19-28-0.py',\n",
    " 'C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts\\\\run_kdiba_pin01_one_11-03_12-3-25\\\\figures_kdiba_pin01_one_11-03_12-3-25.py',\n",
    " 'C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts\\\\run_kdiba_pin01_one_fet11-01_12-58-54\\\\figures_kdiba_pin01_one_fet11-01_12-58-54.py']]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# generate_figures_script_paths\n",
    "# gen_scripts_fig_paths = [Path(r'K:\\scratch\\gen_scripts').joinpath(Path(k).parent.relative_to('C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts')) for k in generate_figures_script_paths]\n",
    "gen_scripts_sess_folder_paths = [Path(r'K:\\scratch\\gen_scripts').joinpath(Path(k).parent.relative_to('C:\\\\Users\\\\pho\\\\repos\\\\Spike3DWorkEnv\\\\Spike3D\\\\output\\\\gen_scripts')) for k in generate_figures_script_paths]\n",
    "gen_scripts_sess_folder_paths\n",
    "# gen_scripts_fig_paths\n",
    "gen_scripts_sess_folder_paths = [v for v in gen_scripts_sess_folder_paths if v.exists()]\n",
    "\n",
    "gen_scripts_fig_paths = [Path(k).parent.joinpath('EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2025-07-02').resolve() for k in gen_scripts_sess_folder_paths]\n",
    "\n",
    "gen_scripts_sess_folder_paths\n",
    "gen_scripts_fig_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1840ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_scripts_fig_paths = [Path(k).parent.joinpath('EXTERNAL/Screenshots/ProgrammaticDisplayFunctionTesting/2025-07-02').resolve() for k in generate_figures_script_paths]\n",
    "\n",
    "gen_scripts_fig_paths = [v for v in gen_scripts_fig_paths if v.exists()]\n",
    "gen_scripts_fig_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ff32be",
   "metadata": {},
   "source": [
    "# 2025-07-08 - Quantitative LxC/SxC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d483de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# track_templates.get_decoder_aclu_peak_map_dict(peak_mode='peaks')\n",
    "\n",
    "# track_templates.long_LR_decoder.\n",
    "\n",
    "## Just needs laps\n",
    "long_epoch_name, short_epoch_name, global_epoch_name = curr_active_pipeline.find_LongShortGlobal_epoch_names()\n",
    "global_spikes_df = deepcopy(curr_active_pipeline.computation_results[global_epoch_name]['computed_data'].pf1D.spikes_df)\n",
    "global_laps = deepcopy(curr_active_pipeline.filtered_sessions[global_epoch_name].laps).trimmed_to_non_overlapping() \n",
    "global_laps_epochs_df = global_laps.to_dataframe()\n",
    "global_laps_epochs_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300212ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# peaks_results_df: pd.DataFrame = track_templates.long_LR_decoder.get_tuning_curve_peak_df(peak_mode='peaks')\n",
    "\n",
    "\n",
    "# peaks_results_df: pd.DataFrame = track_templates.long_LR_decoder.pf.tuning_curves_dict\n",
    "\n",
    "\n",
    "filtered_spikes_df: pd.DataFrame = track_templates.long_LR_decoder.pf.filtered_spikes_df\n",
    "filtered_spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e211b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_counts_dict = {a_decoder_name:deepcopy(a_decoder.pf.filtered_spikes_df['aclu']).value_counts().to_dict() for a_decoder_name, a_decoder in track_templates.get_decoders_dict().items()}\n",
    "any_decoder_aclus_list = deepcopy(track_templates.any_decoder_neuron_IDs)\n",
    "any_decoder_aclus_list ## this somehow loses the short-only cells?!?! Such as [3, 4, 8, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d01cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.DisplayFunctions.MultiContextComparingDisplayFunctions.LongShortTrackComparingDisplayFunctions import PhoJonathanPlotHelpers\n",
    "from pyphoplacecellanalysis.General.Batch.NonInteractiveProcessing import BatchPhoJonathanFiguresHelper\n",
    "\n",
    "## Get global 'jonathan_firing_rate_analysis' results:\n",
    "curr_jonathan_firing_rate_analysis = curr_active_pipeline.global_computation_results.computed_data['jonathan_firing_rate_analysis']\n",
    "neuron_replay_stats_df, rdf, aclu_to_idx, irdf = curr_jonathan_firing_rate_analysis.neuron_replay_stats_df, curr_jonathan_firing_rate_analysis.rdf.rdf, curr_jonathan_firing_rate_analysis.rdf.aclu_to_idx, curr_jonathan_firing_rate_analysis.irdf.irdf\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "# Batch Output of Figures                                                                                              #\n",
    "# ==================================================================================================================== #\n",
    "## 🗨️🟢 2022-11-05 - Pho-Jonathan Batch Outputs of Firing Rate Figures\n",
    "short_only_df = neuron_replay_stats_df[neuron_replay_stats_df.track_membership == SplitPartitionMembership.RIGHT_ONLY]\n",
    "short_only_aclus = short_only_df.index.values.tolist()\n",
    "long_only_df = neuron_replay_stats_df[neuron_replay_stats_df.track_membership == SplitPartitionMembership.LEFT_ONLY]\n",
    "long_only_aclus = long_only_df.index.values.tolist()\n",
    "shared_df = neuron_replay_stats_df[neuron_replay_stats_df.track_membership == SplitPartitionMembership.SHARED]\n",
    "shared_aclus = shared_df.index.values.tolist()\n",
    "print(f'shared_aclus: {shared_aclus}')\n",
    "print(f'long_only_aclus: {long_only_aclus}')\n",
    "print(f'short_only_aclus: {short_only_aclus}')\n",
    "\n",
    "active_identifying_session_ctx = curr_active_pipeline.sess.get_context() # 'bapun_RatN_Day4_2019-10-15_11-30-06'    \n",
    "## MODE: this mode creates a special folder to contain the outputs for this session.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c54a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Pipeline.Stages.ComputationFunctions.MultiContextComputationFunctions.DirectionalPlacefieldGlobalComputationFunctions import TrackTemplates\n",
    "\n",
    "decoders_total_num_spikes_df, (LxC_cells_df, SxC_cells_df) = TrackTemplates.perform_determine_quant_cell_eXclusivities(track_templates=track_templates)\n",
    "# decoders_total_num_spikes_df['aclu'] = decoders_total_num_spikes_df.index\n",
    "decoders_total_num_spikes_df: pd.DataFrame = deepcopy(decoders_total_num_spikes_df)\n",
    "# decoders_total_num_spikes_df = decoders_total_num_spikes_df.neuron_identity.make_neuron_indexed_df_global(curr_active_pipeline.get_session_context(), add_expanded_session_context_keys=False, add_extended_aclu_identity_columns=True)\n",
    "# decoders_total_num_spikes_df\n",
    "# LxC_cells_df, SxC_cells_df\n",
    "\n",
    "# print(decoders_total_num_spikes_df.columns.to_list()) # ['long_LR_n_spikes', 'long_RL_n_spikes', 'short_LR_n_spikes', 'short_RL_n_spikes', 'long_n_spikes', 'short_n_spikes', 'total_n_spikes', 'pct_long_n_spikes', 'pct_short_n_spikes', 'is_n_spikes_LxC', 'is_n_spikes_SxC']\n",
    "# ['long_LR_lap_dur', 'long_RL_lap_dur', 'short_LR_lap_dur', 'short_RL_lap_dur', 'long_lap_dur', 'short_lap_dur', 'total_lap_dur', 'long_fr_Hz', 'short_fr_Hz', 'total_fr_Hz', 'pct_long_fr_Hz', 'pct_short_fr_Hz', 'is_fr_Hz_LxC', 'is_fr_Hz_SxC']\n",
    "decoders_total_num_spikes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b229cc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoders_total_num_spikes_df[decoders_total_num_spikes_df['is_fr_Hz_LxC']]\n",
    "decoders_total_num_spikes_df[decoders_total_num_spikes_df['is_fr_Hz_SxC']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad25c9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_templates.long_LR_decoder.pf.epochs\n",
    "\n",
    "total_duration_dict = {k:deepcopy(v.pf.epochs.duration).sum() for k, v in track_templates.get_decoders_dict().items()}\n",
    "total_duration_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab36cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03f08bdd",
   "metadata": {},
   "source": [
    "# 2025-07-09 - Computation Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10755e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout, _master_params_dict = curr_active_pipeline.get_all_parameters(allow_update_global_computation_config=False, get_panel_gui_widget=True)\n",
    "layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60ee562",
   "metadata": {},
   "outputs": [],
   "source": [
    "_master_params_dict['preprocessing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b725c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuropy.core.parameters import ParametersContainer\n",
    "\n",
    "# After user makes changes, get updated values:\n",
    "current_params = deepcopy(curr_active_pipeline.global_computation_results.computation_config.to_dict())\n",
    "current_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f9fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import ast\n",
    "\n",
    "# Create widgets\n",
    "minimum_fr_widget = widgets.IntText(\n",
    "    value=2,\n",
    "    description='Min FR (Hz):',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='200px')\n",
    ")\n",
    "\n",
    "qclu_text_widget = widgets.Text(\n",
    "    value='[1, 2, 4, 6, 7, 8, 9]',\n",
    "    description='QClu Values:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='300px')\n",
    ")\n",
    "\n",
    "# Button to get values\n",
    "get_values_button = widgets.Button(\n",
    "    description='Get Current Values',\n",
    "    button_style='info'\n",
    ")\n",
    "\n",
    "# Output area\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_button_click(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        \n",
    "        # Parse the qclu values from text\n",
    "        try:\n",
    "            qclu_values = ast.literal_eval(qclu_text_widget.value)\n",
    "            if not isinstance(qclu_values, list):\n",
    "                qclu_values = [qclu_values]\n",
    "        except:\n",
    "            print(\"Error: Invalid format for QClu Values. Please use format: [1, 2, 3, ...]\")\n",
    "            return\n",
    "            \n",
    "        values = {\n",
    "            'minimum_inclusion_fr_Hz': minimum_fr_widget.value,\n",
    "            'included_qclu_values': qclu_values\n",
    "        }\n",
    "        print(\"Selected values:\", values)\n",
    "\n",
    "get_values_button.on_click(on_button_click)\n",
    "\n",
    "# Display interface\n",
    "interface = widgets.VBox([\n",
    "    minimum_fr_widget,\n",
    "    qclu_text_widget,\n",
    "    get_values_button,\n",
    "    output\n",
    "])\n",
    "\n",
    "display(interface)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c586ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preprocessing_parameters: ParametersContainer = deepcopy(curr_active_pipeline.active_sess_config)\n",
    "preprocessing_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fdeaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\t\t\t\t\t\t\t\t\t\n",
    "# long_pf1D.config # {'speed_thresh': 10.0, 'grid_bin': (4.877453969028168, 14.388489208633093), 'grid_bin_bounds': ((0.0, 287.7697841726619), (86.33093525179856, 201.4388489208633)), 'smooth': (2.0, 2.0), 'frate_thresh': 1.0, 'is_directional': False}\n",
    "track_templates.long_LR_decoder.pf.config # {'speed_thresh': 10.0, 'grid_bin': (4.877453969028168, 14.388489208633093), 'grid_bin_bounds': ((0.0, 287.7697841726619), (86.33093525179856, 201.4388489208633)), 'smooth': (2.0, 2.0), 'frate_thresh': 1.0, 'is_directional': False}\n",
    "\n",
    "{'speed_thresh': 10.0, 'grid_bin': (4.877453969028168, 14.388489208633093), 'grid_bin_bounds': ((0.0, 287.7697841726619), (86.33093525179856, 201.4388489208633)), 'smooth': (2.0, 2.0), 'frate_thresh': 1.0, 'is_directional': False} ## Kamran used 1.44cm^2 Pseudo2D bins\n",
    "\n",
    "\n",
    "long_pf2D.config\n",
    "# [/c:/Users/pho/repos/Spike3DWorkEnv/NeuroPy/neuropy/core/session/Formats/BaseDataSessionFormats.py:279](vscode://file/c:/Users/pho/repos/Spike3DWorkEnv/NeuroPy/neuropy/core/session/Formats/BaseDataSessionFormats.py:279)\n",
    "# ```python\n",
    "# # From `core.session.Formats.BaseDataSessionFormats.build_default_computation_configs`\n",
    "# 'speed_thresh': 10.0, 'grid_bin': cls.compute_position_grid_bin_size(sess.position.x, sess.position.y, num_bins=(64, 64)), 'grid_bin_bounds': None, 'smooth': (2.0, 2.0), 'frate_thresh': 1.0, 'time_bin_size': 0.1, \n",
    "# ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2738436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyphoplacecellanalysis.General.Mixins.ExportHelpers import FigureOutputLocation, ContextToPathMode, FileOutputManager\n",
    "\n",
    "out_man: FileOutputManager = curr_active_pipeline.get_output_manager(figure_output_location=FigureOutputLocation.CUSTOM, context_to_path_mode=ContextToPathMode.GLOBAL_UNIQUE, override_output_parent_path=collected_outputs_path)\n",
    "\n",
    "\n",
    "# FileOutputManager(figure_output_location=figure_output_location, context_to_path_mode=context_to_path_mode, override_output_parent_path=override_output_parent_path)\n",
    "\n",
    "out_man"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_UV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
